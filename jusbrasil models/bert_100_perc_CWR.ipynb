{"cells":[{"cell_type":"markdown","metadata":{"id":"FFh7WVoJH5dr"},"source":["Adapted from [ner_with_bilstm_and_crf](https://www.kaggle.com/nikkisharma536/ner-with-bilstm-and-crf/notebook)\n","Altigran Soares da Silva\n","IComp/UFAM - 15/03/2021\n"],"id":"FFh7WVoJH5dr"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10910,"status":"ok","timestamp":1661666609893,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"instant-coupon","outputId":"e096350b-9e5a-4614-e192-768d3f955876"},"outputs":[{"name":"stdout","output_type":"stream","text":["Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.97)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (1.2.2)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n"]}],"source":["# For this to work, use:\n","# Keras 2.3.1\n","# Also remember to use GPU in your colab notebook\n","%tensorflow_version 2.x\n","\n","# Code to read csv file into Colaboratory:\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","from math import nan\n","from future.utils import iteritems\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import math\n","import random\n","import json\n","import pickle\n","import time\n","from requests import get\n","\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import torch\n","from torch import cuda\n","from torch.utils.data import Dataset, DataLoader\n","\n","!pip install sentencepiece\n","!pip install transformers\n","from transformers import BertForTokenClassification, AutoTokenizer\n","\n","!pip install seqeval\n","from seqeval.metrics import f1_score, classification_report"],"id":"instant-coupon"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mmt06ncv89hH"},"outputs":[],"source":["# Code to read csv file from google drive into Colaboratory:\n","DATA_TRAINING_FILE_ID = '1FllL2kWZ5q1E0alqyLz7TGC1qlKYwJxN'\n","DATA_TRAINING_FILENAME = 'ner_training_dataset.csv'\n","DATA_DEV_FILE_ID = '1pJS8Cc_AeixyHXgXm9uB_KaboX5E-G40'\n","DATA_DEV_FILENAME = 'ner_validation_dataset.csv'\n","DATA_TEST_FILE_ID = '1IYIIMhI1uQNjxlp9D4WzEBKLk20gE6RC'\n","DATA_TEST_FILENAME = 'ner_test_dataset.csv'\n","BACKUP_FOLDER_ID = '18ZJg_YZnxA86FdlCUMPqAvdGsXCVCDnb'\n","\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","downloaded_training = drive.CreateFile({'id': DATA_TRAINING_FILE_ID})\n","downloaded_training.GetContentFile(DATA_TRAINING_FILENAME)\n","downloaded_dev = drive.CreateFile({'id': DATA_DEV_FILE_ID})\n","downloaded_dev.GetContentFile(DATA_DEV_FILENAME)\n","downloaded_test = drive.CreateFile({'id': DATA_TEST_FILE_ID})\n","downloaded_test.GetContentFile(DATA_TEST_FILENAME)\n","\n","# Read the csv file in a dataframe called \"data\"\n","training_data = pd.read_csv(DATA_TRAINING_FILENAME, encoding=\"utf-8\")\n","dev_data = pd.read_csv(DATA_DEV_FILENAME, encoding=\"utf-8\")\n","test_data = pd.read_csv(DATA_TEST_FILENAME, encoding=\"utf-8\")\n","# Fill NaN values using the specified method\n","# Ffill propagate last valid observation/value forward to next valid \n","training_data = training_data.fillna(method=\"ffill\")\n","dev_data = dev_data.fillna(method=\"ffill\")\n","test_data = test_data.fillna(method=\"ffill\")\n","\n","notebook_filename = get('http://172.28.0.2:9000/api/sessions').json()[0]['name']"],"id":"Mmt06ncv89hH"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":598},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1661666617750,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"adverse-doctor","outputId":"f3b682a4-3285-4cc7-c36a-156d241db6c7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of training sentences:  1817\n","Number of dev sentences:  321\n","Number of test sentences:  378\n","Number of words in the training dataset:  11597\n","Number of words in the dev dataset:  4202\n","Number of words in the test dataset:  5076\n","Tags in the training dataset: ['I-LEGISLACAO', 'B-LEGISLACAO', 'O']\n","Number of Labels in the training dataset:  3\n","Tags in the dev dataset: ['I-LEGISLACAO', 'B-LEGISLACAO', 'O']\n","Number of Labels in the dev dataset:  3\n","Tags in the test dataset: ['I-LEGISLACAO', 'B-LEGISLACAO', 'O']\n","Number of Labels in the test dataset:  3\n","What the training dataset looks like:\n"]},{"data":{"text/html":["\n","  <div id=\"df-8bdbe96d-972e-425c-bc1e-257fa6d219be\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence #</th>\n","      <th>Word</th>\n","      <th>Tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sentence: 671</td>\n","      <td>“</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sentence: 671</td>\n","      <td>Agravo</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sentence: 671</td>\n","      <td>regimental</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sentence: 671</td>\n","      <td>em</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sentence: 671</td>\n","      <td>habeas</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Sentence: 671</td>\n","      <td>corpus</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Sentence: 671</td>\n","      <td>.</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Sentence: 671</td>\n","      <td>Homicídio</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Sentence: 671</td>\n","      <td>qualificado</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Sentence: 671</td>\n","      <td>(</td>\n","      <td>O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8bdbe96d-972e-425c-bc1e-257fa6d219be')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8bdbe96d-972e-425c-bc1e-257fa6d219be button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8bdbe96d-972e-425c-bc1e-257fa6d219be');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["      Sentence #         Word Tag\n","0  Sentence: 671            “   O\n","1  Sentence: 671       Agravo   O\n","2  Sentence: 671   regimental   O\n","3  Sentence: 671           em   O\n","4  Sentence: 671       habeas   O\n","5  Sentence: 671       corpus   O\n","6  Sentence: 671            .   O\n","7  Sentence: 671    Homicídio   O\n","8  Sentence: 671  qualificado   O\n","9  Sentence: 671            (   O"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Explore the input dataset\n","print(\"Number of training sentences: \", len(training_data.groupby(['Sentence #'])))\n","print(\"Number of dev sentences: \", len(dev_data.groupby(['Sentence #'])))\n","print(\"Number of test sentences: \", len(test_data.groupby(['Sentence #'])))\n","\n","training_words = list(set(training_data[\"Word\"].values))\n","n_training_words = len(training_words)\n","print(\"Number of words in the training dataset: \", n_training_words)\n","dev_words = list(set(dev_data[\"Word\"].values))\n","n_dev_words = len(dev_words)\n","print(\"Number of words in the dev dataset: \", n_dev_words)\n","test_words = list(set(test_data[\"Word\"].values))\n","n_test_words = len(test_words)\n","print(\"Number of words in the test dataset: \", n_test_words)\n","\n","training_tags = list(set(training_data[\"Tag\"].values))\n","print(\"Tags in the training dataset:\", training_tags)\n","n_training_tags = len(training_tags)\n","print(\"Number of Labels in the training dataset: \", n_training_tags)\n","dev_tags = list(set(dev_data[\"Tag\"].values))\n","print(\"Tags in the dev dataset:\", dev_tags)\n","n_dev_tags = len(dev_tags)\n","print(\"Number of Labels in the dev dataset: \", n_dev_tags)\n","test_tags = list(set(test_data[\"Tag\"].values))\n","print(\"Tags in the test dataset:\", test_tags)\n","n_test_tags = len(test_tags)\n","print(\"Number of Labels in the test dataset: \", n_test_tags)\n","\n","print(\"What the training dataset looks like:\")\n","# Show the first 10 rows\n","training_data.head(n=10)"],"id":"adverse-doctor"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1661666617751,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"painful-karaoke","outputId":"8ff7c1f1-29dc-46e7-bafd-d41ecefb510b"},"outputs":[{"data":{"text/plain":["[('em', 'O'),\n"," ('seus', 'O'),\n"," ('votos', 'O'),\n"," ('os', 'O'),\n"," ('argumentos', 'O'),\n"," ('de', 'O'),\n"," ('ambas', 'O'),\n"," ('as', 'O'),\n"," ('partes', 'O'),\n"," (',', 'O'),\n"," ('não', 'O'),\n"," ('havendo', 'O'),\n"," ('reconhecer', 'O'),\n"," (',', 'O'),\n"," ('agora', 'O'),\n"," (',', 'O'),\n"," ('quaisquer', 'O'),\n"," ('dos', 'O'),\n"," ('vícios', 'O'),\n"," ('do', 'O'),\n"," ('art.', 'B-LEGISLACAO'),\n"," ('1.022', 'I-LEGISLACAO'),\n"," (',', 'O'),\n"," ('do', 'O'),\n"," ('Código', 'B-LEGISLACAO'),\n"," ('de', 'I-LEGISLACAO'),\n"," ('Processo', 'I-LEGISLACAO'),\n"," ('Civil', 'I-LEGISLACAO'),\n"," ('.', 'O')]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# SentenceGetter re-organize \"data\" as an arry of sentences\n","# Each sentence is a list of pairs <word,tag> \n","class SentenceGetter(object):\n","    \n","    def __init__(self, dataset):\n","        self.n_sent = 1\n","        self.dataset = dataset\n","        self.empty = False\n","        agg_func = lambda s: [(w, t) for w,t in zip(s[\"Word\"].values.tolist(),\n","                                                        s[\"Tag\"].values.tolist())]\n","        self.grouped = self.dataset.groupby(\"Sentence #\").apply(agg_func)\n","        self.sentences = [s for s in self.grouped]\n","    \n","    def get_next(self):\n","        try:\n","            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n","            self.n_sent += 1\n","            return s\n","        except:\n","            return None\n","\n","training_getter = SentenceGetter(training_data)\n","training_sentences = training_getter.sentences\n","dev_getter = SentenceGetter(dev_data)\n","dev_sentences = dev_getter.sentences\n","test_getter = SentenceGetter(test_data)\n","test_sentences = test_getter.sentences\n","\n","# Example: training sentence #200 \n","training_sentences[200]"],"id":"painful-karaoke"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1661666618529,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"round-providence","outputId":"558cbba9-f105-4e35-8532-a9af1949aa34"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Explore set of sentences\n","# Plot sentences by length\n","plt.hist([len(s) for s in training_sentences], bins=50)\n","plt.title('Token per training sentence')\n","plt.xlabel('Len (number of token)')\n","plt.ylabel('# samples')\n","plt.show()"],"id":"round-providence"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1661666618530,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"urxTzspTyPq5","outputId":"240ed9db-3444-42cc-ae1d-319ca6528723"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Explore set of sentences\n","# Plot sentences by length\n","plt.hist([len(s) for s in dev_sentences], bins=50)\n","plt.title('Token per dev sentence')\n","plt.xlabel('Len (number of token)')\n","plt.ylabel('# samples')\n","plt.show()"],"id":"urxTzspTyPq5"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"elapsed":566,"status":"ok","timestamp":1661666619081,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"JJ91V_51yPw9","outputId":"7ce7372e-4572-41eb-fa56-4f9a15703f4b"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Explore set of sentences\n","# Plot sentences by length\n","plt.hist([len(s) for s in test_sentences], bins=50)\n","plt.title('Token per test sentence')\n","plt.xlabel('Len (number of token)')\n","plt.ylabel('# samples')\n","plt.show()"],"id":"JJ91V_51yPw9"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1661666619081,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"juvenile-scene","outputId":"1aa0ae3a-0721-493f-8f16-f4f81e14e6a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["4197\n","Consta\n","1\n","I-LEGISLACAO\n"]}],"source":["# Keras (and most other ML packages) expect all the ids to be numeric, \n","# this is an optimisation to save memory. \n","# We will create the following dictionaries:\n","# word2idx: assign a numeric index to each word in the dataset\n","# idx2word: inverted version of word2idx\n","# tag2idx: assign a numeric index to each tag in the dataset\n","# idx2tag: inverted version of tag2idx\n","\n","# Group training, dev and test data in order to create word-index dicts and to\n","# convert data to numeric indeces later\n","data = pd.concat([training_data, dev_data, test_data])\n","\n","# words <= list of all words in the input dataset\n","words = list(set(data[\"Word\"].values))\n","n_words = len(words)\n","\n","# tags <= list of all tags in the input dataset\n","tags = []\n","for tag in set(data[\"Tag\"].values):\n","    if tag is nan or isinstance(tag, float):\n","        tags.append('unk')\n","    else:\n","        tags.append(tag)\n","n_tags = len(tags)\n","\n","# Dictionaries\n","word2idx = {w: i for i, w in enumerate(words)}\n","idx2word = {i: w for w, i in iteritems(word2idx)}\n","tag2idx = {t: i for i, t in enumerate(tags)}\n","idx2tag = {v: k for k, v in iteritems(tag2idx)}\n","\n","# Index number for the word 'civil'\n","print(word2idx['civil'])\n","# Word of index 10\n","print(idx2word[10])\n","# Index number for the tag 'B-LEGISLACAO'\n","print(tag2idx['B-LEGISLACAO'])\n","# Tag of index 0\n","print(idx2tag[0])"],"id":"juvenile-scene"},{"cell_type":"code","execution_count":null,"metadata":{"id":"delayed-dryer"},"outputs":[],"source":["# Convert train, dev and test data to numeric values\n","X_train = [[word2idx[w[0]] for w in s] for s in training_sentences]\n","y_train = [[tag2idx[w[1]] for w in s] for s in training_sentences]\n","\n","X_dev = [[word2idx[w[0]] for w in s] for s in dev_sentences]\n","y_dev = [[tag2idx[w[1]] for w in s] for s in dev_sentences]\n","\n","X_test = [[word2idx[w[0]] for w in s] for s in test_sentences]\n","y_test = [[tag2idx[w[1]] for w in s] for s in test_sentences]"],"id":"delayed-dryer"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1661666619082,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"Ttsyh05Rhovo","outputId":"305dd70e-35f0-4a77-e516-ae61708b404c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Points in X_train before removal: 1817\n","Points in y_train before removal: 1817\n","Points in X_train before removal: 1817\n","Points in y_train before removal: 1817\n"]}],"source":["# Use this function to randomly remove some points from training dataset\n","# Use removal percentage in decimal value. E.g.: if you set as 0.5, it will\n","# remove 50% of the dataset\n","\n","def random_remove_data_points(dataset, labels, removal_percentage):\n","    if removal_percentage < 0 or removal_percentage > 1:\n","        raise Exception(\"Invalid removal percentage\")\n","    \n","    if removal_percentage == 1:\n","        raise Exception(\"You can't remove the entire dataset\")\n","    \n","    number_of_points_remaining = round(len(dataset)*(1-removal_percentage))\n","\n","    try_again = True\n","\n","    while try_again:\n","      random_idxs = np.random.choice(len(dataset), number_of_points_remaining, replace=False)\n","      cut_dataset_sentences = [dataset[i] for i in random_idxs]\n","      cut_dataset_labels = [labels[i] for i in random_idxs]\n","      cut_tags = list(set([idx2tag[j] for sub in cut_dataset_labels for j in sub]))\n","\n","      if all(i in cut_tags for i in tags if i[:2] == \"B-\"):\n","        try_again = False\n","\n","    return cut_dataset_sentences, cut_dataset_labels \n","\n","print(f\"Points in X_train before removal: {len(X_train)}\")\n","print(f\"Points in y_train before removal: {len(y_train)}\")\n","# X_train, y_train = random_remove_data_points(X_train, y_train, 0.95)\n","print(f\"Points in X_train before removal: {len(X_train)}\")\n","print(f\"Points in y_train before removal: {len(y_train)}\")"],"id":"Ttsyh05Rhovo"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0SN-NYLpgsFa"},"outputs":[],"source":["# Aux functions to save data and dicts, if data consistency is important\n","# and there is desire to not random split again\n","\n","def save_backup_dataset(dataset, filename):\n","  dataset_df = pd.DataFrame(dataset)\n","  dataset_df.to_csv(filename, index=False)\n","  gfile = drive.CreateFile({'parents': [{'id': BACKUP_FOLDER_ID}]})\n","  gfile.SetContentFile(filename)\n","  gfile.Upload()\n","\n","def save_backup_dict(dict, filename):\n","  dict_file = open(filename, \"wb\")\n","  pickle.dump(dict, dict_file)\n","  dict_file.close()\n","  gfile = drive.CreateFile({'parents': [{'id': BACKUP_FOLDER_ID}]})\n","  gfile.SetContentFile(filename)\n","  gfile.Upload()"],"id":"0SN-NYLpgsFa"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18773,"status":"ok","timestamp":1661666637848,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"MzRQfI30tuI2","outputId":"d67c5ac5-c1ba-4044-93c6-d2fba3dd6667"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1064, 12743, 11813, 8981, 11009, 1987, 157, 9382, 7251, 12743, 2724, 8981, 2891, 13404, 2177, 8734, 3701, 2654, 2294, 2786, 2423, 13441, 2129, 8981, 11899, 3329, 13441, 9883, 5326, 12463, 8981, 12743, 12413, 8981, 4987, 12323, 13402, 8637, 2654, 8981, 11295, 1016, 13441, 8946, 8637, 10774, 9197, 8637, 6167, 8981, 239, 9577, 3946, 2294, 2561, 8637, 4021, 8713, 477, 1226, 2294, 3161, 13441, 4714, 3628]\n","[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n","[4844, 12382, 8981, 10979, 2654, 7340, 5349, 11009, 570, 8637, 5452, 7956, 3989, 732, 10638, 8637, 9954, 8637, 12501, 3110, 8981, 7769, 7308, 8478, 11802, 2324, 12323, 6987, 3962, 8637, 11091, 12710, 7762, 13000, 3218, 6149, 10416, 9397, 8637, 176, 8290, 12323, 10484, 8981, 12323, 5375, 8981, 5820, 3701, 12323, 13343, 373, 11899, 7543, 8713, 3663, 10338, 11719, 12496, 2603, 8981, 10515, 8981, 8713, 1626, 789, 8734, 12496, 10101, 8713, 1626, 218, 3701, 12496, 6828, 13441, 2415, 8486, 3628]\n","[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 2, 1, 2, 2, 1, 0, 2, 1, 0, 2, 1, 0, 2, 1, 0, 2, 1, 2, 2]\n","[3400, 3628, 7812, 3628, 10784, 3628, 905, 5315, 5394, 11869, 3628]\n","[2, 2, 2, 2, 1, 0, 0, 2, 1, 0, 2]\n","4197\n","1\n","I-LEGISLACAO\n","modos\n","13578\n","3\n"]}],"source":["# Uncomment this cell if you want to save data for further use\n","\n","# Check some points before saving\n","print(X_train[0])\n","print(y_train[0])\n","print(X_dev[0])\n","print(y_dev[0])\n","print(X_test[0])\n","print(y_test[0])\n","print(word2idx['civil'])\n","print(tag2idx['B-LEGISLACAO'])\n","print(idx2tag[0])\n","print(idx2word[100])\n","print(n_words)\n","print(n_tags)\n","\n","X_train_filename = f'{notebook_filename}_X_train.csv'\n","y_train_filename = f'{notebook_filename}_y_train.csv'\n","X_dev_filename = f'{notebook_filename}_X_dev.csv'\n","y_dev_filename = f'{notebook_filename}_y_dev.csv'\n","X_test_filename = f'{notebook_filename}_X_test.csv'\n","y_test_filename = f'{notebook_filename}_y_test.csv'\n","\n","word2idx_filename = f'{notebook_filename}_word2idx.pkl'\n","idx2word_filename = f'{notebook_filename}_idx2word.pkl'\n","tag2idx_filename = f'{notebook_filename}_tag2idx.pkl'\n","idx2tag_filename = f'{notebook_filename}_idx2tag.pkl'\n","\n","others_filename = f'{notebook_filename}_others.pkl'\n","\n","save_backup_dataset(X_train, X_train_filename)\n","save_backup_dataset(y_train, y_train_filename)\n","save_backup_dataset(X_dev, X_dev_filename)\n","save_backup_dataset(y_dev, y_dev_filename)\n","save_backup_dataset(X_test, X_test_filename)\n","save_backup_dataset(y_test, y_test_filename)\n","\n","save_backup_dict(word2idx, word2idx_filename)\n","save_backup_dict(idx2word, idx2word_filename)\n","save_backup_dict(tag2idx, tag2idx_filename)\n","save_backup_dict(idx2tag, idx2tag_filename)\n","\n","save_backup_dict({\"n_words\":n_words, \"n_tags\":n_tags}, others_filename)"],"id":"MzRQfI30tuI2"},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":79180,"status":"ok","timestamp":1666075876413,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"zvip_oC0j5-y","outputId":"e5e8bb2d-1f59-4fee-c3a7-cce069444534"},"outputs":[{"output_type":"stream","name":"stdout","text":["Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 31.6 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n","\u001b[K     |████████████████████████████████| 5.3 MB 28.5 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (5.0.0)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n","\u001b[K     |████████████████████████████████| 163 kB 58.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 64.1 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.23.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 2.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=dcb382f90f6c65967ff60f59809066e1a17d0315e1633d6cb13941ac1d667c9b\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n","[1064, 12743, 11813, 8981, 11009, 1987, 157, 9382, 7251, 12743, 2724, 8981, 2891, 13404, 2177, 8734, 3701, 2654, 2294, 2786, 2423, 13441, 2129, 8981, 11899, 3329, 13441, 9883, 5326, 12463, 8981, 12743, 12413, 8981, 4987, 12323, 13402, 8637, 2654, 8981, 11295, 1016, 13441, 8946, 8637, 10774, 9197, 8637, 6167, 8981, 239, 9577, 3946, 2294, 2561, 8637, 4021, 8713, 477, 1226, 2294, 3161, 13441, 4714, 3628]\n","[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n","[4844, 12382, 8981, 10979, 2654, 7340, 5349, 11009, 570, 8637, 5452, 7956, 3989, 732, 10638, 8637, 9954, 8637, 12501, 3110, 8981, 7769, 7308, 8478, 11802, 2324, 12323, 6987, 3962, 8637, 11091, 12710, 7762, 13000, 3218, 6149, 10416, 9397, 8637, 176, 8290, 12323, 10484, 8981, 12323, 5375, 8981, 5820, 3701, 12323, 13343, 373, 11899, 7543, 8713, 3663, 10338, 11719, 12496, 2603, 8981, 10515, 8981, 8713, 1626, 789, 8734, 12496, 10101, 8713, 1626, 218, 3701, 12496, 6828, 13441, 2415, 8486, 3628]\n","[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 2, 1, 2, 2, 1, 0, 2, 1, 0, 2, 1, 0, 2, 1, 0, 2, 1, 2, 2]\n","[3400, 3628, 7812, 3628, 10784, 3628, 905, 5315, 5394, 11869, 3628]\n","[2, 2, 2, 2, 1, 0, 0, 2, 1, 0, 2]\n","4197\n","1\n","I-LEGISLACAO\n","modos\n","13578\n","3\n"]}],"source":["# Uncomment this cell if you want to load saved data\n","\n","# Re-import necessary libs\n","import pandas as pd\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","import pickle, math\n","from requests import get\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import random\n","import time\n","%tensorflow_version 2.x\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import torch\n","from torch import cuda\n","from torch.utils.data import Dataset, DataLoader\n","!pip install sentencepiece\n","!pip install transformers\n","from transformers import BertForTokenClassification, AutoTokenizer\n","import matplotlib.pyplot as plt\n","!pip install seqeval\n","from seqeval.metrics import f1_score, classification_report\n","\n","BACKUP_FOLDER_ID = '18ZJg_YZnxA86FdlCUMPqAvdGsXCVCDnb'\n","notebook_filename = get('http://172.28.0.2:9000/api/sessions').json()[0]['name'].replace(\"_CWR\",\"\")\n","\n","X_train_filename = f'{notebook_filename}_X_train.csv'\n","y_train_filename = f'{notebook_filename}_y_train.csv'\n","X_dev_filename = f'{notebook_filename}_X_dev.csv'\n","y_dev_filename = f'{notebook_filename}_y_dev.csv'\n","X_test_filename = f'{notebook_filename}_X_test.csv'\n","y_test_filename = f'{notebook_filename}_y_test.csv'\n","\n","word2idx_filename = f'{notebook_filename}_word2idx.pkl'\n","idx2word_filename = f'{notebook_filename}_idx2word.pkl'\n","tag2idx_filename = f'{notebook_filename}_tag2idx.pkl'\n","idx2tag_filename = f'{notebook_filename}_idx2tag.pkl'\n","\n","others_filename = f'{notebook_filename}_others.pkl'\n","\n","# Re-get important variables\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","def get_backup_files_ids(folder_id):\n","  file_list = drive.ListFile({'q': \"'{}' in parents and trashed=false\".format(folder_id)}).GetList()\n","  return file_list\n","\n","def load_backup_dataset(file_id):\n","  downloaded = drive.CreateFile({'id':file_id})\n","  downloaded.GetContentFile(f\"{file_id}.csv\")\n","\n","  dataset = pd.read_csv(f\"{file_id}.csv\", encoding=\"latin1\")\n","  dataset = dataset.values.tolist()\n","  dataset = [ [ int(word) for word in sentence if str(word) != 'nan' ] for sentence in dataset]\n","  return dataset\n","\n","def load_backup_dict(file_id):\n","  downloaded = drive.CreateFile({'id':file_id})\n","  downloaded.GetContentFile(f\"{file_id}.pkl\")\n","\n","  dict_file = open(f\"{file_id}.pkl\", \"rb\")\n","  out_dict = pickle.load(dict_file)\n","  return out_dict\n","\n","backup_file_list = get_backup_files_ids(BACKUP_FOLDER_ID)\n","\n","X_train_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == X_train_filename][0]['id']\n","y_train_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == y_train_filename][0]['id']\n","X_dev_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == X_dev_filename][0]['id']\n","y_dev_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == y_dev_filename][0]['id']\n","X_test_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == X_test_filename][0]['id']\n","y_test_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == y_test_filename][0]['id']\n","\n","word2idx_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == word2idx_filename][0]['id']\n","idx2word_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == idx2word_filename][0]['id']\n","tag2idx_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == tag2idx_filename][0]['id']\n","idx2tag_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == idx2tag_filename][0]['id']\n","\n","others_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == others_filename][0]['id']\n","\n","X_train = load_backup_dataset(X_train_file_id)\n","y_train = load_backup_dataset(y_train_file_id)\n","X_dev = load_backup_dataset(X_dev_file_id)\n","y_dev = load_backup_dataset(y_dev_file_id)\n","X_test = load_backup_dataset(X_test_file_id)\n","y_test = load_backup_dataset(y_test_file_id)\n","\n","word2idx = load_backup_dict(word2idx_file_id)\n","idx2word = load_backup_dict(idx2word_file_id)\n","tag2idx = load_backup_dict(tag2idx_file_id)\n","idx2tag = load_backup_dict(idx2tag_file_id)\n","\n","others = load_backup_dict(others_file_id)\n","\n","n_words = others[\"n_words\"]\n","n_tags = others[\"n_tags\"]\n","\n","# Check some points after loading data to see if they match the ones before saving\n","print(X_train[0])\n","print(y_train[0])\n","print(X_dev[0])\n","print(y_dev[0])\n","print(X_test[0])\n","print(y_test[0])\n","print(word2idx['civil'])\n","print(tag2idx['B-LEGISLACAO'])\n","print(idx2tag[0])\n","print(idx2word[100])\n","print(n_words)\n","print(n_tags)"],"id":"zvip_oC0j5-y"},{"cell_type":"code","execution_count":2,"metadata":{"id":"2wRVTj71hovp","colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["82139eeec95847e885df5d78b299fb33","d81db4b5feee4411b1bf66bab8d4f680","5b030a01d9414ded94244470147a091c","391d763bb122412e92aa6572c013016c","e35dfb31ee594b0fb8d6d2b02979fef0","cfcc5aaa7906478ea26702bbfd5aed59","f31dc921312946499ad1c68502b7dc4b","2bdcae15631c41eb99c75e8a84052b0a","47c18c1b52094d0892fdb1df7496743a","e9aa45bce93b4218b46924cae67b1f5f","81f8c1538d1c4e63a57407eb4ec9ea9f","3e7cd746f017407d82ad6cc0fb9e3142","59e518d44ff54ad2acdd02407ed40978","ca96b776f9694c11b47be0a6a87d4a5b","e29a008722344c5e9c718f7fbde9f69e","f407cdd445db49adb748dbb450c3a029","a7cc3f99db144b46927b85fd0fb119a5","81a5a802f4d7439a894012ff2e184abc","d587040812004b7bbaf45a755ddad82b","f51c07e9dd6540459e9d2020b66dbcdd","eb46b745ac1c403d91d4bab7f98fa752","5f5b26b49b82492287c75af86cdc0f20","b7cdb5883c0347068e779fb8a4b8c50a","c2b88fdcc36044689489160fda863ceb","d8381a1898c94808ab2cdf66e6c56d06","5e3b6cf92fef40e6ad4795f0136fcee2","98bfb49e144b41ad994034ad992c68cf","cb11736c06484b44a994ac6e9911ba18","8b84fba173ea45ad914cd3222f0b9278","b3e5cd4877e24bb9ae492b57dd70c586","27e14dd3172444ca830654c2db338705","52852f905a3c4690a5fbb14642651f51","8d409eb99d0f4a318a7850e7c61ed383","55f5d4ea71434b819e8409a1733677d0","defcd8b191cc422b825bd2c75751df45","dc465c76c4da4c14b61ecadfa35c16a0","5b25b246f029456eb9dfcb3de02e9a98","93aa6be594c64014a36232baa8a76552","3ea492fe8f70452d882ecde4e9283a8e","6538a23fcc484540bf7520bbcffc3bd0","a6b1e20798dc445fa211c37e82e75ad5","ef87c76e862d4426a1ef1114a22d814c","c62df58d74424898b5644f894584169a","3a90334aa40a4031af2399be845e00fc"]},"executionInfo":{"status":"ok","timestamp":1666075891022,"user_tz":240,"elapsed":14618,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}},"outputId":"b012e398-cd70-4040-ce29-52562d6fc015"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82139eeec95847e885df5d78b299fb33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e7cd746f017407d82ad6cc0fb9e3142"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/996k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7cdb5883c0347068e779fb8a4b8c50a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55f5d4ea71434b819e8409a1733677d0"}},"metadata":{}}],"source":["tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n","\n","from transformers import pipeline\n","from future.utils import iteritems\n","\n","# Augmentation function using entity replacement technique.\n","# It will generate a new dataset, with X% more points based on\n","# the original dataset. E.g.: if you set augmentation percentage as 0.5 and dataset has\n","# 1000 points, it will generate a dataset with 1500 points.\n","\n","def generate_sentences(dataset, labels, augmented_set_size_percentage):\n","    if augmented_set_size_percentage < 0:\n","        raise Exception(\"Invalid augmented set size percentage\")\n","\n","    unmasker = pipeline('fill-mask', model='bert-base-multilingual-cased')\n","    \n","    number_of_new_sentences = math.ceil(augmented_set_size_percentage * len(dataset))\n","\n","    found_subset = False\n","\n","    while not found_subset:\n","      random_idxs = np.random.choice(len(dataset), number_of_new_sentences, replace=True)\n","      base_labels = [labels[i] for i in random_idxs]\n","      found_subset = all([tag2idx[\"O\"] in labels for labels in base_labels])\n","\n","    base_sequences = [dataset[i] for i in random_idxs]\n","\n","    new_sequences = []\n","    new_labels = []\n","    \n","    for k, sequence in enumerate(base_sequences):\n","      sequence_str = [idx2word[word] for word in sequence]\n","\n","      # check max number of tokens bert support and truncate sentence before augmentation\n","      # augmented sentence will be shorter than original sentence if higher than bert limit\n","      encoding = tokenizer(sequence_str,\n","                             is_split_into_words=True, \n","                             return_offsets_mapping=True, \n","                             truncation=True, \n","                             max_length=512)\n","      \n","      max_n_of_tokens = len([mapping for mapping in encoding[\"offset_mapping\"] if mapping[0] == 0 and mapping[1] != 0])\n","\n","      truncated_sequence_str = sequence_str[:max_n_of_tokens]\n","      truncated_labels = base_labels[k][:max_n_of_tokens]\n","\n","      # print(len(sequence_str),len(truncated_sequence_str),len(base_labels[k]),len(truncated_labels))\n","\n","      replaceable_indices = [i for i,label in enumerate(truncated_labels) if label == tag2idx[\"O\"]]\n","      replace_percent = round(random.uniform(0.1, 1), 1)\n","      replace_qty = max(math.floor(replace_percent*len(replaceable_indices)), 1)\n","      replace_indices = random.sample(replaceable_indices, k=replace_qty)\n","      replace_indices.sort()\n","\n","      masked_text_list = [\"[MASK]\" if i in replace_indices else word for i,word in enumerate(truncated_sequence_str)]\n","      new_mask_sent = ' '.join(masked_text_list)\n","      augmented_text_list = unmasker(new_mask_sent)\n","\n","      augmented_sentence = truncated_sequence_str.copy()\n","      if len(replace_indices) == 1:\n","        augmented_text_list = [augmented_text_list]\n","\n","      for i,index in enumerate(replace_indices):\n","        available_words = [word[\"token_str\"] for word in augmented_text_list[i] if word[\"token_str\"] != truncated_sequence_str[index]]\n","        new_word = random.choice(available_words)\n","        if new_word != \"[UNK]\":\n","          augmented_sentence[index] = new_word\n","\n","      # print(\"Original text->\",len(sequence_str),sequence_str)\n","      # print(\"Augmented text->\",len(sequence_str),augmented_sentence)\n","\n","      new_sequences.append(augmented_sentence)\n","      new_labels.append(truncated_labels)\n","\n","    all_words = list(set([word for seq in new_sequences for word in seq]))\n","    updated_word2idx = word2idx.copy()\n","    updated_idx2word = idx2word.copy()\n","    for word in all_words:\n","      try:\n","        updated_word2idx[word]\n","      except:\n","        updated_word2idx[word] = len(updated_word2idx)\n","    updated_idx2word = {i: w for w, i in iteritems(updated_word2idx)}\n","\n","    new_sequences = [[updated_word2idx[word] for word in seq] for seq in new_sequences]\n","\n","    augmented_X_train = dataset + new_sequences\n","    augmented_y_train = labels + new_labels\n","\n","    print(f\"Points in X_train after augmentation: {len(augmented_X_train)}\")\n","    print(f\"Points in y_train after augmentation: {len(augmented_y_train)}\")\n","\n","    return augmented_X_train, augmented_y_train, updated_word2idx, updated_idx2word"],"id":"2wRVTj71hovp"},{"cell_type":"code","execution_count":3,"metadata":{"id":"mYHzTnzZZfBg","executionInfo":{"status":"ok","timestamp":1666075892719,"user_tz":240,"elapsed":1704,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}}},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n","\n","class dataset(Dataset):\n","  def __init__(self, dataframe, tokenizer, max_len):\n","        self.len = len(dataframe)\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","  def __getitem__(self, index):\n","        # step 1: get the sentence and word labels\n","        sentence = self.data.sentence[index]\n","        word_labels = self.data.word_labels[index].split(\",\") \n","\n","        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n","        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n","        encoding = self.tokenizer(sentence,\n","                             is_split_into_words=True, \n","                             return_offsets_mapping=True, \n","                             padding='max_length', \n","                             truncation=True, \n","                             max_length=self.max_len)\n","        \n","        # step 3: create token labels only for first word pieces of each tokenized word\n","        labels = [tag2idx[label] for label in word_labels] \n","        # code based on https://huggingface.co/transformers/custom_datasets.html#tok-ner\n","        # create an empty array of -100 of length max_length\n","        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n","        \n","        # set only labels whose first offset position is 0 and the second is not 0\n","        i = 0\n","        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n","          if mapping[0] == 0 and mapping[1] != 0:\n","            # overwrite label\n","            encoded_labels[idx] = labels[i]\n","            i += 1\n","\n","        # step 4: turn everything into PyTorch tensors\n","        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n","        item['labels'] = torch.as_tensor(encoded_labels)\n","        \n","        return item\n","\n","  def __len__(self):\n","        return self.len"],"id":"mYHzTnzZZfBg"},{"cell_type":"code","execution_count":4,"metadata":{"id":"d8H1s-6b_-pM","executionInfo":{"status":"ok","timestamp":1666075892720,"user_tz":240,"elapsed":11,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}}},"outputs":[],"source":["# some configuration variables\n","LEARNING_RATE = 5e-05\n","MAX_GRAD_NORM = 10\n","TRAINING_STOP_LOSS_PERCENTAGE = 1\n","\n","# Model creation function\n","def create_model(maxlen, n_labels, training_set, testing_set, validation_set):\n","  device = 'cuda' if cuda.is_available() else 'cpu'\n","  print(\"Device: \", device)\n","\n","  model = BertForTokenClassification.from_pretrained('bert-base-multilingual-cased', num_labels=n_labels)\n","  model.to(device)\n","\n","  optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n","\n","  TRAIN_BATCH_SIZE = round(0.05*len(training_set))\n","  if TRAIN_BATCH_SIZE > 16:\n","    TRAIN_BATCH_SIZE = 16\n","  if TRAIN_BATCH_SIZE < 10:\n","    TRAIN_BATCH_SIZE = 10\n","\n","  VALID_BATCH_SIZE = round(0.1*len(validation_set))\n","  if VALID_BATCH_SIZE > 16:\n","    VALID_BATCH_SIZE = 16\n","  if VALID_BATCH_SIZE < 10:\n","    VALID_BATCH_SIZE = 10\n","\n","  train_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                  'shuffle': True,\n","                  'num_workers': 0\n","                  }\n","\n","  test_params = {'batch_size': VALID_BATCH_SIZE,\n","                  'shuffle': True,\n","                  'num_workers': 0\n","                  }\n","\n","  training_loader = DataLoader(training_set, **train_params)\n","  testing_loader = DataLoader(testing_set, **test_params)\n","  validation_loader = DataLoader(validation_set, **test_params)\n","\n","  return model, device, optimizer, training_loader, testing_loader, validation_loader"],"id":"d8H1s-6b_-pM"},{"cell_type":"code","execution_count":5,"metadata":{"id":"cjp-jXx4AmiV","executionInfo":{"status":"ok","timestamp":1666075892720,"user_tz":240,"elapsed":10,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}}},"outputs":[],"source":["# Model training function\n","def train(model, device, optimizer, training_loader, epoch, training_stop_loss_percentage):\n","    tr_loss, tr_accuracy = 0, 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","    tr_preds, tr_labels = [], []\n","    losses = []\n","    # put model in training mode\n","    model.train()\n","    \n","    for idx, batch in enumerate(training_loader):\n","        \n","        ids = batch['input_ids'].to(device, dtype = torch.long)\n","        mask = batch['attention_mask'].to(device, dtype = torch.long)\n","        labels = batch['labels'].to(device, dtype = torch.long)\n","\n","        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels, return_dict = False)\n","        tr_loss += loss.item()\n","\n","        nb_tr_steps += 1\n","        nb_tr_examples += labels.size(0)\n","        \n","        if idx % 100==0:\n","            loss_step = tr_loss/nb_tr_steps\n","            print(f\"Training loss per 100 training steps: {loss_step}\")\n","            losses.append(loss_step)\n","            last_5_losses = losses[-5:]\n","            loss_min = min(last_5_losses)\n","            loss_max = max(last_5_losses)\n","            if len(last_5_losses) > 1 and (loss_max - loss_min)/loss_max < training_stop_loss_percentage/100:\n","              print(\"Stopping epoch...\")\n","              break\n","           \n","        # compute training accuracy\n","        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","        \n","        # only compute accuracy at active labels\n","        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n","        \n","        labels = torch.masked_select(flattened_targets, active_accuracy)\n","        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","        \n","        tr_labels.extend(labels)\n","        tr_preds.extend(predictions)\n","\n","        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n","        tr_accuracy += tmp_tr_accuracy\n","    \n","        # gradient clipping\n","        torch.nn.utils.clip_grad_norm_(\n","            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n","        )\n","        \n","        # backward pass\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    epoch_loss = tr_loss / nb_tr_steps\n","    tr_accuracy = tr_accuracy / nb_tr_steps\n","    print(f\"Training loss epoch: {epoch_loss}\")\n","    print(f\"Training accuracy epoch: {tr_accuracy}\")"],"id":"cjp-jXx4AmiV"},{"cell_type":"code","execution_count":6,"metadata":{"id":"JvdztU6FA8Bd","executionInfo":{"status":"ok","timestamp":1666075892720,"user_tz":240,"elapsed":9,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}}},"outputs":[],"source":["# Model testing function\n","def test(model, device, testing_loader):\n","    print(\"Validating model...\")\n","    # put model in evaluation mode\n","    model.eval()\n","    \n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_examples, nb_eval_steps = 0, 0\n","    eval_preds, eval_labels = [], []\n","    \n","    with torch.no_grad():\n","        for idx, batch in enumerate(testing_loader):\n","            \n","            ids = batch['input_ids'].to(device, dtype = torch.long)\n","            mask = batch['attention_mask'].to(device, dtype = torch.long)\n","            labels = batch['labels'].to(device, dtype = torch.long)\n","            \n","            loss, eval_logits = model(input_ids=ids, attention_mask=mask, labels=labels, return_dict = False)\n","            \n","            eval_loss += loss.item()\n","\n","            nb_eval_steps += 1\n","            nb_eval_examples += labels.size(0)\n","        \n","            # compute evaluation accuracy\n","            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","            \n","            # only compute accuracy at active labels\n","            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","        \n","            labels = torch.masked_select(flattened_targets, active_accuracy)\n","            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","            \n","            eval_labels.extend(labels)\n","            eval_preds.extend(predictions)\n","            \n","            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n","            eval_accuracy += tmp_eval_accuracy\n","\n","    labels = [idx2tag[id.item()] for id in eval_labels]\n","    predictions = [idx2tag[id.item()] for id in eval_preds]\n","    \n","    eval_loss = eval_loss / nb_eval_steps\n","    eval_accuracy = eval_accuracy / nb_eval_steps\n","    print(f\"Validation Loss: {eval_loss}\")\n","    print(f\"Validation Accuracy: {eval_accuracy}\")\n","\n","    return labels, predictions, eval_loss"],"id":"JvdztU6FA8Bd"},{"cell_type":"code","execution_count":7,"metadata":{"id":"jMknjbDrh6Fk","executionInfo":{"status":"ok","timestamp":1666075892721,"user_tz":240,"elapsed":10,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}}},"outputs":[],"source":["def create_train_and_validate_model(augmented_percentage):\n","\n","  augmented_X_train, augmented_y_train, updated_word2idx, updated_idx2word = generate_sentences(X_train, y_train, augmented_percentage)\n","\n","  maxlen_X_train = max([len(s) for s in augmented_X_train])\n","  maxlen_X_test = max([len(s) for s in X_test])\n","  maxlen_X_dev = max([len(s) for s in X_dev])\n","  maxlen_y_train = max([len(s) for s in augmented_y_train])\n","  maxlen_y_test = max([len(s) for s in y_test])\n","  maxlen_y_dev = max([len(s) for s in y_dev])\n","\n","  maxlen = max([maxlen_X_train, maxlen_X_test, maxlen_X_dev, maxlen_y_train, maxlen_y_test, maxlen_y_dev])\n","\n","  if maxlen > 512:\n","    maxlen = 512\n","\n","  augmented_X_train_words = [[updated_idx2word[word] for word in sentence] for sentence in augmented_X_train]\n","  X_dev_words = [[updated_idx2word[word] for word in sentence] for sentence in X_dev]\n","  X_test_words = [[updated_idx2word[word] for word in sentence] for sentence in X_test]\n","  augmented_y_train_tags = [','.join([idx2tag[tag] for tag in sentence]) for sentence in augmented_y_train]\n","  y_dev_tags = [','.join([idx2tag[tag] for tag in sentence]) for sentence in y_dev]\n","  y_test_tags = [','.join([idx2tag[tag] for tag in sentence]) for sentence in y_test]\n","\n","  new_train_df = pd.DataFrame({\"sentence\": augmented_X_train_words, \"word_labels\": augmented_y_train_tags}).reset_index(drop=True)\n","  new_test_df = pd.DataFrame({\"sentence\": X_test_words, \"word_labels\": y_test_tags}).reset_index(drop=True)\n","  new_val_df = pd.DataFrame({\"sentence\": X_dev_words, \"word_labels\": y_dev_tags}).reset_index(drop=True)\n","\n","  training_set = dataset(new_train_df, tokenizer, maxlen)\n","  testing_set = dataset(new_test_df, tokenizer, maxlen)\n","  validation_set = dataset(new_val_df, tokenizer, maxlen)\n","\n","  model, device, optimizer, training_loader, testing_loader, val_loader = create_model(maxlen, len(tag2idx), training_set, testing_set, validation_set)\n","\n","  training_start_time = time.clock()\n","  min_val_loss = 0\n","  MAX_PATIENCE = 5\n","  patience = 0\n","\n","  for epoch in range(100):\n","    print(f\"Training epoch: {epoch + 1}\")\n","    if patience == MAX_PATIENCE:\n","      print(\"Patience limit reached\")\n","      break\n","    train(model, device, optimizer, training_loader, epoch, TRAINING_STOP_LOSS_PERCENTAGE)\n","    labels, predictions, val_loss = test(model, device, val_loader)\n","    if ((min_val_loss == 0) or (min_val_loss != 0 and val_loss < min_val_loss)):\n","      min_val_loss = val_loss\n","      torch.save(model.state_dict(), 'checkpoint.pt')\n","      patience = 0\n","    else:\n","      patience = patience + 1\n","  print(f\"Training duration: {(time.clock() - training_start_time)/60} minutes\")\n","\n","  checkpoint = torch.load('checkpoint.pt')\n","  model.load_state_dict(checkpoint)\n","\n","  validation_start_time = time.clock()\n","  labels, predictions, test_loss = test(model, device, testing_loader)\n","  labels = [labels]\n","  predictions = [predictions]\n","  print(f\"Validation duration: {(time.clock() - validation_start_time)/60} minutes\")\n","\n","  print(\"F1-score (test): {:.1%}\".format(f1_score(labels, predictions)))\n","  print(classification_report(labels, predictions))"],"id":"jMknjbDrh6Fk"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["1fd215feb3bb4396823a979901744613","b9404b0372904c94add8ab62649b9559","4883b0fa3aea457cb708e9c66fd03010","0a56886a395f4c2498f95d973025e3fc","8cdf951025a946de942a538c2d0680cb","0144b652a2574e4681860c828131da40","ebc5fd08b6fd4efc9b17deeda2755ffc","15fa284c24c54ba1b23d78e0ea14f862","eecec21d287f4c4cb43550a7e8af3116","c82daa0a1dd04c70941f524f214279d7","aa8be15a00ca4b7ea9e48d3815310f3e"]},"id":"Jhz9BiIwGCsV","outputId":"ff6742cc-04b7-4d5d-befc-6935c21aea34","executionInfo":{"status":"ok","timestamp":1665728496340,"user_tz":240,"elapsed":24996192,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["!!!!!! Augmented Percentage 25.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/714M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fd215feb3bb4396823a979901744613"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 2272\n","Points in y_train after augmentation: 2272\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.0860687494277954\n","Training loss per 100 training steps: 0.08232921017518285\n","Training loss epoch: 0.06542055560341499\n","Training accuracy epoch: 0.9787939822176966\n","Validating model...\n","Validation Loss: 0.031400268453927266\n","Validation Accuracy: 0.9904711606297779\n","Training epoch: 2\n","Training loss per 100 training steps: 0.007571236230432987\n","Training loss per 100 training steps: 0.015688498618569927\n","Training loss epoch: 0.015368090184982603\n","Training accuracy epoch: 0.9954272336567129\n","Validating model...\n","Validation Loss: 0.01093589163515606\n","Validation Accuracy: 0.9966836190730497\n","Training epoch: 3\n","Training loss per 100 training steps: 0.006698808632791042\n","Training loss per 100 training steps: 0.010282717790975613\n","Training loss epoch: 0.010230487440860319\n","Training accuracy epoch: 0.9971559026059924\n","Validating model...\n","Validation Loss: 0.013041534976288122\n","Validation Accuracy: 0.9959156448082012\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0031226188875734806\n","Training loss per 100 training steps: 0.006304840931160569\n","Training loss epoch: 0.006131407943440267\n","Training accuracy epoch: 0.9980115808083765\n","Validating model...\n","Validation Loss: 0.013610738675543828\n","Validation Accuracy: 0.996745644825644\n","Training epoch: 5\n","Training loss per 100 training steps: 0.004847928881645203\n","Training loss per 100 training steps: 0.004587918824843583\n","Training loss epoch: 0.004715201678266913\n","Training accuracy epoch: 0.9984963669106993\n","Validating model...\n","Validation Loss: 0.01182178885833959\n","Validation Accuracy: 0.9972563911994328\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00522422743961215\n","Training loss per 100 training steps: 0.003194630672777127\n","Training loss epoch: 0.0035506255366605\n","Training accuracy epoch: 0.9988634109490238\n","Validating model...\n","Validation Loss: 0.010951512974099301\n","Validation Accuracy: 0.9967143952081992\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0015912700910121202\n","Training loss per 100 training steps: 0.0024861549819695144\n","Training loss epoch: 0.0028403762780854634\n","Training accuracy epoch: 0.999082983057288\n","Validating model...\n","Validation Loss: 0.010862335405753194\n","Validation Accuracy: 0.9971974881164882\n","Training epoch: 8\n","Training loss per 100 training steps: 0.0003961119509767741\n","Training loss per 100 training steps: 0.003875807132272253\n","Training loss epoch: 0.003601426334414651\n","Training accuracy epoch: 0.9988309368031075\n","Validating model...\n","Validation Loss: 0.017221199326567807\n","Validation Accuracy: 0.9967908304183885\n","Training epoch: 9\n","Training loss per 100 training steps: 0.0032921964302659035\n","Training loss per 100 training steps: 0.0027017939753229913\n","Training loss epoch: 0.002878090195941106\n","Training accuracy epoch: 0.9991001235139487\n","Validating model...\n","Validation Loss: 0.012817711574219478\n","Validation Accuracy: 0.9968696222791584\n","Training epoch: 10\n","Training loss per 100 training steps: 0.0006252173334360123\n","Training loss per 100 training steps: 0.0035046179447349593\n","Training loss epoch: 0.0030221557145766933\n","Training accuracy epoch: 0.9991368428367086\n","Validating model...\n","Validation Loss: 0.017133140953644346\n","Validation Accuracy: 0.9971064862835991\n","Training epoch: 11\n","Training loss per 100 training steps: 0.00138069165404886\n","Training loss per 100 training steps: 0.001373872983310888\n","Stopping epoch...\n","Training loss epoch: 0.001373872983310888\n","Training accuracy epoch: 0.9897415310043238\n","Validating model...\n","Validation Loss: 0.012266728191337149\n","Validation Accuracy: 0.9977311304577023\n","Training epoch: 12\n","Training loss per 100 training steps: 0.00018954987172037363\n","Training loss per 100 training steps: 0.0013544283008939438\n","Training loss epoch: 0.0015573365327955016\n","Training accuracy epoch: 0.9994947527994495\n","Validating model...\n","Validation Loss: 0.014386804006356951\n","Validation Accuracy: 0.9969492764923495\n","Training epoch: 13\n","Patience limit reached\n","Training duration: 42.80361621666667 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.013377219242405166\n","Validation Accuracy: 0.9967429818000327\n","Validation duration: 0.21987561666666502 minutes\n","F1-score (test): 97.7%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.98      0.98      1238\n","\n","   micro avg       0.97      0.98      0.98      1238\n","   macro avg       0.97      0.98      0.98      1238\n","weighted avg       0.97      0.98      0.98      1238\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 2272\n","Points in y_train after augmentation: 2272\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.0292695760726929\n","Training loss per 100 training steps: 0.0767454173793961\n","Training loss epoch: 0.060458672865831724\n","Training accuracy epoch: 0.9800361461457571\n","Validating model...\n","Validation Loss: 0.01625418139987492\n","Validation Accuracy: 0.9949182989373891\n","Training epoch: 2\n","Training loss per 100 training steps: 0.01807083562016487\n","Training loss per 100 training steps: 0.01694233206418887\n","Training loss epoch: 0.016149072083939706\n","Training accuracy epoch: 0.9949807814813835\n","Validating model...\n","Validation Loss: 0.015037555502550233\n","Validation Accuracy: 0.995335455314505\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0016845890786498785\n","Training loss per 100 training steps: 0.00867896949086283\n","Training loss epoch: 0.008253968711229185\n","Training accuracy epoch: 0.9975357443206238\n","Validating model...\n","Validation Loss: 0.014028300992712113\n","Validation Accuracy: 0.9961734515656702\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01791164092719555\n","Training loss per 100 training steps: 0.005978396120319826\n","Training loss epoch: 0.006237464182613365\n","Training accuracy epoch: 0.9981106069148391\n","Validating model...\n","Validation Loss: 0.008038520067895575\n","Validation Accuracy: 0.9973940450150542\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0042746542021632195\n","Training loss per 100 training steps: 0.0038250712953026103\n","Training loss epoch: 0.004003617409260084\n","Training accuracy epoch: 0.998826284433926\n","Validating model...\n","Validation Loss: 0.007616445677870486\n","Validation Accuracy: 0.9979669647122327\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0012887322809547186\n","Training loss per 100 training steps: 0.003081475701289699\n","Training loss epoch: 0.003975152632053105\n","Training accuracy epoch: 0.9987273012782303\n","Validating model...\n","Validation Loss: 0.013976850783538317\n","Validation Accuracy: 0.996317291634037\n","Training epoch: 7\n","Training loss per 100 training steps: 0.004431030713021755\n","Training loss per 100 training steps: 0.005471965948426358\n","Training loss epoch: 0.005093404440320766\n","Training accuracy epoch: 0.998372744114553\n","Validating model...\n","Validation Loss: 0.010503984250092236\n","Validation Accuracy: 0.9980028683532399\n","Training epoch: 8\n","Training loss per 100 training steps: 0.0016669919714331627\n","Training loss per 100 training steps: 0.0030892194686878223\n","Training loss epoch: 0.0033933544658230202\n","Training accuracy epoch: 0.9989440415249684\n","Validating model...\n","Validation Loss: 0.014190824879430389\n","Validation Accuracy: 0.996499203474101\n","Training epoch: 9\n","Training loss per 100 training steps: 0.018160579726099968\n","Training loss per 100 training steps: 0.004423687990644191\n","Training loss epoch: 0.004059847159764949\n","Training accuracy epoch: 0.9986802279670024\n","Validating model...\n","Validation Loss: 0.01607444933237968\n","Validation Accuracy: 0.9967852051286563\n","Training epoch: 10\n","Training loss per 100 training steps: 0.00022058829199522734\n","Training loss per 100 training steps: 0.0029806452772336883\n","Training loss epoch: 0.0035258365301993303\n","Training accuracy epoch: 0.9990275363169647\n","Validating model...\n","Validation Loss: 0.010779864772173044\n","Validation Accuracy: 0.9971426352774784\n","Training epoch: 11\n","Patience limit reached\n","Training duration: 36.63969663333334 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.012956496638556322\n","Validation Accuracy: 0.9967908849037261\n","Validation duration: 0.22054298333332553 minutes\n","F1-score (test): 97.6%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.98      0.98      1238\n","\n","   micro avg       0.97      0.98      0.98      1238\n","   macro avg       0.97      0.98      0.98      1238\n","weighted avg       0.97      0.98      0.98      1238\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 2272\n","Points in y_train after augmentation: 2272\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.1854203939437866\n","Training loss per 100 training steps: 0.08716074922260376\n","Training loss epoch: 0.06789082506651872\n","Training accuracy epoch: 0.9768091230463225\n","Validating model...\n","Validation Loss: 0.014698125760159678\n","Validation Accuracy: 0.9947055089421971\n","Training epoch: 2\n","Training loss per 100 training steps: 0.012730628252029419\n","Training loss per 100 training steps: 0.012217954319837217\n","Training loss epoch: 0.011728259527393368\n","Training accuracy epoch: 0.9967251061284869\n","Validating model...\n","Validation Loss: 0.015557506631705024\n","Validation Accuracy: 0.9958727092082447\n","Training epoch: 3\n","Training loss per 100 training steps: 0.003720623906701803\n","Training loss per 100 training steps: 0.008486600790119795\n","Training loss epoch: 0.00852344215549955\n","Training accuracy epoch: 0.9974435344320429\n","Validating model...\n","Validation Loss: 0.012507042497634843\n","Validation Accuracy: 0.9969482792036082\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0009087295038625598\n","Training loss per 100 training steps: 0.009730112673783915\n","Training loss epoch: 0.009564746432760599\n","Training accuracy epoch: 0.9971656616890371\n","Validating model...\n","Validation Loss: 0.012288183957848343\n","Validation Accuracy: 0.9971567420436065\n","Training epoch: 5\n","Training loss per 100 training steps: 0.007181563880294561\n","Training loss per 100 training steps: 0.004880970175087563\n","Training loss epoch: 0.0055526170310233125\n","Training accuracy epoch: 0.998518247969275\n","Validating model...\n","Validation Loss: 0.010570701525423266\n","Validation Accuracy: 0.9971930597924485\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0018436505924910307\n","Training loss per 100 training steps: 0.004377859471697766\n","Training loss epoch: 0.004444578592419546\n","Training accuracy epoch: 0.9987362758386034\n","Validating model...\n","Validation Loss: 0.017207949810350936\n","Validation Accuracy: 0.9959472175162005\n","Training epoch: 7\n","Training loss per 100 training steps: 0.00020386297546792775\n","Training loss per 100 training steps: 0.003827586846995527\n","Training loss epoch: 0.003704528963104346\n","Training accuracy epoch: 0.9989508273941705\n","Validating model...\n","Validation Loss: 0.013658424734395729\n","Validation Accuracy: 0.9973306561792431\n","Training epoch: 8\n","Training loss per 100 training steps: 0.00030498605337925255\n","Training loss per 100 training steps: 0.0018212349050462772\n","Training loss epoch: 0.0019200982276512586\n","Training accuracy epoch: 0.9994701237415665\n","Validating model...\n","Validation Loss: 0.017033932363639388\n","Validation Accuracy: 0.9970340900819797\n","Training epoch: 9\n","Training loss per 100 training steps: 0.0017128278268501163\n","Training loss per 100 training steps: 0.00144931707746755\n","Training loss epoch: 0.0015874866124723783\n","Training accuracy epoch: 0.9995383342626348\n","Validating model...\n","Validation Loss: 0.023221080855277944\n","Validation Accuracy: 0.9963293174140772\n","Training epoch: 10\n","Training loss per 100 training steps: 0.0038425156380981207\n","Training loss per 100 training steps: 0.0015078323933879136\n","Training loss epoch: 0.0015803778821374553\n","Training accuracy epoch: 0.9994726507467236\n","Validating model...\n","Validation Loss: 0.014299602913308177\n","Validation Accuracy: 0.9976099486738794\n","Training epoch: 11\n","Patience limit reached\n","Training duration: 36.65648828333333 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.013353489403016283\n","Validation Accuracy: 0.996524580158583\n","Validation duration: 0.2233278500000021 minutes\n","F1-score (test): 97.4%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.96      0.99      0.97      1238\n","\n","   micro avg       0.96      0.99      0.97      1238\n","   macro avg       0.96      0.99      0.97      1238\n","weighted avg       0.96      0.99      0.97      1238\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 2272\n","Points in y_train after augmentation: 2272\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.1224209070205688\n","Training loss per 100 training steps: 0.07824731024793617\n","Training loss epoch: 0.06245928624985923\n","Training accuracy epoch: 0.9791847114907235\n","Validating model...\n","Validation Loss: 0.014684658980556941\n","Validation Accuracy: 0.9959640756636458\n","Training epoch: 2\n","Training loss per 100 training steps: 0.025143468752503395\n","Training loss per 100 training steps: 0.010714503959522094\n","Training loss epoch: 0.010449016591350377\n","Training accuracy epoch: 0.9967068937262055\n","Validating model...\n","Validation Loss: 0.016600020924150676\n","Validation Accuracy: 0.9954486075405197\n","Training epoch: 3\n","Training loss per 100 training steps: 0.006568460259586573\n","Training loss per 100 training steps: 0.007759572541004619\n","Training loss epoch: 0.0072990159709482045\n","Training accuracy epoch: 0.9978110122861898\n","Validating model...\n","Validation Loss: 0.0118329319607472\n","Validation Accuracy: 0.9970217507578929\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0012755101779475808\n","Training loss per 100 training steps: 0.004987398353243929\n","Training loss epoch: 0.00578829628197332\n","Training accuracy epoch: 0.9984126962208884\n","Validating model...\n","Validation Loss: 0.016888044089899353\n","Validation Accuracy: 0.9954207389899195\n","Training epoch: 5\n","Training loss per 100 training steps: 0.000597169972024858\n","Training loss per 100 training steps: 0.0032774304016867863\n","Training loss epoch: 0.0033968230842142924\n","Training accuracy epoch: 0.9989564321770922\n","Validating model...\n","Validation Loss: 0.009867593237209977\n","Validation Accuracy: 0.9974803772419304\n","Training epoch: 6\n","Training loss per 100 training steps: 0.004512528423219919\n","Training loss per 100 training steps: 0.003882524277611479\n","Training loss epoch: 0.004051203526512222\n","Training accuracy epoch: 0.998792567180636\n","Validating model...\n","Validation Loss: 0.013697741431488317\n","Validation Accuracy: 0.996795913755243\n","Training epoch: 7\n","Training loss per 100 training steps: 0.003977504093199968\n","Training loss per 100 training steps: 0.003280875603852812\n","Training loss epoch: 0.003218740624810969\n","Training accuracy epoch: 0.9989525624608979\n","Validating model...\n","Validation Loss: 0.013788989927152648\n","Validation Accuracy: 0.9967888874286495\n","Training epoch: 8\n","Training loss per 100 training steps: 0.0016905023949220777\n","Training loss per 100 training steps: 0.003153333655892212\n","Training loss epoch: 0.00289905106388098\n","Training accuracy epoch: 0.9990560887948382\n","Validating model...\n","Validation Loss: 0.011534308087513117\n","Validation Accuracy: 0.9976231641761644\n","Training epoch: 9\n","Training loss per 100 training steps: 0.00011630092194536701\n","Training loss per 100 training steps: 0.0019566864165705676\n","Training loss epoch: 0.0021398632712256406\n","Training accuracy epoch: 0.9992873444702814\n","Validating model...\n","Validation Loss: 0.013866110469669886\n","Validation Accuracy: 0.9973462672030993\n","Training epoch: 10\n","Training loss per 100 training steps: 0.009285184554755688\n","Training loss per 100 training steps: 0.0048990794537458705\n","Training loss epoch: 0.004292104353482219\n","Training accuracy epoch: 0.9988369086465215\n","Validating model...\n","Validation Loss: 0.01118750781807605\n","Validation Accuracy: 0.9975584181539554\n","Training epoch: 11\n","Patience limit reached\n","Training duration: 36.638148016666676 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.009997340152646453\n","Validation Accuracy: 0.9970518112460541\n","Validation duration: 0.22304526666666788 minutes\n","F1-score (test): 98.1%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.99      0.98      1238\n","\n","   micro avg       0.97      0.99      0.98      1238\n","   macro avg       0.97      0.99      0.98      1238\n","weighted avg       0.97      0.99      0.98      1238\n","\n","!!!!!! Starting model number 5 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 2272\n","Points in y_train after augmentation: 2272\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.284462332725525\n","Training loss per 100 training steps: 0.08952537832302179\n","Training loss epoch: 0.06970020597735026\n","Training accuracy epoch: 0.9762429447526555\n","Validating model...\n","Validation Loss: 0.013842408678361348\n","Validation Accuracy: 0.9960599450157813\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0349896065890789\n","Training loss per 100 training steps: 0.01342074235896626\n","Training loss epoch: 0.012596467691047353\n","Training accuracy epoch: 0.996201907038875\n","Validating model...\n","Validation Loss: 0.013903039368978213\n","Validation Accuracy: 0.9962532670638411\n","Training epoch: 3\n","Training loss per 100 training steps: 0.00346291228197515\n","Training loss per 100 training steps: 0.008011103527606603\n","Training loss epoch: 0.008254624854832311\n","Training accuracy epoch: 0.9975849680659398\n","Validating model...\n","Validation Loss: 0.015099356860099803\n","Validation Accuracy: 0.9943997863576867\n","Training epoch: 4\n","Training loss per 100 training steps: 0.002672287868335843\n","Training loss per 100 training steps: 0.00618503015173719\n","Training loss epoch: 0.006714738557003701\n","Training accuracy epoch: 0.9979155157217654\n","Validating model...\n","Validation Loss: 0.019852352995907756\n","Validation Accuracy: 0.9946064294088226\n","Training epoch: 5\n","Training loss per 100 training steps: 0.009732119739055634\n","Training loss per 100 training steps: 0.005252847858614722\n","Training loss epoch: 0.005043026468549317\n","Training accuracy epoch: 0.998453964835451\n","Validating model...\n","Validation Loss: 0.018585433544926457\n","Validation Accuracy: 0.9955502645849756\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0006479123840108514\n","Training loss per 100 training steps: 0.003649700338212257\n","Training loss epoch: 0.0039511783150783875\n","Training accuracy epoch: 0.9987710459703075\n","Validating model...\n","Validation Loss: 0.012179949048177582\n","Validation Accuracy: 0.996986179884614\n","Training epoch: 7\n","Training loss per 100 training steps: 0.001267756219021976\n","Training loss per 100 training steps: 0.00338470709488824\n","Training loss epoch: 0.003740899673393357\n","Training accuracy epoch: 0.9987807733230046\n","Validating model...\n","Validation Loss: 0.011940789258958483\n","Validation Accuracy: 0.9973711761873367\n","Training epoch: 8\n","Training loss per 100 training steps: 0.008074205368757248\n","Training loss per 100 training steps: 0.002555275483300107\n","Training loss epoch: 0.002437124023575526\n","Training accuracy epoch: 0.9992627123449574\n","Validating model...\n","Validation Loss: 0.011164439478307031\n","Validation Accuracy: 0.9974693888849527\n","Training epoch: 9\n","Training loss per 100 training steps: 0.0032954521011561155\n","Training loss per 100 training steps: 0.0015313581325514887\n","Training loss epoch: 0.0016555044618963993\n","Training accuracy epoch: 0.999498591996655\n","Validating model...\n","Validation Loss: 0.015728872811450856\n","Validation Accuracy: 0.9966956322130182\n","Training epoch: 10\n","Training loss per 100 training steps: 0.0021582243498414755\n","Training loss per 100 training steps: 0.0019583028139941866\n","Training loss epoch: 0.0023237992303825517\n","Training accuracy epoch: 0.9992527694244222\n","Validating model...\n","Validation Loss: 0.015716022759512442\n","Validation Accuracy: 0.9964658645424346\n","Training epoch: 11\n","Training loss per 100 training steps: 0.012401786632835865\n","Training loss per 100 training steps: 0.0077039254565624115\n","Training loss epoch: 0.007390338516979426\n","Training accuracy epoch: 0.9978495276041823\n","Validating model...\n","Validation Loss: 0.011684733238195934\n","Validation Accuracy: 0.9968616388183927\n","Training epoch: 12\n","Training loss per 100 training steps: 0.0007422239286825061\n","Training loss per 100 training steps: 0.0028918665891546655\n","Training loss epoch: 0.002768556181071687\n","Training accuracy epoch: 0.9990994798331106\n","Validating model...\n","Validation Loss: 0.014036969457135586\n","Validation Accuracy: 0.9970683849293507\n","Training epoch: 13\n","Training loss per 100 training steps: 0.003560840617865324\n","Training loss per 100 training steps: 0.004835831690203608\n","Training loss epoch: 0.0047843793708522405\n","Training accuracy epoch: 0.9983971479010966\n","Validating model...\n","Validation Loss: 0.014993576094379282\n","Validation Accuracy: 0.9966702547681544\n","Training epoch: 14\n","Patience limit reached\n","Training duration: 47.572780349999995 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.014185484011856412\n","Validation Accuracy: 0.9972978567837866\n","Validation duration: 0.2211856333333344 minutes\n","F1-score (test): 98.2%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.98      0.99      0.98      1238\n","\n","   micro avg       0.98      0.99      0.98      1238\n","   macro avg       0.98      0.99      0.98      1238\n","weighted avg       0.98      0.99      0.98      1238\n","\n","!!!!!! Starting model number 6 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 2272\n","Points in y_train after augmentation: 2272\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 0.9890460968017578\n","Training loss per 100 training steps: 0.07825138962753855\n","Training loss epoch: 0.06085584139694053\n","Training accuracy epoch: 0.981294675306506\n","Validating model...\n","Validation Loss: 0.012345167409096445\n","Validation Accuracy: 0.9964435811088217\n","Training epoch: 2\n","Training loss per 100 training steps: 0.008445598185062408\n","Training loss per 100 training steps: 0.01260841535381272\n","Training loss epoch: 0.013014516772695777\n","Training accuracy epoch: 0.9960785053154569\n","Validating model...\n","Validation Loss: 0.01219751080636689\n","Validation Accuracy: 0.9962887052951862\n","Training epoch: 3\n","Training loss per 100 training steps: 0.005709276534616947\n","Training loss per 100 training steps: 0.009884695906888251\n","Training loss epoch: 0.009273864651872764\n","Training accuracy epoch: 0.9971942928070748\n","Validating model...\n","Validation Loss: 0.010224602204592278\n","Validation Accuracy: 0.997481699540336\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0022652852348983288\n","Training loss per 100 training steps: 0.004081623382361532\n","Training loss epoch: 0.004125158879028725\n","Training accuracy epoch: 0.9986564112149122\n","Validating model...\n","Validation Loss: 0.014429473382257302\n","Validation Accuracy: 0.9961685132671656\n","Training epoch: 5\n","Training loss per 100 training steps: 0.006396966520696878\n","Training loss per 100 training steps: 0.003933532470243632\n","Training loss epoch: 0.0038939067098012026\n","Training accuracy epoch: 0.9988162136931868\n","Validating model...\n","Validation Loss: 0.010409453440280188\n","Validation Accuracy: 0.9974504514576181\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0035754384007304907\n","Training loss per 100 training steps: 0.0031230803090666354\n","Training loss epoch: 0.003096308973498977\n","Training accuracy epoch: 0.9990741248961551\n","Validating model...\n","Validation Loss: 0.01428307562604286\n","Validation Accuracy: 0.9968574836179845\n","Training epoch: 7\n","Training loss per 100 training steps: 0.012143942527472973\n","Training loss per 100 training steps: 0.005036249379399763\n","Training loss epoch: 0.004654637394683242\n","Training accuracy epoch: 0.9986258842865227\n","Validating model...\n","Validation Loss: 0.012597940531988917\n","Validation Accuracy: 0.9973928047995807\n","Training epoch: 8\n","Training loss per 100 training steps: 0.0006257629138417542\n","Training loss per 100 training steps: 0.004628812278506212\n","Training loss epoch: 0.004874839509591791\n","Training accuracy epoch: 0.9984958766742463\n","Validating model...\n","Validation Loss: 0.011132828605782595\n","Validation Accuracy: 0.9964422327466449\n","Training epoch: 9\n","Patience limit reached\n","Training duration: 29.31734936666665 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.01253793668365688\n","Validation Accuracy: 0.9964940711021688\n","Validation duration: 0.22304996666665222 minutes\n","F1-score (test): 98.0%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.99      0.98      1238\n","\n","   micro avg       0.97      0.99      0.98      1238\n","   macro avg       0.97      0.99      0.98      1238\n","weighted avg       0.97      0.99      0.98      1238\n","\n","!!!!!! Starting model number 7 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 2272\n","Points in y_train after augmentation: 2272\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 0.9331566095352173\n","Training loss per 100 training steps: 0.08360751988458456\n","Training loss epoch: 0.0654440809969305\n","Training accuracy epoch: 0.9806266730510577\n","Validating model...\n","Validation Loss: 0.011588027404199931\n","Validation Accuracy: 0.9963116490840804\n","Training epoch: 2\n","Training loss per 100 training steps: 0.01412385143339634\n","Training loss per 100 training steps: 0.012692732620629307\n","Training loss epoch: 0.012004535130395646\n","Training accuracy epoch: 0.9963565219986762\n","Validating model...\n","Validation Loss: 0.008549935991011028\n","Validation Accuracy: 0.9973687780974311\n","Training epoch: 3\n","Training loss per 100 training steps: 0.007882938720285892\n","Training loss per 100 training steps: 0.007411989721695496\n","Training loss epoch: 0.007688773039672655\n","Training accuracy epoch: 0.9976461179908647\n","Validating model...\n","Validation Loss: 0.01677532191249719\n","Validation Accuracy: 0.9954342442932935\n","Training epoch: 4\n","Training loss per 100 training steps: 0.008846943266689777\n","Training loss per 100 training steps: 0.008640533884569984\n","Training loss epoch: 0.007835889064615041\n","Training accuracy epoch: 0.9976036077888706\n","Validating model...\n","Validation Loss: 0.011781778836891698\n","Validation Accuracy: 0.9973317339362964\n","Training epoch: 5\n","Training loss per 100 training steps: 0.002268312033265829\n","Training loss per 100 training steps: 0.005091533291621576\n","Training loss epoch: 0.005188386461207263\n","Training accuracy epoch: 0.998431508222763\n","Validating model...\n","Validation Loss: 0.012484411173794624\n","Validation Accuracy: 0.9973181972054325\n","Training epoch: 6\n","Training loss per 100 training steps: 0.01218422781676054\n","Training loss per 100 training steps: 0.00217964504914598\n","Training loss epoch: 0.0027841225568869996\n","Training accuracy epoch: 0.9991783293655101\n","Validating model...\n","Validation Loss: 0.011482915050735409\n","Validation Accuracy: 0.9974559397567899\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0018395727965980768\n","Training loss per 100 training steps: 0.005108787689492277\n","Training loss epoch: 0.004705809565973436\n","Training accuracy epoch: 0.9984865638126993\n","Validating model...\n","Validation Loss: 0.010560783432430028\n","Validation Accuracy: 0.9976097345695555\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 25.641053900000042 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.014044602959378002\n","Validation Accuracy: 0.9961456897976384\n","Validation duration: 0.22011575000002873 minutes\n","F1-score (test): 97.4%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.98      0.97      1238\n","\n","   micro avg       0.97      0.98      0.97      1238\n","   macro avg       0.97      0.98      0.97      1238\n","weighted avg       0.97      0.98      0.97      1238\n","\n","!!!!!! Starting model number 8 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 2272\n","Points in y_train after augmentation: 2272\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.2049622535705566\n","Training loss per 100 training steps: 0.08202141848402006\n","Training loss epoch: 0.06491058241103737\n","Training accuracy epoch: 0.9772304812953275\n","Validating model...\n","Validation Loss: 0.016128178126001286\n","Validation Accuracy: 0.9950729867126468\n","Training epoch: 2\n","Training loss per 100 training steps: 0.013143068179488182\n","Training loss per 100 training steps: 0.013806598007420796\n","Training loss epoch: 0.012302225664287517\n","Training accuracy epoch: 0.9963143613944581\n","Validating model...\n","Validation Loss: 0.011992827310764585\n","Validation Accuracy: 0.9966892620279209\n","Training epoch: 3\n","Training loss per 100 training steps: 0.00246641063131392\n","Training loss per 100 training steps: 0.008011931696985065\n","Training loss epoch: 0.007493151925072979\n","Training accuracy epoch: 0.9977740424113714\n","Validating model...\n","Validation Loss: 0.016346728180776284\n","Validation Accuracy: 0.9954233657315376\n","Training epoch: 4\n","Training loss per 100 training steps: 0.007847587577998638\n","Training loss per 100 training steps: 0.008804329082261458\n","Training loss epoch: 0.007905798187212114\n","Training accuracy epoch: 0.9977250803850634\n","Validating model...\n","Validation Loss: 0.011628651872299434\n","Validation Accuracy: 0.9974070967234635\n","Training epoch: 5\n","Training loss per 100 training steps: 0.002272315789014101\n","Training loss per 100 training steps: 0.004471478305871156\n","Training loss epoch: 0.004512249974474069\n","Training accuracy epoch: 0.9986536597001914\n","Validating model...\n","Validation Loss: 0.013674828986820233\n","Validation Accuracy: 0.9966241382354243\n","Training epoch: 6\n","Training loss per 100 training steps: 0.007097144145518541\n","Training loss per 100 training steps: 0.004311546932278884\n","Training loss epoch: 0.0041933521791525236\n","Training accuracy epoch: 0.9988428127452178\n","Validating model...\n","Validation Loss: 0.011040722710146968\n","Validation Accuracy: 0.9975391366051418\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0004507152480073273\n","Training loss per 100 training steps: 0.002525916325947325\n","Training loss epoch: 0.002868016851774063\n","Training accuracy epoch: 0.9991661200589632\n","Validating model...\n","Validation Loss: 0.010786011842962276\n","Validation Accuracy: 0.9976829483159937\n","Training epoch: 8\n","Training loss per 100 training steps: 0.0014828538987785578\n","Training loss per 100 training steps: 0.0022070813445157675\n","Training loss epoch: 0.0028362064844720445\n","Training accuracy epoch: 0.9991627334619331\n","Validating model...\n","Validation Loss: 0.01137911423644428\n","Validation Accuracy: 0.9974747057420951\n","Training epoch: 9\n","Training loss per 100 training steps: 0.00602545402944088\n","Training loss per 100 training steps: 0.0026128934076779732\n","Training loss epoch: 0.0022805041771277157\n","Training accuracy epoch: 0.9993794735002705\n","Validating model...\n","Validation Loss: 0.015930163142218675\n","Validation Accuracy: 0.9970905835864149\n","Training epoch: 10\n","Training loss per 100 training steps: 0.0007854477153159678\n","Training loss per 100 training steps: 0.0022412726032751667\n","Training loss epoch: 0.002159686162690698\n","Training accuracy epoch: 0.9993119839351249\n","Validating model...\n","Validation Loss: 0.016554931921356392\n","Validation Accuracy: 0.9972293531353701\n","Training epoch: 11\n","Training loss per 100 training steps: 0.00014768482651561499\n","Training loss per 100 training steps: 0.0018219406803909085\n","Training loss epoch: 0.002125450727964537\n","Training accuracy epoch: 0.9993517551617658\n","Validating model...\n","Validation Loss: 0.015563685596654457\n","Validation Accuracy: 0.9966013266074014\n","Training epoch: 12\n","Training loss per 100 training steps: 0.00043447015923447907\n","Training loss per 100 training steps: 0.007642453910490742\n","Training loss epoch: 0.007387189093465232\n","Training accuracy epoch: 0.9979093720445238\n","Validating model...\n","Validation Loss: 0.013120752759624295\n","Validation Accuracy: 0.9971421716375711\n","Training epoch: 13\n","Patience limit reached\n","Training duration: 44.013019900000046 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.012853215806444496\n","Validation Accuracy: 0.9968050980952543\n","Validation duration: 0.22015700000004776 minutes\n","F1-score (test): 98.0%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.99      0.98      1238\n","\n","   micro avg       0.97      0.99      0.98      1238\n","   macro avg       0.97      0.99      0.98      1238\n","weighted avg       0.97      0.99      0.98      1238\n","\n","!!!!!! Starting model number 9 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 2272\n","Points in y_train after augmentation: 2272\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.171086072921753\n","Training loss per 100 training steps: 0.08689488680793507\n","Training loss epoch: 0.06841112626388564\n","Training accuracy epoch: 0.9766413102620655\n","Validating model...\n","Validation Loss: 0.01400891526247419\n","Validation Accuracy: 0.9960843179490744\n","Training epoch: 2\n","Training loss per 100 training steps: 0.020419368520379066\n","Training loss per 100 training steps: 0.0139860958944416\n","Training loss epoch: 0.013828656960829673\n","Training accuracy epoch: 0.9958478471905862\n","Validating model...\n","Validation Loss: 0.012068734726025945\n","Validation Accuracy: 0.9966171457243773\n","Training epoch: 3\n","Training loss per 100 training steps: 0.002090692985802889\n","Training loss per 100 training steps: 0.00693241567904185\n","Training loss epoch: 0.006918204512978366\n","Training accuracy epoch: 0.997875182589181\n","Validating model...\n","Validation Loss: 0.011269969011274432\n","Validation Accuracy: 0.9971101051091602\n","Training epoch: 4\n","Training loss per 100 training steps: 0.002255400875583291\n","Training loss per 100 training steps: 0.004229193925050705\n","Training loss epoch: 0.004586629872866185\n","Training accuracy epoch: 0.9986172808733852\n","Validating model...\n","Validation Loss: 0.010258611292339907\n","Validation Accuracy: 0.9976530937504723\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0005775331519544125\n","Training loss per 100 training steps: 0.00454945506246779\n","Training loss epoch: 0.00518859227058399\n","Training accuracy epoch: 0.9984279043053982\n","Validating model...\n","Validation Loss: 0.015311900932006427\n","Validation Accuracy: 0.9964240043013884\n","Training epoch: 6\n","Training loss per 100 training steps: 0.020684504881501198\n","Training loss per 100 training steps: 0.0067914093280958\n","Training loss epoch: 0.0062739179479073025\n","Training accuracy epoch: 0.9982976027691424\n","Validating model...\n","Validation Loss: 0.01380100427957673\n","Validation Accuracy: 0.9971861600065077\n","Training epoch: 7\n","Training loss per 100 training steps: 0.002434657420963049\n","Training loss per 100 training steps: 0.004320724975198996\n","Training loss epoch: 0.004479108755718621\n","Training accuracy epoch: 0.9986558579609526\n","Validating model...\n","Validation Loss: 0.01866707681031022\n","Validation Accuracy: 0.9953365615215025\n","Training epoch: 8\n","Training loss per 100 training steps: 0.005594645161181688\n","Training loss per 100 training steps: 0.0028227949663385803\n","Training loss epoch: 0.0031773275855607286\n","Training accuracy epoch: 0.9991115225442068\n","Validating model...\n","Validation Loss: 0.009978595718469782\n","Validation Accuracy: 0.9977508466741509\n","Training epoch: 9\n","Training loss per 100 training steps: 0.0001746226625982672\n","Training loss per 100 training steps: 0.0024905159284526685\n","Training loss epoch: 0.003295558495383503\n","Training accuracy epoch: 0.9991206615718501\n","Validating model...\n","Validation Loss: 0.010445209553533156\n","Validation Accuracy: 0.9976082531652244\n","Training epoch: 10\n","Training loss per 100 training steps: 0.00037338881520554423\n","Training loss per 100 training steps: 0.003857806484597634\n","Training loss epoch: 0.0036602526630867688\n","Training accuracy epoch: 0.9988977870949783\n","Validating model...\n","Validation Loss: 0.009935857965111998\n","Validation Accuracy: 0.9975692882545275\n","Training epoch: 11\n","Training loss per 100 training steps: 0.0013243643334135413\n","Training loss per 100 training steps: 0.004842603875604794\n","Training loss epoch: 0.004807099646429161\n","Training accuracy epoch: 0.9986653653503252\n","Validating model...\n","Validation Loss: 0.015751782251754776\n","Validation Accuracy: 0.9969373632558468\n","Training epoch: 12\n","Training loss per 100 training steps: 0.004086867440491915\n","Training loss per 100 training steps: 0.0022589552362759524\n","Training loss epoch: 0.0023672538624504996\n","Training accuracy epoch: 0.9993611377609192\n","Validating model...\n","Validation Loss: 0.01593171007144043\n","Validation Accuracy: 0.9968114516380131\n","Training epoch: 13\n","Training loss per 100 training steps: 0.0007629023748449981\n","Training loss per 100 training steps: 0.0037222842006981002\n","Training loss epoch: 0.0033219152492549742\n","Training accuracy epoch: 0.9990990513756941\n","Validating model...\n","Validation Loss: 0.011997832512688114\n","Validation Accuracy: 0.9978881931296973\n","Training epoch: 14\n","Training loss per 100 training steps: 0.00010132845636690035\n","Training loss per 100 training steps: 0.007495617025732385\n","Training loss epoch: 0.006626211980353257\n","Training accuracy epoch: 0.99801135525155\n","Validating model...\n","Validation Loss: 0.015555301316670097\n","Validation Accuracy: 0.9969922373418216\n","Training epoch: 15\n","Training loss per 100 training steps: 0.002279527485370636\n","Training loss per 100 training steps: 0.003329408588968471\n","Training loss epoch: 0.004039109043781498\n","Training accuracy epoch: 0.9988221014604883\n","Validating model...\n","Validation Loss: 0.012519423755639721\n","Validation Accuracy: 0.9967562744854835\n","Training epoch: 16\n","Patience limit reached\n","Training duration: 54.98872168333334 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.011831121712020831\n","Validation Accuracy: 0.9969945010070838\n","Validation duration: 0.22333131666667516 minutes\n","F1-score (test): 97.9%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.99      0.98      1238\n","\n","   micro avg       0.97      0.99      0.98      1238\n","   macro avg       0.97      0.99      0.98      1238\n","weighted avg       0.97      0.99      0.98      1238\n","\n","!!!!!! Starting model number 10 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 2272\n","Points in y_train after augmentation: 2272\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.0889582633972168\n","Training loss per 100 training steps: 0.10415541166716283\n","Training loss epoch: 0.07982803122665157\n","Training accuracy epoch: 0.9744858849344112\n","Validating model...\n","Validation Loss: 0.01464344579948201\n","Validation Accuracy: 0.9959755601258452\n","Training epoch: 2\n","Training loss per 100 training steps: 0.005639960523694754\n","Training loss per 100 training steps: 0.012117196410424122\n","Training loss epoch: 0.01279517186602289\n","Training accuracy epoch: 0.996308509560914\n","Validating model...\n","Validation Loss: 0.014734974970841514\n","Validation Accuracy: 0.9948379436217994\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0016223194543272257\n","Training loss per 100 training steps: 0.008116560006090024\n","Training loss epoch: 0.008205916038156867\n","Training accuracy epoch: 0.9976292747475207\n","Validating model...\n","Validation Loss: 0.016320905287838763\n","Validation Accuracy: 0.996606952174445\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0021712633315473795\n","Training loss per 100 training steps: 0.00547002198818338\n","Training loss epoch: 0.006113607338756736\n","Training accuracy epoch: 0.9981828611789155\n","Validating model...\n","Validation Loss: 0.013529712151336883\n","Validation Accuracy: 0.996087143604103\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0054350318387150764\n","Training loss per 100 training steps: 0.004844114075744488\n","Training loss epoch: 0.005462206137476449\n","Training accuracy epoch: 0.9984152538150647\n","Validating model...\n","Validation Loss: 0.011750994785134458\n","Validation Accuracy: 0.9971681760152165\n","Training epoch: 6\n","Training loss per 100 training steps: 0.004587866831570864\n","Training loss per 100 training steps: 0.003968197156474603\n","Training loss epoch: 0.00402620341567303\n","Training accuracy epoch: 0.9987461514182663\n","Validating model...\n","Validation Loss: 0.0189227264113253\n","Validation Accuracy: 0.9961152569030359\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0005380306974984705\n","Training loss per 100 training steps: 0.0026023140841908293\n","Training loss epoch: 0.0028080325710491284\n","Training accuracy epoch: 0.999174072868503\n","Validating model...\n","Validation Loss: 0.009836308933569984\n","Validation Accuracy: 0.9978665135828739\n","Training epoch: 8\n","Training loss per 100 training steps: 0.007097821217030287\n","Training loss per 100 training steps: 0.0037393246328983787\n","Training loss epoch: 0.003759242336765427\n","Training accuracy epoch: 0.9988615470869175\n","Validating model...\n","Validation Loss: 0.013164704578923107\n","Validation Accuracy: 0.9973526943985566\n","Training epoch: 9\n","Training loss per 100 training steps: 0.005273118149489164\n","Training loss per 100 training steps: 0.0027841658390237774\n","Training loss epoch: 0.0024402391476106575\n","Training accuracy epoch: 0.9992707879669471\n","Validating model...\n","Validation Loss: 0.01347172668517617\n","Validation Accuracy: 0.9973879632116395\n","Training epoch: 10\n","Training loss per 100 training steps: 0.005037627182900906\n","Training loss per 100 training steps: 0.005938365206722917\n","Training loss epoch: 0.005216531372099499\n","Training accuracy epoch: 0.9985164709186826\n","Validating model...\n","Validation Loss: 0.01188946398109519\n","Validation Accuracy: 0.9974411799295414\n","Training epoch: 11\n","Training loss per 100 training steps: 0.011606908403337002\n","Training loss per 100 training steps: 0.003991185157922314\n","Training loss epoch: 0.003918830789599001\n","Training accuracy epoch: 0.9989675044658576\n","Validating model...\n","Validation Loss: 0.011776016890681126\n","Validation Accuracy: 0.9971855620105108\n","Training epoch: 12\n","Training loss per 100 training steps: 0.0014756848104298115\n","Training loss per 100 training steps: 0.0025753532914533557\n","Training loss epoch: 0.0024699231319791066\n","Training accuracy epoch: 0.9992825764795079\n","Validating model...\n","Validation Loss: 0.01294179834630562\n","Validation Accuracy: 0.9976915254154933\n","Training epoch: 13\n","Patience limit reached\n","Training duration: 43.98816496666665 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.011977012592372679\n","Validation Accuracy: 0.996976349706164\n","Validation duration: 0.2199723499999891 minutes\n","F1-score (test): 98.0%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.99      0.98      1238\n","\n","   micro avg       0.97      0.99      0.98      1238\n","   macro avg       0.97      0.99      0.98      1238\n","weighted avg       0.97      0.99      0.98      1238\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0.25\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"Jhz9BiIwGCsV"},{"cell_type":"code","execution_count":null,"metadata":{"id":"jdO4m5O4Hlo3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665757087955,"user_tz":240,"elapsed":28591620,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}},"outputId":"a4303af4-5d0b-4af3-ed7d-e62edf79cd99"},"outputs":[{"output_type":"stream","name":"stdout","text":["!!!!!! Augmented Percentage 50.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 2726\n","Points in y_train after augmentation: 2726\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 0.9259651899337769\n","Training loss per 100 training steps: 0.08664982521095045\n","Training loss epoch: 0.05886697201112732\n","Training accuracy epoch: 0.9819004789929399\n","Validating model...\n","Validation Loss: 0.01588757356096591\n","Validation Accuracy: 0.9957030530004225\n","Training epoch: 2\n","Training loss per 100 training steps: 0.014247862622141838\n","Training loss per 100 training steps: 0.014943510854137268\n","Training loss epoch: 0.013314986013948961\n","Training accuracy epoch: 0.9961171686238919\n","Validating model...\n","Validation Loss: 0.008172163960850975\n","Validation Accuracy: 0.9978055725505416\n","Training epoch: 3\n","Training loss per 100 training steps: 0.002612123964354396\n","Training loss per 100 training steps: 0.006589516255910056\n","Training loss epoch: 0.006434367524054206\n","Training accuracy epoch: 0.9981559291738964\n","Validating model...\n","Validation Loss: 0.00879051014462242\n","Validation Accuracy: 0.9977325443356087\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0023377269972115755\n","Training loss per 100 training steps: 0.0044919457325497455\n","Training loss epoch: 0.006598308317452446\n","Training accuracy epoch: 0.9980137172040894\n","Validating model...\n","Validation Loss: 0.015801833727025604\n","Validation Accuracy: 0.9959380568483882\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0013160499511286616\n","Training loss per 100 training steps: 0.0045565622469691544\n","Training loss epoch: 0.005217171187665074\n","Training accuracy epoch: 0.9983091024276729\n","Validating model...\n","Validation Loss: 0.028952843860939277\n","Validation Accuracy: 0.9941781315819751\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0003615188179537654\n","Training loss per 100 training steps: 0.00714746276380628\n","Training loss epoch: 0.007074737764860242\n","Training accuracy epoch: 0.9979196479285998\n","Validating model...\n","Validation Loss: 0.010635573210449712\n","Validation Accuracy: 0.9970604621003235\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0195144172757864\n","Training loss per 100 training steps: 0.005739820608898011\n","Training loss epoch: 0.0046767489954421424\n","Training accuracy epoch: 0.998671173265726\n","Validating model...\n","Validation Loss: 0.013568992848463711\n","Validation Accuracy: 0.9972205733394575\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 30.51712971666669 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.01177542043660651\n","Validation Accuracy: 0.9962724426826646\n","Validation duration: 0.2232415166666518 minutes\n","F1-score (test): 97.6%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.99      0.98      1238\n","\n","   micro avg       0.97      0.99      0.98      1238\n","   macro avg       0.97      0.99      0.98      1238\n","weighted avg       0.97      0.99      0.98      1238\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 2726\n","Points in y_train after augmentation: 2726\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 0.8659623861312866\n","Training loss per 100 training steps: 0.07690821040772122\n","Training loss epoch: 0.05362773854666722\n","Training accuracy epoch: 0.9841178162053001\n","Validating model...\n","Validation Loss: 0.01640018455440267\n","Validation Accuracy: 0.9950669365165565\n","Training epoch: 2\n","Training loss per 100 training steps: 0.01863662153482437\n","Training loss per 100 training steps: 0.01228437213328584\n","Training loss epoch: 0.011685512357456773\n","Training accuracy epoch: 0.9964131604521612\n","Validating model...\n","Validation Loss: 0.013220945119558434\n","Validation Accuracy: 0.9962727913138969\n","Training epoch: 3\n","Training loss per 100 training steps: 0.005918063689023256\n","Training loss per 100 training steps: 0.006734181146510867\n","Training loss epoch: 0.007699169772193762\n","Training accuracy epoch: 0.9976780664736552\n","Validating model...\n","Validation Loss: 0.014390244263701052\n","Validation Accuracy: 0.9962629227086394\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0013415636494755745\n","Training loss per 100 training steps: 0.00611710063274604\n","Training loss epoch: 0.007475750339819984\n","Training accuracy epoch: 0.9978315760664289\n","Validating model...\n","Validation Loss: 0.017913009313772255\n","Validation Accuracy: 0.9955647934320982\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0030918698757886887\n","Training loss per 100 training steps: 0.0049339038542342735\n","Training loss epoch: 0.0045652465460133025\n","Training accuracy epoch: 0.9985340909213144\n","Validating model...\n","Validation Loss: 0.010826963894422599\n","Validation Accuracy: 0.99728298607002\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0004341478634160012\n","Training loss per 100 training steps: 0.004673975028096477\n","Training loss epoch: 0.00425867099203959\n","Training accuracy epoch: 0.9986128051100065\n","Validating model...\n","Validation Loss: 0.011795403469001204\n","Validation Accuracy: 0.9976355743202673\n","Training epoch: 7\n","Training loss per 100 training steps: 0.007431773003190756\n","Training loss per 100 training steps: 0.0030967879736113666\n","Training loss epoch: 0.003053564484175349\n","Training accuracy epoch: 0.9991142921778757\n","Validating model...\n","Validation Loss: 0.02032083658109297\n","Validation Accuracy: 0.9952916287966839\n","Training epoch: 8\n","Training loss per 100 training steps: 0.0004087679262738675\n","Training loss per 100 training steps: 0.004942453611802913\n","Training loss epoch: 0.0051104308662807425\n","Training accuracy epoch: 0.9984905800904303\n","Validating model...\n","Validation Loss: 0.010735430201401911\n","Validation Accuracy: 0.9978042433848823\n","Training epoch: 9\n","Training loss per 100 training steps: 0.0005192214739508927\n","Training loss per 100 training steps: 0.002795316354431544\n","Training loss epoch: 0.002594038839896185\n","Training accuracy epoch: 0.9992567539924788\n","Validating model...\n","Validation Loss: 0.009996188993682154\n","Validation Accuracy: 0.9978138373815061\n","Training epoch: 10\n","Training loss per 100 training steps: 0.00024910253705456853\n","Training loss per 100 training steps: 0.002085672215177357\n","Training loss epoch: 0.002470902075885682\n","Training accuracy epoch: 0.9992475210871794\n","Validating model...\n","Validation Loss: 0.012812836394351464\n","Validation Accuracy: 0.997233886116083\n","Training epoch: 11\n","Training loss per 100 training steps: 0.0014377436600625515\n","Training loss per 100 training steps: 0.002810756486868209\n","Training loss epoch: 0.003093325744315979\n","Training accuracy epoch: 0.9991319056378772\n","Validating model...\n","Validation Loss: 0.014750381456299996\n","Validation Accuracy: 0.9972833120505978\n","Training epoch: 12\n","Training loss per 100 training steps: 0.006050469353795052\n","Training loss per 100 training steps: 0.0025821480925118847\n","Training loss epoch: 0.005022250541706423\n","Training accuracy epoch: 0.9985741659153342\n","Validating model...\n","Validation Loss: 0.015576859767731679\n","Validation Accuracy: 0.9952898909662649\n","Training epoch: 13\n","Training loss per 100 training steps: 0.004354167263954878\n","Training loss per 100 training steps: 0.011721605086344119\n","Training loss epoch: 0.008592840916053692\n","Training accuracy epoch: 0.9975104885609494\n","Validating model...\n","Validation Loss: 0.011082597705743475\n","Validation Accuracy: 0.9974000522653208\n","Training epoch: 14\n","Training loss per 100 training steps: 0.00045714707812294364\n","Training loss per 100 training steps: 0.001957112018056133\n","Training loss epoch: 0.00253127724572125\n","Training accuracy epoch: 0.9991720706508695\n","Validating model...\n","Validation Loss: 0.01270953893219398\n","Validation Accuracy: 0.9976434839425197\n","Training epoch: 15\n","Patience limit reached\n","Training duration: 61.001804599999986 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.016924318915547094\n","Validation Accuracy: 0.9967263191203659\n","Validation duration: 0.22041484999996708 minutes\n","F1-score (test): 98.1%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.99      0.98      1238\n","\n","   micro avg       0.97      0.99      0.98      1238\n","   macro avg       0.97      0.99      0.98      1238\n","weighted avg       0.97      0.99      0.98      1238\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 2726\n","Points in y_train after augmentation: 2726\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.2903555631637573\n","Training loss per 100 training steps: 0.08223190314440738\n","Training loss epoch: 0.05714373719165025\n","Training accuracy epoch: 0.9803801368653815\n","Validating model...\n","Validation Loss: 0.01261617453946244\n","Validation Accuracy: 0.9964226324787255\n","Training epoch: 2\n","Training loss per 100 training steps: 0.022369462996721268\n","Training loss per 100 training steps: 0.012163695968032842\n","Training loss epoch: 0.011327214752819541\n","Training accuracy epoch: 0.9966227314994757\n","Validating model...\n","Validation Loss: 0.00947615635093479\n","Validation Accuracy: 0.9971813742177386\n","Training epoch: 3\n","Training loss per 100 training steps: 0.003606528276577592\n","Training loss per 100 training steps: 0.010013649255120298\n","Training loss epoch: 0.008843348869422113\n","Training accuracy epoch: 0.9972306501946243\n","Validating model...\n","Validation Loss: 0.009721270084680458\n","Validation Accuracy: 0.997467779847713\n","Training epoch: 4\n","Training loss per 100 training steps: 0.015451588667929173\n","Training loss per 100 training steps: 0.006403289564152128\n","Training loss epoch: 0.005751596672759304\n","Training accuracy epoch: 0.9982203582579593\n","Validating model...\n","Validation Loss: 0.010399611982090088\n","Validation Accuracy: 0.9971405221141184\n","Training epoch: 5\n","Training loss per 100 training steps: 0.004939639940857887\n","Training loss per 100 training steps: 0.0035189902270155136\n","Training loss epoch: 0.0032525017554344126\n","Training accuracy epoch: 0.9989528431862308\n","Validating model...\n","Validation Loss: 0.014225304384516286\n","Validation Accuracy: 0.9961061164431302\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0015893846284598112\n","Training loss per 100 training steps: 0.0055501938634436795\n","Training loss epoch: 0.0049752055731845735\n","Training accuracy epoch: 0.9983916521027445\n","Validating model...\n","Validation Loss: 0.015890607773880697\n","Validation Accuracy: 0.9969854373168154\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0017594894161447883\n","Training loss per 100 training steps: 0.0024947184247499574\n","Training loss epoch: 0.002472183998966554\n","Training accuracy epoch: 0.9992162074346812\n","Validating model...\n","Validation Loss: 0.016431709486087562\n","Validation Accuracy: 0.9968387346069201\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 30.50047741666664 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.011271824145903034\n","Validation Accuracy: 0.9964295350500642\n","Validation duration: 0.22032983333325926 minutes\n","F1-score (test): 97.8%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.99      0.98      1238\n","\n","   micro avg       0.97      0.99      0.98      1238\n","   macro avg       0.97      0.99      0.98      1238\n","weighted avg       0.97      0.99      0.98      1238\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 2726\n","Points in y_train after augmentation: 2726\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.0387800931930542\n","Training loss per 100 training steps: 0.08302518227921411\n","Training loss epoch: 0.05675162424943383\n","Training accuracy epoch: 0.9822029025002834\n","Validating model...\n","Validation Loss: 0.015265940057967478\n","Validation Accuracy: 0.9958911575573486\n","Training epoch: 2\n","Training loss per 100 training steps: 0.005879840347915888\n","Training loss per 100 training steps: 0.01270862013830038\n","Training loss epoch: 0.011763598416912865\n","Training accuracy epoch: 0.9964750358157376\n","Validating model...\n","Validation Loss: 0.013553476479414496\n","Validation Accuracy: 0.9963290997304297\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0008966586901806295\n","Training loss per 100 training steps: 0.007813398063524008\n","Training loss epoch: 0.007215539027857785\n","Training accuracy epoch: 0.997752415684191\n","Validating model...\n","Validation Loss: 0.007703873768886773\n","Validation Accuracy: 0.9981510813773118\n","Training epoch: 4\n","Training loss per 100 training steps: 0.012412704527378082\n","Training loss per 100 training steps: 0.004349219910731299\n","Training loss epoch: 0.004267625389852131\n","Training accuracy epoch: 0.9987246464341323\n","Validating model...\n","Validation Loss: 0.008547308556964188\n","Validation Accuracy: 0.9980503918008846\n","Training epoch: 5\n","Training loss per 100 training steps: 0.004373194184154272\n","Training loss per 100 training steps: 0.006291165180984967\n","Training loss epoch: 0.0064863805086059195\n","Training accuracy epoch: 0.9979176047561218\n","Validating model...\n","Validation Loss: 0.01632247058556199\n","Validation Accuracy: 0.9968770065944884\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0007482027867808938\n","Training loss per 100 training steps: 0.00321380127116745\n","Training loss epoch: 0.0032206901540344566\n","Training accuracy epoch: 0.9989697689616014\n","Validating model...\n","Validation Loss: 0.011426852791503603\n","Validation Accuracy: 0.9973000757113786\n","Training epoch: 7\n","Training loss per 100 training steps: 0.006359863094985485\n","Training loss per 100 training steps: 0.002272859494383954\n","Training loss epoch: 0.002401075705958051\n","Training accuracy epoch: 0.9992386392186933\n","Validating model...\n","Validation Loss: 0.01054393885472867\n","Validation Accuracy: 0.9970787226429445\n","Training epoch: 8\n","Training loss per 100 training steps: 0.0004278784617781639\n","Training loss per 100 training steps: 0.0016146265956879212\n","Training loss epoch: 0.0015596446888562162\n","Training accuracy epoch: 0.999519216422139\n","Validating model...\n","Validation Loss: 0.010606840065606991\n","Validation Accuracy: 0.9976772423715287\n","Training epoch: 9\n","Patience limit reached\n","Training duration: 34.85714273333336 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.007750113752990728\n","Validation Accuracy: 0.9973812938507386\n","Validation duration: 0.22044228333337135 minutes\n","F1-score (test): 98.1%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.99      0.98      1238\n","\n","   micro avg       0.97      0.99      0.98      1238\n","   macro avg       0.97      0.99      0.98      1238\n","weighted avg       0.97      0.99      0.98      1238\n","\n","!!!!!! Starting model number 5 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 2726\n","Points in y_train after augmentation: 2726\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.058682918548584\n","Training loss per 100 training steps: 0.07965739764789544\n","Training loss epoch: 0.055914956701875865\n","Training accuracy epoch: 0.9817262943809801\n","Validating model...\n","Validation Loss: 0.013342838310303964\n","Validation Accuracy: 0.9961445551808539\n","Training epoch: 2\n","Training loss per 100 training steps: 0.008082612417638302\n","Training loss per 100 training steps: 0.011243588153946\n","Training loss epoch: 0.011040400578204695\n","Training accuracy epoch: 0.9966433260051422\n","Validating model...\n","Validation Loss: 0.010820801694145692\n","Validation Accuracy: 0.9967264217548529\n","Training epoch: 3\n","Training loss per 100 training steps: 0.011241622269153595\n","Training loss per 100 training steps: 0.006196425026939665\n","Training loss epoch: 0.006089916997058154\n","Training accuracy epoch: 0.9980715285118321\n","Validating model...\n","Validation Loss: 0.011159198574854859\n","Validation Accuracy: 0.9962934834490353\n","Training epoch: 4\n","Training loss per 100 training steps: 0.001631486346013844\n","Training loss per 100 training steps: 0.004469311888915219\n","Training loss epoch: 0.005085436760278402\n","Training accuracy epoch: 0.9983743716429682\n","Validating model...\n","Validation Loss: 0.014418965104033262\n","Validation Accuracy: 0.9963291030209692\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0014350961428135633\n","Training loss per 100 training steps: 0.005235509572482649\n","Training loss epoch: 0.00459380844757383\n","Training accuracy epoch: 0.9985521410049303\n","Validating model...\n","Validation Loss: 0.009285660654270379\n","Validation Accuracy: 0.9978073391451465\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0002664784260559827\n","Training loss per 100 training steps: 0.002793693410807248\n","Training loss epoch: 0.0034305018657319417\n","Training accuracy epoch: 0.9989671200004647\n","Validating model...\n","Validation Loss: 0.011661983598709671\n","Validation Accuracy: 0.9970044230631819\n","Training epoch: 7\n","Training loss per 100 training steps: 0.006332265678793192\n","Training loss per 100 training steps: 0.002954028745350142\n","Training loss epoch: 0.004004481312211559\n","Training accuracy epoch: 0.9987828117863745\n","Validating model...\n","Validation Loss: 0.013734430400897205\n","Validation Accuracy: 0.997181633072724\n","Training epoch: 8\n","Training loss per 100 training steps: 0.006361179053783417\n","Training loss per 100 training steps: 0.0029921754910829613\n","Training loss epoch: 0.004768397039415557\n","Training accuracy epoch: 0.998491526302614\n","Validating model...\n","Validation Loss: 0.015483299548144541\n","Validation Accuracy: 0.9965417665387206\n","Training epoch: 9\n","Training loss per 100 training steps: 0.016240205615758896\n","Training loss per 100 training steps: 0.005500178368754067\n","Training loss epoch: 0.004406187649644715\n","Training accuracy epoch: 0.9985995859584798\n","Validating model...\n","Validation Loss: 0.016938190355653034\n","Validation Accuracy: 0.9964531142097469\n","Training epoch: 10\n","Training loss per 100 training steps: 0.0005877986550331116\n","Training loss per 100 training steps: 0.0018603334821530705\n","Training loss epoch: 0.002127996473372315\n","Training accuracy epoch: 0.999342406617916\n","Validating model...\n","Validation Loss: 0.016247496441619227\n","Validation Accuracy: 0.9960481493414006\n","Training epoch: 11\n","Patience limit reached\n","Training duration: 43.56329358333326 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.012486208623158745\n","Validation Accuracy: 0.9961022018544949\n","Validation duration: 0.22057558333338723 minutes\n","F1-score (test): 97.9%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.99      0.98      1238\n","\n","   micro avg       0.97      0.99      0.98      1238\n","   macro avg       0.97      0.99      0.98      1238\n","weighted avg       0.97      0.99      0.98      1238\n","\n","!!!!!! Starting model number 6 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 2726\n","Points in y_train after augmentation: 2726\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.1206191778182983\n","Training loss per 100 training steps: 0.08411673450897826\n","Training loss epoch: 0.05787661092829678\n","Training accuracy epoch: 0.9808200516137163\n","Validating model...\n","Validation Loss: 0.01417273620609194\n","Validation Accuracy: 0.9958272035460863\n","Training epoch: 2\n","Training loss per 100 training steps: 0.012458531185984612\n","Training loss per 100 training steps: 0.012960998205431175\n","Training loss epoch: 0.012130679787349021\n","Training accuracy epoch: 0.9964638089268208\n","Validating model...\n","Validation Loss: 0.012417818602573658\n","Validation Accuracy: 0.9963192533901041\n","Training epoch: 3\n","Training loss per 100 training steps: 0.004489076789468527\n","Training loss per 100 training steps: 0.010049421072817675\n","Training loss epoch: 0.00878344458096922\n","Training accuracy epoch: 0.9974770410847822\n","Validating model...\n","Validation Loss: 0.009449460625460017\n","Validation Accuracy: 0.9975572925811298\n","Training epoch: 4\n","Training loss per 100 training steps: 0.006276851985603571\n","Training loss per 100 training steps: 0.005392692571086348\n","Training loss epoch: 0.005024296099834733\n","Training accuracy epoch: 0.9984489602444528\n","Validating model...\n","Validation Loss: 0.011634156823198455\n","Validation Accuracy: 0.9972927590922482\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0017126337625086308\n","Training loss per 100 training steps: 0.0033414386003047672\n","Training loss epoch: 0.004392283953224548\n","Training accuracy epoch: 0.9987653498822257\n","Validating model...\n","Validation Loss: 0.011140269649331458\n","Validation Accuracy: 0.9976185154520542\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0008435747004114091\n","Training loss per 100 training steps: 0.003049642488399018\n","Training loss epoch: 0.0036307244963024207\n","Training accuracy epoch: 0.9989418398032961\n","Validating model...\n","Validation Loss: 0.0104398353041255\n","Validation Accuracy: 0.9980132899015572\n","Training epoch: 7\n","Training loss per 100 training steps: 0.00027105759363621473\n","Training loss per 100 training steps: 0.006278938604034668\n","Training loss epoch: 0.006034319266988024\n","Training accuracy epoch: 0.9982984192977636\n","Validating model...\n","Validation Loss: 0.013320235497390275\n","Validation Accuracy: 0.99664971816961\n","Training epoch: 8\n","Training loss per 100 training steps: 0.011068936437368393\n","Training loss per 100 training steps: 0.004891432351190689\n","Training loss epoch: 0.004288867669798194\n","Training accuracy epoch: 0.9986591772348531\n","Validating model...\n","Validation Loss: 0.0163266492412991\n","Validation Accuracy: 0.9966907397812406\n","Training epoch: 9\n","Patience limit reached\n","Training duration: 34.83779499999994 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.014284608068313295\n","Validation Accuracy: 0.9959875218231247\n","Validation duration: 0.22000518333334185 minutes\n","F1-score (test): 97.8%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.99      0.98      1238\n","\n","   micro avg       0.97      0.99      0.98      1238\n","   macro avg       0.97      0.99      0.98      1238\n","weighted avg       0.97      0.99      0.98      1238\n","\n","!!!!!! Starting model number 7 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 2726\n","Points in y_train after augmentation: 2726\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.0166269540786743\n","Training loss per 100 training steps: 0.08597683858605895\n","Training loss epoch: 0.05875331990023236\n","Training accuracy epoch: 0.9819305958309203\n","Validating model...\n","Validation Loss: 0.012336959995861565\n","Validation Accuracy: 0.9963193284351219\n","Training epoch: 2\n","Training loss per 100 training steps: 0.02067367546260357\n","Training loss per 100 training steps: 0.012341887163376381\n","Training loss epoch: 0.012690773594590742\n","Training accuracy epoch: 0.9962470065685806\n","Validating model...\n","Validation Loss: 0.014226434430817054\n","Validation Accuracy: 0.995648629219861\n","Training epoch: 3\n","Training loss per 100 training steps: 0.006468061823397875\n","Training loss per 100 training steps: 0.009154395433719095\n","Training loss epoch: 0.008555110885383159\n","Training accuracy epoch: 0.9975577017909897\n","Validating model...\n","Validation Loss: 0.009654381611090642\n","Validation Accuracy: 0.9970888980807041\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0028226610738784075\n","Training loss per 100 training steps: 0.006838134269513614\n","Training loss epoch: 0.005728303301808484\n","Training accuracy epoch: 0.998314708551659\n","Validating model...\n","Validation Loss: 0.01046622095305966\n","Validation Accuracy: 0.9973214971501156\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0006327818264253438\n","Training loss per 100 training steps: 0.004196307762228598\n","Training loss epoch: 0.0048006068695062905\n","Training accuracy epoch: 0.9984720149274374\n","Validating model...\n","Validation Loss: 0.009885458465716857\n","Validation Accuracy: 0.9978705811499774\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0005989503697492182\n","Training loss per 100 training steps: 0.0035151198526814412\n","Training loss epoch: 0.003636874185843742\n","Training accuracy epoch: 0.99883974783796\n","Validating model...\n","Validation Loss: 0.012096259564194562\n","Validation Accuracy: 0.9972874393882372\n","Training epoch: 7\n","Training loss per 100 training steps: 0.00020128017058596015\n","Training loss per 100 training steps: 0.0026721400524302857\n","Training loss epoch: 0.0033909549084982196\n","Training accuracy epoch: 0.9989621011664076\n","Validating model...\n","Validation Loss: 0.01771173886594451\n","Validation Accuracy: 0.9961440748690397\n","Training epoch: 8\n","Training loss per 100 training steps: 0.0017054222989827394\n","Training loss per 100 training steps: 0.004658296196055852\n","Training loss epoch: 0.004518827147817931\n","Training accuracy epoch: 0.9986568709715157\n","Validating model...\n","Validation Loss: 0.012459589901222248\n","Validation Accuracy: 0.9965576097451114\n","Training epoch: 9\n","Patience limit reached\n","Training duration: 34.8039375166667 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.014189792488953875\n","Validation Accuracy: 0.9963225310492727\n","Validation duration: 0.22215326666664623 minutes\n","F1-score (test): 97.9%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.99      0.98      1238\n","\n","   micro avg       0.97      0.99      0.98      1238\n","   macro avg       0.97      0.99      0.98      1238\n","weighted avg       0.97      0.99      0.98      1238\n","\n","!!!!!! Starting model number 8 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 2726\n","Points in y_train after augmentation: 2726\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.185909390449524\n","Training loss per 100 training steps: 0.07744741420916254\n","Training loss epoch: 0.05399826528607971\n","Training accuracy epoch: 0.9818713957795524\n","Validating model...\n","Validation Loss: 0.017496485817467884\n","Validation Accuracy: 0.9953187239215252\n","Training epoch: 2\n","Training loss per 100 training steps: 0.029128538444638252\n","Training loss per 100 training steps: 0.01192902924555197\n","Training loss epoch: 0.010933922671465127\n","Training accuracy epoch: 0.9967755030184808\n","Validating model...\n","Validation Loss: 0.018883752324091757\n","Validation Accuracy: 0.9946155502463241\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04158756136894226\n","Training loss per 100 training steps: 0.007083558665339531\n","Training loss epoch: 0.006895589037173379\n","Training accuracy epoch: 0.9979984655232532\n","Validating model...\n","Validation Loss: 0.03716286777662823\n","Validation Accuracy: 0.9922912483839325\n","Training epoch: 4\n","Training loss per 100 training steps: 0.003857705742120743\n","Training loss per 100 training steps: 0.007572249279156936\n","Training loss epoch: 0.006685584942689057\n","Training accuracy epoch: 0.9980203227265024\n","Validating model...\n","Validation Loss: 0.028972920901391523\n","Validation Accuracy: 0.9916752546113943\n","Training epoch: 5\n","Training loss per 100 training steps: 0.009397375397384167\n","Training loss per 100 training steps: 0.00523812293869185\n","Training loss epoch: 0.00538628146240259\n","Training accuracy epoch: 0.9983920817635953\n","Validating model...\n","Validation Loss: 0.02321458794453758\n","Validation Accuracy: 0.9945913632724052\n","Training epoch: 6\n","Training loss per 100 training steps: 0.008219125680625439\n","Training loss per 100 training steps: 0.003226032806214609\n","Training loss epoch: 0.0035994793502008\n","Training accuracy epoch: 0.9988906690213011\n","Validating model...\n","Validation Loss: 0.011719015701341309\n","Validation Accuracy: 0.9972644726096791\n","Training epoch: 7\n","Training loss per 100 training steps: 0.00016169640002772212\n","Training loss per 100 training steps: 0.003420131302774091\n","Training loss epoch: 0.003990097954880843\n","Training accuracy epoch: 0.9989654512578662\n","Validating model...\n","Validation Loss: 0.011966550177367892\n","Validation Accuracy: 0.9973746548587743\n","Training epoch: 8\n","Training loss per 100 training steps: 0.0019212256884202361\n","Training loss per 100 training steps: 0.003794111460989046\n","Training loss epoch: 0.0036276540054690515\n","Training accuracy epoch: 0.9989854921819065\n","Validating model...\n","Validation Loss: 0.011170383658844955\n","Validation Accuracy: 0.9971221197112062\n","Training epoch: 9\n","Training loss per 100 training steps: 0.0006583901704289019\n","Training loss per 100 training steps: 0.0025750361414658514\n","Training loss epoch: 0.0027380835734497028\n","Training accuracy epoch: 0.9991646016504884\n","Validating model...\n","Validation Loss: 0.012961345444117407\n","Validation Accuracy: 0.996900348625382\n","Training epoch: 10\n","Training loss per 100 training steps: 0.0007099126814864576\n","Training loss per 100 training steps: 0.002204513643008984\n","Training loss epoch: 0.0024045379314560048\n","Training accuracy epoch: 0.9992751521002973\n","Validating model...\n","Validation Loss: 0.02495876867344902\n","Validation Accuracy: 0.9944137370338465\n","Training epoch: 11\n","Training loss per 100 training steps: 0.00026968319434672594\n","Training loss per 100 training steps: 0.001277730562518141\n","Training loss epoch: 0.001635123081249151\n","Training accuracy epoch: 0.9994731318506025\n","Validating model...\n","Validation Loss: 0.019997443996890935\n","Validation Accuracy: 0.9960288047452033\n","Training epoch: 12\n","Training loss per 100 training steps: 0.0006092475377954543\n","Training loss per 100 training steps: 0.00238495983404112\n","Training loss epoch: 0.0019288312401915275\n","Training accuracy epoch: 0.9994234749467638\n","Validating model...\n","Validation Loss: 0.016492478969190587\n","Validation Accuracy: 0.9967950022543445\n","Training epoch: 13\n","Training loss per 100 training steps: 0.0049968296661973\n","Training loss per 100 training steps: 0.0012493698828116562\n","Training loss epoch: 0.0020046606152486915\n","Training accuracy epoch: 0.999406810928057\n","Validating model...\n","Validation Loss: 0.011928965910469526\n","Validation Accuracy: 0.9976487718658718\n","Training epoch: 14\n","Patience limit reached\n","Training duration: 56.53150319999998 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.013068227814073907\n","Validation Accuracy: 0.9959671121116038\n","Validation duration: 0.22006055000007715 minutes\n","F1-score (test): 97.3%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.96      0.98      0.97      1238\n","\n","   micro avg       0.96      0.98      0.97      1238\n","   macro avg       0.96      0.98      0.97      1238\n","weighted avg       0.96      0.98      0.97      1238\n","\n","!!!!!! Starting model number 9 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 2726\n","Points in y_train after augmentation: 2726\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.1050846576690674\n","Training loss per 100 training steps: 0.07825641169922777\n","Training loss epoch: 0.05490655448609059\n","Training accuracy epoch: 0.9820652988400618\n","Validating model...\n","Validation Loss: 0.015482853133497494\n","Validation Accuracy: 0.9949060384240963\n","Training epoch: 2\n","Training loss per 100 training steps: 0.005680826026946306\n","Training loss per 100 training steps: 0.011729774641052884\n","Training loss epoch: 0.01153493307194569\n","Training accuracy epoch: 0.9965406121925893\n","Validating model...\n","Validation Loss: 0.015386709657572542\n","Validation Accuracy: 0.9952362516899733\n","Training epoch: 3\n","Training loss per 100 training steps: 0.005903121083974838\n","Training loss per 100 training steps: 0.0061258167287191875\n","Training loss epoch: 0.007367313926125882\n","Training accuracy epoch: 0.9979422874868435\n","Validating model...\n","Validation Loss: 0.012511301598957894\n","Validation Accuracy: 0.9966436975913991\n","Training epoch: 4\n","Training loss per 100 training steps: 0.005597100593149662\n","Training loss per 100 training steps: 0.005638463808786087\n","Stopping epoch...\n","Training loss epoch: 0.005638463808786087\n","Training accuracy epoch: 0.9885718730654114\n","Validating model...\n","Validation Loss: 0.014794810094393878\n","Validation Accuracy: 0.9964025588178517\n","Training epoch: 5\n","Training loss per 100 training steps: 0.017590418457984924\n","Training loss per 100 training steps: 0.006092455793670056\n","Training loss epoch: 0.00561262455461506\n","Training accuracy epoch: 0.9983856567291531\n","Validating model...\n","Validation Loss: 0.010727368956958387\n","Validation Accuracy: 0.997206872422001\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0035221546422690153\n","Training loss per 100 training steps: 0.00615510804547541\n","Training loss epoch: 0.006572420587739362\n","Training accuracy epoch: 0.998165741800745\n","Validating model...\n","Validation Loss: 0.010107272235299683\n","Validation Accuracy: 0.9976295731196181\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0004785943601746112\n","Training loss per 100 training steps: 0.0035648889129919156\n","Training loss epoch: 0.004282166714264674\n","Training accuracy epoch: 0.9988240757488066\n","Validating model...\n","Validation Loss: 0.011435406716676274\n","Validation Accuracy: 0.9975635787201628\n","Training epoch: 8\n","Training loss per 100 training steps: 0.004806252662092447\n","Training loss per 100 training steps: 0.004389484040525576\n","Training loss epoch: 0.004207650925043347\n","Training accuracy epoch: 0.9987497230314508\n","Validating model...\n","Validation Loss: 0.012995702200160372\n","Validation Accuracy: 0.9966787613039683\n","Training epoch: 9\n","Training loss per 100 training steps: 0.0014443246182054281\n","Training loss per 100 training steps: 0.0025993911376554924\n","Training loss epoch: 0.0026082095296659277\n","Training accuracy epoch: 0.9992284207991396\n","Validating model...\n","Validation Loss: 0.009241182947464819\n","Validation Accuracy: 0.9975944019947625\n","Training epoch: 10\n","Training loss per 100 training steps: 0.0010045684175565839\n","Training loss per 100 training steps: 0.0015214043467332687\n","Training loss epoch: 0.0018125933034242368\n","Training accuracy epoch: 0.9994357962411293\n","Validating model...\n","Validation Loss: 0.014488729262666311\n","Validation Accuracy: 0.9968671542079862\n","Training epoch: 11\n","Training loss per 100 training steps: 0.00016289518680423498\n","Training loss per 100 training steps: 0.0018843700037347061\n","Training loss epoch: 0.002313973884220264\n","Training accuracy epoch: 0.9993062602398799\n","Validating model...\n","Validation Loss: 0.017055318452288963\n","Validation Accuracy: 0.9963978418645286\n","Training epoch: 12\n","Training loss per 100 training steps: 0.015023604035377502\n","Training loss per 100 training steps: 0.0027332955396919753\n","Training loss epoch: 0.002723964851037109\n","Training accuracy epoch: 0.9992773493081466\n","Validating model...\n","Validation Loss: 0.012890452888747123\n","Validation Accuracy: 0.997462573431694\n","Training epoch: 13\n","Training loss per 100 training steps: 0.0009451599325984716\n","Training loss per 100 training steps: 0.006982311602012775\n","Training loss epoch: 0.00644402265270773\n","Training accuracy epoch: 0.9983510003948535\n","Validating model...\n","Validation Loss: 0.015203345198685946\n","Validation Accuracy: 0.9967791309372565\n","Training epoch: 14\n","Training loss per 100 training steps: 0.0029116373043507338\n","Training loss per 100 training steps: 0.0033618766694308933\n","Training loss epoch: 0.0030196242207441376\n","Training accuracy epoch: 0.9990730577142425\n","Validating model...\n","Validation Loss: 0.011631148887491213\n","Validation Accuracy: 0.9972467174474525\n","Training epoch: 15\n","Patience limit reached\n","Training duration: 59.28174521666673 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.013994202030365463\n","Validation Accuracy: 0.9968760182372671\n","Validation duration: 0.22040040000004713 minutes\n","F1-score (test): 98.2%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.98      0.99      0.98      1238\n","\n","   micro avg       0.98      0.99      0.98      1238\n","   macro avg       0.98      0.99      0.98      1238\n","weighted avg       0.98      0.99      0.98      1238\n","\n","!!!!!! Starting model number 10 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 2726\n","Points in y_train after augmentation: 2726\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.1742044687271118\n","Training loss per 100 training steps: 0.08001080809142624\n","Training loss epoch: 0.05433486789200803\n","Training accuracy epoch: 0.9817210651448307\n","Validating model...\n","Validation Loss: 0.012962547020011005\n","Validation Accuracy: 0.9963855809912571\n","Training epoch: 2\n","Training loss per 100 training steps: 0.004071371629834175\n","Training loss per 100 training steps: 0.011288750053401853\n","Training loss epoch: 0.010356402608745714\n","Training accuracy epoch: 0.9971132739629257\n","Validating model...\n","Validation Loss: 0.022029498126357794\n","Validation Accuracy: 0.9942366903473285\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0011002221144735813\n","Training loss per 100 training steps: 0.006984295543354687\n","Training loss epoch: 0.0067587100751105725\n","Training accuracy epoch: 0.9979805571919227\n","Validating model...\n","Validation Loss: 0.009711591273246865\n","Validation Accuracy: 0.9975290084986612\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0008598808199167252\n","Training loss per 100 training steps: 0.005780771466624453\n","Training loss epoch: 0.0060593320942846024\n","Training accuracy epoch: 0.9982257051767693\n","Validating model...\n","Validation Loss: 0.013041538235397422\n","Validation Accuracy: 0.9969303122036166\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0025535249151289463\n","Training loss per 100 training steps: 0.005027467373119999\n","Training loss epoch: 0.004645157732121913\n","Training accuracy epoch: 0.9984633888413291\n","Validating model...\n","Validation Loss: 0.010759860290341922\n","Validation Accuracy: 0.9970548150710443\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00075510487658903\n","Training loss per 100 training steps: 0.003390502710947721\n","Training loss epoch: 0.003589073938371379\n","Training accuracy epoch: 0.9990015461464723\n","Validating model...\n","Validation Loss: 0.011521940304235267\n","Validation Accuracy: 0.9971664709115676\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0027384208515286446\n","Training loss per 100 training steps: 0.0049619433508395205\n","Training loss epoch: 0.004588605389860187\n","Training accuracy epoch: 0.9987189368581983\n","Validating model...\n","Validation Loss: 0.011376305014415439\n","Validation Accuracy: 0.9976166405774025\n","Training epoch: 8\n","Training loss per 100 training steps: 0.00047963866381905973\n","Training loss per 100 training steps: 0.004292718105860709\n","Training loss epoch: 0.0055057447324016765\n","Training accuracy epoch: 0.9983674406634062\n","Validating model...\n","Validation Loss: 0.009394420620602821\n","Validation Accuracy: 0.9979411495648604\n","Training epoch: 9\n","Training loss per 100 training steps: 0.010644033551216125\n","Training loss per 100 training steps: 0.005324312244135066\n","Training loss epoch: 0.004732352929436248\n","Training accuracy epoch: 0.9986398536668405\n","Validating model...\n","Validation Loss: 0.011500199427765827\n","Validation Accuracy: 0.9972725645369155\n","Training epoch: 10\n","Training loss per 100 training steps: 0.0014155699172988534\n","Training loss per 100 training steps: 0.002650637524536728\n","Training loss epoch: 0.002825678411799031\n","Training accuracy epoch: 0.999206054946101\n","Validating model...\n","Validation Loss: 0.010646969484306672\n","Validation Accuracy: 0.9977688347962103\n","Training epoch: 11\n","Training loss per 100 training steps: 0.0001410040131304413\n","Training loss per 100 training steps: 0.0019211644631459512\n","Training loss epoch: 0.0020963076757551688\n","Training accuracy epoch: 0.9993758509625592\n","Validating model...\n","Validation Loss: 0.025332013095196868\n","Validation Accuracy: 0.9940502950767396\n","Training epoch: 12\n","Training loss per 100 training steps: 0.0007146701100282371\n","Training loss per 100 training steps: 0.003280750203587802\n","Training loss epoch: 0.003491874725470382\n","Training accuracy epoch: 0.9990406020869247\n","Validating model...\n","Validation Loss: 0.011947496304163082\n","Validation Accuracy: 0.9971001489994745\n","Training epoch: 13\n","Training loss per 100 training steps: 0.00046700460370630026\n","Training loss per 100 training steps: 0.001941537709396948\n","Training loss epoch: 0.0018677474396759086\n","Training accuracy epoch: 0.9994008529971656\n","Validating model...\n","Validation Loss: 0.013807185327528887\n","Validation Accuracy: 0.9969499273060487\n","Training epoch: 14\n","Patience limit reached\n","Training duration: 56.49673558333331 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.016735703730470657\n","Validation Accuracy: 0.9964642681851498\n","Validation duration: 0.2216525499999989 minutes\n","F1-score (test): 97.1%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.96      0.98      0.97      1238\n","\n","   micro avg       0.96      0.98      0.97      1238\n","   macro avg       0.96      0.98      0.97      1238\n","weighted avg       0.96      0.98      0.97      1238\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0.5\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"jdO4m5O4Hlo3"},{"cell_type":"code","execution_count":null,"metadata":{"id":"oKNxFPucHn_R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665787199867,"user_tz":240,"elapsed":30111922,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}},"outputId":"26a5f69d-16a5-4982-d594-e57c71987253"},"outputs":[{"output_type":"stream","name":"stdout","text":["!!!!!! Augmented Percentage 75.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 3180\n","Points in y_train after augmentation: 3180\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.1952024698257446\n","Training loss per 100 training steps: 0.08477844408768608\n","Training loss epoch: 0.05302254419689577\n","Training accuracy epoch: 0.9820578021944811\n","Validating model...\n","Validation Loss: 0.01292804249429277\n","Validation Accuracy: 0.996622408545627\n","Training epoch: 2\n","Training loss per 100 training steps: 0.005022761877626181\n","Training loss per 100 training steps: 0.012068973547009068\n","Training loss epoch: 0.011869908868857009\n","Training accuracy epoch: 0.9966323043027036\n","Validating model...\n","Validation Loss: 0.012546036822078306\n","Validation Accuracy: 0.9966090490578241\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0028199995867908\n","Training loss per 100 training steps: 0.007118918854019393\n","Training loss epoch: 0.007031120238217277\n","Training accuracy epoch: 0.997907795262988\n","Validating model...\n","Validation Loss: 0.014229354079967985\n","Validation Accuracy: 0.9961342391931486\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0029597689863294363\n","Training loss per 100 training steps: 0.005595006480049987\n","Training loss epoch: 0.005378512470970099\n","Training accuracy epoch: 0.9983200071422753\n","Validating model...\n","Validation Loss: 0.01596472225650186\n","Validation Accuracy: 0.9963444428936851\n","Training epoch: 5\n","Training loss per 100 training steps: 0.005179692059755325\n","Training loss per 100 training steps: 0.0035487835050276987\n","Training loss epoch: 0.004188772594195266\n","Training accuracy epoch: 0.9987934692734906\n","Validating model...\n","Validation Loss: 0.021741057465468266\n","Validation Accuracy: 0.9955497984909275\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0025783414021134377\n","Training loss per 100 training steps: 0.004251780359409887\n","Training loss epoch: 0.004298021852534004\n","Training accuracy epoch: 0.9986157011386996\n","Validating model...\n","Validation Loss: 0.0152862978927823\n","Validation Accuracy: 0.9966774964789875\n","Training epoch: 7\n","Training loss per 100 training steps: 0.019552212208509445\n","Training loss per 100 training steps: 0.004439983362047288\n","Training loss epoch: 0.003487007244162194\n","Training accuracy epoch: 0.9989374547866144\n","Validating model...\n","Validation Loss: 0.01551381383268606\n","Validation Accuracy: 0.9970466154518605\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 35.20631201666668 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.016252614540765837\n","Validation Accuracy: 0.9951132561121705\n","Validation duration: 0.22038086666664944 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 97.4%\n","              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.98      0.97      1238\n","\n","   micro avg       0.97      0.98      0.97      1238\n","   macro avg       0.97      0.98      0.97      1238\n","weighted avg       0.97      0.98      0.97      1238\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 3180\n","Points in y_train after augmentation: 3180\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.027701735496521\n","Training loss per 100 training steps: 0.07839699642327015\n","Training loss epoch: 0.05007058520211684\n","Training accuracy epoch: 0.9839001613676529\n","Validating model...\n","Validation Loss: 0.011469153022127492\n","Validation Accuracy: 0.9966368460346947\n","Training epoch: 2\n","Training loss per 100 training steps: 0.01464808452874422\n","Training loss per 100 training steps: 0.012221182017624009\n","Training loss epoch: 0.012689933358649513\n","Training accuracy epoch: 0.9960864646883479\n","Validating model...\n","Validation Loss: 0.011280124562160512\n","Validation Accuracy: 0.9970574902640288\n","Training epoch: 3\n","Training loss per 100 training steps: 0.009129664860665798\n","Training loss per 100 training steps: 0.006301514375009712\n","Training loss epoch: 0.006532978770748979\n","Training accuracy epoch: 0.9980582856009166\n","Validating model...\n","Validation Loss: 0.019937582567460293\n","Validation Accuracy: 0.9944652245249146\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03001655824482441\n","Training loss per 100 training steps: 0.005610269288178579\n","Training loss epoch: 0.005398034341513394\n","Training accuracy epoch: 0.9984844717455239\n","Validating model...\n","Validation Loss: 0.009003605951875215\n","Validation Accuracy: 0.9976627744261335\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0035418125335127115\n","Training loss per 100 training steps: 0.003561524103601961\n","Stopping epoch...\n","Training loss epoch: 0.003561524103601961\n","Training accuracy epoch: 0.9889714304851955\n","Validating model...\n","Validation Loss: 0.013794946345678042\n","Validation Accuracy: 0.9968025452913355\n","Training epoch: 6\n","Training loss per 100 training steps: 0.001008822349831462\n","Training loss per 100 training steps: 0.0032967839862328334\n","Training loss epoch: 0.0034932928267985127\n","Training accuracy epoch: 0.9989222153262285\n","Validating model...\n","Validation Loss: 0.01119228188569347\n","Validation Accuracy: 0.9968812342329287\n","Training epoch: 7\n","Training loss per 100 training steps: 0.01103061344474554\n","Training loss per 100 training steps: 0.0041932692235631935\n","Training loss epoch: 0.004347555239337681\n","Training accuracy epoch: 0.9986624067332442\n","Validating model...\n","Validation Loss: 0.011977589290143528\n","Validation Accuracy: 0.9971132130761815\n","Training epoch: 8\n","Training loss per 100 training steps: 0.0035414432641118765\n","Training loss per 100 training steps: 0.005875667066533478\n","Training loss epoch: 0.006454197675338946\n","Training accuracy epoch: 0.9981030013940542\n","Validating model...\n","Validation Loss: 0.012971973758664847\n","Validation Accuracy: 0.9975925437220502\n","Training epoch: 9\n","Training loss per 100 training steps: 0.004532713908702135\n","Training loss per 100 training steps: 0.0017238912094957287\n","Training loss epoch: 0.003594809047697608\n","Training accuracy epoch: 0.9989844440942327\n","Validating model...\n","Validation Loss: 0.013979641907748632\n","Validation Accuracy: 0.9965301958039708\n","Training epoch: 10\n","Patience limit reached\n","Training duration: 42.9586517333332 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.011620478541772172\n","Validation Accuracy: 0.996143178729148\n","Validation duration: 0.21945909999994911 minutes\n","F1-score (test): 97.7%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.99      0.98      1238\n","\n","   micro avg       0.97      0.99      0.98      1238\n","   macro avg       0.97      0.99      0.98      1238\n","weighted avg       0.97      0.99      0.98      1238\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 3180\n","Points in y_train after augmentation: 3180\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.0264118909835815\n","Training loss per 100 training steps: 0.09603931219086494\n","Training loss epoch: 0.05823180201491481\n","Training accuracy epoch: 0.9817527914318298\n","Validating model...\n","Validation Loss: 0.017946756643054652\n","Validation Accuracy: 0.9953405002273515\n","Training epoch: 2\n","Training loss per 100 training steps: 0.00508110411465168\n","Training loss per 100 training steps: 0.01050687938845615\n","Training loss epoch: 0.011195726174950113\n","Training accuracy epoch: 0.9966929577772672\n","Validating model...\n","Validation Loss: 0.012105836563499733\n","Validation Accuracy: 0.9967511252845288\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0011694419663399458\n","Training loss per 100 training steps: 0.0053008965969818765\n","Training loss epoch: 0.006391236543200264\n","Training accuracy epoch: 0.9980888853494975\n","Validating model...\n","Validation Loss: 0.011791433415575219\n","Validation Accuracy: 0.9965791845523905\n","Training epoch: 4\n","Training loss per 100 training steps: 0.010661888867616653\n","Training loss per 100 training steps: 0.008999019219208104\n","Training loss epoch: 0.007100393534807638\n","Training accuracy epoch: 0.9978463217589879\n","Validating model...\n","Validation Loss: 0.011419972809172967\n","Validation Accuracy: 0.9973285314616719\n","Training epoch: 5\n","Training loss per 100 training steps: 0.000976990326307714\n","Training loss per 100 training steps: 0.004355973363387177\n","Training loss epoch: 0.00564333749766843\n","Training accuracy epoch: 0.9982802126537275\n","Validating model...\n","Validation Loss: 0.012227420085331514\n","Validation Accuracy: 0.9966421097586688\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0029214138630777597\n","Training loss per 100 training steps: 0.0045455121685921375\n","Training loss epoch: 0.0038959161786408744\n","Training accuracy epoch: 0.9987076043916856\n","Validating model...\n","Validation Loss: 0.014411213816077049\n","Validation Accuracy: 0.9970562555078537\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0017968103056773543\n","Training loss per 100 training steps: 0.0036941255563968044\n","Training loss epoch: 0.0033416514303628822\n","Training accuracy epoch: 0.9990246146236507\n","Validating model...\n","Validation Loss: 0.010278978097111187\n","Validation Accuracy: 0.9973678679829838\n","Training epoch: 8\n","Training loss per 100 training steps: 0.003075122367590666\n","Training loss per 100 training steps: 0.00340594789822987\n","Training loss epoch: 0.004599808731700478\n","Training accuracy epoch: 0.9986950546876355\n","Validating model...\n","Validation Loss: 0.017760822939419\n","Validation Accuracy: 0.9959256761246764\n","Training epoch: 9\n","Training loss per 100 training steps: 0.00047482780064456165\n","Training loss per 100 training steps: 0.004611237002187985\n","Training loss epoch: 0.003660705846487328\n","Training accuracy epoch: 0.9988785592197708\n","Validating model...\n","Validation Loss: 0.012596616751709786\n","Validation Accuracy: 0.9974654818062945\n","Training epoch: 10\n","Training loss per 100 training steps: 0.003073387546464801\n","Training loss per 100 training steps: 0.0015534764355438124\n","Training loss epoch: 0.002349839519168807\n","Training accuracy epoch: 0.9992748058032551\n","Validating model...\n","Validation Loss: 0.014555451674910035\n","Validation Accuracy: 0.9972921400454398\n","Training epoch: 11\n","Training loss per 100 training steps: 0.0017770868726074696\n","Training loss per 100 training steps: 0.002421534891669076\n","Training loss epoch: 0.0022328603950315376\n","Training accuracy epoch: 0.9993513108339056\n","Validating model...\n","Validation Loss: 0.017596681729282\n","Validation Accuracy: 0.9970890013687833\n","Training epoch: 12\n","Training loss per 100 training steps: 0.002409749198704958\n","Training loss per 100 training steps: 0.002529315920285869\n","Training loss epoch: 0.002124549821659018\n","Training accuracy epoch: 0.9993538468226635\n","Validating model...\n","Validation Loss: 0.015474025646220807\n","Validation Accuracy: 0.9974204192029084\n","Training epoch: 13\n","Patience limit reached\n","Training duration: 60.58116998333329 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.009481165448960382\n","Validation Accuracy: 0.9976581871859574\n","Validation duration: 0.22235208333343812 minutes\n","F1-score (test): 98.4%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.98      0.99      0.98      1238\n","\n","   micro avg       0.98      0.99      0.98      1238\n","   macro avg       0.98      0.99      0.98      1238\n","weighted avg       0.98      0.99      0.98      1238\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 3180\n","Points in y_train after augmentation: 3180\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.1358158588409424\n","Training loss per 100 training steps: 0.08585530385089171\n","Training loss epoch: 0.05323034152622573\n","Training accuracy epoch: 0.9821078801176091\n","Validating model...\n","Validation Loss: 0.013727096912805877\n","Validation Accuracy: 0.996842845918594\n","Training epoch: 2\n","Training loss per 100 training steps: 0.005200405139476061\n","Training loss per 100 training steps: 0.009143653459441249\n","Training loss epoch: 0.009189984194311926\n","Training accuracy epoch: 0.9972215540046908\n","Validating model...\n","Validation Loss: 0.012994078096068864\n","Validation Accuracy: 0.996671768499944\n","Training epoch: 3\n","Training loss per 100 training steps: 0.005704366136342287\n","Training loss per 100 training steps: 0.005913848618430427\n","Training loss epoch: 0.007118169598114073\n","Training accuracy epoch: 0.997745275221308\n","Validating model...\n","Validation Loss: 0.010378814443746316\n","Validation Accuracy: 0.9969057796795072\n","Training epoch: 4\n","Training loss per 100 training steps: 0.00437774695456028\n","Training loss per 100 training steps: 0.004623738850874937\n","Training loss epoch: 0.004832520938084119\n","Training accuracy epoch: 0.9985147884118487\n","Validating model...\n","Validation Loss: 0.01722711159804714\n","Validation Accuracy: 0.9952720245442516\n","Training epoch: 5\n","Training loss per 100 training steps: 0.02111993543803692\n","Training loss per 100 training steps: 0.004479806526739261\n","Training loss epoch: 0.004084470560019555\n","Training accuracy epoch: 0.9986430213257239\n","Validating model...\n","Validation Loss: 0.010392590364755875\n","Validation Accuracy: 0.9976678616638444\n","Training epoch: 6\n","Training loss per 100 training steps: 0.006809642072767019\n","Training loss per 100 training steps: 0.0031014165983248346\n","Training loss epoch: 0.003390441047097615\n","Training accuracy epoch: 0.9989898124393228\n","Validating model...\n","Validation Loss: 0.012192021560275905\n","Validation Accuracy: 0.9972057158117131\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0006979057798162103\n","Training loss per 100 training steps: 0.004427288222575611\n","Training loss epoch: 0.004227653534925864\n","Training accuracy epoch: 0.9987360007961356\n","Validating model...\n","Validation Loss: 0.00989262871527379\n","Validation Accuracy: 0.9976058551087563\n","Training epoch: 8\n","Training loss per 100 training steps: 0.002763996599242091\n","Training loss per 100 training steps: 0.003496255964071877\n","Training loss epoch: 0.0029974810808491028\n","Training accuracy epoch: 0.9991305587246481\n","Validating model...\n","Validation Loss: 0.011729496545220692\n","Validation Accuracy: 0.997642211359803\n","Training epoch: 9\n","Training loss per 100 training steps: 0.0001231287169503048\n","Training loss per 100 training steps: 0.0018357553018708275\n","Training loss epoch: 0.0022208967320556665\n","Training accuracy epoch: 0.9992468269474422\n","Validating model...\n","Validation Loss: 0.016149719580599117\n","Validation Accuracy: 0.9971743193801349\n","Training epoch: 10\n","Training loss per 100 training steps: 0.001261914148926735\n","Training loss per 100 training steps: 0.0015503518672162634\n","Training loss epoch: 0.0015808588681621453\n","Training accuracy epoch: 0.999497428031312\n","Validating model...\n","Validation Loss: 0.017338335808181865\n","Validation Accuracy: 0.997250103565411\n","Training epoch: 11\n","Training loss per 100 training steps: 5.865325147169642e-05\n","Training loss per 100 training steps: 0.0025776010548761046\n","Training loss epoch: 0.0021704022283804774\n","Training accuracy epoch: 0.9992725086092024\n","Validating model...\n","Validation Loss: 0.01519619517802355\n","Validation Accuracy: 0.9973684792189695\n","Training epoch: 12\n","Training loss per 100 training steps: 0.004299519583582878\n","Training loss per 100 training steps: 0.004762460990172942\n","Training loss epoch: 0.004564049318009413\n","Training accuracy epoch: 0.9986623754407201\n","Validating model...\n","Validation Loss: 0.029198845604523307\n","Validation Accuracy: 0.994453245756448\n","Training epoch: 13\n","Patience limit reached\n","Training duration: 60.53503941666689 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.013092688715308517\n","Validation Accuracy: 0.9967043198584163\n","Validation duration: 0.22295108333346433 minutes\n","F1-score (test): 97.9%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.98      0.98      0.98      1238\n","\n","   micro avg       0.98      0.98      0.98      1238\n","   macro avg       0.98      0.98      0.98      1238\n","weighted avg       0.98      0.98      0.98      1238\n","\n","!!!!!! Starting model number 5 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 3180\n","Points in y_train after augmentation: 3180\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.197015404701233\n","Training loss per 100 training steps: 0.0872569739781689\n","Training loss epoch: 0.054533424779033314\n","Training accuracy epoch: 0.9813805554521134\n","Validating model...\n","Validation Loss: 0.015013500515903746\n","Validation Accuracy: 0.9956480068493725\n","Training epoch: 2\n","Training loss per 100 training steps: 0.008149374276399612\n","Training loss per 100 training steps: 0.009589110284993001\n","Training loss epoch: 0.009918822693093281\n","Training accuracy epoch: 0.9970607195541769\n","Validating model...\n","Validation Loss: 0.009498801821748549\n","Validation Accuracy: 0.9971411091025874\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0014259879244491458\n","Training loss per 100 training steps: 0.005006054004234732\n","Training loss epoch: 0.006252597126350434\n","Training accuracy epoch: 0.9980365207010244\n","Validating model...\n","Validation Loss: 0.009551517722900912\n","Validation Accuracy: 0.997186343428178\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0022244376596063375\n","Training loss per 100 training steps: 0.004733568027017334\n","Training loss epoch: 0.004446347349311047\n","Training accuracy epoch: 0.9987961718180014\n","Validating model...\n","Validation Loss: 0.010048969323092717\n","Validation Accuracy: 0.9974354761084501\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0005060119437985122\n","Training loss per 100 training steps: 0.0033555791776980004\n","Training loss epoch: 0.003258948438992752\n","Training accuracy epoch: 0.9989977143853274\n","Validating model...\n","Validation Loss: 0.01043008216635956\n","Validation Accuracy: 0.9974952959809326\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00022001986508257687\n","Training loss per 100 training steps: 0.0038389911303713937\n","Training loss epoch: 0.004323657429788786\n","Training accuracy epoch: 0.9986229200962163\n","Validating model...\n","Validation Loss: 0.00903342682951396\n","Validation Accuracy: 0.9973636644309832\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0051080468110740185\n","Training loss per 100 training steps: 0.003082630482786404\n","Training loss epoch: 0.0033113911684167258\n","Training accuracy epoch: 0.9990092986051553\n","Validating model...\n","Validation Loss: 0.009575715975231668\n","Validation Accuracy: 0.9977895058031062\n","Training epoch: 8\n","Training loss per 100 training steps: 0.007288389839231968\n","Training loss per 100 training steps: 0.0033435609238049347\n","Training loss epoch: 0.0035524446934481484\n","Training accuracy epoch: 0.9988715466574477\n","Validating model...\n","Validation Loss: 0.016381060440922045\n","Validation Accuracy: 0.996030417442894\n","Training epoch: 9\n","Training loss per 100 training steps: 0.010735281743109226\n","Training loss per 100 training steps: 0.004280397676549262\n","Training loss epoch: 0.0036990781383116227\n","Training accuracy epoch: 0.9988498293212037\n","Validating model...\n","Validation Loss: 0.012236459230518363\n","Validation Accuracy: 0.9973208882158194\n","Training epoch: 10\n","Training loss per 100 training steps: 0.0013970707077533007\n","Training loss per 100 training steps: 0.0024026602955873927\n","Training loss epoch: 0.0023375778065525795\n","Training accuracy epoch: 0.9993148514223683\n","Validating model...\n","Validation Loss: 0.009148950154970711\n","Validation Accuracy: 0.99805696874795\n","Training epoch: 11\n","Training loss per 100 training steps: 0.009045084938406944\n","Training loss per 100 training steps: 0.0023905919367847458\n","Training loss epoch: 0.002425689920898581\n","Training accuracy epoch: 0.9992948367941289\n","Validating model...\n","Validation Loss: 0.009774694312433158\n","Validation Accuracy: 0.9977097782725269\n","Training epoch: 12\n","Patience limit reached\n","Training duration: 55.5503787166667 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.016592256207028793\n","Validation Accuracy: 0.9956119579398678\n","Validation duration: 0.22077516666662025 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 97.3%\n","              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.98      0.97      1238\n","\n","   micro avg       0.97      0.98      0.97      1238\n","   macro avg       0.97      0.98      0.97      1238\n","weighted avg       0.97      0.98      0.97      1238\n","\n","!!!!!! Starting model number 6 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 3180\n","Points in y_train after augmentation: 3180\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.1715095043182373\n","Training loss per 100 training steps: 0.08412582677844359\n","Training loss epoch: 0.05194157331447168\n","Training accuracy epoch: 0.9822795938260726\n","Validating model...\n","Validation Loss: 0.010653694287785107\n","Validation Accuracy: 0.9967703760361833\n","Training epoch: 2\n","Training loss per 100 training steps: 0.009936646558344364\n","Training loss per 100 training steps: 0.012373988973069013\n","Training loss epoch: 0.010768232802332767\n","Training accuracy epoch: 0.9968922469905033\n","Validating model...\n","Validation Loss: 0.015685607183037235\n","Validation Accuracy: 0.9962542625794\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0011943710269406438\n","Training loss per 100 training steps: 0.0066091920952842855\n","Training loss epoch: 0.007188182341136113\n","Training accuracy epoch: 0.9977640460345188\n","Validating model...\n","Validation Loss: 0.019859151263344324\n","Validation Accuracy: 0.9960927788502856\n","Training epoch: 4\n","Training loss per 100 training steps: 0.007143672555685043\n","Training loss per 100 training steps: 0.0035896263660754697\n","Training loss epoch: 0.004624894437087342\n","Training accuracy epoch: 0.9986623013148686\n","Validating model...\n","Validation Loss: 0.010063951268204533\n","Validation Accuracy: 0.9978732797800459\n","Training epoch: 5\n","Training loss per 100 training steps: 0.005490396171808243\n","Training loss per 100 training steps: 0.004168740625546249\n","Training loss epoch: 0.006324437366162039\n","Training accuracy epoch: 0.9982449356602631\n","Validating model...\n","Validation Loss: 0.011605019275780901\n","Validation Accuracy: 0.9968554503224938\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00395039701834321\n","Training loss per 100 training steps: 0.0048635391016216434\n","Training loss epoch: 0.004652132795118591\n","Training accuracy epoch: 0.9986702557221636\n","Validating model...\n","Validation Loss: 0.01088874265579285\n","Validation Accuracy: 0.9975247739532029\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0004275006358511746\n","Training loss per 100 training steps: 0.0022849895061215035\n","Training loss epoch: 0.0029264498343992505\n","Training accuracy epoch: 0.9990916532959473\n","Validating model...\n","Validation Loss: 0.013580545301443809\n","Validation Accuracy: 0.9972311298603028\n","Training epoch: 8\n","Training loss per 100 training steps: 0.00011042119876947254\n","Training loss per 100 training steps: 0.003777648173955541\n","Training loss epoch: 0.0034115039932694526\n","Training accuracy epoch: 0.9989952874190092\n","Validating model...\n","Validation Loss: 0.013840665298717102\n","Validation Accuracy: 0.9973661064602665\n","Training epoch: 9\n","Training loss per 100 training steps: 0.00026083303964696825\n","Training loss per 100 training steps: 0.003121575887838268\n","Training loss epoch: 0.0028613655752328052\n","Training accuracy epoch: 0.9991316415115535\n","Validating model...\n","Validation Loss: 0.013390460289970395\n","Validation Accuracy: 0.9966372980239788\n","Training epoch: 10\n","Patience limit reached\n","Training duration: 45.41640356666685 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.013934644097995866\n","Validation Accuracy: 0.9972117841348004\n","Validation duration: 0.22317138333334394 minutes\n","F1-score (test): 98.0%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.99      0.98      1238\n","\n","   micro avg       0.97      0.99      0.98      1238\n","   macro avg       0.97      0.99      0.98      1238\n","weighted avg       0.97      0.99      0.98      1238\n","\n","!!!!!! Starting model number 7 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 3180\n","Points in y_train after augmentation: 3180\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.341079592704773\n","Training loss per 100 training steps: 0.11563754715209845\n","Training loss epoch: 0.06865731017060353\n","Training accuracy epoch: 0.9771776994962291\n","Validating model...\n","Validation Loss: 0.014922397643593805\n","Validation Accuracy: 0.994703370729891\n","Training epoch: 2\n","Training loss per 100 training steps: 0.009768908843398094\n","Training loss per 100 training steps: 0.010161852407601136\n","Training loss epoch: 0.010076765682964806\n","Training accuracy epoch: 0.9968890281448606\n","Validating model...\n","Validation Loss: 0.009637198839863274\n","Validation Accuracy: 0.9973698004777337\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04408099502325058\n","Training loss per 100 training steps: 0.006589561182426953\n","Training loss epoch: 0.006254518293013946\n","Training accuracy epoch: 0.9981419241326157\n","Validating model...\n","Validation Loss: 0.01056462035852573\n","Validation Accuracy: 0.9973615670718304\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0026573960203677416\n","Training loss per 100 training steps: 0.005371482084715038\n","Training loss epoch: 0.004817245061051255\n","Training accuracy epoch: 0.9984815657944168\n","Validating model...\n","Validation Loss: 0.011872924694866274\n","Validation Accuracy: 0.9962491519748162\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0011655319249257445\n","Training loss per 100 training steps: 0.005689092085634515\n","Training loss epoch: 0.005957564365805534\n","Training accuracy epoch: 0.9980643505231971\n","Validating model...\n","Validation Loss: 0.009856966264557005\n","Validation Accuracy: 0.9970241076335129\n","Training epoch: 6\n","Training loss per 100 training steps: 0.007693968713283539\n","Training loss per 100 training steps: 0.004128511228724291\n","Training loss epoch: 0.004044764078608024\n","Training accuracy epoch: 0.998798116132084\n","Validating model...\n","Validation Loss: 0.011962569039280339\n","Validation Accuracy: 0.9972993532628033\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0032552555203437805\n","Training loss per 100 training steps: 0.005328931620241936\n","Training loss epoch: 0.00482558748304865\n","Training accuracy epoch: 0.998564314347077\n","Validating model...\n","Validation Loss: 0.013213514739705022\n","Validation Accuracy: 0.9976339936760714\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 35.31906869999997 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.01492350731859915\n","Validation Accuracy: 0.9957820454266683\n","Validation duration: 0.21938035000008918 minutes\n","F1-score (test): 97.4%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.98      0.97      1238\n","\n","   micro avg       0.97      0.98      0.97      1238\n","   macro avg       0.97      0.98      0.97      1238\n","weighted avg       0.97      0.98      0.97      1238\n","\n","!!!!!! Starting model number 8 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 3180\n","Points in y_train after augmentation: 3180\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.3705042600631714\n","Training loss per 100 training steps: 0.0932201492590922\n","Training loss epoch: 0.05690624481347862\n","Training accuracy epoch: 0.9803696245348629\n","Validating model...\n","Validation Loss: 0.015304486572165928\n","Validation Accuracy: 0.994969489022641\n","Training epoch: 2\n","Training loss per 100 training steps: 0.007872332818806171\n","Training loss per 100 training steps: 0.010414012720448767\n","Training loss epoch: 0.011308878262108427\n","Training accuracy epoch: 0.9966378526910062\n","Validating model...\n","Validation Loss: 0.012393093616646226\n","Validation Accuracy: 0.9969054447349002\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0017618214478716254\n","Training loss per 100 training steps: 0.0070764029045280365\n","Training loss epoch: 0.007620447120616381\n","Training accuracy epoch: 0.997735249713229\n","Validating model...\n","Validation Loss: 0.010640985468247285\n","Validation Accuracy: 0.9967795870019367\n","Training epoch: 4\n","Training loss per 100 training steps: 0.008961644023656845\n","Training loss per 100 training steps: 0.006208414334912166\n","Training loss epoch: 0.00521984878652811\n","Training accuracy epoch: 0.9985243719652759\n","Validating model...\n","Validation Loss: 0.010634070494623822\n","Validation Accuracy: 0.9976857940890363\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0024844040162861347\n","Training loss per 100 training steps: 0.0041772552215814645\n","Training loss epoch: 0.004196786932221932\n","Training accuracy epoch: 0.9988064693786619\n","Validating model...\n","Validation Loss: 0.01223108223071211\n","Validation Accuracy: 0.9977813041653896\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0009301618556492031\n","Training loss per 100 training steps: 0.003955098801513783\n","Training loss epoch: 0.003682423261902178\n","Training accuracy epoch: 0.9988981041493814\n","Validating model...\n","Validation Loss: 0.012399044666554324\n","Validation Accuracy: 0.9977662968827588\n","Training epoch: 7\n","Training loss per 100 training steps: 0.003004704602062702\n","Training loss per 100 training steps: 0.004910413101909102\n","Training loss epoch: 0.006438825415121509\n","Training accuracy epoch: 0.9981035492668527\n","Validating model...\n","Validation Loss: 0.01801726633788175\n","Validation Accuracy: 0.996045507772452\n","Training epoch: 8\n","Training loss per 100 training steps: 0.02132168412208557\n","Training loss per 100 training steps: 0.004357419687030505\n","Training loss epoch: 0.004724360152364746\n","Training accuracy epoch: 0.9986678708621097\n","Validating model...\n","Validation Loss: 0.014583662057876132\n","Validation Accuracy: 0.9969723905010278\n","Training epoch: 9\n","Training loss per 100 training steps: 0.007279151119291782\n","Training loss per 100 training steps: 0.004354381767613928\n","Training loss epoch: 0.0035867829765128816\n","Training accuracy epoch: 0.9990007541335325\n","Validating model...\n","Validation Loss: 0.012777045059227107\n","Validation Accuracy: 0.9977174621617931\n","Training epoch: 10\n","Patience limit reached\n","Training duration: 45.39919363333344 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.012927322245862646\n","Validation Accuracy: 0.9966600916319609\n","Validation duration: 0.2226927999998831 minutes\n","F1-score (test): 97.7%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.98      0.98      1238\n","\n","   micro avg       0.97      0.98      0.98      1238\n","   macro avg       0.97      0.98      0.98      1238\n","weighted avg       0.97      0.98      0.98      1238\n","\n","!!!!!! Starting model number 9 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 3180\n","Points in y_train after augmentation: 3180\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 0.9462398290634155\n","Training loss per 100 training steps: 0.0765451355214867\n","Training loss epoch: 0.04884349042315729\n","Training accuracy epoch: 0.9845240775426326\n","Validating model...\n","Validation Loss: 0.012560364579604496\n","Validation Accuracy: 0.9962561006575854\n","Training epoch: 2\n","Training loss per 100 training steps: 0.01686190441250801\n","Training loss per 100 training steps: 0.009916258631228\n","Training loss epoch: 0.009978044423158866\n","Training accuracy epoch: 0.996960432277784\n","Validating model...\n","Validation Loss: 0.009318404993835083\n","Validation Accuracy: 0.9974120837466897\n","Training epoch: 3\n","Training loss per 100 training steps: 0.00903745461255312\n","Training loss per 100 training steps: 0.007337737091676341\n","Training loss epoch: 0.006485877444806167\n","Training accuracy epoch: 0.9980295610752548\n","Validating model...\n","Validation Loss: 0.011938740302173841\n","Validation Accuracy: 0.9970103622191837\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0016583682736381888\n","Training loss per 100 training steps: 0.00326778592788476\n","Training loss epoch: 0.00399772641959778\n","Training accuracy epoch: 0.9987486898075646\n","Validating model...\n","Validation Loss: 0.01504106340109415\n","Validation Accuracy: 0.9961695126318608\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0075641777366399765\n","Training loss per 100 training steps: 0.003326251624655762\n","Training loss epoch: 0.0037075535653260812\n","Training accuracy epoch: 0.9989165320079136\n","Validating model...\n","Validation Loss: 0.011214551073776204\n","Validation Accuracy: 0.9970883706843914\n","Training epoch: 6\n","Training loss per 100 training steps: 0.026557793840765953\n","Training loss per 100 training steps: 0.0023257980478459525\n","Training loss epoch: 0.002984272675691395\n","Training accuracy epoch: 0.999069293218651\n","Validating model...\n","Validation Loss: 0.01091906584943423\n","Validation Accuracy: 0.9971573508649596\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0017072407063096762\n","Training loss per 100 training steps: 0.002520100413279903\n","Training loss epoch: 0.003292637574610747\n","Training accuracy epoch: 0.9989036014634993\n","Validating model...\n","Validation Loss: 0.01693808820883056\n","Validation Accuracy: 0.9961775600713972\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 35.29993880000014 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.01298901270274655\n","Validation Accuracy: 0.9962021101905486\n","Validation duration: 0.21929458333324875 minutes\n","F1-score (test): 97.2%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.96      0.98      0.97      1238\n","\n","   micro avg       0.96      0.98      0.97      1238\n","   macro avg       0.96      0.98      0.97      1238\n","weighted avg       0.96      0.98      0.97      1238\n","\n","!!!!!! Starting model number 10 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 3180\n","Points in y_train after augmentation: 3180\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 0.9505318999290466\n","Training loss per 100 training steps: 0.07660540251411718\n","Training loss epoch: 0.04738798521894344\n","Training accuracy epoch: 0.9852189895559815\n","Validating model...\n","Validation Loss: 0.014561034752876453\n","Validation Accuracy: 0.9959365405199281\n","Training epoch: 2\n","Training loss per 100 training steps: 0.022043967619538307\n","Training loss per 100 training steps: 0.010043368250359827\n","Training loss epoch: 0.010791245891961817\n","Training accuracy epoch: 0.996906246618425\n","Validating model...\n","Validation Loss: 0.010263576765456014\n","Validation Accuracy: 0.9973083872802178\n","Training epoch: 3\n","Training loss per 100 training steps: 0.012514202855527401\n","Training loss per 100 training steps: 0.006688857412468273\n","Training loss epoch: 0.007434955934979883\n","Training accuracy epoch: 0.9977764334814364\n","Validating model...\n","Validation Loss: 0.014738519770270657\n","Validation Accuracy: 0.9959372625578171\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0032622560393065214\n","Training loss per 100 training steps: 0.005972075154186494\n","Training loss epoch: 0.005801239455526522\n","Training accuracy epoch: 0.9984036135394896\n","Validating model...\n","Validation Loss: 0.010493852950665834\n","Validation Accuracy: 0.9969640094624003\n","Training epoch: 5\n","Training loss per 100 training steps: 0.004839927423745394\n","Training loss per 100 training steps: 0.004147479166553383\n","Training loss epoch: 0.0037581545802274365\n","Training accuracy epoch: 0.9988935945713991\n","Validating model...\n","Validation Loss: 0.010608663303996548\n","Validation Accuracy: 0.9973816939256027\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0037765263114124537\n","Training loss per 100 training steps: 0.002404370049958689\n","Training loss epoch: 0.0026130119587111067\n","Training accuracy epoch: 0.9992454790133659\n","Validating model...\n","Validation Loss: 0.012043233514175102\n","Validation Accuracy: 0.9975260326847374\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0002100179553963244\n","Training loss per 100 training steps: 0.0027532044766510554\n","Training loss epoch: 0.003153645685200735\n","Training accuracy epoch: 0.9990305360720083\n","Validating model...\n","Validation Loss: 0.018228877077836797\n","Validation Accuracy: 0.9960314973341459\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 35.28743719999984 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.013933202249366635\n","Validation Accuracy: 0.9962926921773935\n","Validation duration: 0.22243974999995164 minutes\n","F1-score (test): 97.5%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.98      0.97      1238\n","\n","   micro avg       0.97      0.98      0.97      1238\n","   macro avg       0.97      0.98      0.97      1238\n","weighted avg       0.97      0.98      0.97      1238\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0.75\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"oKNxFPucHn_R"},{"cell_type":"code","execution_count":null,"metadata":{"id":"1tBh5gOBHpN1","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["707228563e3e461eb3395c705b2dac33","479874ab763f44f1966266312d2bd93d","08d443fbdcbb47dab83b4f0bf80f81fc","702d5e635a60473d812cfcfbb4595589","3129250bd6c145f583618e5c95e5f860","32bd67cc541e4236bc7526614aaeb5c0","c841d11604c242bb84305f06b695ec7a","cd7e324f938249a2af2539cc5e7f682d","b75440cc1889475ca0c508e8bfb138a7","df6072c661ee42ff868747fd788daeda","9a22ed8ad11849128ff2b34d989a5135"]},"outputId":"ab87954c-8637-4f42-b6ec-cc620f4953e3","executionInfo":{"status":"ok","timestamp":1665930148289,"user_tz":240,"elapsed":10815311,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}}},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 100% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"707228563e3e461eb3395c705b2dac33","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/714M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 3634\n","Points in y_train after augmentation: 3634\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.1419353485107422\n","Training loss per 100 training steps: 0.092795484182932\n","Training loss per 100 training steps: 0.05595768073953651\n","Training loss epoch: 0.0510574416022568\n","Training accuracy epoch: 0.9832381080949688\n","Validating model...\n","Validation Loss: 0.014745538423691565\n","Validation Accuracy: 0.9956068504187336\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0014129901537671685\n","Training loss per 100 training steps: 0.00961019775120191\n","Training loss per 100 training steps: 0.010831162281941382\n","Training loss epoch: 0.010810610620976883\n","Training accuracy epoch: 0.9967778401694152\n","Validating model...\n","Validation Loss: 0.01585737360818755\n","Validation Accuracy: 0.994958646513202\n","Training epoch: 3\n","Training loss per 100 training steps: 0.00905467476695776\n","Training loss per 100 training steps: 0.007773159254782621\n","Training loss per 100 training steps: 0.006730665056473941\n","Training loss epoch: 0.006832403324918695\n","Training accuracy epoch: 0.9980218044446535\n","Validating model...\n","Validation Loss: 0.013435452334566176\n","Validation Accuracy: 0.996704016755509\n","Training epoch: 4\n","Training loss per 100 training steps: 0.004280186723917723\n","Training loss per 100 training steps: 0.0038242876304355037\n","Training loss per 100 training steps: 0.0037362841665264063\n","Training loss epoch: 0.00418838043371675\n","Training accuracy epoch: 0.9987526648284027\n","Validating model...\n","Validation Loss: 0.010142717219423503\n","Validation Accuracy: 0.9971366039857619\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0022161114029586315\n","Training loss per 100 training steps: 0.004118019270901983\n","Training loss per 100 training steps: 0.0037993435473968992\n","Training loss epoch: 0.004169857747017471\n","Training accuracy epoch: 0.9987639088673145\n","Validating model...\n","Validation Loss: 0.012651320666399053\n","Validation Accuracy: 0.9974210481903402\n","Training epoch: 6\n","Training loss per 100 training steps: 0.007956705056130886\n","Training loss per 100 training steps: 0.004968083739303177\n","Training loss per 100 training steps: 0.006680962380821949\n","Training loss epoch: 0.006462808857625197\n","Training accuracy epoch: 0.9981062189121875\n","Validating model...\n","Validation Loss: 0.013071590787149034\n","Validation Accuracy: 0.9970689089515244\n","Training epoch: 7\n","Training loss per 100 training steps: 0.018519314005970955\n","Training loss per 100 training steps: 0.0038299553586449014\n","Training loss per 100 training steps: 0.0035706467356950403\n","Training loss epoch: 0.00393490201049804\n","Training accuracy epoch: 0.998764130785972\n","Validating model...\n","Validation Loss: 0.010520981045937376\n","Validation Accuracy: 0.9975700688035415\n","Training epoch: 8\n","Training loss per 100 training steps: 0.009705660864710808\n","Training loss per 100 training steps: 0.002697516642091623\n","Training loss per 100 training steps: 0.002720728711907367\n","Training loss epoch: 0.003105268795352139\n","Training accuracy epoch: 0.9990631528918612\n","Validating model...\n","Validation Loss: 0.01298281339577876\n","Validation Accuracy: 0.9969669116272912\n","Training epoch: 9\n","Training loss per 100 training steps: 0.00037787487963214517\n","Training loss per 100 training steps: 0.002698329878395532\n","Training loss per 100 training steps: 0.0027713339060476336\n","Training loss epoch: 0.002717022081030831\n","Training accuracy epoch: 0.9992081676542286\n","Validating model...\n","Validation Loss: 0.013344832833397612\n","Validation Accuracy: 0.9974333004223959\n","Training epoch: 10\n","Patience limit reached\n","Training duration: 50.70899655 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.014535445894580334\n","Validation Accuracy: 0.9962302040589469\n","Validation duration: 0.21781643333333706 minutes\n","F1-score (test): 97.1%\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.96      0.98      0.97      1238\n","\n","   micro avg       0.96      0.98      0.97      1238\n","   macro avg       0.96      0.98      0.97      1238\n","weighted avg       0.96      0.98      0.97      1238\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 3634\n","Points in y_train after augmentation: 3634\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.0245609283447266\n","Training loss per 100 training steps: 0.08278388601017765\n","Training loss per 100 training steps: 0.05122430681074919\n","Training loss epoch: 0.04674268301715257\n","Training accuracy epoch: 0.9850008775564093\n","Validating model...\n","Validation Loss: 0.020027910080638582\n","Validation Accuracy: 0.9941274706785448\n","Training epoch: 2\n","Training loss per 100 training steps: 0.010410470888018608\n","Training loss per 100 training steps: 0.009939018936048602\n","Training loss per 100 training steps: 0.009851732504998904\n","Training loss epoch: 0.009938446675700936\n","Training accuracy epoch: 0.9971062880748094\n","Validating model...\n","Validation Loss: 0.00980914813616047\n","Validation Accuracy: 0.9973282096191383\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0009541322360746562\n","Training loss per 100 training steps: 0.005842393833860331\n","Training loss per 100 training steps: 0.006705993216106001\n","Training loss epoch: 0.006833946407520368\n","Training accuracy epoch: 0.997944213713815\n","Validating model...\n","Validation Loss: 0.016213082038683796\n","Validation Accuracy: 0.9953043320067406\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03132231906056404\n","Training loss per 100 training steps: 0.004768450885214658\n","Training loss per 100 training steps: 0.006127583275567068\n","Training loss epoch: 0.006363169082505281\n","Training accuracy epoch: 0.9980350423161078\n","Validating model...\n","Validation Loss: 0.012876058939755672\n","Validation Accuracy: 0.996631503863414\n","Training epoch: 5\n","Training loss per 100 training steps: 0.003440477652475238\n","Training loss per 100 training steps: 0.003983450127652579\n","Training loss per 100 training steps: 0.003686258467134385\n","Training loss epoch: 0.003844418027782874\n","Training accuracy epoch: 0.9988003157726699\n","Validating model...\n","Validation Loss: 0.011084107023807951\n","Validation Accuracy: 0.9967777311585809\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00259451474994421\n","Training loss per 100 training steps: 0.0041259878315319685\n","Training loss per 100 training steps: 0.004337377276544376\n","Training loss epoch: 0.004293387039708027\n","Training accuracy epoch: 0.9986383206488706\n","Validating model...\n","Validation Loss: 0.0410006758147141\n","Validation Accuracy: 0.9912638316399431\n","Training epoch: 7\n","Training loss per 100 training steps: 0.004819254390895367\n","Training loss per 100 training steps: 0.003359187057237187\n","Training loss per 100 training steps: 0.004553001854074679\n","Training loss epoch: 0.004485335477064629\n","Training accuracy epoch: 0.9986389057414718\n","Validating model...\n","Validation Loss: 0.012678043237732103\n","Validation Accuracy: 0.9971843503972209\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 39.40924088333333 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.011842040462700728\n","Validation Accuracy: 0.9966626043481347\n","Validation duration: 0.2149365166666636 minutes\n","F1-score (test): 97.6%\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.99      0.98      1238\n","\n","   micro avg       0.97      0.99      0.98      1238\n","   macro avg       0.97      0.99      0.98      1238\n","weighted avg       0.97      0.99      0.98      1238\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 3634\n","Points in y_train after augmentation: 3634\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.1622706651687622\n","Training loss per 100 training steps: 0.08326862830355174\n","Training loss per 100 training steps: 0.05216320544777818\n","Training loss epoch: 0.04769144099682627\n","Training accuracy epoch: 0.9839549035157343\n","Validating model...\n","Validation Loss: 0.013147275087595474\n","Validation Accuracy: 0.9957266644481461\n","Training epoch: 2\n","Training loss per 100 training steps: 0.011539299041032791\n","Training loss per 100 training steps: 0.010630988874956782\n","Training loss per 100 training steps: 0.009879598199431575\n","Training loss epoch: 0.00971522545921943\n","Training accuracy epoch: 0.9971428022994614\n","Validating model...\n","Validation Loss: 0.010779292360807415\n","Validation Accuracy: 0.9973596552478059\n","Training epoch: 3\n","Training loss per 100 training steps: 0.005942824762314558\n","Training loss per 100 training steps: 0.0057809685041671525\n","Training loss per 100 training steps: 0.006233055204059233\n","Training loss epoch: 0.006218931796881901\n","Training accuracy epoch: 0.9979617915157304\n","Validating model...\n","Validation Loss: 0.010105314472595984\n","Validation Accuracy: 0.9969089911531397\n","Training epoch: 4\n","Training loss per 100 training steps: 0.00526083167642355\n","Training loss per 100 training steps: 0.004266193372429127\n","Training loss per 100 training steps: 0.004765066665287978\n","Training loss epoch: 0.004831761118813965\n","Training accuracy epoch: 0.9984277415277641\n","Validating model...\n","Validation Loss: 0.009294235886911684\n","Validation Accuracy: 0.9980220999765725\n","Training epoch: 5\n","Training loss per 100 training steps: 0.003185356967151165\n","Training loss per 100 training steps: 0.002859811752684193\n","Training loss per 100 training steps: 0.0026312668172008965\n","Training loss epoch: 0.002741167878028998\n","Training accuracy epoch: 0.999088353577715\n","Validating model...\n","Validation Loss: 0.013387856228897968\n","Validation Accuracy: 0.9964860120353136\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0016561507945880294\n","Training loss per 100 training steps: 0.0030821999371435614\n","Training loss per 100 training steps: 0.004048777481696547\n","Training loss epoch: 0.003919948752586048\n","Training accuracy epoch: 0.9987504366602153\n","Validating model...\n","Validation Loss: 0.016725618559576105\n","Validation Accuracy: 0.9969243115120828\n","Training epoch: 7\n","Training loss per 100 training steps: 0.00026947446167469025\n","Training loss per 100 training steps: 0.003396673542162113\n","Training loss per 100 training steps: 0.0032332033613295323\n","Training loss epoch: 0.003811159607785317\n","Training accuracy epoch: 0.9989568443825736\n","Validating model...\n","Validation Loss: 0.013194849766607928\n","Validation Accuracy: 0.9969687579474007\n","Training epoch: 8\n","Training loss per 100 training steps: 0.00611164141446352\n","Training loss per 100 training steps: 0.002870300017561796\n","Training loss per 100 training steps: 0.004065174186729365\n","Training loss epoch: 0.0038492291698690806\n","Training accuracy epoch: 0.9989279046893828\n","Validating model...\n","Validation Loss: 0.01143294024465528\n","Validation Accuracy: 0.9975551451236433\n","Training epoch: 9\n","Training loss per 100 training steps: 0.00027016823878511786\n","Training loss per 100 training steps: 0.002873833610906466\n","Training loss per 100 training steps: 0.002832825907404837\n","Training loss epoch: 0.0027044176887150236\n","Training accuracy epoch: 0.9991138385199684\n","Validating model...\n","Validation Loss: 0.020038733774570227\n","Validation Accuracy: 0.9963161748914987\n","Training epoch: 10\n","Patience limit reached\n","Training duration: 50.71672951666666 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.015205156246035282\n","Validation Accuracy: 0.9959697071368274\n","Validation duration: 0.21506851666669416 minutes\n","F1-score (test): 97.5%\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.96      0.99      0.97      1238\n","\n","   micro avg       0.96      0.99      0.97      1238\n","   macro avg       0.96      0.99      0.97      1238\n","weighted avg       0.96      0.99      0.97      1238\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 3634\n","Points in y_train after augmentation: 3634\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.209105372428894\n","Training loss per 100 training steps: 0.08166060806482588\n","Training loss per 100 training steps: 0.050688180852384856\n","Training loss epoch: 0.04641304403112531\n","Training accuracy epoch: 0.9841889199010408\n","Validating model...\n","Validation Loss: 0.01047228456618974\n","Validation Accuracy: 0.997022267061896\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0360465943813324\n","Training loss per 100 training steps: 0.01208718289681111\n","Training loss per 100 training steps: 0.010481187617215119\n","Training loss epoch: 0.010548750653310492\n","Training accuracy epoch: 0.9967830605421975\n","Validating model...\n","Validation Loss: 0.009600220609822177\n","Validation Accuracy: 0.9970793410734731\n","Training epoch: 3\n","Training loss per 100 training steps: 0.012456743977963924\n","Training loss per 100 training steps: 0.0070722064739300655\n","Training loss per 100 training steps: 0.007240275559171951\n","Training loss epoch: 0.007148177562237578\n","Training accuracy epoch: 0.9977182790567496\n","Validating model...\n","Validation Loss: 0.013585959766281857\n","Validation Accuracy: 0.9960946341749932\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0012116390280425549\n","Training loss per 100 training steps: 0.0058226909411789865\n","Training loss per 100 training steps: 0.007540693264935323\n","Training loss epoch: 0.007345224620254604\n","Training accuracy epoch: 0.9978066557181285\n","Validating model...\n","Validation Loss: 0.008199466932377877\n","Validation Accuracy: 0.9981970824786501\n","Training epoch: 5\n","Training loss per 100 training steps: 0.004290050361305475\n","Training loss per 100 training steps: 0.003891344692518861\n","Training loss per 100 training steps: 0.004048435360341523\n","Training loss epoch: 0.004085861035587425\n","Training accuracy epoch: 0.9987267580343364\n","Validating model...\n","Validation Loss: 0.013470281065868525\n","Validation Accuracy: 0.9974972308960977\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0007453681319020689\n","Training loss per 100 training steps: 0.002456299946349492\n","Training loss per 100 training steps: 0.002615742763954409\n","Training loss epoch: 0.002599025177563849\n","Training accuracy epoch: 0.9992019292530607\n","Validating model...\n","Validation Loss: 0.00987258783044083\n","Validation Accuracy: 0.9974500329128551\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0012764488346874714\n","Training loss per 100 training steps: 0.0029320004509962487\n","Training loss per 100 training steps: 0.002937786535948367\n","Training loss epoch: 0.002749181173624636\n","Training accuracy epoch: 0.9991532187396934\n","Validating model...\n","Validation Loss: 0.013149373516387727\n","Validation Accuracy: 0.9978792326266535\n","Training epoch: 8\n","Training loss per 100 training steps: 8.880515088094398e-05\n","Training loss per 100 training steps: 0.0025604158889307492\n","Training loss per 100 training steps: 0.0023979247465587233\n","Training loss epoch: 0.002306768617624281\n","Training accuracy epoch: 0.9993059790256713\n","Validating model...\n","Validation Loss: 0.011588195253699226\n","Validation Accuracy: 0.997713568594755\n","Training epoch: 9\n","Training loss per 100 training steps: 8.93248216016218e-05\n","Training loss per 100 training steps: 0.0019922856100844126\n","Training loss per 100 training steps: 0.0017305338963827428\n","Training loss epoch: 0.0017359944031819683\n","Training accuracy epoch: 0.9994718135542323\n","Validating model...\n","Validation Loss: 0.01880564310522459\n","Validation Accuracy: 0.9956537460417765\n","Training epoch: 10\n","Patience limit reached\n","Training duration: 50.69616428333335 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.011755429190088762\n","Validation Accuracy: 0.9971177806458821\n","Validation duration: 0.21779518333332817 minutes\n","F1-score (test): 98.1%\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.99      0.98      1238\n","\n","   micro avg       0.97      0.99      0.98      1238\n","   macro avg       0.97      0.99      0.98      1238\n","weighted avg       0.97      0.99      0.98      1238\n","\n","!!!!!! Starting model number 5 !!!!!!\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 3634\n","Points in y_train after augmentation: 3634\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 0.9881126284599304\n","Training loss per 100 training steps: 0.08169788515453438\n","Training loss per 100 training steps: 0.04994487219932605\n","Training loss epoch: 0.04564498391323069\n","Training accuracy epoch: 0.9851806988335411\n","Validating model...\n","Validation Loss: 0.011444502521217578\n","Validation Accuracy: 0.9968097849778201\n","Training epoch: 2\n","Training loss per 100 training steps: 0.008678749203681946\n","Training loss per 100 training steps: 0.012346387758394611\n","Training loss per 100 training steps: 0.011363019519520285\n","Training loss epoch: 0.010763158135281023\n","Training accuracy epoch: 0.9967127795464696\n","Validating model...\n","Validation Loss: 0.016554675641514006\n","Validation Accuracy: 0.9958821781981319\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0011403054231777787\n","Training loss per 100 training steps: 0.006246308097903995\n","Training loss per 100 training steps: 0.0062796684133760005\n","Training loss epoch: 0.0059978099240029946\n","Training accuracy epoch: 0.9982537737993261\n","Validating model...\n","Validation Loss: 0.013306754686449753\n","Validation Accuracy: 0.9971148780751985\n","Training epoch: 4\n","Training loss per 100 training steps: 0.008779540657997131\n","Training loss per 100 training steps: 0.004125074019089645\n","Training loss per 100 training steps: 0.004072147705409773\n","Training loss epoch: 0.004221786348991149\n","Training accuracy epoch: 0.9986905882125974\n","Validating model...\n","Validation Loss: 0.010316083735753117\n","Validation Accuracy: 0.996985997849756\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0030421593692153692\n","Training loss per 100 training steps: 0.005941417876522675\n","Training loss per 100 training steps: 0.0063329389411782315\n","Training loss epoch: 0.006240252205380034\n","Training accuracy epoch: 0.9982103937036069\n","Validating model...\n","Validation Loss: 0.014446425621697147\n","Validation Accuracy: 0.9959588073776877\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0063733868300914764\n","Training loss per 100 training steps: 0.0049935139896922125\n","Training loss per 100 training steps: 0.004967840748124661\n","Training loss epoch: 0.004760380964893429\n","Training accuracy epoch: 0.9985576858897445\n","Validating model...\n","Validation Loss: 0.013870192272276784\n","Validation Accuracy: 0.9976578191632329\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0005087886820547283\n","Training loss per 100 training steps: 0.0018808048427834563\n","Training loss per 100 training steps: 0.0018753904699934623\n","Training loss epoch: 0.0020251762599767524\n","Training accuracy epoch: 0.9993437830732994\n","Validating model...\n","Validation Loss: 0.012898540291297693\n","Validation Accuracy: 0.9975362002909904\n","Training epoch: 8\n","Training loss per 100 training steps: 0.001537915668450296\n","Training loss per 100 training steps: 0.0024465765827969364\n","Training loss per 100 training steps: 0.0024441705994904263\n","Training loss epoch: 0.002599699849014813\n","Training accuracy epoch: 0.999185165968336\n","Validating model...\n","Validation Loss: 0.012361291354560914\n","Validation Accuracy: 0.9970228566722765\n","Training epoch: 9\n","Training loss per 100 training steps: 0.006393331568688154\n","Training loss per 100 training steps: 0.0041372571919271305\n","Training loss per 100 training steps: 0.00447659266809122\n","Training loss epoch: 0.004499133949266571\n","Training accuracy epoch: 0.9986644325908606\n","Validating model...\n","Validation Loss: 0.01164206855260307\n","Validation Accuracy: 0.997357416878678\n","Training epoch: 10\n","Patience limit reached\n","Training duration: 50.673413700000005 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.01151899347314611\n","Validation Accuracy: 0.9972323901237771\n","Validation duration: 0.21475706666666763 minutes\n","F1-score (test): 98.2%\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.98      0.99      0.98      1238\n","\n","   micro avg       0.98      0.99      0.98      1238\n","   macro avg       0.98      0.99      0.98      1238\n","weighted avg       0.98      0.99      0.98      1238\n","\n","!!!!!! Starting model number 6 !!!!!!\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 3634\n","Points in y_train after augmentation: 3634\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.0878263711929321\n","Training loss per 100 training steps: 0.08547364362506288\n","Training loss per 100 training steps: 0.052705193445230114\n","Training loss epoch: 0.0480557410301755\n","Training accuracy epoch: 0.9843629964725649\n","Validating model...\n","Validation Loss: 0.015872251598574666\n","Validation Accuracy: 0.9952882242900439\n","Training epoch: 2\n","Training loss per 100 training steps: 0.007904420606791973\n","Training loss per 100 training steps: 0.008159292847987745\n","Training loss per 100 training steps: 0.009167872447478794\n","Training loss epoch: 0.009558576885753785\n","Training accuracy epoch: 0.9972318215787164\n","Validating model...\n","Validation Loss: 0.009096190014610156\n","Validation Accuracy: 0.9975807727451337\n","Training epoch: 3\n","Training loss per 100 training steps: 0.015952004119753838\n","Training loss per 100 training steps: 0.005541025593503388\n","Training loss per 100 training steps: 0.005392828567036942\n","Training loss epoch: 0.006256413671954968\n","Training accuracy epoch: 0.9981783680511283\n","Validating model...\n","Validation Loss: 0.010828605807286553\n","Validation Accuracy: 0.9965690346863847\n","Training epoch: 4\n","Training loss per 100 training steps: 0.007107831072062254\n","Training loss per 100 training steps: 0.004280925250904967\n","Training loss per 100 training steps: 0.005502277741307712\n","Training loss epoch: 0.005404061595056606\n","Training accuracy epoch: 0.9983637085503002\n","Validating model...\n","Validation Loss: 0.011852459566961486\n","Validation Accuracy: 0.9972400922092705\n","Training epoch: 5\n","Training loss per 100 training steps: 0.005162250250577927\n","Training loss per 100 training steps: 0.004413242111965728\n","Training loss per 100 training steps: 0.0038579747790878464\n","Training loss epoch: 0.0039670409361797125\n","Training accuracy epoch: 0.9988175464633415\n","Validating model...\n","Validation Loss: 0.012852885869679517\n","Validation Accuracy: 0.996974586437653\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00792628526687622\n","Training loss per 100 training steps: 0.00444294114068086\n","Training loss per 100 training steps: 0.0036926000973482535\n","Training loss epoch: 0.003474988218729043\n","Training accuracy epoch: 0.9989329816376926\n","Validating model...\n","Validation Loss: 0.021042994837487294\n","Validation Accuracy: 0.9959632181765318\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0002640850725583732\n","Training loss per 100 training steps: 0.001792909931921686\n","Training loss per 100 training steps: 0.0022891477863559158\n","Training loss epoch: 0.0022938411934375295\n","Training accuracy epoch: 0.9993329067476772\n","Validating model...\n","Validation Loss: 0.016397610005826988\n","Validation Accuracy: 0.9966641378618732\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 39.39753468333329 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.009208370688914632\n","Validation Accuracy: 0.9968506370840567\n","Validation duration: 0.21795123333334535 minutes\n","F1-score (test): 97.8%\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.99      0.98      1238\n","\n","   micro avg       0.97      0.99      0.98      1238\n","   macro avg       0.97      0.99      0.98      1238\n","weighted avg       0.97      0.99      0.98      1238\n","\n","!!!!!! Starting model number 7 !!!!!!\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 3634\n","Points in y_train after augmentation: 3634\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.2871360778808594\n","Training loss per 100 training steps: 0.09565104270298587\n","Training loss per 100 training steps: 0.05773029259443098\n","Training loss epoch: 0.05275220424651675\n","Training accuracy epoch: 0.9818915603147931\n","Validating model...\n","Validation Loss: 0.011462774621101008\n","Validation Accuracy: 0.9971067652970088\n","Training epoch: 2\n","Training loss per 100 training steps: 0.008726620115339756\n","Training loss per 100 training steps: 0.011076146560965457\n","Training loss per 100 training steps: 0.010628961908471173\n","Training loss epoch: 0.010358824253974793\n","Training accuracy epoch: 0.9968230842869835\n","Validating model...\n","Validation Loss: 0.01085836357170982\n","Validation Accuracy: 0.9970190715867414\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0010134360054507852\n","Training loss per 100 training steps: 0.0065587394158206054\n","Training loss per 100 training steps: 0.007213491685610306\n","Training loss epoch: 0.0076947116812924946\n","Training accuracy epoch: 0.9977783514825488\n","Validating model...\n","Validation Loss: 0.011353896012657233\n","Validation Accuracy: 0.996356671865284\n","Training epoch: 4\n","Training loss per 100 training steps: 0.003372680861502886\n","Training loss per 100 training steps: 0.005046626757098463\n","Training loss per 100 training steps: 0.004750511628854788\n","Training loss epoch: 0.004841382321932255\n","Training accuracy epoch: 0.9984856939428941\n","Validating model...\n","Validation Loss: 0.01186149676366421\n","Validation Accuracy: 0.9967371222097431\n","Training epoch: 5\n","Training loss per 100 training steps: 0.003538151504471898\n","Training loss per 100 training steps: 0.004030744886051144\n","Training loss per 100 training steps: 0.0043613846454768216\n","Training loss epoch: 0.004272396152118107\n","Training accuracy epoch: 0.9987359333867846\n","Validating model...\n","Validation Loss: 0.011235171540950736\n","Validation Accuracy: 0.9972964234727145\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0003396404208615422\n","Training loss per 100 training steps: 0.0047921494187183195\n","Training loss per 100 training steps: 0.005197902742504844\n","Training loss epoch: 0.0052224970584479466\n","Training accuracy epoch: 0.9985208090512079\n","Validating model...\n","Validation Loss: 0.014991169059136328\n","Validation Accuracy: 0.9967112644126248\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0022525209933519363\n","Training loss per 100 training steps: 0.0034675157738741176\n","Training loss per 100 training steps: 0.0026555918205969048\n","Training loss epoch: 0.00260824727123882\n","Training accuracy epoch: 0.9992223402106063\n","Validating model...\n","Validation Loss: 0.014381656159371016\n","Validation Accuracy: 0.9976270936061657\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 39.33774385000003 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.01632616536032098\n","Validation Accuracy: 0.9959028273578356\n","Validation duration: 0.21796139999999772 minutes\n","F1-score (test): 97.1%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.96      0.98      0.97      1238\n","\n","   micro avg       0.96      0.98      0.97      1238\n","   macro avg       0.96      0.98      0.97      1238\n","weighted avg       0.96      0.98      0.97      1238\n","\n","!!!!!! Starting model number 8 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 3634\n","Points in y_train after augmentation: 3634\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 0.910412609577179\n","Training loss per 100 training steps: 0.07467948610313457\n","Training loss per 100 training steps: 0.04820838597932117\n","Training loss epoch: 0.044209698426512706\n","Training accuracy epoch: 0.9865599154429215\n","Validating model...\n","Validation Loss: 0.013720407244926762\n","Validation Accuracy: 0.9957725308693174\n","Training epoch: 2\n","Training loss per 100 training steps: 0.027455314993858337\n","Training loss per 100 training steps: 0.012253395446557735\n","Training loss per 100 training steps: 0.010737437526672264\n","Training loss epoch: 0.012533290970870376\n","Training accuracy epoch: 0.9964514028459147\n","Validating model...\n","Validation Loss: 0.014281383260995859\n","Validation Accuracy: 0.9953653760960657\n","Training epoch: 3\n","Training loss per 100 training steps: 0.009031952358782291\n","Training loss per 100 training steps: 0.010754512053554748\n","Training loss per 100 training steps: 0.009938857508000838\n","Training loss epoch: 0.009819735160961404\n","Training accuracy epoch: 0.9971490507275249\n","Validating model...\n","Validation Loss: 0.01017913984486811\n","Validation Accuracy: 0.9971680131326737\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0006610908312723041\n","Training loss per 100 training steps: 0.008246714934778151\n","Training loss per 100 training steps: 0.007938058358363446\n","Training loss epoch: 0.007508667892308726\n","Training accuracy epoch: 0.9975923889083481\n","Validating model...\n","Validation Loss: 0.010815831188492234\n","Validation Accuracy: 0.9972604268145391\n","Training epoch: 5\n","Training loss per 100 training steps: 0.00680092629045248\n","Training loss per 100 training steps: 0.0030128424550639465\n","Training loss per 100 training steps: 0.0032163875238171813\n","Training loss epoch: 0.003322242572259009\n","Training accuracy epoch: 0.998982883882435\n","Validating model...\n","Validation Loss: 0.016115512743237474\n","Validation Accuracy: 0.995025116411813\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0046900915913283825\n","Training loss per 100 training steps: 0.002961692082367741\n","Training loss per 100 training steps: 0.003473837529759407\n","Training loss epoch: 0.003369667372393642\n","Training accuracy epoch: 0.998999717583088\n","Validating model...\n","Validation Loss: 0.01411474730897074\n","Validation Accuracy: 0.9963652571943403\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0003116541774943471\n","Training loss per 100 training steps: 0.005040419473840698\n","Training loss per 100 training steps: 0.004295186942025663\n","Training loss epoch: 0.004231695656495791\n","Training accuracy epoch: 0.9986539300893212\n","Validating model...\n","Validation Loss: 0.01097922285511491\n","Validation Accuracy: 0.9970479722825354\n","Training epoch: 8\n","Training loss per 100 training steps: 0.0010422886116430163\n","Training loss per 100 training steps: 0.0028002947730405283\n","Training loss per 100 training steps: 0.0032247472855619235\n","Training loss epoch: 0.003046940435843569\n","Training accuracy epoch: 0.9989614095902524\n","Validating model...\n","Validation Loss: 0.014719862471403238\n","Validation Accuracy: 0.9973246701600017\n","Training epoch: 9\n","Patience limit reached\n","Training duration: 44.94260965000006 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.011709698612927847\n","Validation Accuracy: 0.9963110860677893\n","Validation duration: 0.21842221666665865 minutes\n","F1-score (test): 97.5%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.96      0.99      0.97      1238\n","\n","   micro avg       0.96      0.99      0.97      1238\n","   macro avg       0.96      0.99      0.97      1238\n","weighted avg       0.96      0.99      0.97      1238\n","\n","!!!!!! Starting model number 9 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 3634\n","Points in y_train after augmentation: 3634\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.063659429550171\n","Training loss per 100 training steps: 0.08400397129485955\n","Training loss per 100 training steps: 0.052895504998654794\n","Training loss epoch: 0.04834429757555195\n","Training accuracy epoch: 0.9845453836635031\n","Validating model...\n","Validation Loss: 0.014008749207104779\n","Validation Accuracy: 0.995805127762752\n","Training epoch: 2\n","Training loss per 100 training steps: 0.012874649837613106\n","Training loss per 100 training steps: 0.009712822041140021\n","Training loss per 100 training steps: 0.009598531405671977\n","Training loss epoch: 0.009009183441281621\n","Training accuracy epoch: 0.9973119255613564\n","Validating model...\n","Validation Loss: 0.011939735216271532\n","Validation Accuracy: 0.9966198507309517\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0024259916972368956\n","Training loss per 100 training steps: 0.005266808046864825\n","Training loss per 100 training steps: 0.0061203197776502115\n","Training loss epoch: 0.005879634124747163\n","Training accuracy epoch: 0.9982151648612305\n","Validating model...\n","Validation Loss: 0.010368045217113658\n","Validation Accuracy: 0.9973500333145333\n","Training epoch: 4\n","Training loss per 100 training steps: 0.008515268564224243\n","Training loss per 100 training steps: 0.0038150211577597628\n","Training loss per 100 training steps: 0.005053510324818381\n","Training loss epoch: 0.004969040825655388\n","Training accuracy epoch: 0.9984129149659732\n","Validating model...\n","Validation Loss: 0.01709400804784742\n","Validation Accuracy: 0.9961137273501885\n","Training epoch: 5\n","Training loss per 100 training steps: 0.020811982452869415\n","Training loss per 100 training steps: 0.004710782461368599\n","Training loss per 100 training steps: 0.005106396987033424\n","Training loss epoch: 0.0052980976465174506\n","Training accuracy epoch: 0.9984677672838391\n","Validating model...\n","Validation Loss: 0.011142040388048849\n","Validation Accuracy: 0.9968417196817275\n","Training epoch: 6\n","Training loss per 100 training steps: 0.009151394478976727\n","Training loss per 100 training steps: 0.004642793833650418\n","Training loss per 100 training steps: 0.004269467288757378\n","Training loss epoch: 0.004019860447027767\n","Training accuracy epoch: 0.9987955851011046\n","Validating model...\n","Validation Loss: 0.010596892230404635\n","Validation Accuracy: 0.9976551188754067\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0012526571517810225\n","Training loss per 100 training steps: 0.0015871637315465724\n","Training loss per 100 training steps: 0.0027679287369974915\n","Training loss epoch: 0.002820119980705178\n","Training accuracy epoch: 0.9992160221891102\n","Validating model...\n","Validation Loss: 0.0167818689806154\n","Validation Accuracy: 0.9969309323406848\n","Training epoch: 8\n","Training loss per 100 training steps: 0.0028622858226299286\n","Training loss per 100 training steps: 0.001976733021743568\n","Training loss per 100 training steps: 0.001723411109115157\n","Training loss epoch: 0.0017505697320909046\n","Training accuracy epoch: 0.9994430246620943\n","Validating model...\n","Validation Loss: 0.015695936907615674\n","Validation Accuracy: 0.997111740894294\n","Training epoch: 9\n","Patience limit reached\n","Training duration: 44.972887466666606 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.012736375191404173\n","Validation Accuracy: 0.9967199024269076\n","Validation duration: 0.2140082666666179 minutes\n","F1-score (test): 97.2%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.96      0.98      0.97      1238\n","\n","   micro avg       0.96      0.98      0.97      1238\n","   macro avg       0.96      0.98      0.97      1238\n","weighted avg       0.96      0.98      0.97      1238\n","\n","!!!!!! Starting model number 10 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 3634\n","Points in y_train after augmentation: 3634\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.0741286277770996\n","Training loss per 100 training steps: 0.08029871075275806\n","Training loss per 100 training steps: 0.04932752750878829\n","Training loss epoch: 0.045379322824342046\n","Training accuracy epoch: 0.9851723651719745\n","Validating model...\n","Validation Loss: 0.014688668656162918\n","Validation Accuracy: 0.9951221519066313\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0022879766765981913\n","Training loss per 100 training steps: 0.011302007708034597\n","Training loss per 100 training steps: 0.010053803527146226\n","Training loss epoch: 0.010124324365231013\n","Training accuracy epoch: 0.9968069385813436\n","Validating model...\n","Validation Loss: 0.010428282091327543\n","Validation Accuracy: 0.9968498558313856\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0009368432802148163\n","Training loss per 100 training steps: 0.007098268356178841\n","Training loss per 100 training steps: 0.00627498066403778\n","Training loss epoch: 0.006332207014406377\n","Training accuracy epoch: 0.9979563922694055\n","Validating model...\n","Validation Loss: 0.012657896045961283\n","Validation Accuracy: 0.9966594244108268\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0022548376582562923\n","Training loss per 100 training steps: 0.00387181420761534\n","Training loss per 100 training steps: 0.00446302171390265\n","Training loss epoch: 0.00429712533099391\n","Training accuracy epoch: 0.998669852446337\n","Validating model...\n","Validation Loss: 0.010600671011897725\n","Validation Accuracy: 0.9976920359579639\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0006883185706101358\n","Training loss per 100 training steps: 0.0035038442795549862\n","Training loss per 100 training steps: 0.003620954212364544\n","Training loss epoch: 0.003578416234105182\n","Training accuracy epoch: 0.9989117264595158\n","Validating model...\n","Validation Loss: 0.01213777497702852\n","Validation Accuracy: 0.9970950495619265\n","Training epoch: 6\n","Training loss per 100 training steps: 0.002780300099402666\n","Training loss per 100 training steps: 0.002432352628332383\n","Training loss per 100 training steps: 0.002242956619467343\n","Training loss epoch: 0.0022513650520730216\n","Training accuracy epoch: 0.9993433790423775\n","Validating model...\n","Validation Loss: 0.01716188242426142\n","Validation Accuracy: 0.9970554592760034\n","Training epoch: 7\n","Training loss per 100 training steps: 0.00042285575182177126\n","Training loss per 100 training steps: 0.002641267713019855\n","Training loss per 100 training steps: 0.0038351879073034705\n","Training loss epoch: 0.0038853474079428053\n","Training accuracy epoch: 0.9987815247965833\n","Validating model...\n","Validation Loss: 0.022717854628094107\n","Validation Accuracy: 0.9947456435131986\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 39.434162650000026 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.01353565933580588\n","Validation Accuracy: 0.9957794162305093\n","Validation duration: 0.21429440000004737 minutes\n","F1-score (test): 96.8%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.95      0.98      0.97      1238\n","\n","   micro avg       0.95      0.98      0.97      1238\n","   macro avg       0.95      0.98      0.97      1238\n","weighted avg       0.95      0.98      0.97      1238\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 1\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"1tBh5gOBHpN1"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zjhn7-LqHri0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665984127224,"user_tz":240,"elapsed":53978939,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}},"outputId":"162c53ea-cfa1-496f-cc5a-ef6490297f31"},"outputs":[{"output_type":"stream","name":"stdout","text":["!!!!!! Augmented Percentage 200% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 5451\n","Points in y_train after augmentation: 5451\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.1629048585891724\n","Training loss per 100 training steps: 0.08141219041236483\n","Training loss per 100 training steps: 0.050555441328162205\n","Training loss per 100 training steps: 0.03849998828985936\n","Training loss epoch: 0.03541209841047378\n","Training accuracy epoch: 0.9884297674877681\n","Validating model...\n","Validation Loss: 0.015007781718547145\n","Validation Accuracy: 0.9960048545578498\n","Training epoch: 2\n","Training loss per 100 training steps: 0.007450344040989876\n","Training loss per 100 training steps: 0.008211238029076359\n","Training loss per 100 training steps: 0.008790425431366723\n","Training loss per 100 training steps: 0.00847759491963578\n","Training loss epoch: 0.008171941182040815\n","Training accuracy epoch: 0.9974758104275784\n","Validating model...\n","Validation Loss: 0.019930035004758144\n","Validation Accuracy: 0.9948180903931187\n","Training epoch: 3\n","Training loss per 100 training steps: 0.004395956639200449\n","Training loss per 100 training steps: 0.005011157103869511\n","Training loss per 100 training steps: 0.005365827062488094\n","Training loss per 100 training steps: 0.005967550862954149\n","Training loss epoch: 0.0059962139760732615\n","Training accuracy epoch: 0.9982351863879272\n","Validating model...\n","Validation Loss: 0.012490070435714665\n","Validation Accuracy: 0.9971369096182195\n","Training epoch: 4\n","Training loss per 100 training steps: 0.006134556606411934\n","Training loss per 100 training steps: 0.005455097792172196\n","Training loss per 100 training steps: 0.0048044542568435765\n","Training loss per 100 training steps: 0.004909728805943929\n","Training loss epoch: 0.004848580994296585\n","Training accuracy epoch: 0.998532003156156\n","Validating model...\n","Validation Loss: 0.009894977989634277\n","Validation Accuracy: 0.9976803195912722\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0011584943858906627\n","Training loss per 100 training steps: 0.004094813071914008\n","Training loss per 100 training steps: 0.004241243350171584\n","Training loss per 100 training steps: 0.004640767167975385\n","Training loss epoch: 0.004793952814941916\n","Training accuracy epoch: 0.998637778714115\n","Validating model...\n","Validation Loss: 0.007919928658382213\n","Validation Accuracy: 0.9978472326036851\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0020048560108989477\n","Training loss per 100 training steps: 0.0036471018470140256\n","Training loss per 100 training steps: 0.0026732781073075616\n","Training loss per 100 training steps: 0.0036852388969832177\n","Training loss epoch: 0.003816209777397967\n","Training accuracy epoch: 0.9989579971444605\n","Validating model...\n","Validation Loss: 0.012073900589408973\n","Validation Accuracy: 0.9974605580277592\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0027575280983000994\n","Training loss per 100 training steps: 0.0032130231867437157\n","Training loss per 100 training steps: 0.0035480002160108793\n","Training loss per 100 training steps: 0.003238757015164343\n","Training loss epoch: 0.0032202075350339335\n","Training accuracy epoch: 0.9990887287571573\n","Validating model...\n","Validation Loss: 0.01385297722195641\n","Validation Accuracy: 0.9970961280001456\n","Training epoch: 8\n","Training loss per 100 training steps: 0.0004392544797156006\n","Training loss per 100 training steps: 0.0021287239474932535\n","Training loss per 100 training steps: 0.0017632240471619804\n","Training loss per 100 training steps: 0.00250678428884714\n","Training loss epoch: 0.002721635023379648\n","Training accuracy epoch: 0.9992244467924738\n","Validating model...\n","Validation Loss: 0.01684124890951872\n","Validation Accuracy: 0.9974049189958885\n","Training epoch: 9\n","Training loss per 100 training steps: 0.008410601876676083\n","Training loss per 100 training steps: 0.003388408375463084\n","Training loss per 100 training steps: 0.002970725313348543\n","Training loss per 100 training steps: 0.0028925530039674396\n","Training loss epoch: 0.002828872148303453\n","Training accuracy epoch: 0.9992681456623707\n","Validating model...\n","Validation Loss: 0.011306262501117695\n","Validation Accuracy: 0.9972779882794749\n","Training epoch: 10\n","Training loss per 100 training steps: 7.900423952378333e-05\n","Training loss per 100 training steps: 0.002471819190057179\n","Training loss per 100 training steps: 0.0030025573923288433\n","Training loss per 100 training steps: 0.0038989671049656986\n","Training loss epoch: 0.0039360754256014836\n","Training accuracy epoch: 0.998906668301171\n","Validating model...\n","Validation Loss: 0.011120682411793885\n","Validation Accuracy: 0.9976174823360748\n","Training epoch: 11\n","Patience limit reached\n","Training duration: 83.50401693333333 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.01328951787824432\n","Validation Accuracy: 0.9969570665539397\n","Validation duration: 0.2142792333333394 minutes\n","F1-score (test): 98.3%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.98      0.99      0.98      1238\n","\n","   micro avg       0.98      0.99      0.98      1238\n","   macro avg       0.98      0.99      0.98      1238\n","weighted avg       0.98      0.99      0.98      1238\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 5451\n","Points in y_train after augmentation: 5451\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.223551869392395\n","Training loss per 100 training steps: 0.08494558475570439\n","Training loss per 100 training steps: 0.05380451049428637\n","Training loss per 100 training steps: 0.04001945698907618\n","Training loss epoch: 0.036549029170598324\n","Training accuracy epoch: 0.9877116921650669\n","Validating model...\n","Validation Loss: 0.013698543995685344\n","Validation Accuracy: 0.995825986020825\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0073067424818873405\n","Training loss per 100 training steps: 0.008680583150725407\n","Training loss per 100 training steps: 0.007875232655839967\n","Training loss per 100 training steps: 0.00758690419682283\n","Training loss epoch: 0.0077853477719585385\n","Training accuracy epoch: 0.9977087863449959\n","Validating model...\n","Validation Loss: 0.00997358171679523\n","Validation Accuracy: 0.9973164269412945\n","Training epoch: 3\n","Training loss per 100 training steps: 0.018217630684375763\n","Training loss per 100 training steps: 0.003454013271453228\n","Training loss per 100 training steps: 0.004245015232046528\n","Training loss per 100 training steps: 0.004803237782517043\n","Training loss epoch: 0.004933823102716796\n","Training accuracy epoch: 0.9984442885181201\n","Validating model...\n","Validation Loss: 0.014333370252903219\n","Validation Accuracy: 0.995718082439887\n","Training epoch: 4\n","Training loss per 100 training steps: 0.001616088324226439\n","Training loss per 100 training steps: 0.004250544301576516\n","Training loss per 100 training steps: 0.0036967991961966112\n","Training loss per 100 training steps: 0.0035394744990724972\n","Training loss epoch: 0.003721921498358251\n","Training accuracy epoch: 0.998810693070459\n","Validating model...\n","Validation Loss: 0.009232881130758739\n","Validation Accuracy: 0.9975775430032111\n","Training epoch: 5\n","Training loss per 100 training steps: 0.012969164177775383\n","Training loss per 100 training steps: 0.0026808342728406502\n","Training loss per 100 training steps: 0.0028505685812847538\n","Training loss per 100 training steps: 0.003140482291527227\n","Training loss epoch: 0.003098773417310397\n","Training accuracy epoch: 0.9990305035525738\n","Validating model...\n","Validation Loss: 0.01260575957972573\n","Validation Accuracy: 0.9971979648388652\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00016520830104127526\n","Training loss per 100 training steps: 0.0022952269921888997\n","Training loss per 100 training steps: 0.0022249345712220953\n","Training loss per 100 training steps: 0.0026060066957989177\n","Training loss epoch: 0.002656958067986061\n","Training accuracy epoch: 0.9991868850108078\n","Validating model...\n","Validation Loss: 0.010987035836955155\n","Validation Accuracy: 0.9977688196340838\n","Training epoch: 7\n","Training loss per 100 training steps: 0.00791584886610508\n","Training loss per 100 training steps: 0.003296798303732556\n","Training loss per 100 training steps: 0.0039880519632345054\n","Training loss per 100 training steps: 0.004051773586629332\n","Training loss epoch: 0.003970828096498735\n","Training accuracy epoch: 0.9988449866640031\n","Validating model...\n","Validation Loss: 0.013620222179659842\n","Validation Accuracy: 0.9973265704362184\n","Training epoch: 8\n","Training loss per 100 training steps: 0.015699783340096474\n","Training loss per 100 training steps: 0.0036265024381383127\n","Training loss per 100 training steps: 0.0031878047363231112\n","Training loss per 100 training steps: 0.0035030290855623107\n","Training loss epoch: 0.0036435279389826275\n","Training accuracy epoch: 0.9988194147124426\n","Validating model...\n","Validation Loss: 0.011641031491481477\n","Validation Accuracy: 0.9968902759826241\n","Training epoch: 9\n","Training loss per 100 training steps: 0.0005989152123220265\n","Training loss per 100 training steps: 0.0026997053889614773\n","Training loss per 100 training steps: 0.0023050921001268577\n","Training loss per 100 training steps: 0.0025763310053861705\n","Training loss epoch: 0.0026320325309758742\n","Training accuracy epoch: 0.9991674052183974\n","Validating model...\n","Validation Loss: 0.01678307779574035\n","Validation Accuracy: 0.9964505728427502\n","Training epoch: 10\n","Patience limit reached\n","Training duration: 75.20110545000001 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.01388937817561479\n","Validation Accuracy: 0.9964341879932422\n","Validation duration: 0.2139594833333831 minutes\n","F1-score (test): 97.6%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.98      0.98      1238\n","\n","   micro avg       0.97      0.98      0.98      1238\n","   macro avg       0.97      0.98      0.98      1238\n","weighted avg       0.97      0.98      0.98      1238\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 5451\n","Points in y_train after augmentation: 5451\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.1790341138839722\n","Training loss per 100 training steps: 0.08443164550192138\n","Training loss per 100 training steps: 0.05274619072541335\n","Training loss per 100 training steps: 0.04104866850517839\n","Training loss epoch: 0.037597410757739175\n","Training accuracy epoch: 0.9873844610685688\n","Validating model...\n","Validation Loss: 0.016390793877820085\n","Validation Accuracy: 0.9955386993690638\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0034785571042448282\n","Training loss per 100 training steps: 0.01040004785541482\n","Training loss per 100 training steps: 0.009563602296871814\n","Training loss per 100 training steps: 0.00930875582652216\n","Training loss epoch: 0.009185577618829426\n","Training accuracy epoch: 0.997285785596864\n","Validating model...\n","Validation Loss: 0.014929216985668367\n","Validation Accuracy: 0.9963138660009773\n","Training epoch: 3\n","Training loss per 100 training steps: 0.005743513349443674\n","Training loss per 100 training steps: 0.005842188399142152\n","Training loss per 100 training steps: 0.0060976075765211135\n","Training loss per 100 training steps: 0.0060547665509927484\n","Training loss epoch: 0.005931948007572964\n","Training accuracy epoch: 0.9982023661767772\n","Validating model...\n","Validation Loss: 0.012967530743827367\n","Validation Accuracy: 0.9965087437885788\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0006656534387730062\n","Training loss per 100 training steps: 0.003930772369653148\n","Training loss per 100 training steps: 0.003609097475961803\n","Training loss per 100 training steps: 0.003479912609757857\n","Training loss epoch: 0.00350893186214974\n","Training accuracy epoch: 0.998916531744094\n","Validating model...\n","Validation Loss: 0.02569799043651853\n","Validation Accuracy: 0.9935881883217771\n","Training epoch: 5\n","Training loss per 100 training steps: 0.018876897171139717\n","Training loss per 100 training steps: 0.003960772865281284\n","Training loss per 100 training steps: 0.00517931216427088\n","Training loss per 100 training steps: 0.0048579486706073665\n","Training loss epoch: 0.004739658519616446\n","Training accuracy epoch: 0.9986572259482979\n","Validating model...\n","Validation Loss: 0.012272314569123583\n","Validation Accuracy: 0.9973016167855504\n","Training epoch: 6\n","Training loss per 100 training steps: 0.004809802398085594\n","Training loss per 100 training steps: 0.006475229712006046\n","Training loss per 100 training steps: 0.005843181616788272\n","Training loss per 100 training steps: 0.0050762706517726896\n","Training loss epoch: 0.004979508087205252\n","Training accuracy epoch: 0.9985175026829088\n","Validating model...\n","Validation Loss: 0.03354160054108694\n","Validation Accuracy: 0.9945634778383902\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0022806329652667046\n","Training loss per 100 training steps: 0.003919509847073281\n","Training loss per 100 training steps: 0.0034415159513913234\n","Training loss per 100 training steps: 0.003173019931087173\n","Training loss epoch: 0.0030127747239213154\n","Training accuracy epoch: 0.9991596586658802\n","Validating model...\n","Validation Loss: 0.011024260963971582\n","Validation Accuracy: 0.9971911107186435\n","Training epoch: 8\n","Training loss per 100 training steps: 0.005823688581585884\n","Training loss per 100 training steps: 0.002956042725663162\n","Training loss per 100 training steps: 0.0029050368137005485\n","Training loss per 100 training steps: 0.0029331011678626106\n","Training loss epoch: 0.002989816062425586\n","Training accuracy epoch: 0.999133289508118\n","Validating model...\n","Validation Loss: 0.013050563414470247\n","Validation Accuracy: 0.996916711937996\n","Training epoch: 9\n","Training loss per 100 training steps: 0.001406350638717413\n","Training loss per 100 training steps: 0.002650355601494228\n","Training loss per 100 training steps: 0.0021646557943494375\n","Training loss per 100 training steps: 0.0022021689277777158\n","Training loss epoch: 0.002122128131763383\n","Training accuracy epoch: 0.9992751047049037\n","Validating model...\n","Validation Loss: 0.016768913724999515\n","Validation Accuracy: 0.9969231083729879\n","Training epoch: 10\n","Training loss per 100 training steps: 0.0030860353726893663\n","Training loss per 100 training steps: 0.0014517426045653572\n","Training loss per 100 training steps: 0.0029696548874144626\n","Training loss per 100 training steps: 0.0025496589999139388\n","Training loss epoch: 0.0026216485028730313\n","Training accuracy epoch: 0.9992834009199303\n","Validating model...\n","Validation Loss: 0.02326900359427479\n","Validation Accuracy: 0.9953374551041456\n","Training epoch: 11\n","Training loss per 100 training steps: 0.004753388464450836\n","Training loss per 100 training steps: 0.002149766761474461\n","Training loss per 100 training steps: 0.0018710482820269185\n","Training loss per 100 training steps: 0.0017300522980187687\n","Training loss epoch: 0.0016905061378421709\n","Training accuracy epoch: 0.9994666263980989\n","Validating model...\n","Validation Loss: 0.01777259983923397\n","Validation Accuracy: 0.9972117079801567\n","Training epoch: 12\n","Training loss per 100 training steps: 7.437402382493019e-05\n","Training loss per 100 training steps: 0.002779354813112762\n","Training loss per 100 training steps: 0.002420582101465028\n","Training loss per 100 training steps: 0.0022893445976626746\n","Training loss epoch: 0.002587861502623319\n","Training accuracy epoch: 0.9991883973996081\n","Validating model...\n","Validation Loss: 0.018607121559311747\n","Validation Accuracy: 0.9967567843849829\n","Training epoch: 13\n","Patience limit reached\n","Training duration: 100.22103904999992 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.013722574649818853\n","Validation Accuracy: 0.9969059684452605\n","Validation duration: 0.21324271666671848 minutes\n","F1-score (test): 97.6%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.99      0.98      1238\n","\n","   micro avg       0.97      0.99      0.98      1238\n","   macro avg       0.97      0.99      0.98      1238\n","weighted avg       0.97      0.99      0.98      1238\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 5451\n","Points in y_train after augmentation: 5451\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.3265239000320435\n","Training loss per 100 training steps: 0.10273619814969526\n","Training loss per 100 training steps: 0.0613029000397994\n","Training loss per 100 training steps: 0.0458500883240327\n","Training loss epoch: 0.04159749073080194\n","Training accuracy epoch: 0.9861085214286724\n","Validating model...\n","Validation Loss: 0.013864210673740931\n","Validation Accuracy: 0.9956016092272851\n","Training epoch: 2\n","Training loss per 100 training steps: 0.003811923786997795\n","Training loss per 100 training steps: 0.007791490526869893\n","Training loss per 100 training steps: 0.008564303380487005\n","Training loss per 100 training steps: 0.008359094592916665\n","Training loss epoch: 0.00788327938898554\n","Training accuracy epoch: 0.9976144296631568\n","Validating model...\n","Validation Loss: 0.016330406961406835\n","Validation Accuracy: 0.9963169113119399\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0020354653242975473\n","Training loss per 100 training steps: 0.005010573602757546\n","Training loss per 100 training steps: 0.005071100321976556\n","Training loss per 100 training steps: 0.005022669328073816\n","Training loss epoch: 0.005194318798414016\n","Training accuracy epoch: 0.9984294081812141\n","Validating model...\n","Validation Loss: 0.00948504106851206\n","Validation Accuracy: 0.9972099811440365\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0017274220008403063\n","Training loss per 100 training steps: 0.005513806473293761\n","Training loss per 100 training steps: 0.004644895516837245\n","Training loss per 100 training steps: 0.0044868003302489705\n","Training loss epoch: 0.004794016916789948\n","Training accuracy epoch: 0.9986166699041745\n","Validating model...\n","Validation Loss: 0.016158751926490196\n","Validation Accuracy: 0.9960835327995935\n","Training epoch: 5\n","Training loss per 100 training steps: 0.00194161431863904\n","Training loss per 100 training steps: 0.004816296677961531\n","Training loss per 100 training steps: 0.004134700224611478\n","Training loss per 100 training steps: 0.0037608917393958338\n","Training loss epoch: 0.0038373791278545444\n","Training accuracy epoch: 0.9988879925313691\n","Validating model...\n","Validation Loss: 0.024267217220594398\n","Validation Accuracy: 0.9916247904359772\n","Training epoch: 6\n","Training loss per 100 training steps: 0.007193081080913544\n","Training loss per 100 training steps: 0.003164960373865007\n","Training loss per 100 training steps: 0.0031508001689030266\n","Training loss per 100 training steps: 0.0035268100822021284\n","Training loss epoch: 0.003561587370358987\n","Training accuracy epoch: 0.9989723562238932\n","Validating model...\n","Validation Loss: 0.011856410931310771\n","Validation Accuracy: 0.9971090865869162\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0011374722234904766\n","Training loss per 100 training steps: 0.0033013863688364214\n","Training loss per 100 training steps: 0.004112630849106866\n","Training loss per 100 training steps: 0.004049160513002251\n","Training loss epoch: 0.0039368936067044735\n","Training accuracy epoch: 0.998928289531114\n","Validating model...\n","Validation Loss: 0.010983072088579536\n","Validation Accuracy: 0.997236047253123\n","Training epoch: 8\n","Training loss per 100 training steps: 7.500770880142227e-05\n","Training loss per 100 training steps: 0.0022263650099907098\n","Training loss per 100 training steps: 0.0024829606309637953\n","Training loss per 100 training steps: 0.0026610424067372374\n","Training loss epoch: 0.002480893404023907\n","Training accuracy epoch: 0.9992480139326977\n","Validating model...\n","Validation Loss: 0.01229847652315844\n","Validation Accuracy: 0.9976302208924972\n","Training epoch: 9\n","Patience limit reached\n","Training duration: 66.72900573333342 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.0137501427513295\n","Validation Accuracy: 0.9968822675352086\n","Validation duration: 0.213968549999845 minutes\n","F1-score (test): 97.8%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.99      0.98      1238\n","\n","   micro avg       0.97      0.99      0.98      1238\n","   macro avg       0.97      0.99      0.98      1238\n","weighted avg       0.97      0.99      0.98      1238\n","\n","!!!!!! Starting model number 5 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 5451\n","Points in y_train after augmentation: 5451\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 0.9974281787872314\n","Training loss per 100 training steps: 0.09215779357248603\n","Training loss per 100 training steps: 0.05610239954517033\n","Training loss per 100 training steps: 0.041198534575024884\n","Training loss epoch: 0.03755553293945213\n","Training accuracy epoch: 0.9884099864997309\n","Validating model...\n","Validation Loss: 0.01153570607199245\n","Validation Accuracy: 0.9965165851381149\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0010872239945456386\n","Training loss per 100 training steps: 0.0079468076410104\n","Training loss per 100 training steps: 0.0076772338629350415\n","Training loss per 100 training steps: 0.007530364541312141\n","Training loss epoch: 0.008050829197056155\n","Training accuracy epoch: 0.9975837456627077\n","Validating model...\n","Validation Loss: 0.015956448122215944\n","Validation Accuracy: 0.995725722535804\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0077036540023982525\n","Training loss per 100 training steps: 0.006855075725205565\n","Training loss per 100 training steps: 0.006886692454506161\n","Training loss per 100 training steps: 0.006103944185526773\n","Training loss epoch: 0.005937468682958941\n","Training accuracy epoch: 0.9982044642065259\n","Validating model...\n","Validation Loss: 0.010894555315081518\n","Validation Accuracy: 0.9971897814190255\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0010519789066165686\n","Training loss per 100 training steps: 0.0024425952681190436\n","Training loss per 100 training steps: 0.003841241770208204\n","Training loss per 100 training steps: 0.004257843722751754\n","Training loss epoch: 0.004336020292735063\n","Training accuracy epoch: 0.9986537265078477\n","Validating model...\n","Validation Loss: 0.012078968090853388\n","Validation Accuracy: 0.996322676826676\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0028849130030721426\n","Training loss per 100 training steps: 0.0026148264747318157\n","Training loss per 100 training steps: 0.0024270374014850856\n","Training loss per 100 training steps: 0.003085368160438605\n","Training loss epoch: 0.0030795506480048532\n","Training accuracy epoch: 0.9990005100045318\n","Validating model...\n","Validation Loss: 0.016245519498451835\n","Validation Accuracy: 0.9963121574468429\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0057409764267504215\n","Training loss per 100 training steps: 0.0031309180143364187\n","Training loss per 100 training steps: 0.0029301196153942305\n","Training loss per 100 training steps: 0.00289576695200274\n","Training loss epoch: 0.0027531774633956147\n","Training accuracy epoch: 0.9991980256513545\n","Validating model...\n","Validation Loss: 0.01608862317204642\n","Validation Accuracy: 0.9969618484275407\n","Training epoch: 7\n","Training loss per 100 training steps: 0.00111022696364671\n","Training loss per 100 training steps: 0.0019305879978124758\n","Training loss per 100 training steps: 0.003098436174524018\n","Training loss per 100 training steps: 0.0029957125989071047\n","Training loss epoch: 0.0030007531634262045\n","Training accuracy epoch: 0.9992047342528851\n","Validating model...\n","Validation Loss: 0.017503175985655702\n","Validation Accuracy: 0.9966452913868122\n","Training epoch: 8\n","Training loss per 100 training steps: 0.00787582341581583\n","Training loss per 100 training steps: 0.0014651200094298888\n","Training loss per 100 training steps: 0.0015690051667439746\n","Training loss per 100 training steps: 0.0020023083799178103\n","Training loss epoch: 0.0020633056273070592\n","Training accuracy epoch: 0.9993666832823633\n","Validating model...\n","Validation Loss: 0.014756748556724883\n","Validation Accuracy: 0.9971260497509329\n","Training epoch: 9\n","Patience limit reached\n","Training duration: 66.76354565000001 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.01291061082156375\n","Validation Accuracy: 0.9965560870760656\n","Validation duration: 0.2133523833331613 minutes\n","F1-score (test): 97.9%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.99      0.98      1238\n","\n","   micro avg       0.97      0.99      0.98      1238\n","   macro avg       0.97      0.99      0.98      1238\n","weighted avg       0.97      0.99      0.98      1238\n","\n","!!!!!! Starting model number 6 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 5451\n","Points in y_train after augmentation: 5451\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.0855070352554321\n","Training loss per 100 training steps: 0.07770271638482071\n","Training loss per 100 training steps: 0.048971311708759346\n","Training loss per 100 training steps: 0.0373780668587068\n","Training loss epoch: 0.03423419378150276\n","Training accuracy epoch: 0.9890794503267304\n","Validating model...\n","Validation Loss: 0.012441794888304901\n","Validation Accuracy: 0.9967048005877808\n","Training epoch: 2\n","Training loss per 100 training steps: 0.006374989170581102\n","Training loss per 100 training steps: 0.007935888964410798\n","Training loss per 100 training steps: 0.00875512707430582\n","Training loss per 100 training steps: 0.008361812453156961\n","Training loss epoch: 0.008340146213522744\n","Training accuracy epoch: 0.9975282448957763\n","Validating model...\n","Validation Loss: 0.012911678801867225\n","Validation Accuracy: 0.996363498186569\n","Training epoch: 3\n","Training loss per 100 training steps: 0.009715626016259193\n","Training loss per 100 training steps: 0.008426963975238106\n","Training loss per 100 training steps: 0.007596675428620942\n","Training loss per 100 training steps: 0.006796255986499399\n","Training loss epoch: 0.006835150638384584\n","Training accuracy epoch: 0.9980216340846455\n","Validating model...\n","Validation Loss: 0.011837087302583746\n","Validation Accuracy: 0.9971572245299184\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0006919120205566287\n","Training loss per 100 training steps: 0.0031385589939931704\n","Training loss per 100 training steps: 0.0033993931712069554\n","Training loss per 100 training steps: 0.0037464417742570687\n","Training loss epoch: 0.003726670644662542\n","Training accuracy epoch: 0.9988817368503918\n","Validating model...\n","Validation Loss: 0.01174916881756785\n","Validation Accuracy: 0.9975270753540871\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0012981410836800933\n","Training loss per 100 training steps: 0.002578648849791561\n","Training loss per 100 training steps: 0.0030022562127873134\n","Training loss per 100 training steps: 0.0034275039629407377\n","Training loss epoch: 0.0035716102104681843\n","Training accuracy epoch: 0.9989225611352103\n","Validating model...\n","Validation Loss: 0.01203514590417312\n","Validation Accuracy: 0.9970679009434947\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0027725801337510347\n","Training loss per 100 training steps: 0.0022092433099183692\n","Training loss per 100 training steps: 0.0022879701364353655\n","Training loss per 100 training steps: 0.0022311203195739568\n","Training loss epoch: 0.0022674616753178153\n","Training accuracy epoch: 0.999288138544351\n","Validating model...\n","Validation Loss: 0.010472744636769806\n","Validation Accuracy: 0.9976555466377748\n","Training epoch: 7\n","Training loss per 100 training steps: 0.00032947692670859396\n","Training loss per 100 training steps: 0.0015068130125637433\n","Training loss per 100 training steps: 0.0021281112708515936\n","Training loss per 100 training steps: 0.0025515812798935\n","Training loss epoch: 0.002707521278608988\n","Training accuracy epoch: 0.9991984784078584\n","Validating model...\n","Validation Loss: 0.016793232042497646\n","Validation Accuracy: 0.9966416666649675\n","Training epoch: 8\n","Training loss per 100 training steps: 0.0009173048892989755\n","Training loss per 100 training steps: 0.0023350724018966124\n","Training loss per 100 training steps: 0.0030679991739554174\n","Training loss per 100 training steps: 0.0038821852262316743\n","Training loss epoch: 0.0038580209810924826\n","Training accuracy epoch: 0.99882487126857\n","Validating model...\n","Validation Loss: 0.013196556949835559\n","Validation Accuracy: 0.9975770165569452\n","Training epoch: 9\n","Training loss per 100 training steps: 0.009778867475688457\n","Training loss per 100 training steps: 0.00258217849909895\n","Training loss per 100 training steps: 0.0026031979034983194\n","Training loss per 100 training steps: 0.0027540178144346006\n","Training loss epoch: 0.002941152077223532\n","Training accuracy epoch: 0.9990965517553266\n","Validating model...\n","Validation Loss: 0.01185354891978412\n","Validation Accuracy: 0.9976106658585244\n","Training epoch: 10\n","Training loss per 100 training steps: 0.005585927050560713\n","Training loss per 100 training steps: 0.0020040481145716144\n","Training loss per 100 training steps: 0.001527731282027587\n","Training loss per 100 training steps: 0.0022030097320914193\n","Training loss epoch: 0.002174903091859891\n","Training accuracy epoch: 0.9993996738303571\n","Validating model...\n","Validation Loss: 0.015566640365899989\n","Validation Accuracy: 0.9969986410478633\n","Training epoch: 11\n","Training loss per 100 training steps: 0.0012383776484057307\n","Training loss per 100 training steps: 0.002448644661511719\n","Training loss per 100 training steps: 0.0018714254631719376\n","Training loss per 100 training steps: 0.00290072432296537\n","Training loss epoch: 0.0030534196331323113\n","Training accuracy epoch: 0.9991104631815619\n","Validating model...\n","Validation Loss: 0.013543347820467759\n","Validation Accuracy: 0.997262375282588\n","Training epoch: 12\n","Patience limit reached\n","Training duration: 91.73849048333335 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.01596475503962817\n","Validation Accuracy: 0.9966164064037542\n","Validation duration: 0.21374196666656645 minutes\n","F1-score (test): 97.8%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.99      0.98      1238\n","\n","   micro avg       0.97      0.99      0.98      1238\n","   macro avg       0.97      0.99      0.98      1238\n","weighted avg       0.97      0.99      0.98      1238\n","\n","!!!!!! Starting model number 7 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 5451\n","Points in y_train after augmentation: 5451\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.1058855056762695\n","Training loss per 100 training steps: 0.0869751213727021\n","Training loss per 100 training steps: 0.05461737076839923\n","Training loss per 100 training steps: 0.041334550234448916\n","Training loss epoch: 0.03799183355115868\n","Training accuracy epoch: 0.9876419647190037\n","Validating model...\n","Validation Loss: 0.01217158473030265\n","Validation Accuracy: 0.9963364547397275\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0023971283808350563\n","Training loss per 100 training steps: 0.007703034070638552\n","Training loss per 100 training steps: 0.007249924270273997\n","Training loss per 100 training steps: 0.00710843166305863\n","Training loss epoch: 0.0073300215323992305\n","Training accuracy epoch: 0.997733776195427\n","Validating model...\n","Validation Loss: 0.010794208202111934\n","Validation Accuracy: 0.9965105760417872\n","Training epoch: 3\n","Training loss per 100 training steps: 0.004557245410978794\n","Training loss per 100 training steps: 0.005053901140512391\n","Training loss per 100 training steps: 0.006464997853864267\n","Training loss per 100 training steps: 0.00645133908560532\n","Training loss epoch: 0.006260403322236533\n","Training accuracy epoch: 0.9982019560073011\n","Validating model...\n","Validation Loss: 0.012927252059203706\n","Validation Accuracy: 0.9965101193664958\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0007629102328792214\n","Training loss per 100 training steps: 0.004433398767222309\n","Training loss per 100 training steps: 0.004799947065642377\n","Training loss per 100 training steps: 0.004740809446643184\n","Training loss epoch: 0.0045424385518713\n","Training accuracy epoch: 0.9986700757353866\n","Validating model...\n","Validation Loss: 0.012847951554812468\n","Validation Accuracy: 0.996590674287008\n","Training epoch: 5\n","Training loss per 100 training steps: 0.009277093224227428\n","Training loss per 100 training steps: 0.0031050722018785607\n","Training loss per 100 training steps: 0.002881977910657219\n","Training loss per 100 training steps: 0.003324924013461373\n","Training loss epoch: 0.0033148023827497155\n","Training accuracy epoch: 0.9989985990865824\n","Validating model...\n","Validation Loss: 0.012232654406467364\n","Validation Accuracy: 0.9967299939476353\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0007911327411420643\n","Training loss per 100 training steps: 0.0017425049859096785\n","Training loss per 100 training steps: 0.0022926662428805833\n","Training loss per 100 training steps: 0.0026688143656326286\n","Training loss epoch: 0.0026236033747270545\n","Training accuracy epoch: 0.9991996756783097\n","Validating model...\n","Validation Loss: 0.01337223272102641\n","Validation Accuracy: 0.996905856063942\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0009221603395417333\n","Training loss per 100 training steps: 0.0023299389946566072\n","Training loss per 100 training steps: 0.0021778474510033424\n","Training loss per 100 training steps: 0.0024293200457822517\n","Training loss epoch: 0.002455187047462326\n","Training accuracy epoch: 0.9992305051852652\n","Validating model...\n","Validation Loss: 0.017150566179355207\n","Validation Accuracy: 0.9958221827710904\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 58.35724154999989 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.010835664405021816\n","Validation Accuracy: 0.9965182260339511\n","Validation duration: 0.21376971666686587 minutes\n","F1-score (test): 97.6%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.99      0.98      1238\n","\n","   micro avg       0.97      0.99      0.98      1238\n","   macro avg       0.97      0.99      0.98      1238\n","weighted avg       0.97      0.99      0.98      1238\n","\n","!!!!!! Starting model number 8 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 5451\n","Points in y_train after augmentation: 5451\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.1039149761199951\n","Training loss per 100 training steps: 0.0880401442795623\n","Training loss per 100 training steps: 0.05326251205941894\n","Training loss per 100 training steps: 0.03974987511976353\n","Training loss epoch: 0.036581305437038525\n","Training accuracy epoch: 0.9879446048354575\n","Validating model...\n","Validation Loss: 0.010804392678740745\n","Validation Accuracy: 0.9969716522626235\n","Training epoch: 2\n","Training loss per 100 training steps: 0.019211480394005775\n","Training loss per 100 training steps: 0.008442958933013113\n","Training loss per 100 training steps: 0.008346075002556963\n","Training loss per 100 training steps: 0.007838175563022581\n","Training loss epoch: 0.008048349061654471\n","Training accuracy epoch: 0.9975703771049202\n","Validating model...\n","Validation Loss: 0.014464245033672168\n","Validation Accuracy: 0.9961488203529456\n","Training epoch: 3\n","Training loss per 100 training steps: 0.004964515566825867\n","Training loss per 100 training steps: 0.005175988000557103\n","Training loss per 100 training steps: 0.007094992531766995\n","Training loss per 100 training steps: 0.006953013600995052\n","Training loss epoch: 0.006611012497992266\n","Training accuracy epoch: 0.9980143693201563\n","Validating model...\n","Validation Loss: 0.015724249145499754\n","Validation Accuracy: 0.996773388855552\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0008205610793083906\n","Training loss per 100 training steps: 0.004119513174265365\n","Training loss per 100 training steps: 0.004140056623015622\n","Training loss per 100 training steps: 0.004078099990224519\n","Training loss epoch: 0.004328716981745\n","Training accuracy epoch: 0.9986247714188821\n","Validating model...\n","Validation Loss: 0.015690803056627158\n","Validation Accuracy: 0.9961007694680619\n","Training epoch: 5\n","Training loss per 100 training steps: 0.013393518514931202\n","Training loss per 100 training steps: 0.003498722808991702\n","Training loss per 100 training steps: 0.003232126995037595\n","Training loss per 100 training steps: 0.0031380256262240063\n","Training loss epoch: 0.0029468321974752496\n","Training accuracy epoch: 0.9990815458033921\n","Validating model...\n","Validation Loss: 0.014658303320954604\n","Validation Accuracy: 0.9973785019514458\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0012839382980018854\n","Training loss per 100 training steps: 0.000882675495172452\n","Training loss per 100 training steps: 0.0013959489465808143\n","Training loss per 100 training steps: 0.0016351503342663888\n","Training loss epoch: 0.0016014028975015978\n","Training accuracy epoch: 0.9995271032697725\n","Validating model...\n","Validation Loss: 0.014616011113892975\n","Validation Accuracy: 0.9973563337324065\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 50.00589341666661 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.016622364399760652\n","Validation Accuracy: 0.994857990809428\n","Validation duration: 0.21352158333344656 minutes\n","F1-score (test): 96.9%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.95      0.98      0.97      1238\n","\n","   micro avg       0.95      0.98      0.97      1238\n","   macro avg       0.95      0.98      0.97      1238\n","weighted avg       0.95      0.98      0.97      1238\n","\n","!!!!!! Starting model number 9 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 5451\n","Points in y_train after augmentation: 5451\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.0015699863433838\n","Training loss per 100 training steps: 0.0848382944195061\n","Training loss per 100 training steps: 0.052189826817061774\n","Training loss per 100 training steps: 0.04001040295198826\n","Training loss epoch: 0.03704055644318467\n","Training accuracy epoch: 0.9882924101086578\n","Validating model...\n","Validation Loss: 0.013710765522860345\n","Validation Accuracy: 0.9959111557225742\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0028344227466732264\n","Training loss per 100 training steps: 0.008239570050154545\n","Training loss per 100 training steps: 0.008806310681538166\n","Training loss per 100 training steps: 0.00873656148528773\n","Training loss epoch: 0.008399319130455518\n","Training accuracy epoch: 0.9974281156092737\n","Validating model...\n","Validation Loss: 0.01233010603096946\n","Validation Accuracy: 0.996202562846498\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0010113428579643369\n","Training loss per 100 training steps: 0.0043970997333480505\n","Training loss per 100 training steps: 0.004475011356639449\n","Training loss per 100 training steps: 0.004854741967540386\n","Training loss epoch: 0.005313465726137492\n","Training accuracy epoch: 0.9984185059658385\n","Validating model...\n","Validation Loss: 0.010207834544070508\n","Validation Accuracy: 0.9972152892420841\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0053540742956101894\n","Training loss per 100 training steps: 0.006101877043902007\n","Training loss per 100 training steps: 0.005475783728503863\n","Training loss per 100 training steps: 0.005363797041596427\n","Training loss epoch: 0.005146307964074218\n","Training accuracy epoch: 0.9984572188110954\n","Validating model...\n","Validation Loss: 0.01150091651652474\n","Validation Accuracy: 0.9974074221989729\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0004816398140974343\n","Training loss per 100 training steps: 0.0035100240308772956\n","Training loss per 100 training steps: 0.004200068061477192\n","Training loss per 100 training steps: 0.004405992051384039\n","Training loss epoch: 0.004565145879547088\n","Training accuracy epoch: 0.9985738350546678\n","Validating model...\n","Validation Loss: 0.009495492366026849\n","Validation Accuracy: 0.997410292136922\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0003944865020457655\n","Training loss per 100 training steps: 0.006151672259767282\n","Training loss per 100 training steps: 0.00557500762976874\n","Training loss per 100 training steps: 0.004736733046259562\n","Training loss epoch: 0.004559386792473899\n","Training accuracy epoch: 0.998632639171032\n","Validating model...\n","Validation Loss: 0.012432189838450756\n","Validation Accuracy: 0.9970663127598075\n","Training epoch: 7\n","Training loss per 100 training steps: 0.006387177389115095\n","Training loss per 100 training steps: 0.002256235884866184\n","Training loss per 100 training steps: 0.002217328144011229\n","Training loss per 100 training steps: 0.0022870423799577714\n","Training loss epoch: 0.0022022247636771645\n","Training accuracy epoch: 0.9993194854599766\n","Validating model...\n","Validation Loss: 0.014265549417835982\n","Validation Accuracy: 0.9974949895023298\n","Training epoch: 8\n","Training loss per 100 training steps: 0.005198614206165075\n","Training loss per 100 training steps: 0.0015149624130680252\n","Training loss per 100 training steps: 0.0017020791243222127\n","Training loss per 100 training steps: 0.0018271394062904193\n","Training loss epoch: 0.0018955447885940207\n","Training accuracy epoch: 0.9994455092316529\n","Validating model...\n","Validation Loss: 0.012600573030145565\n","Validation Accuracy: 0.9977341802450422\n","Training epoch: 9\n","Training loss per 100 training steps: 0.00017121103883255273\n","Training loss per 100 training steps: 0.002035790426186332\n","Training loss per 100 training steps: 0.0031083595463111233\n","Training loss per 100 training steps: 0.0031559888883932814\n","Training loss epoch: 0.002975334823513069\n","Training accuracy epoch: 0.9990728369021572\n","Validating model...\n","Validation Loss: 0.01361808918660418\n","Validation Accuracy: 0.9976869099333089\n","Training epoch: 10\n","Training loss per 100 training steps: 0.007203888613730669\n","Training loss per 100 training steps: 0.0015503281435782566\n","Training loss per 100 training steps: 0.0017131797476259403\n","Training loss per 100 training steps: 0.0020442706784183657\n","Training loss epoch: 0.002399106976759691\n","Training accuracy epoch: 0.9992699065015086\n","Validating model...\n","Validation Loss: 0.00943971086547078\n","Validation Accuracy: 0.9968241777824817\n","Training epoch: 11\n","Training loss per 100 training steps: 0.0003614283923525363\n","Training loss per 100 training steps: 0.0022365945964212537\n","Training loss per 100 training steps: 0.00205092444496165\n","Training loss per 100 training steps: 0.0028816811304251885\n","Training loss epoch: 0.003030533537557031\n","Training accuracy epoch: 0.9992036881785245\n","Validating model...\n","Validation Loss: 0.013349809457092002\n","Validation Accuracy: 0.997502168773172\n","Training epoch: 12\n","Training loss per 100 training steps: 0.0007747475174255669\n","Training loss per 100 training steps: 0.00264570417544242\n","Training loss per 100 training steps: 0.0026362826893860775\n","Training loss per 100 training steps: 0.0025561285256479704\n","Training loss epoch: 0.0025494387315717986\n","Training accuracy epoch: 0.9992978217170656\n","Validating model...\n","Validation Loss: 0.012234074067930038\n","Validation Accuracy: 0.9965663509030117\n","Training epoch: 13\n","Training loss per 100 training steps: 0.0015946525381878018\n","Training loss per 100 training steps: 0.0018029573554963238\n","Training loss per 100 training steps: 0.0017704190935302307\n","Training loss per 100 training steps: 0.0017682568689382232\n","Training loss epoch: 0.0017592899586970896\n","Training accuracy epoch: 0.9994425219739538\n","Validating model...\n","Validation Loss: 0.01753176166844891\n","Validation Accuracy: 0.996879710510729\n","Training epoch: 14\n","Training loss per 100 training steps: 0.002629393944516778\n","Training loss per 100 training steps: 0.0023878992838530897\n","Training loss per 100 training steps: 0.003331963843605203\n","Training loss per 100 training steps: 0.0032020309082505275\n","Training loss epoch: 0.003157013563827671\n","Training accuracy epoch: 0.9990800809607158\n","Validating model...\n","Validation Loss: 0.022892494107509265\n","Validation Accuracy: 0.9960890952325717\n","Training epoch: 15\n","Training loss per 100 training steps: 0.000550455879420042\n","Training loss per 100 training steps: 0.0015448115398000238\n","Training loss per 100 training steps: 0.001783299667367466\n","Training loss per 100 training steps: 0.0016762776028804258\n","Training loss epoch: 0.0016282599589326884\n","Training accuracy epoch: 0.9995295169892525\n","Validating model...\n","Validation Loss: 0.017283032950564076\n","Validation Accuracy: 0.9968391642764536\n","Training epoch: 16\n","Patience limit reached\n","Training duration: 125.08192723333316 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.015458801826146859\n","Validation Accuracy: 0.9958246843593711\n","Validation duration: 0.21385238333338444 minutes\n","F1-score (test): 97.8%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.99      0.98      1238\n","\n","   micro avg       0.97      0.99      0.98      1238\n","   macro avg       0.97      0.99      0.98      1238\n","weighted avg       0.97      0.99      0.98      1238\n","\n","!!!!!! Starting model number 10 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 5451\n","Points in y_train after augmentation: 5451\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.3181264400482178\n","Training loss per 100 training steps: 0.09620997256663914\n","Training loss per 100 training steps: 0.059203597167923824\n","Training loss per 100 training steps: 0.04431554515408259\n","Training loss epoch: 0.040394394452304\n","Training accuracy epoch: 0.9866250477825074\n","Validating model...\n","Validation Loss: 0.009749448489552984\n","Validation Accuracy: 0.9969708787380727\n","Training epoch: 2\n","Training loss per 100 training steps: 0.011488474905490875\n","Training loss per 100 training steps: 0.007915429523131708\n","Training loss per 100 training steps: 0.007326969362862538\n","Training loss per 100 training steps: 0.007802421888992101\n","Training loss epoch: 0.00777041236609678\n","Training accuracy epoch: 0.9976052821209906\n","Validating model...\n","Validation Loss: 0.008915399519970552\n","Validation Accuracy: 0.997053299460704\n","Training epoch: 3\n","Training loss per 100 training steps: 0.050519347190856934\n","Training loss per 100 training steps: 0.004688116613173821\n","Training loss per 100 training steps: 0.005000686460995319\n","Training loss per 100 training steps: 0.005166050336753758\n","Training loss epoch: 0.005065078685118863\n","Training accuracy epoch: 0.998418656587121\n","Validating model...\n","Validation Loss: 0.009672277563714445\n","Validation Accuracy: 0.997198477820755\n","Training epoch: 4\n","Training loss per 100 training steps: 0.008791958913207054\n","Training loss per 100 training steps: 0.003104861806181956\n","Training loss per 100 training steps: 0.0036328577590930802\n","Training loss per 100 training steps: 0.00563660227739352\n","Training loss epoch: 0.005462587011871003\n","Training accuracy epoch: 0.9984263850548996\n","Validating model...\n","Validation Loss: 0.010096815429971599\n","Validation Accuracy: 0.9971973379891855\n","Training epoch: 5\n","Training loss per 100 training steps: 0.001124776666983962\n","Training loss per 100 training steps: 0.0024413583627446683\n","Training loss per 100 training steps: 0.003121756677329309\n","Training loss per 100 training steps: 0.0029916594979406234\n","Training loss epoch: 0.003049107062549445\n","Training accuracy epoch: 0.9990401654001189\n","Validating model...\n","Validation Loss: 0.01154129019968899\n","Validation Accuracy: 0.9975810674844584\n","Training epoch: 6\n","Training loss per 100 training steps: 0.002080382779240608\n","Training loss per 100 training steps: 0.00276250714516281\n","Training loss per 100 training steps: 0.0030172847873654067\n","Training loss per 100 training steps: 0.002945604741688782\n","Training loss epoch: 0.003004792801199564\n","Training accuracy epoch: 0.9990684455853069\n","Validating model...\n","Validation Loss: 0.011403884136165115\n","Validation Accuracy: 0.9974225200896735\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0010390152456238866\n","Training loss per 100 training steps: 0.0013537335201336007\n","Training loss per 100 training steps: 0.001826362384462078\n","Training loss per 100 training steps: 0.0017697618828346354\n","Training loss epoch: 0.0017124762686450497\n","Training accuracy epoch: 0.9994509782072782\n","Validating model...\n","Validation Loss: 0.013433852495533452\n","Validation Accuracy: 0.9976888415692015\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 58.35524845000012 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.011336948292713108\n","Validation Accuracy: 0.9962139539452303\n","Validation duration: 0.21374031666685672 minutes\n","F1-score (test): 97.4%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.98      0.97      1238\n","\n","   micro avg       0.97      0.98      0.97      1238\n","   macro avg       0.97      0.98      0.97      1238\n","weighted avg       0.97      0.98      0.97      1238\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 2\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"Zjhn7-LqHri0"},{"cell_type":"code","execution_count":null,"metadata":{"id":"TTDq-xbgHqXQ","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["ec3e6c1415ff4ac5a08cf226bce44f8e","574d72c0bec14609a0dc6823e50c2721","df24b7b3debf4164ad3448edb54221bf","70b0df1a6128407991ceb39b0d74d6e5","754f280f826545fea18ae7dcbc17a576","b5aa35d876f340cabcb7e3cff020f61b","850b8bc1bb8b46f1b3e983374fde319a","87dee83e0cde44a480ee5af2b7ebc2d7","cc3d4a91d7cc4b9dae3792106a6bb7b0","4767ee72dca94b828a247d1ecc47e774","7405d6e3e12f47c0a8b695c335bba561"]},"outputId":"cbc7435c-b9fc-4af9-e053-dfe797ededc0"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 500% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ec3e6c1415ff4ac5a08cf226bce44f8e","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/714M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 10902\n","Points in y_train after augmentation: 10902\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.1834180355072021\n","Training loss per 100 training steps: 0.07663882764443608\n","Training loss per 100 training steps: 0.04766841344442682\n","Training loss per 100 training steps: 0.03625266571286323\n","Training loss per 100 training steps: 0.02941035496450129\n","Training loss per 100 training steps: 0.025278583270585454\n","Training loss per 100 training steps: 0.022451369387265017\n","Training loss epoch: 0.02064101888134678\n","Training accuracy epoch: 0.9931530195397992\n","Validating model...\n","Validation Loss: 0.012638748780037054\n","Validation Accuracy: 0.9964672416920474\n","Training epoch: 2\n","Training loss per 100 training steps: 0.001841390272602439\n","Training loss per 100 training steps: 0.0053101131697715544\n","Training loss per 100 training steps: 0.005778610590058819\n","Training loss per 100 training steps: 0.005368224333593099\n","Training loss per 100 training steps: 0.005488237710136914\n","Training loss per 100 training steps: 0.005617895573402008\n","Training loss per 100 training steps: 0.005614632423888674\n","Training loss epoch: 0.005719439766824753\n","Training accuracy epoch: 0.9983268254603297\n","Validating model...\n","Validation Loss: 0.012533196278603836\n","Validation Accuracy: 0.9960363750277101\n","Training epoch: 3\n","Training loss per 100 training steps: 0.009637800976634026\n","Training loss per 100 training steps: 0.0025997751554944506\n","Training loss per 100 training steps: 0.0028093780870335084\n","Training loss per 100 training steps: 0.00352579433733189\n","Training loss per 100 training steps: 0.0038730174508559787\n","Training loss per 100 training steps: 0.003981361354193153\n","Training loss per 100 training steps: 0.004923642684385268\n","Training loss epoch: 0.005012369876594062\n","Training accuracy epoch: 0.9985053802223505\n","Validating model...\n","Validation Loss: 0.01186590583252144\n","Validation Accuracy: 0.996923848604357\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0027915393002331257\n","Training loss per 100 training steps: 0.005001972942157202\n","Training loss per 100 training steps: 0.004319732728672263\n","Training loss per 100 training steps: 0.0042675279802396205\n","Training loss per 100 training steps: 0.004030358180825896\n","Training loss per 100 training steps: 0.0038975256905318103\n","Training loss per 100 training steps: 0.0037561039702110935\n","Training loss epoch: 0.003813926813273021\n","Training accuracy epoch: 0.9988822024177191\n","Validating model...\n","Validation Loss: 0.014262909023229787\n","Validation Accuracy: 0.9972747036292072\n","Training epoch: 5\n","Training loss per 100 training steps: 0.00837842095643282\n","Training loss per 100 training steps: 0.0023221316383065225\n","Training loss per 100 training steps: 0.002004425342497213\n","Training loss per 100 training steps: 0.002102521386030312\n","Training loss per 100 training steps: 0.002167753894878897\n","Training loss per 100 training steps: 0.0022167681202984544\n","Training loss per 100 training steps: 0.0023413914241245948\n","Training loss epoch: 0.002406517965729346\n","Training accuracy epoch: 0.9992662259817241\n","Validating model...\n","Validation Loss: 0.01655818766076187\n","Validation Accuracy: 0.9971763775020854\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0001373436243738979\n","Training loss per 100 training steps: 0.004407082742689832\n","Training loss per 100 training steps: 0.0035309161578866294\n","Training loss per 100 training steps: 0.0033935355412453936\n","Training loss per 100 training steps: 0.0035685092208084263\n","Training loss per 100 training steps: 0.0040217784162577775\n","Training loss per 100 training steps: 0.004397167500991571\n","Training loss epoch: 0.004240546911352149\n","Training accuracy epoch: 0.9987656486645243\n","Validating model...\n","Validation Loss: 0.01338234962341154\n","Validation Accuracy: 0.9970336166506025\n","Training epoch: 7\n","Training loss per 100 training steps: 0.004745448939502239\n","Training loss per 100 training steps: 0.002831273760484061\n","Training loss per 100 training steps: 0.0028307783515936816\n","Training loss per 100 training steps: 0.002562329101839286\n","Training loss per 100 training steps: 0.002365610854332926\n","Training loss per 100 training steps: 0.002187616465389855\n","Training loss per 100 training steps: 0.0020716022078618597\n","Training loss epoch: 0.0020246536488280724\n","Training accuracy epoch: 0.9993742447341879\n","Validating model...\n","Validation Loss: 0.01675821465687477\n","Validation Accuracy: 0.9971875391019538\n","Training epoch: 8\n","Training loss per 100 training steps: 0.0007977251661941409\n","Training loss per 100 training steps: 0.0016269464220674155\n","Training loss per 100 training steps: 0.0015893369844124394\n","Training loss per 100 training steps: 0.0017513169072921047\n","Training loss per 100 training steps: 0.0016407459876979812\n","Training loss per 100 training steps: 0.0016075283697527575\n","Training loss per 100 training steps: 0.0015796771825469132\n","Training loss epoch: 0.0016703873073863212\n","Training accuracy epoch: 0.9995054823345231\n","Validating model...\n","Validation Loss: 0.016124911251955337\n","Validation Accuracy: 0.997043085536671\n","Training epoch: 9\n","Patience limit reached\n","Training duration: 140.40371105 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.016397624344487365\n","Validation Accuracy: 0.9965521321662171\n","Validation duration: 0.23553300000000188 minutes\n","F1-score (test): 97.6%\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.98      0.98      1238\n","\n","   micro avg       0.97      0.98      0.98      1238\n","   macro avg       0.97      0.98      0.98      1238\n","weighted avg       0.97      0.98      0.98      1238\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 10902\n","Points in y_train after augmentation: 10902\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.0914033651351929\n","Training loss per 100 training steps: 0.09581667433797132\n","Training loss per 100 training steps: 0.05684552553100558\n","Training loss per 100 training steps: 0.04231342746361014\n","Training loss per 100 training steps: 0.034435688833557444\n","Training loss per 100 training steps: 0.030091154118609464\n","Training loss per 100 training steps: 0.02648023087730842\n","Training loss epoch: 0.024248836152962222\n","Training accuracy epoch: 0.9924329038306243\n","Validating model...\n","Validation Loss: 0.009291777148194211\n","Validation Accuracy: 0.9972099405816679\n","Training epoch: 2\n","Training loss per 100 training steps: 0.006115292198956013\n","Training loss per 100 training steps: 0.005469338278693036\n","Training loss per 100 training steps: 0.005363072162167985\n","Training loss per 100 training steps: 0.006251679990350491\n","Training loss per 100 training steps: 0.006230411498544347\n","Training loss per 100 training steps: 0.006151585706833568\n","Training loss per 100 training steps: 0.006000618417825768\n","Training loss epoch: 0.0059278844926991744\n","Training accuracy epoch: 0.9981847970648836\n","Validating model...\n","Validation Loss: 0.012458358215683672\n","Validation Accuracy: 0.9971159041161455\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0010817574802786112\n","Training loss per 100 training steps: 0.0035106850461515664\n","Training loss per 100 training steps: 0.004975629584190195\n","Training loss per 100 training steps: 0.004775548057144885\n","Training loss per 100 training steps: 0.00447211364574688\n","Training loss per 100 training steps: 0.004718926632037352\n","Training loss per 100 training steps: 0.004650892770222831\n","Training loss epoch: 0.004453224213648355\n","Training accuracy epoch: 0.9986312406838161\n","Validating model...\n","Validation Loss: 0.015220469347782671\n","Validation Accuracy: 0.9962078884279968\n","Training epoch: 4\n","Training loss per 100 training steps: 0.00042190696694888175\n","Training loss per 100 training steps: 0.002576881492600343\n","Training loss per 100 training steps: 0.0025759857882115995\n","Training loss per 100 training steps: 0.002294361526556499\n","Training loss per 100 training steps: 0.002257658504057058\n","Training loss per 100 training steps: 0.0023061362139007195\n","Training loss per 100 training steps: 0.0027142561758438763\n","Training loss epoch: 0.0028579547380421875\n","Training accuracy epoch: 0.9991090829688388\n","Validating model...\n","Validation Loss: 0.010978045990971927\n","Validation Accuracy: 0.9973888043959546\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0031681011896580458\n","Training loss per 100 training steps: 0.0012730301962862837\n","Training loss per 100 training steps: 0.0018209109715898741\n","Training loss per 100 training steps: 0.002371207378550678\n","Training loss per 100 training steps: 0.0027220129896226184\n","Training loss per 100 training steps: 0.002850819255429029\n","Training loss per 100 training steps: 0.002912293018820365\n","Training loss epoch: 0.0028901794628495405\n","Training accuracy epoch: 0.9990949762878049\n","Validating model...\n","Validation Loss: 0.013361345094034775\n","Validation Accuracy: 0.9978546205599022\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0016223714919760823\n","Training loss per 100 training steps: 0.001743027899078022\n","Training loss per 100 training steps: 0.001998530862955301\n","Training loss per 100 training steps: 0.002034859803743197\n","Training loss per 100 training steps: 0.0021060035494185215\n","Training loss per 100 training steps: 0.0024191632179869616\n","Training loss per 100 training steps: 0.002486439679712313\n","Training loss epoch: 0.0024476753237343252\n","Training accuracy epoch: 0.999232355836456\n","Validating model...\n","Validation Loss: 0.010957830693119572\n","Validation Accuracy: 0.9970428572716866\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 105.36394916666669 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.012273870590433944\n","Validation Accuracy: 0.9965951162057021\n","Validation duration: 0.24034841666671128 minutes\n","F1-score (test): 98.1%\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.98      0.99      0.98      1238\n","\n","   micro avg       0.98      0.99      0.98      1238\n","   macro avg       0.98      0.99      0.98      1238\n","weighted avg       0.98      0.99      0.98      1238\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 10902\n","Points in y_train after augmentation: 10902\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.1921813488006592\n","Training loss per 100 training steps: 0.09430119592585776\n","Training loss per 100 training steps: 0.05685549689716293\n","Training loss per 100 training steps: 0.042893020553356566\n","Training loss per 100 training steps: 0.0349886077241345\n","Training loss per 100 training steps: 0.029979070203105536\n","Training loss per 100 training steps: 0.02643996853820713\n","Training loss epoch: 0.024229997779752054\n","Training accuracy epoch: 0.9921047868140074\n","Validating model...\n","Validation Loss: 0.010846227252235016\n","Validation Accuracy: 0.9969544128482749\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0013052847934886813\n","Training loss per 100 training steps: 0.005676719171310876\n","Training loss per 100 training steps: 0.005951176566695586\n","Training loss per 100 training steps: 0.005642861329307981\n","Training loss per 100 training steps: 0.005423458952089758\n","Training loss per 100 training steps: 0.0051975216813366434\n","Training loss per 100 training steps: 0.00520146791313286\n","Training loss epoch: 0.00527613350994461\n","Training accuracy epoch: 0.9983319916253016\n","Validating model...\n","Validation Loss: 0.010317175651531821\n","Validation Accuracy: 0.9976356749794777\n","Training epoch: 3\n","Training loss per 100 training steps: 0.000887486559804529\n","Training loss per 100 training steps: 0.004743478118873081\n","Training loss per 100 training steps: 0.004812238989667202\n","Training loss per 100 training steps: 0.004617948292132291\n","Training loss per 100 training steps: 0.004306715434391581\n","Training loss per 100 training steps: 0.0044540271966885675\n","Training loss per 100 training steps: 0.004278499701559817\n","Training loss epoch: 0.004080333373196716\n","Training accuracy epoch: 0.9987637720231632\n","Validating model...\n","Validation Loss: 0.009297337708717567\n","Validation Accuracy: 0.9976870881572676\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0033286267425864935\n","Training loss per 100 training steps: 0.004989676552105437\n","Training loss per 100 training steps: 0.004563947565507825\n","Training loss per 100 training steps: 0.012615696264452539\n","Training loss per 100 training steps: 0.011059719397967445\n","Training loss per 100 training steps: 0.009971027467717015\n","Training loss per 100 training steps: 0.008979540739311898\n","Training loss epoch: 0.008362310724589827\n","Training accuracy epoch: 0.9977485191311729\n","Validating model...\n","Validation Loss: 0.010884059122223075\n","Validation Accuracy: 0.9971015279173401\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0004149307787884027\n","Training loss per 100 training steps: 0.003183350827150729\n","Training loss per 100 training steps: 0.0029115729280171187\n","Training loss per 100 training steps: 0.002965602188941982\n","Training loss per 100 training steps: 0.003422669689059246\n","Training loss per 100 training steps: 0.003401732039731972\n","Training loss per 100 training steps: 0.0033073945648634277\n","Training loss epoch: 0.003189255401802019\n","Training accuracy epoch: 0.999076993846717\n","Validating model...\n","Validation Loss: 0.014802226636372021\n","Validation Accuracy: 0.997437187381\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00011643282778095454\n","Training loss per 100 training steps: 0.002294571000963362\n","Training loss per 100 training steps: 0.002104405356770606\n","Training loss per 100 training steps: 0.0022091088729550476\n","Training loss per 100 training steps: 0.002409426737988967\n","Training loss per 100 training steps: 0.0024730664368914864\n","Training loss per 100 training steps: 0.002406906797019631\n","Training loss epoch: 0.0025021673969401604\n","Training accuracy epoch: 0.9992209983610402\n","Validating model...\n","Validation Loss: 0.017818952978164555\n","Validation Accuracy: 0.996542932642545\n","Training epoch: 7\n","Training loss per 100 training steps: 0.00024675618624314666\n","Training loss per 100 training steps: 0.002907047803451896\n","Training loss per 100 training steps: 0.0028629402673342966\n","Training loss per 100 training steps: 0.0028760741800660104\n","Training loss per 100 training steps: 0.0028242426877458505\n","Training loss per 100 training steps: 0.0026797133390475407\n","Training loss per 100 training steps: 0.0026361195581309513\n","Training loss epoch: 0.002513718556429679\n","Training accuracy epoch: 0.999228591254932\n","Validating model...\n","Validation Loss: 0.013018033009237635\n","Validation Accuracy: 0.9972665609060759\n","Training epoch: 8\n","Training loss per 100 training steps: 0.0001933353196363896\n","Training loss per 100 training steps: 0.001301638560395833\n","Training loss per 100 training steps: 0.0012204873431105466\n","Training loss per 100 training steps: 0.001292952786187082\n","Training loss per 100 training steps: 0.0014754133803320398\n","Training loss per 100 training steps: 0.001537984148550701\n","Training loss per 100 training steps: 0.001635114808001547\n","Training loss epoch: 0.0016126964023590296\n","Training accuracy epoch: 0.999530113695317\n","Validating model...\n","Validation Loss: 0.015259804782198487\n","Validation Accuracy: 0.9974634430149718\n","Training epoch: 9\n","Patience limit reached\n","Training duration: 140.5165863833334 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.01588794138084874\n","Validation Accuracy: 0.9963136075618829\n","Validation duration: 0.236876283333307 minutes\n","F1-score (test): 97.6%\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.99      0.98      1238\n","\n","   micro avg       0.97      0.99      0.98      1238\n","   macro avg       0.97      0.99      0.98      1238\n","weighted avg       0.97      0.99      0.98      1238\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 10902\n","Points in y_train after augmentation: 10902\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.0872682332992554\n","Training loss per 100 training steps: 0.08688923111185431\n","Training loss per 100 training steps: 0.0519223071505033\n","Training loss per 100 training steps: 0.03924176339570594\n","Training loss per 100 training steps: 0.03253878949894024\n","Training loss per 100 training steps: 0.028160132858121467\n","Training loss per 100 training steps: 0.02530754522727291\n","Training loss epoch: 0.023193955815843062\n","Training accuracy epoch: 0.9923957755255072\n","Validating model...\n","Validation Loss: 0.019639977610495407\n","Validation Accuracy: 0.9954850964599541\n","Training epoch: 2\n","Training loss per 100 training steps: 0.023626279085874557\n","Training loss per 100 training steps: 0.008270848363794681\n","Training loss per 100 training steps: 0.0076099507131588305\n","Training loss per 100 training steps: 0.006628463529858682\n","Training loss per 100 training steps: 0.006275023829654681\n","Training loss per 100 training steps: 0.005974781944566572\n","Training loss per 100 training steps: 0.005900939972218926\n","Training loss epoch: 0.00568060604222986\n","Training accuracy epoch: 0.9983246060113801\n","Validating model...\n","Validation Loss: 0.013570657453133858\n","Validation Accuracy: 0.9975452339595651\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0004344618646427989\n","Training loss per 100 training steps: 0.0030806976152090632\n","Training loss per 100 training steps: 0.0038001535434868945\n","Training loss per 100 training steps: 0.0042570973650755\n","Training loss per 100 training steps: 0.004174272572819696\n","Training loss per 100 training steps: 0.004352469084958198\n","Training loss per 100 training steps: 0.004480800655161607\n","Training loss epoch: 0.004491322137826106\n","Training accuracy epoch: 0.9986707130550142\n","Validating model...\n","Validation Loss: 0.010812113371988138\n","Validation Accuracy: 0.9973417374233653\n","Training epoch: 4\n","Training loss per 100 training steps: 0.004208370577543974\n","Training loss per 100 training steps: 0.00463880039636267\n","Training loss per 100 training steps: 0.0038761925657783097\n","Training loss per 100 training steps: 0.0035908365280313674\n","Training loss per 100 training steps: 0.0033799724264271867\n","Training loss per 100 training steps: 0.0036809624749827878\n","Training loss per 100 training steps: 0.0035050470625338404\n","Training loss epoch: 0.003487200966998933\n","Training accuracy epoch: 0.998915011395077\n","Validating model...\n","Validation Loss: 0.011489593567863008\n","Validation Accuracy: 0.9975099317611671\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0005947957979515195\n","Training loss per 100 training steps: 0.0018281341020489287\n","Training loss per 100 training steps: 0.0025507582116128403\n","Training loss per 100 training steps: 0.0027833192546788503\n","Training loss per 100 training steps: 0.002856365504382559\n","Training loss per 100 training steps: 0.0030681433005980752\n","Training loss per 100 training steps: 0.003032216772742129\n","Training loss epoch: 0.003198683409902936\n","Training accuracy epoch: 0.9990341060035229\n","Validating model...\n","Validation Loss: 0.010518414374451996\n","Validation Accuracy: 0.9978803332141778\n","Training epoch: 6\n","Training loss per 100 training steps: 0.010151279158890247\n","Training loss per 100 training steps: 0.003348615877851867\n","Training loss per 100 training steps: 0.0035324343777904856\n","Training loss per 100 training steps: 0.003485685356160602\n","Training loss per 100 training steps: 0.0032830917072551938\n","Training loss per 100 training steps: 0.0032257392468925325\n","Training loss per 100 training steps: 0.0032527597725307417\n","Training loss epoch: 0.0030394960016714525\n","Training accuracy epoch: 0.9991089667548918\n","Validating model...\n","Validation Loss: 0.014099483717343122\n","Validation Accuracy: 0.9970946016426342\n","Training epoch: 7\n","Training loss per 100 training steps: 0.000497543893288821\n","Training loss per 100 training steps: 0.002033650184523932\n","Training loss per 100 training steps: 0.002339432041734296\n","Training loss per 100 training steps: 0.0021756165559876223\n","Training loss per 100 training steps: 0.0021070193212298343\n","Training loss per 100 training steps: 0.002278468368929393\n","Training loss per 100 training steps: 0.0027743992665732694\n","Training loss epoch: 0.0027380517771170725\n","Training accuracy epoch: 0.9992681789996778\n","Validating model...\n","Validation Loss: 0.013688112699431562\n","Validation Accuracy: 0.997690820088865\n","Training epoch: 8\n","Training loss per 100 training steps: 0.007865987718105316\n","Training loss per 100 training steps: 0.0017242090293756078\n","Training loss per 100 training steps: 0.0013764665428013599\n","Training loss per 100 training steps: 0.001654697313694799\n","Training loss per 100 training steps: 0.0019108584628862047\n","Training loss per 100 training steps: 0.0019267067203321505\n","Training loss per 100 training steps: 0.0020122847171918866\n","Training loss epoch: 0.002116725551269233\n","Training accuracy epoch: 0.9993842017745126\n","Validating model...\n","Validation Loss: 0.013359270714274663\n","Validation Accuracy: 0.9976693253489883\n","Training epoch: 9\n","Training loss per 100 training steps: 8.01992355263792e-05\n","Training loss per 100 training steps: 0.0010531806614074745\n","Training loss per 100 training steps: 0.0021475111864660973\n","Training loss per 100 training steps: 0.0029035034542260313\n","Training loss per 100 training steps: 0.003041403452106467\n","Training loss per 100 training steps: 0.0028501688377505496\n","Training loss per 100 training steps: 0.0027174738805360492\n","Training loss epoch: 0.0025723580079168927\n","Training accuracy epoch: 0.9992410042507904\n","Validating model...\n","Validation Loss: 0.014134128965451964\n","Validation Accuracy: 0.9976711325948012\n","Training epoch: 10\n","Training loss per 100 training steps: 0.0006574316066689789\n","Training loss per 100 training steps: 0.0020440568810900545\n","Training loss per 100 training steps: 0.0016881225276743474\n","Training loss per 100 training steps: 0.0017146679538532633\n","Training loss per 100 training steps: 0.0016465097658583364\n","Training loss per 100 training steps: 0.0018412845479061305\n","Training loss per 100 training steps: 0.0025380021933371377\n","Training loss epoch: 0.0026907862355612794\n","Training accuracy epoch: 0.9992231247034514\n","Validating model...\n","Validation Loss: 0.015388657586819525\n","Validation Accuracy: 0.9972384764530373\n","Training epoch: 11\n","Patience limit reached\n","Training duration: 174.70478439999994 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.01741930882174832\n","Validation Accuracy: 0.9950330498026251\n","Validation duration: 0.23605458333331625 minutes\n","F1-score (test): 96.9%\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.97      0.97      1238\n","\n","   micro avg       0.97      0.97      0.97      1238\n","   macro avg       0.97      0.97      0.97      1238\n","weighted avg       0.97      0.97      0.97      1238\n","\n","!!!!!! Starting model number 5 !!!!!!\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 10902\n","Points in y_train after augmentation: 10902\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.0427178144454956\n","Training loss per 100 training steps: 0.08546800123490762\n","Training loss per 100 training steps: 0.05184514643346418\n","Training loss per 100 training steps: 0.039292680729254834\n","Training loss per 100 training steps: 0.03272184130371063\n","Training loss per 100 training steps: 0.027989120445815575\n","Training loss per 100 training steps: 0.02518825675903226\n","Training loss epoch: 0.02364186233946032\n","Training accuracy epoch: 0.9924986318373363\n","Validating model...\n","Validation Loss: 0.016725696967027727\n","Validation Accuracy: 0.9947445039004046\n","Training epoch: 2\n","Training loss per 100 training steps: 0.018943950533866882\n","Training loss per 100 training steps: 0.00864537837073705\n","Training loss per 100 training steps: 0.007183129538084607\n","Training loss per 100 training steps: 0.006450707896717397\n","Training loss per 100 training steps: 0.006452853594329777\n","Training loss per 100 training steps: 0.006059324009015881\n","Training loss per 100 training steps: 0.005881574169438977\n","Training loss epoch: 0.005700821242509601\n","Training accuracy epoch: 0.9982197493779316\n","Validating model...\n","Validation Loss: 0.011918686758214054\n","Validation Accuracy: 0.9970139203710259\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0017725605284795165\n","Training loss per 100 training steps: 0.0038604411186470584\n","Training loss per 100 training steps: 0.0038975196411550526\n","Training loss per 100 training steps: 0.003795201397822718\n","Training loss per 100 training steps: 0.003879660844408467\n","Training loss per 100 training steps: 0.004364800313629973\n","Training loss per 100 training steps: 0.004904769967175411\n","Training loss epoch: 0.005187920450985782\n","Training accuracy epoch: 0.9985298789829932\n","Validating model...\n","Validation Loss: 0.0136034625327392\n","Validation Accuracy: 0.9962863474827459\n","Training epoch: 4\n","Training loss per 100 training steps: 0.013559143990278244\n","Training loss per 100 training steps: 0.005506317932297024\n","Training loss per 100 training steps: 0.004402292330821151\n","Training loss per 100 training steps: 0.004124599237410171\n","Training loss per 100 training steps: 0.0040073982412028916\n","Training loss per 100 training steps: 0.003752060243942958\n","Training loss per 100 training steps: 0.00408367259240643\n","Training loss epoch: 0.00408405286544245\n","Training accuracy epoch: 0.9987878383070212\n","Validating model...\n","Validation Loss: 0.010399426399436336\n","Validation Accuracy: 0.9975784918570236\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0019414827693253756\n","Training loss per 100 training steps: 0.0024266400943797816\n","Training loss per 100 training steps: 0.0022430918470852713\n","Training loss per 100 training steps: 0.0023131136300537907\n","Training loss per 100 training steps: 0.002430298807934618\n","Training loss per 100 training steps: 0.0024389017848090565\n","Training loss per 100 training steps: 0.002562753208397902\n","Training loss epoch: 0.002513519800997203\n","Training accuracy epoch: 0.9992507020808621\n","Validating model...\n","Validation Loss: 0.0159881668187154\n","Validation Accuracy: 0.9960400388832472\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0018783813575282693\n","Training loss per 100 training steps: 0.00164269364402139\n","Training loss per 100 training steps: 0.0016270105905603677\n","Training loss per 100 training steps: 0.0016483501851893912\n","Training loss per 100 training steps: 0.0017648740210059809\n","Training loss per 100 training steps: 0.0021440417880178517\n","Training loss per 100 training steps: 0.0022406948361146143\n","Training loss epoch: 0.002368029516174053\n","Training accuracy epoch: 0.9992554678438729\n","Validating model...\n","Validation Loss: 0.010112230814272715\n","Validation Accuracy: 0.9975272285129066\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0010264749871566892\n","Training loss per 100 training steps: 0.004506385802189902\n","Training loss per 100 training steps: 0.004983064604101996\n","Training loss per 100 training steps: 0.0045296843822735505\n","Training loss per 100 training steps: 0.003944663258765392\n","Training loss per 100 training steps: 0.004013126262029192\n","Training loss per 100 training steps: 0.004036646977905799\n","Training loss epoch: 0.0038793536080252967\n","Training accuracy epoch: 0.9988325196164096\n","Validating model...\n","Validation Loss: 0.023280852492808618\n","Validation Accuracy: 0.9957331246267861\n","Training epoch: 8\n","Training loss per 100 training steps: 0.007865495048463345\n","Training loss per 100 training steps: 0.0024285993284066344\n","Training loss per 100 training steps: 0.002512425013916452\n","Training loss per 100 training steps: 0.0021564810513003876\n","Training loss per 100 training steps: 0.0019986686387429265\n","Training loss per 100 training steps: 0.0018673218220244675\n","Training loss per 100 training steps: 0.0017912577051460306\n","Training loss epoch: 0.0017542854034018145\n","Training accuracy epoch: 0.9994773711142234\n","Validating model...\n","Validation Loss: 0.012872765099884765\n","Validation Accuracy: 0.9973657843020395\n","Training epoch: 9\n","Training loss per 100 training steps: 0.0019985276740044355\n","Training loss per 100 training steps: 0.0008827453758286619\n","Training loss per 100 training steps: 0.0007616054647846411\n","Training loss per 100 training steps: 0.0010783782501941786\n","Training loss per 100 training steps: 0.0016977309538229665\n","Training loss per 100 training steps: 0.0017790779833713947\n","Training loss per 100 training steps: 0.002139517006673695\n","Training loss epoch: 0.002170511574091037\n","Training accuracy epoch: 0.9993538455990112\n","Validating model...\n","Validation Loss: 0.014806096923036551\n","Validation Accuracy: 0.9973120139231426\n","Training epoch: 10\n","Training loss per 100 training steps: 0.006651501636952162\n","Training loss per 100 training steps: 0.0021109637655712557\n","Training loss per 100 training steps: 0.00238376446246385\n","Training loss per 100 training steps: 0.0025978305184918005\n","Training loss per 100 training steps: 0.002461482820847113\n","Training loss per 100 training steps: 0.002392422478715343\n","Training loss per 100 training steps: 0.002503383057548865\n","Training loss epoch: 0.0023683482017119715\n","Training accuracy epoch: 0.999269362528155\n","Validating model...\n","Validation Loss: 0.014141327903893225\n","Validation Accuracy: 0.9971455906557535\n","Training epoch: 11\n","Training loss per 100 training steps: 0.00018090855155605823\n","Training loss per 100 training steps: 0.0026211009479642474\n","Training loss per 100 training steps: 0.0024025621394648806\n","Training loss per 100 training steps: 0.002194132276161574\n","Training loss per 100 training steps: 0.002135103639556747\n","Training loss per 100 training steps: 0.0021126215923652197\n","Training loss per 100 training steps: 0.0020255412513712407\n","Training loss epoch: 0.002084658737962228\n","Training accuracy epoch: 0.9994169048444824\n","Validating model...\n","Validation Loss: 0.011672335039682886\n","Validation Accuracy: 0.997396441635423\n","Training epoch: 12\n","Patience limit reached\n","Training duration: 192.37636733333346 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.015455639521860576\n","Validation Accuracy: 0.9966300395431261\n","Validation duration: 0.23604563333331802 minutes\n","F1-score (test): 97.7%\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.98      0.98      1238\n","\n","   micro avg       0.97      0.98      0.98      1238\n","   macro avg       0.97      0.98      0.98      1238\n","weighted avg       0.97      0.98      0.98      1238\n","\n","!!!!!! Starting model number 6 !!!!!!\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 10902\n","Points in y_train after augmentation: 10902\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.2148432731628418\n","Training loss per 100 training steps: 0.08928228873243131\n","Training loss per 100 training steps: 0.05370196050429133\n","Training loss per 100 training steps: 0.04051915163397046\n","Training loss per 100 training steps: 0.0337166330934458\n","Training loss per 100 training steps: 0.029719253008959334\n","Training loss per 100 training steps: 0.02630784987817176\n","Training loss epoch: 0.023989539948465165\n","Training accuracy epoch: 0.9921006557556297\n","Validating model...\n","Validation Loss: 0.011044541809020475\n","Validation Accuracy: 0.9962318332485606\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0030234302394092083\n","Training loss per 100 training steps: 0.005565880768411415\n","Training loss per 100 training steps: 0.005989388928491511\n","Training loss per 100 training steps: 0.006629451327110978\n","Training loss per 100 training steps: 0.006760023601069824\n","Training loss per 100 training steps: 0.006722873254846912\n","Training loss per 100 training steps: 0.0067551024355714485\n","Training loss epoch: 0.006822273510654527\n","Training accuracy epoch: 0.9979647820675261\n","Validating model...\n","Validation Loss: 0.02043807287312423\n","Validation Accuracy: 0.996009011933934\n","Training epoch: 3\n","Training loss per 100 training steps: 0.002757833804935217\n","Training loss per 100 training steps: 0.005056186860552897\n","Training loss per 100 training steps: 0.005812736434586328\n","Training loss per 100 training steps: 0.005265723097695431\n","Training loss per 100 training steps: 0.0050366448632119505\n","Training loss per 100 training steps: 0.0050404002607114355\n","Training loss per 100 training steps: 0.004768721088466328\n","Training loss epoch: 0.004631231121832055\n","Training accuracy epoch: 0.9986393231251344\n","Validating model...\n","Validation Loss: 0.012035383230579014\n","Validation Accuracy: 0.9976780824474729\n","Training epoch: 4\n","Training loss per 100 training steps: 0.004338298458606005\n","Training loss per 100 training steps: 0.0026248116247179587\n","Training loss per 100 training steps: 0.0026648529357717323\n","Training loss per 100 training steps: 0.0029785113632250647\n","Training loss per 100 training steps: 0.0031532602829281954\n","Training loss per 100 training steps: 0.003098985577517323\n","Training loss per 100 training steps: 0.0031493115099258343\n","Training loss epoch: 0.003601424981304564\n","Training accuracy epoch: 0.9989400918260513\n","Validating model...\n","Validation Loss: 0.013024361840853956\n","Validation Accuracy: 0.9965903304825291\n","Training epoch: 5\n","Training loss per 100 training steps: 0.008344543166458607\n","Training loss per 100 training steps: 0.0034362049550013987\n","Training loss per 100 training steps: 0.003258184271779743\n","Training loss per 100 training steps: 0.003244043870712437\n","Training loss per 100 training steps: 0.0029474994523191337\n","Training loss per 100 training steps: 0.002923673073375554\n","Training loss per 100 training steps: 0.0031517928803921486\n","Training loss epoch: 0.0031827551225070395\n","Training accuracy epoch: 0.9990224992647787\n","Validating model...\n","Validation Loss: 0.013909898482996227\n","Validation Accuracy: 0.9974560537729751\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0002149129140889272\n","Training loss per 100 training steps: 0.0036636553763810748\n","Training loss per 100 training steps: 0.0032081792209943494\n","Training loss per 100 training steps: 0.0035661889650693405\n","Training loss per 100 training steps: 0.0035761423102650992\n","Training loss per 100 training steps: 0.0034296821911761538\n","Training loss per 100 training steps: 0.0034150757157246597\n","Training loss epoch: 0.003483437085133305\n","Training accuracy epoch: 0.9989569541321709\n","Validating model...\n","Validation Loss: 0.015342079263410554\n","Validation Accuracy: 0.9963734110217459\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 104.38933348333327 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.012459782374207862\n","Validation Accuracy: 0.9958690912261594\n","Validation duration: 0.23392768333336184 minutes\n","F1-score (test): 96.7%\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.96      0.98      0.97      1238\n","\n","   micro avg       0.96      0.98      0.97      1238\n","   macro avg       0.96      0.98      0.97      1238\n","weighted avg       0.96      0.98      0.97      1238\n","\n","!!!!!! Starting model number 7 !!!!!!\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 10902\n","Points in y_train after augmentation: 10902\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.1916834115982056\n","Training loss per 100 training steps: 0.0896370039819417\n","Training loss per 100 training steps: 0.05432782465573493\n","Training loss per 100 training steps: 0.04110940314823161\n","Training loss per 100 training steps: 0.03362418518969534\n","Training loss per 100 training steps: 0.02893949365113191\n","Training loss per 100 training steps: 0.02546985004612085\n","Training loss epoch: 0.023621867932360468\n","Training accuracy epoch: 0.9922849066296233\n","Validating model...\n","Validation Loss: 0.012095912048174623\n","Validation Accuracy: 0.9967931688851572\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0012624639784917235\n","Training loss per 100 training steps: 0.006077588987386887\n","Training loss per 100 training steps: 0.0072728849414461505\n","Training loss per 100 training steps: 0.007538656576061266\n","Training loss per 100 training steps: 0.007078404044221501\n","Training loss per 100 training steps: 0.00664212177694053\n","Training loss per 100 training steps: 0.006608107121849778\n","Training loss epoch: 0.006393881510209007\n","Training accuracy epoch: 0.9980552239419692\n","Validating model...\n","Validation Loss: 0.02024448623463589\n","Validation Accuracy: 0.9950811925806327\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0038266486953943968\n","Training loss per 100 training steps: 0.0029489645592656244\n","Training loss per 100 training steps: 0.0033571459591882164\n","Training loss per 100 training steps: 0.003508192786680607\n","Training loss per 100 training steps: 0.0032981112973331683\n","Training loss per 100 training steps: 0.003346772431287317\n","Training loss per 100 training steps: 0.003872526794488576\n","Training loss epoch: 0.004056402085478011\n","Training accuracy epoch: 0.9988516243925288\n","Validating model...\n","Validation Loss: 0.013099104110768253\n","Validation Accuracy: 0.9973365767880059\n","Training epoch: 4\n","Training loss per 100 training steps: 0.005892956629395485\n","Training loss per 100 training steps: 0.006111605351071547\n","Training loss per 100 training steps: 0.004732687305101594\n","Training loss per 100 training steps: 0.0039365783886992885\n","Training loss per 100 training steps: 0.003948486184780724\n","Training loss per 100 training steps: 0.0037685338516647376\n","Training loss per 100 training steps: 0.003765682039973008\n","Training loss epoch: 0.0036605932836372528\n","Training accuracy epoch: 0.9988678370590927\n","Validating model...\n","Validation Loss: 0.01740917203555693\n","Validation Accuracy: 0.9962822499655243\n","Training epoch: 5\n","Training loss per 100 training steps: 0.00031132306321524084\n","Training loss per 100 training steps: 0.001865110123257146\n","Training loss per 100 training steps: 0.002179560412528122\n","Training loss per 100 training steps: 0.0018960711376139533\n","Training loss per 100 training steps: 0.0024229788167330004\n","Training loss per 100 training steps: 0.002710875930593564\n","Training loss per 100 training steps: 0.002844734776516636\n","Training loss epoch: 0.0029987949185683875\n","Training accuracy epoch: 0.9991124331922343\n","Validating model...\n","Validation Loss: 0.013137652822825615\n","Validation Accuracy: 0.9975025216876632\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0008496209047734737\n","Training loss per 100 training steps: 0.0035696040012955545\n","Training loss per 100 training steps: 0.004056296515154284\n","Training loss per 100 training steps: 0.004233048803325196\n","Training loss per 100 training steps: 0.0038783326990347346\n","Training loss per 100 training steps: 0.0037435243467405527\n","Training loss per 100 training steps: 0.0037330840710764973\n","Training loss epoch: 0.0035737230205632998\n","Training accuracy epoch: 0.998973431060935\n","Validating model...\n","Validation Loss: 0.01516224569890515\n","Validation Accuracy: 0.9959599808550956\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 103.9537281000002 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.019248455479100812\n","Validation Accuracy: 0.9953056032592361\n","Validation duration: 0.2310833833333163 minutes\n","F1-score (test): 97.4%\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.97      0.98      0.97      1238\n","\n","   micro avg       0.97      0.98      0.97      1238\n","   macro avg       0.97      0.98      0.97      1238\n","weighted avg       0.97      0.98      0.97      1238\n","\n","!!!!!! Starting model number 8 !!!!!!\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 10902\n","Points in y_train after augmentation: 10902\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.1542264223098755\n","Training loss per 100 training steps: 0.09326740384267845\n","Training loss per 100 training steps: 0.0564172743409594\n","Training loss per 100 training steps: 0.042215869195397285\n","Training loss per 100 training steps: 0.03451362975229721\n","Training loss per 100 training steps: 0.029332925727151283\n","Training loss per 100 training steps: 0.025968620873512715\n","Training loss epoch: 0.023729357590581035\n","Training accuracy epoch: 0.9923084845481003\n","Validating model...\n","Validation Loss: 0.012923451190415238\n","Validation Accuracy: 0.9962281689133823\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0012087475042790174\n","Training loss per 100 training steps: 0.007097822742532053\n","Training loss per 100 training steps: 0.0070891976240670205\n","Training loss per 100 training steps: 0.0061988073144294865\n","Training loss per 100 training steps: 0.005846487687807908\n","Training loss per 100 training steps: 0.005840805881906383\n","Training loss per 100 training steps: 0.005888995841058253\n","Training loss epoch: 0.005792116094660134\n","Training accuracy epoch: 0.9982097382601759\n","Validating model...\n","Validation Loss: 0.010448233379845209\n","Validation Accuracy: 0.997176758912759\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0063353232108056545\n","Training loss per 100 training steps: 0.005370940592677084\n","Training loss per 100 training steps: 0.005341831992095944\n","Training loss per 100 training steps: 0.004818249953503835\n","Training loss per 100 training steps: 0.004871060251511757\n","Training loss per 100 training steps: 0.004830806120478886\n","Training loss per 100 training steps: 0.004637693831806645\n","Training loss epoch: 0.004664175305935869\n","Training accuracy epoch: 0.9985877116591203\n","Validating model...\n","Validation Loss: 0.009030974740328799\n","Validation Accuracy: 0.997723953399698\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0007758524734526873\n","Training loss per 100 training steps: 0.003994992333936902\n","Training loss per 100 training steps: 0.003619406184038803\n","Training loss per 100 training steps: 0.003944907327105432\n","Training loss per 100 training steps: 0.004503868319381736\n","Training loss per 100 training steps: 0.004384095370149665\n","Training loss per 100 training steps: 0.0041724803858764386\n","Training loss epoch: 0.003952443900591647\n","Training accuracy epoch: 0.998811732386561\n","Validating model...\n","Validation Loss: 0.013136980089170504\n","Validation Accuracy: 0.9969461131713246\n","Training epoch: 5\n","Training loss per 100 training steps: 0.01314182486385107\n","Training loss per 100 training steps: 0.0017406104473566572\n","Training loss per 100 training steps: 0.002123750020518629\n","Training loss per 100 training steps: 0.002164240214330503\n","Training loss per 100 training steps: 0.002335526777313502\n","Training loss per 100 training steps: 0.0025571739107815125\n","Training loss per 100 training steps: 0.0025748265550997553\n","Training loss epoch: 0.0026082917246696147\n","Training accuracy epoch: 0.9991740265391305\n","Validating model...\n","Validation Loss: 0.011986426814733673\n","Validation Accuracy: 0.9978753519164123\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00029017371707595885\n","Training loss per 100 training steps: 0.0014544326481657187\n","Training loss per 100 training steps: 0.00159848765725651\n","Training loss per 100 training steps: 0.0017098511022997501\n","Training loss per 100 training steps: 0.0017903964668366463\n","Training loss per 100 training steps: 0.0018259722194719772\n","Training loss per 100 training steps: 0.0018506475545577035\n","Training loss epoch: 0.002032376482772615\n","Training accuracy epoch: 0.9993874156286255\n","Validating model...\n","Validation Loss: 0.016006121957616415\n","Validation Accuracy: 0.9962354939445655\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0011951883789151907\n","Training loss per 100 training steps: 0.003211569287135591\n","Training loss per 100 training steps: 0.0029475554720057285\n","Training loss per 100 training steps: 0.0028104504888935866\n","Training loss per 100 training steps: 0.0035319684870218702\n","Training loss per 100 training steps: 0.003909454943777837\n","Training loss per 100 training steps: 0.0037468857695427977\n","Training loss epoch: 0.003678104507584003\n","Training accuracy epoch: 0.9988200519643315\n","Validating model...\n","Validation Loss: 0.015926224460729697\n","Validation Accuracy: 0.9964898310225668\n","Training epoch: 8\n","Training loss per 100 training steps: 0.00028448860393837094\n","Training loss per 100 training steps: 0.0025862052107816515\n","Training loss per 100 training steps: 0.0024808709277021083\n","Training loss per 100 training steps: 0.0021032222770088725\n","Training loss per 100 training steps: 0.0022381667409840395\n","Training loss per 100 training steps: 0.0022561709582353973\n","Training loss per 100 training steps: 0.0021254296693201504\n","Training loss epoch: 0.0021012791004785735\n","Training accuracy epoch: 0.9993582936955393\n","Validating model...\n","Validation Loss: 0.014507689612011225\n","Validation Accuracy: 0.997141837667605\n","Training epoch: 9\n","Patience limit reached\n","Training duration: 139.40831125000017 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.012228201450246464\n","Validation Accuracy: 0.9971284011649404\n","Validation duration: 0.2307082999999693 minutes\n","F1-score (test): 98.2%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.98      0.99      0.98      1238\n","\n","   micro avg       0.98      0.99      0.98      1238\n","   macro avg       0.98      0.99      0.98      1238\n","weighted avg       0.98      0.99      0.98      1238\n","\n","!!!!!! Starting model number 9 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 10902\n","Points in y_train after augmentation: 10902\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.1834288835525513\n","Training loss per 100 training steps: 0.08756095310212067\n","Training loss per 100 training steps: 0.052534105787887725\n","Training loss per 100 training steps: 0.0402032091898033\n","Training loss per 100 training steps: 0.03331520545622682\n","Training loss per 100 training steps: 0.02899281338192783\n","Training loss per 100 training steps: 0.02545382899974865\n","Training loss epoch: 0.023360156696450234\n","Training accuracy epoch: 0.9924968379536764\n","Validating model...\n","Validation Loss: 0.014596631379044126\n","Validation Accuracy: 0.9962601166049749\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0008593259262852371\n","Training loss per 100 training steps: 0.008553023214940683\n","Training loss per 100 training steps: 0.006773511749771609\n","Training loss per 100 training steps: 0.006602847413827071\n","Training loss per 100 training steps: 0.006074304210201795\n","Training loss per 100 training steps: 0.005564641475461623\n","Training loss per 100 training steps: 0.00549168324926748\n","Training loss epoch: 0.005522591132366629\n","Training accuracy epoch: 0.9983828684726466\n","Validating model...\n","Validation Loss: 0.011155630795526252\n","Validation Accuracy: 0.9974644798841046\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0066102659329771996\n","Training loss per 100 training steps: 0.004296887927345176\n","Training loss per 100 training steps: 0.004141593198549693\n","Training loss per 100 training steps: 0.004332969465110826\n","Training loss per 100 training steps: 0.0051362529358762125\n","Training loss per 100 training steps: 0.004838683989282164\n","Training loss per 100 training steps: 0.004834373755709418\n","Training loss epoch: 0.004858836671973331\n","Training accuracy epoch: 0.9985332992271825\n","Validating model...\n","Validation Loss: 0.008192344211108451\n","Validation Accuracy: 0.9978962475247813\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0063758306205272675\n","Training loss per 100 training steps: 0.003093083547085344\n","Training loss per 100 training steps: 0.00469331545039255\n","Training loss per 100 training steps: 0.004687162752900825\n","Training loss per 100 training steps: 0.004317904414566689\n","Training loss per 100 training steps: 0.0041874484752892505\n","Training loss per 100 training steps: 0.0040580480444639125\n","Training loss epoch: 0.004013103959196061\n","Training accuracy epoch: 0.9988055150376789\n","Validating model...\n","Validation Loss: 0.010324772657917319\n","Validation Accuracy: 0.9977843646746886\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0023868284188210964\n","Training loss per 100 training steps: 0.001147051747484331\n","Training loss per 100 training steps: 0.0021328202795605953\n","Training loss per 100 training steps: 0.0024633063890314136\n","Training loss per 100 training steps: 0.002723469137072016\n","Training loss per 100 training steps: 0.002746402264194272\n","Training loss per 100 training steps: 0.002614562964377175\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 5\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"TTDq-xbgHqXQ"},{"cell_type":"code","source":["number_of_training_models = 2\n","target_augmented_percentage = 5\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"metadata":{"id":"pCnEIUSX0Tmj","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["c57ebc6354ec490fbc3aafce9e4156b1","81ac0d3fc73e4cd9b9e03b7c1cdfaf20","89c24efe02ec496a970fad09b75b1667","e2e76c37e2fa46ae9165162652cc2b66","2107634121e04734a211b7ea8b8aad8b","e2a9f5eed8df4f62b5249294b1c3e4d8","d933594bacf047428977750e6bbae276","602ebd982a844cbf82269e513ec82b5c","5544f8dbd0744916905741efb6eb81d4","50927da0d55a43598bed5fcb03bf599d","6b70e3c502f54e6db0ea19c4cdd837de"]},"executionInfo":{"status":"ok","timestamp":1666097586086,"user_tz":240,"elapsed":21693374,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}},"outputId":"930aae66-ac28-4d7e-bceb-30050e34dfdc"},"id":"pCnEIUSX0Tmj","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["!!!!!! Augmented Percentage 500% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/714M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c57ebc6354ec490fbc3aafce9e4156b1"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 10902\n","Points in y_train after augmentation: 10902\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.2287684679031372\n","Training loss per 100 training steps: 0.08043738863532349\n","Training loss per 100 training steps: 0.04987903414131953\n","Training loss per 100 training steps: 0.03738834657683115\n","Training loss per 100 training steps: 0.03200806952049686\n","Training loss per 100 training steps: 0.027854292973004163\n","Training loss per 100 training steps: 0.02452273986395487\n","Training loss epoch: 0.022610468233164326\n","Training accuracy epoch: 0.9924579965578688\n","Validating model...\n","Validation Loss: 0.01047421099030457\n","Validation Accuracy: 0.9968095022339936\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0038069940637797117\n","Training loss per 100 training steps: 0.0054829573356154565\n","Training loss per 100 training steps: 0.008417376306513787\n","Training loss per 100 training steps: 0.00875072382234634\n","Training loss per 100 training steps: 0.008693327359606087\n","Training loss per 100 training steps: 0.00842259171949337\n","Training loss per 100 training steps: 0.007968479322603502\n","Training loss epoch: 0.007969979142163856\n","Training accuracy epoch: 0.9976140394258857\n","Validating model...\n","Validation Loss: 0.013813742006494153\n","Validation Accuracy: 0.9957090813297317\n","Training epoch: 3\n","Training loss per 100 training steps: 0.004261726513504982\n","Training loss per 100 training steps: 0.0035985323252089524\n","Training loss per 100 training steps: 0.003350541983318135\n","Training loss per 100 training steps: 0.0037031749301018393\n","Training loss per 100 training steps: 0.004163749366209023\n","Training loss per 100 training steps: 0.004361488472477686\n","Training loss per 100 training steps: 0.0043231696886300635\n","Training loss epoch: 0.004342137041656267\n","Training accuracy epoch: 0.9986706306695592\n","Validating model...\n","Validation Loss: 0.014776503418813394\n","Validation Accuracy: 0.9967901917420822\n","Training epoch: 4\n","Training loss per 100 training steps: 0.00853881984949112\n","Training loss per 100 training steps: 0.004293680255659188\n","Training loss per 100 training steps: 0.004062040786677913\n","Training loss per 100 training steps: 0.0037535118754747003\n","Training loss per 100 training steps: 0.0033400531386012476\n","Training loss per 100 training steps: 0.0035743742192715\n","Training loss per 100 training steps: 0.0036385354211784632\n","Training loss epoch: 0.0036760579031075167\n","Training accuracy epoch: 0.9989371564128501\n","Validating model...\n","Validation Loss: 0.016320597613230348\n","Validation Accuracy: 0.9969054764630627\n","Training epoch: 5\n","Training loss per 100 training steps: 0.008181015960872173\n","Training loss per 100 training steps: 0.00345281549459404\n","Training loss per 100 training steps: 0.004554851458427341\n","Training loss per 100 training steps: 0.005386564205081567\n","Training loss per 100 training steps: 0.005467960024155279\n","Training loss per 100 training steps: 0.005283671291126775\n","Training loss per 100 training steps: 0.004914318539363761\n","Training loss epoch: 0.004680349160875282\n","Training accuracy epoch: 0.9986131830779694\n","Validating model...\n","Validation Loss: 0.015622970399168221\n","Validation Accuracy: 0.9971046993732412\n","Training epoch: 6\n","Training loss per 100 training steps: 0.006388775072991848\n","Training loss per 100 training steps: 0.0022530694545326193\n","Training loss per 100 training steps: 0.002183841463944073\n","Training loss per 100 training steps: 0.0020723077273259306\n","Training loss per 100 training steps: 0.0021553555130308984\n","Training loss per 100 training steps: 0.0023788919087984212\n","Training loss per 100 training steps: 0.002396326037938319\n","Training loss epoch: 0.0024472160468917868\n","Training accuracy epoch: 0.9992938948281117\n","Validating model...\n","Validation Loss: 0.013050711945955603\n","Validation Accuracy: 0.9971922286959709\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 102.68228495000001 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.011029982296652937\n","Validation Accuracy: 0.9970968079188568\n","Validation duration: 0.2283542333333268 minutes\n","F1-score (test): 98.0%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.98      0.98      0.98      1238\n","\n","   micro avg       0.98      0.98      0.98      1238\n","   macro avg       0.98      0.98      0.98      1238\n","weighted avg       0.98      0.98      0.98      1238\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 10902\n","Points in y_train after augmentation: 10902\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.175498604774475\n","Training loss per 100 training steps: 0.08724570556055053\n","Training loss per 100 training steps: 0.052453074498861954\n","Training loss per 100 training steps: 0.039541828267793004\n","Training loss per 100 training steps: 0.03287314293044445\n","Training loss per 100 training steps: 0.028269903993879086\n","Training loss per 100 training steps: 0.025129660375155943\n","Training loss epoch: 0.023561236988500447\n","Training accuracy epoch: 0.992313630748442\n","Validating model...\n","Validation Loss: 0.012613062183109355\n","Validation Accuracy: 0.9967824613896068\n","Training epoch: 2\n","Training loss per 100 training steps: 0.004112414550036192\n","Training loss per 100 training steps: 0.005413416439539402\n","Training loss per 100 training steps: 0.005927644960251544\n","Training loss per 100 training steps: 0.005953171076626282\n","Training loss per 100 training steps: 0.006865488174520932\n","Training loss per 100 training steps: 0.0074028152437263005\n","Training loss per 100 training steps: 0.0071304261738121795\n","Training loss epoch: 0.006790923818831859\n","Training accuracy epoch: 0.9979599548915318\n","Validating model...\n","Validation Loss: 0.013804155265028211\n","Validation Accuracy: 0.9967253328610846\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0005206394125707448\n","Training loss per 100 training steps: 0.0036506863291626613\n","Training loss per 100 training steps: 0.003750136156713553\n","Training loss per 100 training steps: 0.004095486355686338\n","Training loss per 100 training steps: 0.003798145564387528\n","Training loss per 100 training steps: 0.0037387064507503217\n","Training loss per 100 training steps: 0.003841639329898582\n","Training loss epoch: 0.003956419246589944\n","Training accuracy epoch: 0.9987831494898121\n","Validating model...\n","Validation Loss: 0.01207968989529902\n","Validation Accuracy: 0.9969527986048797\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0016496338648721576\n","Training loss per 100 training steps: 0.0051609519786964455\n","Training loss per 100 training steps: 0.003933241246172588\n","Training loss per 100 training steps: 0.0033515065165269082\n","Training loss per 100 training steps: 0.003224628546753561\n","Training loss per 100 training steps: 0.0031308928683464405\n","Training loss per 100 training steps: 0.00310097795502009\n","Training loss epoch: 0.0029941583144934003\n","Training accuracy epoch: 0.9990115513828435\n","Validating model...\n","Validation Loss: 0.015990609271241175\n","Validation Accuracy: 0.9972279752123879\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0003487613284960389\n","Training loss per 100 training steps: 0.0024332801199352166\n","Training loss per 100 training steps: 0.0033339066670200353\n","Training loss per 100 training steps: 0.0029506644410908106\n","Training loss per 100 training steps: 0.002939248219785046\n","Training loss per 100 training steps: 0.0033928894697750796\n","Training loss per 100 training steps: 0.0035067691637724933\n","Training loss epoch: 0.0034963389880964778\n","Training accuracy epoch: 0.9989450636210906\n","Validating model...\n","Validation Loss: 0.01284872678141775\n","Validation Accuracy: 0.9971431827056297\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0009535024291835725\n","Training loss per 100 training steps: 0.0029008548211788706\n","Training loss per 100 training steps: 0.002897633224278596\n","Training loss per 100 training steps: 0.0028264726927129556\n","Training loss per 100 training steps: 0.003006774746182757\n","Training loss per 100 training steps: 0.0028693265332999556\n","Training loss per 100 training steps: 0.0027950314410109195\n","Training loss epoch: 0.002740161266196285\n","Training accuracy epoch: 0.9992149193226546\n","Validating model...\n","Validation Loss: 0.013046785636972692\n","Validation Accuracy: 0.9971114828177582\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0011579270940274\n","Training loss per 100 training steps: 0.0012644914432973682\n","Training loss per 100 training steps: 0.001478217569890705\n","Training loss per 100 training steps: 0.0020372621689433755\n","Training loss per 100 training steps: 0.002031471038983789\n","Training loss per 100 training steps: 0.002055206371353447\n","Training loss per 100 training steps: 0.0021955439165843665\n","Training loss epoch: 0.0023263223715930454\n","Training accuracy epoch: 0.9992639571961869\n","Validating model...\n","Validation Loss: 0.011542904108604748\n","Validation Accuracy: 0.9972025591802508\n","Training epoch: 8\n","Training loss per 100 training steps: 0.002899178536608815\n","Training loss per 100 training steps: 0.0016832546778928056\n","Training loss per 100 training steps: 0.001605867807199108\n","Training loss per 100 training steps: 0.0014832233483016459\n","Training loss per 100 training steps: 0.0013582572316665205\n","Training loss per 100 training steps: 0.0014951954684649985\n","Training loss per 100 training steps: 0.0014984646082339714\n","Training loss epoch: 0.0016546129739019248\n","Training accuracy epoch: 0.9995000703829885\n","Validating model...\n","Validation Loss: 0.013870059844347929\n","Validation Accuracy: 0.996968077572156\n","Training epoch: 9\n","Training loss per 100 training steps: 0.001209025620482862\n","Training loss per 100 training steps: 0.0014458606914342796\n","Training loss per 100 training steps: 0.0015633096950952124\n","Training loss per 100 training steps: 0.001710815681403242\n","Training loss per 100 training steps: 0.0027169417477134607\n","Training loss per 100 training steps: 0.0034668201272773343\n","Training loss per 100 training steps: 0.0037884278708059027\n","Training loss epoch: 0.003728176628583962\n","Training accuracy epoch: 0.9988749934307094\n","Validating model...\n","Validation Loss: 0.017840930352533525\n","Validation Accuracy: 0.9969072198434997\n","Training epoch: 10\n","Training loss per 100 training steps: 0.0018270821310579777\n","Training loss per 100 training steps: 0.0017824309284736558\n","Training loss per 100 training steps: 0.0016045484761124684\n","Training loss per 100 training steps: 0.0016609109775692613\n","Training loss per 100 training steps: 0.0018393024615500704\n","Training loss per 100 training steps: 0.0017210781103156427\n","Training loss per 100 training steps: 0.0016512683294107693\n","Training loss epoch: 0.001575924032050963\n","Training accuracy epoch: 0.999495251390437\n","Validating model...\n","Validation Loss: 0.01868765085635546\n","Validation Accuracy: 0.9967792517081191\n","Training epoch: 11\n","Training loss per 100 training steps: 0.0039392211474478245\n","Training loss per 100 training steps: 0.001080003089492214\n","Training loss per 100 training steps: 0.0014729694772558923\n","Training loss per 100 training steps: 0.0018569110311772573\n","Training loss per 100 training steps: 0.0017074786605497732\n","Training loss per 100 training steps: 0.0015892718393659747\n","Training loss per 100 training steps: 0.0015950536053136474\n","Training loss epoch: 0.001617037466665437\n","Training accuracy epoch: 0.9994772987169763\n","Validating model...\n","Validation Loss: 0.016903329629583044\n","Validation Accuracy: 0.9971277497023778\n","Training epoch: 12\n","Training loss per 100 training steps: 0.002685160143300891\n","Training loss per 100 training steps: 0.0011126253036246173\n","Training loss per 100 training steps: 0.0014449026597892825\n","Training loss per 100 training steps: 0.0014084158544733704\n","Training loss per 100 training steps: 0.0014490987249884705\n","Training loss per 100 training steps: 0.0016938280941958112\n","Training loss per 100 training steps: 0.0017437515644132494\n","Training loss epoch: 0.0018855608068299896\n","Training accuracy epoch: 0.9993659453628075\n","Validating model...\n","Validation Loss: 0.01939777172680936\n","Validation Accuracy: 0.9961865812191164\n","Training epoch: 13\n","Patience limit reached\n","Training duration: 205.38135893333336 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.015524436411093726\n","Validation Accuracy: 0.9965805713413802\n","Validation duration: 0.22865136666666028 minutes\n","F1-score (test): 97.9%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","  LEGISLACAO       0.98      0.98      0.98      1238\n","\n","   micro avg       0.98      0.98      0.98      1238\n","   macro avg       0.98      0.98      0.98      1238\n","weighted avg       0.98      0.98      0.98      1238\n","\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1fd215feb3bb4396823a979901744613":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b9404b0372904c94add8ab62649b9559","IPY_MODEL_4883b0fa3aea457cb708e9c66fd03010","IPY_MODEL_0a56886a395f4c2498f95d973025e3fc"],"layout":"IPY_MODEL_8cdf951025a946de942a538c2d0680cb"}},"b9404b0372904c94add8ab62649b9559":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0144b652a2574e4681860c828131da40","placeholder":"​","style":"IPY_MODEL_ebc5fd08b6fd4efc9b17deeda2755ffc","value":"Downloading: 100%"}},"4883b0fa3aea457cb708e9c66fd03010":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_15fa284c24c54ba1b23d78e0ea14f862","max":714314041,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eecec21d287f4c4cb43550a7e8af3116","value":714314041}},"0a56886a395f4c2498f95d973025e3fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c82daa0a1dd04c70941f524f214279d7","placeholder":"​","style":"IPY_MODEL_aa8be15a00ca4b7ea9e48d3815310f3e","value":" 714M/714M [00:13&lt;00:00, 54.2MB/s]"}},"8cdf951025a946de942a538c2d0680cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0144b652a2574e4681860c828131da40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebc5fd08b6fd4efc9b17deeda2755ffc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"15fa284c24c54ba1b23d78e0ea14f862":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eecec21d287f4c4cb43550a7e8af3116":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c82daa0a1dd04c70941f524f214279d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa8be15a00ca4b7ea9e48d3815310f3e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"707228563e3e461eb3395c705b2dac33":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_479874ab763f44f1966266312d2bd93d","IPY_MODEL_08d443fbdcbb47dab83b4f0bf80f81fc","IPY_MODEL_702d5e635a60473d812cfcfbb4595589"],"layout":"IPY_MODEL_3129250bd6c145f583618e5c95e5f860"}},"479874ab763f44f1966266312d2bd93d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32bd67cc541e4236bc7526614aaeb5c0","placeholder":"​","style":"IPY_MODEL_c841d11604c242bb84305f06b695ec7a","value":"Downloading: 100%"}},"08d443fbdcbb47dab83b4f0bf80f81fc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd7e324f938249a2af2539cc5e7f682d","max":714314041,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b75440cc1889475ca0c508e8bfb138a7","value":714314041}},"702d5e635a60473d812cfcfbb4595589":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df6072c661ee42ff868747fd788daeda","placeholder":"​","style":"IPY_MODEL_9a22ed8ad11849128ff2b34d989a5135","value":" 714M/714M [00:10&lt;00:00, 61.4MB/s]"}},"3129250bd6c145f583618e5c95e5f860":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32bd67cc541e4236bc7526614aaeb5c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c841d11604c242bb84305f06b695ec7a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd7e324f938249a2af2539cc5e7f682d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b75440cc1889475ca0c508e8bfb138a7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"df6072c661ee42ff868747fd788daeda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a22ed8ad11849128ff2b34d989a5135":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec3e6c1415ff4ac5a08cf226bce44f8e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_574d72c0bec14609a0dc6823e50c2721","IPY_MODEL_df24b7b3debf4164ad3448edb54221bf","IPY_MODEL_70b0df1a6128407991ceb39b0d74d6e5"],"layout":"IPY_MODEL_754f280f826545fea18ae7dcbc17a576"}},"574d72c0bec14609a0dc6823e50c2721":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5aa35d876f340cabcb7e3cff020f61b","placeholder":"​","style":"IPY_MODEL_850b8bc1bb8b46f1b3e983374fde319a","value":"Downloading: 100%"}},"df24b7b3debf4164ad3448edb54221bf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_87dee83e0cde44a480ee5af2b7ebc2d7","max":714314041,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cc3d4a91d7cc4b9dae3792106a6bb7b0","value":714314041}},"70b0df1a6128407991ceb39b0d74d6e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4767ee72dca94b828a247d1ecc47e774","placeholder":"​","style":"IPY_MODEL_7405d6e3e12f47c0a8b695c335bba561","value":" 714M/714M [00:10&lt;00:00, 66.4MB/s]"}},"754f280f826545fea18ae7dcbc17a576":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5aa35d876f340cabcb7e3cff020f61b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"850b8bc1bb8b46f1b3e983374fde319a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"87dee83e0cde44a480ee5af2b7ebc2d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc3d4a91d7cc4b9dae3792106a6bb7b0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4767ee72dca94b828a247d1ecc47e774":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7405d6e3e12f47c0a8b695c335bba561":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82139eeec95847e885df5d78b299fb33":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d81db4b5feee4411b1bf66bab8d4f680","IPY_MODEL_5b030a01d9414ded94244470147a091c","IPY_MODEL_391d763bb122412e92aa6572c013016c"],"layout":"IPY_MODEL_e35dfb31ee594b0fb8d6d2b02979fef0"}},"d81db4b5feee4411b1bf66bab8d4f680":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cfcc5aaa7906478ea26702bbfd5aed59","placeholder":"​","style":"IPY_MODEL_f31dc921312946499ad1c68502b7dc4b","value":"Downloading: 100%"}},"5b030a01d9414ded94244470147a091c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bdcae15631c41eb99c75e8a84052b0a","max":29,"min":0,"orientation":"horizontal","style":"IPY_MODEL_47c18c1b52094d0892fdb1df7496743a","value":29}},"391d763bb122412e92aa6572c013016c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9aa45bce93b4218b46924cae67b1f5f","placeholder":"​","style":"IPY_MODEL_81f8c1538d1c4e63a57407eb4ec9ea9f","value":" 29.0/29.0 [00:00&lt;00:00, 1.10kB/s]"}},"e35dfb31ee594b0fb8d6d2b02979fef0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfcc5aaa7906478ea26702bbfd5aed59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f31dc921312946499ad1c68502b7dc4b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2bdcae15631c41eb99c75e8a84052b0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47c18c1b52094d0892fdb1df7496743a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e9aa45bce93b4218b46924cae67b1f5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81f8c1538d1c4e63a57407eb4ec9ea9f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e7cd746f017407d82ad6cc0fb9e3142":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_59e518d44ff54ad2acdd02407ed40978","IPY_MODEL_ca96b776f9694c11b47be0a6a87d4a5b","IPY_MODEL_e29a008722344c5e9c718f7fbde9f69e"],"layout":"IPY_MODEL_f407cdd445db49adb748dbb450c3a029"}},"59e518d44ff54ad2acdd02407ed40978":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7cc3f99db144b46927b85fd0fb119a5","placeholder":"​","style":"IPY_MODEL_81a5a802f4d7439a894012ff2e184abc","value":"Downloading: 100%"}},"ca96b776f9694c11b47be0a6a87d4a5b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d587040812004b7bbaf45a755ddad82b","max":625,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f51c07e9dd6540459e9d2020b66dbcdd","value":625}},"e29a008722344c5e9c718f7fbde9f69e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb46b745ac1c403d91d4bab7f98fa752","placeholder":"​","style":"IPY_MODEL_5f5b26b49b82492287c75af86cdc0f20","value":" 625/625 [00:00&lt;00:00, 27.0kB/s]"}},"f407cdd445db49adb748dbb450c3a029":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7cc3f99db144b46927b85fd0fb119a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81a5a802f4d7439a894012ff2e184abc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d587040812004b7bbaf45a755ddad82b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f51c07e9dd6540459e9d2020b66dbcdd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eb46b745ac1c403d91d4bab7f98fa752":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f5b26b49b82492287c75af86cdc0f20":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7cdb5883c0347068e779fb8a4b8c50a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c2b88fdcc36044689489160fda863ceb","IPY_MODEL_d8381a1898c94808ab2cdf66e6c56d06","IPY_MODEL_5e3b6cf92fef40e6ad4795f0136fcee2"],"layout":"IPY_MODEL_98bfb49e144b41ad994034ad992c68cf"}},"c2b88fdcc36044689489160fda863ceb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb11736c06484b44a994ac6e9911ba18","placeholder":"​","style":"IPY_MODEL_8b84fba173ea45ad914cd3222f0b9278","value":"Downloading: 100%"}},"d8381a1898c94808ab2cdf66e6c56d06":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3e5cd4877e24bb9ae492b57dd70c586","max":995526,"min":0,"orientation":"horizontal","style":"IPY_MODEL_27e14dd3172444ca830654c2db338705","value":995526}},"5e3b6cf92fef40e6ad4795f0136fcee2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52852f905a3c4690a5fbb14642651f51","placeholder":"​","style":"IPY_MODEL_8d409eb99d0f4a318a7850e7c61ed383","value":" 996k/996k [00:01&lt;00:00, 928kB/s]"}},"98bfb49e144b41ad994034ad992c68cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb11736c06484b44a994ac6e9911ba18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b84fba173ea45ad914cd3222f0b9278":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b3e5cd4877e24bb9ae492b57dd70c586":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27e14dd3172444ca830654c2db338705":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"52852f905a3c4690a5fbb14642651f51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d409eb99d0f4a318a7850e7c61ed383":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"55f5d4ea71434b819e8409a1733677d0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_defcd8b191cc422b825bd2c75751df45","IPY_MODEL_dc465c76c4da4c14b61ecadfa35c16a0","IPY_MODEL_5b25b246f029456eb9dfcb3de02e9a98"],"layout":"IPY_MODEL_93aa6be594c64014a36232baa8a76552"}},"defcd8b191cc422b825bd2c75751df45":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ea492fe8f70452d882ecde4e9283a8e","placeholder":"​","style":"IPY_MODEL_6538a23fcc484540bf7520bbcffc3bd0","value":"Downloading: 100%"}},"dc465c76c4da4c14b61ecadfa35c16a0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6b1e20798dc445fa211c37e82e75ad5","max":1961828,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ef87c76e862d4426a1ef1114a22d814c","value":1961828}},"5b25b246f029456eb9dfcb3de02e9a98":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c62df58d74424898b5644f894584169a","placeholder":"​","style":"IPY_MODEL_3a90334aa40a4031af2399be845e00fc","value":" 1.96M/1.96M [00:01&lt;00:00, 2.18MB/s]"}},"93aa6be594c64014a36232baa8a76552":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ea492fe8f70452d882ecde4e9283a8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6538a23fcc484540bf7520bbcffc3bd0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a6b1e20798dc445fa211c37e82e75ad5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef87c76e862d4426a1ef1114a22d814c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c62df58d74424898b5644f894584169a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a90334aa40a4031af2399be845e00fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c57ebc6354ec490fbc3aafce9e4156b1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_81ac0d3fc73e4cd9b9e03b7c1cdfaf20","IPY_MODEL_89c24efe02ec496a970fad09b75b1667","IPY_MODEL_e2e76c37e2fa46ae9165162652cc2b66"],"layout":"IPY_MODEL_2107634121e04734a211b7ea8b8aad8b"}},"81ac0d3fc73e4cd9b9e03b7c1cdfaf20":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2a9f5eed8df4f62b5249294b1c3e4d8","placeholder":"​","style":"IPY_MODEL_d933594bacf047428977750e6bbae276","value":"Downloading: 100%"}},"89c24efe02ec496a970fad09b75b1667":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_602ebd982a844cbf82269e513ec82b5c","max":714314041,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5544f8dbd0744916905741efb6eb81d4","value":714314041}},"e2e76c37e2fa46ae9165162652cc2b66":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50927da0d55a43598bed5fcb03bf599d","placeholder":"​","style":"IPY_MODEL_6b70e3c502f54e6db0ea19c4cdd837de","value":" 714M/714M [00:10&lt;00:00, 61.3MB/s]"}},"2107634121e04734a211b7ea8b8aad8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2a9f5eed8df4f62b5249294b1c3e4d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d933594bacf047428977750e6bbae276":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"602ebd982a844cbf82269e513ec82b5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5544f8dbd0744916905741efb6eb81d4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"50927da0d55a43598bed5fcb03bf599d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b70e3c502f54e6db0ea19c4cdd837de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}