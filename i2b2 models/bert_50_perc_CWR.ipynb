{"cells":[{"cell_type":"markdown","metadata":{"id":"FFh7WVoJH5dr"},"source":["Adapted from [ner_with_bilstm_and_crf](https://www.kaggle.com/nikkisharma536/ner-with-bilstm-and-crf/notebook)\n","Altigran Soares da Silva\n","IComp/UFAM - 15/03/2021\n"],"id":"FFh7WVoJH5dr"},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":226743,"status":"ok","timestamp":1667797787269,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"zvip_oC0j5-y","outputId":"c0fae405-d66b-4641-a16a-704c83fb6c81"},"outputs":[{"output_type":"stream","name":"stdout","text":["Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 17.5 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n","\u001b[K     |████████████████████████████████| 5.5 MB 32.5 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n","\u001b[K     |████████████████████████████████| 163 kB 70.0 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 78.8 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.24.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 312 kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=4ab7048c0024204ffdf3b8964c07324bc1d7b03a71cc90a6ee6d337c2c8f69e4\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n","[8485, 14629, 4676]\n","[3, 3, 3]\n","[27510, 13880, 24183, 12605, 18868, 2286, 13149, 26441, 18810, 6328, 10914, 11897]\n","[2, 4, 4, 4, 4, 4, 3, 6, 1, 1, 1, 3]\n","[8570, 13812, 4676]\n","[3, 3, 3]\n","4045\n","0\n","B-problem\n","reticulocyte\n","28388\n","7\n"]}],"source":["# Uncomment this cell if you want to load saved data\n","\n","# Re-import necessary libs\n","import pandas as pd\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","import pickle, math\n","from requests import get\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import random\n","import time\n","%tensorflow_version 2.x\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import torch\n","from torch import cuda\n","from torch.utils.data import Dataset, DataLoader\n","!pip install sentencepiece\n","!pip install transformers\n","from transformers import BertForTokenClassification, AutoTokenizer\n","import matplotlib.pyplot as plt\n","!pip install seqeval\n","from seqeval.metrics import f1_score, classification_report\n","\n","BACKUP_FOLDER_ID = '1YWR4Ip8w94RwFMyMtNpRa9M0FpiJtqd5'\n","notebook_filename = get('http://172.28.0.2:9000/api/sessions').json()[0]['name'].replace(\"_CWR\",\"\")\n","\n","X_train_filename = f'{notebook_filename}_X_train.csv'\n","y_train_filename = f'{notebook_filename}_y_train.csv'\n","X_dev_filename = f'{notebook_filename}_X_dev.csv'\n","y_dev_filename = f'{notebook_filename}_y_dev.csv'\n","X_test_filename = f'{notebook_filename}_X_test.csv'\n","y_test_filename = f'{notebook_filename}_y_test.csv'\n","\n","word2idx_filename = f'{notebook_filename}_word2idx.pkl'\n","idx2word_filename = f'{notebook_filename}_idx2word.pkl'\n","tag2idx_filename = f'{notebook_filename}_tag2idx.pkl'\n","idx2tag_filename = f'{notebook_filename}_idx2tag.pkl'\n","\n","others_filename = f'{notebook_filename}_others.pkl'\n","\n","# Re-get important variables\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","def get_backup_files_ids(folder_id):\n","  file_list = drive.ListFile({'q': \"'{}' in parents and trashed=false\".format(folder_id)}).GetList()\n","  return file_list\n","\n","def load_backup_dataset(file_id):\n","  downloaded = drive.CreateFile({'id':file_id})\n","  downloaded.GetContentFile(f\"{file_id}.csv\")\n","\n","  dataset = pd.read_csv(f\"{file_id}.csv\", encoding=\"latin1\")\n","  dataset = dataset.values.tolist()\n","  dataset = [ [ int(word) for word in sentence if str(word) != 'nan' ] for sentence in dataset]\n","  return dataset\n","\n","def load_backup_dict(file_id):\n","  downloaded = drive.CreateFile({'id':file_id})\n","  downloaded.GetContentFile(f\"{file_id}.pkl\")\n","\n","  dict_file = open(f\"{file_id}.pkl\", \"rb\")\n","  out_dict = pickle.load(dict_file)\n","  return out_dict\n","\n","backup_file_list = get_backup_files_ids(BACKUP_FOLDER_ID)\n","\n","X_train_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == X_train_filename][0]['id']\n","y_train_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == y_train_filename][0]['id']\n","X_dev_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == X_dev_filename][0]['id']\n","y_dev_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == y_dev_filename][0]['id']\n","X_test_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == X_test_filename][0]['id']\n","y_test_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == y_test_filename][0]['id']\n","\n","word2idx_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == word2idx_filename][0]['id']\n","idx2word_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == idx2word_filename][0]['id']\n","tag2idx_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == tag2idx_filename][0]['id']\n","idx2tag_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == idx2tag_filename][0]['id']\n","\n","others_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == others_filename][0]['id']\n","\n","X_train = load_backup_dataset(X_train_file_id)\n","y_train = load_backup_dataset(y_train_file_id)\n","X_dev = load_backup_dataset(X_dev_file_id)\n","y_dev = load_backup_dataset(y_dev_file_id)\n","X_test = load_backup_dataset(X_test_file_id)\n","y_test = load_backup_dataset(y_test_file_id)\n","\n","word2idx = load_backup_dict(word2idx_file_id)\n","idx2word = load_backup_dict(idx2word_file_id)\n","tag2idx = load_backup_dict(tag2idx_file_id)\n","idx2tag = load_backup_dict(idx2tag_file_id)\n","\n","others = load_backup_dict(others_file_id)\n","\n","n_words = others[\"n_words\"]\n","n_tags = others[\"n_tags\"]\n","\n","# Check some points after loading data to see if they match the ones before saving\n","print(X_train[0])\n","print(y_train[0])\n","print(X_dev[0])\n","print(y_dev[0])\n","print(X_test[0])\n","print(y_test[0])\n","print(word2idx['comprehension'])\n","print(tag2idx['B-treatment'])\n","print(idx2tag[2])\n","print(idx2word[100])\n","print(n_words)\n","print(n_tags)"],"id":"zvip_oC0j5-y"},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["2a8b97b643de4b7090020a5a1e412dde","6c766dca95cd4bb5bf62faa40269e618","5d292bbc495248e89614c1989ffaf5d5","dc4fa025cfc84c3fb8cfab0384657e47","609a22dcb24645acb33a7efb07f39711","eb46cd9bb8ea4cfa8ed71b7edef5c2b2","661f0c39c0c94415b17d888f62a683fc","761ec7234a454d40a439bfffd2f0129d","6c88382be4c14906947389574acd0467","ca27e05c6dc74f619ad070173ab74b19","bde7203c65044ed58abe386dbe26c763","0b89087260c045aaaf156d81497b267d","63f376cdfecf465396cc12136e5a690a","b77882f55419482a9653a23c8291d4a1","3202025588b9490fbb03453ce032da2e","f81c5c220d724042a84b5ba277916b23","8cbe5ab9a7924f8bae4f32db63e8ca0a","a4bf4ec0b3ea4568a69046943e81182d","bd06bd4f769f4617ac2d6c4261c4625c","3589329714bb4931a8784242036796b3","1a7f90344ae0410382bcc91dea062da8","5f394a93fe094487ad36bf4448ae1a0e"]},"executionInfo":{"elapsed":9567,"status":"ok","timestamp":1667797796829,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"2wRVTj71hovp","outputId":"03833758-1e9e-4d04-dc98-1d7ca6eff35c"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/385 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a8b97b643de4b7090020a5a1e412dde"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/228k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b89087260c045aaaf156d81497b267d"}},"metadata":{}}],"source":["tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n","\n","from transformers import pipeline\n","from future.utils import iteritems\n","\n","# Augmentation function using entity replacement technique.\n","# It will generate a new dataset, with X% more points based on\n","# the original dataset. E.g.: if you set augmentation percentage as 0.5 and dataset has\n","# 1000 points, it will generate a dataset with 1500 points.\n","\n","def generate_sentences(dataset, labels, augmented_set_size_percentage):\n","    if augmented_set_size_percentage < 0:\n","        raise Exception(\"Invalid augmented set size percentage\")\n","\n","    unmasker = pipeline('fill-mask', model='allenai/scibert_scivocab_uncased')\n","    \n","    number_of_new_sentences = math.ceil(augmented_set_size_percentage * len(dataset))\n","\n","    valid_dataset_idxs = [i for i,labels in enumerate(labels) if tag2idx[\"O\"] in labels]\n","    valid_dataset_sents = [sent for i,sent in enumerate(dataset) if i in valid_dataset_idxs]\n","    valid_dataset_labels = [labels for i,labels in enumerate(labels) if i in valid_dataset_idxs]\n","\n","    random_idxs = np.random.choice(len(valid_dataset_sents), number_of_new_sentences, replace=True)\n","    base_labels = [valid_dataset_labels[i] for i in random_idxs]\n","\n","    if not all([tag2idx[\"O\"] in labels for labels in base_labels]):\n","        raise Exception(\"Sentence without 'O'-tagged token in the dataset!!!\")\n","\n","    base_sequences = [valid_dataset_sents[i] for i in random_idxs]\n","\n","    new_sequences = []\n","    new_labels = []\n","    \n","    for k, sequence in enumerate(base_sequences):\n","      sequence_str = [idx2word[word] for word in sequence]\n","\n","      # check max number of tokens bert support and truncate sentence before augmentation\n","      # augmented sentence will be shorter than original sentence if higher than bert limit\n","      encoding = tokenizer(sequence_str,\n","                             is_split_into_words=True, \n","                             return_offsets_mapping=True, \n","                             truncation=True, \n","                             max_length=512)\n","      \n","      max_n_of_tokens = len([mapping for mapping in encoding[\"offset_mapping\"] if mapping[0] == 0 and mapping[1] != 0])\n","\n","      truncated_sequence_str = sequence_str[:max_n_of_tokens]\n","      truncated_labels = base_labels[k][:max_n_of_tokens]\n","\n","      # print(len(sequence_str),len(truncated_sequence_str),len(base_labels[k]),len(truncated_labels))\n","\n","      replaceable_indices = [i for i,label in enumerate(truncated_labels) if label == tag2idx[\"O\"]]\n","      replace_percent = round(random.uniform(0.1, 1), 1)\n","      replace_qty = max(math.floor(replace_percent*len(replaceable_indices)), 1)\n","      replace_indices = random.sample(replaceable_indices, k=replace_qty)\n","      replace_indices.sort()\n","\n","      masked_text_list = [\"[MASK]\" if i in replace_indices else word for i,word in enumerate(truncated_sequence_str)]\n","      new_mask_sent = ' '.join(masked_text_list)\n","      augmented_text_list = unmasker(new_mask_sent)\n","\n","      augmented_sentence = truncated_sequence_str.copy()\n","      if len(replace_indices) == 1:\n","        augmented_text_list = [augmented_text_list]\n","\n","      for i,index in enumerate(replace_indices):\n","        available_words = [word[\"token_str\"] for word in augmented_text_list[i] if word[\"token_str\"] != truncated_sequence_str[index]]\n","        new_word = random.choice(available_words)\n","        if new_word != \"[UNK]\":\n","          augmented_sentence[index] = new_word\n","\n","      # print(\"Original text->\",len(sequence_str),sequence_str)\n","      # print(\"Augmented text->\",len(sequence_str),augmented_sentence)\n","\n","      new_sequences.append(augmented_sentence)\n","      new_labels.append(truncated_labels)\n","\n","    all_words = list(set([word for seq in new_sequences for word in seq]))\n","    updated_word2idx = word2idx.copy()\n","    updated_idx2word = idx2word.copy()\n","    for word in all_words:\n","      try:\n","        updated_word2idx[word]\n","      except:\n","        updated_word2idx[word] = len(updated_word2idx)\n","    updated_idx2word = {i: w for w, i in iteritems(updated_word2idx)}\n","\n","    new_sequences = [[updated_word2idx[word] for word in seq] for seq in new_sequences]\n","\n","    augmented_X_train = dataset + new_sequences\n","    augmented_y_train = labels + new_labels\n","\n","    print(f\"Points in X_train after augmentation: {len(augmented_X_train)}\")\n","    print(f\"Points in y_train after augmentation: {len(augmented_y_train)}\")\n","\n","    return augmented_X_train, augmented_y_train, updated_word2idx, updated_idx2word"],"id":"2wRVTj71hovp"},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":4234,"status":"ok","timestamp":1667797801060,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"mYHzTnzZZfBg"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n","\n","class dataset(Dataset):\n","  def __init__(self, dataframe, tokenizer, max_len):\n","        self.len = len(dataframe)\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","  def __getitem__(self, index):\n","        # step 1: get the sentence and word labels\n","        sentence = self.data.sentence[index]\n","        word_labels = self.data.word_labels[index].split(\",\") \n","\n","        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n","        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n","        encoding = self.tokenizer(sentence,\n","                             is_split_into_words=True, \n","                             return_offsets_mapping=True, \n","                             padding='max_length', \n","                             truncation=True, \n","                             max_length=self.max_len)\n","        \n","        # step 3: create token labels only for first word pieces of each tokenized word\n","        labels = [tag2idx[label] for label in word_labels] \n","        # code based on https://huggingface.co/transformers/custom_datasets.html#tok-ner\n","        # create an empty array of -100 of length max_length\n","        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n","        \n","        # set only labels whose first offset position is 0 and the second is not 0\n","        i = 0\n","        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n","          if mapping[0] == 0 and mapping[1] != 0:\n","            # overwrite label\n","            encoded_labels[idx] = labels[i]\n","            i += 1\n","\n","        # step 4: turn everything into PyTorch tensors\n","        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n","        item['labels'] = torch.as_tensor(encoded_labels)\n","        \n","        return item\n","\n","  def __len__(self):\n","        return self.len"],"id":"mYHzTnzZZfBg"},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1667797801060,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"d8H1s-6b_-pM"},"outputs":[],"source":["# some configuration variables\n","LEARNING_RATE = 5e-05\n","MAX_GRAD_NORM = 10\n","TRAINING_STOP_LOSS_PERCENTAGE = 1\n","\n","# Model creation function\n","def create_model(maxlen, n_labels, training_set, testing_set, validation_set):\n","  device = 'cuda' if cuda.is_available() else 'cpu'\n","  print(\"Device: \", device)\n","\n","  model = BertForTokenClassification.from_pretrained('allenai/scibert_scivocab_uncased', num_labels=n_labels)\n","  model.to(device)\n","\n","  optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n","\n","  TRAIN_BATCH_SIZE = round(0.05*len(training_set))\n","  if TRAIN_BATCH_SIZE > 32:\n","    TRAIN_BATCH_SIZE = 32\n","  if TRAIN_BATCH_SIZE < 10:\n","    TRAIN_BATCH_SIZE = 10\n","\n","  VALID_BATCH_SIZE = round(0.1*len(validation_set))\n","  if VALID_BATCH_SIZE > 32:\n","    VALID_BATCH_SIZE = 32\n","  if VALID_BATCH_SIZE < 10:\n","    VALID_BATCH_SIZE = 10\n","\n","  train_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                  'shuffle': True,\n","                  'num_workers': 0\n","                  }\n","\n","  test_params = {'batch_size': VALID_BATCH_SIZE,\n","                  'shuffle': True,\n","                  'num_workers': 0\n","                  }\n","\n","  training_loader = DataLoader(training_set, **train_params)\n","  testing_loader = DataLoader(testing_set, **test_params)\n","  validation_loader = DataLoader(validation_set, **test_params)\n","\n","  return model, device, optimizer, training_loader, testing_loader, validation_loader"],"id":"d8H1s-6b_-pM"},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1667797801060,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"cjp-jXx4AmiV"},"outputs":[],"source":["# Model training function\n","def train(model, device, optimizer, training_loader, epoch, training_stop_loss_percentage):\n","    tr_loss, tr_accuracy = 0, 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","    tr_preds, tr_labels = [], []\n","    losses = []\n","    # put model in training mode\n","    model.train()\n","    \n","    for idx, batch in enumerate(training_loader):\n","        \n","        ids = batch['input_ids'].to(device, dtype = torch.long)\n","        mask = batch['attention_mask'].to(device, dtype = torch.long)\n","        labels = batch['labels'].to(device, dtype = torch.long)\n","\n","        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels, return_dict = False)\n","        tr_loss += loss.item()\n","\n","        nb_tr_steps += 1\n","        nb_tr_examples += labels.size(0)\n","        \n","        if idx % 100==0:\n","            loss_step = tr_loss/nb_tr_steps\n","            print(f\"Training loss per 100 training steps: {loss_step}\")\n","            losses.append(loss_step)\n","            last_5_losses = losses[-5:]\n","            loss_min = min(last_5_losses)\n","            loss_max = max(last_5_losses)\n","            if len(last_5_losses) > 1 and (loss_max - loss_min)/loss_max < training_stop_loss_percentage/100:\n","              print(\"Stopping epoch...\")\n","              break\n","           \n","        # compute training accuracy\n","        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","        \n","        # only compute accuracy at active labels\n","        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n","        \n","        labels = torch.masked_select(flattened_targets, active_accuracy)\n","        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","        \n","        tr_labels.extend(labels)\n","        tr_preds.extend(predictions)\n","\n","        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n","        tr_accuracy += tmp_tr_accuracy\n","    \n","        # gradient clipping\n","        torch.nn.utils.clip_grad_norm_(\n","            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n","        )\n","        \n","        # backward pass\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    epoch_loss = tr_loss / nb_tr_steps\n","    tr_accuracy = tr_accuracy / nb_tr_steps\n","    print(f\"Training loss epoch: {epoch_loss}\")\n","    print(f\"Training accuracy epoch: {tr_accuracy}\")"],"id":"cjp-jXx4AmiV"},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1667797801061,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"JvdztU6FA8Bd"},"outputs":[],"source":["# Model testing function\n","def test(model, device, testing_loader):\n","    print(\"Validating model...\")\n","    # put model in evaluation mode\n","    model.eval()\n","    \n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_examples, nb_eval_steps = 0, 0\n","    eval_preds, eval_labels = [], []\n","    \n","    with torch.no_grad():\n","        for idx, batch in enumerate(testing_loader):\n","            \n","            ids = batch['input_ids'].to(device, dtype = torch.long)\n","            mask = batch['attention_mask'].to(device, dtype = torch.long)\n","            labels = batch['labels'].to(device, dtype = torch.long)\n","            \n","            loss, eval_logits = model(input_ids=ids, attention_mask=mask, labels=labels, return_dict = False)\n","            \n","            eval_loss += loss.item()\n","\n","            nb_eval_steps += 1\n","            nb_eval_examples += labels.size(0)\n","        \n","            # compute evaluation accuracy\n","            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","            \n","            # only compute accuracy at active labels\n","            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","        \n","            labels = torch.masked_select(flattened_targets, active_accuracy)\n","            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","            \n","            eval_labels.extend(labels)\n","            eval_preds.extend(predictions)\n","            \n","            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n","            eval_accuracy += tmp_eval_accuracy\n","\n","    labels = [idx2tag[id.item()] for id in eval_labels]\n","    predictions = [idx2tag[id.item()] for id in eval_preds]\n","    \n","    eval_loss = eval_loss / nb_eval_steps\n","    eval_accuracy = eval_accuracy / nb_eval_steps\n","    print(f\"Validation Loss: {eval_loss}\")\n","    print(f\"Validation Accuracy: {eval_accuracy}\")\n","\n","    return labels, predictions, eval_loss"],"id":"JvdztU6FA8Bd"},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1667797801061,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"jMknjbDrh6Fk"},"outputs":[],"source":["def create_train_and_validate_model(augmented_percentage):\n","\n","  augmented_X_train, augmented_y_train, updated_word2idx, updated_idx2word = generate_sentences(X_train, y_train, augmented_percentage)\n","\n","  maxlen_X_train = max([len(s) for s in augmented_X_train])\n","  maxlen_X_test = max([len(s) for s in X_test])\n","  maxlen_X_dev = max([len(s) for s in X_dev])\n","  maxlen_y_train = max([len(s) for s in augmented_y_train])\n","  maxlen_y_test = max([len(s) for s in y_test])\n","  maxlen_y_dev = max([len(s) for s in y_dev])\n","\n","  maxlen = max([maxlen_X_train, maxlen_X_test, maxlen_X_dev, maxlen_y_train, maxlen_y_test, maxlen_y_dev])\n","\n","  if maxlen > 512:\n","    maxlen = 512\n","\n","  augmented_X_train_words = [[updated_idx2word[word] for word in sentence] for sentence in augmented_X_train]\n","  X_dev_words = [[updated_idx2word[word] for word in sentence] for sentence in X_dev]\n","  X_test_words = [[updated_idx2word[word] for word in sentence] for sentence in X_test]\n","  augmented_y_train_tags = [','.join([idx2tag[tag] for tag in sentence]) for sentence in augmented_y_train]\n","  y_dev_tags = [','.join([idx2tag[tag] for tag in sentence]) for sentence in y_dev]\n","  y_test_tags = [','.join([idx2tag[tag] for tag in sentence]) for sentence in y_test]\n","\n","  new_train_df = pd.DataFrame({\"sentence\": augmented_X_train_words, \"word_labels\": augmented_y_train_tags}).reset_index(drop=True)\n","  new_test_df = pd.DataFrame({\"sentence\": X_test_words, \"word_labels\": y_test_tags}).reset_index(drop=True)\n","  new_val_df = pd.DataFrame({\"sentence\": X_dev_words, \"word_labels\": y_dev_tags}).reset_index(drop=True)\n","\n","  training_set = dataset(new_train_df, tokenizer, maxlen)\n","  testing_set = dataset(new_test_df, tokenizer, maxlen)\n","  validation_set = dataset(new_val_df, tokenizer, maxlen)\n","\n","  model, device, optimizer, training_loader, testing_loader, val_loader = create_model(maxlen, len(tag2idx), training_set, testing_set, validation_set)\n","\n","  training_start_time = time.clock()\n","  min_val_loss = 0\n","  MAX_PATIENCE = 5\n","  patience = 0\n","\n","  for epoch in range(100):\n","    print(f\"Training epoch: {epoch + 1}\")\n","    if patience == MAX_PATIENCE:\n","      print(\"Patience limit reached\")\n","      break\n","    train(model, device, optimizer, training_loader, epoch, TRAINING_STOP_LOSS_PERCENTAGE)\n","    labels, predictions, val_loss = test(model, device, val_loader)\n","    if ((min_val_loss == 0) or (min_val_loss != 0 and val_loss < min_val_loss)):\n","      min_val_loss = val_loss\n","      torch.save(model.state_dict(), 'checkpoint.pt')\n","      patience = 0\n","    else:\n","      patience = patience + 1\n","  print(f\"Training duration: {(time.clock() - training_start_time)/60} minutes\")\n","\n","  checkpoint = torch.load('checkpoint.pt')\n","  model.load_state_dict(checkpoint)\n","\n","  validation_start_time = time.clock()\n","  labels, predictions, test_loss = test(model, device, testing_loader)\n","  labels = [labels]\n","  predictions = [predictions]\n","  print(f\"Validation duration: {(time.clock() - validation_start_time)/60} minutes\")\n","\n","  print(\"F1-score (test): {:.1%}\".format(f1_score(labels, predictions)))\n","  print(classification_report(labels, predictions))"],"id":"jMknjbDrh6Fk"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["196ec565e27846a88f90317c418222ca","fd5d4ffabc3246d4bf1448a2ffbfec5c","11cc85243f43445c98c5b05ed0bce628","ed73f1fc06074b2cb67309be8a3ea929","bd744a1c91be49589a90a62d75376492","5f19cc0d5b1141bf97eea7de0b3554ee","bea9a733a36b4170ac5edea2bd4de384","75a80bf75ecd40ea8615cde224b7bf57","b852009c08084950af88673efcd6adf7","aa641c6bd151407ba1c53079a142aa58","6fbff192aef143c3ba4158b951a5e29d"]},"executionInfo":{"elapsed":25985325,"status":"ok","timestamp":1667519461971,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"Jhz9BiIwGCsV","outputId":"b49bf6ad-e213-493a-89a5-99bd6eb017b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 25.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"196ec565e27846a88f90317c418222ca","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 8668\n","Points in y_train after augmentation: 8668\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.151399850845337\n","Training loss per 100 training steps: 0.4115949422858729\n","Training loss per 100 training steps: 0.3064652738434758\n","Training loss epoch: 0.27063679486183223\n","Training accuracy epoch: 0.9153756369911416\n","Validating model...\n","Validation Loss: 0.16597268169189427\n","Validation Accuracy: 0.9483588865097369\n","Training epoch: 2\n","Training loss per 100 training steps: 0.1792663335800171\n","Training loss per 100 training steps: 0.09657939554809934\n","Training loss per 100 training steps: 0.09692429614007769\n","Training loss epoch: 0.09691595978952422\n","Training accuracy epoch: 0.9702651811091888\n","Validating model...\n","Validation Loss: 0.15086433978436828\n","Validation Accuracy: 0.9544215447125948\n","Training epoch: 3\n","Training loss per 100 training steps: 0.08653587847948074\n","Training loss per 100 training steps: 0.05235556599287556\n","Training loss per 100 training steps: 0.054041009769306994\n","Training loss epoch: 0.057012589028057024\n","Training accuracy epoch: 0.9823248987630935\n","Validating model...\n","Validation Loss: 0.18063426090331822\n","Validation Accuracy: 0.951535653245676\n","Training epoch: 4\n","Training loss per 100 training steps: 0.11468103528022766\n","Training loss per 100 training steps: 0.04787778511809388\n","Training loss per 100 training steps: 0.04674071049206515\n","Training loss epoch: 0.046718377363953976\n","Training accuracy epoch: 0.985991760972752\n","Validating model...\n","Validation Loss: 0.1830806854338228\n","Validation Accuracy: 0.954442120500096\n","Training epoch: 5\n","Training loss per 100 training steps: 0.015807580202817917\n","Training loss per 100 training steps: 0.025001435827620624\n","Training loss per 100 training steps: 0.03139250683517135\n","Training loss epoch: 0.0328882190315534\n","Training accuracy epoch: 0.9900376314823722\n","Validating model...\n","Validation Loss: 0.18264478466824277\n","Validation Accuracy: 0.9543592652826199\n","Training epoch: 6\n","Training loss per 100 training steps: 0.05104585364460945\n","Training loss per 100 training steps: 0.016954208747253265\n","Training loss per 100 training steps: 0.02026714087030688\n","Training loss epoch: 0.023912242724134062\n","Training accuracy epoch: 0.9928558197699393\n","Validating model...\n","Validation Loss: 0.19602652987489452\n","Validation Accuracy: 0.951164213011162\n","Training epoch: 7\n","Training loss per 100 training steps: 0.004365784116089344\n","Training loss per 100 training steps: 0.0217482625186388\n","Training loss per 100 training steps: 0.029555396406230196\n","Training loss epoch: 0.032489545904512335\n","Training accuracy epoch: 0.9897668306265871\n","Validating model...\n","Validation Loss: 0.21886422313967502\n","Validation Accuracy: 0.9522649409387756\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 37.031422649999996 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16239074941862514\n","Validation Accuracy: 0.9530746565316238\n","Validation duration: 5.954127833333336 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.1%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.85      0.83     12546\n","        test       0.82      0.85      0.83      9012\n","   treatment       0.81      0.85      0.83      9297\n","\n","   micro avg       0.81      0.85      0.83     30855\n","   macro avg       0.81      0.85      0.83     30855\n","weighted avg       0.81      0.85      0.83     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 8668\n","Points in y_train after augmentation: 8668\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.826480746269226\n","Training loss per 100 training steps: 0.4122780197770289\n","Training loss per 100 training steps: 0.30625499981404536\n","Training loss epoch: 0.26981400222795915\n","Training accuracy epoch: 0.9154987261179502\n","Validating model...\n","Validation Loss: 0.16165607949936545\n","Validation Accuracy: 0.9472850595540966\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06183552369475365\n","Training loss per 100 training steps: 0.09761359667091972\n","Training loss per 100 training steps: 0.0991467017383866\n","Training loss epoch: 0.098034244539333\n","Training accuracy epoch: 0.9690005453955887\n","Validating model...\n","Validation Loss: 0.15574332360516896\n","Validation Accuracy: 0.9534672879423451\n","Training epoch: 3\n","Training loss per 100 training steps: 0.042956169694662094\n","Training loss per 100 training steps: 0.04776348097544938\n","Training loss per 100 training steps: 0.05250109122621257\n","Training loss epoch: 0.057204626935338294\n","Training accuracy epoch: 0.982497410655629\n","Validating model...\n","Validation Loss: 0.16174986448090573\n","Validation Accuracy: 0.9566191823672304\n","Training epoch: 4\n","Training loss per 100 training steps: 0.020343773066997528\n","Training loss per 100 training steps: 0.03467231370637765\n","Training loss per 100 training steps: 0.033156259563422545\n","Training loss epoch: 0.034398068575106036\n","Training accuracy epoch: 0.9897373066669756\n","Validating model...\n","Validation Loss: 0.1816402871113319\n","Validation Accuracy: 0.9528034265967401\n","Training epoch: 5\n","Training loss per 100 training steps: 0.04789220541715622\n","Training loss per 100 training steps: 0.02563740449063111\n","Training loss per 100 training steps: 0.026675392012922697\n","Training loss epoch: 0.026888004449158356\n","Training accuracy epoch: 0.9921026254762703\n","Validating model...\n","Validation Loss: 0.21423987405640738\n","Validation Accuracy: 0.9519988227803081\n","Training epoch: 6\n","Training loss per 100 training steps: 0.04289912432432175\n","Training loss per 100 training steps: 0.018395645920265612\n","Training loss per 100 training steps: 0.019974785149433367\n","Training loss epoch: 0.021211286298148814\n","Training accuracy epoch: 0.9936094789126289\n","Validating model...\n","Validation Loss: 0.21093850365126288\n","Validation Accuracy: 0.9527428106251437\n","Training epoch: 7\n","Training loss per 100 training steps: 0.015195299871265888\n","Training loss per 100 training steps: 0.01380834912640356\n","Training loss per 100 training steps: 0.016720873930384936\n","Training loss epoch: 0.017763136283363942\n","Training accuracy epoch: 0.9947987523732095\n","Validating model...\n","Validation Loss: 0.2093230029568076\n","Validation Accuracy: 0.9554042766526679\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 37.16790421666667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1650455121330365\n","Validation Accuracy: 0.9515924850879081\n","Validation duration: 5.931834949999999 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.85      0.83     12546\n","        test       0.87      0.82      0.85      9012\n","   treatment       0.84      0.81      0.83      9297\n","\n","   micro avg       0.83      0.83      0.83     30855\n","   macro avg       0.84      0.83      0.83     30855\n","weighted avg       0.83      0.83      0.83     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 8668\n","Points in y_train after augmentation: 8668\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.2622883319854736\n","Training loss per 100 training steps: 0.40661945747266903\n","Training loss per 100 training steps: 0.29889720852547025\n","Training loss epoch: 0.2653806631992884\n","Training accuracy epoch: 0.9165842087307297\n","Validating model...\n","Validation Loss: 0.15558048773121524\n","Validation Accuracy: 0.9513770821445604\n","Training epoch: 2\n","Training loss per 100 training steps: 0.12803953886032104\n","Training loss per 100 training steps: 0.09515305532898644\n","Training loss per 100 training steps: 0.10009080456078645\n","Training loss epoch: 0.09815838410625599\n","Training accuracy epoch: 0.9684751625007596\n","Validating model...\n","Validation Loss: 0.16103416572433787\n","Validation Accuracy: 0.9520289077535599\n","Training epoch: 3\n","Training loss per 100 training steps: 0.07546047121286392\n","Training loss per 100 training steps: 0.050279862127534235\n","Training loss per 100 training steps: 0.05254754284860112\n","Training loss epoch: 0.05326733956237176\n","Training accuracy epoch: 0.9829747927150034\n","Validating model...\n","Validation Loss: 0.1637081660620578\n","Validation Accuracy: 0.954591859043464\n","Training epoch: 4\n","Training loss per 100 training steps: 0.05051502212882042\n","Training loss per 100 training steps: 0.03295747590214383\n","Training loss per 100 training steps: 0.03258866352545774\n","Training loss epoch: 0.035124836015734975\n","Training accuracy epoch: 0.9890202220458054\n","Validating model...\n","Validation Loss: 0.18224429926992236\n","Validation Accuracy: 0.9561402186449939\n","Training epoch: 5\n","Training loss per 100 training steps: 0.02294914610683918\n","Training loss per 100 training steps: 0.02358052732842504\n","Training loss per 100 training steps: 0.029237642070505564\n","Training loss epoch: 0.03103850932484252\n","Training accuracy epoch: 0.9907965903940863\n","Validating model...\n","Validation Loss: 0.19290508996308237\n","Validation Accuracy: 0.9570906306983725\n","Training epoch: 6\n","Training loss per 100 training steps: 0.016128046438097954\n","Training loss per 100 training steps: 0.021571764780097816\n","Training loss per 100 training steps: 0.02376497429922983\n","Training loss epoch: 0.02388739029273762\n","Training accuracy epoch: 0.9925535896985725\n","Validating model...\n","Validation Loss: 0.222404830060996\n","Validation Accuracy: 0.9537371444497754\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 31.830354500000006 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15767407097586397\n","Validation Accuracy: 0.9501286236747346\n","Validation duration: 5.914809666666664 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.82      0.82     12546\n","        test       0.78      0.88      0.83      9012\n","   treatment       0.81      0.84      0.83      9297\n","\n","   micro avg       0.81      0.85      0.83     30855\n","   macro avg       0.81      0.85      0.83     30855\n","weighted avg       0.81      0.85      0.83     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 8668\n","Points in y_train after augmentation: 8668\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8051694631576538\n","Training loss per 100 training steps: 0.40624354056792683\n","Training loss per 100 training steps: 0.29309032369979576\n","Training loss epoch: 0.2607279098644248\n","Training accuracy epoch: 0.9171089228750317\n","Validating model...\n","Validation Loss: 0.16570485441328645\n","Validation Accuracy: 0.9463575714528076\n","Training epoch: 2\n","Training loss per 100 training steps: 0.11285821348428726\n","Training loss per 100 training steps: 0.09827109169915761\n","Training loss per 100 training steps: 0.09284716537824614\n","Training loss epoch: 0.09587578898178915\n","Training accuracy epoch: 0.9699177864958731\n","Validating model...\n","Validation Loss: 0.14593689956448294\n","Validation Accuracy: 0.9537040097925018\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03267870098352432\n","Training loss per 100 training steps: 0.050088760138738274\n","Training loss per 100 training steps: 0.052885831384664746\n","Training loss epoch: 0.05371528582963611\n","Training accuracy epoch: 0.9837430756894943\n","Validating model...\n","Validation Loss: 0.15822312615618303\n","Validation Accuracy: 0.9550302605711748\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03699851781129837\n","Training loss per 100 training steps: 0.04120498826026474\n","Training loss per 100 training steps: 0.04183273895212741\n","Training loss epoch: 0.04109801014033026\n","Training accuracy epoch: 0.9875238520050056\n","Validating model...\n","Validation Loss: 0.1847184221320725\n","Validation Accuracy: 0.9555859541670795\n","Training epoch: 5\n","Training loss per 100 training steps: 0.02373926155269146\n","Training loss per 100 training steps: 0.023730308900928438\n","Stopping epoch...\n","Training loss epoch: 0.023730308900928438\n","Training accuracy epoch: 0.9834426707986307\n","Validating model...\n","Validation Loss: 0.17890213062236834\n","Validation Accuracy: 0.9554223786635695\n","Training epoch: 6\n","Training loss per 100 training steps: 0.010192430578172207\n","Training loss per 100 training steps: 0.019362981036987782\n","Training loss per 100 training steps: 0.025553394206313054\n","Training loss epoch: 0.02572173715184178\n","Training accuracy epoch: 0.9926461960632569\n","Validating model...\n","Validation Loss: 0.1836384053148523\n","Validation Accuracy: 0.9554435815204777\n","Training epoch: 7\n","Training loss per 100 training steps: 0.08218459784984589\n","Training loss per 100 training steps: 0.0224589469109542\n","Training loss per 100 training steps: 0.019425011632051226\n","Training loss epoch: 0.01999677094799291\n","Training accuracy epoch: 0.9939528369739796\n","Validating model...\n","Validation Loss: 0.20780880076738148\n","Validation Accuracy: 0.9520318422348364\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 34.130151066666684 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1556895544959439\n","Validation Accuracy: 0.9522830987033226\n","Validation duration: 5.919590316666654 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.84      0.83     12546\n","        test       0.82      0.88      0.85      9012\n","   treatment       0.80      0.86      0.83      9297\n","\n","   micro avg       0.81      0.86      0.83     30855\n","   macro avg       0.81      0.86      0.84     30855\n","weighted avg       0.81      0.86      0.83     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 8668\n","Points in y_train after augmentation: 8668\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0288798809051514\n","Training loss per 100 training steps: 0.39746451894245527\n","Training loss per 100 training steps: 0.29832814960040854\n","Training loss epoch: 0.2630175055860373\n","Training accuracy epoch: 0.9164902610202214\n","Validating model...\n","Validation Loss: 0.1610999538430146\n","Validation Accuracy: 0.9489194868003487\n","Training epoch: 2\n","Training loss per 100 training steps: 0.1392158567905426\n","Training loss per 100 training steps: 0.10063136053631211\n","Training loss per 100 training steps: 0.09477535110726878\n","Training loss epoch: 0.09667768243466576\n","Training accuracy epoch: 0.9695050447301359\n","Validating model...\n","Validation Loss: 0.16259073741830787\n","Validation Accuracy: 0.9486814081601774\n","Training epoch: 3\n","Training loss per 100 training steps: 0.033520810306072235\n","Training loss per 100 training steps: 0.05827732957290983\n","Training loss per 100 training steps: 0.056063363057519515\n","Training loss epoch: 0.05434575156614569\n","Training accuracy epoch: 0.9822705005638973\n","Validating model...\n","Validation Loss: 0.15741399557075716\n","Validation Accuracy: 0.9560810431762387\n","Training epoch: 4\n","Training loss per 100 training steps: 0.027968507260084152\n","Training loss per 100 training steps: 0.03368265572520397\n","Training loss per 100 training steps: 0.033277964769672624\n","Training loss epoch: 0.034684342727395\n","Training accuracy epoch: 0.9895473500558405\n","Validating model...\n","Validation Loss: 0.19361048438525819\n","Validation Accuracy: 0.9530815182096348\n","Training epoch: 5\n","Training loss per 100 training steps: 0.011952967382967472\n","Training loss per 100 training steps: 0.024396698060906538\n","Training loss per 100 training steps: 0.026319986845792932\n","Training loss epoch: 0.025459192583691396\n","Training accuracy epoch: 0.9922757197110244\n","Validating model...\n","Validation Loss: 0.20748932653578459\n","Validation Accuracy: 0.9550818574934681\n","Training epoch: 6\n","Training loss per 100 training steps: 0.004683333914726973\n","Training loss per 100 training steps: 0.018295898656637437\n","Training loss per 100 training steps: 0.020408717853443427\n","Training loss epoch: 0.022167072557101913\n","Training accuracy epoch: 0.9933743305916398\n","Validating model...\n","Validation Loss: 0.21904063345743463\n","Validation Accuracy: 0.9545715317801424\n","Training epoch: 7\n","Training loss per 100 training steps: 0.009016730822622776\n","Training loss per 100 training steps: 0.017263500594492484\n","Training loss per 100 training steps: 0.018963016213128688\n","Training loss epoch: 0.0189288815436627\n","Training accuracy epoch: 0.9944456717207535\n","Validating model...\n","Validation Loss: 0.22122727442145734\n","Validation Accuracy: 0.9570466033472775\n","Training epoch: 8\n","Training loss per 100 training steps: 0.0009281389066018164\n","Training loss per 100 training steps: 0.014043094088625403\n","Training loss per 100 training steps: 0.017852480830978\n","Training loss epoch: 0.017540731074995573\n","Training accuracy epoch: 0.9945493310735847\n","Validating model...\n","Validation Loss: 0.22057063080515568\n","Validation Accuracy: 0.9545427171981969\n","Training epoch: 9\n","Patience limit reached\n","Training duration: 42.38896711666666 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1841167227615154\n","Validation Accuracy: 0.9521821254855078\n","Validation duration: 5.845924183333318 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.84      0.83     12546\n","        test       0.86      0.84      0.85      9012\n","   treatment       0.81      0.86      0.83      9297\n","\n","   micro avg       0.83      0.85      0.84     30855\n","   macro avg       0.83      0.85      0.84     30855\n","weighted avg       0.83      0.85      0.84     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 8668\n","Points in y_train after augmentation: 8668\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1030304431915283\n","Training loss per 100 training steps: 0.3738956138639167\n","Training loss per 100 training steps: 0.2792550281283274\n","Training loss epoch: 0.24972156461369507\n","Training accuracy epoch: 0.9222214701677245\n","Validating model...\n","Validation Loss: 0.15933166497520038\n","Validation Accuracy: 0.9503382013266529\n","Training epoch: 2\n","Training loss per 100 training steps: 0.11140038818120956\n","Training loss per 100 training steps: 0.09511663515747774\n","Training loss per 100 training steps: 0.09416189466357527\n","Training loss epoch: 0.09208349150182796\n","Training accuracy epoch: 0.9711337526181892\n","Validating model...\n","Validation Loss: 0.15728184875923318\n","Validation Accuracy: 0.9521647361018113\n","Training epoch: 3\n","Training loss per 100 training steps: 0.017846645787358284\n","Training loss per 100 training steps: 0.05425592556614244\n","Training loss per 100 training steps: 0.054687967975693405\n","Training loss epoch: 0.054811413700578945\n","Training accuracy epoch: 0.9829689265332814\n","Validating model...\n","Validation Loss: 0.17532450702742902\n","Validation Accuracy: 0.9529670230271513\n","Training epoch: 4\n","Training loss per 100 training steps: 0.023697784170508385\n","Training loss per 100 training steps: 0.029794966165750923\n","Training loss per 100 training steps: 0.034709702189131386\n","Training loss epoch: 0.03466264171976032\n","Training accuracy epoch: 0.9889219606388651\n","Validating model...\n","Validation Loss: 0.18010112742421688\n","Validation Accuracy: 0.9562201514813405\n","Training epoch: 5\n","Training loss per 100 training steps: 0.004802154842764139\n","Training loss per 100 training steps: 0.023136884526183624\n","Training loss per 100 training steps: 0.02305935131355805\n","Training loss epoch: 0.024518389990243965\n","Training accuracy epoch: 0.9923836518453293\n","Validating model...\n","Validation Loss: 0.19349475988706985\n","Validation Accuracy: 0.9555301552816271\n","Training epoch: 6\n","Training loss per 100 training steps: 0.011027687229216099\n","Training loss per 100 training steps: 0.029663432583139086\n","Training loss per 100 training steps: 0.02490950159587207\n","Training loss epoch: 0.023930815199297264\n","Training accuracy epoch: 0.9930845873892381\n","Validating model...\n","Validation Loss: 0.20907734841253464\n","Validation Accuracy: 0.9529387752534383\n","Training epoch: 7\n","Training loss per 100 training steps: 0.012618438340723515\n","Training loss per 100 training steps: 0.018075625717900418\n","Training loss per 100 training steps: 0.021223842251648552\n","Training loss epoch: 0.02053749243025599\n","Training accuracy epoch: 0.993760807451489\n","Validating model...\n","Validation Loss: 0.2132994120323716\n","Validation Accuracy: 0.9563643222948557\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 36.75298011666667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16498805322421337\n","Validation Accuracy: 0.9506977927244868\n","Validation duration: 5.849164416666644 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.8%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.85      0.83     12546\n","        test       0.79      0.86      0.83      9012\n","   treatment       0.83      0.83      0.83      9297\n","\n","   micro avg       0.81      0.85      0.83     30855\n","   macro avg       0.81      0.85      0.83     30855\n","weighted avg       0.81      0.85      0.83     30855\n","\n","!!!!!! Starting model number 7 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 8668\n","Points in y_train after augmentation: 8668\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.3156356811523438\n","Training loss per 100 training steps: 0.40711933691607843\n","Training loss per 100 training steps: 0.2962252138488328\n","Training loss epoch: 0.2711928889595275\n","Training accuracy epoch: 0.9148898813404654\n","Validating model...\n","Validation Loss: 0.1576894670241065\n","Validation Accuracy: 0.9501870591749728\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05503293499350548\n","Training loss per 100 training steps: 0.09776373237076372\n","Training loss per 100 training steps: 0.0939048812747817\n","Training loss epoch: 0.09685960332639652\n","Training accuracy epoch: 0.9700755769801273\n","Validating model...\n","Validation Loss: 0.15244685998791224\n","Validation Accuracy: 0.9545011523962104\n","Training epoch: 3\n","Training loss per 100 training steps: 0.10390399396419525\n","Training loss per 100 training steps: 0.05003781770678735\n","Training loss per 100 training steps: 0.05202407892376407\n","Training loss epoch: 0.053714974651051295\n","Training accuracy epoch: 0.9838086964647329\n","Validating model...\n","Validation Loss: 0.17747629833008563\n","Validation Accuracy: 0.9536320872423927\n","Training epoch: 4\n","Training loss per 100 training steps: 0.038388095796108246\n","Training loss per 100 training steps: 0.04077350619332035\n","Training loss per 100 training steps: 0.04199637747624546\n","Training loss epoch: 0.04570438350272465\n","Training accuracy epoch: 0.9859383767203582\n","Validating model...\n","Validation Loss: 0.18273976416169824\n","Validation Accuracy: 0.9515193843708436\n","Training epoch: 5\n","Training loss per 100 training steps: 0.027819130569696426\n","Training loss per 100 training steps: 0.03272999572973367\n","Training loss per 100 training steps: 0.034087385536305866\n","Training loss epoch: 0.033735268971817466\n","Training accuracy epoch: 0.9899036242171093\n","Validating model...\n","Validation Loss: 0.2151564842743146\n","Validation Accuracy: 0.9539919815035384\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0034014105331152678\n","Training loss per 100 training steps: 0.019908222758861276\n","Training loss per 100 training steps: 0.022477595653067534\n","Training loss epoch: 0.0229231129257383\n","Training accuracy epoch: 0.992865893265511\n","Validating model...\n","Validation Loss: 0.21629392301252523\n","Validation Accuracy: 0.9529793973593738\n","Training epoch: 7\n","Training loss per 100 training steps: 0.011539006605744362\n","Training loss per 100 training steps: 0.021343664044864697\n","Training loss per 100 training steps: 0.019713083461659096\n","Training loss epoch: 0.019549576145926718\n","Training accuracy epoch: 0.994267810596969\n","Validating model...\n","Validation Loss: 0.20810191681632748\n","Validation Accuracy: 0.955830634562732\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 36.76202475000003 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15488387747447835\n","Validation Accuracy: 0.9529901790497937\n","Validation duration: 5.856110850000005 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.85      0.82     12546\n","        test       0.85      0.87      0.86      9012\n","   treatment       0.83      0.84      0.84      9297\n","\n","   micro avg       0.82      0.85      0.84     30855\n","   macro avg       0.83      0.85      0.84     30855\n","weighted avg       0.82      0.85      0.84     30855\n","\n","!!!!!! Starting model number 8 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 8668\n","Points in y_train after augmentation: 8668\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.777787208557129\n","Training loss per 100 training steps: 0.41401948875719957\n","Training loss per 100 training steps: 0.30736035571910847\n","Training loss epoch: 0.27157389830344275\n","Training accuracy epoch: 0.9153184652017125\n","Validating model...\n","Validation Loss: 0.16444226349522542\n","Validation Accuracy: 0.9499925100992616\n","Training epoch: 2\n","Training loss per 100 training steps: 0.17005644738674164\n","Training loss per 100 training steps: 0.10098591970630211\n","Training loss per 100 training steps: 0.10002370733786281\n","Training loss epoch: 0.1012881855408204\n","Training accuracy epoch: 0.9685858924778858\n","Validating model...\n","Validation Loss: 0.1381693986159834\n","Validation Accuracy: 0.9547640070420172\n","Training epoch: 3\n","Training loss per 100 training steps: 0.1285429447889328\n","Training loss per 100 training steps: 0.05236952214289715\n","Training loss per 100 training steps: 0.05414861598427394\n","Training loss epoch: 0.054997337822255944\n","Training accuracy epoch: 0.9827491048715861\n","Validating model...\n","Validation Loss: 0.1875026369975372\n","Validation Accuracy: 0.9512883346822881\n","Training epoch: 4\n","Training loss per 100 training steps: 0.02282779850065708\n","Training loss per 100 training steps: 0.03173460806305013\n","Training loss per 100 training steps: 0.03539170603388318\n","Training loss epoch: 0.03801089547303028\n","Training accuracy epoch: 0.9883637850209551\n","Validating model...\n","Validation Loss: 0.1787384704916508\n","Validation Accuracy: 0.9530212096348448\n","Training epoch: 5\n","Training loss per 100 training steps: 0.020096318796277046\n","Training loss per 100 training steps: 0.02582008879179928\n","Training loss per 100 training steps: 0.02442806151021383\n","Training loss epoch: 0.024644931027841002\n","Training accuracy epoch: 0.9922751186077641\n","Validating model...\n","Validation Loss: 0.1983772325510909\n","Validation Accuracy: 0.9548663846615875\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0660313218832016\n","Training loss per 100 training steps: 0.021355683166109543\n","Training loss per 100 training steps: 0.023465274725415146\n","Training loss epoch: 0.023692543148423967\n","Training accuracy epoch: 0.9931336316264219\n","Validating model...\n","Validation Loss: 0.21621006994520303\n","Validation Accuracy: 0.9526118185366753\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0025262078270316124\n","Training loss per 100 training steps: 0.0168626842389833\n","Training loss per 100 training steps: 0.02055445263904765\n","Training loss epoch: 0.023905919030750327\n","Training accuracy epoch: 0.9928257622367027\n","Validating model...\n","Validation Loss: 0.21030596162906134\n","Validation Accuracy: 0.9543146736407324\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 36.770565349999984 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15006923743661632\n","Validation Accuracy: 0.9536677009272231\n","Validation duration: 5.839464983333346 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.85      0.82     12546\n","        test       0.83      0.86      0.85      9012\n","   treatment       0.83      0.85      0.84      9297\n","\n","   micro avg       0.82      0.85      0.84     30855\n","   macro avg       0.82      0.85      0.84     30855\n","weighted avg       0.82      0.85      0.84     30855\n","\n","!!!!!! Starting model number 9 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 8668\n","Points in y_train after augmentation: 8668\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0953991413116455\n","Training loss per 100 training steps: 0.4201182253880076\n","Training loss per 100 training steps: 0.30283338383803915\n","Training loss epoch: 0.2703872829180802\n","Training accuracy epoch: 0.9154235415937014\n","Validating model...\n","Validation Loss: 0.15994707369185113\n","Validation Accuracy: 0.9473411824914157\n","Training epoch: 2\n","Training loss per 100 training steps: 0.11023889482021332\n","Training loss per 100 training steps: 0.10623545015212332\n","Training loss per 100 training steps: 0.10432913640875426\n","Training loss epoch: 0.1024723050469787\n","Training accuracy epoch: 0.9669517443025836\n","Validating model...\n","Validation Loss: 0.15278644368729807\n","Validation Accuracy: 0.9556607239930456\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04537664353847504\n","Training loss per 100 training steps: 0.06068562826897839\n","Training loss per 100 training steps: 0.06413157543732752\n","Training loss epoch: 0.0636520068817583\n","Training accuracy epoch: 0.9804000672288163\n","Validating model...\n","Validation Loss: 0.1855770804883017\n","Validation Accuracy: 0.9502214435177303\n","Training epoch: 4\n","Training loss per 100 training steps: 0.11467751860618591\n","Training loss per 100 training steps: 0.03845167718712462\n","Training loss per 100 training steps: 0.045366036283450005\n","Training loss epoch: 0.04588408412100795\n","Training accuracy epoch: 0.9855828812855265\n","Validating model...\n","Validation Loss: 0.18794412497285898\n","Validation Accuracy: 0.9531755082876449\n","Training epoch: 5\n","Training loss per 100 training steps: 0.025290489196777344\n","Training loss per 100 training steps: 0.020562378439526675\n","Training loss per 100 training steps: 0.02652704119346387\n","Training loss epoch: 0.027673271624285494\n","Training accuracy epoch: 0.9912932995930035\n","Validating model...\n","Validation Loss: 0.20087155890832473\n","Validation Accuracy: 0.954075262494233\n","Training epoch: 6\n","Training loss per 100 training steps: 0.007247581612318754\n","Training loss per 100 training steps: 0.01849414257789123\n","Training loss per 100 training steps: 0.018841677134513707\n","Training loss epoch: 0.019779718799750247\n","Training accuracy epoch: 0.994211900858488\n","Validating model...\n","Validation Loss: 0.19995457400846017\n","Validation Accuracy: 0.9555921737723236\n","Training epoch: 7\n","Training loss per 100 training steps: 0.00889142882078886\n","Training loss per 100 training steps: 0.015629276673604576\n","Training loss per 100 training steps: 0.016216537509743698\n","Training loss epoch: 0.017790472464003632\n","Training accuracy epoch: 0.9946460230487423\n","Validating model...\n","Validation Loss: 0.21952418748337726\n","Validation Accuracy: 0.9559311551364851\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 36.75886233333331 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16660372470074367\n","Validation Accuracy: 0.951344276754785\n","Validation duration: 5.864311666666678 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.9%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.86      0.83     12546\n","        test       0.83      0.85      0.84      9012\n","   treatment       0.78      0.86      0.82      9297\n","\n","   micro avg       0.80      0.85      0.83     30855\n","   macro avg       0.81      0.85      0.83     30855\n","weighted avg       0.80      0.85      0.83     30855\n","\n","!!!!!! Starting model number 10 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 8668\n","Points in y_train after augmentation: 8668\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.763763666152954\n","Training loss per 100 training steps: 0.37862513177465684\n","Training loss per 100 training steps: 0.28749344568347457\n","Training loss epoch: 0.25680748534103603\n","Training accuracy epoch: 0.919538643316283\n","Validating model...\n","Validation Loss: 0.1507385578248408\n","Validation Accuracy: 0.9513257841895947\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09353027492761612\n","Training loss per 100 training steps: 0.08380394714819912\n","Training loss per 100 training steps: 0.09140569834844835\n","Training loss epoch: 0.09120088099842252\n","Training accuracy epoch: 0.9717302842419003\n","Validating model...\n","Validation Loss: 0.1599252431520394\n","Validation Accuracy: 0.9525959950323665\n","Training epoch: 3\n","Training loss per 100 training steps: 0.019989006221294403\n","Training loss per 100 training steps: 0.054430393654262964\n","Training loss per 100 training steps: 0.05307884989723341\n","Training loss epoch: 0.05678196784754961\n","Training accuracy epoch: 0.9823504892480713\n","Validating model...\n","Validation Loss: 0.18080484542947312\n","Validation Accuracy: 0.9503548042438804\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03333745151758194\n","Training loss per 100 training steps: 0.03094134291191355\n","Training loss per 100 training steps: 0.03223851170339877\n","Training loss epoch: 0.03415467873270661\n","Training accuracy epoch: 0.9891154199266784\n","Validating model...\n","Validation Loss: 0.18415978439636044\n","Validation Accuracy: 0.956865661931984\n","Training epoch: 5\n","Training loss per 100 training steps: 0.02935841493308544\n","Training loss per 100 training steps: 0.023414091095282225\n","Training loss per 100 training steps: 0.026559980239241908\n","Training loss epoch: 0.02667039461610873\n","Training accuracy epoch: 0.991708349156858\n","Validating model...\n","Validation Loss: 0.23283110525120387\n","Validation Accuracy: 0.9509344319009937\n","Training epoch: 6\n","Training loss per 100 training steps: 0.014402365311980247\n","Training loss per 100 training steps: 0.02018374520628298\n","Training loss per 100 training steps: 0.021284410327473722\n","Training loss epoch: 0.021300335376045747\n","Training accuracy epoch: 0.9931590668523037\n","Validating model...\n","Validation Loss: 0.21362173980609936\n","Validation Accuracy: 0.9545207027708431\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 31.533937866666687 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1570575244302206\n","Validation Accuracy: 0.9493081335640648\n","Validation duration: 5.851583616666661 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.1%\n","              precision    recall  f1-score   support\n","\n","     problem       0.78      0.87      0.82     12546\n","        test       0.83      0.88      0.85      9012\n","   treatment       0.77      0.88      0.82      9297\n","\n","   micro avg       0.79      0.88      0.83     30855\n","   macro avg       0.79      0.88      0.83     30855\n","weighted avg       0.79      0.88      0.83     30855\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0.25\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"Jhz9BiIwGCsV"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27245931,"status":"ok","timestamp":1667547919409,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"jdO4m5O4Hlo3","outputId":"e8ea2c4d-39b9-4762-9efd-d2fd1562f4f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 50.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 10401\n","Points in y_train after augmentation: 10401\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7097498178482056\n","Training loss per 100 training steps: 0.3993726531320279\n","Training loss per 100 training steps: 0.2961876662216376\n","Training loss per 100 training steps: 0.24857546970792782\n","Training loss epoch: 0.24142746083392688\n","Training accuracy epoch: 0.9251300795118155\n","Validating model...\n","Validation Loss: 0.15981557433094298\n","Validation Accuracy: 0.9500409509742618\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0744708850979805\n","Training loss per 100 training steps: 0.08818969097320396\n","Training loss per 100 training steps: 0.08816704429241258\n","Training loss per 100 training steps: 0.09263307750348831\n","Training loss epoch: 0.09230265320031232\n","Training accuracy epoch: 0.9711476822116282\n","Validating model...\n","Validation Loss: 0.16115606816896758\n","Validation Accuracy: 0.9518600894524414\n","Training epoch: 3\n","Training loss per 100 training steps: 0.026895787566900253\n","Training loss per 100 training steps: 0.04810730571683386\n","Training loss per 100 training steps: 0.048528332921180556\n","Training loss per 100 training steps: 0.04873251541520769\n","Training loss epoch: 0.048647256864469066\n","Training accuracy epoch: 0.9851809554761142\n","Validating model...\n","Validation Loss: 0.20157946169666655\n","Validation Accuracy: 0.9484401586329748\n","Training epoch: 4\n","Training loss per 100 training steps: 0.05573417991399765\n","Training loss per 100 training steps: 0.03212007616489831\n","Training loss per 100 training steps: 0.03578287325753131\n","Training loss per 100 training steps: 0.03559254812760483\n","Training loss epoch: 0.03526802059340482\n","Training accuracy epoch: 0.9894733272214595\n","Validating model...\n","Validation Loss: 0.1931230000329095\n","Validation Accuracy: 0.9542224523903484\n","Training epoch: 5\n","Training loss per 100 training steps: 0.013046435080468655\n","Training loss per 100 training steps: 0.02145465512847583\n","Training loss per 100 training steps: 0.020149676149493242\n","Training loss per 100 training steps: 0.02137002213726569\n","Training loss epoch: 0.02149952606596567\n","Training accuracy epoch: 0.993060623491251\n","Validating model...\n","Validation Loss: 0.197672768749974\n","Validation Accuracy: 0.9544983512920691\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00487425085157156\n","Training loss per 100 training steps: 0.014595968911013944\n","Training loss per 100 training steps: 0.018603720256551378\n","Training loss per 100 training steps: 0.018640643020123367\n","Training loss epoch: 0.018727434632844046\n","Training accuracy epoch: 0.9944146688829646\n","Validating model...\n","Validation Loss: 0.22532806327784216\n","Validation Accuracy: 0.9521358095740069\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 37.121832816666696 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16258517377664922\n","Validation Accuracy: 0.9497780688375548\n","Validation duration: 5.835305366666701 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.78      0.85      0.81     12546\n","        test       0.83      0.83      0.83      9012\n","   treatment       0.84      0.83      0.83      9297\n","\n","   micro avg       0.81      0.84      0.82     30855\n","   macro avg       0.81      0.84      0.83     30855\n","weighted avg       0.81      0.84      0.82     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 10401\n","Points in y_train after augmentation: 10401\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.056079149246216\n","Training loss per 100 training steps: 0.4088125819026834\n","Training loss per 100 training steps: 0.29292012398960576\n","Training loss per 100 training steps: 0.24990530998950386\n","Training loss epoch: 0.2416590834479276\n","Training accuracy epoch: 0.9231819688524104\n","Validating model...\n","Validation Loss: 0.15845115686004813\n","Validation Accuracy: 0.9487527165850244\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06305518001317978\n","Training loss per 100 training steps: 0.08548176378970689\n","Training loss per 100 training steps: 0.0906334986993626\n","Training loss per 100 training steps: 0.08759855468791486\n","Training loss epoch: 0.08704617648082642\n","Training accuracy epoch: 0.9731951127600138\n","Validating model...\n","Validation Loss: 0.16068951040506363\n","Validation Accuracy: 0.9512836283809862\n","Training epoch: 3\n","Training loss per 100 training steps: 0.013906859792768955\n","Training loss per 100 training steps: 0.04534417647628648\n","Training loss per 100 training steps: 0.04649946141052083\n","Training loss per 100 training steps: 0.04686249441086652\n","Training loss epoch: 0.04670914023988909\n","Training accuracy epoch: 0.9859298775167421\n","Validating model...\n","Validation Loss: 0.1873688632259508\n","Validation Accuracy: 0.9521864372829473\n","Training epoch: 4\n","Training loss per 100 training steps: 0.02429971657693386\n","Training loss per 100 training steps: 0.03215774704268811\n","Training loss per 100 training steps: 0.03208315869056578\n","Training loss per 100 training steps: 0.03592000502212734\n","Training loss epoch: 0.036384150988288066\n","Training accuracy epoch: 0.9888003274359637\n","Validating model...\n","Validation Loss: 0.1938077670509939\n","Validation Accuracy: 0.9528057598755639\n","Training epoch: 5\n","Training loss per 100 training steps: 0.010463530197739601\n","Training loss per 100 training steps: 0.026308496207192465\n","Training loss per 100 training steps: 0.025865468490215492\n","Training loss per 100 training steps: 0.029855125320323455\n","Training loss epoch: 0.02937834783249386\n","Training accuracy epoch: 0.9917290042608637\n","Validating model...\n","Validation Loss: 0.20949101827542793\n","Validation Accuracy: 0.9538475571510416\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0021276504267007113\n","Training loss per 100 training steps: 0.015896497641247467\n","Training loss per 100 training steps: 0.017153663014580694\n","Training loss per 100 training steps: 0.017782542752055607\n","Training loss epoch: 0.01784604872049095\n","Training accuracy epoch: 0.994677964910137\n","Validating model...\n","Validation Loss: 0.19764397936788472\n","Validation Accuracy: 0.9561180975280049\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 37.068667383333256 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16620926494727395\n","Validation Accuracy: 0.9466255588668011\n","Validation duration: 5.810094666666676 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 81.8%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.83      0.81     12546\n","        test       0.79      0.88      0.83      9012\n","   treatment       0.79      0.83      0.81      9297\n","\n","   micro avg       0.79      0.85      0.82     30855\n","   macro avg       0.79      0.85      0.82     30855\n","weighted avg       0.79      0.85      0.82     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 10401\n","Points in y_train after augmentation: 10401\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9539952278137207\n","Training loss per 100 training steps: 0.3985782210337053\n","Training loss per 100 training steps: 0.29086498488018764\n","Training loss per 100 training steps: 0.24823104645871244\n","Training loss epoch: 0.240866863420176\n","Training accuracy epoch: 0.9244867762416911\n","Validating model...\n","Validation Loss: 0.15511372927334402\n","Validation Accuracy: 0.9524287987633407\n","Training epoch: 2\n","Training loss per 100 training steps: 0.11333578824996948\n","Training loss per 100 training steps: 0.09384818021023628\n","Training loss per 100 training steps: 0.08992132886465806\n","Training loss per 100 training steps: 0.09099613248287047\n","Training loss epoch: 0.08949345137289742\n","Training accuracy epoch: 0.971891589158239\n","Validating model...\n","Validation Loss: 0.1539877812535345\n","Validation Accuracy: 0.9563729855946113\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02170668914914131\n","Training loss per 100 training steps: 0.042125625826307744\n","Training loss per 100 training steps: 0.047776860238252145\n","Training loss per 100 training steps: 0.04871552753450962\n","Training loss epoch: 0.05009297944428228\n","Training accuracy epoch: 0.9845317748582041\n","Validating model...\n","Validation Loss: 0.17004836045882918\n","Validation Accuracy: 0.952191158181045\n","Training epoch: 4\n","Training loss per 100 training steps: 0.025298502296209335\n","Training loss per 100 training steps: 0.037076362626544096\n","Training loss per 100 training steps: 0.03701322775656144\n","Training loss per 100 training steps: 0.037078463868856854\n","Training loss epoch: 0.036701353511093125\n","Training accuracy epoch: 0.9890191907434955\n","Validating model...\n","Validation Loss: 0.19311036938777218\n","Validation Accuracy: 0.9532992795194974\n","Training epoch: 5\n","Training loss per 100 training steps: 0.024173324927687645\n","Training loss per 100 training steps: 0.026178019705671116\n","Training loss per 100 training steps: 0.02605073712244908\n","Training loss per 100 training steps: 0.028543876566416722\n","Training loss epoch: 0.028317883388607825\n","Training accuracy epoch: 0.9915195090226759\n","Validating model...\n","Validation Loss: 0.21580625347212537\n","Validation Accuracy: 0.9512646948077471\n","Training epoch: 6\n","Training loss per 100 training steps: 0.004172183107584715\n","Training loss per 100 training steps: 0.019545119201607706\n","Training loss per 100 training steps: 0.02141711223941176\n","Training loss per 100 training steps: 0.024266578878416833\n","Training loss epoch: 0.023957036272810123\n","Training accuracy epoch: 0.9927435276675415\n","Validating model...\n","Validation Loss: 0.212022792644702\n","Validation Accuracy: 0.9521616769143568\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0015796218067407608\n","Training loss per 100 training steps: 0.01749259415359264\n","Training loss per 100 training steps: 0.016125390648410946\n","Training loss per 100 training steps: 0.015808430861370744\n","Training loss epoch: 0.01567072263205327\n","Training accuracy epoch: 0.9954529903943969\n","Validating model...\n","Validation Loss: 0.2716175375397426\n","Validation Accuracy: 0.9508183907555233\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 43.25424595000004 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15826741528602456\n","Validation Accuracy: 0.9542187798998087\n","Validation duration: 5.81329324999994 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.86      0.83     12546\n","        test       0.84      0.89      0.86      9012\n","   treatment       0.82      0.87      0.84      9297\n","\n","   micro avg       0.82      0.87      0.84     30855\n","   macro avg       0.82      0.87      0.85     30855\n","weighted avg       0.82      0.87      0.84     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 10401\n","Points in y_train after augmentation: 10401\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0637781620025635\n","Training loss per 100 training steps: 0.40556756857008036\n","Training loss per 100 training steps: 0.2940536522820814\n","Training loss per 100 training steps: 0.2485678040877331\n","Training loss epoch: 0.2395654310775132\n","Training accuracy epoch: 0.9248925709139224\n","Validating model...\n","Validation Loss: 0.16760754170404238\n","Validation Accuracy: 0.95052521387618\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06819580495357513\n","Training loss per 100 training steps: 0.08820456727453978\n","Training loss per 100 training steps: 0.08944046010833177\n","Training loss per 100 training steps: 0.08877409119282748\n","Training loss epoch: 0.08878016030047006\n","Training accuracy epoch: 0.9724240562309514\n","Validating model...\n","Validation Loss: 0.17328299959371615\n","Validation Accuracy: 0.9495468434585632\n","Training epoch: 3\n","Training loss per 100 training steps: 0.051850877702236176\n","Training loss per 100 training steps: 0.04495691569835538\n","Training loss per 100 training steps: 0.049604929735726534\n","Training loss per 100 training steps: 0.04951975688313527\n","Training loss epoch: 0.04920010067246843\n","Training accuracy epoch: 0.984503598139814\n","Validating model...\n","Validation Loss: 0.17784145413958408\n","Validation Accuracy: 0.9522194294770944\n","Training epoch: 4\n","Training loss per 100 training steps: 0.02897191420197487\n","Training loss per 100 training steps: 0.030722818782294888\n","Training loss per 100 training steps: 0.030331953733913897\n","Training loss per 100 training steps: 0.031234122462728466\n","Training loss epoch: 0.03074587054337815\n","Training accuracy epoch: 0.9906111748934362\n","Validating model...\n","Validation Loss: 0.21985780791222276\n","Validation Accuracy: 0.9520807764988475\n","Training epoch: 5\n","Training loss per 100 training steps: 0.021375039592385292\n","Training loss per 100 training steps: 0.0300878730780067\n","Training loss per 100 training steps: 0.03494578584929029\n","Training loss per 100 training steps: 0.033885872741059656\n","Training loss epoch: 0.03540937495237556\n","Training accuracy epoch: 0.9891095464758952\n","Validating model...\n","Validation Loss: 0.1954722825389404\n","Validation Accuracy: 0.9524583270015086\n","Training epoch: 6\n","Training loss per 100 training steps: 0.02198021113872528\n","Training loss per 100 training steps: 0.024971868797887743\n","Training loss per 100 training steps: 0.023214275311025333\n","Training loss per 100 training steps: 0.020518529310666236\n","Training loss epoch: 0.02053239266013161\n","Training accuracy epoch: 0.9938499177890406\n","Validating model...\n","Validation Loss: 0.21735440042208543\n","Validation Accuracy: 0.9573689328582083\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 37.054575883333385 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.17476304076154958\n","Validation Accuracy: 0.9482930617875444\n","Validation duration: 5.814350416666639 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 81.1%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.81      0.82     12546\n","        test       0.83      0.81      0.82      9012\n","   treatment       0.75      0.85      0.80      9297\n","\n","   micro avg       0.80      0.82      0.81     30855\n","   macro avg       0.80      0.82      0.81     30855\n","weighted avg       0.80      0.82      0.81     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 10401\n","Points in y_train after augmentation: 10401\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.194148540496826\n","Training loss per 100 training steps: 0.4174559855520135\n","Training loss per 100 training steps: 0.3087371619631402\n","Training loss per 100 training steps: 0.2624309715564267\n","Training loss epoch: 0.2542122161255841\n","Training accuracy epoch: 0.9220308930439748\n","Validating model...\n","Validation Loss: 0.18259213037498587\n","Validation Accuracy: 0.9422235350230624\n","Training epoch: 2\n","Training loss per 100 training steps: 0.051277320832014084\n","Training loss per 100 training steps: 0.09213823150142585\n","Training loss per 100 training steps: 0.09633156594204072\n","Training loss per 100 training steps: 0.0949723107610331\n","Training loss epoch: 0.09300289463840691\n","Training accuracy epoch: 0.9705808080770593\n","Validating model...\n","Validation Loss: 0.15795364107501197\n","Validation Accuracy: 0.9536909400951644\n","Training epoch: 3\n","Training loss per 100 training steps: 0.027296800166368484\n","Training loss per 100 training steps: 0.05138408903512034\n","Training loss per 100 training steps: 0.05318966121250643\n","Training loss per 100 training steps: 0.05371361311704564\n","Training loss epoch: 0.05402065645082907\n","Training accuracy epoch: 0.9839362292654958\n","Validating model...\n","Validation Loss: 0.1892051144031348\n","Validation Accuracy: 0.9495581790163126\n","Training epoch: 4\n","Training loss per 100 training steps: 0.09405041486024857\n","Training loss per 100 training steps: 0.033612845345667684\n","Training loss per 100 training steps: 0.03682236587258046\n","Training loss per 100 training steps: 0.03663336120753168\n","Training loss epoch: 0.03599695847805395\n","Training accuracy epoch: 0.9885533860436153\n","Validating model...\n","Validation Loss: 0.2058307376581353\n","Validation Accuracy: 0.9527158513570246\n","Training epoch: 5\n","Training loss per 100 training steps: 0.005729940254241228\n","Training loss per 100 training steps: 0.021988646084636375\n","Training loss per 100 training steps: 0.02164108279179689\n","Training loss per 100 training steps: 0.023899644955937004\n","Training loss epoch: 0.024715959055183534\n","Training accuracy epoch: 0.9929603842817398\n","Validating model...\n","Validation Loss: 0.1934503148999307\n","Validation Accuracy: 0.9534250093023166\n","Training epoch: 6\n","Training loss per 100 training steps: 0.03664028272032738\n","Training loss per 100 training steps: 0.01626122325755619\n","Training loss per 100 training steps: 0.01606128253222244\n","Training loss per 100 training steps: 0.02092055493073872\n","Training loss epoch: 0.020780999313088626\n","Training accuracy epoch: 0.9933830285382462\n","Validating model...\n","Validation Loss: 0.22433741661635312\n","Validation Accuracy: 0.9508500596251005\n","Training epoch: 7\n","Training loss per 100 training steps: 0.006138265132904053\n","Training loss per 100 training steps: 0.015145675283810585\n","Training loss per 100 training steps: 0.017278957690937045\n","Training loss per 100 training steps: 0.01974909601422132\n","Training loss epoch: 0.0200722733415389\n","Training accuracy epoch: 0.9939164375264199\n","Validating model...\n","Validation Loss: 0.2155746678858028\n","Validation Accuracy: 0.9524443615486802\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 43.23907428333332 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.17142207005074145\n","Validation Accuracy: 0.9519457881379849\n","Validation duration: 5.825856933333368 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.84      0.81     12546\n","        test       0.86      0.86      0.86      9012\n","   treatment       0.81      0.85      0.83      9297\n","\n","   micro avg       0.81      0.85      0.83     30855\n","   macro avg       0.82      0.85      0.83     30855\n","weighted avg       0.81      0.85      0.83     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 10401\n","Points in y_train after augmentation: 10401\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.2684051990509033\n","Training loss per 100 training steps: 0.4175099310013327\n","Training loss per 100 training steps: 0.307200899764673\n","Training loss per 100 training steps: 0.260003624094087\n","Training loss epoch: 0.25006777346934095\n","Training accuracy epoch: 0.9220650976894581\n","Validating model...\n","Validation Loss: 0.16819323942839326\n","Validation Accuracy: 0.9481757938629496\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04626601189374924\n","Training loss per 100 training steps: 0.09234786260467355\n","Training loss per 100 training steps: 0.09774690209447745\n","Training loss per 100 training steps: 0.09494362301208648\n","Training loss epoch: 0.09393545089895192\n","Training accuracy epoch: 0.9704827085272635\n","Validating model...\n","Validation Loss: 0.16186108984440178\n","Validation Accuracy: 0.953332921806214\n","Training epoch: 3\n","Training loss per 100 training steps: 0.06104370206594467\n","Training loss per 100 training steps: 0.055977829612127626\n","Training loss per 100 training steps: 0.05539839010018466\n","Training loss per 100 training steps: 0.05520655786575273\n","Training loss epoch: 0.05373655180689633\n","Training accuracy epoch: 0.9833085758293477\n","Validating model...\n","Validation Loss: 0.16896078987168028\n","Validation Accuracy: 0.9571803881385167\n","Training epoch: 4\n","Training loss per 100 training steps: 0.015456930734217167\n","Training loss per 100 training steps: 0.03088377925594992\n","Training loss per 100 training steps: 0.036989941996109874\n","Training loss per 100 training steps: 0.03911301155150729\n","Training loss epoch: 0.03859226746354116\n","Training accuracy epoch: 0.9880191839587318\n","Validating model...\n","Validation Loss: 0.20825246469928071\n","Validation Accuracy: 0.9519125096009315\n","Training epoch: 5\n","Training loss per 100 training steps: 0.02405938133597374\n","Training loss per 100 training steps: 0.030210868437027576\n","Training loss per 100 training steps: 0.03024013205451673\n","Training loss per 100 training steps: 0.03204940315566112\n","Training loss epoch: 0.03178488821042287\n","Training accuracy epoch: 0.9908683657053835\n","Validating model...\n","Validation Loss: 0.21368357169974064\n","Validation Accuracy: 0.9550820909677891\n","Training epoch: 6\n","Training loss per 100 training steps: 0.016384068876504898\n","Training loss per 100 training steps: 0.02390062580482186\n","Training loss per 100 training steps: 0.024362469486723104\n","Training loss per 100 training steps: 0.02389075537231531\n","Training loss epoch: 0.024127963032613456\n","Training accuracy epoch: 0.9925437373871778\n","Validating model...\n","Validation Loss: 0.22989115578594146\n","Validation Accuracy: 0.9511671963431789\n","Training epoch: 7\n","Training loss per 100 training steps: 0.002486137906089425\n","Training loss per 100 training steps: 0.015362740694867944\n","Training loss per 100 training steps: 0.01818914594712542\n","Training loss per 100 training steps: 0.017257116079420175\n","Training loss epoch: 0.017506237630660938\n","Training accuracy epoch: 0.9947987448389136\n","Validating model...\n","Validation Loss: 0.23722934471322343\n","Validation Accuracy: 0.951824225735868\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 43.2516790166667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.18012208157193121\n","Validation Accuracy: 0.9490550357638554\n","Validation duration: 5.823077166666675 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.8%\n","              precision    recall  f1-score   support\n","\n","     problem       0.84      0.83      0.83     12546\n","        test       0.85      0.78      0.82      9012\n","   treatment       0.81      0.85      0.83      9297\n","\n","   micro avg       0.83      0.82      0.83     30855\n","   macro avg       0.83      0.82      0.83     30855\n","weighted avg       0.83      0.82      0.83     30855\n","\n","!!!!!! Starting model number 7 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 10401\n","Points in y_train after augmentation: 10401\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9151930809020996\n","Training loss per 100 training steps: 0.414364287906354\n","Training loss per 100 training steps: 0.29944878490410043\n","Training loss per 100 training steps: 0.2518681281701077\n","Training loss epoch: 0.24257060955135734\n","Training accuracy epoch: 0.9245243997655513\n","Validating model...\n","Validation Loss: 0.14752614072390965\n","Validation Accuracy: 0.9532462676941167\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0830383226275444\n","Training loss per 100 training steps: 0.09049476281103522\n","Training loss per 100 training steps: 0.0866155516430365\n","Training loss per 100 training steps: 0.08726340654210196\n","Training loss epoch: 0.08604825970265398\n","Training accuracy epoch: 0.9733732934511264\n","Validating model...\n","Validation Loss: 0.15898609091225382\n","Validation Accuracy: 0.9541895605955272\n","Training epoch: 3\n","Training loss per 100 training steps: 0.009324638172984123\n","Training loss per 100 training steps: 0.040867149308877124\n","Training loss per 100 training steps: 0.04461863679366548\n","Training loss per 100 training steps: 0.046141042364792176\n","Training loss epoch: 0.046496365987838593\n","Training accuracy epoch: 0.9855710811779094\n","Validating model...\n","Validation Loss: 0.19541947691181263\n","Validation Accuracy: 0.9489763224615267\n","Training epoch: 4\n","Training loss per 100 training steps: 0.009464151225984097\n","Training loss per 100 training steps: 0.030347559363627347\n","Training loss per 100 training steps: 0.031335912852209824\n","Training loss per 100 training steps: 0.03245997759033972\n","Training loss epoch: 0.03199799612115039\n","Training accuracy epoch: 0.9902659713042817\n","Validating model...\n","Validation Loss: 0.19583283841319674\n","Validation Accuracy: 0.956320836421575\n","Training epoch: 5\n","Training loss per 100 training steps: 0.010842296294867992\n","Training loss per 100 training steps: 0.03501800975836076\n","Training loss per 100 training steps: 0.03532310705214961\n","Training loss per 100 training steps: 0.031746685748573304\n","Training loss epoch: 0.031180772238319592\n","Training accuracy epoch: 0.9906108983362814\n","Validating model...\n","Validation Loss: 0.20852043102313947\n","Validation Accuracy: 0.9572580732688156\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0037465307395905256\n","Training loss per 100 training steps: 0.020665798399661952\n","Training loss per 100 training steps: 0.019023358236896385\n","Training loss per 100 training steps: 0.01927724806282459\n","Training loss epoch: 0.018827606582030938\n","Training accuracy epoch: 0.9946511927203797\n","Validating model...\n","Validation Loss: 0.2204508803597373\n","Validation Accuracy: 0.9557922990375308\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 37.04966480000003 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15651796636154391\n","Validation Accuracy: 0.9498733087743011\n","Validation duration: 5.836034016666599 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.85      0.82     12546\n","        test       0.82      0.86      0.84      9012\n","   treatment       0.79      0.85      0.82      9297\n","\n","   micro avg       0.80      0.85      0.82     30855\n","   macro avg       0.80      0.85      0.82     30855\n","weighted avg       0.80      0.85      0.82     30855\n","\n","!!!!!! Starting model number 8 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 10401\n","Points in y_train after augmentation: 10401\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.3448822498321533\n","Training loss per 100 training steps: 0.4169130498672476\n","Training loss per 100 training steps: 0.30380893985170926\n","Training loss per 100 training steps: 0.25668644196542595\n","Training loss epoch: 0.24717971784679757\n","Training accuracy epoch: 0.9218833539835065\n","Validating model...\n","Validation Loss: 0.15295022842171904\n","Validation Accuracy: 0.9510102737479063\n","Training epoch: 2\n","Training loss per 100 training steps: 0.08996672183275223\n","Training loss per 100 training steps: 0.08273328728697235\n","Training loss per 100 training steps: 0.09117207077762751\n","Training loss per 100 training steps: 0.09081060197544702\n","Training loss epoch: 0.09091093240978383\n","Training accuracy epoch: 0.9724392512951107\n","Validating model...\n","Validation Loss: 0.16662930179532473\n","Validation Accuracy: 0.9520808348169382\n","Training epoch: 3\n","Training loss per 100 training steps: 0.032616809010505676\n","Training loss per 100 training steps: 0.04902889045637728\n","Training loss per 100 training steps: 0.054679336350652114\n","Training loss per 100 training steps: 0.057160101936158544\n","Training loss epoch: 0.05633388952019287\n","Training accuracy epoch: 0.9823351458326866\n","Validating model...\n","Validation Loss: 0.18865184271829083\n","Validation Accuracy: 0.9535006577982685\n","Training epoch: 4\n","Training loss per 100 training steps: 0.040079496800899506\n","Training loss per 100 training steps: 0.034528424170347724\n","Training loss per 100 training steps: 0.03350049449218928\n","Training loss per 100 training steps: 0.034389363935192506\n","Training loss epoch: 0.03402581175286973\n","Training accuracy epoch: 0.9897026457401377\n","Validating model...\n","Validation Loss: 0.20716585722062494\n","Validation Accuracy: 0.9522367420476914\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0021838468965142965\n","Training loss per 100 training steps: 0.023526421909469485\n","Training loss per 100 training steps: 0.0237826802263926\n","Training loss per 100 training steps: 0.026065698462813796\n","Training loss epoch: 0.02599878626272255\n","Training accuracy epoch: 0.9919083905740631\n","Validating model...\n","Validation Loss: 0.20556207705143983\n","Validation Accuracy: 0.954441624297112\n","Training epoch: 6\n","Training loss per 100 training steps: 0.005030856467783451\n","Training loss per 100 training steps: 0.016697597496285296\n","Training loss per 100 training steps: 0.01959589617129934\n","Training loss per 100 training steps: 0.02121291285345139\n","Training loss epoch: 0.02304551953072567\n","Training accuracy epoch: 0.9930563925310575\n","Validating model...\n","Validation Loss: 0.20982228567847958\n","Validation Accuracy: 0.9510397277091415\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 37.04764783333339 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1672981823816102\n","Validation Accuracy: 0.9479861161128494\n","Validation duration: 5.844632000000032 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 81.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.77      0.85      0.80     12546\n","        test       0.87      0.82      0.84      9012\n","   treatment       0.76      0.85      0.80      9297\n","\n","   micro avg       0.79      0.84      0.81     30855\n","   macro avg       0.80      0.84      0.82     30855\n","weighted avg       0.79      0.84      0.81     30855\n","\n","!!!!!! Starting model number 9 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 10401\n","Points in y_train after augmentation: 10401\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9878451824188232\n","Training loss per 100 training steps: 0.41182464914451733\n","Training loss per 100 training steps: 0.3034575280561969\n","Training loss per 100 training steps: 0.25699981772325364\n","Training loss epoch: 0.24749524187456612\n","Training accuracy epoch: 0.920851949950344\n","Validating model...\n","Validation Loss: 0.15628474505690784\n","Validation Accuracy: 0.952935074038674\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06350618600845337\n","Training loss per 100 training steps: 0.09132459516277408\n","Training loss per 100 training steps: 0.09272647933543321\n","Training loss per 100 training steps: 0.0916614102700917\n","Training loss epoch: 0.09159104828294252\n","Training accuracy epoch: 0.9710833123833958\n","Validating model...\n","Validation Loss: 0.17874969597663973\n","Validation Accuracy: 0.9490441895740562\n","Training epoch: 3\n","Training loss per 100 training steps: 0.01301990170031786\n","Training loss per 100 training steps: 0.06256838636196191\n","Training loss per 100 training steps: 0.061741546632731285\n","Training loss per 100 training steps: 0.0608914724606835\n","Training loss epoch: 0.061132818162998336\n","Training accuracy epoch: 0.9811762327909838\n","Validating model...\n","Validation Loss: 0.2085499946608559\n","Validation Accuracy: 0.9482880776771692\n","Training epoch: 4\n","Training loss per 100 training steps: 0.011625433340668678\n","Training loss per 100 training steps: 0.034975899314268095\n","Training loss per 100 training steps: 0.03358203626240126\n","Training loss per 100 training steps: 0.03459742101159974\n","Training loss epoch: 0.035920680885523144\n","Training accuracy epoch: 0.9892932323209869\n","Validating model...\n","Validation Loss: 0.17787609498512436\n","Validation Accuracy: 0.9546412713379839\n","Training epoch: 5\n","Training loss per 100 training steps: 0.013118269853293896\n","Training loss per 100 training steps: 0.025196813736203135\n","Training loss per 100 training steps: 0.028719111735496985\n","Training loss per 100 training steps: 0.029904229756741726\n","Training loss epoch: 0.029912588307976815\n","Training accuracy epoch: 0.9910457573411623\n","Validating model...\n","Validation Loss: 0.21163446670277164\n","Validation Accuracy: 0.9538639073828816\n","Training epoch: 6\n","Training loss per 100 training steps: 0.020213110372424126\n","Training loss per 100 training steps: 0.0255529564162163\n","Training loss per 100 training steps: 0.023243761271011288\n","Training loss per 100 training steps: 0.023257789479342733\n","Training loss epoch: 0.023050975781026942\n","Training accuracy epoch: 0.9930334906575019\n","Validating model...\n","Validation Loss: 0.2121588910216248\n","Validation Accuracy: 0.955220404969981\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 37.04353045000001 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1649198590419945\n","Validation Accuracy: 0.9508446900848078\n","Validation duration: 5.81802356666667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.83      0.82     12546\n","        test       0.86      0.84      0.85      9012\n","   treatment       0.76      0.88      0.82      9297\n","\n","   micro avg       0.81      0.85      0.83     30855\n","   macro avg       0.81      0.85      0.83     30855\n","weighted avg       0.81      0.85      0.83     30855\n","\n","!!!!!! Starting model number 10 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 10401\n","Points in y_train after augmentation: 10401\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.3933379650115967\n","Training loss per 100 training steps: 0.42587937104820023\n","Training loss per 100 training steps: 0.30995180715450005\n","Training loss per 100 training steps: 0.26051552405587064\n","Training loss epoch: 0.2528633742691075\n","Training accuracy epoch: 0.9196581377569045\n","Validating model...\n","Validation Loss: 0.16735013724341022\n","Validation Accuracy: 0.9482274480179526\n","Training epoch: 2\n","Training loss per 100 training steps: 0.1009414941072464\n","Training loss per 100 training steps: 0.10311074765159352\n","Training loss per 100 training steps: 0.0993623753536993\n","Training loss per 100 training steps: 0.09353260526068484\n","Training loss epoch: 0.09240947854333768\n","Training accuracy epoch: 0.9708571409720799\n","Validating model...\n","Validation Loss: 0.1851935986453643\n","Validation Accuracy: 0.9510371487669184\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02795218490064144\n","Training loss per 100 training steps: 0.05526844335092914\n","Training loss per 100 training steps: 0.05296026381307203\n","Training loss per 100 training steps: 0.05254172510854232\n","Training loss epoch: 0.05166731824932968\n","Training accuracy epoch: 0.9844956763061807\n","Validating model...\n","Validation Loss: 0.19431694000717495\n","Validation Accuracy: 0.9506200212612183\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01627802662551403\n","Training loss per 100 training steps: 0.02618699611422818\n","Training loss per 100 training steps: 0.031750229977891405\n","Training loss per 100 training steps: 0.0343770293114348\n","Training loss epoch: 0.03450913459878644\n","Training accuracy epoch: 0.989728831013003\n","Validating model...\n","Validation Loss: 0.1906838718704976\n","Validation Accuracy: 0.9550992304328678\n","Training epoch: 5\n","Training loss per 100 training steps: 0.008956985548138618\n","Training loss per 100 training steps: 0.02755741694928285\n","Training loss per 100 training steps: 0.024437096875174834\n","Training loss per 100 training steps: 0.02735328276995941\n","Training loss epoch: 0.02852006831483671\n","Training accuracy epoch: 0.9919585239234651\n","Validating model...\n","Validation Loss: 0.20612932001421977\n","Validation Accuracy: 0.9541510899547907\n","Training epoch: 6\n","Training loss per 100 training steps: 0.012369981966912746\n","Training loss per 100 training steps: 0.02037625024925069\n","Training loss per 100 training steps: 0.022219213755541846\n","Training loss per 100 training steps: 0.02232343613354186\n","Training loss epoch: 0.022155612662500285\n","Training accuracy epoch: 0.9932880542545476\n","Validating model...\n","Validation Loss: 0.21814754571426997\n","Validation Accuracy: 0.9539420449893949\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 37.06073104999996 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.18412692469751668\n","Validation Accuracy: 0.9437393945531839\n","Validation duration: 5.81174556666665 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 80.1%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.84      0.82     12546\n","        test       0.85      0.70      0.76      9012\n","   treatment       0.78      0.85      0.81      9297\n","\n","   micro avg       0.80      0.80      0.80     30855\n","   macro avg       0.81      0.79      0.80     30855\n","weighted avg       0.81      0.80      0.80     30855\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0.5\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"jdO4m5O4Hlo3"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"oKNxFPucHn_R","outputId":"422568fc-d7df-4365-89b9-8bb14665d044"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 75.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 12135\n","Points in y_train after augmentation: 12135\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8905740976333618\n","Training loss per 100 training steps: 0.39641130708231787\n","Training loss per 100 training steps: 0.29625649974491464\n","Training loss per 100 training steps: 0.25026199488940826\n","Training loss epoch: 0.22866361580396954\n","Training accuracy epoch: 0.9274242790185767\n","Validating model...\n","Validation Loss: 0.15450543431299074\n","Validation Accuracy: 0.952117216717273\n","Training epoch: 2\n","Training loss per 100 training steps: 0.1069023460149765\n","Training loss per 100 training steps: 0.08534096330773122\n","Training loss per 100 training steps: 0.08679929590177032\n","Training loss per 100 training steps: 0.08305919586535407\n","Training loss epoch: 0.08345291224847498\n","Training accuracy epoch: 0.973567496785309\n","Validating model...\n","Validation Loss: 0.1833564006759749\n","Validation Accuracy: 0.9491160289262641\n","Training epoch: 3\n","Training loss per 100 training steps: 0.052750878036022186\n","Training loss per 100 training steps: 0.04142307367931941\n","Training loss per 100 training steps: 0.04084890198648272\n","Training loss per 100 training steps: 0.042590381456941266\n","Training loss epoch: 0.04423974909831917\n","Training accuracy epoch: 0.9857966858594005\n","Validating model...\n","Validation Loss: 0.19120360240824036\n","Validation Accuracy: 0.951207032473557\n","Training epoch: 4\n","Training loss per 100 training steps: 0.04428635910153389\n","Training loss per 100 training steps: 0.030201203897503196\n","Training loss per 100 training steps: 0.028927891109768875\n","Training loss per 100 training steps: 0.028051827273848296\n","Training loss epoch: 0.028603447510211384\n","Training accuracy epoch: 0.9910467882313272\n","Validating model...\n","Validation Loss: 0.22018162371566544\n","Validation Accuracy: 0.9504215353701425\n","Training epoch: 5\n","Training loss per 100 training steps: 0.012127947062253952\n","Training loss per 100 training steps: 0.02151315659169329\n","Training loss per 100 training steps: 0.026503142433366114\n","Training loss per 100 training steps: 0.028108267002565742\n","Training loss epoch: 0.030289192932449575\n","Training accuracy epoch: 0.9909939173313331\n","Validating model...\n","Validation Loss: 0.21893917082192063\n","Validation Accuracy: 0.9513326139621331\n","Training epoch: 6\n","Training loss per 100 training steps: 0.033267322927713394\n","Training loss per 100 training steps: 0.019682605402765445\n","Training loss per 100 training steps: 0.019252598412081236\n","Training loss per 100 training steps: 0.01948588095522993\n","Training loss epoch: 0.0189773063477141\n","Training accuracy epoch: 0.9943627450661899\n","Validating model...\n","Validation Loss: 0.23400070377952092\n","Validation Accuracy: 0.953525137822755\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 42.684735166666606 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16176042024960258\n","Validation Accuracy: 0.950335965410939\n","Validation duration: 5.812917883333406 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.78      0.84      0.81     12546\n","        test       0.82      0.85      0.83      9012\n","   treatment       0.80      0.84      0.82      9297\n","\n","   micro avg       0.80      0.84      0.82     30855\n","   macro avg       0.80      0.84      0.82     30855\n","weighted avg       0.80      0.84      0.82     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 12135\n","Points in y_train after augmentation: 12135\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9709906578063965\n","Training loss per 100 training steps: 0.4151453037958334\n","Training loss per 100 training steps: 0.30741594735514466\n","Training loss per 100 training steps: 0.2533911918088843\n","Training loss epoch: 0.2295723287976886\n","Training accuracy epoch: 0.9288341170454166\n","Validating model...\n","Validation Loss: 0.16135189512913878\n","Validation Accuracy: 0.9511527855827214\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06972953677177429\n","Training loss per 100 training steps: 0.08306670641655674\n","Training loss per 100 training steps: 0.08498405610021223\n","Training loss per 100 training steps: 0.08601555009790235\n","Training loss epoch: 0.08428216306247602\n","Training accuracy epoch: 0.9734403704383447\n","Validating model...\n","Validation Loss: 0.16489885338618385\n","Validation Accuracy: 0.9536535959449507\n","Training epoch: 3\n","Training loss per 100 training steps: 0.019208984449505806\n","Training loss per 100 training steps: 0.04281450645297323\n","Training loss per 100 training steps: 0.043018932412586995\n","Training loss per 100 training steps: 0.04395532511187055\n","Training loss epoch: 0.0436261406437935\n","Training accuracy epoch: 0.986870681523676\n","Validating model...\n","Validation Loss: 0.18681258241367804\n","Validation Accuracy: 0.9542381763781693\n","Training epoch: 4\n","Training loss per 100 training steps: 0.015432738699018955\n","Training loss per 100 training steps: 0.02453336527335946\n","Training loss per 100 training steps: 0.02643745974521732\n","Training loss per 100 training steps: 0.028082798882944515\n","Training loss epoch: 0.02918189518876668\n","Training accuracy epoch: 0.9913277031715564\n","Validating model...\n","Validation Loss: 0.19324354752414413\n","Validation Accuracy: 0.9508981822705064\n","Training epoch: 5\n","Training loss per 100 training steps: 0.012159625999629498\n","Training loss per 100 training steps: 0.025204712151558978\n","Training loss per 100 training steps: 0.028201139708679743\n","Training loss per 100 training steps: 0.026159542281276538\n","Training loss epoch: 0.02622387217354691\n","Training accuracy epoch: 0.9921559117822331\n","Validating model...\n","Validation Loss: 0.22789112638149941\n","Validation Accuracy: 0.9513264936902529\n","Training epoch: 6\n","Training loss per 100 training steps: 0.005947719793766737\n","Training loss per 100 training steps: 0.0191914096179575\n","Training loss per 100 training steps: 0.019179677632139226\n","Training loss per 100 training steps: 0.019821198349485973\n","Training loss epoch: 0.01967128414988493\n","Training accuracy epoch: 0.9941786538952809\n","Validating model...\n","Validation Loss: 0.25399666435581136\n","Validation Accuracy: 0.9521678337821367\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 42.70555394999998 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16767086047642538\n","Validation Accuracy: 0.9499469480707915\n","Validation duration: 5.811921716666742 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.85      0.82     12546\n","        test       0.84      0.85      0.84      9012\n","   treatment       0.81      0.84      0.82      9297\n","\n","   micro avg       0.81      0.84      0.83     30855\n","   macro avg       0.81      0.84      0.83     30855\n","weighted avg       0.81      0.84      0.83     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 12135\n","Points in y_train after augmentation: 12135\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9835360050201416\n","Training loss per 100 training steps: 0.3947426777812514\n","Training loss per 100 training steps: 0.29661310441903216\n","Training loss per 100 training steps: 0.25095671914097084\n","Training loss epoch: 0.22978004755354242\n","Training accuracy epoch: 0.9277531233116548\n","Validating model...\n","Validation Loss: 0.15394601071035707\n","Validation Accuracy: 0.9502063005513913\n","Training epoch: 2\n","Training loss per 100 training steps: 0.08168136328458786\n","Training loss per 100 training steps: 0.08856509103080129\n","Training loss per 100 training steps: 0.09262246216429555\n","Training loss per 100 training steps: 0.09053384531536866\n","Training loss epoch: 0.08662235651802468\n","Training accuracy epoch: 0.9722390890019795\n","Validating model...\n","Validation Loss: 0.1898856135931882\n","Validation Accuracy: 0.9488448844486869\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04486142471432686\n","Training loss per 100 training steps: 0.05374500834576712\n","Training loss per 100 training steps: 0.049961297675522404\n","Training loss per 100 training steps: 0.04942945009128398\n","Training loss epoch: 0.05018713351241068\n","Training accuracy epoch: 0.9844463644734163\n","Validating model...\n","Validation Loss: 0.1883802745588027\n","Validation Accuracy: 0.9512577951623866\n","Training epoch: 4\n","Training loss per 100 training steps: 0.010476221330463886\n","Training loss per 100 training steps: 0.027168916791935664\n","Training loss per 100 training steps: 0.032465071381482094\n","Training loss per 100 training steps: 0.03521945713972827\n","Training loss epoch: 0.03662151844596098\n","Training accuracy epoch: 0.9885815600649754\n","Validating model...\n","Validation Loss: 0.1982482006446785\n","Validation Accuracy: 0.9544920011839481\n","Training epoch: 5\n","Training loss per 100 training steps: 0.004014072474092245\n","Training loss per 100 training steps: 0.028534427528398684\n","Training loss per 100 training steps: 0.029443898930362616\n","Training loss per 100 training steps: 0.02932892013975478\n","Training loss epoch: 0.029227665354081087\n","Training accuracy epoch: 0.9909699988530958\n","Validating model...\n","Validation Loss: 0.24363471974026074\n","Validation Accuracy: 0.948270249595154\n","Training epoch: 6\n","Training loss per 100 training steps: 0.017178243026137352\n","Training loss per 100 training steps: 0.03626050259503029\n","Training loss per 100 training steps: 0.03048455160034737\n","Training loss per 100 training steps: 0.027680988076600892\n","Training loss epoch: 0.027258490790355656\n","Training accuracy epoch: 0.9919885796436869\n","Validating model...\n","Validation Loss: 0.22856526538826427\n","Validation Accuracy: 0.9526175234601457\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 42.6447288333334 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15658804357560627\n","Validation Accuracy: 0.9517266328530345\n","Validation duration: 5.841171933333438 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.8%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.83      0.81     12546\n","        test       0.82      0.87      0.84      9012\n","   treatment       0.84      0.82      0.83      9297\n","\n","   micro avg       0.82      0.84      0.83     30855\n","   macro avg       0.82      0.84      0.83     30855\n","weighted avg       0.82      0.84      0.83     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 12135\n","Points in y_train after augmentation: 12135\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0196707248687744\n","Training loss per 100 training steps: 0.3997880435078451\n","Training loss per 100 training steps: 0.2908457625397847\n","Training loss per 100 training steps: 0.24592593312882308\n","Training loss epoch: 0.2253066987044325\n","Training accuracy epoch: 0.9290667838166885\n","Validating model...\n","Validation Loss: 0.16371856477450242\n","Validation Accuracy: 0.9493033345106343\n","Training epoch: 2\n","Training loss per 100 training steps: 0.050275690853595734\n","Training loss per 100 training steps: 0.09045511553303735\n","Training loss per 100 training steps: 0.08711792791809016\n","Training loss per 100 training steps: 0.08767406232159994\n","Training loss epoch: 0.08577621047581105\n","Training accuracy epoch: 0.9734633121470435\n","Validating model...\n","Validation Loss: 0.1570227552302085\n","Validation Accuracy: 0.9543243739250226\n","Training epoch: 3\n","Training loss per 100 training steps: 0.07787001878023148\n","Training loss per 100 training steps: 0.04606115497362864\n","Training loss per 100 training steps: 0.04554041476331799\n","Training loss per 100 training steps: 0.049061553177587765\n","Training loss epoch: 0.050202228504502656\n","Training accuracy epoch: 0.9848738993856684\n","Validating model...\n","Validation Loss: 0.17448283148953667\n","Validation Accuracy: 0.9535481431330247\n","Training epoch: 4\n","Training loss per 100 training steps: 0.04575031250715256\n","Training loss per 100 training steps: 0.03161944995523606\n","Training loss per 100 training steps: 0.035033182594322816\n","Training loss per 100 training steps: 0.034216035609179955\n","Training loss epoch: 0.036841608612724626\n","Training accuracy epoch: 0.9893479414353415\n","Validating model...\n","Validation Loss: 0.2120462396702209\n","Validation Accuracy: 0.9486543239461925\n","Training epoch: 5\n","Training loss per 100 training steps: 0.03181660547852516\n","Training loss per 100 training steps: 0.02170113472516953\n","Training loss per 100 training steps: 0.022792484499490936\n","Training loss per 100 training steps: 0.02227269659597006\n","Training loss epoch: 0.02265360533860267\n","Training accuracy epoch: 0.9930251848873318\n","Validating model...\n","Validation Loss: 0.20481543080252293\n","Validation Accuracy: 0.9527372618073052\n","Training epoch: 6\n","Training loss per 100 training steps: 0.017422277480363846\n","Training loss per 100 training steps: 0.014622917676017168\n","Training loss per 100 training steps: 0.015202255118568776\n","Training loss per 100 training steps: 0.015588321007921227\n","Training loss epoch: 0.017548291987163553\n","Training accuracy epoch: 0.9947796126917879\n","Validating model...\n","Validation Loss: 0.22709293679225367\n","Validation Accuracy: 0.9501317158798926\n","Training epoch: 7\n","Training loss per 100 training steps: 0.00707516074180603\n","Training loss per 100 training steps: 0.017505908610834047\n","Training loss per 100 training steps: 0.019767289544543744\n","Training loss per 100 training steps: 0.019384376295692167\n","Training loss epoch: 0.019186057036093093\n","Training accuracy epoch: 0.9942116632144624\n","Validating model...\n","Validation Loss: 0.22601608610288662\n","Validation Accuracy: 0.9517388480553121\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 49.78924853333326 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16704547911757361\n","Validation Accuracy: 0.9520213518562725\n","Validation duration: 5.814025416666603 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.83      0.82     12546\n","        test       0.84      0.83      0.83      9012\n","   treatment       0.81      0.86      0.84      9297\n","\n","   micro avg       0.82      0.84      0.83     30855\n","   macro avg       0.82      0.84      0.83     30855\n","weighted avg       0.82      0.84      0.83     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 12135\n","Points in y_train after augmentation: 12135\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9459244012832642\n","Training loss per 100 training steps: 0.4023031683841554\n","Training loss per 100 training steps: 0.30064820283236193\n","Training loss per 100 training steps: 0.25601000129631984\n","Training loss epoch: 0.23213170381557\n","Training accuracy epoch: 0.926883030942656\n","Validating model...\n","Validation Loss: 0.16358177987979605\n","Validation Accuracy: 0.9488596335357095\n","Training epoch: 2\n","Training loss per 100 training steps: 0.10866298526525497\n","Training loss per 100 training steps: 0.09235758378659145\n","Training loss per 100 training steps: 0.0900017193041334\n","Training loss per 100 training steps: 0.08678991578680237\n","Training loss epoch: 0.08714530511857256\n","Training accuracy epoch: 0.9730998086883534\n","Validating model...\n","Validation Loss: 0.17204561444942829\n","Validation Accuracy: 0.9525356712297727\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0253192950040102\n","Training loss per 100 training steps: 0.0412517793725549\n","Training loss per 100 training steps: 0.04561667845338879\n","Training loss per 100 training steps: 0.04614775250294552\n","Training loss epoch: 0.045221543962773135\n","Training accuracy epoch: 0.9863181648848981\n","Validating model...\n","Validation Loss: 0.17280675343830476\n","Validation Accuracy: 0.958359508983448\n","Training epoch: 4\n","Training loss per 100 training steps: 0.009372472763061523\n","Training loss per 100 training steps: 0.02996880033901791\n","Training loss per 100 training steps: 0.029721240120342197\n","Training loss per 100 training steps: 0.03040802907090374\n","Training loss epoch: 0.03200611611429945\n","Training accuracy epoch: 0.9903130447921913\n","Validating model...\n","Validation Loss: 0.2030290611717221\n","Validation Accuracy: 0.9518745866574049\n","Training epoch: 5\n","Training loss per 100 training steps: 0.04942639172077179\n","Training loss per 100 training steps: 0.021861822647503623\n","Training loss per 100 training steps: 0.024444194237784996\n","Training loss per 100 training steps: 0.025516296751206227\n","Training loss epoch: 0.025878560678929238\n","Training accuracy epoch: 0.9925076342586152\n","Validating model...\n","Validation Loss: 0.22322012823945903\n","Validation Accuracy: 0.9515450200413255\n","Training epoch: 6\n","Training loss per 100 training steps: 0.030572718009352684\n","Training loss per 100 training steps: 0.020401919329778688\n","Training loss per 100 training steps: 0.019727523682757157\n","Training loss per 100 training steps: 0.020291893100567112\n","Training loss epoch: 0.02004121364596741\n","Training accuracy epoch: 0.9941191953553847\n","Validating model...\n","Validation Loss: 0.22666892919737797\n","Validation Accuracy: 0.9529317753437968\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 42.741740899999904 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16395615709350547\n","Validation Accuracy: 0.9515016782737161\n","Validation duration: 5.866532499999933 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.8%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.83      0.82     12546\n","        test       0.85      0.85      0.85      9012\n","   treatment       0.84      0.78      0.81      9297\n","\n","   micro avg       0.83      0.82      0.83     30855\n","   macro avg       0.83      0.82      0.83     30855\n","weighted avg       0.83      0.82      0.83     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 12135\n","Points in y_train after augmentation: 12135\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8778607845306396\n","Training loss per 100 training steps: 0.3975840730979891\n","Training loss per 100 training steps: 0.2988712457541506\n","Training loss per 100 training steps: 0.252344705374831\n","Training loss epoch: 0.23106785560713003\n","Training accuracy epoch: 0.9279926823878569\n","Validating model...\n","Validation Loss: 0.1578093585255858\n","Validation Accuracy: 0.9508290714935865\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09071850776672363\n","Training loss per 100 training steps: 0.09301592433585389\n","Training loss per 100 training steps: 0.09168885016248594\n","Training loss per 100 training steps: 0.08918418518679086\n","Training loss epoch: 0.08827132304738226\n","Training accuracy epoch: 0.9720961248104381\n","Validating model...\n","Validation Loss: 0.16438970424525148\n","Validation Accuracy: 0.9518433375572348\n","Training epoch: 3\n","Training loss per 100 training steps: 0.06430931389331818\n","Training loss per 100 training steps: 0.047796348487902984\n","Training loss per 100 training steps: 0.04987794724038214\n","Training loss per 100 training steps: 0.049990948936298636\n","Training loss epoch: 0.05160931784193963\n","Training accuracy epoch: 0.9841363571812779\n","Validating model...\n","Validation Loss: 0.1914334748569247\n","Validation Accuracy: 0.9466561734367296\n","Training epoch: 4\n","Training loss per 100 training steps: 0.050949059426784515\n","Training loss per 100 training steps: 0.03235403147738169\n","Training loss per 100 training steps: 0.032544921679348124\n","Training loss per 100 training steps: 0.033163578724457674\n","Training loss epoch: 0.033204091961593615\n","Training accuracy epoch: 0.9901128071618248\n","Validating model...\n","Validation Loss: 0.20294599496311955\n","Validation Accuracy: 0.951756565478604\n","Training epoch: 5\n","Training loss per 100 training steps: 0.008981946855783463\n","Training loss per 100 training steps: 0.021616137586534023\n","Training loss per 100 training steps: 0.01987169129919928\n","Training loss per 100 training steps: 0.02140971718791507\n","Training loss epoch: 0.021750522168861752\n","Training accuracy epoch: 0.9936525952028251\n","Validating model...\n","Validation Loss: 0.21208946301009168\n","Validation Accuracy: 0.952366035540215\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0020759818144142628\n","Training loss per 100 training steps: 0.021249943092410073\n","Training loss per 100 training steps: 0.021222287471885724\n","Training loss per 100 training steps: 0.02079858631408074\n","Training loss epoch: 0.019768869775917235\n","Training accuracy epoch: 0.9939652883412206\n","Validating model...\n","Validation Loss: 0.22458067255747782\n","Validation Accuracy: 0.9541557599155616\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 43.20092958333335 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16771470088429782\n","Validation Accuracy: 0.9499809057540792\n","Validation duration: 5.889454449999903 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.83      0.82     12546\n","        test       0.81      0.83      0.82      9012\n","   treatment       0.82      0.83      0.83      9297\n","\n","   micro avg       0.81      0.83      0.82     30855\n","   macro avg       0.81      0.83      0.82     30855\n","weighted avg       0.81      0.83      0.82     30855\n","\n","!!!!!! Starting model number 7 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 12135\n","Points in y_train after augmentation: 12135\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.448530912399292\n","Training loss per 100 training steps: 0.4216905957696461\n","Training loss per 100 training steps: 0.30893972345549076\n","Training loss per 100 training steps: 0.26208784491863363\n","Training loss epoch: 0.23877283468058236\n","Training accuracy epoch: 0.924543634883917\n","Validating model...\n","Validation Loss: 0.15839684437718485\n","Validation Accuracy: 0.9498874007026465\n","Training epoch: 2\n","Training loss per 100 training steps: 0.14966611564159393\n","Training loss per 100 training steps: 0.08658812071501028\n","Training loss per 100 training steps: 0.08619510472302709\n","Training loss per 100 training steps: 0.08687426203063556\n","Training loss epoch: 0.08663381976075471\n","Training accuracy epoch: 0.9724589838103728\n","Validating model...\n","Validation Loss: 0.19201382157670988\n","Validation Accuracy: 0.946392317056137\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03785174340009689\n","Training loss per 100 training steps: 0.04875408515039057\n","Training loss per 100 training steps: 0.05011118865057604\n","Training loss per 100 training steps: 0.05229709773909214\n","Training loss epoch: 0.053723338752445816\n","Training accuracy epoch: 0.9834960023640085\n","Validating model...\n","Validation Loss: 0.17767654673813224\n","Validation Accuracy: 0.9561066686385115\n","Training epoch: 4\n","Training loss per 100 training steps: 0.017766987904906273\n","Training loss per 100 training steps: 0.03429123267328533\n","Training loss per 100 training steps: 0.034183550685115936\n","Training loss per 100 training steps: 0.03392507928729899\n","Training loss epoch: 0.034561716044003044\n","Training accuracy epoch: 0.9897479073259065\n","Validating model...\n","Validation Loss: 0.19001976911026935\n","Validation Accuracy: 0.9530015812207725\n","Training epoch: 5\n","Training loss per 100 training steps: 0.007267690729349852\n","Training loss per 100 training steps: 0.017814209299752175\n","Training loss per 100 training steps: 0.020922810097852844\n","Training loss per 100 training steps: 0.023874283634610412\n","Training loss epoch: 0.024373514226202753\n","Training accuracy epoch: 0.9928747941859073\n","Validating model...\n","Validation Loss: 0.20678942102043854\n","Validation Accuracy: 0.9561112920000585\n","Training epoch: 6\n","Training loss per 100 training steps: 0.021851619705557823\n","Training loss per 100 training steps: 0.017366869688624203\n","Training loss per 100 training steps: 0.018505435241780138\n","Training loss per 100 training steps: 0.019731371491015007\n","Training loss epoch: 0.020943169967320405\n","Training accuracy epoch: 0.9936362388355439\n","Validating model...\n","Validation Loss: 0.25510195238733446\n","Validation Accuracy: 0.9509234096323054\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 43.23519141666669 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16657826824855335\n","Validation Accuracy: 0.9477361929008086\n","Validation duration: 5.889056183333256 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 81.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.74      0.87      0.80     12546\n","        test       0.82      0.87      0.84      9012\n","   treatment       0.80      0.84      0.82      9297\n","\n","   micro avg       0.78      0.86      0.82     30855\n","   macro avg       0.79      0.86      0.82     30855\n","weighted avg       0.78      0.86      0.82     30855\n","\n","!!!!!! Starting model number 8 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 12135\n","Points in y_train after augmentation: 12135\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1487154960632324\n","Training loss per 100 training steps: 0.40901751432678485\n","Training loss per 100 training steps: 0.29637838447864967\n","Training loss per 100 training steps: 0.25239879196119863\n","Training loss epoch: 0.23180522359907627\n","Training accuracy epoch: 0.9264681292864189\n","Validating model...\n","Validation Loss: 0.14872812958700315\n","Validation Accuracy: 0.9508920504015038\n","Training epoch: 2\n","Training loss per 100 training steps: 0.1278621256351471\n","Training loss per 100 training steps: 0.08853880657196635\n","Training loss per 100 training steps: 0.08419072117878874\n","Training loss per 100 training steps: 0.0845201053436957\n","Training loss epoch: 0.08410600449140858\n","Training accuracy epoch: 0.9738737770737698\n","Validating model...\n","Validation Loss: 0.1834852181907211\n","Validation Accuracy: 0.9491997385401704\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04885770380496979\n","Training loss per 100 training steps: 0.04306586680122384\n","Training loss per 100 training steps: 0.04458064476343159\n","Training loss per 100 training steps: 0.04684540016291991\n","Training loss epoch: 0.04595929732926092\n","Training accuracy epoch: 0.9859040475768092\n","Validating model...\n","Validation Loss: 0.193227885510204\n","Validation Accuracy: 0.9521283144062006\n","Training epoch: 4\n","Training loss per 100 training steps: 0.07041317969560623\n","Training loss per 100 training steps: 0.029832165826591525\n","Training loss per 100 training steps: 0.034516754679483785\n","Training loss per 100 training steps: 0.0354449785139684\n","Training loss epoch: 0.0363740090568746\n","Training accuracy epoch: 0.9886016815380512\n","Validating model...\n","Validation Loss: 0.20557730465933874\n","Validation Accuracy: 0.9494553352250777\n","Training epoch: 5\n","Training loss per 100 training steps: 0.023914430290460587\n","Training loss per 100 training steps: 0.030189512121159178\n","Training loss per 100 training steps: 0.028107252132972303\n","Training loss per 100 training steps: 0.02838931487334824\n","Training loss epoch: 0.02704095169105322\n","Training accuracy epoch: 0.9919145489584984\n","Validating model...\n","Validation Loss: 0.20178134915987392\n","Validation Accuracy: 0.9498905770248709\n","Training epoch: 6\n","Training loss per 100 training steps: 0.009640669450163841\n","Training loss per 100 training steps: 0.01913214177192917\n","Training loss per 100 training steps: 0.016919179957948477\n","Training loss per 100 training steps: 0.018117251286153182\n","Training loss epoch: 0.01979251464547001\n","Training accuracy epoch: 0.9940319487342106\n","Validating model...\n","Validation Loss: 0.21023865860536115\n","Validation Accuracy: 0.9533252498148216\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 43.26176346666664 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16550837436052798\n","Validation Accuracy: 0.948922926271248\n","Validation duration: 5.882421149999815 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 81.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.78      0.79     12546\n","        test       0.81      0.88      0.84      9012\n","   treatment       0.79      0.85      0.82      9297\n","\n","   micro avg       0.80      0.83      0.82     30855\n","   macro avg       0.80      0.84      0.82     30855\n","weighted avg       0.80      0.83      0.82     30855\n","\n","!!!!!! Starting model number 9 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 12135\n","Points in y_train after augmentation: 12135\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.2882118225097656\n","Training loss per 100 training steps: 0.42522726097319385\n","Training loss per 100 training steps: 0.3057068387667338\n","Training loss per 100 training steps: 0.2596661712714406\n","Training loss epoch: 0.23664662166449585\n","Training accuracy epoch: 0.9243423085516441\n","Validating model...\n","Validation Loss: 0.14710450419164323\n","Validation Accuracy: 0.9520038787919667\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09474828094244003\n","Training loss per 100 training steps: 0.08645895831655748\n","Training loss per 100 training steps: 0.0851840016093865\n","Training loss per 100 training steps: 0.08468713891998775\n","Training loss epoch: 0.08367774237045332\n","Training accuracy epoch: 0.9730197149880272\n","Validating model...\n","Validation Loss: 0.16793108305760793\n","Validation Accuracy: 0.9516496317142001\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04596036672592163\n","Training loss per 100 training steps: 0.05168544243338822\n","Training loss per 100 training steps: 0.05352455488549759\n","Training loss per 100 training steps: 0.05093417011906835\n","Training loss epoch: 0.050750900594223484\n","Training accuracy epoch: 0.9845554351689763\n","Validating model...\n","Validation Loss: 0.19534077996073604\n","Validation Accuracy: 0.948398366480372\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03462864086031914\n","Training loss per 100 training steps: 0.03320328369367831\n","Training loss per 100 training steps: 0.0321013420688183\n","Training loss per 100 training steps: 0.03375319435811939\n","Training loss epoch: 0.033396568180882914\n","Training accuracy epoch: 0.9898549256608925\n","Validating model...\n","Validation Loss: 0.20572500184855677\n","Validation Accuracy: 0.9498022658094393\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0223234836012125\n","Training loss per 100 training steps: 0.021863663265951863\n","Training loss per 100 training steps: 0.026544808333656238\n","Training loss per 100 training steps: 0.026157886916895294\n","Training loss epoch: 0.025720885433379168\n","Training accuracy epoch: 0.9921459045653204\n","Validating model...\n","Validation Loss: 0.22088536196811634\n","Validation Accuracy: 0.95123356633001\n","Training epoch: 6\n","Training loss per 100 training steps: 0.01721903681755066\n","Training loss per 100 training steps: 0.015932706527591746\n","Training loss per 100 training steps: 0.020754051038274886\n","Training loss per 100 training steps: 0.021291725892702\n","Training loss epoch: 0.02481384947727508\n","Training accuracy epoch: 0.9925287862323513\n","Validating model...\n","Validation Loss: 0.20512154065798244\n","Validation Accuracy: 0.9505912986780144\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 43.26840963333331 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15943623526470252\n","Validation Accuracy: 0.9493099906714546\n","Validation duration: 5.8758723166664515 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 81.8%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.83      0.81     12546\n","        test       0.79      0.86      0.82      9012\n","   treatment       0.81      0.84      0.83      9297\n","\n","   micro avg       0.80      0.84      0.82     30855\n","   macro avg       0.80      0.84      0.82     30855\n","weighted avg       0.80      0.84      0.82     30855\n","\n","!!!!!! Starting model number 10 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 12135\n","Points in y_train after augmentation: 12135\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1754207611083984\n","Training loss per 100 training steps: 0.426604918250353\n","Training loss per 100 training steps: 0.30854023702034905\n","Training loss per 100 training steps: 0.25645172681374806\n","Training loss epoch: 0.23021476102110586\n","Training accuracy epoch: 0.9276455430553086\n","Validating model...\n","Validation Loss: 0.15720838743757892\n","Validation Accuracy: 0.9513375825981645\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04761676862835884\n","Training loss per 100 training steps: 0.0899242426656039\n","Training loss per 100 training steps: 0.08891914601655519\n","Training loss per 100 training steps: 0.08483525629362643\n","Training loss epoch: 0.08282093358299646\n","Training accuracy epoch: 0.973428422933191\n","Validating model...\n","Validation Loss: 0.1697557762071684\n","Validation Accuracy: 0.9507066004461387\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02280723676085472\n","Training loss per 100 training steps: 0.039494112622693624\n","Training loss per 100 training steps: 0.04158982353757566\n","Training loss per 100 training steps: 0.04274148985038069\n","Training loss epoch: 0.0431812185389725\n","Training accuracy epoch: 0.9864800121850804\n","Validating model...\n","Validation Loss: 0.19523131066038238\n","Validation Accuracy: 0.9515299363491162\n","Training epoch: 4\n","Training loss per 100 training steps: 0.015207802876830101\n","Training loss per 100 training steps: 0.03460007953217788\n","Training loss per 100 training steps: 0.033201495588025015\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0.75\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"oKNxFPucHn_R"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["381583743b294e029b86aa759f0db4b8","d7d779352f1c437c8c3a8410087aaab7","f1750556467d48b5ab143e8b0564cf2b","94f4700043cf495c9a64d97b05561bc4","7b475e9de3164bf5bf7231dde76adf44","d4ba919e581b4b4591a7740bb812589e","44d90a3e49e94a17b4754fff91ea4a99","cd7266723b5446c59ef8b7a42f630606","a1572206c8a240f9897d5fa9d1ced648","ec8c913e8d854a40b928987f412f1d69","80ec0f6545fa40fdb53fd639badf9e5a"]},"executionInfo":{"elapsed":3335303,"status":"ok","timestamp":1667605702991,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"6oNWXKYzqPC8","outputId":"418e652f-e4a7-4ea5-bc30-90eb899a7ef5"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 75.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"381583743b294e029b86aa759f0db4b8","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 12135\n","Points in y_train after augmentation: 12135\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0680952072143555\n","Training loss per 100 training steps: 0.41259681086729066\n","Training loss per 100 training steps: 0.3109761198139309\n","Training loss per 100 training steps: 0.2616361731360125\n","Training loss epoch: 0.23740827467684683\n","Training accuracy epoch: 0.9249461896577754\n","Validating model...\n","Validation Loss: 0.15394058213992554\n","Validation Accuracy: 0.951572041042434\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09090100228786469\n","Training loss per 100 training steps: 0.09858914088494707\n","Training loss per 100 training steps: 0.0936411822780003\n","Training loss per 100 training steps: 0.09011868450580245\n","Training loss epoch: 0.09082033892750348\n","Training accuracy epoch: 0.9717289231783963\n","Validating model...\n","Validation Loss: 0.1750603300313671\n","Validation Accuracy: 0.9504623671474831\n","Training epoch: 3\n","Training loss per 100 training steps: 0.043799109756946564\n","Training loss per 100 training steps: 0.04474096835618562\n","Training loss per 100 training steps: 0.04473156520902221\n","Training loss per 100 training steps: 0.0456147866967162\n","Training loss epoch: 0.0470081101808893\n","Training accuracy epoch: 0.9854932116071916\n","Validating model...\n","Validation Loss: 0.18646280588461206\n","Validation Accuracy: 0.9498192095991619\n","Training epoch: 4\n","Training loss per 100 training steps: 0.013235892169177532\n","Training loss per 100 training steps: 0.030750057975863023\n","Training loss per 100 training steps: 0.029158127199932563\n","Training loss per 100 training steps: 0.029782758263772063\n","Training loss epoch: 0.03168019233332751\n","Training accuracy epoch: 0.9898033982370441\n","Validating model...\n","Validation Loss: 0.21912379707995946\n","Validation Accuracy: 0.9466692051397106\n","Training epoch: 5\n","Training loss per 100 training steps: 0.04294966533780098\n","Training loss per 100 training steps: 0.026830746220553866\n","Training loss per 100 training steps: 0.024925494644170005\n","Training loss per 100 training steps: 0.026682176361126558\n","Training loss epoch: 0.027938898159099106\n","Training accuracy epoch: 0.9913850232019097\n","Validating model...\n","Validation Loss: 0.2242481392965495\n","Validation Accuracy: 0.9491823329567038\n","Training epoch: 6\n","Training loss per 100 training steps: 0.007332247216254473\n","Training loss per 100 training steps: 0.017472203252122433\n","Training loss per 100 training steps: 0.018689048071380297\n","Training loss per 100 training steps: 0.02003949813168044\n","Training loss epoch: 0.020905004161881822\n","Training accuracy epoch: 0.9934974149034825\n","Validating model...\n","Validation Loss: 0.2471973899413239\n","Validation Accuracy: 0.9475495202517112\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 45.08800321666667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16660521262221867\n","Validation Accuracy: 0.9480467967972163\n","Validation duration: 6.379539066666666 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.78      0.86      0.82     12546\n","        test       0.80      0.86      0.83      9012\n","   treatment       0.82      0.84      0.83      9297\n","\n","   micro avg       0.80      0.85      0.82     30855\n","   macro avg       0.80      0.85      0.83     30855\n","weighted avg       0.80      0.85      0.82     30855\n","\n"]}],"source":["number_of_training_models = 1\n","target_augmented_percentage = 0.75\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"6oNWXKYzqPC8"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"1tBh5gOBHpN1","outputId":"43a2fa3e-c8e7-4462-8327-c7039d9b86f1"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 100% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 13868\n","Points in y_train after augmentation: 13868\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8015668392181396\n","Training loss per 100 training steps: 0.424247676193124\n","Training loss per 100 training steps: 0.3072571091038819\n","Training loss per 100 training steps: 0.25991248181615756\n","Training loss per 100 training steps: 0.2326646077950622\n","Training loss epoch: 0.22453848939938342\n","Training accuracy epoch: 0.9300065825430168\n","Validating model...\n","Validation Loss: 0.17426669936288486\n","Validation Accuracy: 0.9492312257103389\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06061606854200363\n","Training loss per 100 training steps: 0.08324631233469094\n","Training loss per 100 training steps: 0.08694196531354491\n","Training loss per 100 training steps: 0.08639475425389716\n","Training loss per 100 training steps: 0.08412804355626541\n","Training loss epoch: 0.08282455030189234\n","Training accuracy epoch: 0.973822059710246\n","Validating model...\n","Validation Loss: 0.17938551769966815\n","Validation Accuracy: 0.9523737835899393\n","Training epoch: 3\n","Training loss per 100 training steps: 0.032063454389572144\n","Training loss per 100 training steps: 0.04832400475619453\n","Training loss per 100 training steps: 0.05024503340564705\n","Training loss per 100 training steps: 0.04918298269761262\n","Training loss per 100 training steps: 0.04893081456113913\n","Training loss epoch: 0.049823452842481915\n","Training accuracy epoch: 0.9845817715244176\n","Validating model...\n","Validation Loss: 0.18189236001631656\n","Validation Accuracy: 0.9520238502898493\n","Training epoch: 4\n","Training loss per 100 training steps: 0.011340649798512459\n","Training loss per 100 training steps: 0.040257415420716945\n","Training loss per 100 training steps: 0.03724084746333497\n","Training loss per 100 training steps: 0.0341185596713524\n","Training loss per 100 training steps: 0.03320272835296697\n","Training loss epoch: 0.033394870749022386\n","Training accuracy epoch: 0.9898122190729017\n","Validating model...\n","Validation Loss: 0.19931411494005036\n","Validation Accuracy: 0.9506176020517918\n","Training epoch: 5\n","Training loss per 100 training steps: 0.004323932342231274\n","Training loss per 100 training steps: 0.01932521761247501\n","Training loss per 100 training steps: 0.01800644116572322\n","Training loss per 100 training steps: 0.018868222508186542\n","Training loss per 100 training steps: 0.020203300953948372\n","Training loss epoch: 0.02033637044079546\n","Training accuracy epoch: 0.9941005142674939\n","Validating model...\n","Validation Loss: 0.22368203189417526\n","Validation Accuracy: 0.9525848790990902\n","Training epoch: 6\n","Training loss per 100 training steps: 0.002397308824583888\n","Training loss per 100 training steps: 0.013976985712577173\n","Training loss per 100 training steps: 0.018885378082356977\n","Training loss per 100 training steps: 0.020979126469785985\n","Training loss per 100 training steps: 0.020174672962990855\n","Training loss epoch: 0.021019849120714373\n","Training accuracy epoch: 0.9935643304693736\n","Validating model...\n","Validation Loss: 0.21600378757983738\n","Validation Accuracy: 0.9521196548954376\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 51.271395749999996 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.17481048489032588\n","Validation Accuracy: 0.9481276025377924\n","Validation duration: 6.364505733333347 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.1%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.85      0.82     12546\n","        test       0.84      0.86      0.85      9012\n","   treatment       0.81      0.77      0.79      9297\n","\n","   micro avg       0.81      0.83      0.82     30855\n","   macro avg       0.82      0.83      0.82     30855\n","weighted avg       0.81      0.83      0.82     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 13868\n","Points in y_train after augmentation: 13868\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1968722343444824\n","Training loss per 100 training steps: 0.43405971329401033\n","Training loss per 100 training steps: 0.31466689288838584\n","Training loss per 100 training steps: 0.2668089064525013\n","Training loss per 100 training steps: 0.2316746685068655\n","Training loss epoch: 0.2237412420183008\n","Training accuracy epoch: 0.9299772559488424\n","Validating model...\n","Validation Loss: 0.19158668583863742\n","Validation Accuracy: 0.9399331216162709\n","Training epoch: 2\n","Training loss per 100 training steps: 0.12728367745876312\n","Training loss per 100 training steps: 0.08594756531021973\n","Training loss per 100 training steps: 0.08331043784742925\n","Training loss per 100 training steps: 0.08428536596834858\n","Training loss per 100 training steps: 0.08525062585133418\n","Training loss epoch: 0.08453228593211673\n","Training accuracy epoch: 0.9730251006029057\n","Validating model...\n","Validation Loss: 0.2003295671364123\n","Validation Accuracy: 0.9457853906747576\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0538654550909996\n","Training loss per 100 training steps: 0.04506163530992252\n","Training loss per 100 training steps: 0.04273577170001704\n","Training loss per 100 training steps: 0.041981913212012265\n","Training loss per 100 training steps: 0.04449173326701613\n","Training loss epoch: 0.04500827677215317\n","Training accuracy epoch: 0.9866653061276709\n","Validating model...\n","Validation Loss: 0.18576538151541314\n","Validation Accuracy: 0.9483981496413608\n","Training epoch: 4\n","Training loss per 100 training steps: 0.06873021274805069\n","Training loss per 100 training steps: 0.02672078803476721\n","Training loss per 100 training steps: 0.029007510320904355\n","Training loss per 100 training steps: 0.029146715913175223\n","Training loss per 100 training steps: 0.030225482556511394\n","Training loss epoch: 0.03054976782091992\n","Training accuracy epoch: 0.9906668560191337\n","Validating model...\n","Validation Loss: 0.22655050432333698\n","Validation Accuracy: 0.9476766641533074\n","Training epoch: 5\n","Training loss per 100 training steps: 0.02085382305085659\n","Training loss per 100 training steps: 0.029518239988512038\n","Training loss per 100 training steps: 0.02640623751383701\n","Training loss per 100 training steps: 0.025545257190474468\n","Training loss per 100 training steps: 0.02764938257203816\n","Training loss epoch: 0.028087028144796546\n","Training accuracy epoch: 0.991862363341808\n","Validating model...\n","Validation Loss: 0.26555522773172946\n","Validation Accuracy: 0.9408556125364942\n","Training epoch: 6\n","Training loss per 100 training steps: 0.04597575590014458\n","Training loss per 100 training steps: 0.023610586930979227\n","Training loss per 100 training steps: 0.02164206410403739\n","Training loss per 100 training steps: 0.023514822870724993\n","Training loss per 100 training steps: 0.023013073935909685\n","Training loss epoch: 0.022469917318970394\n","Training accuracy epoch: 0.9932518625170452\n","Validating model...\n","Validation Loss: 0.2491926894607869\n","Validation Accuracy: 0.9497966094406681\n","Training epoch: 7\n","Training loss per 100 training steps: 0.03137437254190445\n","Training loss per 100 training steps: 0.014471172298636693\n","Training loss per 100 training steps: 0.014836362137086227\n","Training loss per 100 training steps: 0.014830258147183039\n","Training loss per 100 training steps: 0.015041686641081397\n","Training loss epoch: 0.015149244881977546\n","Training accuracy epoch: 0.9955927613087551\n","Validating model...\n","Validation Loss: 0.21944999716595395\n","Validation Accuracy: 0.9564307337069408\n","Training epoch: 8\n","Training loss per 100 training steps: 0.0008468047599308193\n","Training loss per 100 training steps: 0.010527151120690591\n","Training loss per 100 training steps: 0.01555313465671396\n","Training loss per 100 training steps: 0.014222409163212614\n","Training loss per 100 training steps: 0.013651152924292528\n","Training loss epoch: 0.014016271948458708\n","Training accuracy epoch: 0.9959113327598926\n","Validating model...\n","Validation Loss: 0.2629788833392131\n","Validation Accuracy: 0.9495911659542786\n","Training epoch: 9\n","Patience limit reached\n","Training duration: 68.31602960000001 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.19133933161437097\n","Validation Accuracy: 0.9494555918243316\n","Validation duration: 6.334254933333341 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.83      0.82     12546\n","        test       0.80      0.85      0.82      9012\n","   treatment       0.83      0.83      0.83      9297\n","\n","   micro avg       0.81      0.84      0.82     30855\n","   macro avg       0.81      0.84      0.82     30855\n","weighted avg       0.81      0.84      0.82     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 13868\n","Points in y_train after augmentation: 13868\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.744179129600525\n","Training loss per 100 training steps: 0.38483519158741036\n","Training loss per 100 training steps: 0.29029933081485737\n","Training loss per 100 training steps: 0.24697716675228454\n","Training loss per 100 training steps: 0.2157416644081139\n","Training loss epoch: 0.20882896918048094\n","Training accuracy epoch: 0.9345618833432106\n","Validating model...\n","Validation Loss: 0.172057503858557\n","Validation Accuracy: 0.9437933207884397\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07471019774675369\n","Training loss per 100 training steps: 0.07692999091220669\n","Training loss per 100 training steps: 0.08084198186146234\n","Training loss per 100 training steps: 0.08130430917493826\n","Training loss per 100 training steps: 0.08031286643655446\n","Training loss epoch: 0.08020247121809333\n","Training accuracy epoch: 0.9740210872810293\n","Validating model...\n","Validation Loss: 0.17899351715799663\n","Validation Accuracy: 0.9528703814186441\n","Training epoch: 3\n","Training loss per 100 training steps: 0.028029868379235268\n","Training loss per 100 training steps: 0.042613482075088686\n","Training loss per 100 training steps: 0.04498733960055\n","Training loss per 100 training steps: 0.04562253623108605\n","Training loss per 100 training steps: 0.044475935460497946\n","Training loss epoch: 0.044724552322947315\n","Training accuracy epoch: 0.9859273836336158\n","Validating model...\n","Validation Loss: 0.1778998203309519\n","Validation Accuracy: 0.9519686455905131\n","Training epoch: 4\n","Training loss per 100 training steps: 0.006255590356886387\n","Training loss per 100 training steps: 0.028524481244200824\n","Training loss per 100 training steps: 0.028760994083725323\n","Training loss per 100 training steps: 0.03011015255315124\n","Training loss per 100 training steps: 0.0296938208804496\n","Training loss epoch: 0.029839089558210893\n","Training accuracy epoch: 0.9909355780904908\n","Validating model...\n","Validation Loss: 0.2220060777209409\n","Validation Accuracy: 0.949197419887907\n","Training epoch: 5\n","Training loss per 100 training steps: 0.00457243574783206\n","Training loss per 100 training steps: 0.01654430811862821\n","Training loss per 100 training steps: 0.018630276896020127\n","Training loss per 100 training steps: 0.02371548233763392\n","Training loss per 100 training steps: 0.02505082679965285\n","Training loss epoch: 0.02492814961150782\n","Training accuracy epoch: 0.9922470879266297\n","Validating model...\n","Validation Loss: 0.22264057175292598\n","Validation Accuracy: 0.951447096717311\n","Training epoch: 6\n","Training loss per 100 training steps: 0.002250182908028364\n","Training loss per 100 training steps: 0.01437979264733483\n","Training loss per 100 training steps: 0.01752694830036634\n","Training loss per 100 training steps: 0.01977037500003755\n","Training loss per 100 training steps: 0.01895690989155703\n","Training loss epoch: 0.019151722837973402\n","Training accuracy epoch: 0.994257371861692\n","Validating model...\n","Validation Loss: 0.23534053516296016\n","Validation Accuracy: 0.9529156079639627\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 51.25081856666669 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.18209021410654747\n","Validation Accuracy: 0.9424649016749813\n","Validation duration: 6.324299133333322 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 80.9%\n","              precision    recall  f1-score   support\n","\n","     problem       0.74      0.85      0.79     12546\n","        test       0.83      0.82      0.83      9012\n","   treatment       0.80      0.85      0.82      9297\n","\n","   micro avg       0.78      0.84      0.81     30855\n","   macro avg       0.79      0.84      0.81     30855\n","weighted avg       0.78      0.84      0.81     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 13868\n","Points in y_train after augmentation: 13868\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0304434299468994\n","Training loss per 100 training steps: 0.4239004062544001\n","Training loss per 100 training steps: 0.31036004062686395\n","Training loss per 100 training steps: 0.26058709320683415\n","Training loss per 100 training steps: 0.23090213553938188\n","Training loss epoch: 0.2246073182878269\n","Training accuracy epoch: 0.9297162518759109\n","Validating model...\n","Validation Loss: 0.14955129706627363\n","Validation Accuracy: 0.9521120612042577\n","Training epoch: 2\n","Training loss per 100 training steps: 0.11744605004787445\n","Training loss per 100 training steps: 0.08691970732911389\n","Training loss per 100 training steps: 0.08205976857067045\n","Training loss per 100 training steps: 0.07934390868298537\n","Training loss per 100 training steps: 0.07825619129561576\n","Training loss epoch: 0.07741881511496028\n","Training accuracy epoch: 0.9760435721877221\n","Validating model...\n","Validation Loss: 0.18299474703849522\n","Validation Accuracy: 0.9507817856224183\n","Training epoch: 3\n","Training loss per 100 training steps: 0.062193065881729126\n","Training loss per 100 training steps: 0.04359630433067974\n","Training loss per 100 training steps: 0.04825588230006582\n","Training loss per 100 training steps: 0.049956149679989216\n","Training loss per 100 training steps: 0.05309303683644518\n","Training loss epoch: 0.05314603742332228\n","Training accuracy epoch: 0.9833289544609396\n","Validating model...\n","Validation Loss: 0.19549334337088195\n","Validation Accuracy: 0.9514680591860897\n","Training epoch: 4\n","Training loss per 100 training steps: 0.04510797560214996\n","Training loss per 100 training steps: 0.03128155683038185\n","Training loss per 100 training steps: 0.02871182889866397\n","Training loss per 100 training steps: 0.0310975712160518\n","Training loss per 100 training steps: 0.03024640697257203\n","Training loss epoch: 0.029656943400934433\n","Training accuracy epoch: 0.9909506968989303\n","Validating model...\n","Validation Loss: 0.20043443835207395\n","Validation Accuracy: 0.9564460188930555\n","Training epoch: 5\n","Training loss per 100 training steps: 0.09085904806852341\n","Training loss per 100 training steps: 0.023991215572978307\n","Training loss per 100 training steps: 0.021379547607181453\n","Training loss per 100 training steps: 0.02141263460016429\n","Training loss per 100 training steps: 0.020895830828794034\n","Training loss epoch: 0.020663004869746458\n","Training accuracy epoch: 0.9938999927511982\n","Validating model...\n","Validation Loss: 0.21242882679035138\n","Validation Accuracy: 0.9554413594940345\n","Training epoch: 6\n","Training loss per 100 training steps: 0.003275088267400861\n","Training loss per 100 training steps: 0.01607447489865567\n","Training loss per 100 training steps: 0.021341285991496338\n","Training loss per 100 training steps: 0.022105681264782292\n","Training loss per 100 training steps: 0.02323131478638934\n","Training loss epoch: 0.023580694113523284\n","Training accuracy epoch: 0.9928021086866514\n","Validating model...\n","Validation Loss: 0.226860925289137\n","Validation Accuracy: 0.951696226390911\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 51.22287625000002 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1580820718512836\n","Validation Accuracy: 0.9497247890121309\n","Validation duration: 6.3168199833333345 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.85      0.82     12546\n","        test       0.80      0.87      0.83      9012\n","   treatment       0.79      0.82      0.81      9297\n","\n","   micro avg       0.79      0.85      0.82     30855\n","   macro avg       0.79      0.85      0.82     30855\n","weighted avg       0.79      0.85      0.82     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 13868\n","Points in y_train after augmentation: 13868\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1115012168884277\n","Training loss per 100 training steps: 0.41393701414955725\n","Training loss per 100 training steps: 0.2997962236404419\n","Training loss per 100 training steps: 0.25440403258434163\n","Training loss per 100 training steps: 0.2266915075369458\n","Training loss epoch: 0.2204317939017088\n","Training accuracy epoch: 0.930742365032788\n","Validating model...\n","Validation Loss: 0.15797437722613286\n","Validation Accuracy: 0.951178113214363\n","Training epoch: 2\n","Training loss per 100 training steps: 0.029542433097958565\n","Training loss per 100 training steps: 0.08051067812017876\n","Training loss per 100 training steps: 0.07897206131758085\n","Training loss per 100 training steps: 0.07940090232624664\n","Training loss per 100 training steps: 0.07879319543859682\n","Training loss epoch: 0.07842232636283344\n","Training accuracy epoch: 0.9755252316895421\n","Validating model...\n","Validation Loss: 0.17659477734720552\n","Validation Accuracy: 0.951338500064188\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02318638563156128\n","Training loss per 100 training steps: 0.0420206913328038\n","Training loss per 100 training steps: 0.04754813409998865\n","Training loss per 100 training steps: 0.048122646687768916\n","Training loss per 100 training steps: 0.05023738510553676\n","Training loss epoch: 0.05101179910291519\n","Training accuracy epoch: 0.9840905459281779\n","Validating model...\n","Validation Loss: 0.20237732572214945\n","Validation Accuracy: 0.9463500933385466\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01649460196495056\n","Training loss per 100 training steps: 0.026356289147095074\n","Training loss per 100 training steps: 0.02830882548280431\n","Training loss per 100 training steps: 0.029671500366957752\n","Training loss per 100 training steps: 0.030384459760692668\n","Training loss epoch: 0.030364901684964942\n","Training accuracy epoch: 0.9910278484026822\n","Validating model...\n","Validation Loss: 0.2062676792553106\n","Validation Accuracy: 0.9528296580968988\n","Training epoch: 5\n","Training loss per 100 training steps: 0.012410711497068405\n","Training loss per 100 training steps: 0.02272887460859769\n","Training loss per 100 training steps: 0.020515813125617136\n","Training loss per 100 training steps: 0.019445142062826458\n","Training loss per 100 training steps: 0.020115918729238288\n","Training loss epoch: 0.020324136338396265\n","Training accuracy epoch: 0.9941484185834051\n","Validating model...\n","Validation Loss: 0.22065910776810987\n","Validation Accuracy: 0.9536788780283049\n","Training epoch: 6\n","Training loss per 100 training steps: 0.019853269681334496\n","Training loss per 100 training steps: 0.017406532832532014\n","Training loss per 100 training steps: 0.01971765511914791\n","Training loss per 100 training steps: 0.01899295720442715\n","Training loss per 100 training steps: 0.019619450188082806\n","Training loss epoch: 0.0202232857296739\n","Training accuracy epoch: 0.9939761046331532\n","Validating model...\n","Validation Loss: 0.22993050781743868\n","Validation Accuracy: 0.9509118987317927\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 51.019792766666676 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16186657523805345\n","Validation Accuracy: 0.9506009085637298\n","Validation duration: 6.318454850000005 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.8%\n","              precision    recall  f1-score   support\n","\n","     problem       0.78      0.86      0.82     12546\n","        test       0.84      0.86      0.85      9012\n","   treatment       0.79      0.86      0.82      9297\n","\n","   micro avg       0.80      0.86      0.83     30855\n","   macro avg       0.80      0.86      0.83     30855\n","weighted avg       0.80      0.86      0.83     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 13868\n","Points in y_train after augmentation: 13868\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7228556871414185\n","Training loss per 100 training steps: 0.3892996472002256\n","Training loss per 100 training steps: 0.29521226686476476\n","Training loss per 100 training steps: 0.25250970983129006\n","Training loss per 100 training steps: 0.22571194001898504\n","Training loss epoch: 0.22017759525041153\n","Training accuracy epoch: 0.9306446329747512\n","Validating model...\n","Validation Loss: 0.17147525457979798\n","Validation Accuracy: 0.9468040795054248\n","Training epoch: 2\n","Training loss per 100 training steps: 0.1284860372543335\n","Training loss per 100 training steps: 0.09363710730899089\n","Training loss per 100 training steps: 0.08819291563194931\n","Training loss per 100 training steps: 0.08538860997240805\n","Training loss per 100 training steps: 0.08300640698791739\n","Training loss epoch: 0.08280870468626099\n","Training accuracy epoch: 0.9744515782119054\n","Validating model...\n","Validation Loss: 0.16948622750577988\n","Validation Accuracy: 0.9527220547882187\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0793079063296318\n","Training loss per 100 training steps: 0.04450045622156767\n","Training loss per 100 training steps: 0.0423038575615252\n","Training loss per 100 training steps: 0.04157412233159095\n","Training loss per 100 training steps: 0.042042096217448574\n","Training loss epoch: 0.04394500052839655\n","Training accuracy epoch: 0.9863559714901976\n","Validating model...\n","Validation Loss: 0.2017248384896424\n","Validation Accuracy: 0.9523878190349009\n","Training epoch: 4\n","Training loss per 100 training steps: 0.008998255245387554\n","Training loss per 100 training steps: 0.03432017129541624\n","Training loss per 100 training steps: 0.03569539017808526\n","Training loss per 100 training steps: 0.038032995523773504\n","Training loss per 100 training steps: 0.036860753213661605\n","Training loss epoch: 0.03684562900798902\n","Training accuracy epoch: 0.988413824087918\n","Validating model...\n","Validation Loss: 0.19559197080648177\n","Validation Accuracy: 0.9560076247788092\n","Training epoch: 5\n","Training loss per 100 training steps: 0.027518831193447113\n","Training loss per 100 training steps: 0.022132269166741925\n","Training loss per 100 training steps: 0.021661934626997628\n","Training loss per 100 training steps: 0.021507255381059853\n","Training loss per 100 training steps: 0.02124631665185433\n","Training loss epoch: 0.02195532389737833\n","Training accuracy epoch: 0.9934333105402123\n","Validating model...\n","Validation Loss: 0.22609599377028644\n","Validation Accuracy: 0.9522189137661078\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0028054453432559967\n","Training loss per 100 training steps: 0.016907430654460803\n","Training loss per 100 training steps: 0.015923666490927635\n","Training loss per 100 training steps: 0.016787968215685758\n","Training loss per 100 training steps: 0.01811500205678698\n","Training loss epoch: 0.018488912327882454\n","Training accuracy epoch: 0.99443109347424\n","Validating model...\n","Validation Loss: 0.2328122335111166\n","Validation Accuracy: 0.9509796329383495\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0012110515963286161\n","Training loss per 100 training steps: 0.01495324604969361\n","Training loss per 100 training steps: 0.015706864136400916\n","Training loss per 100 training steps: 0.014959689925124628\n","Training loss per 100 training steps: 0.015144926391410156\n","Training loss epoch: 0.015399091824803883\n","Training accuracy epoch: 0.9956770647477896\n","Validating model...\n","Validation Loss: 0.22362025018612092\n","Validation Accuracy: 0.9545943388543745\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 59.67893103333329 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.18141056027767868\n","Validation Accuracy: 0.9504918683899072\n","Validation duration: 6.314852233333416 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.83      0.83     12546\n","        test       0.86      0.84      0.85      9012\n","   treatment       0.79      0.87      0.83      9297\n","\n","   micro avg       0.82      0.85      0.83     30855\n","   macro avg       0.82      0.85      0.84     30855\n","weighted avg       0.82      0.85      0.83     30855\n","\n","!!!!!! Starting model number 7 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 13868\n","Points in y_train after augmentation: 13868\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9514087438583374\n","Training loss per 100 training steps: 0.4160341804865563\n","Training loss per 100 training steps: 0.3043605239311261\n","Training loss per 100 training steps: 0.2552291753878229\n","Training loss per 100 training steps: 0.22604998147249816\n","Training loss epoch: 0.21956999252297088\n","Training accuracy epoch: 0.9314094244278637\n","Validating model...\n","Validation Loss: 0.1573114888863517\n","Validation Accuracy: 0.9495347543631949\n","Training epoch: 2\n","Training loss per 100 training steps: 0.061432357877492905\n","Training loss per 100 training steps: 0.08830872452863962\n","Training loss per 100 training steps: 0.08451824820605083\n","Training loss per 100 training steps: 0.07989365126987133\n","Training loss per 100 training steps: 0.0766034272297325\n","Training loss epoch: 0.07662896616470223\n","Training accuracy epoch: 0.9758348035813773\n","Validating model...\n","Validation Loss: 0.16828556015313445\n","Validation Accuracy: 0.9530826650688167\n","Training epoch: 3\n","Training loss per 100 training steps: 0.015174515545368195\n","Training loss per 100 training steps: 0.04103235796204593\n","Training loss per 100 training steps: 0.04147528798379634\n","Training loss per 100 training steps: 0.04165852128797245\n","Training loss per 100 training steps: 0.04370965273467884\n","Training loss epoch: 0.04361732254525827\n","Training accuracy epoch: 0.9863648995458356\n","Validating model...\n","Validation Loss: 0.1815701023518265\n","Validation Accuracy: 0.953514877128879\n","Training epoch: 4\n","Training loss per 100 training steps: 0.015887008979916573\n","Training loss per 100 training steps: 0.024314600785290547\n","Training loss per 100 training steps: 0.028027538912699775\n","Training loss per 100 training steps: 0.030709074726219962\n","Training loss per 100 training steps: 0.03212221943049871\n","Training loss epoch: 0.03212919039463985\n","Training accuracy epoch: 0.9901456017868825\n","Validating model...\n","Validation Loss: 0.20164066311213877\n","Validation Accuracy: 0.9509945752194997\n","Training epoch: 5\n","Training loss per 100 training steps: 0.012660079635679722\n","Training loss per 100 training steps: 0.018411106959049874\n","Training loss per 100 training steps: 0.02059232585991626\n","Training loss per 100 training steps: 0.02062056304622392\n","Training loss per 100 training steps: 0.021736074949410322\n","Training loss epoch: 0.022163220239461996\n","Training accuracy epoch: 0.9932407207195061\n","Validating model...\n","Validation Loss: 0.218220794791138\n","Validation Accuracy: 0.951969738667519\n","Training epoch: 6\n","Training loss per 100 training steps: 0.016689684242010117\n","Training loss per 100 training steps: 0.014208361154334565\n","Training loss per 100 training steps: 0.02460615893458688\n","Training loss per 100 training steps: 0.024741217254025186\n","Training loss per 100 training steps: 0.023937241764050536\n","Training loss epoch: 0.024403089509224346\n","Training accuracy epoch: 0.9923510441775621\n","Validating model...\n","Validation Loss: 0.23583605583128217\n","Validation Accuracy: 0.9495330619433471\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 51.18292730000006 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16714824193277983\n","Validation Accuracy: 0.9487537410071751\n","Validation duration: 6.310073566666688 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 80.9%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.79      0.80     12546\n","        test       0.79      0.84      0.81      9012\n","   treatment       0.78      0.85      0.82      9297\n","\n","   micro avg       0.80      0.82      0.81     30855\n","   macro avg       0.79      0.83      0.81     30855\n","weighted avg       0.80      0.82      0.81     30855\n","\n","!!!!!! Starting model number 8 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 13868\n","Points in y_train after augmentation: 13868\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.974058985710144\n","Training loss per 100 training steps: 0.4071726177145939\n","Training loss per 100 training steps: 0.30197222441879673\n","Training loss per 100 training steps: 0.2563251832073115\n","Training loss per 100 training steps: 0.22598017532926545\n","Training loss epoch: 0.2184965670653855\n","Training accuracy epoch: 0.9298838469904013\n","Validating model...\n","Validation Loss: 0.14754608196097535\n","Validation Accuracy: 0.9511244682433558\n","Training epoch: 2\n","Training loss per 100 training steps: 0.08716180920600891\n","Training loss per 100 training steps: 0.08522532220081527\n","Training loss per 100 training steps: 0.07987832512928923\n","Training loss per 100 training steps: 0.07805979190289083\n","Training loss per 100 training steps: 0.07645239796898237\n","Training loss epoch: 0.07595388653091571\n","Training accuracy epoch: 0.9758046692627967\n","Validating model...\n","Validation Loss: 0.1774143987129648\n","Validation Accuracy: 0.9535256023118731\n","Training epoch: 3\n","Training loss per 100 training steps: 0.029189014807343483\n","Training loss per 100 training steps: 0.03971579559792829\n","Training loss per 100 training steps: 0.043629952938068865\n","Training loss per 100 training steps: 0.046214151884617895\n","Training loss per 100 training steps: 0.047620331053912376\n","Training loss epoch: 0.04885560236195283\n","Training accuracy epoch: 0.9847698650297018\n","Validating model...\n","Validation Loss: 0.1666786807601328\n","Validation Accuracy: 0.9539429259064324\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01161994319409132\n","Training loss per 100 training steps: 0.0276629904119095\n","Training loss per 100 training steps: 0.029797926750173096\n","Training loss per 100 training steps: 0.02871322824675404\n","Training loss per 100 training steps: 0.02992403385533656\n","Training loss epoch: 0.029661561026074815\n","Training accuracy epoch: 0.991135411422807\n","Validating model...\n","Validation Loss: 0.19351739823431163\n","Validation Accuracy: 0.9540129003338933\n","Training epoch: 5\n","Training loss per 100 training steps: 0.034998636692762375\n","Training loss per 100 training steps: 0.021267931987900324\n","Training loss per 100 training steps: 0.01903133140645217\n","Training loss per 100 training steps: 0.020515266191322615\n","Training loss per 100 training steps: 0.0218196194656681\n","Training loss epoch: 0.021937717896862566\n","Training accuracy epoch: 0.9934323806597276\n","Validating model...\n","Validation Loss: 0.23442061619179977\n","Validation Accuracy: 0.9506489069313588\n","Training epoch: 6\n","Training loss per 100 training steps: 0.05205637589097023\n","Training loss per 100 training steps: 0.016876856589546924\n","Training loss per 100 training steps: 0.017762793304771648\n","Training loss per 100 training steps: 0.01864140194262907\n","Training loss per 100 training steps: 0.01976005063175068\n","Training loss epoch: 0.020193665917407\n","Training accuracy epoch: 0.9938354735698746\n","Validating model...\n","Validation Loss: 0.23884243681397918\n","Validation Accuracy: 0.9499601927443455\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 51.114981166666624 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15490388420746765\n","Validation Accuracy: 0.9517728912874504\n","Validation duration: 6.296663399999913 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.82      0.82     12546\n","        test       0.82      0.83      0.82      9012\n","   treatment       0.81      0.86      0.83      9297\n","\n","   micro avg       0.82      0.83      0.82     30855\n","   macro avg       0.82      0.83      0.82     30855\n","weighted avg       0.82      0.83      0.82     30855\n","\n","!!!!!! Starting model number 9 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 13868\n","Points in y_train after augmentation: 13868\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0265896320343018\n","Training loss per 100 training steps: 0.3961425473046775\n","Training loss per 100 training steps: 0.29563122655992485\n","Training loss per 100 training steps: 0.24775541904212234\n","Training loss per 100 training steps: 0.2224956538779034\n","Training loss epoch: 0.21523010068088083\n","Training accuracy epoch: 0.9320663336330108\n","Validating model...\n","Validation Loss: 0.15757993265212356\n","Validation Accuracy: 0.9497056819539408\n","Training epoch: 2\n","Training loss per 100 training steps: 0.1761571764945984\n","Training loss per 100 training steps: 0.07831985951576492\n","Training loss per 100 training steps: 0.07922121959817202\n","Training loss per 100 training steps: 0.08609076605744635\n","Training loss per 100 training steps: 0.08856256196317158\n","Training loss epoch: 0.08819605150229988\n","Training accuracy epoch: 0.9727423568429652\n","Validating model...\n","Validation Loss: 0.18896616864707563\n","Validation Accuracy: 0.9466834304764352\n","Training epoch: 3\n","Training loss per 100 training steps: 0.018129216507077217\n","Training loss per 100 training steps: 0.05625317538950113\n","Training loss per 100 training steps: 0.059744783742028976\n","Training loss per 100 training steps: 0.05801289705899962\n","Training loss per 100 training steps: 0.056820848120604076\n","Training loss epoch: 0.056389006674461374\n","Training accuracy epoch: 0.9830136066499408\n","Validating model...\n","Validation Loss: 0.18560557464113484\n","Validation Accuracy: 0.9536592474454997\n","Training epoch: 4\n","Training loss per 100 training steps: 0.023829732090234756\n","Training loss per 100 training steps: 0.03380866706518844\n","Training loss per 100 training steps: 0.0347310701380507\n","Training loss per 100 training steps: 0.03555873906985544\n","Training loss per 100 training steps: 0.03579582794606593\n","Training loss epoch: 0.03562959473020041\n","Training accuracy epoch: 0.9898216077101472\n","Validating model...\n","Validation Loss: 0.19603552328204954\n","Validation Accuracy: 0.9537145719014748\n","Training epoch: 5\n","Training loss per 100 training steps: 0.006860694848001003\n","Training loss per 100 training steps: 0.02258966527279872\n","Training loss per 100 training steps: 0.021646881832530378\n","Training loss per 100 training steps: 0.021481139034046744\n","Training loss per 100 training steps: 0.02382555858280273\n","Training loss epoch: 0.0233416052985548\n","Training accuracy epoch: 0.9931217275838076\n","Validating model...\n","Validation Loss: 0.2442479580761744\n","Validation Accuracy: 0.9537721671742592\n","Training epoch: 6\n","Training loss per 100 training steps: 0.04358480125665665\n","Training loss per 100 training steps: 0.020653561003146564\n","Training loss per 100 training steps: 0.020580625003701846\n","Training loss per 100 training steps: 0.020208405694139942\n","Training loss per 100 training steps: 0.020004613594264673\n","Training loss epoch: 0.020426776562039506\n","Training accuracy epoch: 0.994095281709085\n","Validating model...\n","Validation Loss: 0.25599706405169004\n","Validation Accuracy: 0.9496044428982997\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 51.047825116666594 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1621941909564797\n","Validation Accuracy: 0.9501495339509338\n","Validation duration: 6.289443133333285 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.84      0.82     12546\n","        test       0.84      0.84      0.84      9012\n","   treatment       0.78      0.84      0.81      9297\n","\n","   micro avg       0.81      0.84      0.82     30855\n","   macro avg       0.81      0.84      0.82     30855\n","weighted avg       0.81      0.84      0.82     30855\n","\n","!!!!!! Starting model number 10 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 13868\n","Points in y_train after augmentation: 13868\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0362894535064697\n","Training loss per 100 training steps: 0.41041320296797423\n","Training loss per 100 training steps: 0.29723714423639264\n","Training loss per 100 training steps: 0.25500690375154594\n","Training loss per 100 training steps: 0.2276941255719733\n","Training loss epoch: 0.2201740367999\n","Training accuracy epoch: 0.9313035952904631\n","Validating model...\n","Validation Loss: 0.18605348462988805\n","Validation Accuracy: 0.9403421146129834\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07894083857536316\n","Training loss per 100 training steps: 0.08169938618372573\n","Training loss per 100 training steps: 0.07939732728053385\n","Training loss per 100 training steps: 0.07847739308391793\n","Training loss per 100 training steps: 0.07781109804440837\n","Training loss epoch: 0.07734657002801788\n","Training accuracy epoch: 0.9750772114301142\n","Validating model...\n","Validation Loss: 0.17225311701367427\n","Validation Accuracy: 0.952906331121097\n","Training epoch: 3\n","Training loss per 100 training steps: 0.10363750904798508\n","Training loss per 100 training steps: 0.04233992675383861\n","Training loss per 100 training steps: 0.04170748825759548\n","Training loss per 100 training steps: 0.041821410833854857\n","Training loss per 100 training steps: 0.04272352679321389\n","Training loss epoch: 0.04244454337492121\n","Training accuracy epoch: 0.987038099177962\n","Validating model...\n","Validation Loss: 0.19394772412110264\n","Validation Accuracy: 0.9537871534097306\n","Training epoch: 4\n","Training loss per 100 training steps: 0.02854708768427372\n","Training loss per 100 training steps: 0.029980662887418033\n","Training loss per 100 training steps: 0.029404118002637925\n","Training loss per 100 training steps: 0.030992952386610383\n","Training loss per 100 training steps: 0.03167729949848053\n","Training loss epoch: 0.0316048470258172\n","Training accuracy epoch: 0.9900727365239134\n","Validating model...\n","Validation Loss: 0.20554416900041042\n","Validation Accuracy: 0.9528290787643464\n","Training epoch: 5\n","Training loss per 100 training steps: 0.012814032845199108\n","Training loss per 100 training steps: 0.02092467212823616\n","Training loss per 100 training steps: 0.02218052092534189\n","Training loss per 100 training steps: 0.021662609490405063\n","Training loss per 100 training steps: 0.0215010576285747\n","Training loss epoch: 0.0213819239524618\n","Training accuracy epoch: 0.9932253034387161\n","Validating model...\n","Validation Loss: 0.23330517439776427\n","Validation Accuracy: 0.951521986335474\n","Training epoch: 6\n","Training loss per 100 training steps: 0.001285314792767167\n","Training loss per 100 training steps: 0.02387519416025849\n","Training loss per 100 training steps: 0.021190282497763523\n","Training loss per 100 training steps: 0.020427402357982342\n","Training loss per 100 training steps: 0.018862015315728665\n","Training loss epoch: 0.020100586694366974\n","Training accuracy epoch: 0.994066168997522\n","Validating model...\n","Validation Loss: 0.20647938641441332\n","Validation Accuracy: 0.9519591015362936\n","Training epoch: 7\n","Training loss per 100 training steps: 0.017406336963176727\n","Training loss per 100 training steps: 0.017252023096685068\n","Stopping epoch...\n","Training loss epoch: 0.017252023096685068\n","Training accuracy epoch: 0.9849168574780134\n","Validating model...\n","Validation Loss: 0.24731719585788714\n","Validation Accuracy: 0.9482300858410048\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 53.4121504 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1856967186829058\n","Validation Accuracy: 0.9504155807313924\n","Validation duration: 6.2903551999999765 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.82      0.83     12546\n","        test       0.83      0.82      0.83      9012\n","   treatment       0.82      0.83      0.82      9297\n","\n","   micro avg       0.82      0.83      0.83     30855\n","   macro avg       0.82      0.83      0.83     30855\n","weighted avg       0.82      0.83      0.83     30855\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 1\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"1tBh5gOBHpN1"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Zjhn7-LqHri0","outputId":"fae89a88-a254-4f5a-c0e4-c483e4f73383"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 200% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 20802\n","Points in y_train after augmentation: 20802\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.180438995361328\n","Training loss per 100 training steps: 0.41704781840343286\n","Training loss per 100 training steps: 0.31157837355907875\n","Training loss per 100 training steps: 0.26497252526819903\n","Training loss per 100 training steps: 0.23697231379233097\n","Training loss per 100 training steps: 0.2138224960548316\n","Training loss per 100 training steps: 0.19663033136065908\n","Training loss epoch: 0.1891658272137851\n","Training accuracy epoch: 0.9396467195521093\n","Validating model...\n","Validation Loss: 0.16785038787532935\n","Validation Accuracy: 0.9520844754754455\n","Training epoch: 2\n","Training loss per 100 training steps: 0.027275679633021355\n","Training loss per 100 training steps: 0.06639585106882571\n","Training loss per 100 training steps: 0.06282274238533568\n","Training loss per 100 training steps: 0.06549145943296461\n","Training loss per 100 training steps: 0.06477439361380558\n","Training loss per 100 training steps: 0.0639145624909379\n","Training loss per 100 training steps: 0.06438275617617066\n","Training loss epoch: 0.06561402183095996\n","Training accuracy epoch: 0.9789212557504456\n","Validating model...\n","Validation Loss: 0.20265332019174254\n","Validation Accuracy: 0.9470075361761164\n","Training epoch: 3\n","Training loss per 100 training steps: 0.023093950003385544\n","Training loss per 100 training steps: 0.033685978529698186\n","Training loss per 100 training steps: 0.03570320475985533\n","Training loss per 100 training steps: 0.035181438041374434\n","Training loss per 100 training steps: 0.036587193223910214\n","Training loss per 100 training steps: 0.036652755019665806\n","Training loss per 100 training steps: 0.03738118861120089\n","Training loss epoch: 0.036947324894906555\n","Training accuracy epoch: 0.9884126363308722\n","Validating model...\n","Validation Loss: 0.1994169878882247\n","Validation Accuracy: 0.9511270534649956\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03348487988114357\n","Training loss per 100 training steps: 0.02482451451827062\n","Training loss per 100 training steps: 0.024722095764246745\n","Training loss per 100 training steps: 0.02501265319571691\n","Training loss per 100 training steps: 0.02592780067123231\n","Training loss per 100 training steps: 0.024994663856765572\n","Training loss per 100 training steps: 0.026244947351104643\n","Training loss epoch: 0.02586830878728992\n","Training accuracy epoch: 0.9918633322625758\n","Validating model...\n","Validation Loss: 0.24639943880694254\n","Validation Accuracy: 0.9471390778791632\n","Training epoch: 5\n","Training loss per 100 training steps: 0.04060056060552597\n","Training loss per 100 training steps: 0.013898910547140986\n","Training loss per 100 training steps: 0.014570420891288622\n","Training loss per 100 training steps: 0.01623843713948562\n","Training loss per 100 training steps: 0.01727544013685152\n","Training loss per 100 training steps: 0.017443518770731775\n","Training loss per 100 training steps: 0.01834459074329509\n","Training loss epoch: 0.018548474747291658\n","Training accuracy epoch: 0.9945556643070012\n","Validating model...\n","Validation Loss: 0.23647828748473873\n","Validation Accuracy: 0.9480027478616093\n","Training epoch: 6\n","Training loss per 100 training steps: 0.004545306786894798\n","Training loss per 100 training steps: 0.014305696252728858\n","Training loss per 100 training steps: 0.014237187979876097\n","Training loss per 100 training steps: 0.022827889561321296\n","Training loss per 100 training steps: 0.02300851878486841\n","Training loss per 100 training steps: 0.023301140386009396\n","Training loss per 100 training steps: 0.022965139289998285\n","Training loss epoch: 0.022502082275516765\n","Training accuracy epoch: 0.9931173264175953\n","Validating model...\n","Validation Loss: 0.25684942517961773\n","Validation Accuracy: 0.9522460672178401\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 74.82884698333328 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.17454282945039234\n","Validation Accuracy: 0.9502373455710187\n","Validation duration: 6.2846243333333405 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.1%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.80      0.80     12546\n","        test       0.82      0.87      0.85      9012\n","   treatment       0.81      0.84      0.83      9297\n","\n","   micro avg       0.81      0.84      0.82     30855\n","   macro avg       0.81      0.84      0.82     30855\n","weighted avg       0.80      0.84      0.82     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 20802\n","Points in y_train after augmentation: 20802\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8241313695907593\n","Training loss per 100 training steps: 0.41166532076526396\n","Training loss per 100 training steps: 0.298966061676023\n","Training loss per 100 training steps: 0.2517658636667008\n","Training loss per 100 training steps: 0.22174593321793246\n","Training loss per 100 training steps: 0.20258274333116538\n","Training loss per 100 training steps: 0.18767973018838047\n","Training loss epoch: 0.1808876777253759\n","Training accuracy epoch: 0.942584268946789\n","Validating model...\n","Validation Loss: 0.171367437856925\n","Validation Accuracy: 0.9496464148978524\n","Training epoch: 2\n","Training loss per 100 training steps: 0.03644189238548279\n","Training loss per 100 training steps: 0.06622377891868057\n","Training loss per 100 training steps: 0.0650536110114992\n","Training loss per 100 training steps: 0.061368129302769206\n","Training loss per 100 training steps: 0.060588498885494814\n","Training loss per 100 training steps: 0.05918899262342565\n","Training loss per 100 training steps: 0.06023207035290694\n","Training loss epoch: 0.06065985949094137\n","Training accuracy epoch: 0.981083634829847\n","Validating model...\n","Validation Loss: 0.2203978103670207\n","Validation Accuracy: 0.943493124704983\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0255212914198637\n","Training loss per 100 training steps: 0.03996596949193442\n","Training loss per 100 training steps: 0.036367538203809655\n","Training loss per 100 training steps: 0.034916127455247525\n","Training loss per 100 training steps: 0.035354369662834464\n","Training loss per 100 training steps: 0.035551182957535274\n","Training loss per 100 training steps: 0.03513695266366643\n","Training loss epoch: 0.035193248796591484\n","Training accuracy epoch: 0.9890345200437485\n","Validating model...\n","Validation Loss: 0.200208447825212\n","Validation Accuracy: 0.9521498819896037\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0051135169342160225\n","Training loss per 100 training steps: 0.023636612104076783\n","Training loss per 100 training steps: 0.02443025834349897\n","Training loss per 100 training steps: 0.024721789265251055\n","Training loss per 100 training steps: 0.029768746721754523\n","Training loss per 100 training steps: 0.03115747723263222\n","Training loss per 100 training steps: 0.0312941946904175\n","Training loss epoch: 0.03120633943988863\n","Training accuracy epoch: 0.9902235005705071\n","Validating model...\n","Validation Loss: 0.22528671630500974\n","Validation Accuracy: 0.9484540676475918\n","Training epoch: 5\n","Training loss per 100 training steps: 0.004770954605191946\n","Training loss per 100 training steps: 0.019999134375040632\n","Training loss per 100 training steps: 0.019778074134275576\n","Training loss per 100 training steps: 0.01846033619736875\n","Training loss per 100 training steps: 0.018051159754729346\n","Training loss per 100 training steps: 0.017789248548512684\n","Training loss per 100 training steps: 0.01726105234219798\n","Training loss epoch: 0.017457221151142167\n","Training accuracy epoch: 0.9946381796824565\n","Validating model...\n","Validation Loss: 0.23546506667074252\n","Validation Accuracy: 0.9518051135392456\n","Training epoch: 6\n","Training loss per 100 training steps: 0.002538950415328145\n","Training loss per 100 training steps: 0.011958667596958872\n","Training loss per 100 training steps: 0.013453096750803958\n","Training loss per 100 training steps: 0.013529194951420217\n","Training loss per 100 training steps: 0.013438685075292814\n","Training loss per 100 training steps: 0.014195136433353874\n","Training loss per 100 training steps: 0.013526294343913448\n","Training loss epoch: 0.013642020653196526\n","Training accuracy epoch: 0.9960654702274152\n","Validating model...\n","Validation Loss: 0.2459138985965159\n","Validation Accuracy: 0.9522643735822516\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 74.92563076666653 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16959694858114407\n","Validation Accuracy: 0.9508275611646977\n","Validation duration: 6.302255383333249 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.83      0.82     12546\n","        test       0.77      0.90      0.83      9012\n","   treatment       0.85      0.81      0.83      9297\n","\n","   micro avg       0.81      0.84      0.83     30855\n","   macro avg       0.81      0.85      0.83     30855\n","weighted avg       0.81      0.84      0.83     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 20802\n","Points in y_train after augmentation: 20802\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8053576946258545\n","Training loss per 100 training steps: 0.39794374183558\n","Training loss per 100 training steps: 0.2922952229073688\n","Training loss per 100 training steps: 0.25094340964409206\n","Training loss per 100 training steps: 0.22505972529773105\n","Training loss per 100 training steps: 0.2058137081890644\n","Training loss per 100 training steps: 0.18900591004236963\n","Training loss epoch: 0.18196110120908673\n","Training accuracy epoch: 0.9421224895894595\n","Validating model...\n","Validation Loss: 0.173029600703097\n","Validation Accuracy: 0.9489453824438099\n","Training epoch: 2\n","Training loss per 100 training steps: 0.08913879841566086\n","Training loss per 100 training steps: 0.06762239064025406\n","Training loss per 100 training steps: 0.06765776185958243\n","Training loss per 100 training steps: 0.06560711282153808\n","Training loss per 100 training steps: 0.06389890509562339\n","Training loss per 100 training steps: 0.06356103838646335\n","Training loss per 100 training steps: 0.0628862315858598\n","Training loss epoch: 0.06322170242213161\n","Training accuracy epoch: 0.9798098874423478\n","Validating model...\n","Validation Loss: 0.17063793997195634\n","Validation Accuracy: 0.9541857541627942\n","Training epoch: 3\n","Training loss per 100 training steps: 0.011811083182692528\n","Training loss per 100 training steps: 0.030239484030845584\n","Training loss per 100 training steps: 0.032867253664185976\n","Training loss per 100 training steps: 0.03381541608623925\n","Training loss per 100 training steps: 0.03509448966135659\n","Training loss per 100 training steps: 0.03724079620034551\n","Training loss per 100 training steps: 0.036677516051785035\n","Training loss epoch: 0.0365853485815476\n","Training accuracy epoch: 0.9886378485320523\n","Validating model...\n","Validation Loss: 0.2372709298143526\n","Validation Accuracy: 0.9490997460544945\n","Training epoch: 4\n","Training loss per 100 training steps: 0.030496247112751007\n","Training loss per 100 training steps: 0.02040253689980577\n","Training loss per 100 training steps: 0.021156518094864817\n","Training loss per 100 training steps: 0.021525919685129423\n","Training loss per 100 training steps: 0.02204298203073075\n","Training loss per 100 training steps: 0.023501519472900585\n","Training loss per 100 training steps: 0.023914657860526354\n","Training loss epoch: 0.02397207203610856\n","Training accuracy epoch: 0.9923295397042015\n","Validating model...\n","Validation Loss: 0.25220832194794307\n","Validation Accuracy: 0.9476129309911726\n","Training epoch: 5\n","Training loss per 100 training steps: 0.014744266867637634\n","Training loss per 100 training steps: 0.017719280269195205\n","Training loss per 100 training steps: 0.019171069898881222\n","Training loss per 100 training steps: 0.019209456971368482\n","Training loss per 100 training steps: 0.019934669267206204\n","Training loss per 100 training steps: 0.019573344261280472\n","Training loss per 100 training steps: 0.019141696325112784\n","Training loss epoch: 0.01967245608352886\n","Training accuracy epoch: 0.9940202866552198\n","Validating model...\n","Validation Loss: 0.2477084533855706\n","Validation Accuracy: 0.9495166119676238\n","Training epoch: 6\n","Training loss per 100 training steps: 0.004015773069113493\n","Training loss per 100 training steps: 0.017982256124464628\n","Training loss per 100 training steps: 0.01728611870362442\n","Training loss per 100 training steps: 0.01740490546981043\n","Training loss per 100 training steps: 0.016573281176089243\n","Training loss per 100 training steps: 0.017328062427554098\n","Training loss per 100 training steps: 0.017175025423202653\n","Training loss epoch: 0.01699354309974397\n","Training accuracy epoch: 0.994869026232428\n","Validating model...\n","Validation Loss: 0.2839501814602257\n","Validation Accuracy: 0.943990416133564\n","Training epoch: 7\n","Training loss per 100 training steps: 0.002681547775864601\n","Training loss per 100 training steps: 0.012072941420039642\n","Training loss per 100 training steps: 0.014179453960056904\n","Training loss per 100 training steps: 0.014690148534502314\n","Training loss per 100 training steps: 0.015063480037279623\n","Training loss per 100 training steps: 0.01588029230730106\n","Training loss per 100 training steps: 0.015800181114499903\n","Training loss epoch: 0.016598754345790587\n","Training accuracy epoch: 0.9951867905472306\n","Validating model...\n","Validation Loss: 0.2841718019312852\n","Validation Accuracy: 0.9462854168212071\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 87.38044103333353 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.18771882355644334\n","Validation Accuracy: 0.9503719272491921\n","Validation duration: 6.313092299999941 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 81.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.76      0.82      0.79     12546\n","        test       0.83      0.87      0.85      9012\n","   treatment       0.81      0.83      0.82      9297\n","\n","   micro avg       0.80      0.84      0.82     30855\n","   macro avg       0.80      0.84      0.82     30855\n","weighted avg       0.80      0.84      0.82     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 20802\n","Points in y_train after augmentation: 20802\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7277283668518066\n","Training loss per 100 training steps: 0.39957777993513804\n","Training loss per 100 training steps: 0.29982113908624175\n","Training loss per 100 training steps: 0.25077747648885085\n","Training loss per 100 training steps: 0.22393098158617863\n","Training loss per 100 training steps: 0.20426299077962448\n","Training loss per 100 training steps: 0.18906742364738427\n","Training loss epoch: 0.1821337375609625\n","Training accuracy epoch: 0.9428400981208589\n","Validating model...\n","Validation Loss: 0.18784223917823334\n","Validation Accuracy: 0.9460051264648484\n","Training epoch: 2\n","Training loss per 100 training steps: 0.03608588129281998\n","Training loss per 100 training steps: 0.06720361113548279\n","Training loss per 100 training steps: 0.06728198269928866\n","Training loss per 100 training steps: 0.06637071354927315\n","Training loss per 100 training steps: 0.06437227548915252\n","Training loss per 100 training steps: 0.062349034839508655\n","Training loss per 100 training steps: 0.06206203982568719\n","Training loss epoch: 0.06170448491860542\n","Training accuracy epoch: 0.9804333618612494\n","Validating model...\n","Validation Loss: 0.18970285827753605\n","Validation Accuracy: 0.9514174286833484\n","Training epoch: 3\n","Training loss per 100 training steps: 0.08708585798740387\n","Training loss per 100 training steps: 0.04006282513785997\n","Training loss per 100 training steps: 0.040196607175482374\n","Training loss per 100 training steps: 0.04228559830164122\n","Training loss per 100 training steps: 0.04049005885399469\n","Training loss per 100 training steps: 0.04009949154835826\n","Training loss per 100 training steps: 0.03923708187476631\n","Training loss epoch: 0.03867375057014692\n","Training accuracy epoch: 0.9878625160746692\n","Validating model...\n","Validation Loss: 0.23728332631652813\n","Validation Accuracy: 0.9473656122658518\n","Training epoch: 4\n","Training loss per 100 training steps: 0.07996414601802826\n","Training loss per 100 training steps: 0.031046908558576856\n","Training loss per 100 training steps: 0.027852241417267984\n","Training loss per 100 training steps: 0.0267805288208531\n","Training loss per 100 training steps: 0.025460327053709684\n","Training loss per 100 training steps: 0.026303182890036417\n","Training loss per 100 training steps: 0.02611910820258363\n","Training loss epoch: 0.02633559721405439\n","Training accuracy epoch: 0.9919985116663128\n","Validating model...\n","Validation Loss: 0.20676606250080196\n","Validation Accuracy: 0.9531731696672744\n","Training epoch: 5\n","Training loss per 100 training steps: 0.031139392405748367\n","Training loss per 100 training steps: 0.016027210713110605\n","Training loss per 100 training steps: 0.01780321725078891\n","Training loss per 100 training steps: 0.01984399876540273\n","Training loss per 100 training steps: 0.020952704404376243\n","Training loss per 100 training steps: 0.02097417936279734\n","Training loss per 100 training steps: 0.020683450832673984\n","Training loss epoch: 0.020548433061212033\n","Training accuracy epoch: 0.993726007011527\n","Validating model...\n","Validation Loss: 0.22929293944352222\n","Validation Accuracy: 0.9533256127106003\n","Training epoch: 6\n","Training loss per 100 training steps: 0.019431766122579575\n","Training loss per 100 training steps: 0.01285167588243759\n","Training loss per 100 training steps: 0.013758603544252465\n","Training loss per 100 training steps: 0.017127591497195185\n","Training loss per 100 training steps: 0.017364723768368007\n","Training loss per 100 training steps: 0.018522918113438085\n","Training loss per 100 training steps: 0.018367359653338418\n","Training loss epoch: 0.018394314578964174\n","Training accuracy epoch: 0.9943365061563798\n","Validating model...\n","Validation Loss: 0.24637508692292423\n","Validation Accuracy: 0.9492661446550071\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 74.93588558333335 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1902610746932354\n","Validation Accuracy: 0.9469107890705614\n","Validation duration: 6.30972663333329 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 81.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.80      0.80     12546\n","        test       0.82      0.83      0.83      9012\n","   treatment       0.85      0.80      0.82      9297\n","\n","   micro avg       0.82      0.81      0.81     30855\n","   macro avg       0.82      0.81      0.82     30855\n","weighted avg       0.82      0.81      0.81     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 20802\n","Points in y_train after augmentation: 20802\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9375016689300537\n","Training loss per 100 training steps: 0.4004032602994749\n","Training loss per 100 training steps: 0.3028165345538908\n","Training loss per 100 training steps: 0.25735581880342523\n","Training loss per 100 training steps: 0.22790404760332178\n","Training loss per 100 training steps: 0.20763446807400315\n","Training loss per 100 training steps: 0.19134873854532566\n","Training loss epoch: 0.18441041848964176\n","Training accuracy epoch: 0.9420776410003168\n","Validating model...\n","Validation Loss: 0.1716650736506109\n","Validation Accuracy: 0.9470597063992641\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07578926533460617\n","Training loss per 100 training steps: 0.06362956046301982\n","Training loss per 100 training steps: 0.06684425695386914\n","Training loss per 100 training steps: 0.06522378999201513\n","Training loss per 100 training steps: 0.06335816020842762\n","Training loss per 100 training steps: 0.06499477076862832\n","Training loss per 100 training steps: 0.06437685731534974\n","Training loss epoch: 0.06329839268199293\n","Training accuracy epoch: 0.9805372162768828\n","Validating model...\n","Validation Loss: 0.1971595489069239\n","Validation Accuracy: 0.9510719955928386\n","Training epoch: 3\n","Training loss per 100 training steps: 0.022042129188776016\n","Training loss per 100 training steps: 0.03370919307039147\n","Training loss per 100 training steps: 0.03253458968748278\n","Training loss per 100 training steps: 0.03631315284263206\n","Training loss per 100 training steps: 0.03651581860224059\n","Training loss per 100 training steps: 0.03727006625213071\n","Training loss per 100 training steps: 0.03715225052593676\n","Training loss epoch: 0.0365121637287456\n","Training accuracy epoch: 0.988694239207675\n","Validating model...\n","Validation Loss: 0.2110692628405311\n","Validation Accuracy: 0.9503957303660038\n","Training epoch: 4\n","Training loss per 100 training steps: 0.016080763190984726\n","Training loss per 100 training steps: 0.02740834018280084\n","Training loss per 100 training steps: 0.03002032798087104\n","Training loss per 100 training steps: 0.029151361045022296\n","Training loss per 100 training steps: 0.029560341563033977\n","Training loss per 100 training steps: 0.02789712362567673\n","Training loss per 100 training steps: 0.027123954693729465\n","Training loss epoch: 0.027002742011157276\n","Training accuracy epoch: 0.9919827182520885\n","Validating model...\n","Validation Loss: 0.2486109050450387\n","Validation Accuracy: 0.9458611738953494\n","Training epoch: 5\n","Training loss per 100 training steps: 0.04655475541949272\n","Training loss per 100 training steps: 0.017740515302198175\n","Training loss per 100 training steps: 0.018352533548732116\n","Training loss per 100 training steps: 0.01866471768605161\n","Training loss per 100 training steps: 0.018475457528046333\n","Training loss per 100 training steps: 0.02032681537151686\n","Training loss per 100 training steps: 0.021252835511513513\n","Training loss epoch: 0.022928982943056092\n","Training accuracy epoch: 0.9929858681346364\n","Validating model...\n","Validation Loss: 0.25147769904949446\n","Validation Accuracy: 0.9462886004294636\n","Training epoch: 6\n","Training loss per 100 training steps: 0.03048343025147915\n","Training loss per 100 training steps: 0.031997937513146515\n","Training loss per 100 training steps: 0.025698379601296315\n","Training loss per 100 training steps: 0.023174368135516602\n","Training loss per 100 training steps: 0.021579893663417584\n","Training loss per 100 training steps: 0.020483768712336516\n","Training loss per 100 training steps: 0.019751378383339086\n","Training loss epoch: 0.01945436868109181\n","Training accuracy epoch: 0.9942158790092561\n","Validating model...\n","Validation Loss: 0.27592618403012875\n","Validation Accuracy: 0.9476750778636645\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 74.76727463333349 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.17564805710464027\n","Validation Accuracy: 0.9475471164495873\n","Validation duration: 6.286843133333362 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.76      0.85      0.80     12546\n","        test       0.83      0.88      0.85      9012\n","   treatment       0.83      0.82      0.82      9297\n","\n","   micro avg       0.80      0.85      0.82     30855\n","   macro avg       0.80      0.85      0.83     30855\n","weighted avg       0.80      0.85      0.82     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 20802\n","Points in y_train after augmentation: 20802\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.047513484954834\n","Training loss per 100 training steps: 0.39221923554887866\n","Training loss per 100 training steps: 0.292054897442979\n","Training loss per 100 training steps: 0.24852159203485\n","Training loss per 100 training steps: 0.22469804918119438\n","Training loss per 100 training steps: 0.20656308639578952\n","Training loss per 100 training steps: 0.19065391708060034\n","Training loss epoch: 0.18339647256845062\n","Training accuracy epoch: 0.9417101602148863\n","Validating model...\n","Validation Loss: 0.1892281702489822\n","Validation Accuracy: 0.944305225241557\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07362883538007736\n","Training loss per 100 training steps: 0.06170530678095794\n","Training loss per 100 training steps: 0.0647084045070988\n","Training loss per 100 training steps: 0.06487637399339993\n","Training loss per 100 training steps: 0.06322653213297563\n","Training loss per 100 training steps: 0.0634818269393431\n","Training loss per 100 training steps: 0.06425813275130586\n","Training loss epoch: 0.0634393978974111\n","Training accuracy epoch: 0.9796903085620058\n","Validating model...\n","Validation Loss: 0.17445635614166785\n","Validation Accuracy: 0.9520672713752029\n","Training epoch: 3\n","Training loss per 100 training steps: 0.005677695386111736\n","Training loss per 100 training steps: 0.03400398921313705\n","Training loss per 100 training steps: 0.03796211413492388\n","Training loss per 100 training steps: 0.03812428307178062\n","Training loss per 100 training steps: 0.03749944981387317\n","Training loss per 100 training steps: 0.03644911290825848\n","Training loss per 100 training steps: 0.037301919229534734\n","Training loss epoch: 0.03657670781265722\n","Training accuracy epoch: 0.988766494806419\n","Validating model...\n","Validation Loss: 0.25236568776527785\n","Validation Accuracy: 0.9471220424643046\n","Training epoch: 4\n","Training loss per 100 training steps: 0.05480414628982544\n","Training loss per 100 training steps: 0.01900691273714425\n","Training loss per 100 training steps: 0.021471730651176392\n","Training loss per 100 training steps: 0.021996870225425378\n","Training loss per 100 training steps: 0.022530578170610393\n","Training loss per 100 training steps: 0.02289717784360564\n","Training loss per 100 training steps: 0.02340355674490587\n","Training loss epoch: 0.023431040837140482\n","Training accuracy epoch: 0.9932115415266801\n","Validating model...\n","Validation Loss: 0.2512128625379561\n","Validation Accuracy: 0.9475134110932463\n","Training epoch: 5\n","Training loss per 100 training steps: 0.01598511077463627\n","Training loss per 100 training steps: 0.017613238513257613\n","Training loss per 100 training steps: 0.017589639854937125\n","Training loss per 100 training steps: 0.017655874627829526\n","Training loss per 100 training steps: 0.020845224615331608\n","Training loss per 100 training steps: 0.02168736867864566\n","Training loss per 100 training steps: 0.021123295326886882\n","Training loss epoch: 0.02207372444722953\n","Training accuracy epoch: 0.9932128365728454\n","Validating model...\n","Validation Loss: 0.2315835663202134\n","Validation Accuracy: 0.9498475574770755\n","Training epoch: 6\n","Training loss per 100 training steps: 0.026173949241638184\n","Training loss per 100 training steps: 0.023477399401311383\n","Training loss per 100 training steps: 0.024674884099235284\n","Training loss per 100 training steps: 0.02250765324910589\n","Training loss per 100 training steps: 0.020558091122053212\n","Training loss per 100 training steps: 0.01896751772411569\n","Training loss per 100 training steps: 0.01842914203828055\n","Training loss epoch: 0.018492475119380056\n","Training accuracy epoch: 0.9946696110828359\n","Validating model...\n","Validation Loss: 0.26249700719369695\n","Validation Accuracy: 0.942767297847782\n","Training epoch: 7\n","Training loss per 100 training steps: 0.009161563590168953\n","Training loss per 100 training steps: 0.01021874694661975\n","Training loss per 100 training steps: 0.012627326406999515\n","Training loss per 100 training steps: 0.01365749551684509\n","Training loss per 100 training steps: 0.01366570777708445\n","Training loss per 100 training steps: 0.01426951126648023\n","Training loss per 100 training steps: 0.014531677409427545\n","Training loss epoch: 0.014779099934538948\n","Training accuracy epoch: 0.9957068561416943\n","Validating model...\n","Validation Loss: 0.2798590474314504\n","Validation Accuracy: 0.9484800907032765\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 87.24733935000016 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.18748318944104808\n","Validation Accuracy: 0.949539522815076\n","Validation duration: 6.31237703333342 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.82      0.82     12546\n","        test       0.83      0.83      0.83      9012\n","   treatment       0.80      0.85      0.82      9297\n","\n","   micro avg       0.82      0.83      0.82     30855\n","   macro avg       0.82      0.83      0.83     30855\n","weighted avg       0.82      0.83      0.82     30855\n","\n","!!!!!! Starting model number 7 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 20802\n","Points in y_train after augmentation: 20802\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0644195079803467\n","Training loss per 100 training steps: 0.40613940313901054\n","Training loss per 100 training steps: 0.30444237927150963\n","Training loss per 100 training steps: 0.26244495198922696\n","Training loss per 100 training steps: 0.2330055421826771\n","Training loss per 100 training steps: 0.2091287235225627\n","Training loss per 100 training steps: 0.1926256872422237\n","Training loss epoch: 0.18757690804310934\n","Training accuracy epoch: 0.9401711147403582\n","Validating model...\n","Validation Loss: 0.15786343290434254\n","Validation Accuracy: 0.9501705341427978\n","Training epoch: 2\n","Training loss per 100 training steps: 0.061133358627557755\n","Training loss per 100 training steps: 0.06932884054535096\n","Training loss per 100 training steps: 0.07101002739584861\n","Training loss per 100 training steps: 0.06895422516235976\n","Training loss per 100 training steps: 0.0684154586880433\n","Training loss per 100 training steps: 0.0676955195318558\n","Training loss per 100 training steps: 0.06670425698229308\n","Training loss epoch: 0.06539663007574445\n","Training accuracy epoch: 0.9794079401427582\n","Validating model...\n","Validation Loss: 0.18513542563690769\n","Validation Accuracy: 0.9508144873138762\n","Training epoch: 3\n","Training loss per 100 training steps: 0.029790585860610008\n","Training loss per 100 training steps: 0.0368063849290962\n","Training loss per 100 training steps: 0.039600656706079915\n","Training loss per 100 training steps: 0.041035572483832404\n","Training loss per 100 training steps: 0.04123793695960426\n","Training loss per 100 training steps: 0.04009916927333654\n","Training loss per 100 training steps: 0.03978023984250202\n","Training loss epoch: 0.03983199094033127\n","Training accuracy epoch: 0.9874170435234698\n","Validating model...\n","Validation Loss: 0.20147331741142582\n","Validation Accuracy: 0.9466853026296471\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0038556810468435287\n","Training loss per 100 training steps: 0.019697922669203564\n","Training loss per 100 training steps: 0.0206649068914428\n","Training loss per 100 training steps: 0.021570200749914288\n","Training loss per 100 training steps: 0.023797011384659183\n","Training loss per 100 training steps: 0.024963962327095933\n","Training loss per 100 training steps: 0.024839351114277694\n","Training loss epoch: 0.02465902928841628\n","Training accuracy epoch: 0.9924240926458207\n","Validating model...\n","Validation Loss: 0.236996112802586\n","Validation Accuracy: 0.9508376115941427\n","Training epoch: 5\n","Training loss per 100 training steps: 0.021989498287439346\n","Training loss per 100 training steps: 0.02153174191111662\n","Training loss per 100 training steps: 0.02450535604145276\n","Training loss per 100 training steps: 0.02356374400580438\n","Training loss per 100 training steps: 0.02407210576609288\n","Training loss per 100 training steps: 0.023752663258515196\n","Training loss per 100 training steps: 0.02467691311872287\n","Training loss epoch: 0.02433065805114239\n","Training accuracy epoch: 0.9926501516780735\n","Validating model...\n","Validation Loss: 0.24455159187109765\n","Validation Accuracy: 0.9494873101519736\n","Training epoch: 6\n","Training loss per 100 training steps: 0.004238932393491268\n","Training loss per 100 training steps: 0.015204504769097201\n","Training loss per 100 training steps: 0.012798806721059633\n","Training loss per 100 training steps: 0.01381581303148385\n","Training loss per 100 training steps: 0.015687401093800374\n","Training loss per 100 training steps: 0.01682344469392371\n","Training loss per 100 training steps: 0.01628071567998229\n","Training loss epoch: 0.016678915666480665\n","Training accuracy epoch: 0.9948293208118316\n","Validating model...\n","Validation Loss: 0.2617863057689233\n","Validation Accuracy: 0.9478189434929872\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 74.9798768166666 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16996409644640084\n","Validation Accuracy: 0.9484896441038189\n","Validation duration: 6.302973750000092 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 81.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.80      0.80     12546\n","        test       0.81      0.85      0.83      9012\n","   treatment       0.81      0.84      0.83      9297\n","\n","   micro avg       0.81      0.83      0.82     30855\n","   macro avg       0.81      0.83      0.82     30855\n","weighted avg       0.81      0.83      0.82     30855\n","\n","!!!!!! Starting model number 8 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 20802\n","Points in y_train after augmentation: 20802\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.2069144248962402\n","Training loss per 100 training steps: 0.43294666914066465\n","Training loss per 100 training steps: 0.3173521499135601\n","Training loss per 100 training steps: 0.2654596281259559\n","Training loss per 100 training steps: 0.23619100856513453\n","Training loss per 100 training steps: 0.21280150895495853\n","Training loss per 100 training steps: 0.1972862427958137\n","Training loss epoch: 0.18994832407116616\n","Training accuracy epoch: 0.9400391620022106\n","Validating model...\n","Validation Loss: 0.16569297729277765\n","Validation Accuracy: 0.9500448577013404\n","Training epoch: 2\n","Training loss per 100 training steps: 0.12587477266788483\n","Training loss per 100 training steps: 0.07086652982057912\n","Training loss per 100 training steps: 0.06676075592247853\n","Training loss per 100 training steps: 0.06487306637497638\n","Training loss per 100 training steps: 0.06431453053995112\n","Training loss per 100 training steps: 0.06365225005880028\n","Training loss per 100 training steps: 0.0624881061956212\n","Training loss epoch: 0.061213465498490494\n","Training accuracy epoch: 0.980842009008486\n","Validating model...\n","Validation Loss: 0.18880304812707685\n","Validation Accuracy: 0.9541220349773949\n","Training epoch: 3\n","Training loss per 100 training steps: 0.007015972398221493\n","Training loss per 100 training steps: 0.03476974776586388\n","Training loss per 100 training steps: 0.034180274307357136\n","Training loss per 100 training steps: 0.034107941790697385\n","Training loss per 100 training steps: 0.03496129067900342\n","Training loss per 100 training steps: 0.03696909604432385\n","Training loss per 100 training steps: 0.037741732645699265\n","Training loss epoch: 0.037297340607950674\n","Training accuracy epoch: 0.9882776689346364\n","Validating model...\n","Validation Loss: 0.22227552746023452\n","Validation Accuracy: 0.9497871411979036\n","Training epoch: 4\n","Training loss per 100 training steps: 0.010098962113261223\n","Training loss per 100 training steps: 0.025753930521700164\n","Training loss per 100 training steps: 0.0245890734785014\n","Training loss per 100 training steps: 0.024272244398681714\n","Training loss per 100 training steps: 0.025538198148078072\n","Training loss per 100 training steps: 0.026399260872120814\n","Training loss per 100 training steps: 0.02752119570998816\n","Training loss epoch: 0.028445315232644208\n","Training accuracy epoch: 0.9912869840723585\n","Validating model...\n","Validation Loss: 0.28132428802162796\n","Validation Accuracy: 0.9405761615788111\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0029150438494980335\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 2\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"Zjhn7-LqHri0"},{"cell_type":"code","source":["number_of_training_models = 3\n","target_augmented_percentage = 2\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["49ec2d57f62a4c91b303a8f0b9551cba","99b8d053c53c404ba33767a9a346873c","7ccfd36eb1764ffba583c7245996937a","75b9dd62824142d882d31584f46d2e38","66df70642ff04877838fc5d776f45422","9bdfcf7256dc47629f657fb59464eea3","5d8a864a612d478bb6263ae2c7ac16c5","8bf24c1d1bf947c98f8b454350002b73","a65042ddb2ef418d89ef4cafb4e51204","8b392968a97946c9925d001668d9be3c","3a551be1ced0468ba62ce2787969925e"]},"id":"U92MdkHWT89D","executionInfo":{"status":"ok","timestamp":1667727402083,"user_tz":240,"elapsed":16357695,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"}},"outputId":"bc351fcf-e031-4103-f6c2-fa57aba39c6c"},"id":"U92MdkHWT89D","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["!!!!!! Augmented Percentage 200% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49ec2d57f62a4c91b303a8f0b9551cba"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 20802\n","Points in y_train after augmentation: 20802\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.869899868965149\n","Training loss per 100 training steps: 0.43082260200292755\n","Training loss per 100 training steps: 0.3138652157353525\n","Training loss per 100 training steps: 0.2648707631220453\n","Training loss per 100 training steps: 0.23434951825257846\n","Training loss per 100 training steps: 0.21234654731855182\n","Training loss per 100 training steps: 0.19540555770516693\n","Training loss epoch: 0.1879309939417971\n","Training accuracy epoch: 0.9401845938609064\n","Validating model...\n","Validation Loss: 0.18164658914138745\n","Validation Accuracy: 0.9443506541577285\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09451775252819061\n","Training loss per 100 training steps: 0.06378033483345615\n","Training loss per 100 training steps: 0.06442047173704081\n","Training loss per 100 training steps: 0.06460411831167251\n","Training loss per 100 training steps: 0.0634810408934988\n","Training loss per 100 training steps: 0.06222607524779267\n","Training loss per 100 training steps: 0.06222030262117229\n","Training loss epoch: 0.061505192313336135\n","Training accuracy epoch: 0.9804216445280786\n","Validating model...\n","Validation Loss: 0.19389232639949044\n","Validation Accuracy: 0.949863763541405\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03471946716308594\n","Training loss per 100 training steps: 0.027456981270564812\n","Training loss per 100 training steps: 0.030155499620984\n","Training loss per 100 training steps: 0.03248754801132726\n","Training loss per 100 training steps: 0.03433136356689101\n","Training loss per 100 training steps: 0.035729650754487134\n","Training loss per 100 training steps: 0.03599691938801813\n","Training loss epoch: 0.036163648722955126\n","Training accuracy epoch: 0.9886053676290077\n","Validating model...\n","Validation Loss: 0.21129783131665997\n","Validation Accuracy: 0.9495126995394649\n","Training epoch: 4\n","Training loss per 100 training steps: 0.015916049480438232\n","Training loss per 100 training steps: 0.028662396322862053\n","Training loss per 100 training steps: 0.030148552117906326\n","Training loss per 100 training steps: 0.029448641040223184\n","Training loss per 100 training steps: 0.0281265247947051\n","Training loss per 100 training steps: 0.027548681093800903\n","Training loss per 100 training steps: 0.02722236570178108\n","Training loss epoch: 0.026634758310346004\n","Training accuracy epoch: 0.9916316918943501\n","Validating model...\n","Validation Loss: 0.23624591676929554\n","Validation Accuracy: 0.9491846962461101\n","Training epoch: 5\n","Training loss per 100 training steps: 0.01069787610322237\n","Training loss per 100 training steps: 0.01737645005641302\n","Training loss per 100 training steps: 0.01613079619189071\n","Training loss per 100 training steps: 0.017076993683094708\n","Training loss per 100 training steps: 0.017610397067488848\n","Training loss per 100 training steps: 0.017529758082739006\n","Training loss per 100 training steps: 0.017359437675199034\n","Training loss epoch: 0.01721980417012802\n","Training accuracy epoch: 0.9949084906159958\n","Validating model...\n","Validation Loss: 0.25047221160554267\n","Validation Accuracy: 0.9505003948902202\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00902196578681469\n","Training loss per 100 training steps: 0.015172657495454451\n","Training loss per 100 training steps: 0.01575188855139599\n","Training loss per 100 training steps: 0.015561417553614844\n","Training loss per 100 training steps: 0.016803519625609806\n","Training loss per 100 training steps: 0.01787353035192909\n","Training loss per 100 training steps: 0.01936904538970808\n","Training loss epoch: 0.019113058530156515\n","Training accuracy epoch: 0.9941472011627212\n","Validating model...\n","Validation Loss: 0.23501218436890609\n","Validation Accuracy: 0.9524994323267951\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 74.91923255 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.18650848201165596\n","Validation Accuracy: 0.9450569983933422\n","Validation duration: 6.277784899999991 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 79.8%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.81      0.80     12546\n","        test       0.76      0.82      0.79      9012\n","   treatment       0.77      0.85      0.81      9297\n","\n","   micro avg       0.78      0.82      0.80     30855\n","   macro avg       0.77      0.82      0.80     30855\n","weighted avg       0.78      0.82      0.80     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 20802\n","Points in y_train after augmentation: 20802\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9102853536605835\n","Training loss per 100 training steps: 0.4364148241901162\n","Training loss per 100 training steps: 0.32768844438726036\n","Training loss per 100 training steps: 0.27404567114142486\n","Training loss per 100 training steps: 0.23910241035693452\n","Training loss per 100 training steps: 0.21569210269717043\n","Training loss per 100 training steps: 0.19866871612825232\n","Training loss epoch: 0.19136745847540604\n","Training accuracy epoch: 0.9395900334092593\n","Validating model...\n","Validation Loss: 0.16845273178119163\n","Validation Accuracy: 0.9477175524073617\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0347144715487957\n","Training loss per 100 training steps: 0.06987013501843603\n","Training loss per 100 training steps: 0.06910010907261525\n","Training loss per 100 training steps: 0.0684594864805424\n","Training loss per 100 training steps: 0.06836043753222262\n","Training loss per 100 training steps: 0.06794700750285489\n","Training loss per 100 training steps: 0.06678157129143666\n","Training loss epoch: 0.06582925590999802\n","Training accuracy epoch: 0.9788659583232063\n","Validating model...\n","Validation Loss: 0.1860796922890397\n","Validation Accuracy: 0.9526030177213461\n","Training epoch: 3\n","Training loss per 100 training steps: 0.011462219059467316\n","Training loss per 100 training steps: 0.0342317700736446\n","Training loss per 100 training steps: 0.035629569716167764\n","Training loss per 100 training steps: 0.03738671942286045\n","Training loss per 100 training steps: 0.03677596123203951\n","Training loss per 100 training steps: 0.03611791365735322\n","Training loss per 100 training steps: 0.03658864073363906\n","Training loss epoch: 0.036820538308737535\n","Training accuracy epoch: 0.9886429055589293\n","Validating model...\n","Validation Loss: 0.20667742657196986\n","Validation Accuracy: 0.951604202229604\n","Training epoch: 4\n","Training loss per 100 training steps: 0.10488016903400421\n","Training loss per 100 training steps: 0.024940090739205112\n","Training loss per 100 training steps: 0.02462215022072752\n","Training loss per 100 training steps: 0.025101260910974043\n","Training loss per 100 training steps: 0.026566813103018557\n","Training loss per 100 training steps: 0.028280510131210208\n","Training loss per 100 training steps: 0.027961895093143594\n","Training loss epoch: 0.02820919060556736\n","Training accuracy epoch: 0.9914422633650715\n","Validating model...\n","Validation Loss: 0.22660730130873719\n","Validation Accuracy: 0.9484521472207142\n","Training epoch: 5\n","Training loss per 100 training steps: 0.001769338734447956\n","Training loss per 100 training steps: 0.018047605420458177\n","Training loss per 100 training steps: 0.016579657827216706\n","Training loss per 100 training steps: 0.01705985671053161\n","Training loss per 100 training steps: 0.01840125276600278\n","Training loss per 100 training steps: 0.018199135767093335\n","Training loss per 100 training steps: 0.018607652927640387\n","Training loss epoch: 0.018649230480835003\n","Training accuracy epoch: 0.9945307271040477\n","Validating model...\n","Validation Loss: 0.2262664632871747\n","Validation Accuracy: 0.9518152482671789\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0020866142585873604\n","Training loss per 100 training steps: 0.01100984396266585\n","Training loss per 100 training steps: 0.013096500920631056\n","Training loss per 100 training steps: 0.014729769797079061\n","Training loss per 100 training steps: 0.016056554131714994\n","Training loss per 100 training steps: 0.016940288903389663\n","Training loss per 100 training steps: 0.017318898041774448\n","Training loss epoch: 0.017160903476956535\n","Training accuracy epoch: 0.9950503085787193\n","Validating model...\n","Validation Loss: 0.2732048813592304\n","Validation Accuracy: 0.9448073919422011\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 75.01541139999999 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.1627393786825619\n","Validation Accuracy: 0.9492455321085179\n","Validation duration: 6.285209383333343 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 81.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.77      0.86      0.81     12546\n","        test       0.80      0.88      0.84      9012\n","   treatment       0.79      0.82      0.80      9297\n","\n","   micro avg       0.78      0.85      0.82     30855\n","   macro avg       0.78      0.85      0.82     30855\n","weighted avg       0.78      0.85      0.82     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 20802\n","Points in y_train after augmentation: 20802\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9952595233917236\n","Training loss per 100 training steps: 0.4312101040441211\n","Training loss per 100 training steps: 0.3205084251378899\n","Training loss per 100 training steps: 0.27048189848958454\n","Training loss per 100 training steps: 0.23786033013663685\n","Training loss per 100 training steps: 0.21595473797199968\n","Training loss per 100 training steps: 0.1979072412379867\n","Training loss epoch: 0.19073936588684534\n","Training accuracy epoch: 0.9385888192830218\n","Validating model...\n","Validation Loss: 0.18506857931807444\n","Validation Accuracy: 0.9470598281932484\n","Training epoch: 2\n","Training loss per 100 training steps: 0.036794696003198624\n","Training loss per 100 training steps: 0.0738244914809371\n","Training loss per 100 training steps: 0.07155337041494117\n","Training loss per 100 training steps: 0.07269833950431046\n","Training loss per 100 training steps: 0.07078553345100838\n","Training loss per 100 training steps: 0.0692407686947408\n","Training loss per 100 training steps: 0.06942668048658729\n","Training loss epoch: 0.06953074903995086\n","Training accuracy epoch: 0.9778727404318994\n","Validating model...\n","Validation Loss: 0.18722800770169729\n","Validation Accuracy: 0.9490108940267068\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03283664956688881\n","Training loss per 100 training steps: 0.035400656725067904\n","Training loss per 100 training steps: 0.035227532173038936\n","Training loss per 100 training steps: 0.03635387827156489\n","Training loss per 100 training steps: 0.03743333524636497\n","Training loss per 100 training steps: 0.03919775199290075\n","Training loss per 100 training steps: 0.03912097071072772\n","Training loss epoch: 0.03924259364410209\n","Training accuracy epoch: 0.9875840165409612\n","Validating model...\n","Validation Loss: 0.21676144081276733\n","Validation Accuracy: 0.9485106910352555\n","Training epoch: 4\n","Training loss per 100 training steps: 0.019775886088609695\n","Training loss per 100 training steps: 0.02416361800030722\n","Training loss per 100 training steps: 0.02233184635377401\n","Training loss per 100 training steps: 0.02313818298110064\n","Training loss per 100 training steps: 0.024087092887663614\n","Training loss per 100 training steps: 0.025905005756752593\n","Training loss per 100 training steps: 0.02788762332245509\n","Training loss epoch: 0.02830833328519261\n","Training accuracy epoch: 0.9909812719145513\n","Validating model...\n","Validation Loss: 0.21774312960250036\n","Validation Accuracy: 0.9495691691243748\n","Training epoch: 5\n","Training loss per 100 training steps: 0.004368693567812443\n","Training loss per 100 training steps: 0.020939669910689244\n","Training loss per 100 training steps: 0.024039614714556998\n","Training loss per 100 training steps: 0.025874046797932208\n","Training loss per 100 training steps: 0.025664840659133607\n","Training loss per 100 training steps: 0.025881413149855613\n","Training loss per 100 training steps: 0.025006404350327326\n","Training loss epoch: 0.024765408658150714\n","Training accuracy epoch: 0.9920855194089201\n","Validating model...\n","Validation Loss: 0.2594865723089738\n","Validation Accuracy: 0.945634322782618\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0018800048856064677\n","Training loss per 100 training steps: 0.010752050912625497\n","Training loss per 100 training steps: 0.013155574782488553\n","Training loss per 100 training steps: 0.015612997911677872\n","Training loss per 100 training steps: 0.015047519555082545\n","Training loss per 100 training steps: 0.014923859303461634\n","Training loss per 100 training steps: 0.015215532653087583\n","Training loss epoch: 0.01524023487170573\n","Training accuracy epoch: 0.9955976400641158\n","Validating model...\n","Validation Loss: 0.25067441596032736\n","Validation Accuracy: 0.9486010549958072\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 75.12071766666662 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.20755626581160835\n","Validation Accuracy: 0.9418344416547021\n","Validation duration: 6.2846805333333275 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 79.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.81      0.81     12546\n","        test       0.84      0.82      0.83      9012\n","   treatment       0.66      0.89      0.76      9297\n","\n","   micro avg       0.76      0.84      0.80     30855\n","   macro avg       0.77      0.84      0.80     30855\n","weighted avg       0.77      0.84      0.80     30855\n","\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TTDq-xbgHqXQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b5bbbf33-e504-4f55-90dd-ea2d114fb5a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["!!!!!! Augmented Percentage 500% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 41604\n","Points in y_train after augmentation: 41604\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.093999147415161\n","Training loss per 100 training steps: 0.43001670154309507\n","Training loss per 100 training steps: 0.30998956743831657\n","Training loss per 100 training steps: 0.26148459762087295\n","Training loss per 100 training steps: 0.23052601361103783\n","Training loss per 100 training steps: 0.20829346533604487\n","Training loss per 100 training steps: 0.19234807293446807\n","Training loss per 100 training steps: 0.17951129731880275\n","Training loss per 100 training steps: 0.16895509822138313\n","Training loss per 100 training steps: 0.15855675612624887\n","Training loss per 100 training steps: 0.1510213919581248\n","Training loss per 100 training steps: 0.14395713685274963\n","Training loss per 100 training steps: 0.1386986037516202\n","Training loss per 100 training steps: 0.13323764744387234\n","Training loss epoch: 0.13323764744387234\n","Training accuracy epoch: 0.9573588889381001\n","Validating model...\n","Validation Loss: 0.18826381378359608\n","Validation Accuracy: 0.9469718073667927\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04287195950746536\n","Training loss per 100 training steps: 0.051227649922786965\n","Training loss per 100 training steps: 0.04704136455626185\n","Training loss per 100 training steps: 0.043714598938203925\n","Training loss per 100 training steps: 0.04329466971422446\n","Training loss per 100 training steps: 0.042163229287655916\n","Training loss per 100 training steps: 0.043169575108032356\n","Training loss per 100 training steps: 0.044285236335041986\n","Training loss per 100 training steps: 0.04434414078584976\n","Training loss per 100 training steps: 0.04451190038391913\n","Training loss per 100 training steps: 0.04416283912939037\n","Training loss per 100 training steps: 0.04334535501596199\n","Training loss per 100 training steps: 0.04306869470994364\n","Training loss per 100 training steps: 0.042163327385168196\n","Training loss epoch: 0.042163327385168196\n","Training accuracy epoch: 0.9867087114422117\n","Validating model...\n","Validation Loss: 0.2751079295072463\n","Validation Accuracy: 0.9374844039406176\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03500958904623985\n","Training loss per 100 training steps: 0.022433685606788142\n","Training loss per 100 training steps: 0.023904222653036593\n","Training loss per 100 training steps: 0.022243907649814154\n","Training loss per 100 training steps: 0.02211344880609311\n","Training loss per 100 training steps: 0.022286766873274796\n","Training loss per 100 training steps: 0.022251180815161788\n","Training loss per 100 training steps: 0.022769850861087185\n","Training loss per 100 training steps: 0.023167435318021134\n","Training loss per 100 training steps: 0.02313572888355082\n","Training loss per 100 training steps: 0.024083615345466363\n","Training loss per 100 training steps: 0.024135988068531736\n","Training loss per 100 training steps: 0.02429621212824568\n","Training loss per 100 training steps: 0.024111261354010555\n","Training loss epoch: 0.024111261354010555\n","Training accuracy epoch: 0.9924930541142745\n","Validating model...\n","Validation Loss: 0.22935505259733696\n","Validation Accuracy: 0.9479605451631292\n","Training epoch: 4\n","Training loss per 100 training steps: 0.022612985223531723\n","Training loss per 100 training steps: 0.015811368965977193\n","Training loss per 100 training steps: 0.018846537798541178\n","Training loss per 100 training steps: 0.018280785029368828\n","Training loss per 100 training steps: 0.01751296627123322\n","Training loss per 100 training steps: 0.01659069059369249\n","Training loss per 100 training steps: 0.01711664452539453\n","Training loss per 100 training steps: 0.018217253969459477\n","Training loss per 100 training steps: 0.018602390888265652\n","Training loss per 100 training steps: 0.018878859539514202\n","Training loss per 100 training steps: 0.018951629305183498\n","Training loss per 100 training steps: 0.01894148676022828\n","Training loss per 100 training steps: 0.018611333532587274\n","Training loss per 100 training steps: 0.018359047545516947\n","Training loss epoch: 0.018359047545516947\n","Training accuracy epoch: 0.9942547181050343\n","Validating model...\n","Validation Loss: 0.29346435188086\n","Validation Accuracy: 0.9416236477205359\n","Training epoch: 5\n","Training loss per 100 training steps: 0.012792161665856838\n","Training loss per 100 training steps: 0.01179454915598957\n","Training loss per 100 training steps: 0.013808935860389686\n","Training loss per 100 training steps: 0.01331225831790261\n","Training loss per 100 training steps: 0.013531337447604977\n","Training loss per 100 training steps: 0.01282745540551488\n","Training loss per 100 training steps: 0.01322946247260029\n","Training loss per 100 training steps: 0.013438378607760584\n","Training loss per 100 training steps: 0.013734416136173381\n","Training loss per 100 training steps: 0.014212756613827622\n","Training loss per 100 training steps: 0.014713108558828788\n","Training loss per 100 training steps: 0.014483792547319045\n","Training loss per 100 training steps: 0.014772738932765095\n","Training loss per 100 training steps: 0.014888819739395941\n","Training loss epoch: 0.014888819739395941\n","Training accuracy epoch: 0.9955324935378465\n","Validating model...\n","Validation Loss: 0.2975676261469141\n","Validation Accuracy: 0.9405013702965153\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0029156852979213\n","Training loss per 100 training steps: 0.012597182824963353\n","Training loss per 100 training steps: 0.011115533213446204\n","Training loss per 100 training steps: 0.009890648718839016\n","Training loss per 100 training steps: 0.010403981445346462\n","Training loss per 100 training steps: 0.010965122380313656\n","Training loss per 100 training steps: 0.0118724283070128\n","Training loss per 100 training steps: 0.012156119555501119\n","Training loss per 100 training steps: 0.012134349309706615\n","Training loss per 100 training steps: 0.012068387382896617\n","Training loss per 100 training steps: 0.013555455196619296\n","Training loss per 100 training steps: 0.013614749105176259\n","Training loss per 100 training steps: 0.013691750569890394\n","Training loss per 100 training steps: 0.013748040068294205\n","Training loss epoch: 0.013748040068294205\n","Training accuracy epoch: 0.9961027036594354\n","Validating model...\n","Validation Loss: 0.3029042814749402\n","Validation Accuracy: 0.9453392665885516\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 147.24964708333337 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.1984209552163655\n","Validation Accuracy: 0.9466721931187186\n","Validation duration: 6.2737145166667085 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 81.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.81      0.81     12546\n","        test       0.80      0.87      0.83      9012\n","   treatment       0.76      0.84      0.80      9297\n","\n","   micro avg       0.79      0.84      0.81     30855\n","   macro avg       0.79      0.84      0.81     30855\n","weighted avg       0.79      0.84      0.81     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 41604\n","Points in y_train after augmentation: 41604\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9395867586135864\n","Training loss per 100 training steps: 0.40906692355281055\n","Training loss per 100 training steps: 0.29663619235973454\n","Training loss per 100 training steps: 0.25111981040714587\n","Training loss per 100 training steps: 0.2258386056489332\n","Training loss per 100 training steps: 0.2049629849729364\n","Training loss per 100 training steps: 0.18912204201278987\n","Training loss per 100 training steps: 0.17652213433159572\n","Training loss per 100 training steps: 0.165947782989596\n","Training loss per 100 training steps: 0.1569483265297262\n","Training loss per 100 training steps: 0.14980281936330395\n","Training loss per 100 training steps: 0.143888851186154\n","Training loss per 100 training steps: 0.13899934060831276\n","Training loss per 100 training steps: 0.1337291544731377\n","Training loss epoch: 0.1337291544731377\n","Training accuracy epoch: 0.9575034643654652\n","Validating model...\n","Validation Loss: 0.19511015480988986\n","Validation Accuracy: 0.947054491616886\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07226499170064926\n","Training loss per 100 training steps: 0.04858914045340354\n","Training loss per 100 training steps: 0.04768452044710776\n","Training loss per 100 training steps: 0.04511150182998334\n","Training loss per 100 training steps: 0.045345477138569304\n","Training loss per 100 training steps: 0.04534912253906597\n","Training loss per 100 training steps: 0.04532554308874548\n","Training loss per 100 training steps: 0.04484136813697531\n","Training loss per 100 training steps: 0.04494935865967433\n","Training loss per 100 training steps: 0.0445235431688909\n","Training loss per 100 training steps: 0.04433773197703525\n","Training loss per 100 training steps: 0.04388802763659145\n","Training loss per 100 training steps: 0.04428818418728118\n","Training loss per 100 training steps: 0.04435899113408712\n","Training loss epoch: 0.04435899113408712\n","Training accuracy epoch: 0.9864974313326106\n","Validating model...\n","Validation Loss: 0.2504422153019673\n","Validation Accuracy: 0.9444949842232273\n","Training epoch: 3\n","Training loss per 100 training steps: 0.09408807009458542\n","Training loss per 100 training steps: 0.025264285375723745\n","Training loss per 100 training steps: 0.024705551129149562\n","Training loss per 100 training steps: 0.0240735949815384\n","Training loss per 100 training steps: 0.024722420369528066\n","Training loss per 100 training steps: 0.02519849562104754\n","Training loss per 100 training steps: 0.02585864823583526\n","Training loss per 100 training steps: 0.02560033657177539\n","Training loss per 100 training steps: 0.026190121838946208\n","Training loss per 100 training steps: 0.026305506216748705\n","Training loss per 100 training steps: 0.025788547815527064\n","Training loss per 100 training steps: 0.025776558187172716\n","Training loss per 100 training steps: 0.026314837058779662\n","Training loss per 100 training steps: 0.026596310085865407\n","Training loss epoch: 0.026596310085865407\n","Training accuracy epoch: 0.9921286067104319\n","Validating model...\n","Validation Loss: 0.2416321828042145\n","Validation Accuracy: 0.9474302210786523\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03823740407824516\n","Training loss per 100 training steps: 0.014094731054098189\n","Training loss per 100 training steps: 0.015827645528285455\n","Training loss per 100 training steps: 0.01842135830377801\n","Training loss per 100 training steps: 0.018795608017974513\n","Training loss per 100 training steps: 0.01865860143713114\n","Training loss per 100 training steps: 0.018780644574631068\n","Training loss per 100 training steps: 0.018812482317548562\n","Training loss per 100 training steps: 0.019099068038926265\n","Training loss per 100 training steps: 0.01924068575170533\n","Training loss per 100 training steps: 0.019238829106395062\n","Training loss per 100 training steps: 0.019209113611750258\n","Training loss per 100 training steps: 0.01918221559336461\n","Stopping epoch...\n","Training loss epoch: 0.01918221559336461\n","Training accuracy epoch: 0.9933013038064674\n","Validating model...\n","Validation Loss: 0.33479957125306903\n","Validation Accuracy: 0.9359629510112052\n","Training epoch: 5\n","Training loss per 100 training steps: 0.02753513678908348\n","Training loss per 100 training steps: 0.012866639947382696\n","Training loss per 100 training steps: 0.012911733544682991\n","Training loss per 100 training steps: 0.012997670155703137\n","Training loss per 100 training steps: 0.014460526996317141\n","Training loss per 100 training steps: 0.015184043075165762\n","Training loss per 100 training steps: 0.01506671261679832\n","Training loss per 100 training steps: 0.015458235139417171\n","Training loss per 100 training steps: 0.01555610848966429\n","Training loss per 100 training steps: 0.016070209621390035\n","Training loss per 100 training steps: 0.01619540090408324\n","Training loss per 100 training steps: 0.016069286473635307\n","Training loss per 100 training steps: 0.01594018976560904\n","Training loss per 100 training steps: 0.016051680581649724\n","Training loss epoch: 0.016051680581649724\n","Training accuracy epoch: 0.9952069423985642\n","Validating model...\n","Validation Loss: 0.27007280509652837\n","Validation Accuracy: 0.9441238964581117\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0016535192262381315\n","Training loss per 100 training steps: 0.009676039730380797\n","Training loss per 100 training steps: 0.011407017612549482\n","Training loss per 100 training steps: 0.011218433139818268\n","Training loss per 100 training steps: 0.011322490271638692\n","Training loss per 100 training steps: 0.011425192010397938\n","Training loss per 100 training steps: 0.011972319979339563\n","Training loss per 100 training steps: 0.012343345797347029\n","Training loss per 100 training steps: 0.013014073049377524\n","Training loss per 100 training steps: 0.013006059373267662\n","Training loss per 100 training steps: 0.013248703152464179\n","Training loss per 100 training steps: 0.013476762109411565\n","Training loss per 100 training steps: 0.013135559700782659\n","Training loss per 100 training steps: 0.012952315183402039\n","Training loss epoch: 0.012952315183402039\n","Training accuracy epoch: 0.9961563048121769\n","Validating model...\n","Validation Loss: 0.29153134102945205\n","Validation Accuracy: 0.9475284331735432\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 145.13335908333332 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.20140627481871182\n","Validation Accuracy: 0.9463286655236\n","Validation duration: 6.255656033333313 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 80.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.82      0.81     12546\n","        test       0.76      0.85      0.80      9012\n","   treatment       0.80      0.81      0.81      9297\n","\n","   micro avg       0.79      0.82      0.81     30855\n","   macro avg       0.79      0.83      0.81     30855\n","weighted avg       0.79      0.82      0.81     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 41604\n","Points in y_train after augmentation: 41604\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.099130630493164\n","Training loss per 100 training steps: 0.43181646032498616\n","Training loss per 100 training steps: 0.3099910328489038\n","Training loss per 100 training steps: 0.2608990721107519\n","Training loss per 100 training steps: 0.23173103155452118\n","Training loss per 100 training steps: 0.21088722984338115\n","Training loss per 100 training steps: 0.19565054062388204\n","Training loss per 100 training steps: 0.1832732810757087\n","Training loss per 100 training steps: 0.171987219656656\n","Training loss per 100 training steps: 0.1624113182918676\n","Training loss per 100 training steps: 0.15485566177895735\n","Training loss per 100 training steps: 0.14846491894188196\n","Training loss per 100 training steps: 0.14207568338496004\n","Training loss per 100 training steps: 0.13682597744665886\n","Training loss epoch: 0.13682597744665886\n","Training accuracy epoch: 0.9565620839166994\n","Validating model...\n","Validation Loss: 0.1769139018248428\n","Validation Accuracy: 0.949898721319433\n","Training epoch: 2\n","Training loss per 100 training steps: 0.009626026265323162\n","Training loss per 100 training steps: 0.05100793210734235\n","Training loss per 100 training steps: 0.05029306625623015\n","Training loss per 100 training steps: 0.04969224749841539\n","Training loss per 100 training steps: 0.04922058786720762\n","Training loss per 100 training steps: 0.04729375214605944\n","Training loss per 100 training steps: 0.04691570450802847\n","Training loss per 100 training steps: 0.04671096401827173\n","Training loss per 100 training steps: 0.04571812448194123\n","Training loss per 100 training steps: 0.04536934052004823\n","Training loss per 100 training steps: 0.04461849866631244\n","Training loss per 100 training steps: 0.04421689092447232\n","Training loss per 100 training steps: 0.044142170177503555\n","Training loss per 100 training steps: 0.043819778662108365\n","Training loss epoch: 0.043819778662108365\n","Training accuracy epoch: 0.9863871767244363\n","Validating model...\n","Validation Loss: 0.23046699362238507\n","Validation Accuracy: 0.9471339878380639\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03624200075864792\n","Training loss per 100 training steps: 0.028850380901828187\n","Training loss per 100 training steps: 0.026728182508081975\n","Training loss per 100 training steps: 0.02502564816933707\n","Training loss per 100 training steps: 0.02466066393442684\n","Training loss per 100 training steps: 0.025073411901892273\n","Training loss per 100 training steps: 0.025116618935943903\n","Training loss per 100 training steps: 0.025138996744272\n","Training loss per 100 training steps: 0.024811428454477855\n","Training loss per 100 training steps: 0.02465398359209605\n","Training loss per 100 training steps: 0.02513643761439208\n","Training loss per 100 training steps: 0.025586331032521493\n","Training loss per 100 training steps: 0.02621652026507394\n","Training loss per 100 training steps: 0.026758373762453356\n","Training loss epoch: 0.026758373762453356\n","Training accuracy epoch: 0.9917395477044149\n","Validating model...\n","Validation Loss: 0.27094078499388385\n","Validation Accuracy: 0.9391566933570314\n","Training epoch: 4\n","Training loss per 100 training steps: 0.024244485422968864\n","Training loss per 100 training steps: 0.02177037701983521\n","Training loss per 100 training steps: 0.01867445439823662\n","Training loss per 100 training steps: 0.01834394861535986\n","Training loss per 100 training steps: 0.01796597859915404\n","Training loss per 100 training steps: 0.01735914923129148\n","Training loss per 100 training steps: 0.017612511736308668\n","Training loss per 100 training steps: 0.018417735835386192\n","Training loss per 100 training steps: 0.019555077851046813\n","Training loss per 100 training steps: 0.019677051883592703\n","Training loss per 100 training steps: 0.019804351323022072\n","Training loss per 100 training steps: 0.01980311201068955\n","Training loss per 100 training steps: 0.01947414667210751\n","Training loss per 100 training steps: 0.019300105884419053\n","Training loss epoch: 0.019300105884419053\n","Training accuracy epoch: 0.9942560061885299\n","Validating model...\n","Validation Loss: 0.2793739613314921\n","Validation Accuracy: 0.9460628299491182\n","Training epoch: 5\n","Training loss per 100 training steps: 0.006752230226993561\n","Training loss per 100 training steps: 0.010650372020277831\n","Training loss per 100 training steps: 0.012323288756813067\n","Training loss per 100 training steps: 0.012417820073815799\n","Training loss per 100 training steps: 0.015124495923310109\n","Training loss per 100 training steps: 0.016926801486494773\n","Training loss per 100 training steps: 0.017570466131956692\n","Training loss per 100 training steps: 0.01800052112191929\n","Training loss per 100 training steps: 0.017527333047190397\n","Training loss per 100 training steps: 0.017010353772165036\n","Training loss per 100 training steps: 0.016363820305170182\n","Training loss per 100 training steps: 0.016366786959674758\n","Training loss per 100 training steps: 0.016515084233436055\n","Training loss per 100 training steps: 0.01625303654687604\n","Training loss epoch: 0.01625303654687604\n","Training accuracy epoch: 0.9952337523699404\n","Validating model...\n","Validation Loss: 0.3054887537735623\n","Validation Accuracy: 0.9422987145100555\n","Training epoch: 6\n","Training loss per 100 training steps: 0.029894515872001648\n","Training loss per 100 training steps: 0.009342786005645124\n","Training loss per 100 training steps: 0.010462767421890546\n","Training loss per 100 training steps: 0.011770830589431288\n","Training loss per 100 training steps: 0.012564817247057318\n","Training loss per 100 training steps: 0.012601979064343622\n","Training loss per 100 training steps: 0.012705476277079953\n","Training loss per 100 training steps: 0.013109091053718998\n","Training loss per 100 training steps: 0.013375995119305626\n","Training loss per 100 training steps: 0.013280546199036148\n","Training loss per 100 training steps: 0.013470715111256791\n","Training loss per 100 training steps: 0.013255443530674047\n","Training loss per 100 training steps: 0.013306310887692371\n","Training loss per 100 training steps: 0.013701614237508663\n","Training loss epoch: 0.013701614237508663\n","Training accuracy epoch: 0.9958666515510013\n","Validating model...\n","Validation Loss: 0.3354803818677153\n","Validation Accuracy: 0.9374471780535477\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 146.64686366666658 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.19021593346001786\n","Validation Accuracy: 0.9460600835212861\n","Validation duration: 6.258349049999864 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 81.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.79      0.79     12546\n","        test       0.82      0.84      0.83      9012\n","   treatment       0.80      0.83      0.82      9297\n","\n","   micro avg       0.81      0.81      0.81     30855\n","   macro avg       0.81      0.82      0.81     30855\n","weighted avg       0.81      0.81      0.81     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 41604\n","Points in y_train after augmentation: 41604\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9844661951065063\n","Training loss per 100 training steps: 0.4305063703715211\n","Training loss per 100 training steps: 0.3123343151007126\n","Training loss per 100 training steps: 0.26549718280220747\n","Training loss per 100 training steps: 0.23461163113650835\n","Training loss per 100 training steps: 0.21423582347507725\n","Training loss per 100 training steps: 0.19790513065648258\n","Training loss per 100 training steps: 0.18263940746695356\n","Training loss per 100 training steps: 0.17153831304966027\n","Training loss per 100 training steps: 0.162591737552394\n","Training loss per 100 training steps: 0.1554357737375351\n","Training loss per 100 training steps: 0.1483805142486845\n","Training loss per 100 training steps: 0.14250728107219582\n","Training loss per 100 training steps: 0.13719846342449046\n","Training loss epoch: 0.13719846342449046\n","Training accuracy epoch: 0.9561803122167438\n","Validating model...\n","Validation Loss: 0.17596997939921044\n","Validation Accuracy: 0.950826450491901\n","Training epoch: 2\n","Training loss per 100 training steps: 0.027237912639975548\n","Training loss per 100 training steps: 0.04635655449813988\n","Training loss per 100 training steps: 0.04488402764678965\n","Training loss per 100 training steps: 0.046871249760467054\n","Training loss per 100 training steps: 0.04634087639361471\n","Training loss per 100 training steps: 0.04529545245972832\n","Training loss per 100 training steps: 0.046028942483773275\n","Training loss per 100 training steps: 0.046429734657480036\n","Training loss per 100 training steps: 0.04583145620867601\n","Training loss per 100 training steps: 0.04495812641388502\n","Training loss per 100 training steps: 0.04430921575739295\n","Training loss per 100 training steps: 0.04386915620602498\n","Training loss per 100 training steps: 0.04441389979792295\n","Training loss per 100 training steps: 0.04471907543242522\n","Training loss epoch: 0.04471907543242522\n","Training accuracy epoch: 0.9857607940140964\n","Validating model...\n","Validation Loss: 0.23322920075484685\n","Validation Accuracy: 0.9485987749191002\n","Training epoch: 3\n","Training loss per 100 training steps: 0.027492797002196312\n","Training loss per 100 training steps: 0.02308171656383847\n","Training loss per 100 training steps: 0.022982564243946724\n","Training loss per 100 training steps: 0.023260101682948956\n","Training loss per 100 training steps: 0.023872715785943827\n","Training loss per 100 training steps: 0.02387394179741549\n","Training loss per 100 training steps: 0.02384904873669349\n","Training loss per 100 training steps: 0.023736715697654828\n","Training loss per 100 training steps: 0.02428346516172949\n","Training loss per 100 training steps: 0.026069016436739752\n","Training loss per 100 training steps: 0.026091970144489596\n","Training loss per 100 training steps: 0.02616291507319602\n","Training loss per 100 training steps: 0.02619842023339214\n","Training loss per 100 training steps: 0.025843787036523545\n","Training loss epoch: 0.025843787036523545\n","Training accuracy epoch: 0.9920196832612741\n","Validating model...\n","Validation Loss: 0.2700302663573681\n","Validation Accuracy: 0.9454577788527025\n","Training epoch: 4\n","Training loss per 100 training steps: 0.005079891998320818\n","Training loss per 100 training steps: 0.016080425878166046\n","Training loss per 100 training steps: 0.014515818784184828\n","Training loss per 100 training steps: 0.015903576092130854\n","Training loss per 100 training steps: 0.016322879625052942\n","Training loss per 100 training steps: 0.016330233778855195\n","Training loss per 100 training steps: 0.015953770597179045\n","Training loss per 100 training steps: 0.01709544351210681\n","Training loss per 100 training steps: 0.01771722492986747\n","Training loss per 100 training steps: 0.01786405466518005\n","Training loss per 100 training steps: 0.017704443624944423\n","Training loss per 100 training steps: 0.01819908335631215\n","Training loss per 100 training steps: 0.018076330271099176\n","Training loss per 100 training steps: 0.01803303513424754\n","Training loss epoch: 0.01803303513424754\n","Training accuracy epoch: 0.9944986754913141\n","Validating model...\n","Validation Loss: 0.3498536589761059\n","Validation Accuracy: 0.940173110387059\n","Training epoch: 5\n","Training loss per 100 training steps: 0.019054748117923737\n","Training loss per 100 training steps: 0.022022038478044664\n","Training loss per 100 training steps: 0.018382363862923315\n","Training loss per 100 training steps: 0.016824604291314153\n","Training loss per 100 training steps: 0.020954890630412337\n","Training loss per 100 training steps: 0.020851963743817956\n","Training loss per 100 training steps: 0.021123787848007308\n","Training loss per 100 training steps: 0.02185168560539019\n","Training loss per 100 training steps: 0.021119634937935367\n","Training loss per 100 training steps: 0.0206247121507504\n","Training loss per 100 training steps: 0.020251366889019812\n","Training loss per 100 training steps: 0.019712839009910426\n","Training loss per 100 training steps: 0.01954151366120123\n","Training loss per 100 training steps: 0.019123359112254507\n","Training loss epoch: 0.019123359112254507\n","Training accuracy epoch: 0.9942903105314106\n","Validating model...\n","Validation Loss: 0.256112081155955\n","Validation Accuracy: 0.945178340461175\n","Training epoch: 6\n","Training loss per 100 training steps: 0.04069104045629501\n","Training loss per 100 training steps: 0.011107974158113564\n","Training loss per 100 training steps: 0.010787500237376518\n","Training loss per 100 training steps: 0.010855681372122249\n","Training loss per 100 training steps: 0.011259877364877833\n","Training loss per 100 training steps: 0.0116685438633849\n","Training loss per 100 training steps: 0.012614734672440352\n","Training loss per 100 training steps: 0.012652079842510712\n","Training loss per 100 training steps: 0.013102073126784863\n","Training loss per 100 training steps: 0.013239743797055944\n","Training loss per 100 training steps: 0.012959223697131214\n","Training loss per 100 training steps: 0.012729490933454804\n","Training loss per 100 training steps: 0.012570269561793286\n","Training loss per 100 training steps: 0.01290573367967242\n","Training loss epoch: 0.01290573367967242\n","Training accuracy epoch: 0.9961335982506532\n","Validating model...\n","Validation Loss: 0.29484397559971004\n","Validation Accuracy: 0.9443395913908154\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 146.97461131666665 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.1847674246458121\n","Validation Accuracy: 0.9494233534614201\n","Validation duration: 6.260829016666685 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 82.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.84      0.82     12546\n","        test       0.86      0.82      0.84      9012\n","   treatment       0.80      0.83      0.81      9297\n","\n","   micro avg       0.82      0.83      0.82     30855\n","   macro avg       0.82      0.83      0.82     30855\n","weighted avg       0.82      0.83      0.82     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 41604\n","Points in y_train after augmentation: 41604\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9635775089263916\n","Training loss per 100 training steps: 0.41256819178562354\n","Training loss per 100 training steps: 0.3031918766783245\n","Training loss per 100 training steps: 0.2557381409471019\n","Training loss per 100 training steps: 0.22812177401565553\n","Training loss per 100 training steps: 0.2094071618097271\n","Training loss per 100 training steps: 0.19308332539629966\n","Training loss per 100 training steps: 0.1792678433628527\n","Training loss per 100 training steps: 0.1676585308640042\n","Training loss per 100 training steps: 0.15940649349544275\n","Training loss per 100 training steps: 0.15151380533194328\n","Training loss per 100 training steps: 0.14526070763004248\n","Training loss per 100 training steps: 0.13975822645938218\n","Training loss per 100 training steps: 0.13376679141532563\n","Training loss epoch: 0.13376679141532563\n","Training accuracy epoch: 0.9570895154258939\n","Validating model...\n","Validation Loss: 0.219940668383202\n","Validation Accuracy: 0.9419152434769393\n","Training epoch: 2\n","Training loss per 100 training steps: 0.025379706174135208\n","Training loss per 100 training steps: 0.04796355751592039\n","Training loss per 100 training steps: 0.04794341350780494\n","Training loss per 100 training steps: 0.04747113140231846\n","Training loss per 100 training steps: 0.04663277481638471\n","Training loss per 100 training steps: 0.04565345628852557\n","Training loss per 100 training steps: 0.04497129345752807\n","Training loss per 100 training steps: 0.044746030745801975\n","Training loss per 100 training steps: 0.044712229758575465\n","Training loss per 100 training steps: 0.04416485759119537\n","Training loss per 100 training steps: 0.04328081252022677\n","Training loss per 100 training steps: 0.0424550157414663\n","Training loss per 100 training steps: 0.042071864866557764\n","Training loss per 100 training steps: 0.04191319467716397\n","Training loss epoch: 0.04191319467716397\n","Training accuracy epoch: 0.9866633514120993\n","Validating model...\n","Validation Loss: 0.23410240195498064\n","Validation Accuracy: 0.9396955921320679\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0032034243922680616\n","Training loss per 100 training steps: 0.02340978122832678\n","Training loss per 100 training steps: 0.024516780778478405\n","Training loss per 100 training steps: 0.024256384119691568\n","Training loss per 100 training steps: 0.02371300243774889\n","Training loss per 100 training steps: 0.0235946155847989\n","Training loss per 100 training steps: 0.024205167493674466\n","Training loss per 100 training steps: 0.023794839703780168\n","Training loss per 100 training steps: 0.024789506477796788\n","Training loss per 100 training steps: 0.025495927320890434\n","Training loss per 100 training steps: 0.025761330384992762\n","Training loss per 100 training steps: 0.02572911772100876\n","Training loss per 100 training steps: 0.025328966012910056\n","Training loss per 100 training steps: 0.025289399358680145\n","Training loss epoch: 0.025289399358680145\n","Training accuracy epoch: 0.9921075817248667\n","Validating model...\n","Validation Loss: 0.25642986963321635\n","Validation Accuracy: 0.9430739462843365\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03424203023314476\n","Training loss per 100 training steps: 0.018085848371207823\n","Training loss per 100 training steps: 0.017517790575227954\n","Training loss per 100 training steps: 0.01921322142720405\n","Training loss per 100 training steps: 0.018210026580637712\n","Training loss per 100 training steps: 0.01813497743284666\n","Training loss per 100 training steps: 0.01828671169900971\n","Training loss per 100 training steps: 0.017720825878294457\n","Training loss per 100 training steps: 0.01797876995148866\n","Training loss per 100 training steps: 0.01858448974218258\n","Training loss per 100 training steps: 0.018482473187785193\n","Training loss per 100 training steps: 0.019197304090566393\n","Training loss per 100 training steps: 0.018999933499313053\n","Training loss per 100 training steps: 0.018825000803215218\n","Training loss epoch: 0.018825000803215218\n","Training accuracy epoch: 0.994310685680191\n","Validating model...\n","Validation Loss: 0.27043276908807456\n","Validation Accuracy: 0.943978067353222\n","Training epoch: 5\n","Training loss per 100 training steps: 0.010610326193273067\n","Training loss per 100 training steps: 0.014483831590041518\n","Training loss per 100 training steps: 0.014129708504271856\n","Training loss per 100 training steps: 0.013190401060331884\n","Training loss per 100 training steps: 0.012913997523196882\n","Training loss per 100 training steps: 0.01379041300040666\n","Training loss per 100 training steps: 0.014678461729167664\n","Training loss per 100 training steps: 0.014853558818126807\n","Training loss per 100 training steps: 0.014498230269097068\n","Training loss per 100 training steps: 0.014958096789740093\n","Training loss per 100 training steps: 0.01494245359350901\n","Training loss per 100 training steps: 0.014860401957245715\n","Training loss per 100 training steps: 0.014966697700675088\n","Training loss per 100 training steps: 0.014798767194040921\n","Training loss epoch: 0.014798767194040921\n","Training accuracy epoch: 0.9954434830549322\n","Validating model...\n","Validation Loss: 0.33105061532228025\n","Validation Accuracy: 0.9420634281395752\n","Training epoch: 6\n","Training loss per 100 training steps: 0.028871795162558556\n","Training loss per 100 training steps: 0.012152577599390677\n","Training loss per 100 training steps: 0.010852949786685124\n","Training loss per 100 training steps: 0.010572047648242476\n","Training loss per 100 training steps: 0.010996433292935658\n","Training loss per 100 training steps: 0.012075430318194314\n","Training loss per 100 training steps: 0.01267087575434742\n","Training loss per 100 training steps: 0.013133313180990857\n","Training loss per 100 training steps: 0.01325076638096923\n","Training loss per 100 training steps: 0.013253000272300584\n","Training loss per 100 training steps: 0.01297167247696768\n","Training loss per 100 training steps: 0.012875701219951468\n","Training loss per 100 training steps: 0.012930239581266557\n","Training loss per 100 training steps: 0.013074651342637867\n","Training loss epoch: 0.013074651342637867\n","Training accuracy epoch: 0.9960829129324248\n","Validating model...\n","Validation Loss: 0.26259450880544527\n","Validation Accuracy: 0.9485410645432004\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 146.9322726666668 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.21634784393892106\n","Validation Accuracy: 0.9416476891311817\n","Validation duration: 6.251932516666662 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 78.9%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.75      0.77     12546\n","        test       0.79      0.84      0.81      9012\n","   treatment       0.80      0.78      0.79      9297\n","\n","   micro avg       0.79      0.79      0.79     30855\n","   macro avg       0.79      0.79      0.79     30855\n","weighted avg       0.79      0.79      0.79     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 41604\n","Points in y_train after augmentation: 41604\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1082839965820312\n","Training loss per 100 training steps: 0.39713174894009484\n","Training loss per 100 training steps: 0.3022524717064639\n","Training loss per 100 training steps: 0.25874433697408616\n","Training loss per 100 training steps: 0.22815087633648715\n","Training loss per 100 training steps: 0.20686007234195392\n","Training loss per 100 training steps: 0.19378249138011017\n","Training loss per 100 training steps: 0.1822576845588213\n","Training loss per 100 training steps: 0.17165599726884628\n","Training loss per 100 training steps: 0.16266818548222955\n","Training loss per 100 training steps: 0.15503606903036454\n","Training loss per 100 training steps: 0.14770446479537072\n","Training loss per 100 training steps: 0.1414494004261856\n","Training loss per 100 training steps: 0.13498514331519307\n","Training loss epoch: 0.13498514331519307\n","Training accuracy epoch: 0.9568640606584219\n","Validating model...\n","Validation Loss: 0.1983553323601433\n","Validation Accuracy: 0.9477393128517249\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0368017740547657\n","Training loss per 100 training steps: 0.047551547882543635\n","Training loss per 100 training steps: 0.04698623587558074\n","Training loss per 100 training steps: 0.0451963965617046\n","Training loss per 100 training steps: 0.04518824027145184\n","Training loss per 100 training steps: 0.044746352499072065\n","Training loss per 100 training steps: 0.04588566026797583\n","Training loss per 100 training steps: 0.04572433385381557\n","Training loss per 100 training steps: 0.046629028076238546\n","Training loss per 100 training steps: 0.046225397835705805\n","Training loss per 100 training steps: 0.04599504525560168\n","Training loss per 100 training steps: 0.04536504857178666\n","Training loss per 100 training steps: 0.04554313760918474\n","Training loss per 100 training steps: 0.04467022756893448\n","Training loss epoch: 0.04467022756893448\n","Training accuracy epoch: 0.9859579600212184\n","Validating model...\n","Validation Loss: 0.21365526797516005\n","Validation Accuracy: 0.950424308655647\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0027544281911104918\n","Training loss per 100 training steps: 0.022567906850340342\n","Training loss per 100 training steps: 0.022658061336341375\n","Training loss per 100 training steps: 0.02357340416139258\n","Training loss per 100 training steps: 0.024305371496480356\n","Training loss per 100 training steps: 0.025439479916929054\n","Training loss per 100 training steps: 0.025931502593031924\n","Training loss per 100 training steps: 0.027740158747646494\n","Training loss per 100 training steps: 0.027743754417201814\n","Training loss per 100 training steps: 0.02705132649264626\n","Training loss per 100 training steps: 0.026900848845188802\n","Training loss per 100 training steps: 0.02667288102137033\n","Training loss per 100 training steps: 0.026642975540382696\n","Training loss per 100 training steps: 0.026531863538781\n","Training loss epoch: 0.026531863538781\n","Training accuracy epoch: 0.9916776166659744\n","Validating model...\n","Validation Loss: 0.2393562605290057\n","Validation Accuracy: 0.9495079364086766\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0011575729586184025\n","Training loss per 100 training steps: 0.016384435467200704\n","Training loss per 100 training steps: 0.017342012840675294\n","Training loss per 100 training steps: 0.017587767849154955\n","Training loss per 100 training steps: 0.017506679195877017\n","Training loss per 100 training steps: 0.01753236798639502\n","Training loss per 100 training steps: 0.017232303960260837\n","Training loss per 100 training steps: 0.01789362768174452\n","Training loss per 100 training steps: 0.018088882594081875\n","Training loss per 100 training steps: 0.01782276880842495\n","Training loss per 100 training steps: 0.017797349748027453\n","Training loss per 100 training steps: 0.017828615886595085\n","Training loss per 100 training steps: 0.018248934140827292\n","Training loss per 100 training steps: 0.018333895174113726\n","Training loss epoch: 0.018333895174113726\n","Training accuracy epoch: 0.9943584477540081\n","Validating model...\n","Validation Loss: 0.2822473414919593\n","Validation Accuracy: 0.9440511081398102\n","Training epoch: 5\n","Training loss per 100 training steps: 0.02528422884643078\n","Training loss per 100 training steps: 0.019733923135814027\n","Training loss per 100 training steps: 0.016571053372411087\n","Training loss per 100 training steps: 0.016319038325814727\n","Training loss per 100 training steps: 0.01631856642039597\n","Training loss per 100 training steps: 0.015756901244327572\n","Training loss per 100 training steps: 0.015215554370840441\n","Training loss per 100 training steps: 0.014801410986755751\n","Training loss per 100 training steps: 0.014927780269427876\n","Training loss per 100 training steps: 0.014472057070102068\n","Training loss per 100 training steps: 0.014475094417182074\n","Training loss per 100 training steps: 0.01534285870120642\n","Training loss per 100 training steps: 0.015788393504249276\n","Training loss per 100 training steps: 0.015915471712773115\n","Training loss epoch: 0.015915471712773115\n","Training accuracy epoch: 0.9953070460592506\n","Validating model...\n","Validation Loss: 0.3237674269513771\n","Validation Accuracy: 0.938552840248544\n","Training epoch: 6\n","Training loss per 100 training steps: 0.002925070933997631\n","Training loss per 100 training steps: 0.013179547704945291\n","Training loss per 100 training steps: 0.013595269309224755\n","Training loss per 100 training steps: 0.013548633859352057\n","Training loss per 100 training steps: 0.014202882642082595\n","Training loss per 100 training steps: 0.014808463696841181\n","Training loss per 100 training steps: 0.015343110346329862\n","Training loss per 100 training steps: 0.015564419847596557\n","Training loss per 100 training steps: 0.016031525680663346\n","Training loss per 100 training steps: 0.015944309574311557\n","Training loss per 100 training steps: 0.01567440257449825\n","Training loss per 100 training steps: 0.015252520457714996\n","Training loss per 100 training steps: 0.014795527005846148\n","Training loss per 100 training steps: 0.014777638743199168\n","Training loss epoch: 0.014777638743199168\n","Training accuracy epoch: 0.9955146534141434\n","Validating model...\n","Validation Loss: 0.32209053533998405\n","Validation Accuracy: 0.9424614228548224\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 146.59262268333333 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.1979012539754708\n","Validation Accuracy: 0.9467677660171463\n","Validation duration: 6.24845505 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 81.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.78      0.83      0.81     12546\n","        test       0.79      0.85      0.82      9012\n","   treatment       0.80      0.82      0.81      9297\n","\n","   micro avg       0.79      0.83      0.81     30855\n","   macro avg       0.79      0.83      0.81     30855\n","weighted avg       0.79      0.83      0.81     30855\n","\n","!!!!!! Starting model number 7 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 41604\n","Points in y_train after augmentation: 41604\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.933673620223999\n","Training loss per 100 training steps: 0.4195947206699022\n","Training loss per 100 training steps: 0.30526091936808913\n","Training loss per 100 training steps: 0.2600890079209971\n","Training loss per 100 training steps: 0.2297236545759246\n","Training loss per 100 training steps: 0.21031993452809053\n","Training loss per 100 training steps: 0.19264104380466032\n","Training loss per 100 training steps: 0.1806693239889497\n","Training loss per 100 training steps: 0.17012963696765468\n","Training loss per 100 training steps: 0.16166761201639948\n","Training loss per 100 training steps: 0.15482472566576985\n","Training loss per 100 training steps: 0.14826527839995157\n","Training loss per 100 training steps: 0.14165459604907493\n","Training loss per 100 training steps: 0.13606128093788686\n","Training loss epoch: 0.13606128093788686\n","Training accuracy epoch: 0.9566632882736995\n","Validating model...\n","Validation Loss: 0.1786435203892844\n","Validation Accuracy: 0.9492016558069509\n","Training epoch: 2\n","Training loss per 100 training steps: 0.02833576872944832\n","Training loss per 100 training steps: 0.03600121812092712\n","Training loss per 100 training steps: 0.04244211531332254\n","Training loss per 100 training steps: 0.04246518291313313\n","Training loss per 100 training steps: 0.04323035476966169\n","Training loss per 100 training steps: 0.04436688157385903\n","Training loss per 100 training steps: 0.04435464379822405\n","Training loss per 100 training steps: 0.04413051683370678\n","Training loss per 100 training steps: 0.043580867439629356\n","Training loss per 100 training steps: 0.04284035853657057\n","Training loss per 100 training steps: 0.04192775156959281\n","Training loss per 100 training steps: 0.04193312570885785\n","Training loss per 100 training steps: 0.043206861197481634\n","Training loss per 100 training steps: 0.04351549104413019\n","Training loss epoch: 0.04351549104413019\n","Training accuracy epoch: 0.9863523006876205\n","Validating model...\n","Validation Loss: 0.26289984288734275\n","Validation Accuracy: 0.9407116812631925\n","Training epoch: 3\n","Training loss per 100 training steps: 0.06494510173797607\n","Training loss per 100 training steps: 0.03483393463296908\n","Training loss per 100 training steps: 0.03068603064971443\n","Training loss per 100 training steps: 0.02867988753983398\n","Training loss per 100 training steps: 0.027591572321679657\n","Training loss per 100 training steps: 0.02708847634587251\n","Training loss per 100 training steps: 0.028481430789771896\n","Training loss per 100 training steps: 0.02775758665291521\n","Training loss per 100 training steps: 0.027529441239951775\n","Training loss per 100 training steps: 0.027502291154666295\n","Training loss per 100 training steps: 0.027406143909483052\n","Training loss per 100 training steps: 0.026972519209715017\n","Training loss per 100 training steps: 0.026789972644014677\n","Training loss per 100 training steps: 0.026680304444603318\n","Training loss epoch: 0.026680304444603318\n","Training accuracy epoch: 0.9918100148138009\n","Validating model...\n","Validation Loss: 0.2453653204871656\n","Validation Accuracy: 0.9488428233346049\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03568866476416588\n","Training loss per 100 training steps: 0.017497997568449983\n","Training loss per 100 training steps: 0.017346464578219832\n","Training loss per 100 training steps: 0.01714668799198675\n","Training loss per 100 training steps: 0.017538397009728333\n","Training loss per 100 training steps: 0.017392859052836024\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 5\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"TTDq-xbgHqXQ"},{"cell_type":"code","source":["number_of_training_models = 4\n","target_augmented_percentage = 5\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a89fbd72e1864424aa761e5fa370917f","3f4e5f702aa34220a33cfdfb5c1914bd","186c6347e80f49eb82c029f00827a590","8164685dcd0041e9a8bfe776991176db","dd98998cdbc443c5bc4392ba94c9b6ac","27ee5825bd724e0cbba7572712adba17","ac486e8f74274767aaab09acf1e5643f","54aa8d7af81140efbd6d5249b5038b9a","4bfb38a75c1841ba8666a655ce61d9bd","cb9e39ec92e345829a91b88797323874","51d6116e342747f598d54549af79ebf3"]},"id":"LtcGfDRHek8V","executionInfo":{"status":"ok","timestamp":1667838658633,"user_tz":240,"elapsed":1399256,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"}},"outputId":"6c1774b5-7cae-4541-9f25-bdbbcdaacca3"},"id":"LtcGfDRHek8V","execution_count":8,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 500% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a89fbd72e1864424aa761e5fa370917f","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 41604\n","Points in y_train after augmentation: 41604\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8510037660598755\n","Training loss per 100 training steps: 0.40105220232859695\n","Training loss per 100 training steps: 0.2960859653146113\n","Training loss per 100 training steps: 0.25045813899796665\n","Training loss per 100 training steps: 0.22156482489031745\n","Training loss per 100 training steps: 0.20261049739451348\n","Training loss per 100 training steps: 0.18959058747439336\n","Training loss per 100 training steps: 0.17630846160842628\n","Training loss per 100 training steps: 0.16582726282689642\n","Training loss per 100 training steps: 0.1567530593184649\n","Training loss per 100 training steps: 0.14985399763495266\n","Training loss per 100 training steps: 0.1434457195714644\n","Training loss per 100 training steps: 0.13801463432982253\n","Training loss per 100 training steps: 0.13247605309471613\n","Training loss epoch: 0.13247605309471613\n","Training accuracy epoch: 0.9578939321155663\n","Validating model...\n","Validation Loss: 0.164857492225801\n","Validation Accuracy: 0.9489158575463376\n","Training epoch: 2\n","Training loss per 100 training steps: 0.03476288914680481\n","Training loss per 100 training steps: 0.04616578234046107\n","Training loss per 100 training steps: 0.04669124652997623\n","Training loss per 100 training steps: 0.0465416887920486\n","Training loss per 100 training steps: 0.04623582543912077\n","Training loss per 100 training steps: 0.044025722387323\n","Training loss per 100 training steps: 0.044750228876746984\n","Training loss per 100 training steps: 0.0441446953968606\n","Training loss per 100 training steps: 0.04439909928117863\n","Training loss per 100 training steps: 0.04440086199354161\n","Training loss per 100 training steps: 0.044121941706243825\n","Training loss per 100 training steps: 0.04364709946374281\n","Training loss per 100 training steps: 0.04365295557740247\n","Training loss per 100 training steps: 0.04332280648853644\n","Training loss epoch: 0.04332280648853644\n","Training accuracy epoch: 0.9867257944393879\n","Validating model...\n","Validation Loss: 0.22301277612614168\n","Validation Accuracy: 0.949584428194201\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03930937126278877\n","Training loss per 100 training steps: 0.024010038557739026\n","Training loss per 100 training steps: 0.02329111523493031\n","Training loss per 100 training steps: 0.02310801693006261\n","Training loss per 100 training steps: 0.023464715414264814\n","Training loss per 100 training steps: 0.02430289361055219\n","Training loss per 100 training steps: 0.02450837843436221\n","Training loss per 100 training steps: 0.024767907812810117\n","Training loss per 100 training steps: 0.024854596660207357\n","Training loss per 100 training steps: 0.024957801466916257\n","Training loss per 100 training steps: 0.025264226063108117\n","Training loss per 100 training steps: 0.025291110942145298\n","Training loss per 100 training steps: 0.025499151621520253\n","Training loss per 100 training steps: 0.025302219547228968\n","Training loss epoch: 0.025302219547228968\n","Training accuracy epoch: 0.9921873335389616\n","Validating model...\n","Validation Loss: 0.27134648575024173\n","Validation Accuracy: 0.9429448895166126\n","Training epoch: 4\n","Training loss per 100 training steps: 0.005231422372162342\n","Training loss per 100 training steps: 0.01906924076737965\n","Training loss per 100 training steps: 0.019838632909906565\n","Training loss per 100 training steps: 0.0195175823880293\n","Training loss per 100 training steps: 0.01884716668201348\n","Training loss per 100 training steps: 0.018949926134253278\n","Training loss per 100 training steps: 0.020032129865327614\n","Training loss per 100 training steps: 0.020076395485614268\n","Training loss per 100 training steps: 0.01958457585179291\n","Training loss per 100 training steps: 0.01961471535431218\n","Training loss per 100 training steps: 0.019270051612322647\n","Training loss per 100 training steps: 0.018952343267707752\n","Training loss per 100 training steps: 0.01871366663393448\n","Training loss per 100 training steps: 0.01841136112204376\n","Training loss epoch: 0.01841136112204376\n","Training accuracy epoch: 0.9943683736499981\n","Validating model...\n","Validation Loss: 0.3645629666552141\n","Validation Accuracy: 0.9386611908227664\n","Training epoch: 5\n","Training loss per 100 training steps: 0.009387078694999218\n","Training loss per 100 training steps: 0.01383184326932498\n","Training loss per 100 training steps: 0.01494502795157046\n","Training loss per 100 training steps: 0.01383070845777274\n","Training loss per 100 training steps: 0.013992062054282436\n","Training loss per 100 training steps: 0.01587551951931442\n","Training loss per 100 training steps: 0.016213070531443503\n","Training loss per 100 training steps: 0.016514537526789812\n","Training loss per 100 training steps: 0.016711841895006373\n","Training loss per 100 training steps: 0.018140379532459207\n","Training loss per 100 training steps: 0.018193750681403744\n","Training loss per 100 training steps: 0.018674566199512202\n","Training loss per 100 training steps: 0.018405082204912656\n","Training loss per 100 training steps: 0.018070269571601138\n","Training loss epoch: 0.018070269571601138\n","Training accuracy epoch: 0.9946159089231219\n","Validating model...\n","Validation Loss: 0.2887148181968308\n","Validation Accuracy: 0.939686885087619\n","Training epoch: 6\n","Training loss per 100 training steps: 0.006010339595377445\n","Training loss per 100 training steps: 0.008911247358260916\n","Training loss per 100 training steps: 0.009046893133474884\n","Training loss per 100 training steps: 0.010348635342879456\n","Training loss per 100 training steps: 0.011493830297486577\n","Training loss per 100 training steps: 0.011108115034942615\n","Training loss per 100 training steps: 0.011275297853704031\n","Training loss per 100 training steps: 0.011677324348069546\n","Training loss per 100 training steps: 0.012143747749851467\n","Training loss per 100 training steps: 0.012596673230727417\n","Training loss per 100 training steps: 0.012365590011539099\n","Training loss per 100 training steps: 0.012535162019607003\n","Training loss per 100 training steps: 0.012775476667961201\n","Training loss per 100 training steps: 0.012926482650288326\n","Training loss epoch: 0.012926482650288326\n","Training accuracy epoch: 0.9961732110588938\n","Validating model...\n","Validation Loss: 0.2698591790319263\n","Validation Accuracy: 0.942202389875035\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 140.70712258333333 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1814748883523323\n","Validation Accuracy: 0.9501957617041591\n","Validation duration: 5.904546349999994 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 82.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.82      0.81     12546\n","        test       0.83      0.86      0.84      9012\n","   treatment       0.82      0.85      0.83      9297\n","\n","   micro avg       0.81      0.84      0.83     30855\n","   macro avg       0.81      0.84      0.83     30855\n","weighted avg       0.81      0.84      0.83     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 41604\n","Points in y_train after augmentation: 41604\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.4678423404693604\n","Training loss per 100 training steps: 0.41656873050597637\n","Training loss per 100 training steps: 0.31469067801438755\n","Training loss per 100 training steps: 0.26074857467729784\n","Training loss per 100 training steps: 0.23154349372422606\n","Training loss per 100 training steps: 0.21088135858882448\n","Training loss per 100 training steps: 0.19412694102193473\n","Training loss per 100 training steps: 0.18184682055138657\n","Training loss per 100 training steps: 0.1704458739729447\n","Training loss per 100 training steps: 0.16136964656759908\n","Training loss per 100 training steps: 0.154179973873895\n","Training loss per 100 training steps: 0.14795803204415658\n","Training loss per 100 training steps: 0.14080462554782988\n","Training loss per 100 training steps: 0.13535232630613434\n","Training loss epoch: 0.13535232630613434\n","Training accuracy epoch: 0.9564781522089879\n","Validating model...\n","Validation Loss: 0.19763476740230213\n","Validation Accuracy: 0.9452599436955749\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04180566966533661\n","Training loss per 100 training steps: 0.049019079263515695\n","Training loss per 100 training steps: 0.044538635311101506\n","Training loss per 100 training steps: 0.0448385975308147\n","Training loss per 100 training steps: 0.04604973605813045\n","Training loss per 100 training steps: 0.04684132718185554\n","Training loss per 100 training steps: 0.04571497477567794\n","Training loss per 100 training steps: 0.04566485417798193\n","Training loss per 100 training steps: 0.04503501076733789\n","Training loss per 100 training steps: 0.045131455292123125\n","Training loss per 100 training steps: 0.04481295301633832\n","Training loss per 100 training steps: 0.04472548781926291\n","Training loss per 100 training steps: 0.044192128243633576\n","Training loss per 100 training steps: 0.04409018044377565\n","Training loss epoch: 0.04409018044377565\n","Training accuracy epoch: 0.9862292675578562\n","Validating model...\n","Validation Loss: 0.24495524627628265\n","Validation Accuracy: 0.9412054811530702\n","Training epoch: 3\n","Training loss per 100 training steps: 0.015862908214330673\n","Training loss per 100 training steps: 0.023739978405969715\n","Training loss per 100 training steps: 0.027878411438557047\n","Training loss per 100 training steps: 0.026620132962328402\n","Training loss per 100 training steps: 0.026985931283378617\n","Training loss per 100 training steps: 0.026848059350219434\n","Training loss per 100 training steps: 0.026748454002214102\n","Training loss per 100 training steps: 0.026242833557809715\n","Training loss per 100 training steps: 0.026562578010096094\n","Training loss per 100 training steps: 0.026323202046484053\n","Training loss per 100 training steps: 0.025835010916465423\n","Training loss per 100 training steps: 0.025620508155629856\n","Training loss per 100 training steps: 0.025441902406885136\n","Training loss per 100 training steps: 0.025537136391781578\n","Training loss epoch: 0.025537136391781578\n","Training accuracy epoch: 0.9923611700555882\n","Validating model...\n","Validation Loss: 0.2425503750609887\n","Validation Accuracy: 0.9472268481795549\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03103775531053543\n","Training loss per 100 training steps: 0.017630938731023286\n","Training loss per 100 training steps: 0.018077473588802143\n","Training loss per 100 training steps: 0.017894005905713058\n","Training loss per 100 training steps: 0.01777554998706162\n","Training loss per 100 training steps: 0.01848891146709685\n","Training loss per 100 training steps: 0.018518598714786057\n","Training loss per 100 training steps: 0.017909325660188442\n","Training loss per 100 training steps: 0.01813902231489951\n","Training loss per 100 training steps: 0.01874409060074806\n","Training loss per 100 training steps: 0.01903055687605931\n","Training loss per 100 training steps: 0.019115627480867054\n","Training loss per 100 training steps: 0.01916360614064179\n","Training loss per 100 training steps: 0.01969502599848428\n","Training loss epoch: 0.01969502599848428\n","Training accuracy epoch: 0.993939543420868\n","Validating model...\n","Validation Loss: 0.2771671779405374\n","Validation Accuracy: 0.9425213958590194\n","Training epoch: 5\n","Training loss per 100 training steps: 0.05015565827488899\n","Training loss per 100 training steps: 0.016039175398666228\n","Training loss per 100 training steps: 0.017793740189300654\n","Training loss per 100 training steps: 0.019417304586637704\n","Training loss per 100 training steps: 0.019525905957119193\n","Training loss per 100 training steps: 0.01941045915090782\n","Training loss per 100 training steps: 0.018654037316944976\n","Training loss per 100 training steps: 0.019011410772627732\n","Training loss per 100 training steps: 0.01816620125078344\n","Training loss per 100 training steps: 0.017900504640739754\n","Training loss per 100 training steps: 0.018130864343453817\n","Training loss per 100 training steps: 0.018503351268789086\n","Training loss per 100 training steps: 0.018244327475797798\n","Training loss per 100 training steps: 0.017968894991261145\n","Training loss epoch: 0.017968894991261145\n","Training accuracy epoch: 0.9946114634711719\n","Validating model...\n","Validation Loss: 0.33406630347107913\n","Validation Accuracy: 0.941478832315775\n","Training epoch: 6\n","Training loss per 100 training steps: 0.03295845538377762\n","Training loss per 100 training steps: 0.010988967938378618\n","Training loss per 100 training steps: 0.015144363317762581\n","Training loss per 100 training steps: 0.015523440171685998\n","Training loss per 100 training steps: 0.01440113971839854\n","Training loss per 100 training steps: 0.013295684689518803\n","Training loss per 100 training steps: 0.012813618025688622\n","Training loss per 100 training steps: 0.01225835268254762\n","Training loss per 100 training steps: 0.012539935720305902\n","Training loss per 100 training steps: 0.012777611544551757\n","Training loss per 100 training steps: 0.012820511204038782\n","Training loss per 100 training steps: 0.013179753214546664\n","Training loss per 100 training steps: 0.013115357336544875\n","Training loss per 100 training steps: 0.013057432158894069\n","Training loss epoch: 0.013057432158894069\n","Training accuracy epoch: 0.9961223644307517\n","Validating model...\n","Validation Loss: 0.33009409677092133\n","Validation Accuracy: 0.9395257840370208\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 140.68824015000004 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.19523843957749368\n","Validation Accuracy: 0.9462122283125823\n","Validation duration: 5.899505550000018 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 81.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.78      0.82      0.80     12546\n","        test       0.83      0.86      0.85      9012\n","   treatment       0.76      0.84      0.80      9297\n","\n","   micro avg       0.79      0.84      0.81     30855\n","   macro avg       0.79      0.84      0.82     30855\n","weighted avg       0.79      0.84      0.81     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 41604\n","Points in y_train after augmentation: 41604\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.783133864402771\n","Training loss per 100 training steps: 0.41891633335611606\n","Training loss per 100 training steps: 0.32005000692694935\n","Training loss per 100 training steps: 0.26717731104142645\n","Training loss per 100 training steps: 0.23871666198582422\n","Training loss per 100 training steps: 0.2156654599897876\n","Training loss per 100 training steps: 0.19966705632512263\n","Training loss per 100 training steps: 0.18840285601059822\n","Training loss per 100 training steps: 0.17833993531828665\n","Training loss per 100 training steps: 0.16860994713569058\n","Training loss per 100 training steps: 0.16067789765363272\n","Training loss per 100 training steps: 0.15389461064208756\n","Training loss per 100 training steps: 0.1489349019982783\n","Training loss per 100 training steps: 0.1434933503046002\n","Training loss epoch: 0.1434933503046002\n","Training accuracy epoch: 0.9550236282390756\n","Validating model...\n","Validation Loss: 0.18372939110963377\n","Validation Accuracy: 0.9460944020209836\n","Training epoch: 2\n","Training loss per 100 training steps: 0.029918571934103966\n","Training loss per 100 training steps: 0.04920553611499248\n","Training loss per 100 training steps: 0.05272395349112316\n","Training loss per 100 training steps: 0.049271481738199924\n","Training loss per 100 training steps: 0.04960491836066369\n","Training loss per 100 training steps: 0.049086237793319866\n","Training loss per 100 training steps: 0.04836346772995261\n","Training loss per 100 training steps: 0.04688785778399764\n","Training loss per 100 training steps: 0.04648237685979892\n","Training loss per 100 training steps: 0.04642404910858171\n","Training loss per 100 training steps: 0.04627071655509839\n","Training loss per 100 training steps: 0.045629261398001095\n","Training loss per 100 training steps: 0.04533184656263062\n","Training loss per 100 training steps: 0.04519185979548501\n","Training loss epoch: 0.04519185979548501\n","Training accuracy epoch: 0.9858115257828799\n","Validating model...\n","Validation Loss: 0.20243228052730683\n","Validation Accuracy: 0.9488443647976535\n","Training epoch: 3\n","Training loss per 100 training steps: 0.14630302786827087\n","Training loss per 100 training steps: 0.0298464294098834\n","Training loss per 100 training steps: 0.028946061241000298\n","Training loss per 100 training steps: 0.02660019843347148\n","Training loss per 100 training steps: 0.02677559547394542\n","Training loss per 100 training steps: 0.026732106097535176\n","Training loss per 100 training steps: 0.026962553072889674\n","Training loss per 100 training steps: 0.028203942259798855\n","Training loss per 100 training steps: 0.029128863285679357\n","Training loss per 100 training steps: 0.0298965575743816\n","Training loss per 100 training steps: 0.02978696106906541\n","Training loss per 100 training steps: 0.029235860291662474\n","Training loss per 100 training steps: 0.029334678140584824\n","Training loss per 100 training steps: 0.029336361471643396\n","Training loss epoch: 0.029336361471643396\n","Training accuracy epoch: 0.9908720214229977\n","Validating model...\n","Validation Loss: 0.25785430757836864\n","Validation Accuracy: 0.942585473680672\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01292431354522705\n","Training loss per 100 training steps: 0.018134646565482793\n","Training loss per 100 training steps: 0.019660142241381757\n","Training loss per 100 training steps: 0.021573175512373362\n","Training loss per 100 training steps: 0.02132147943680558\n","Training loss per 100 training steps: 0.021900689503677122\n","Training loss per 100 training steps: 0.02244380060860348\n","Training loss per 100 training steps: 0.021976830243228\n","Training loss per 100 training steps: 0.021398695781736865\n","Training loss per 100 training steps: 0.020721401085420206\n","Training loss per 100 training steps: 0.020412233040325453\n","Training loss per 100 training steps: 0.020439187085253233\n","Training loss per 100 training steps: 0.02049279515008709\n","Training loss per 100 training steps: 0.020828869474831098\n","Training loss epoch: 0.020828869474831098\n","Training accuracy epoch: 0.9936831663430096\n","Validating model...\n","Validation Loss: 0.28775511026479206\n","Validation Accuracy: 0.9434398252232752\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0072669051587581635\n","Training loss per 100 training steps: 0.015347042785482573\n","Training loss per 100 training steps: 0.015512955664316498\n","Training loss per 100 training steps: 0.016163197304454764\n","Training loss per 100 training steps: 0.01648210808826364\n","Training loss per 100 training steps: 0.016474176409697075\n","Training loss per 100 training steps: 0.017869283090025563\n","Training loss per 100 training steps: 0.019819344915785082\n","Training loss per 100 training steps: 0.02065150343896426\n","Training loss per 100 training steps: 0.02018808599215954\n","Training loss per 100 training steps: 0.019962805761401164\n","Training loss per 100 training steps: 0.01976233846885444\n","Training loss per 100 training steps: 0.019922316603716943\n","Training loss per 100 training steps: 0.019520260681324657\n","Training loss epoch: 0.019520260681324657\n","Training accuracy epoch: 0.9939722303186207\n","Validating model...\n","Validation Loss: 0.287122061669633\n","Validation Accuracy: 0.9443027847198998\n","Training epoch: 6\n","Training loss per 100 training steps: 0.017023999243974686\n","Training loss per 100 training steps: 0.01271013521628528\n","Training loss per 100 training steps: 0.012446975162882932\n","Training loss per 100 training steps: 0.01464286414856877\n","Training loss per 100 training steps: 0.013341395815972592\n","Training loss per 100 training steps: 0.012811226877286294\n","Training loss per 100 training steps: 0.012895083705692811\n","Training loss per 100 training steps: 0.012749405786944433\n","Training loss per 100 training steps: 0.012639827752551564\n","Training loss per 100 training steps: 0.012944298270677881\n","Training loss per 100 training steps: 0.013505173502485273\n","Training loss per 100 training steps: 0.01353906220779733\n","Training loss per 100 training steps: 0.013500241593281923\n","Training loss per 100 training steps: 0.013533319117478381\n","Training loss epoch: 0.013533319117478381\n","Training accuracy epoch: 0.9959667928302331\n","Validating model...\n","Validation Loss: 0.2977329194061942\n","Validation Accuracy: 0.9421518026743936\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 140.3810967 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.19692630778040943\n","Validation Accuracy: 0.9435024679441006\n","Validation duration: 5.863874466666675 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 80.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.75      0.83      0.79     12546\n","        test       0.79      0.84      0.81      9012\n","   treatment       0.80      0.85      0.82      9297\n","\n","   micro avg       0.78      0.84      0.81     30855\n","   macro avg       0.78      0.84      0.81     30855\n","weighted avg       0.78      0.84      0.81     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 41604\n","Points in y_train after augmentation: 41604\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.249527931213379\n","Training loss per 100 training steps: 0.44874658590496175\n","Training loss per 100 training steps: 0.31990491506175617\n","Training loss per 100 training steps: 0.26960292989480933\n","Training loss per 100 training steps: 0.23650461026557962\n","Training loss per 100 training steps: 0.21425243407978625\n","Training loss per 100 training steps: 0.19699224603119092\n","Training loss per 100 training steps: 0.18553998010942496\n","Training loss per 100 training steps: 0.1751503948303644\n","Training loss per 100 training steps: 0.16571252017832888\n","Training loss per 100 training steps: 0.15919879779636442\n","Training loss per 100 training steps: 0.15203731213201457\n","Training loss per 100 training steps: 0.1454996207285421\n","Training loss per 100 training steps: 0.13938960832164987\n","Training loss epoch: 0.13938960832164987\n","Training accuracy epoch: 0.9552034046937437\n","Validating model...\n","Validation Loss: 0.18661552222518177\n","Validation Accuracy: 0.9470074824617883\n","Training epoch: 2\n","Training loss per 100 training steps: 0.060712847858667374\n","Training loss per 100 training steps: 0.045367325510885015\n","Training loss per 100 training steps: 0.0420360984025866\n","Training loss per 100 training steps: 0.04384002012921578\n","Training loss per 100 training steps: 0.04246268559368025\n","Training loss per 100 training steps: 0.042196429489801325\n","Training loss per 100 training steps: 0.041584414999254866\n","Training loss per 100 training steps: 0.04145574191975116\n","Training loss per 100 training steps: 0.04088625987627184\n","Training loss per 100 training steps: 0.0410819156768553\n","Training loss per 100 training steps: 0.04133613051841506\n","Training loss per 100 training steps: 0.041268351576739346\n","Training loss per 100 training steps: 0.0420337744398573\n","Training loss per 100 training steps: 0.04181681463767278\n","Training loss epoch: 0.04181681463767278\n","Training accuracy epoch: 0.9869467582691321\n","Validating model...\n","Validation Loss: 0.20894111351823652\n","Validation Accuracy: 0.9514886876076396\n","Training epoch: 3\n","Training loss per 100 training steps: 0.009791497141122818\n","Training loss per 100 training steps: 0.02869318790461794\n","Training loss per 100 training steps: 0.028654908722576995\n","Training loss per 100 training steps: 0.027302238733223037\n","Training loss per 100 training steps: 0.026062974409447597\n","Training loss per 100 training steps: 0.025729890796472085\n","Training loss per 100 training steps: 0.02546240244467143\n","Training loss per 100 training steps: 0.02565257810064513\n","Training loss per 100 training steps: 0.02560612123647644\n","Training loss per 100 training steps: 0.025618180339485635\n","Training loss per 100 training steps: 0.02777280635799381\n","Training loss per 100 training steps: 0.027748940833711017\n","Training loss per 100 training steps: 0.02787351488318181\n","Training loss per 100 training steps: 0.027562985101993554\n","Training loss epoch: 0.027562985101993554\n","Training accuracy epoch: 0.9912753876409036\n","Validating model...\n","Validation Loss: 0.2921087349517053\n","Validation Accuracy: 0.9413698979615657\n","Training epoch: 4\n","Training loss per 100 training steps: 0.009166529402136803\n","Training loss per 100 training steps: 0.018904894254963365\n","Training loss per 100 training steps: 0.01757706400552598\n","Training loss per 100 training steps: 0.016760679386634274\n","Training loss per 100 training steps: 0.017027284450898125\n","Training loss per 100 training steps: 0.01774443190511383\n","Training loss per 100 training steps: 0.017825715359941142\n","Training loss per 100 training steps: 0.017308690748941393\n","Training loss per 100 training steps: 0.01678945754169133\n","Training loss per 100 training steps: 0.017289796832140863\n","Training loss per 100 training steps: 0.017483907367748727\n","Training loss per 100 training steps: 0.01737558665657547\n","Training loss per 100 training steps: 0.01788264731832448\n","Training loss per 100 training steps: 0.018943702657303475\n","Training loss epoch: 0.018943702657303475\n","Training accuracy epoch: 0.9942110282325863\n","Validating model...\n","Validation Loss: 0.2930288545110009\n","Validation Accuracy: 0.9430295301069713\n","Training epoch: 5\n","Training loss per 100 training steps: 0.00863647647202015\n","Training loss per 100 training steps: 0.012985117247934445\n","Training loss per 100 training steps: 0.015528491629717353\n","Training loss per 100 training steps: 0.01450130711064018\n","Training loss per 100 training steps: 0.014362180441576741\n","Training loss per 100 training steps: 0.015094289656353467\n","Training loss per 100 training steps: 0.014769601818066523\n","Training loss per 100 training steps: 0.014692892900174606\n","Training loss per 100 training steps: 0.01528207416570498\n","Training loss per 100 training steps: 0.015287354104475728\n","Training loss per 100 training steps: 0.014968114085216646\n","Training loss per 100 training steps: 0.014870551567344974\n","Training loss per 100 training steps: 0.015237274582423962\n","Training loss per 100 training steps: 0.01517518452575222\n","Training loss epoch: 0.01517518452575222\n","Training accuracy epoch: 0.9954437914269345\n","Validating model...\n","Validation Loss: 0.2826902689291285\n","Validation Accuracy: 0.9455424251889121\n","Training epoch: 6\n","Training loss per 100 training steps: 0.011443213559687138\n","Training loss per 100 training steps: 0.012741833884040779\n","Training loss per 100 training steps: 0.014834316961400081\n","Training loss per 100 training steps: 0.01625772388021545\n","Training loss per 100 training steps: 0.017060148957629046\n","Training loss per 100 training steps: 0.017467158240430658\n","Training loss per 100 training steps: 0.01645810640271375\n","Training loss per 100 training steps: 0.01614165759380354\n","Training loss per 100 training steps: 0.015894380382579877\n","Training loss per 100 training steps: 0.015215211587028524\n","Training loss per 100 training steps: 0.014873128353445265\n","Training loss per 100 training steps: 0.015007958909830579\n","Training loss per 100 training steps: 0.014720354755285959\n","Training loss per 100 training steps: 0.014720776938983356\n","Training loss epoch: 0.014720776938983356\n","Training accuracy epoch: 0.995502523686834\n","Validating model...\n","Validation Loss: 0.3102977159009738\n","Validation Accuracy: 0.943313921296997\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 140.60455816666666 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.19879525540508675\n","Validation Accuracy: 0.9458053922393341\n","Validation duration: 5.882295799999944 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 80.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.80      0.79     12546\n","        test       0.84      0.81      0.83      9012\n","   treatment       0.81      0.79      0.80      9297\n","\n","   micro avg       0.81      0.80      0.80     30855\n","   macro avg       0.81      0.80      0.81     30855\n","weighted avg       0.81      0.80      0.80     30855\n","\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"11cc85243f43445c98c5b05ed0bce628":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_75a80bf75ecd40ea8615cde224b7bf57","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b852009c08084950af88673efcd6adf7","value":442221694}},"196ec565e27846a88f90317c418222ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fd5d4ffabc3246d4bf1448a2ffbfec5c","IPY_MODEL_11cc85243f43445c98c5b05ed0bce628","IPY_MODEL_ed73f1fc06074b2cb67309be8a3ea929"],"layout":"IPY_MODEL_bd744a1c91be49589a90a62d75376492"}},"381583743b294e029b86aa759f0db4b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d7d779352f1c437c8c3a8410087aaab7","IPY_MODEL_f1750556467d48b5ab143e8b0564cf2b","IPY_MODEL_94f4700043cf495c9a64d97b05561bc4"],"layout":"IPY_MODEL_7b475e9de3164bf5bf7231dde76adf44"}},"44d90a3e49e94a17b4754fff91ea4a99":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f19cc0d5b1141bf97eea7de0b3554ee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fbff192aef143c3ba4158b951a5e29d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"75a80bf75ecd40ea8615cde224b7bf57":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b475e9de3164bf5bf7231dde76adf44":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80ec0f6545fa40fdb53fd639badf9e5a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"94f4700043cf495c9a64d97b05561bc4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec8c913e8d854a40b928987f412f1d69","placeholder":"​","style":"IPY_MODEL_80ec0f6545fa40fdb53fd639badf9e5a","value":" 442M/442M [00:07&lt;00:00, 58.5MB/s]"}},"a1572206c8a240f9897d5fa9d1ced648":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aa641c6bd151407ba1c53079a142aa58":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b852009c08084950af88673efcd6adf7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bd744a1c91be49589a90a62d75376492":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bea9a733a36b4170ac5edea2bd4de384":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd7266723b5446c59ef8b7a42f630606":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4ba919e581b4b4591a7740bb812589e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7d779352f1c437c8c3a8410087aaab7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4ba919e581b4b4591a7740bb812589e","placeholder":"​","style":"IPY_MODEL_44d90a3e49e94a17b4754fff91ea4a99","value":"Downloading: 100%"}},"ec8c913e8d854a40b928987f412f1d69":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed73f1fc06074b2cb67309be8a3ea929":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa641c6bd151407ba1c53079a142aa58","placeholder":"​","style":"IPY_MODEL_6fbff192aef143c3ba4158b951a5e29d","value":" 442M/442M [00:06&lt;00:00, 64.9MB/s]"}},"f1750556467d48b5ab143e8b0564cf2b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd7266723b5446c59ef8b7a42f630606","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a1572206c8a240f9897d5fa9d1ced648","value":442221694}},"fd5d4ffabc3246d4bf1448a2ffbfec5c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f19cc0d5b1141bf97eea7de0b3554ee","placeholder":"​","style":"IPY_MODEL_bea9a733a36b4170ac5edea2bd4de384","value":"Downloading: 100%"}},"2a8b97b643de4b7090020a5a1e412dde":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6c766dca95cd4bb5bf62faa40269e618","IPY_MODEL_5d292bbc495248e89614c1989ffaf5d5","IPY_MODEL_dc4fa025cfc84c3fb8cfab0384657e47"],"layout":"IPY_MODEL_609a22dcb24645acb33a7efb07f39711"}},"6c766dca95cd4bb5bf62faa40269e618":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb46cd9bb8ea4cfa8ed71b7edef5c2b2","placeholder":"​","style":"IPY_MODEL_661f0c39c0c94415b17d888f62a683fc","value":"Downloading: 100%"}},"5d292bbc495248e89614c1989ffaf5d5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_761ec7234a454d40a439bfffd2f0129d","max":385,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6c88382be4c14906947389574acd0467","value":385}},"dc4fa025cfc84c3fb8cfab0384657e47":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca27e05c6dc74f619ad070173ab74b19","placeholder":"​","style":"IPY_MODEL_bde7203c65044ed58abe386dbe26c763","value":" 385/385 [00:00&lt;00:00, 14.4kB/s]"}},"609a22dcb24645acb33a7efb07f39711":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb46cd9bb8ea4cfa8ed71b7edef5c2b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"661f0c39c0c94415b17d888f62a683fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"761ec7234a454d40a439bfffd2f0129d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c88382be4c14906947389574acd0467":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ca27e05c6dc74f619ad070173ab74b19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bde7203c65044ed58abe386dbe26c763":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0b89087260c045aaaf156d81497b267d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_63f376cdfecf465396cc12136e5a690a","IPY_MODEL_b77882f55419482a9653a23c8291d4a1","IPY_MODEL_3202025588b9490fbb03453ce032da2e"],"layout":"IPY_MODEL_f81c5c220d724042a84b5ba277916b23"}},"63f376cdfecf465396cc12136e5a690a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8cbe5ab9a7924f8bae4f32db63e8ca0a","placeholder":"​","style":"IPY_MODEL_a4bf4ec0b3ea4568a69046943e81182d","value":"Downloading: 100%"}},"b77882f55419482a9653a23c8291d4a1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd06bd4f769f4617ac2d6c4261c4625c","max":227845,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3589329714bb4931a8784242036796b3","value":227845}},"3202025588b9490fbb03453ce032da2e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a7f90344ae0410382bcc91dea062da8","placeholder":"​","style":"IPY_MODEL_5f394a93fe094487ad36bf4448ae1a0e","value":" 228k/228k [00:00&lt;00:00, 248kB/s]"}},"f81c5c220d724042a84b5ba277916b23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8cbe5ab9a7924f8bae4f32db63e8ca0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4bf4ec0b3ea4568a69046943e81182d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd06bd4f769f4617ac2d6c4261c4625c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3589329714bb4931a8784242036796b3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1a7f90344ae0410382bcc91dea062da8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f394a93fe094487ad36bf4448ae1a0e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"49ec2d57f62a4c91b303a8f0b9551cba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99b8d053c53c404ba33767a9a346873c","IPY_MODEL_7ccfd36eb1764ffba583c7245996937a","IPY_MODEL_75b9dd62824142d882d31584f46d2e38"],"layout":"IPY_MODEL_66df70642ff04877838fc5d776f45422"}},"99b8d053c53c404ba33767a9a346873c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bdfcf7256dc47629f657fb59464eea3","placeholder":"​","style":"IPY_MODEL_5d8a864a612d478bb6263ae2c7ac16c5","value":"Downloading: 100%"}},"7ccfd36eb1764ffba583c7245996937a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8bf24c1d1bf947c98f8b454350002b73","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a65042ddb2ef418d89ef4cafb4e51204","value":442221694}},"75b9dd62824142d882d31584f46d2e38":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b392968a97946c9925d001668d9be3c","placeholder":"​","style":"IPY_MODEL_3a551be1ced0468ba62ce2787969925e","value":" 442M/442M [00:06&lt;00:00, 59.7MB/s]"}},"66df70642ff04877838fc5d776f45422":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bdfcf7256dc47629f657fb59464eea3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d8a864a612d478bb6263ae2c7ac16c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8bf24c1d1bf947c98f8b454350002b73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a65042ddb2ef418d89ef4cafb4e51204":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8b392968a97946c9925d001668d9be3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a551be1ced0468ba62ce2787969925e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a89fbd72e1864424aa761e5fa370917f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3f4e5f702aa34220a33cfdfb5c1914bd","IPY_MODEL_186c6347e80f49eb82c029f00827a590","IPY_MODEL_8164685dcd0041e9a8bfe776991176db"],"layout":"IPY_MODEL_dd98998cdbc443c5bc4392ba94c9b6ac"}},"3f4e5f702aa34220a33cfdfb5c1914bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27ee5825bd724e0cbba7572712adba17","placeholder":"​","style":"IPY_MODEL_ac486e8f74274767aaab09acf1e5643f","value":"Downloading: 100%"}},"186c6347e80f49eb82c029f00827a590":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_54aa8d7af81140efbd6d5249b5038b9a","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4bfb38a75c1841ba8666a655ce61d9bd","value":442221694}},"8164685dcd0041e9a8bfe776991176db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb9e39ec92e345829a91b88797323874","placeholder":"​","style":"IPY_MODEL_51d6116e342747f598d54549af79ebf3","value":" 442M/442M [00:07&lt;00:00, 56.1MB/s]"}},"dd98998cdbc443c5bc4392ba94c9b6ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27ee5825bd724e0cbba7572712adba17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac486e8f74274767aaab09acf1e5643f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"54aa8d7af81140efbd6d5249b5038b9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4bfb38a75c1841ba8666a655ce61d9bd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cb9e39ec92e345829a91b88797323874":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51d6116e342747f598d54549af79ebf3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}