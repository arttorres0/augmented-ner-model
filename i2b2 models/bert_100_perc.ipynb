{"cells":[{"cell_type":"markdown","metadata":{"id":"FFh7WVoJH5dr"},"source":["Adapted from [ner_with_bilstm_and_crf](https://www.kaggle.com/nikkisharma536/ner-with-bilstm-and-crf/notebook)\n","Altigran Soares da Silva\n","IComp/UFAM - 15/03/2021\n"],"id":"FFh7WVoJH5dr"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9135,"status":"ok","timestamp":1659976238858,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"instant-coupon","outputId":"005c22c5-d7a1-4204-f567-6aac7e4630f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.97)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (1.2.2)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n"]}],"source":["# For this to work, use:\n","# Keras 2.3.1\n","# Also remember to use GPU in your colab notebook\n","%tensorflow_version 2.x\n","\n","# Code to read csv file into Colaboratory:\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","from math import nan\n","from future.utils import iteritems\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import math\n","import random\n","import json\n","import pickle\n","import time\n","from requests import get\n","\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import torch\n","from torch import cuda\n","from torch.utils.data import Dataset, DataLoader\n","\n","!pip install sentencepiece\n","!pip install transformers\n","from transformers import BertForTokenClassification, AutoTokenizer\n","\n","!pip install seqeval\n","from seqeval.metrics import f1_score, classification_report"],"id":"instant-coupon"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mmt06ncv89hH"},"outputs":[],"source":["# Code to read csv file from google drive into Colaboratory:\n","DATA_TRAINING_FILE_ID = '1InFG9u6SJZJfUsEr6A-oqvvI_oZJl6d9'\n","DATA_TRAINING_FILENAME = 'ner_training_dataset.csv'\n","DATA_DEV_FILE_ID = '1d32cwSV9lmpIxhBhSwtDo27GB9K3XQYb'\n","DATA_DEV_FILENAME = 'ner_validation_dataset.csv'\n","DATA_TEST_FILE_ID = '1L-fnx31bK0nZAl9_DDfo7-25H7PYU0l8'\n","DATA_TEST_FILENAME = 'ner_test_dataset.csv'\n","BACKUP_FOLDER_ID = '1YWR4Ip8w94RwFMyMtNpRa9M0FpiJtqd5'\n","\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","downloaded_training = drive.CreateFile({'id': DATA_TRAINING_FILE_ID})\n","downloaded_training.GetContentFile(DATA_TRAINING_FILENAME)\n","downloaded_dev = drive.CreateFile({'id': DATA_DEV_FILE_ID})\n","downloaded_dev.GetContentFile(DATA_DEV_FILENAME)\n","downloaded_test = drive.CreateFile({'id': DATA_TEST_FILE_ID})\n","downloaded_test.GetContentFile(DATA_TEST_FILENAME)\n","\n","# Read the csv file in a dataframe called \"data\"\n","training_data = pd.read_csv(DATA_TRAINING_FILENAME, encoding=\"latin1\")\n","dev_data = pd.read_csv(DATA_DEV_FILENAME, encoding=\"latin1\")\n","test_data = pd.read_csv(DATA_TEST_FILENAME, encoding=\"latin1\")\n","# Fill NaN values using the specified method\n","# Ffill propagate last valid observation/value forward to next valid \n","training_data = training_data.fillna(method=\"ffill\")\n","dev_data = dev_data.fillna(method=\"ffill\")\n","test_data = test_data.fillna(method=\"ffill\")\n","\n","notebook_filename = get('http://172.28.0.2:9000/api/sessions').json()[0]['name']"],"id":"Mmt06ncv89hH"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":588},"executionInfo":{"elapsed":722,"status":"ok","timestamp":1659976250431,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"adverse-doctor","outputId":"fdd5df6f-f0cd-4119-c537-883e2108e0d9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of training sentences:  13867\n","Number of dev sentences:  2448\n","Number of test sentences:  27625\n","Number of words in the training dataset:  14450\n","Number of words in the dev dataset:  5242\n","Number of words in the test dataset:  21696\n","Tags in the training dataset: ['B-treatment', 'B-test', 'I-treatment', 'O', 'I-problem', 'I-test', 'B-problem']\n","Number of Labels in the training dataset:  7\n","Tags in the dev dataset: ['B-treatment', 'B-test', 'I-treatment', 'O', 'I-problem', 'I-test', 'B-problem']\n","Number of Labels in the dev dataset:  7\n","Tags in the test dataset: ['B-treatment', 'B-test', 'I-treatment', 'O', 'I-problem', 'I-test', 'B-problem']\n","Number of Labels in the test dataset:  7\n","What the training dataset looks like:\n"]},{"data":{"text/html":["\n","  <div id=\"df-defcc192-bb10-4764-ba32-85457c98ef2c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence #</th>\n","      <th>Word</th>\n","      <th>Tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sentence: 5851</td>\n","      <td>0802338</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sentence: 15815</td>\n","      <td>The</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sentence: 15815</td>\n","      <td>visualized</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sentence: 15815</td>\n","      <td>paranasal</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sentence: 15815</td>\n","      <td>sinuses</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Sentence: 15815</td>\n","      <td>are</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Sentence: 15815</td>\n","      <td>clear</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Sentence: 15815</td>\n","      <td>.</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Sentence: 4203</td>\n","      <td>Chem-7</td>\n","      <td>B-test</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Sentence: 4203</td>\n","      <td>:</td>\n","      <td>O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-defcc192-bb10-4764-ba32-85457c98ef2c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-defcc192-bb10-4764-ba32-85457c98ef2c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-defcc192-bb10-4764-ba32-85457c98ef2c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["        Sentence #        Word     Tag\n","0   Sentence: 5851     0802338       O\n","1  Sentence: 15815         The       O\n","2  Sentence: 15815  visualized       O\n","3  Sentence: 15815   paranasal       O\n","4  Sentence: 15815     sinuses       O\n","5  Sentence: 15815         are       O\n","6  Sentence: 15815       clear       O\n","7  Sentence: 15815           .       O\n","8   Sentence: 4203      Chem-7  B-test\n","9   Sentence: 4203           :       O"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Explore the input dataset\n","print(\"Number of training sentences: \", len(training_data.groupby(['Sentence #'])))\n","print(\"Number of dev sentences: \", len(dev_data.groupby(['Sentence #'])))\n","print(\"Number of test sentences: \", len(test_data.groupby(['Sentence #'])))\n","\n","training_words = list(set(training_data[\"Word\"].values))\n","n_training_words = len(training_words)\n","print(\"Number of words in the training dataset: \", n_training_words)\n","dev_words = list(set(dev_data[\"Word\"].values))\n","n_dev_words = len(dev_words)\n","print(\"Number of words in the dev dataset: \", n_dev_words)\n","test_words = list(set(test_data[\"Word\"].values))\n","n_test_words = len(test_words)\n","print(\"Number of words in the test dataset: \", n_test_words)\n","\n","training_tags = list(set(training_data[\"Tag\"].values))\n","print(\"Tags in the training dataset:\", training_tags)\n","n_training_tags = len(training_tags)\n","print(\"Number of Labels in the training dataset: \", n_training_tags)\n","dev_tags = list(set(dev_data[\"Tag\"].values))\n","print(\"Tags in the dev dataset:\", dev_tags)\n","n_dev_tags = len(dev_tags)\n","print(\"Number of Labels in the dev dataset: \", n_dev_tags)\n","test_tags = list(set(test_data[\"Tag\"].values))\n","print(\"Tags in the test dataset:\", test_tags)\n","n_test_tags = len(test_tags)\n","print(\"Number of Labels in the test dataset: \", n_test_tags)\n","\n","print(\"What the training dataset looks like:\")\n","# Show the first 10 rows\n","training_data.head(n=10)"],"id":"adverse-doctor"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3024,"status":"ok","timestamp":1659976253450,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"painful-karaoke","outputId":"61599d5a-ef7b-4c13-b81f-8b0ee83684cc"},"outputs":[{"data":{"text/plain":["[('Admission', 'O'), ('Date', 'O'), (':', 'O')]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# SentenceGetter re-organize \"data\" as an arry of sentences\n","# Each sentence is a list of pairs <word,tag> \n","class SentenceGetter(object):\n","    \n","    def __init__(self, dataset):\n","        self.n_sent = 1\n","        self.dataset = dataset\n","        self.empty = False\n","        agg_func = lambda s: [(w, t) for w,t in zip(s[\"Word\"].values.tolist(),\n","                                                        s[\"Tag\"].values.tolist())]\n","        self.grouped = self.dataset.groupby(\"Sentence #\").apply(agg_func)\n","        self.sentences = [s for s in self.grouped]\n","    \n","    def get_next(self):\n","        try:\n","            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n","            self.n_sent += 1\n","            return s\n","        except:\n","            return None\n","\n","training_getter = SentenceGetter(training_data)\n","training_sentences = training_getter.sentences\n","dev_getter = SentenceGetter(dev_data)\n","dev_sentences = dev_getter.sentences\n","test_getter = SentenceGetter(test_data)\n","test_sentences = test_getter.sentences\n","\n","# Example: training sentence #200 \n","training_sentences[200]"],"id":"painful-karaoke"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"elapsed":3435,"status":"ok","timestamp":1659976256881,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"round-providence","outputId":"435e1ee0-f6e3-4549-f1a5-52f4f421a6eb"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Explore set of sentences\n","# Plot sentences by length\n","plt.hist([len(s) for s in training_sentences], bins=50)\n","plt.title('Token per training sentence')\n","plt.xlabel('Len (number of token)')\n","plt.ylabel('# samples')\n","plt.show()"],"id":"round-providence"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1659976256882,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"urxTzspTyPq5","outputId":"9b88bb90-16b7-4963-b0d2-7865166a7686"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Explore set of sentences\n","# Plot sentences by length\n","plt.hist([len(s) for s in dev_sentences], bins=50)\n","plt.title('Token per dev sentence')\n","plt.xlabel('Len (number of token)')\n","plt.ylabel('# samples')\n","plt.show()"],"id":"urxTzspTyPq5"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1659976256883,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"JJ91V_51yPw9","outputId":"0b8420c4-d3c2-4408-872c-6ee11726384e"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Explore set of sentences\n","# Plot sentences by length\n","plt.hist([len(s) for s in test_sentences], bins=50)\n","plt.title('Token per test sentence')\n","plt.xlabel('Len (number of token)')\n","plt.ylabel('# samples')\n","plt.show()"],"id":"JJ91V_51yPw9"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":565,"status":"ok","timestamp":1659976257439,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"juvenile-scene","outputId":"e1d2d771-d2f2-480c-982f-828dfaa8b2a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["11207\n","clonazepam\n","0\n","I-problem\n"]}],"source":["# Keras (and most other ML packages) expect all the ids to be numeric, \n","# this is an optimisation to save memory. \n","# We will create the following dictionaries:\n","# word2idx: assign a numeric index to each word in the dataset\n","# idx2word: inverted version of word2idx\n","# tag2idx: assign a numeric index to each tag in the dataset\n","# idx2tag: inverted version of tag2idx\n","\n","# Group training, dev and test data in order to create word-index dicts and to\n","# convert data to numeric indeces later\n","data = pd.concat([training_data, dev_data, test_data])\n","\n","# words <= list of all words in the input dataset\n","words = list(set(data[\"Word\"].values))\n","n_words = len(words)\n","\n","# tags <= list of all tags in the input dataset\n","tags = []\n","for tag in set(data[\"Tag\"].values):\n","    if tag is nan or isinstance(tag, float):\n","        tags.append('unk')\n","    else:\n","        tags.append(tag)\n","n_tags = len(tags)\n","\n","# Dictionaries\n","word2idx = {w: i for i, w in enumerate(words)}\n","idx2word = {i: w for w, i in iteritems(word2idx)}\n","tag2idx = {t: i for i, t in enumerate(tags)}\n","idx2tag = {v: k for k, v in iteritems(tag2idx)}\n","\n","# Index number for the word 'comprehension'\n","print(word2idx['comprehension'])\n","# Word of index 10\n","print(idx2word[10])\n","# Index number for the tag 'B-treatment'\n","print(tag2idx['B-treatment'])\n","# Tag of index 4\n","print(idx2tag[4])"],"id":"juvenile-scene"},{"cell_type":"code","execution_count":null,"metadata":{"id":"delayed-dryer"},"outputs":[],"source":["# Convert train, dev and test data to numeric values\n","X_train = [[word2idx[w[0]] for w in s] for s in training_sentences]\n","y_train = [[tag2idx[w[1]] for w in s] for s in training_sentences]\n","\n","X_dev = [[word2idx[w[0]] for w in s] for s in dev_sentences]\n","y_dev = [[tag2idx[w[1]] for w in s] for s in dev_sentences]\n","\n","X_test = [[word2idx[w[0]] for w in s] for s in test_sentences]\n","y_test = [[tag2idx[w[1]] for w in s] for s in test_sentences]"],"id":"delayed-dryer"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1659976257441,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"Ttsyh05Rhovo","outputId":"d46ded38-3a86-4cbf-967d-c974ac2850ff"},"outputs":[{"name":"stdout","output_type":"stream","text":["Points in X_train before removal: 13867\n","Points in y_train before removal: 13867\n","Points in X_train before removal: 13867\n","Points in y_train before removal: 13867\n"]}],"source":["# Use this function to randomly remove some points from training dataset\n","# Use removal percentage in decimal value. E.g.: if you set as 0.5, it will\n","# remove 50% of the dataset\n","\n","def random_remove_data_points(dataset, labels, removal_percentage):\n","    if removal_percentage < 0 or removal_percentage > 1:\n","        raise Exception(\"Invalid removal percentage\")\n","    \n","    if removal_percentage == 1:\n","        raise Exception(\"You can't remove the entire dataset\")\n","    \n","    number_of_points_remaining = round(len(dataset)*(1-removal_percentage))\n","\n","    try_again = True\n","\n","    while try_again:\n","      random_idxs = np.random.choice(len(dataset), number_of_points_remaining, replace=False)\n","      cut_dataset_sentences = [dataset[i] for i in random_idxs]\n","      cut_dataset_labels = [labels[i] for i in random_idxs]\n","      cut_tags = list(set([idx2tag[j] for sub in cut_dataset_labels for j in sub]))\n","\n","      if all(i in cut_tags for i in tags if i[:2] == \"B-\"):\n","        try_again = False\n","\n","    return cut_dataset_sentences, cut_dataset_labels \n","\n","print(f\"Points in X_train before removal: {len(X_train)}\")\n","print(f\"Points in y_train before removal: {len(y_train)}\")\n","# X_train, y_train = random_remove_data_points(X_train, y_train, 0.95)\n","print(f\"Points in X_train before removal: {len(X_train)}\")\n","print(f\"Points in y_train before removal: {len(y_train)}\")"],"id":"Ttsyh05Rhovo"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0SN-NYLpgsFa"},"outputs":[],"source":["# Aux functions to save data and dicts, if data consistency is important\n","# and there is desire to not random split again\n","\n","def save_backup_dataset(dataset, filename):\n","  dataset_df = pd.DataFrame(dataset)\n","  dataset_df.to_csv(filename, index=False)\n","  gfile = drive.CreateFile({'parents': [{'id': BACKUP_FOLDER_ID}]})\n","  gfile.SetContentFile(filename)\n","  gfile.Upload()\n","\n","def save_backup_dict(dict, filename):\n","  dict_file = open(filename, \"wb\")\n","  pickle.dump(dict, dict_file)\n","  dict_file.close()\n","  gfile = drive.CreateFile({'parents': [{'id': BACKUP_FOLDER_ID}]})\n","  gfile.SetContentFile(filename)\n","  gfile.Upload()"],"id":"0SN-NYLpgsFa"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31198,"status":"ok","timestamp":1659976288625,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"MzRQfI30tuI2","outputId":"2b0d680c-4346-4db8-e6dd-604d6efa9466"},"outputs":[{"name":"stdout","output_type":"stream","text":["[26483, 24534]\n","[3, 3]\n","[2848, 10024, 5874, 20329, 6229, 11620, 6197, 4706, 18921, 17253, 6514, 26123]\n","[6, 4, 4, 4, 4, 4, 3, 1, 5, 5, 5, 3]\n","[20375, 18072, 6274]\n","[3, 3, 3]\n","11207\n","0\n","I-treatment\n","1.15\n","28388\n","7\n"]}],"source":["# Uncomment this cell if you want to save data for further use\n","\n","# Check some points before saving\n","print(X_train[0])\n","print(y_train[0])\n","print(X_dev[0])\n","print(y_dev[0])\n","print(X_test[0])\n","print(y_test[0])\n","print(word2idx['comprehension'])\n","print(tag2idx['B-treatment'])\n","print(idx2tag[2])\n","print(idx2word[100])\n","print(n_words)\n","print(n_tags)\n","\n","X_train_filename = f'{notebook_filename}_X_train.csv'\n","y_train_filename = f'{notebook_filename}_y_train.csv'\n","X_dev_filename = f'{notebook_filename}_X_dev.csv'\n","y_dev_filename = f'{notebook_filename}_y_dev.csv'\n","X_test_filename = f'{notebook_filename}_X_test.csv'\n","y_test_filename = f'{notebook_filename}_y_test.csv'\n","\n","word2idx_filename = f'{notebook_filename}_word2idx.pkl'\n","idx2word_filename = f'{notebook_filename}_idx2word.pkl'\n","tag2idx_filename = f'{notebook_filename}_tag2idx.pkl'\n","idx2tag_filename = f'{notebook_filename}_idx2tag.pkl'\n","\n","others_filename = f'{notebook_filename}_others.pkl'\n","\n","save_backup_dataset(X_train, X_train_filename)\n","save_backup_dataset(y_train, y_train_filename)\n","save_backup_dataset(X_dev, X_dev_filename)\n","save_backup_dataset(y_dev, y_dev_filename)\n","save_backup_dataset(X_test, X_test_filename)\n","save_backup_dataset(y_test, y_test_filename)\n","\n","save_backup_dict(word2idx, word2idx_filename)\n","save_backup_dict(idx2word, idx2word_filename)\n","save_backup_dict(tag2idx, tag2idx_filename)\n","save_backup_dict(idx2tag, idx2tag_filename)\n","\n","save_backup_dict({\"n_words\":n_words, \"n_tags\":n_tags}, others_filename)"],"id":"MzRQfI30tuI2"},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["3b7323cf80084dddb8c1a520523170e6","d749038c8dee42aeb42b9198e13b490d","ad006cfb44774b099da11d1ebb9bd63a","f8875275143546a7860d72e31edccfe5","e7338e015ed54b80978a15dc25e21f11","d7c09472bf1245a6a4373d24df9294f8","ade7bd522df9481e9393e8fc4466a3dc","ff858519fd9f482c8b2fbe2c55aacae1","27eba65c3a894f9c95ca703f16f029cf","987f4c8c81224b5c85254f53b6805925","bbad552ca57645e68eaa039144ada49f"]},"executionInfo":{"elapsed":72536,"status":"ok","timestamp":1663564026226,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"zvip_oC0j5-y","outputId":"c9cb4874-f974-40f3-bc3c-7494cfe7ed3c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     || 1.3 MB 14.5 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.22.1-py3-none-any.whl (4.9 MB)\n","\u001b[K     || 4.9 MB 13.7 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     || 6.6 MB 47.3 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.9.0\n","  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n","\u001b[K     || 120 kB 69.9 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.22.1\n"]},{"output_type":"stream","name":"stderr","text":["The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"]},{"output_type":"stream","name":"stdout","text":["Moving 0 files to the new cache system\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b7323cf80084dddb8c1a520523170e6"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     || 43 kB 747 kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=dd1cf90b297ca26abb31d653b97f5c5b87be2d54707b562cb2519a9cabd6c9f0\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n","[26483, 24534]\n","[3, 3]\n","[2848, 10024, 5874, 20329, 6229, 11620, 6197, 4706, 18921, 17253, 6514, 26123]\n","[6, 4, 4, 4, 4, 4, 3, 1, 5, 5, 5, 3]\n","[20375, 18072, 6274]\n","[3, 3, 3]\n","11207\n","0\n","I-treatment\n","1.15\n","28388\n","7\n"]}],"source":["# Uncomment this cell if you want to load saved data\n","\n","# Re-import necessary libs\n","import pandas as pd\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","import pickle, math\n","from requests import get\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import random\n","import time\n","%tensorflow_version 2.x\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import torch\n","from torch import cuda\n","from torch.utils.data import Dataset, DataLoader\n","!pip install sentencepiece\n","!pip install transformers\n","from transformers import BertForTokenClassification, AutoTokenizer\n","import matplotlib.pyplot as plt\n","!pip install seqeval\n","from seqeval.metrics import f1_score, classification_report\n","\n","BACKUP_FOLDER_ID = '1YWR4Ip8w94RwFMyMtNpRa9M0FpiJtqd5'\n","notebook_filename = get('http://172.28.0.2:9000/api/sessions').json()[0]['name']\n","\n","X_train_filename = f'{notebook_filename}_X_train.csv'\n","y_train_filename = f'{notebook_filename}_y_train.csv'\n","X_dev_filename = f'{notebook_filename}_X_dev.csv'\n","y_dev_filename = f'{notebook_filename}_y_dev.csv'\n","X_test_filename = f'{notebook_filename}_X_test.csv'\n","y_test_filename = f'{notebook_filename}_y_test.csv'\n","\n","word2idx_filename = f'{notebook_filename}_word2idx.pkl'\n","idx2word_filename = f'{notebook_filename}_idx2word.pkl'\n","tag2idx_filename = f'{notebook_filename}_tag2idx.pkl'\n","idx2tag_filename = f'{notebook_filename}_idx2tag.pkl'\n","\n","others_filename = f'{notebook_filename}_others.pkl'\n","\n","# Re-get important variables\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","def get_backup_files_ids(folder_id):\n","  file_list = drive.ListFile({'q': \"'{}' in parents and trashed=false\".format(folder_id)}).GetList()\n","  return file_list\n","\n","def load_backup_dataset(file_id):\n","  downloaded = drive.CreateFile({'id':file_id})\n","  downloaded.GetContentFile(f\"{file_id}.csv\")\n","\n","  dataset = pd.read_csv(f\"{file_id}.csv\", encoding=\"latin1\")\n","  dataset = dataset.values.tolist()\n","  dataset = [ [ int(word) for word in sentence if str(word) != 'nan' ] for sentence in dataset]\n","  return dataset\n","\n","def load_backup_dict(file_id):\n","  downloaded = drive.CreateFile({'id':file_id})\n","  downloaded.GetContentFile(f\"{file_id}.pkl\")\n","\n","  dict_file = open(f\"{file_id}.pkl\", \"rb\")\n","  out_dict = pickle.load(dict_file)\n","  return out_dict\n","\n","backup_file_list = get_backup_files_ids(BACKUP_FOLDER_ID)\n","\n","X_train_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == X_train_filename][0]['id']\n","y_train_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == y_train_filename][0]['id']\n","X_dev_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == X_dev_filename][0]['id']\n","y_dev_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == y_dev_filename][0]['id']\n","X_test_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == X_test_filename][0]['id']\n","y_test_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == y_test_filename][0]['id']\n","\n","word2idx_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == word2idx_filename][0]['id']\n","idx2word_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == idx2word_filename][0]['id']\n","tag2idx_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == tag2idx_filename][0]['id']\n","idx2tag_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == idx2tag_filename][0]['id']\n","\n","others_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == others_filename][0]['id']\n","\n","X_train = load_backup_dataset(X_train_file_id)\n","y_train = load_backup_dataset(y_train_file_id)\n","X_dev = load_backup_dataset(X_dev_file_id)\n","y_dev = load_backup_dataset(y_dev_file_id)\n","X_test = load_backup_dataset(X_test_file_id)\n","y_test = load_backup_dataset(y_test_file_id)\n","\n","word2idx = load_backup_dict(word2idx_file_id)\n","idx2word = load_backup_dict(idx2word_file_id)\n","tag2idx = load_backup_dict(tag2idx_file_id)\n","idx2tag = load_backup_dict(idx2tag_file_id)\n","\n","others = load_backup_dict(others_file_id)\n","\n","n_words = others[\"n_words\"]\n","n_tags = others[\"n_tags\"]\n","\n","# Check some points after loading data to see if they match the ones before saving\n","print(X_train[0])\n","print(y_train[0])\n","print(X_dev[0])\n","print(y_dev[0])\n","print(X_test[0])\n","print(y_test[0])\n","print(word2idx['comprehension'])\n","print(tag2idx['B-treatment'])\n","print(idx2tag[2])\n","print(idx2word[100])\n","print(n_words)\n","print(n_tags)"],"id":"zvip_oC0j5-y"},{"cell_type":"code","execution_count":2,"metadata":{"id":"ux5-6tyMhovp","executionInfo":{"status":"ok","timestamp":1663564026226,"user_tz":240,"elapsed":7,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}}},"outputs":[],"source":["# Aux function to help in augmentation. Generates a dict where entities\n","# are the keys, and words are the values.\n","\n","def create_entities_dict(dataset, labels, decoded_word=False):\n","    entities_dict = {}\n","    \n","    for i, sentence in enumerate(dataset):\n","        for k, word in enumerate(sentence):\n","            tag = idx2tag[labels[i][k]]\n","            if tag[:2] == \"B-\":\n","                if decoded_word:\n","                    word_list = [idx2word[word]]\n","                else:\n","                    word_list = [word]\n","                j = k + 1\n","                if j < len(labels[i]):\n","                    while idx2tag[labels[i][j]][:2] == \"I-\":\n","                        if decoded_word:\n","                            word_list.append(idx2word[dataset[i][j]])\n","                        else:\n","                            word_list.append(dataset[i][j])\n","                        j = j+1\n","                        if j == len(labels[i]):\n","                            break\n","                        \n","                if entities_dict.get(tag):\n","                    if word_list not in entities_dict[tag]:\n","                        entities_dict[tag].append(word_list)\n","                else:\n","                    entities_dict[tag] = [word_list]\n","                    \n","    return entities_dict\n","\n","entities_dict = create_entities_dict(X_train, y_train)"],"id":"ux5-6tyMhovp"},{"cell_type":"code","execution_count":3,"metadata":{"id":"2wRVTj71hovp","executionInfo":{"status":"ok","timestamp":1663564026848,"user_tz":240,"elapsed":6,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}}},"outputs":[],"source":["# Augmentation function using entity replacement technique.\n","# It will generate a new dataset, with X% more points based on\n","# the original dataset. E.g.: if you set augmentation percentage as 0.5 and dataset has\n","# 1000 points, it will generate a dataset with 1500 points.\n","\n","def generate_sentences(dataset, labels, entities_dict, augmented_set_size_percentage):\n","    if augmented_set_size_percentage < 0:\n","        raise Exception(\"Invalid augmented set size percentage\")\n","\n","    number_of_new_sentences = math.ceil(augmented_set_size_percentage * len(dataset))\n","    random_idxs = np.random.choice(len(dataset), number_of_new_sentences, replace=True)\n","    \n","    base_sequences = [dataset[i] for i in random_idxs]\n","    base_labels = [labels[i] for i in random_idxs]\n","\n","    new_sequences = []\n","    new_labels = []\n","    \n","    for k, sequence in enumerate(base_sequences):\n","        new_sequence = []\n","        new_label = []\n","\n","        for i, word in enumerate(sequence):\n","            tag = idx2tag[base_labels[k][i]]\n","            if tag == \"O\":\n","                new_sequence.append(word)\n","                new_label.append(base_labels[k][i])\n","            elif tag[:2] == \"B-\":\n","                same_entities_type_tmp = entities_dict[tag]\n","                same_entities_type = np.array(same_entities_type_tmp, dtype=object)\n","                random_entity_idx = np.random.choice(len(same_entities_type), 1)[0]\n","                random_entity = same_entities_type[random_entity_idx]\n","                random_number_of_tokens = random.randint(1, len(random_entity))\n","                random_entity_tokens = np.random.choice(random_entity, random_number_of_tokens, replace = False).tolist()\n","                entity = tag[2:]\n","                decoded_token_labels = [f\"I-{entity}\" for token in random_entity_tokens]\n","                decoded_token_labels[0] = tag\n","                encoded_token_labels = [tag2idx[label] for label in decoded_token_labels]\n","                new_sequence = new_sequence + random_entity_tokens\n","                new_label = new_label + encoded_token_labels\n","\n","        new_sequences.append(new_sequence)\n","        new_labels.append(new_label)\n","\n","    augmented_X_train = dataset + new_sequences\n","    augmented_y_train = labels + new_labels\n","\n","    print(f\"Points in X_train after augmentation: {len(augmented_X_train)}\")\n","    print(f\"Points in y_train after augmentation: {len(augmented_y_train)}\")\n","\n","    return augmented_X_train, augmented_y_train"],"id":"2wRVTj71hovp"},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["df65ac411f7445309329a28cc2e33c59","6e461950e0cf4ce29c4b4085e79730c8","56a57aa2aed34ef7b072b335e3e40d72","5f2394d47e2e4eb7bfcc923215e9f37a","803b80c9864b467c8e109def365995dd","6835fd4ff179464a9f7330d6be2d9cd3","40220d404dc946569b6387d066987b76","8f387e763931420c845d739b81caa89b","b0f048a3e0bd437ca0020da6a69a0e82","c1e88e93edc54a4b8d071415434c9e9a","ee41b1973be54488ab3e30183220e8ad","aa34af90bcc04ade8b334782828fc62b","e77a320267b943a8b0085e4a73510080","fc6b18b894374ea3a28611ce694ca4b6","3616f57241ee43e0b09ec074672df150","04af653d421a4f30bfd83a4ce9e41c94","4641bd47b0ea44a2903400718b3e7436","ee7428bb7dbb410bb562f65400eb1fa9","7e5c69cfc28145e8bebfbd62b8667146","2b9b038b885440a691c22b54e3392335","15625f38cd0443f58226c2b4f60aecd6","fe3ab85597514df0a57d74bbab41b700"]},"executionInfo":{"elapsed":3921,"status":"ok","timestamp":1663564030764,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"mYHzTnzZZfBg","outputId":"47c45cb8-e462-4250-f6c6-9d8a68d72774"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/385 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df65ac411f7445309329a28cc2e33c59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/228k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa34af90bcc04ade8b334782828fc62b"}},"metadata":{}}],"source":["tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n","\n","class dataset(Dataset):\n","  def __init__(self, dataframe, tokenizer, max_len):\n","        self.len = len(dataframe)\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","  def __getitem__(self, index):\n","        # step 1: get the sentence and word labels\n","        sentence = self.data.sentence[index]\n","        word_labels = self.data.word_labels[index].split(\",\") \n","\n","        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n","        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n","        encoding = self.tokenizer(sentence,\n","                             is_split_into_words=True, \n","                             return_offsets_mapping=True, \n","                             padding='max_length', \n","                             truncation=True, \n","                             max_length=self.max_len)\n","        \n","        # step 3: create token labels only for first word pieces of each tokenized word\n","        labels = [tag2idx[label] for label in word_labels] \n","        # code based on https://huggingface.co/transformers/custom_datasets.html#tok-ner\n","        # create an empty array of -100 of length max_length\n","        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n","        \n","        # set only labels whose first offset position is 0 and the second is not 0\n","        i = 0\n","        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n","          if mapping[0] == 0 and mapping[1] != 0:\n","            # overwrite label\n","            encoded_labels[idx] = labels[i]\n","            i += 1\n","\n","        # step 4: turn everything into PyTorch tensors\n","        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n","        item['labels'] = torch.as_tensor(encoded_labels)\n","        \n","        return item\n","\n","  def __len__(self):\n","        return self.len"],"id":"mYHzTnzZZfBg"},{"cell_type":"code","execution_count":5,"metadata":{"id":"d8H1s-6b_-pM","executionInfo":{"status":"ok","timestamp":1663564030765,"user_tz":240,"elapsed":12,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}}},"outputs":[],"source":["# some configuration variables\n","LEARNING_RATE = 5e-05\n","MAX_GRAD_NORM = 10\n","TRAINING_STOP_LOSS_PERCENTAGE = 1\n","\n","# Model creation function\n","def create_model(maxlen, n_labels, training_set, testing_set, validation_set):\n","  device = 'cuda' if cuda.is_available() else 'cpu'\n","  print(\"Device: \", device)\n","\n","  model = BertForTokenClassification.from_pretrained('allenai/scibert_scivocab_uncased', num_labels=n_labels)\n","  model.to(device)\n","\n","  optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n","\n","  TRAIN_BATCH_SIZE = round(0.05*len(training_set))\n","  if TRAIN_BATCH_SIZE > 32:\n","    TRAIN_BATCH_SIZE = 32\n","  if TRAIN_BATCH_SIZE < 10:\n","    TRAIN_BATCH_SIZE = 10\n","\n","  VALID_BATCH_SIZE = round(0.1*len(validation_set))\n","  if VALID_BATCH_SIZE > 32:\n","    VALID_BATCH_SIZE = 32\n","  if VALID_BATCH_SIZE < 10:\n","    VALID_BATCH_SIZE = 10\n","\n","  train_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                  'shuffle': True,\n","                  'num_workers': 0\n","                  }\n","\n","  test_params = {'batch_size': VALID_BATCH_SIZE,\n","                  'shuffle': True,\n","                  'num_workers': 0\n","                  }\n","\n","  training_loader = DataLoader(training_set, **train_params)\n","  testing_loader = DataLoader(testing_set, **test_params)\n","  validation_loader = DataLoader(validation_set, **test_params)\n","\n","  return model, device, optimizer, training_loader, testing_loader, validation_loader"],"id":"d8H1s-6b_-pM"},{"cell_type":"code","execution_count":6,"metadata":{"id":"cjp-jXx4AmiV","executionInfo":{"status":"ok","timestamp":1663564030765,"user_tz":240,"elapsed":10,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}}},"outputs":[],"source":["# Model training function\n","def train(model, device, optimizer, training_loader, epoch, training_stop_loss_percentage):\n","    tr_loss, tr_accuracy = 0, 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","    tr_preds, tr_labels = [], []\n","    losses = []\n","    # put model in training mode\n","    model.train()\n","    \n","    for idx, batch in enumerate(training_loader):\n","        \n","        ids = batch['input_ids'].to(device, dtype = torch.long)\n","        mask = batch['attention_mask'].to(device, dtype = torch.long)\n","        labels = batch['labels'].to(device, dtype = torch.long)\n","\n","        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels, return_dict = False)\n","        tr_loss += loss.item()\n","\n","        nb_tr_steps += 1\n","        nb_tr_examples += labels.size(0)\n","        \n","        if idx % 100==0:\n","            loss_step = tr_loss/nb_tr_steps\n","            print(f\"Training loss per 100 training steps: {loss_step}\")\n","            losses.append(loss_step)\n","            last_5_losses = losses[-5:]\n","            loss_min = min(last_5_losses)\n","            loss_max = max(last_5_losses)\n","            if len(last_5_losses) > 1 and (loss_max - loss_min)/loss_max < training_stop_loss_percentage/100:\n","              print(\"Stopping epoch...\")\n","              break\n","           \n","        # compute training accuracy\n","        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","        \n","        # only compute accuracy at active labels\n","        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n","        \n","        labels = torch.masked_select(flattened_targets, active_accuracy)\n","        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","        \n","        tr_labels.extend(labels)\n","        tr_preds.extend(predictions)\n","\n","        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n","        tr_accuracy += tmp_tr_accuracy\n","    \n","        # gradient clipping\n","        torch.nn.utils.clip_grad_norm_(\n","            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n","        )\n","        \n","        # backward pass\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    epoch_loss = tr_loss / nb_tr_steps\n","    tr_accuracy = tr_accuracy / nb_tr_steps\n","    print(f\"Training loss epoch: {epoch_loss}\")\n","    print(f\"Training accuracy epoch: {tr_accuracy}\")"],"id":"cjp-jXx4AmiV"},{"cell_type":"code","execution_count":7,"metadata":{"id":"JvdztU6FA8Bd","executionInfo":{"status":"ok","timestamp":1663564030766,"user_tz":240,"elapsed":10,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}}},"outputs":[],"source":["# Model testing function\n","def test(model, device, testing_loader):\n","    print(\"Validating model...\")\n","    # put model in evaluation mode\n","    model.eval()\n","    \n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_examples, nb_eval_steps = 0, 0\n","    eval_preds, eval_labels = [], []\n","    \n","    with torch.no_grad():\n","        for idx, batch in enumerate(testing_loader):\n","            \n","            ids = batch['input_ids'].to(device, dtype = torch.long)\n","            mask = batch['attention_mask'].to(device, dtype = torch.long)\n","            labels = batch['labels'].to(device, dtype = torch.long)\n","            \n","            loss, eval_logits = model(input_ids=ids, attention_mask=mask, labels=labels, return_dict = False)\n","            \n","            eval_loss += loss.item()\n","\n","            nb_eval_steps += 1\n","            nb_eval_examples += labels.size(0)\n","        \n","            # compute evaluation accuracy\n","            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","            \n","            # only compute accuracy at active labels\n","            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","        \n","            labels = torch.masked_select(flattened_targets, active_accuracy)\n","            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","            \n","            eval_labels.extend(labels)\n","            eval_preds.extend(predictions)\n","            \n","            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n","            eval_accuracy += tmp_eval_accuracy\n","\n","    labels = [idx2tag[id.item()] for id in eval_labels]\n","    predictions = [idx2tag[id.item()] for id in eval_preds]\n","    \n","    eval_loss = eval_loss / nb_eval_steps\n","    eval_accuracy = eval_accuracy / nb_eval_steps\n","    print(f\"Validation Loss: {eval_loss}\")\n","    print(f\"Validation Accuracy: {eval_accuracy}\")\n","\n","    return labels, predictions, eval_loss"],"id":"JvdztU6FA8Bd"},{"cell_type":"code","execution_count":8,"metadata":{"id":"jMknjbDrh6Fk","executionInfo":{"status":"ok","timestamp":1663564030767,"user_tz":240,"elapsed":10,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}}},"outputs":[],"source":["def create_train_and_validate_model(augmented_percentage):\n","\n","  augmented_X_train, augmented_y_train = generate_sentences(X_train, y_train, entities_dict, augmented_percentage)\n","\n","  maxlen_X_train = max([len(s) for s in augmented_X_train])\n","  maxlen_X_test = max([len(s) for s in X_test])\n","  maxlen_X_dev = max([len(s) for s in X_dev])\n","  maxlen_y_train = max([len(s) for s in augmented_y_train])\n","  maxlen_y_test = max([len(s) for s in y_test])\n","  maxlen_y_dev = max([len(s) for s in y_dev])\n","\n","  maxlen = max([maxlen_X_train, maxlen_X_test, maxlen_X_dev, maxlen_y_train, maxlen_y_test, maxlen_y_dev])\n","\n","  augmented_X_train_words = [[idx2word[word] for word in sentence] for sentence in augmented_X_train]\n","  X_dev_words = [[idx2word[word] for word in sentence] for sentence in X_dev]\n","  X_test_words = [[idx2word[word] for word in sentence] for sentence in X_test]\n","  augmented_y_train_tags = [','.join([idx2tag[tag] for tag in sentence]) for sentence in augmented_y_train]\n","  y_dev_tags = [','.join([idx2tag[tag] for tag in sentence]) for sentence in y_dev]\n","  y_test_tags = [','.join([idx2tag[tag] for tag in sentence]) for sentence in y_test]\n","\n","  new_train_df = pd.DataFrame({\"sentence\": augmented_X_train_words, \"word_labels\": augmented_y_train_tags}).reset_index(drop=True)\n","  new_test_df = pd.DataFrame({\"sentence\": X_test_words, \"word_labels\": y_test_tags}).reset_index(drop=True)\n","  new_val_df = pd.DataFrame({\"sentence\": X_dev_words, \"word_labels\": y_dev_tags}).reset_index(drop=True)\n","\n","  training_set = dataset(new_train_df, tokenizer, maxlen)\n","  testing_set = dataset(new_test_df, tokenizer, maxlen)\n","  validation_set = dataset(new_val_df, tokenizer, maxlen)\n","\n","  model, device, optimizer, training_loader, testing_loader, val_loader = create_model(maxlen, len(tag2idx), training_set, testing_set, validation_set)\n","\n","  training_start_time = time.clock()\n","  min_val_loss = 0\n","  MAX_PATIENCE = 5\n","  patience = 0\n","\n","  for epoch in range(100):\n","    print(f\"Training epoch: {epoch + 1}\")\n","    if patience == MAX_PATIENCE:\n","      print(\"Patience limit reached\")\n","      break\n","    train(model, device, optimizer, training_loader, epoch, TRAINING_STOP_LOSS_PERCENTAGE)\n","    labels, predictions, val_loss = test(model, device, val_loader)\n","    if ((min_val_loss == 0) or (min_val_loss != 0 and val_loss < min_val_loss)):\n","      min_val_loss = val_loss\n","      torch.save(model.state_dict(), 'checkpoint.pt')\n","      patience = 0\n","    else:\n","      patience = patience + 1\n","  print(f\"Training duration: {(time.clock() - training_start_time)/60} minutes\")\n","\n","  checkpoint = torch.load('checkpoint.pt')\n","  model.load_state_dict(checkpoint)\n","\n","  validation_start_time = time.clock()\n","  labels, predictions, test_loss = test(model, device, testing_loader)\n","  labels = [labels]\n","  predictions = [predictions]\n","  print(f\"Validation duration: {(time.clock() - validation_start_time)/60} minutes\")\n","\n","  print(\"F1-score (test): {:.1%}\".format(f1_score(labels, predictions)))\n","  print(classification_report(labels, predictions))"],"id":"jMknjbDrh6Fk"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["b538a6c7a2fe45f9a51565f066469c7c","1aa98f24e0024ff9ba67e1dddee39c08","6dfe806144ec40bb92d63fc132ecbe94","396b64ee561c479289f0238ae6bea65d","8913f1d345c045c99f3edd59a93a97a2","d67670e9322c40e2a4f67642052ad546","5c8d5f8e35e042ce937e4f5d5ee39578","2c4fd583a8714239b7d9f6e99654f8cb","b163a08dddc7447da9cf9d104dbac0c0","c4c1ec8567f3478cb9ee6d68ded7bb19","907861512bcb48cc96a447265d1f74d6"]},"id":"bM0wPLD5kaw4","outputId":"96b003d5-1bab-4a0e-fb79-16ba95ec44f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 13867\n","Points in y_train after augmentation: 13867\n","Device:  cuda\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b538a6c7a2fe45f9a51565f066469c7c","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/422M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.076934814453125\n","Training loss per 100 training steps: 0.4080217381810198\n","Training loss per 100 training steps: 0.2951848675028898\n","Training loss per 100 training steps: 0.25808347234397233\n","Training loss per 100 training steps: 0.2313445507086572\n","Training loss epoch: 0.22421084201898991\n","Training accuracy epoch: 0.9288875228380907\n","Validating model...\n","Validation Loss: 0.1388280393870233\n","Validation Accuracy: 0.9556781442237189\n","Training epoch: 2\n","Training loss per 100 training steps: 0.11301907896995544\n","Training loss per 100 training steps: 0.08628076536230522\n","Training loss per 100 training steps: 0.08588689805671054\n","Training loss per 100 training steps: 0.08693183727092126\n","Training loss per 100 training steps: 0.08774499719186762\n","Training loss epoch: 0.08861855633368003\n","Training accuracy epoch: 0.9712695545908171\n","Validating model...\n","Validation Loss: 0.12945744876640958\n","Validation Accuracy: 0.9598433256726073\n","Training epoch: 3\n","Training loss per 100 training steps: 0.025613073259592056\n","Training loss per 100 training steps: 0.051796959823753576\n","Training loss per 100 training steps: 0.055061017628759146\n","Training loss per 100 training steps: 0.055890230902863595\n","Training loss per 100 training steps: 0.05802180654859342\n","Training loss epoch: 0.05803325998785687\n","Training accuracy epoch: 0.9814945979842191\n","Validating model...\n","Validation Loss: 0.13356176468652564\n","Validation Accuracy: 0.9623680821063841\n","Training epoch: 4\n","Training loss per 100 training steps: 0.020793797448277473\n","Training loss per 100 training steps: 0.032315248966973166\n","Training loss per 100 training steps: 0.03397585342485291\n","Training loss per 100 training steps: 0.03543172743514898\n","Training loss per 100 training steps: 0.03738434313961358\n","Training loss epoch: 0.037467926152668515\n","Training accuracy epoch: 0.9882862365504671\n","Validating model...\n","Validation Loss: 0.1767598707954605\n","Validation Accuracy: 0.9608049035620184\n","Training epoch: 5\n","Training loss per 100 training steps: 0.027085529640316963\n","Training loss per 100 training steps: 0.024036278057207195\n","Training loss per 100 training steps: 0.02783789673695035\n","Training loss per 100 training steps: 0.030337452997555615\n","Training loss per 100 training steps: 0.031451991245968085\n","Training loss epoch: 0.03154812725357419\n","Training accuracy epoch: 0.9901807958944582\n","Validating model...\n","Validation Loss: 0.1703783700895774\n","Validation Accuracy: 0.962274376060928\n","Training epoch: 6\n","Training loss per 100 training steps: 0.017981402575969696\n","Training loss per 100 training steps: 0.020839941166894565\n","Training loss per 100 training steps: 0.021531809564443557\n","Training loss per 100 training steps: 0.021194725213077328\n","Training loss per 100 training steps: 0.022056948582867063\n","Training loss epoch: 0.022141911106185196\n","Training accuracy epoch: 0.9929021922717483\n","Validating model...\n","Validation Loss: 0.1807867834199365\n","Validation Accuracy: 0.9629132740385845\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0005309900152496994\n","Training loss per 100 training steps: 0.015122798043257087\n","Training loss per 100 training steps: 0.01455165508269235\n","Training loss per 100 training steps: 0.023274147666084186\n","Training loss per 100 training steps: 0.025685658678993063\n","Training loss epoch: 0.025926385821092204\n","Training accuracy epoch: 0.9921436378337808\n","Validating model...\n","Validation Loss: 0.17573306578900907\n","Validation Accuracy: 0.9597616871786625\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 34.009602216666664 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14138063228003578\n","Validation Accuracy: 0.9569631149239458\n","Validation duration: 3.252362416666665 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.3%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.87      0.85     12546\n","        test       0.84      0.89      0.87      9012\n","   treatment       0.82      0.88      0.85      9297\n","\n","   micro avg       0.83      0.88      0.85     30855\n","   macro avg       0.83      0.88      0.85     30855\n","weighted avg       0.83      0.88      0.85     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 13867\n","Points in y_train after augmentation: 13867\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8143049478530884\n","Training loss per 100 training steps: 0.37413781401839585\n","Training loss per 100 training steps: 0.28603435978664093\n","Training loss per 100 training steps: 0.2483358283053799\n","Training loss per 100 training steps: 0.22157397336719042\n","Training loss epoch: 0.21653434931201868\n","Training accuracy epoch: 0.9314346522752435\n","Validating model...\n","Validation Loss: 0.13457555362543502\n","Validation Accuracy: 0.9553875807426304\n","Training epoch: 2\n","Training loss per 100 training steps: 0.18992814421653748\n","Training loss per 100 training steps: 0.0974468673109123\n","Training loss per 100 training steps: 0.09419996528168074\n","Training loss per 100 training steps: 0.09075902505434331\n","Training loss per 100 training steps: 0.09120413413656843\n","Training loss epoch: 0.09178837652056379\n","Training accuracy epoch: 0.9703211201873695\n","Validating model...\n","Validation Loss: 0.1355926553392178\n","Validation Accuracy: 0.9586255929958234\n","Training epoch: 3\n","Training loss per 100 training steps: 0.031927380710840225\n","Training loss per 100 training steps: 0.04959108781917851\n","Training loss per 100 training steps: 0.05198228046928176\n","Training loss per 100 training steps: 0.05378775758223231\n","Training loss per 100 training steps: 0.055685079878340114\n","Training loss epoch: 0.0557067969069314\n","Training accuracy epoch: 0.9823953465594495\n","Validating model...\n","Validation Loss: 0.1425324594118185\n","Validation Accuracy: 0.959293555943835\n","Training epoch: 4\n","Training loss per 100 training steps: 0.006259052082896233\n","Training loss per 100 training steps: 0.03543147277133078\n","Training loss per 100 training steps: 0.03312788346541388\n","Training loss per 100 training steps: 0.03783117616440841\n","Training loss per 100 training steps: 0.040576053828005665\n","Training loss epoch: 0.040677151326755326\n","Training accuracy epoch: 0.9869433254324835\n","Validating model...\n","Validation Loss: 0.17056164733291446\n","Validation Accuracy: 0.9567117978280306\n","Training epoch: 5\n","Training loss per 100 training steps: 0.03282400965690613\n","Training loss per 100 training steps: 0.026344394665165333\n","Training loss per 100 training steps: 0.025892001584251017\n","Training loss per 100 training steps: 0.027096120902860035\n","Training loss per 100 training steps: 0.03054352236639922\n","Training loss epoch: 0.03138399610246536\n","Training accuracy epoch: 0.9902941120939356\n","Validating model...\n","Validation Loss: 0.16440331285166276\n","Validation Accuracy: 0.9586236811887696\n","Training epoch: 6\n","Training loss per 100 training steps: 0.008128962479531765\n","Training loss per 100 training steps: 0.025751714784845635\n","Training loss per 100 training steps: 0.024834541382096634\n","Training loss per 100 training steps: 0.024874457337219033\n","Training loss per 100 training steps: 0.024246086588563708\n","Training loss epoch: 0.024550606766211357\n","Training accuracy epoch: 0.9924338808273855\n","Validating model...\n","Validation Loss: 0.17230889304577338\n","Validation Accuracy: 0.960179072339336\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 29.040469016666673 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14598278968845046\n","Validation Accuracy: 0.9521206848364311\n","Validation duration: 3.144779666666659 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.83      0.82     12546\n","        test       0.83      0.84      0.84      9012\n","   treatment       0.82      0.85      0.84      9297\n","\n","   micro avg       0.82      0.84      0.83     30855\n","   macro avg       0.82      0.84      0.83     30855\n","weighted avg       0.82      0.84      0.83     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 13867\n","Points in y_train after augmentation: 13867\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.06630802154541\n","Training loss per 100 training steps: 0.3874796669524495\n","Training loss per 100 training steps: 0.28382027080625444\n","Training loss per 100 training steps: 0.24392433255366314\n","Training loss per 100 training steps: 0.22086368218770347\n","Training loss epoch: 0.21499848911701808\n","Training accuracy epoch: 0.932651672177646\n","Validating model...\n","Validation Loss: 0.13589180103660403\n","Validation Accuracy: 0.9570357003504698\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09892712533473969\n","Training loss per 100 training steps: 0.0874815386913643\n","Training loss per 100 training steps: 0.0918958594522147\n","Training loss per 100 training steps: 0.09044027827568724\n","Training loss per 100 training steps: 0.09001389425712408\n","Training loss epoch: 0.09015905640993593\n","Training accuracy epoch: 0.9708976956070456\n","Validating model...\n","Validation Loss: 0.13233992321924729\n","Validation Accuracy: 0.957347203672776\n","Training epoch: 3\n","Training loss per 100 training steps: 0.05278731882572174\n","Training loss per 100 training steps: 0.051921929398754445\n","Training loss per 100 training steps: 0.05276107354627097\n","Training loss per 100 training steps: 0.053310192029217746\n","Training loss per 100 training steps: 0.05935434557200221\n","Training loss epoch: 0.05962096020570754\n","Training accuracy epoch: 0.9813980004076516\n","Validating model...\n","Validation Loss: 0.15042051027057232\n","Validation Accuracy: 0.959978668734765\n","Training epoch: 4\n","Training loss per 100 training steps: 0.019627323374152184\n","Training loss per 100 training steps: 0.0382046458901524\n","Training loss per 100 training steps: 0.040000424486357926\n","Training loss per 100 training steps: 0.04153151365547778\n","Training loss per 100 training steps: 0.042623388058415375\n","Training loss epoch: 0.0430041026385192\n","Training accuracy epoch: 0.9863943776644309\n","Validating model...\n","Validation Loss: 0.1713590380167226\n","Validation Accuracy: 0.95766108042639\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0865107849240303\n","Training loss per 100 training steps: 0.031173384019939025\n","Training loss per 100 training steps: 0.032519368535899255\n","Training loss per 100 training steps: 0.032540700035989654\n","Training loss per 100 training steps: 0.0329379149235929\n","Training loss epoch: 0.03283333511940474\n","Training accuracy epoch: 0.990048205402955\n","Validating model...\n","Validation Loss: 0.1714734511945832\n","Validation Accuracy: 0.9599412024649582\n","Training epoch: 6\n","Training loss per 100 training steps: 0.01309346966445446\n","Training loss per 100 training steps: 0.019746836869617795\n","Training loss per 100 training steps: 0.019265051230334153\n","Training loss per 100 training steps: 0.021346532112371138\n","Training loss per 100 training steps: 0.022311899374980026\n","Training loss epoch: 0.022743061456876518\n","Training accuracy epoch: 0.9931334226389691\n","Validating model...\n","Validation Loss: 0.18704240580464337\n","Validation Accuracy: 0.9594831441958483\n","Training epoch: 7\n","Training loss per 100 training steps: 0.005129150580614805\n","Training loss per 100 training steps: 0.021838551843919248\n","Training loss per 100 training steps: 0.02278549116946391\n","Training loss per 100 training steps: 0.02103280523403987\n","Training loss per 100 training steps: 0.02301151911674957\n","Training loss epoch: 0.02306152606005555\n","Training accuracy epoch: 0.9930022254950273\n","Validating model...\n","Validation Loss: 0.181817136245308\n","Validation Accuracy: 0.9612730166724024\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 33.8943058 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14941491438636417\n","Validation Accuracy: 0.9528198172058301\n","Validation duration: 3.1389994999999997 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.87      0.85     12546\n","        test       0.84      0.87      0.85      9012\n","   treatment       0.81      0.84      0.82      9297\n","\n","   micro avg       0.82      0.86      0.84     30855\n","   macro avg       0.82      0.86      0.84     30855\n","weighted avg       0.82      0.86      0.84     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 13867\n","Points in y_train after augmentation: 13867\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.102623462677002\n","Training loss per 100 training steps: 0.38928973202658174\n","Training loss per 100 training steps: 0.29208727169837523\n","Training loss per 100 training steps: 0.25271550643929214\n","Training loss per 100 training steps: 0.22913776611226455\n","Training loss epoch: 0.2225197082737349\n","Training accuracy epoch: 0.9298474829802353\n","Validating model...\n","Validation Loss: 0.13276134337020384\n","Validation Accuracy: 0.9564774638445911\n","Training epoch: 2\n","Training loss per 100 training steps: 0.14430181682109833\n","Training loss per 100 training steps: 0.09075547741855135\n","Training loss per 100 training steps: 0.09050559890526\n","Training loss per 100 training steps: 0.09178678668181464\n","Training loss per 100 training steps: 0.09168092386002775\n","Training loss epoch: 0.09183380792071949\n","Training accuracy epoch: 0.9703141839325929\n","Validating model...\n","Validation Loss: 0.12935120322100527\n","Validation Accuracy: 0.9593036935451575\n","Training epoch: 3\n","Training loss per 100 training steps: 0.056814830750226974\n","Training loss per 100 training steps: 0.05168011672979239\n","Training loss per 100 training steps: 0.05806951132135012\n","Training loss per 100 training steps: 0.05819436635178486\n","Training loss per 100 training steps: 0.059615963881839984\n","Training loss epoch: 0.05938414440271423\n","Training accuracy epoch: 0.9807514002826246\n","Validating model...\n","Validation Loss: 0.138358825914465\n","Validation Accuracy: 0.9596862621466925\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03218914195895195\n","Training loss per 100 training steps: 0.03456783413859361\n","Training loss per 100 training steps: 0.035080092013883055\n","Training loss per 100 training steps: 0.03638485466761273\n","Training loss per 100 training steps: 0.04055894372062734\n","Training loss epoch: 0.04036002703362964\n","Training accuracy epoch: 0.9868996123741476\n","Validating model...\n","Validation Loss: 0.1505649107472076\n","Validation Accuracy: 0.9592026048511908\n","Training epoch: 5\n","Training loss per 100 training steps: 0.003007357707247138\n","Training loss per 100 training steps: 0.02499542061221039\n","Training loss per 100 training steps: 0.029747561822687067\n","Training loss per 100 training steps: 0.030323056699831867\n","Training loss per 100 training steps: 0.03128004578427595\n","Training loss epoch: 0.031325752580804486\n","Training accuracy epoch: 0.9903167074445359\n","Validating model...\n","Validation Loss: 0.1604070161142713\n","Validation Accuracy: 0.9610719532600734\n","Training epoch: 6\n","Training loss per 100 training steps: 0.006384983658790588\n","Training loss per 100 training steps: 0.023098030602467238\n","Training loss per 100 training steps: 0.023918646694432055\n","Training loss per 100 training steps: 0.023246259373447167\n","Training loss per 100 training steps: 0.024726003486090605\n","Training loss epoch: 0.025085792719994882\n","Training accuracy epoch: 0.9922059585560586\n","Validating model...\n","Validation Loss: 0.164544618349861\n","Validation Accuracy: 0.9607170738965801\n","Training epoch: 7\n","Training loss per 100 training steps: 0.09278915822505951\n","Training loss per 100 training steps: 0.0181959723681442\n","Training loss per 100 training steps: 0.019150938249403955\n","Training loss per 100 training steps: 0.019704164195522678\n","Training loss per 100 training steps: 0.02050276084653824\n","Training loss epoch: 0.02027555338918738\n","Training accuracy epoch: 0.9938720243993269\n","Validating model...\n","Validation Loss: 0.20020480842220706\n","Validation Accuracy: 0.957918357512439\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 33.887622983333344 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14688368227776932\n","Validation Accuracy: 0.9536429258651627\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validation duration: 3.12587443333332 minutes\n","F1-score (test): 84.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.88      0.83     12546\n","        test       0.82      0.88      0.85      9012\n","   treatment       0.82      0.87      0.84      9297\n","\n","   micro avg       0.81      0.88      0.84     30855\n","   macro avg       0.81      0.88      0.84     30855\n","weighted avg       0.81      0.88      0.84     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n","Points in X_train after augmentation: 13867\n","Points in y_train after augmentation: 13867\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.2285525798797607\n","Training loss per 100 training steps: 0.3873993071294067\n","Training loss per 100 training steps: 0.28745311841516946\n","Training loss per 100 training steps: 0.25036500811428325\n","Training loss per 100 training steps: 0.22292677850051415\n","Training loss epoch: 0.21860836529546343\n","Training accuracy epoch: 0.9314571698155706\n","Validating model...\n","Validation Loss: 0.13938939116604918\n","Validation Accuracy: 0.9546328689276871\n","Training epoch: 2\n","Training loss per 100 training steps: 0.08777526021003723\n","Training loss per 100 training steps: 0.09452362558666137\n","Training loss per 100 training steps: 0.09869803055954068\n","Training loss per 100 training steps: 0.10220699071995543\n","Training loss per 100 training steps: 0.09985282322963203\n","Training loss epoch: 0.0989146226274562\n","Training accuracy epoch: 0.9682542506897998\n","Validating model...\n","Validation Loss: 0.12688752672598733\n","Validation Accuracy: 0.9607682072053384\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04813227429986\n","Training loss per 100 training steps: 0.051240543963959315\n","Training loss per 100 training steps: 0.051276057022646884\n","Training loss per 100 training steps: 0.05495141806588369\n","Training loss per 100 training steps: 0.05810042826848992\n","Training loss epoch: 0.060310534522375135\n","Training accuracy epoch: 0.9804411237724201\n","Validating model...\n","Validation Loss: 0.15914472482808226\n","Validation Accuracy: 0.9531094399191959\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03255434334278107\n","Training loss per 100 training steps: 0.04105895888383067\n","Training loss per 100 training steps: 0.04261373652872717\n","Training loss per 100 training steps: 0.04287861401998002\n","Training loss per 100 training steps: 0.04486917158149815\n","Training loss epoch: 0.04425283754083504\n","Training accuracy epoch: 0.9865677956726818\n","Validating model...\n","Validation Loss: 0.16705954713480814\n","Validation Accuracy: 0.9602947814300423\n","Training epoch: 5\n","Training loss per 100 training steps: 0.04071205481886864\n","Training loss per 100 training steps: 0.0315787023541951\n","Training loss per 100 training steps: 0.029585460386243625\n","Training loss per 100 training steps: 0.028251947203118886\n","Training loss per 100 training steps: 0.032389673468844964\n","Training loss epoch: 0.03359887801048513\n","Training accuracy epoch: 0.9892682262684697\n","Validating model...\n","Validation Loss: 0.1632686046907654\n","Validation Accuracy: 0.9568669211722864\n","Training epoch: 6\n","Training loss per 100 training steps: 0.029888730496168137\n","Training loss per 100 training steps: 0.027603785143150848\n","Training loss per 100 training steps: 0.024666702056556144\n","Training loss per 100 training steps: 0.02480341573311573\n","Training loss per 100 training steps: 0.025700623672507805\n","Training loss epoch: 0.027164495413965217\n","Training accuracy epoch: 0.9917861061884734\n","Validating model...\n","Validation Loss: 0.1824730324571009\n","Validation Accuracy: 0.9534119771610521\n","Training epoch: 7\n","Training loss per 100 training steps: 0.015905505046248436\n","Training loss per 100 training steps: 0.013913028919608286\n","Training loss per 100 training steps: 0.017040929548843158\n","Training loss per 100 training steps: 0.017993853615435998\n","Training loss per 100 training steps: 0.019450923677608183\n","Training loss epoch: 0.019516404655996456\n","Training accuracy epoch: 0.993850473951113\n","Validating model...\n","Validation Loss: 0.2021833438631873\n","Validation Accuracy: 0.9597209813741742\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 33.81987441666667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1537106890270176\n","Validation Accuracy: 0.9551800258874441\n","Validation duration: 3.127663916666673 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.84      0.86      0.85     12546\n","        test       0.84      0.89      0.87      9012\n","   treatment       0.82      0.87      0.84      9297\n","\n","   micro avg       0.83      0.87      0.85     30855\n","   macro avg       0.83      0.88      0.85     30855\n","weighted avg       0.83      0.87      0.85     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n","Points in X_train after augmentation: 13867\n","Points in y_train after augmentation: 13867\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.973937749862671\n","Training loss per 100 training steps: 0.3897660719138561\n","Training loss per 100 training steps: 0.29490352711125983\n","Training loss per 100 training steps: 0.24857329394037145\n","Training loss per 100 training steps: 0.2237313110613615\n","Training loss epoch: 0.21955173390097746\n","Training accuracy epoch: 0.9302220028496948\n","Validating model...\n","Validation Loss: 0.13299755329967705\n","Validation Accuracy: 0.9563139802462095\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0515083484351635\n","Training loss per 100 training steps: 0.08164166607479058\n","Training loss per 100 training steps: 0.08782705190864887\n","Training loss per 100 training steps: 0.08933932172208776\n","Training loss per 100 training steps: 0.08899400379401899\n","Training loss epoch: 0.08835121379276815\n","Training accuracy epoch: 0.9721737036474309\n","Validating model...\n","Validation Loss: 0.13802187014129255\n","Validation Accuracy: 0.9572012897606599\n","Training epoch: 3\n","Training loss per 100 training steps: 0.07547798752784729\n","Training loss per 100 training steps: 0.05342812758713666\n","Training loss per 100 training steps: 0.05566611480597981\n","Training loss per 100 training steps: 0.05416297226017991\n","Training loss per 100 training steps: 0.05625725996929065\n","Training loss epoch: 0.05655356321573978\n","Training accuracy epoch: 0.9813132683101894\n","Validating model...\n","Validation Loss: 0.1458964663279521\n","Validation Accuracy: 0.9586083963521029\n","Training epoch: 4\n","Training loss per 100 training steps: 0.019157355651259422\n","Training loss per 100 training steps: 0.03170381416105619\n","Training loss per 100 training steps: 0.03761563873826642\n","Training loss per 100 training steps: 0.03991051543151273\n","Training loss per 100 training steps: 0.0418393524419377\n","Training loss epoch: 0.04151942578202311\n","Training accuracy epoch: 0.9869384859630452\n","Validating model...\n","Validation Loss: 0.15768164007428598\n","Validation Accuracy: 0.961680746801001\n","Training epoch: 5\n","Training loss per 100 training steps: 0.045789025723934174\n","Training loss per 100 training steps: 0.025626081860356843\n","Training loss per 100 training steps: 0.026876467800194127\n","Training loss per 100 training steps: 0.027974472777412097\n","Training loss per 100 training steps: 0.030071354267492825\n","Training loss epoch: 0.030084569515871778\n","Training accuracy epoch: 0.9903406522609495\n","Validating model...\n","Validation Loss: 0.18329117262082828\n","Validation Accuracy: 0.9590770413365947\n","Training epoch: 6\n","Training loss per 100 training steps: 0.02815590426325798\n","Training loss per 100 training steps: 0.029622579710373638\n","Training loss per 100 training steps: 0.026260254171964207\n","Training loss per 100 training steps: 0.025584334902275057\n","Training loss per 100 training steps: 0.027236373588922398\n","Training loss epoch: 0.02750198838066563\n","Training accuracy epoch: 0.9911546039504813\n","Validating model...\n","Validation Loss: 0.1855817548809694\n","Validation Accuracy: 0.9592401625969722\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 28.966353033333327 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14091209392710072\n","Validation Accuracy: 0.9543794992535086\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validation duration: 3.125490816666661 minutes\n","F1-score (test): 84.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.84      0.83     12546\n","        test       0.83      0.89      0.86      9012\n","   treatment       0.84      0.84      0.84      9297\n","\n","   micro avg       0.83      0.86      0.84     30855\n","   macro avg       0.83      0.86      0.84     30855\n","weighted avg       0.83      0.86      0.84     30855\n","\n","!!!!!! Starting model number 7 !!!!!!\n","Points in X_train after augmentation: 13867\n","Points in y_train after augmentation: 13867\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.6050825119018555\n","Training loss per 100 training steps: 0.4297834432656222\n","Training loss per 100 training steps: 0.31415602702888384\n","Training loss per 100 training steps: 0.26566370118075233\n","Training loss per 100 training steps: 0.23633417874073\n","Training loss epoch: 0.23034838750563597\n","Training accuracy epoch: 0.9281541348656105\n","Validating model...\n","Validation Loss: 0.14131459617963085\n","Validation Accuracy: 0.9559687110464874\n","Training epoch: 2\n","Training loss per 100 training steps: 0.2347610890865326\n","Training loss per 100 training steps: 0.09574634406604979\n","Training loss per 100 training steps: 0.09518489913449656\n","Training loss per 100 training steps: 0.09519721602284631\n","Training loss per 100 training steps: 0.0958907101303339\n","Training loss epoch: 0.09509303697925661\n","Training accuracy epoch: 0.9697314062386214\n","Validating model...\n","Validation Loss: 0.14251800512822418\n","Validation Accuracy: 0.9604786354608336\n","Training epoch: 3\n","Training loss per 100 training steps: 0.027266502380371094\n","Training loss per 100 training steps: 0.05415225414891202\n","Training loss per 100 training steps: 0.05766879624932708\n","Training loss per 100 training steps: 0.059935405652388384\n","Training loss per 100 training steps: 0.06127984684536656\n","Training loss epoch: 0.06142868500520488\n","Training accuracy epoch: 0.9802351176160831\n","Validating model...\n","Validation Loss: 0.14757236707713697\n","Validation Accuracy: 0.9598454312423308\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01442890614271164\n","Training loss per 100 training steps: 0.032980859696883524\n","Training loss per 100 training steps: 0.037930744146437045\n","Training loss per 100 training steps: 0.038375515172852086\n","Training loss per 100 training steps: 0.03940013375195983\n","Training loss epoch: 0.039799450623614\n","Training accuracy epoch: 0.9871277743986241\n","Validating model...\n","Validation Loss: 0.17929580444832902\n","Validation Accuracy: 0.9565069826619315\n","Training epoch: 5\n","Training loss per 100 training steps: 0.03859522566199303\n","Training loss per 100 training steps: 0.0304964133976304\n","Training loss per 100 training steps: 0.032102299878484945\n","Training loss per 100 training steps: 0.03482040484896876\n","Training loss per 100 training steps: 0.03575744731479471\n","Training loss epoch: 0.03582579887006432\n","Training accuracy epoch: 0.9890764017912771\n","Validating model...\n","Validation Loss: 0.17170500416647305\n","Validation Accuracy: 0.9590951662452226\n","Training epoch: 6\n","Training loss per 100 training steps: 0.009151789359748363\n","Training loss per 100 training steps: 0.029122995150432287\n","Training loss per 100 training steps: 0.029028344609825618\n","Training loss per 100 training steps: 0.029506915986098572\n","Training loss per 100 training steps: 0.029078455811988868\n","Training loss epoch: 0.0297197302447177\n","Training accuracy epoch: 0.9910776473007247\n","Validating model...\n","Validation Loss: 0.1647857033296839\n","Validation Accuracy: 0.9591568917998281\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 28.978582133333354 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14358686662011746\n","Validation Accuracy: 0.9553179616360821\n","Validation duration: 3.1274540500000207 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.84      0.83      0.83     12546\n","        test       0.80      0.85      0.83      9012\n","   treatment       0.87      0.84      0.85      9297\n","\n","   micro avg       0.84      0.84      0.84     30855\n","   macro avg       0.84      0.84      0.84     30855\n","weighted avg       0.84      0.84      0.84     30855\n","\n","!!!!!! Starting model number 8 !!!!!!\n","Points in X_train after augmentation: 13867\n","Points in y_train after augmentation: 13867\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7298275232315063\n","Training loss per 100 training steps: 0.3798373255251658\n","Training loss per 100 training steps: 0.2764290312851839\n","Training loss per 100 training steps: 0.2419596537081308\n","Training loss per 100 training steps: 0.22208987145761303\n","Training loss epoch: 0.21660299896163873\n","Training accuracy epoch: 0.9311025849343629\n","Validating model...\n","Validation Loss: 0.14293226679520948\n","Validation Accuracy: 0.9533801540938055\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04738463833928108\n","Training loss per 100 training steps: 0.08779536662992127\n","Training loss per 100 training steps: 0.0844905780632957\n","Training loss per 100 training steps: 0.08744158803259465\n","Training loss per 100 training steps: 0.08931226506852487\n","Training loss epoch: 0.08981154420121235\n","Training accuracy epoch: 0.9711434610330614\n","Validating model...\n","Validation Loss: 0.12930076540290536\n","Validation Accuracy: 0.9609076757196967\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04672984406352043\n","Training loss per 100 training steps: 0.05129587534114276\n","Training loss per 100 training steps: 0.052962334926207714\n","Training loss per 100 training steps: 0.055356484209728794\n","Training loss per 100 training steps: 0.05696980838554719\n","Training loss epoch: 0.057367575536203065\n","Training accuracy epoch: 0.9819385119717258\n","Validating model...\n","Validation Loss: 0.14617689405023665\n","Validation Accuracy: 0.9572117421892747\n","Training epoch: 4\n","Training loss per 100 training steps: 0.036615293473005295\n","Training loss per 100 training steps: 0.043530337028389814\n","Training loss per 100 training steps: 0.04009096191348091\n","Training loss per 100 training steps: 0.03854125238060827\n","Training loss per 100 training steps: 0.039702056158691684\n","Training loss epoch: 0.04024303176768622\n","Training accuracy epoch: 0.9873454990567125\n","Validating model...\n","Validation Loss: 0.15127328483315258\n","Validation Accuracy: 0.9610954964985097\n","Training epoch: 5\n","Training loss per 100 training steps: 0.01747332699596882\n","Training loss per 100 training steps: 0.020787521780671385\n","Training loss per 100 training steps: 0.02183396428063586\n","Training loss per 100 training steps: 0.02333003515841755\n","Training loss per 100 training steps: 0.024957001730660323\n","Training loss epoch: 0.025131786203501136\n","Training accuracy epoch: 0.9923158238728151\n","Validating model...\n","Validation Loss: 0.16772887405830544\n","Validation Accuracy: 0.9621498109163593\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0268459003418684\n","Training loss per 100 training steps: 0.024834475212610594\n","Training loss per 100 training steps: 0.02598690237578894\n","Training loss per 100 training steps: 0.02917759103872241\n","Training loss per 100 training steps: 0.029317054188313273\n","Training loss epoch: 0.02924519880864692\n","Training accuracy epoch: 0.9905810109402469\n","Validating model...\n","Validation Loss: 0.17207248985477083\n","Validation Accuracy: 0.9604075358935509\n","Training epoch: 7\n","Training loss per 100 training steps: 0.004128355998545885\n","Training loss per 100 training steps: 0.019221042430415603\n","Training loss per 100 training steps: 0.018392874679727413\n","Training loss per 100 training steps: 0.020023854401626275\n","Training loss per 100 training steps: 0.022777447972982017\n","Training loss epoch: 0.022288584269337518\n","Training accuracy epoch: 0.9930424817962777\n","Validating model...\n","Validation Loss: 0.18195072370399903\n","Validation Accuracy: 0.9632754182753847\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 33.84443705000003 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13871456233189544\n","Validation Accuracy: 0.9573101544344467\n","Validation duration: 3.1272170000000186 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.88      0.86     12546\n","        test       0.85      0.86      0.86      9012\n","   treatment       0.85      0.86      0.86      9297\n","\n","   micro avg       0.85      0.87      0.86     30855\n","   macro avg       0.85      0.87      0.86     30855\n","weighted avg       0.85      0.87      0.86     30855\n","\n","!!!!!! Starting model number 9 !!!!!!\n","Points in X_train after augmentation: 13867\n","Points in y_train after augmentation: 13867\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.4036762714385986\n","Training loss per 100 training steps: 0.43058609837057565\n","Training loss per 100 training steps: 0.3148356346941706\n","Training loss per 100 training steps: 0.2655840052718736\n","Training loss per 100 training steps: 0.2384346826303927\n","Training loss epoch: 0.23309644409519736\n","Training accuracy epoch: 0.925966111577446\n","Validating model...\n","Validation Loss: 0.13416168103357415\n","Validation Accuracy: 0.9558855484718062\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09708733856678009\n","Training loss per 100 training steps: 0.0917767636883672\n","Training loss per 100 training steps: 0.0931599054355823\n","Training loss per 100 training steps: 0.0959946013912806\n","Training loss per 100 training steps: 0.09843073467586998\n","Training loss epoch: 0.0974213495198208\n","Training accuracy epoch: 0.9682048822287194\n","Validating model...\n","Validation Loss: 0.1416319382751917\n","Validation Accuracy: 0.9573427188638832\n","Training epoch: 3\n","Training loss per 100 training steps: 0.06435159593820572\n","Training loss per 100 training steps: 0.055684977874971266\n","Training loss per 100 training steps: 0.056502907799871924\n","Training loss per 100 training steps: 0.05998667309051411\n","Training loss per 100 training steps: 0.061683866485112586\n","Training loss epoch: 0.061709001403374916\n","Training accuracy epoch: 0.9807103179837124\n","Validating model...\n","Validation Loss: 0.14975471274516025\n","Validation Accuracy: 0.9590411366654406\n","Training epoch: 4\n","Training loss per 100 training steps: 0.014246034435927868\n","Training loss per 100 training steps: 0.03666019971058289\n","Training loss per 100 training steps: 0.04099495084933121\n","Training loss per 100 training steps: 0.044612101822986305\n","Training loss per 100 training steps: 0.04816312900920888\n","Training loss epoch: 0.04853628272370946\n","Training accuracy epoch: 0.9850002421395069\n","Validating model...\n","Validation Loss: 0.1567335608369949\n","Validation Accuracy: 0.9587540842095252\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0416625551879406\n","Training loss per 100 training steps: 0.034092529663023084\n","Training loss per 100 training steps: 0.03466491470465539\n","Training loss per 100 training steps: 0.03516418129504284\n","Training loss per 100 training steps: 0.03434911461929068\n","Training loss epoch: 0.034742721123889105\n","Training accuracy epoch: 0.9893636719329127\n","Validating model...\n","Validation Loss: 0.1652442228408869\n","Validation Accuracy: 0.9608903400704562\n","Training epoch: 6\n","Training loss per 100 training steps: 0.01993557997047901\n","Training loss per 100 training steps: 0.026661728192950682\n","Training loss per 100 training steps: 0.02648111101962737\n","Training loss per 100 training steps: 0.0257021404289953\n","Training loss per 100 training steps: 0.026945945332140342\n","Training loss epoch: 0.026819431030648558\n","Training accuracy epoch: 0.9918284952013953\n","Validating model...\n","Validation Loss: 0.16672146651143957\n","Validation Accuracy: 0.961812030310033\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 28.961335183333297 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14065284708825251\n","Validation Accuracy: 0.9542993186795471\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validation duration: 3.1309052166666635 minutes\n","F1-score (test): 84.3%\n","              precision    recall  f1-score   support\n","\n","     problem       0.84      0.83      0.84     12546\n","        test       0.82      0.89      0.85      9012\n","   treatment       0.84      0.84      0.84      9297\n","\n","   micro avg       0.83      0.85      0.84     30855\n","   macro avg       0.83      0.86      0.84     30855\n","weighted avg       0.83      0.85      0.84     30855\n","\n","!!!!!! Starting model number 10 !!!!!!\n","Points in X_train after augmentation: 13867\n","Points in y_train after augmentation: 13867\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1263368129730225\n","Training loss per 100 training steps: 0.4012833702387196\n","Training loss per 100 training steps: 0.2966544816075866\n","Training loss per 100 training steps: 0.25272294382666827\n","Training loss per 100 training steps: 0.22624474801030242\n","Training loss epoch: 0.22091473080217838\n","Training accuracy epoch: 0.9297480212240524\n","Validating model...\n","Validation Loss: 0.12482300579741404\n","Validation Accuracy: 0.9597538504673202\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06116035208106041\n","Training loss per 100 training steps: 0.08801792373899187\n","Training loss per 100 training steps: 0.08800198915252341\n","Training loss per 100 training steps: 0.08773318050658188\n","Training loss per 100 training steps: 0.08791331206901264\n","Training loss epoch: 0.08864978062255043\n","Training accuracy epoch: 0.9712182478272289\n","Validating model...\n","Validation Loss: 0.12517240300000487\n","Validation Accuracy: 0.9586320453031919\n","Training epoch: 3\n","Training loss per 100 training steps: 0.07807692140340805\n","Training loss per 100 training steps: 0.05159839036146013\n","Training loss per 100 training steps: 0.051114682775380005\n","Training loss per 100 training steps: 0.05779194738870592\n","Training loss per 100 training steps: 0.05997238165938163\n","Training loss epoch: 0.0593429358090244\n","Training accuracy epoch: 0.9809077611306576\n","Validating model...\n","Validation Loss: 0.1493989808376056\n","Validation Accuracy: 0.9615978579451814\n","Training epoch: 4\n","Training loss per 100 training steps: 0.015241429209709167\n","Training loss per 100 training steps: 0.03276554553188605\n","Training loss per 100 training steps: 0.03563826340042166\n","Training loss per 100 training steps: 0.03710635196482546\n","Training loss per 100 training steps: 0.03777737905413024\n","Training loss epoch: 0.03912900602938565\n","Training accuracy epoch: 0.987972851568709\n","Validating model...\n","Validation Loss: 0.15009619761258364\n","Validation Accuracy: 0.960476913350512\n","Training epoch: 5\n","Training loss per 100 training steps: 0.07951492816209793\n","Training loss per 100 training steps: 0.03069407234457091\n","Training loss per 100 training steps: 0.030933046295882123\n","Training loss per 100 training steps: 0.03136663778222466\n","Training loss per 100 training steps: 0.03239710525838319\n","Training loss epoch: 0.03207979506350547\n","Training accuracy epoch: 0.9896604815538278\n","Validating model...\n","Validation Loss: 0.1621744334758199\n","Validation Accuracy: 0.9620239571722622\n","Training epoch: 6\n","Training loss per 100 training steps: 0.009131994098424911\n","Training loss per 100 training steps: 0.026991388669449577\n","Training loss per 100 training steps: 0.027541949282821953\n","Training loss per 100 training steps: 0.02817661180764288\n","Training loss per 100 training steps: 0.02797221346814046\n","Training loss epoch: 0.027474591645309143\n","Training accuracy epoch: 0.9916868657059965\n","Validating model...\n","Validation Loss: 0.19299384037202055\n","Validation Accuracy: 0.9588405680585402\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 28.968808633333357 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1432377098697341\n","Validation Accuracy: 0.9537730481857639\n","Validation duration: 3.130216566666665 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.87      0.85     12546\n","        test       0.87      0.87      0.87      9012\n","   treatment       0.78      0.88      0.83      9297\n","\n","   micro avg       0.82      0.88      0.85     30855\n","   macro avg       0.83      0.88      0.85     30855\n","weighted avg       0.83      0.88      0.85     30855\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"bM0wPLD5kaw4"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jhz9BiIwGCsV","executionInfo":{"status":"ok","timestamp":1663057850588,"user_tz":240,"elapsed":962803,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}},"outputId":"9a3b2ef1-9dba-4221-e7c1-0f560609f16d"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 25.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 17334\n","Points in y_train after augmentation: 17334\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.005070447921753\n","Training loss per 100 training steps: 0.3908421085907681\n","Training loss per 100 training steps: 0.2987817872445382\n","Training loss per 100 training steps: 0.25533125481484736\n","Training loss per 100 training steps: 0.23252067196547538\n","Training loss per 100 training steps: 0.21544344907630228\n","Training loss epoch: 0.2102179059421994\n","Training accuracy epoch: 0.9327923753346463\n","Validating model...\n","Validation Loss: 0.13639844519799793\n","Validation Accuracy: 0.956424719964669\n","Training epoch: 2\n","Training loss per 100 training steps: 0.100233294069767\n","Training loss per 100 training steps: 0.08337432946917592\n","Training loss per 100 training steps: 0.09040407958991863\n","Training loss per 100 training steps: 0.09194432709681681\n","Training loss per 100 training steps: 0.09313949383446886\n","Training loss per 100 training steps: 0.09256132161467821\n","Training loss epoch: 0.09256557064436761\n","Training accuracy epoch: 0.9706408872147098\n","Validating model...\n","Validation Loss: 0.1322770785153299\n","Validation Accuracy: 0.9575777803773995\n","Training epoch: 3\n","Training loss per 100 training steps: 0.058733098208904266\n","Training loss per 100 training steps: 0.04904326598279842\n","Training loss per 100 training steps: 0.05445941227641123\n","Training loss per 100 training steps: 0.05638527266984416\n","Training loss per 100 training steps: 0.05750318982770801\n","Training loss per 100 training steps: 0.05611112008815605\n","Training loss epoch: 0.05662377738235759\n","Training accuracy epoch: 0.981831879554618\n","Validating model...\n","Validation Loss: 0.1468829819327825\n","Validation Accuracy: 0.9601870280466702\n","Training epoch: 4\n","Training loss per 100 training steps: 0.04370114207267761\n","Training loss per 100 training steps: 0.03557146459790223\n","Training loss per 100 training steps: 0.03341327292325707\n","Training loss per 100 training steps: 0.035547129687639664\n","Training loss per 100 training steps: 0.036492600948770444\n","Training loss per 100 training steps: 0.036544861001503504\n","Training loss epoch: 0.03689603569120086\n","Training accuracy epoch: 0.988702872892369\n","Validating model...\n","Validation Loss: 0.17374432415931257\n","Validation Accuracy: 0.9512885368792141\n","Training epoch: 5\n","Training loss per 100 training steps: 0.04791257157921791\n","Training loss per 100 training steps: 0.021599215545258163\n","Training loss per 100 training steps: 0.025057085819857484\n","Training loss per 100 training steps: 0.027151999376293433\n","Training loss per 100 training steps: 0.029263305469669234\n","Training loss per 100 training steps: 0.03021132935860014\n","Training loss epoch: 0.03204482175797272\n","Training accuracy epoch: 0.9898359773534832\n","Validating model...\n","Validation Loss: 0.14777290634810925\n","Validation Accuracy: 0.9573399560170703\n","Training epoch: 6\n","Training loss per 100 training steps: 0.09571611881256104\n","Training loss per 100 training steps: 0.025347234069203754\n","Training loss per 100 training steps: 0.0248726077136857\n","Training loss per 100 training steps: 0.0231678881991865\n","Training loss per 100 training steps: 0.023646574007565542\n","Training loss per 100 training steps: 0.02440847124334633\n","Training loss epoch: 0.024556193535338153\n","Training accuracy epoch: 0.992358648361359\n","Validating model...\n","Validation Loss: 0.17285112012177706\n","Validation Accuracy: 0.961263821555119\n","Training epoch: 7\n","Training loss per 100 training steps: 0.03393930941820145\n","Training loss per 100 training steps: 0.017677696639588934\n","Training loss per 100 training steps: 0.01900410973692813\n","Training loss per 100 training steps: 0.01830129170182325\n","Training loss per 100 training steps: 0.019235170973979282\n","Training loss per 100 training steps: 0.02091886899482827\n","Training loss epoch: 0.02150532576211254\n","Training accuracy epoch: 0.9936101862890213\n","Validating model...\n","Validation Loss: 0.19730195635324949\n","Validation Accuracy: 0.9577585303684941\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 41.75628318333335 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14563924031810732\n","Validation Accuracy: 0.9556599201460708\n","Validation duration: 3.1208764833333285 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 84.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.86      0.84     12546\n","        test       0.83      0.89      0.86      9012\n","   treatment       0.81      0.88      0.84      9297\n","\n","   micro avg       0.82      0.87      0.84     30855\n","   macro avg       0.82      0.88      0.85     30855\n","weighted avg       0.82      0.87      0.84     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 17334\n","Points in y_train after augmentation: 17334\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.005798101425171\n","Training loss per 100 training steps: 0.39815102429083077\n","Training loss per 100 training steps: 0.2948392204458441\n","Training loss per 100 training steps: 0.2509693363526731\n","Training loss per 100 training steps: 0.22755043762283134\n","Training loss per 100 training steps: 0.21433486827387066\n","Training loss epoch: 0.20950509120823602\n","Training accuracy epoch: 0.9341743841045647\n","Validating model...\n","Validation Loss: 0.1441662750364124\n","Validation Accuracy: 0.9525762241642008\n","Training epoch: 2\n","Training loss per 100 training steps: 0.1541123241186142\n","Training loss per 100 training steps: 0.08647190201289878\n","Training loss per 100 training steps: 0.08852030326199917\n","Training loss per 100 training steps: 0.09046506449468805\n","Training loss per 100 training steps: 0.08897571122166968\n","Training loss per 100 training steps: 0.08934552545385982\n","Training loss epoch: 0.09015326338864836\n","Training accuracy epoch: 0.9708954935615561\n","Validating model...\n","Validation Loss: 0.14109882884114594\n","Validation Accuracy: 0.9518218608012693\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03838171437382698\n","Training loss per 100 training steps: 0.04365040289035233\n","Training loss per 100 training steps: 0.04849837499842122\n","Training loss per 100 training steps: 0.052005453904676084\n","Training loss per 100 training steps: 0.05442989778070899\n","Training loss per 100 training steps: 0.05507616749676521\n","Training loss epoch: 0.05514206370421276\n","Training accuracy epoch: 0.9824403524328821\n","Validating model...\n","Validation Loss: 0.15610057908993263\n","Validation Accuracy: 0.9583624952412781\n","Training epoch: 4\n","Training loss per 100 training steps: 0.10147266834974289\n","Training loss per 100 training steps: 0.028158542197566517\n","Training loss per 100 training steps: 0.030240648731922927\n","Training loss per 100 training steps: 0.033573230518108586\n","Training loss per 100 training steps: 0.03428958793184685\n","Training loss per 100 training steps: 0.03596054971498807\n","Training loss epoch: 0.035713358580330694\n","Training accuracy epoch: 0.9887402000533164\n","Validating model...\n","Validation Loss: 0.18898907792452094\n","Validation Accuracy: 0.9595864971271838\n","Training epoch: 5\n","Training loss per 100 training steps: 0.017149249091744423\n","Training loss per 100 training steps: 0.02261291659554688\n","Training loss per 100 training steps: 0.022218743658019926\n","Training loss per 100 training steps: 0.023872041106347823\n","Training loss per 100 training steps: 0.025249044308984683\n","Training loss per 100 training steps: 0.02692738497613961\n","Training loss epoch: 0.027790912679384543\n","Training accuracy epoch: 0.9913737142525056\n","Validating model...\n","Validation Loss: 0.16297413124672633\n","Validation Accuracy: 0.9597282922315908\n","Training epoch: 6\n","Training loss per 100 training steps: 0.008387356996536255\n","Training loss per 100 training steps: 0.02145864470460738\n","Training loss per 100 training steps: 0.026048142543474945\n","Training loss per 100 training steps: 0.02424153205656301\n","Training loss per 100 training steps: 0.024058538985478127\n","Training loss per 100 training steps: 0.02449735993414396\n","Training loss epoch: 0.024973076066505714\n","Training accuracy epoch: 0.9925431125007792\n","Validating model...\n","Validation Loss: 0.1959368564527143\n","Validation Accuracy: 0.9593527022922645\n","Training epoch: 7\n","Training loss per 100 training steps: 0.017834648489952087\n","Training loss per 100 training steps: 0.01688516489518253\n","Training loss per 100 training steps: 0.01666732021434863\n","Training loss per 100 training steps: 0.020432685928665213\n","Training loss per 100 training steps: 0.021567799936384288\n","Training loss per 100 training steps: 0.020846856474976787\n","Training loss epoch: 0.02102690084422406\n","Training accuracy epoch: 0.9937700239741679\n","Validating model...\n","Validation Loss: 0.20287570173477198\n","Validation Accuracy: 0.9575270566457865\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 41.75378849999997 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15187195129153594\n","Validation Accuracy: 0.9519912669904955\n","Validation duration: 3.1299746666666883 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 83.8%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.84      0.83     12546\n","        test       0.80      0.90      0.85      9012\n","   treatment       0.84      0.85      0.84      9297\n","\n","   micro avg       0.82      0.86      0.84     30855\n","   macro avg       0.82      0.86      0.84     30855\n","weighted avg       0.82      0.86      0.84     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 17334\n","Points in y_train after augmentation: 17334\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.284592628479004\n","Training loss per 100 training steps: 0.42173181267658083\n","Training loss per 100 training steps: 0.30737891040779464\n","Training loss per 100 training steps: 0.26293351319293645\n","Training loss per 100 training steps: 0.23499755579002776\n","Training loss per 100 training steps: 0.21639090651895354\n","Training loss epoch: 0.2120181765592901\n","Training accuracy epoch: 0.9329014150505417\n","Validating model...\n","Validation Loss: 0.15001367695339315\n","Validation Accuracy: 0.9509544634936853\n","Training epoch: 2\n","Training loss per 100 training steps: 0.08683957904577255\n","Training loss per 100 training steps: 0.08802129462877713\n","Training loss per 100 training steps: 0.0859988742225354\n","Training loss per 100 training steps: 0.08485790677492405\n","Training loss per 100 training steps: 0.08580225901190479\n","Training loss per 100 training steps: 0.08707434485876513\n","Training loss epoch: 0.08671406427968802\n","Training accuracy epoch: 0.9727825921977659\n","Validating model...\n","Validation Loss: 0.1424616127964351\n","Validation Accuracy: 0.9593941767584241\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03310921788215637\n","Training loss per 100 training steps: 0.045219947399553095\n","Training loss per 100 training steps: 0.049219441108998674\n","Training loss per 100 training steps: 0.05134741905798201\n","Training loss per 100 training steps: 0.05164426766995554\n","Training loss per 100 training steps: 0.05183411126922883\n","Training loss epoch: 0.0518407719158241\n","Training accuracy epoch: 0.9832588115076533\n","Validating model...\n","Validation Loss: 0.14475485026933155\n","Validation Accuracy: 0.9580373556948654\n","Training epoch: 4\n","Training loss per 100 training steps: 0.05905831605195999\n","Training loss per 100 training steps: 0.036186988359446275\n","Training loss per 100 training steps: 0.036904571638141405\n","Training loss per 100 training steps: 0.040122446135317666\n","Training loss per 100 training steps: 0.04053609006622449\n","Training loss per 100 training steps: 0.04186795937629814\n","Training loss epoch: 0.0419078345025625\n","Training accuracy epoch: 0.9866883743489971\n","Validating model...\n","Validation Loss: 0.1539014723853438\n","Validation Accuracy: 0.9602438671780115\n","Training epoch: 5\n","Training loss per 100 training steps: 0.07434647530317307\n","Training loss per 100 training steps: 0.029628766852772177\n","Training loss per 100 training steps: 0.03195710918537123\n","Training loss per 100 training steps: 0.03154954627702365\n","Training loss per 100 training steps: 0.0316561220095904\n","Training loss per 100 training steps: 0.030767165777480746\n","Training loss epoch: 0.030335082554724925\n","Training accuracy epoch: 0.9906431330951773\n","Validating model...\n","Validation Loss: 0.18567670523733287\n","Validation Accuracy: 0.9587453722779712\n","Training epoch: 6\n","Training loss per 100 training steps: 0.016201183199882507\n","Training loss per 100 training steps: 0.016996447803766124\n","Training loss per 100 training steps: 0.020240613112842375\n","Training loss per 100 training steps: 0.0213019718556043\n","Training loss per 100 training steps: 0.021032023310087657\n","Training loss per 100 training steps: 0.021072020525570043\n","Training loss epoch: 0.020796435949138308\n","Training accuracy epoch: 0.9938284802268782\n","Validating model...\n","Validation Loss: 0.18964456399152804\n","Validation Accuracy: 0.9595757579993981\n","Training epoch: 7\n","Training loss per 100 training steps: 0.016265999525785446\n","Training loss per 100 training steps: 0.014797308813609958\n","Training loss per 100 training steps: 0.01673266587782401\n","Training loss per 100 training steps: 0.01829417161775004\n","Training loss per 100 training steps: 0.02003358750333522\n","Training loss per 100 training steps: 0.020233526154134995\n","Training loss epoch: 0.020593873375504383\n","Training accuracy epoch: 0.9936476094088931\n","Validating model...\n","Validation Loss: 0.19168622613969175\n","Validation Accuracy: 0.960387706252421\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 42.738149383333315 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14905992067522472\n","Validation Accuracy: 0.9561302797554726\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation duration: 3.1939892833333334 minutes\n","F1-score (test): 84.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.84      0.86      0.85     12546\n","        test       0.82      0.87      0.84      9012\n","   treatment       0.86      0.82      0.84      9297\n","\n","   micro avg       0.84      0.85      0.84     30855\n","   macro avg       0.84      0.85      0.84     30855\n","weighted avg       0.84      0.85      0.84     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 17334\n","Points in y_train after augmentation: 17334\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1680617332458496\n","Training loss per 100 training steps: 0.4058717960989711\n","Training loss per 100 training steps: 0.30555363145856124\n","Training loss per 100 training steps: 0.25742491991862504\n","Training loss per 100 training steps: 0.23204895310995732\n","Training loss per 100 training steps: 0.2164115094488669\n","Training loss epoch: 0.2104827531225072\n","Training accuracy epoch: 0.9328616465816367\n","Validating model...\n","Validation Loss: 0.131404922646168\n","Validation Accuracy: 0.9565713949760903\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07860174030065536\n","Training loss per 100 training steps: 0.09151059296904224\n","Training loss per 100 training steps: 0.09128492878314423\n","Training loss per 100 training steps: 0.08942369380625478\n","Training loss per 100 training steps: 0.08732228329001074\n","Training loss per 100 training steps: 0.0875152817977492\n","Training loss epoch: 0.08829027166370151\n","Training accuracy epoch: 0.9717449303186065\n","Validating model...\n","Validation Loss: 0.12250866813512591\n","Validation Accuracy: 0.9620531090267891\n","Training epoch: 3\n","Training loss per 100 training steps: 0.07400164753198624\n","Training loss per 100 training steps: 0.04770671379392837\n","Training loss per 100 training steps: 0.052045783778624746\n","Training loss per 100 training steps: 0.052024434832701354\n","Training loss per 100 training steps: 0.05275873073197883\n","Training loss per 100 training steps: 0.05392892299519253\n","Training loss epoch: 0.0543587984619456\n","Training accuracy epoch: 0.9830502524565039\n","Validating model...\n","Validation Loss: 0.14057652635330503\n","Validation Accuracy: 0.9610681179705083\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03946903720498085\n","Training loss per 100 training steps: 0.03956565607366807\n","Stopping epoch...\n","Training loss epoch: 0.03956565607366807\n","Training accuracy epoch: 0.9779476455381939\n","Validating model...\n","Validation Loss: 0.1505714463940882\n","Validation Accuracy: 0.9606077415356039\n","Training epoch: 5\n","Training loss per 100 training steps: 0.012643981724977493\n","Training loss per 100 training steps: 0.03058032048312892\n","Training loss per 100 training steps: 0.033049849897567464\n","Training loss per 100 training steps: 0.03371837061243534\n","Training loss per 100 training steps: 0.035093884399228094\n","Training loss per 100 training steps: 0.0353625504160114\n","Training loss epoch: 0.036021040910399586\n","Training accuracy epoch: 0.9890026379500003\n","Validating model...\n","Validation Loss: 0.17311014588196555\n","Validation Accuracy: 0.9563887073205363\n","Training epoch: 6\n","Training loss per 100 training steps: 0.026556232944130898\n","Training loss per 100 training steps: 0.020117612595964996\n","Training loss per 100 training steps: 0.020035742721531948\n","Training loss per 100 training steps: 0.02247533370316047\n","Training loss per 100 training steps: 0.025688131349573512\n","Training loss per 100 training steps: 0.02769753566054077\n","Training loss epoch: 0.027911247521775477\n","Training accuracy epoch: 0.9911224053353119\n","Validating model...\n","Validation Loss: 0.18244671306343047\n","Validation Accuracy: 0.9587681668644946\n","Training epoch: 7\n","Training loss per 100 training steps: 0.02114959806203842\n","Training loss per 100 training steps: 0.022940176103430073\n","Training loss per 100 training steps: 0.022854887874593114\n","Training loss per 100 training steps: 0.026383231116878025\n","Training loss per 100 training steps: 0.02688475423205082\n","Training loss per 100 training steps: 0.02765158809695445\n","Training loss epoch: 0.027913182274081034\n","Training accuracy epoch: 0.9912643526631212\n","Validating model...\n","Validation Loss: 0.17414180303065033\n","Validation Accuracy: 0.9584245160011273\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 38.30924768333334 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14197140631235758\n","Validation Accuracy: 0.956052108166547\n","Validation duration: 3.1998701833333447 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 84.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.86      0.84     12546\n","        test       0.86      0.85      0.85      9012\n","   treatment       0.84      0.86      0.85      9298\n","\n","   micro avg       0.84      0.86      0.85     30856\n","   macro avg       0.84      0.86      0.85     30856\n","weighted avg       0.84      0.86      0.85     30856\n","\n","!!!!!! Starting model number 5 !!!!!!\n","Points in X_train after augmentation: 17334\n","Points in y_train after augmentation: 17334\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.942955493927002\n","Training loss per 100 training steps: 0.4183439275268281\n","Training loss per 100 training steps: 0.31517694844164656\n","Training loss per 100 training steps: 0.2668024537051437\n","Training loss per 100 training steps: 0.24077195014590932\n","Training loss per 100 training steps: 0.22209159507157797\n","Training loss epoch: 0.2163450491521851\n","Training accuracy epoch: 0.9312621124185828\n","Validating model...\n","Validation Loss: 0.13187801806473887\n","Validation Accuracy: 0.9578596164905157\n","Training epoch: 2\n","Training loss per 100 training steps: 0.19472305476665497\n","Training loss per 100 training steps: 0.08569603151466587\n","Training loss per 100 training steps: 0.08565198538352305\n","Training loss per 100 training steps: 0.08841113797528205\n","Training loss per 100 training steps: 0.09126940252319758\n","Training loss per 100 training steps: 0.09086813233577146\n","Training loss epoch: 0.09349424439238391\n","Training accuracy epoch: 0.9703618013236177\n","Validating model...\n","Validation Loss: 0.14263894856459908\n","Validation Accuracy: 0.9557211472367126\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0240588691085577\n","Training loss per 100 training steps: 0.061525281269730316\n","Training loss per 100 training steps: 0.056976727691863606\n","Training loss per 100 training steps: 0.05687366962816529\n","Training loss per 100 training steps: 0.057674068049469646\n","Training loss per 100 training steps: 0.05640649123622956\n","Training loss epoch: 0.055494331930870555\n","Training accuracy epoch: 0.9826591379671196\n","Validating model...\n","Validation Loss: 0.1479215095690512\n","Validation Accuracy: 0.9598959216716407\n","Training epoch: 4\n","Training loss per 100 training steps: 0.05072085186839104\n","Training loss per 100 training steps: 0.029513981776533298\n","Training loss per 100 training steps: 0.03219106699460515\n","Training loss per 100 training steps: 0.03405104459114868\n","Training loss per 100 training steps: 0.03613468843507592\n","Training loss per 100 training steps: 0.03700031826835862\n","Training loss epoch: 0.03720834665644804\n","Training accuracy epoch: 0.9883477671594589\n","Validating model...\n","Validation Loss: 0.16140584082814394\n","Validation Accuracy: 0.9594869623352132\n","Training epoch: 5\n","Training loss per 100 training steps: 0.026301492005586624\n","Training loss per 100 training steps: 0.02771151264539302\n","Training loss per 100 training steps: 0.028846335552160197\n","Training loss per 100 training steps: 0.027508047652628854\n","Training loss per 100 training steps: 0.028201659031774375\n","Training loss per 100 training steps: 0.02949426856966403\n","Training loss epoch: 0.029745049783238296\n","Training accuracy epoch: 0.9906445703790119\n","Validating model...\n","Validation Loss: 0.18108398734603998\n","Validation Accuracy: 0.9568004748850324\n","Training epoch: 6\n","Training loss per 100 training steps: 0.035067904740571976\n","Training loss per 100 training steps: 0.019565553807233932\n","Training loss per 100 training steps: 0.022020394116320383\n","Training loss per 100 training steps: 0.021967631794490614\n","Training loss per 100 training steps: 0.022642407067842374\n","Training loss per 100 training steps: 0.02274888784540055\n","Training loss epoch: 0.02294680226432689\n","Training accuracy epoch: 0.9927907016946917\n","Validating model...\n","Validation Loss: 0.19314512847499413\n","Validation Accuracy: 0.9580302606174621\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 35.83673116666669 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1465787732029437\n","Validation Accuracy: 0.9542020246394803\n","Validation duration: 3.12436556666665 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 83.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.87      0.84     12546\n","        test       0.77      0.87      0.82      9012\n","   treatment       0.83      0.85      0.84      9297\n","\n","   micro avg       0.81      0.87      0.83     30855\n","   macro avg       0.81      0.86      0.83     30855\n","weighted avg       0.81      0.87      0.83     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n","Points in X_train after augmentation: 17334\n","Points in y_train after augmentation: 17334\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9499709606170654\n","Training loss per 100 training steps: 0.39656466599738244\n","Training loss per 100 training steps: 0.30016282860615956\n","Training loss per 100 training steps: 0.2553576618754784\n","Training loss per 100 training steps: 0.23284858917617737\n","Training loss per 100 training steps: 0.21426812040353727\n","Training loss epoch: 0.20936878514218374\n","Training accuracy epoch: 0.9338155006667432\n","Validating model...\n","Validation Loss: 0.13414861653725824\n","Validation Accuracy: 0.9573638508126012\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06915400177240372\n","Training loss per 100 training steps: 0.08383165968416056\n","Training loss per 100 training steps: 0.08817869602280914\n","Training loss per 100 training steps: 0.08799708568091903\n","Training loss per 100 training steps: 0.08709368225595823\n","Training loss per 100 training steps: 0.08846946144866907\n","Training loss epoch: 0.08861941539053547\n","Training accuracy epoch: 0.9717622680171154\n","Validating model...\n","Validation Loss: 0.13619995642114768\n","Validation Accuracy: 0.9598295769342235\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03250674903392792\n","Training loss per 100 training steps: 0.04549527363759456\n","Training loss per 100 training steps: 0.04900268730776968\n","Training loss per 100 training steps: 0.050809851480938764\n","Training loss per 100 training steps: 0.05430334495575611\n","Training loss per 100 training steps: 0.056154787918727495\n","Training loss epoch: 0.057090638128944375\n","Training accuracy epoch: 0.9819443393813827\n","Validating model...\n","Validation Loss: 0.15544782245120445\n","Validation Accuracy: 0.9565731750161319\n","Training epoch: 4\n","Training loss per 100 training steps: 0.019749505445361137\n","Training loss per 100 training steps: 0.035304494162947675\n","Training loss per 100 training steps: 0.03491467122563082\n","Training loss per 100 training steps: 0.036534237574037176\n","Training loss per 100 training steps: 0.038528582953878135\n","Training loss per 100 training steps: 0.038372489292836355\n","Training loss epoch: 0.038365230859923986\n","Training accuracy epoch: 0.9878790883523829\n","Validating model...\n","Validation Loss: 0.15712510979456173\n","Validation Accuracy: 0.9602452616781467\n","Training epoch: 5\n","Training loss per 100 training steps: 0.024353493005037308\n","Training loss per 100 training steps: 0.02184834719363526\n","Training loss per 100 training steps: 0.022292988108985348\n","Training loss per 100 training steps: 0.025407721242477553\n","Training loss per 100 training steps: 0.02719059131111708\n","Training loss per 100 training steps: 0.027828659669416184\n","Training loss epoch: 0.02829964668447035\n","Training accuracy epoch: 0.9914108638859286\n","Validating model...\n","Validation Loss: 0.17731812378609335\n","Validation Accuracy: 0.958947662701577\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0022673492785543203\n","Training loss per 100 training steps: 0.0236199473510358\n","Training loss per 100 training steps: 0.029534928585212696\n","Training loss per 100 training steps: 0.029316710780043637\n","Training loss per 100 training steps: 0.02978135302646592\n","Training loss per 100 training steps: 0.03151376844670051\n","Training loss epoch: 0.03145398068580282\n","Training accuracy epoch: 0.9902087897677265\n","Validating model...\n","Validation Loss: 0.1936064064275933\n","Validation Accuracy: 0.9560913780177945\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 35.81111918333336 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14380865882978672\n","Validation Accuracy: 0.9547431615070789\n","Validation duration: 3.1122268999999507 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 83.8%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.84      0.83     12546\n","        test       0.86      0.86      0.86      9012\n","   treatment       0.80      0.87      0.83      9297\n","\n","   micro avg       0.82      0.86      0.84     30855\n","   macro avg       0.82      0.86      0.84     30855\n","weighted avg       0.82      0.86      0.84     30855\n","\n","!!!!!! Starting model number 7 !!!!!!\n","Points in X_train after augmentation: 17334\n","Points in y_train after augmentation: 17334\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9329174757003784\n","Training loss per 100 training steps: 0.4110368600871303\n","Training loss per 100 training steps: 0.3073015048432706\n","Training loss per 100 training steps: 0.260645033587451\n","Training loss per 100 training steps: 0.2353077981147237\n","Training loss per 100 training steps: 0.21914579083551905\n","Training loss epoch: 0.2132368974964997\n","Training accuracy epoch: 0.9328285053118989\n","Validating model...\n","Validation Loss: 0.13042322593414551\n","Validation Accuracy: 0.9582417554217912\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07557377219200134\n","Training loss per 100 training steps: 0.08478713058636035\n","Training loss per 100 training steps: 0.0877596595097537\n","Training loss per 100 training steps: 0.0879534566341791\n","Training loss per 100 training steps: 0.09092736324792416\n","Training loss per 100 training steps: 0.09324721006412587\n","Training loss epoch: 0.09239327048752251\n","Training accuracy epoch: 0.9706217687836768\n","Validating model...\n","Validation Loss: 0.13935650265836097\n","Validation Accuracy: 0.9577905653388602\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04826958477497101\n","Training loss per 100 training steps: 0.055002041280933535\n","Training loss per 100 training steps: 0.056690371463269884\n","Training loss per 100 training steps: 0.056667863682958224\n","Training loss per 100 training steps: 0.05639294791964354\n","Training loss per 100 training steps: 0.05656729913186542\n","Training loss epoch: 0.05649246752126369\n","Training accuracy epoch: 0.9821031242963288\n","Validating model...\n","Validation Loss: 0.1424651157304451\n","Validation Accuracy: 0.9593910150689459\n","Training epoch: 4\n","Training loss per 100 training steps: 0.10154970735311508\n","Training loss per 100 training steps: 0.035747097450133304\n","Training loss per 100 training steps: 0.03576997821497272\n","Training loss per 100 training steps: 0.035276778736167226\n","Training loss per 100 training steps: 0.0371234287493897\n","Training loss per 100 training steps: 0.038201875546891355\n","Training loss epoch: 0.03838060535593611\n","Training accuracy epoch: 0.9879188528435587\n","Validating model...\n","Validation Loss: 0.16047890351286956\n","Validation Accuracy: 0.9582720855048171\n","Training epoch: 5\n","Training loss per 100 training steps: 0.008482950739562511\n","Training loss per 100 training steps: 0.02776907725918964\n","Training loss per 100 training steps: 0.030055136686835012\n","Training loss per 100 training steps: 0.03196694310700391\n","Training loss per 100 training steps: 0.033018731653511504\n","Training loss per 100 training steps: 0.033555430737733025\n","Training loss epoch: 0.03301661060785796\n","Training accuracy epoch: 0.9899094625657872\n","Validating model...\n","Validation Loss: 0.18804366504410644\n","Validation Accuracy: 0.9585090095936973\n","Training epoch: 6\n","Training loss per 100 training steps: 0.05793546140193939\n","Training loss per 100 training steps: 0.02455821525164889\n","Training loss per 100 training steps: 0.023285291210368313\n","Training loss per 100 training steps: 0.022552921266938586\n","Training loss per 100 training steps: 0.02353909689331534\n","Training loss per 100 training steps: 0.023849612329514908\n","Training loss epoch: 0.02381926556184417\n","Training accuracy epoch: 0.9928762312731056\n","Validating model...\n","Validation Loss: 0.18716045357770733\n","Validation Accuracy: 0.9585159727273355\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 36.80775831666676 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14611213482351526\n","Validation Accuracy: 0.9540153098586658\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation duration: 3.1896941666667167 minutes\n","F1-score (test): 84.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.86      0.83     12546\n","        test       0.84      0.86      0.85      9012\n","   treatment       0.82      0.86      0.84      9297\n","\n","   micro avg       0.82      0.86      0.84     30855\n","   macro avg       0.82      0.86      0.84     30855\n","weighted avg       0.82      0.86      0.84     30855\n","\n","!!!!!! Starting model number 8 !!!!!!\n","Points in X_train after augmentation: 17334\n","Points in y_train after augmentation: 17334\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.086076259613037\n","Training loss per 100 training steps: 0.391824540082771\n","Training loss per 100 training steps: 0.29049698986224276\n","Training loss per 100 training steps: 0.2453868005399985\n","Training loss per 100 training steps: 0.22464431033578894\n","Training loss per 100 training steps: 0.2109385154724954\n","Training loss epoch: 0.20556310016483179\n","Training accuracy epoch: 0.9343510287784229\n","Validating model...\n","Validation Loss: 0.13870571989130664\n","Validation Accuracy: 0.9545883665766529\n","Training epoch: 2\n","Training loss per 100 training steps: 0.1377454251050949\n","Training loss per 100 training steps: 0.0924327862218465\n","Training loss per 100 training steps: 0.08878688331211533\n","Training loss per 100 training steps: 0.08861021134705342\n","Training loss per 100 training steps: 0.08889285507298393\n","Training loss per 100 training steps: 0.08854668742294856\n","Training loss epoch: 0.08907790965060411\n","Training accuracy epoch: 0.9713752830984984\n","Validating model...\n","Validation Loss: 0.1371574473095598\n","Validation Accuracy: 0.9578992861148431\n","Training epoch: 3\n","Training loss per 100 training steps: 0.07434321194887161\n","Training loss per 100 training steps: 0.048958656825309636\n","Training loss per 100 training steps: 0.04909763744666209\n","Training loss per 100 training steps: 0.04717922207753969\n","Training loss per 100 training steps: 0.04990111682865945\n","Training loss per 100 training steps: 0.05154115613457001\n","Training loss epoch: 0.05143543454557245\n","Training accuracy epoch: 0.9837754006624525\n","Validating model...\n","Validation Loss: 0.164903138570681\n","Validation Accuracy: 0.9559523459983683\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01416247058659792\n","Training loss per 100 training steps: 0.03831335694280149\n","Training loss per 100 training steps: 0.03570330562185848\n","Training loss per 100 training steps: 0.038242705347344426\n","Training loss per 100 training steps: 0.03978659122592382\n","Training loss per 100 training steps: 0.04076475078451955\n","Training loss epoch: 0.040894211946928195\n","Training accuracy epoch: 0.9870600112629232\n","Validating model...\n","Validation Loss: 0.15035510399415122\n","Validation Accuracy: 0.95995830548397\n","Training epoch: 5\n","Training loss per 100 training steps: 0.021214032545685768\n","Training loss per 100 training steps: 0.02337323522222883\n","Training loss per 100 training steps: 0.026146125273121084\n","Training loss per 100 training steps: 0.028276756118853077\n","Training loss per 100 training steps: 0.027675973803055778\n","Training loss per 100 training steps: 0.027059074018630173\n","Training loss epoch: 0.02798046405226116\n","Training accuracy epoch: 0.9910181320106519\n","Validating model...\n","Validation Loss: 0.1738150335316147\n","Validation Accuracy: 0.9595455500718331\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00970487855374813\n","Training loss per 100 training steps: 0.023482381685470958\n","Training loss per 100 training steps: 0.022195882965527956\n","Training loss per 100 training steps: 0.022009655089307873\n","Training loss per 100 training steps: 0.02297588984817011\n","Training loss per 100 training steps: 0.023396744283716457\n","Training loss epoch: 0.023622882644911348\n","Training accuracy epoch: 0.9925671033690814\n","Validating model...\n","Validation Loss: 0.1946166981640574\n","Validation Accuracy: 0.9582063824363666\n","Training epoch: 7\n","Training loss per 100 training steps: 0.004039682913571596\n","Training loss per 100 training steps: 0.01431784220789052\n","Training loss per 100 training steps: 0.01740499226282587\n","Training loss per 100 training steps: 0.016173513442397033\n","Training loss per 100 training steps: 0.017308176337930598\n","Training loss per 100 training steps: 0.018025665962580636\n","Training loss epoch: 0.017752329341107567\n","Training accuracy epoch: 0.9948357137462691\n","Validating model...\n","Validation Loss: 0.19509780711748384\n","Validation Accuracy: 0.9598159995974108\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 41.803720583333295 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14363726225349605\n","Validation Accuracy: 0.9557181406916302\n","Validation duration: 3.11930718333327 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 85.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.84      0.87      0.85     12546\n","        test       0.85      0.82      0.83      9012\n","   treatment       0.85      0.86      0.86      9297\n","\n","   micro avg       0.85      0.85      0.85     30855\n","   macro avg       0.85      0.85      0.85     30855\n","weighted avg       0.85      0.85      0.85     30855\n","\n","!!!!!! Starting model number 9 !!!!!!\n","Points in X_train after augmentation: 17334\n","Points in y_train after augmentation: 17334\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8849895000457764\n","Training loss per 100 training steps: 0.40151126660627895\n","Training loss per 100 training steps: 0.3017405240764072\n","Training loss per 100 training steps: 0.26196676670910907\n","Training loss per 100 training steps: 0.23400242676368527\n","Training loss per 100 training steps: 0.2180090361347277\n","Training loss epoch: 0.21320197902056234\n","Training accuracy epoch: 0.9328484716892403\n","Validating model...\n","Validation Loss: 0.13233728876168077\n","Validation Accuracy: 0.9570496441864292\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06309506297111511\n","Training loss per 100 training steps: 0.09271882456902525\n","Training loss per 100 training steps: 0.0868805198795834\n","Training loss per 100 training steps: 0.08688474301112649\n","Training loss per 100 training steps: 0.0871951462482648\n","Training loss per 100 training steps: 0.0871827942737473\n","Training loss epoch: 0.08785621043658949\n","Training accuracy epoch: 0.9714709720260039\n","Validating model...\n","Validation Loss: 0.12988444695902335\n","Validation Accuracy: 0.9590168806827524\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0350884273648262\n","Training loss per 100 training steps: 0.04549997787470791\n","Training loss per 100 training steps: 0.047693329783323316\n","Training loss per 100 training steps: 0.04891854329297684\n","Training loss per 100 training steps: 0.05171668099557651\n","Training loss per 100 training steps: 0.05312618135452315\n","Training loss epoch: 0.053218120064266794\n","Training accuracy epoch: 0.9829396818177\n","Validating model...\n","Validation Loss: 0.1594668889007011\n","Validation Accuracy: 0.9577788091864667\n","Training epoch: 4\n","Training loss per 100 training steps: 0.00856827013194561\n","Training loss per 100 training steps: 0.04870787741948325\n","Training loss per 100 training steps: 0.0434747990614628\n","Training loss per 100 training steps: 0.0419242478863791\n","Training loss per 100 training steps: 0.04132777448230309\n","Training loss per 100 training steps: 0.041073597449913415\n","Training loss epoch: 0.04175513744701346\n","Training accuracy epoch: 0.9869542667359228\n","Validating model...\n","Validation Loss: 0.15563165081979394\n","Validation Accuracy: 0.9588221928275968\n","Training epoch: 5\n","Training loss per 100 training steps: 0.015910152345895767\n","Training loss per 100 training steps: 0.029741395689030684\n","Training loss per 100 training steps: 0.02914771035809385\n","Training loss per 100 training steps: 0.02856049444944137\n","Training loss per 100 training steps: 0.028346865652175503\n","Training loss per 100 training steps: 0.028606067113243712\n","Training loss epoch: 0.029657548642287725\n","Training accuracy epoch: 0.9910067541518351\n","Validating model...\n","Validation Loss: 0.18596384384028322\n","Validation Accuracy: 0.9559032527892148\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00580844609066844\n","Training loss per 100 training steps: 0.02442441249639718\n","Training loss per 100 training steps: 0.02302908956360498\n","Training loss per 100 training steps: 0.023447883897460997\n","Training loss per 100 training steps: 0.02333792763009686\n","Training loss per 100 training steps: 0.023048120637483776\n","Training loss epoch: 0.022528069152890247\n","Training accuracy epoch: 0.9930890545583054\n","Validating model...\n","Validation Loss: 0.19983586950179238\n","Validation Accuracy: 0.9600096695145981\n","Training epoch: 7\n","Training loss per 100 training steps: 0.003415442071855068\n","Training loss per 100 training steps: 0.020299825968340703\n","Training loss per 100 training steps: 0.027444574935014236\n","Training loss per 100 training steps: 0.026912559847195826\n","Training loss per 100 training steps: 0.02641920523167567\n","Training loss per 100 training steps: 0.025264033115703143\n","Training loss epoch: 0.024825559283466667\n","Training accuracy epoch: 0.9924304874803799\n","Validating model...\n","Validation Loss: 0.19356013099661448\n","Validation Accuracy: 0.9574980240646886\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 41.80910398333338 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14479802762313435\n","Validation Accuracy: 0.9547439435255418\n","Validation duration: 3.1199287166666183 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 83.9%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.88      0.84     12546\n","        test       0.81      0.86      0.84      9012\n","   treatment       0.83      0.86      0.85      9297\n","\n","   micro avg       0.81      0.87      0.84     30855\n","   macro avg       0.81      0.87      0.84     30855\n","weighted avg       0.81      0.87      0.84     30855\n","\n","!!!!!! Starting model number 10 !!!!!!\n","Points in X_train after augmentation: 17334\n","Points in y_train after augmentation: 17334\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8637526035308838\n","Training loss per 100 training steps: 0.41101102944057766\n","Training loss per 100 training steps: 0.3002870024659147\n","Training loss per 100 training steps: 0.2600606785486901\n","Training loss per 100 training steps: 0.2346280927577072\n","Training loss per 100 training steps: 0.21719203745117208\n","Training loss epoch: 0.21053984366714734\n","Training accuracy epoch: 0.9340107577246436\n","Validating model...\n","Validation Loss: 0.1403157225773706\n","Validation Accuracy: 0.9546752847484782\n","Training epoch: 2\n","Training loss per 100 training steps: 0.11088825017213821\n","Training loss per 100 training steps: 0.090577771186386\n","Training loss per 100 training steps: 0.0888351076908076\n","Training loss per 100 training steps: 0.0894554516430511\n","Training loss per 100 training steps: 0.09005473258247845\n","Training loss per 100 training steps: 0.09014392232972229\n","Training loss epoch: 0.08984446525917392\n","Training accuracy epoch: 0.9707851419463813\n","Validating model...\n","Validation Loss: 0.13182341909737555\n","Validation Accuracy: 0.9593801317237723\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04710579663515091\n","Training loss per 100 training steps: 0.05048033988361459\n","Training loss per 100 training steps: 0.05197383170548956\n","Training loss per 100 training steps: 0.05281239889401237\n","Training loss per 100 training steps: 0.05196854283573324\n","Training loss per 100 training steps: 0.053879618292912365\n","Training loss epoch: 0.05397339125990359\n","Training accuracy epoch: 0.9828800524255662\n","Validating model...\n","Validation Loss: 0.14340449813995268\n","Validation Accuracy: 0.9607928756375195\n","Training epoch: 4\n","Training loss per 100 training steps: 0.010623152367770672\n","Training loss per 100 training steps: 0.03711747778302962\n","Training loss per 100 training steps: 0.03479572847967421\n","Training loss per 100 training steps: 0.03429985601854112\n","Training loss per 100 training steps: 0.03702985101955434\n","Training loss per 100 training steps: 0.03832625255161551\n","Training loss epoch: 0.039386817740836626\n","Training accuracy epoch: 0.9876372852995597\n","Validating model...\n","Validation Loss: 0.1577262852534458\n","Validation Accuracy: 0.962207749324858\n","Training epoch: 5\n","Training loss per 100 training steps: 0.06163819506764412\n","Training loss per 100 training steps: 0.02429220800536989\n","Training loss per 100 training steps: 0.026310799213645247\n","Training loss per 100 training steps: 0.03076688969272662\n","Training loss per 100 training steps: 0.030548852132726227\n","Training loss per 100 training steps: 0.03025954315706552\n","Training loss epoch: 0.03068576863282996\n","Training accuracy epoch: 0.9907214212415099\n","Validating model...\n","Validation Loss: 0.16639868766311314\n","Validation Accuracy: 0.9612355788162875\n","Training epoch: 6\n","Training loss per 100 training steps: 0.008748338557779789\n","Training loss per 100 training steps: 0.023520266683311156\n","Training loss per 100 training steps: 0.02202063989339035\n","Training loss per 100 training steps: 0.021423048633916544\n","Training loss per 100 training steps: 0.021609588062995698\n","Training loss per 100 training steps: 0.0230234124575288\n","Training loss epoch: 0.02318466895286121\n","Training accuracy epoch: 0.9930299553048798\n","Validating model...\n","Validation Loss: 0.173906084376859\n","Validation Accuracy: 0.9614827189517186\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0013190645258873701\n","Training loss per 100 training steps: 0.01751666036054105\n","Training loss per 100 training steps: 0.018072555282104538\n","Training loss per 100 training steps: 0.018642534690203633\n","Training loss per 100 training steps: 0.020101412257790434\n","Training loss per 100 training steps: 0.018760680470117433\n","Training loss epoch: 0.018683178961080262\n","Training accuracy epoch: 0.9943448280756128\n","Validating model...\n","Validation Loss: 0.19329766999301198\n","Validation Accuracy: 0.9606244359797749\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 41.83677208333332 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.149387624984094\n","Validation Accuracy: 0.9552635062678329\n","Validation duration: 3.119838833333294 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 84.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.86      0.84     12546\n","        test       0.82      0.88      0.85      9012\n","   treatment       0.84      0.84      0.84      9297\n","\n","   micro avg       0.83      0.86      0.85     30855\n","   macro avg       0.83      0.86      0.85     30855\n","weighted avg       0.83      0.86      0.85     30855\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0.25\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"Jhz9BiIwGCsV"},{"cell_type":"code","execution_count":null,"metadata":{"id":"jdO4m5O4Hlo3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663086097640,"user_tz":240,"elapsed":4010088,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}},"outputId":"53c24b71-4c51-4376-9d1f-224eb27bb0a8"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 50.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 20801\n","Points in y_train after augmentation: 20801\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0372326374053955\n","Training loss per 100 training steps: 0.39656256817945157\n","Training loss per 100 training steps: 0.29604987972485486\n","Training loss per 100 training steps: 0.25289761000297395\n","Training loss per 100 training steps: 0.22806702818990943\n","Training loss per 100 training steps: 0.2132746507962069\n","Training loss per 100 training steps: 0.20099598836593838\n","Training loss epoch: 0.19670884464291596\n","Training accuracy epoch: 0.93742750918056\n","Validating model...\n","Validation Loss: 0.13691921798246248\n","Validation Accuracy: 0.9563812081053255\n","Training epoch: 2\n","Training loss per 100 training steps: 0.08501828461885452\n","Training loss per 100 training steps: 0.08418318107355349\n","Stopping epoch...\n","Training loss epoch: 0.08418318107355349\n","Training accuracy epoch: 0.9634045193944282\n","Validating model...\n","Validation Loss: 0.1502517242976404\n","Validation Accuracy: 0.9544271713290252\n","Training epoch: 3\n","Training loss per 100 training steps: 0.06937500089406967\n","Training loss per 100 training steps: 0.08378038935289525\n","Training loss per 100 training steps: 0.0845317119056016\n","Training loss per 100 training steps: 0.08613446574546768\n","Training loss per 100 training steps: 0.08367039498575775\n","Training loss per 100 training steps: 0.08274528986175811\n","Training loss per 100 training steps: 0.08176310044967457\n","Training loss epoch: 0.0812734127614773\n","Training accuracy epoch: 0.9742517998640887\n","Validating model...\n","Validation Loss: 0.14589257748773346\n","Validation Accuracy: 0.9573729820593767\n","Training epoch: 4\n","Training loss per 100 training steps: 0.026574967429041862\n","Training loss per 100 training steps: 0.047746911691040686\n","Training loss per 100 training steps: 0.05073708214736845\n","Training loss per 100 training steps: 0.04876763093597766\n","Training loss per 100 training steps: 0.04909800736934987\n","Training loss per 100 training steps: 0.05044429259144231\n","Training loss per 100 training steps: 0.05190125094980819\n","Training loss epoch: 0.05446234174765154\n","Training accuracy epoch: 0.9829026572281947\n","Validating model...\n","Validation Loss: 0.16071394501955477\n","Validation Accuracy: 0.9557022979559601\n","Training epoch: 5\n","Training loss per 100 training steps: 0.08592041581869125\n","Training loss per 100 training steps: 0.04292124793357631\n","Training loss per 100 training steps: 0.04178992831681053\n","Training loss per 100 training steps: 0.04320822537650797\n","Training loss per 100 training steps: 0.041103707048740064\n","Training loss per 100 training steps: 0.04017215537347881\n","Training loss per 100 training steps: 0.039512248487814566\n","Training loss epoch: 0.03964900647178464\n","Training accuracy epoch: 0.9873202611604943\n","Validating model...\n","Validation Loss: 0.18416716538176134\n","Validation Accuracy: 0.957023092862955\n","Training epoch: 6\n","Training loss per 100 training steps: 0.01946183480322361\n","Training loss per 100 training steps: 0.02952678837712006\n","Training loss per 100 training steps: 0.0283940546591048\n","Training loss per 100 training steps: 0.027466187638422457\n","Training loss per 100 training steps: 0.02605845853486017\n","Training loss per 100 training steps: 0.025381383257792583\n","Training loss per 100 training steps: 0.025533397676296896\n","Training loss epoch: 0.02572574542895753\n","Training accuracy epoch: 0.9919379466658358\n","Validating model...\n","Validation Loss: 0.17150813407059035\n","Validation Accuracy: 0.9610380644635178\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 36.89236373333333 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1537430761187958\n","Validation Accuracy: 0.9526142775595339\n","Validation duration: 3.132384383333313 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 82.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.81      0.82     12546\n","        test       0.76      0.87      0.81      9012\n","   treatment       0.83      0.86      0.84      9297\n","\n","   micro avg       0.81      0.84      0.82     30855\n","   macro avg       0.81      0.85      0.82     30855\n","weighted avg       0.81      0.84      0.82     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 20801\n","Points in y_train after augmentation: 20801\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.177449941635132\n","Training loss per 100 training steps: 0.39328051646157064\n","Training loss per 100 training steps: 0.29525333483569066\n","Training loss per 100 training steps: 0.2539174011428887\n","Training loss per 100 training steps: 0.22944851952635142\n","Training loss per 100 training steps: 0.21462323437045197\n","Training loss per 100 training steps: 0.20217277912946788\n","Training loss epoch: 0.19770428299125622\n","Training accuracy epoch: 0.9374455571285478\n","Validating model...\n","Validation Loss: 0.139334061751505\n","Validation Accuracy: 0.9539717182150457\n","Training epoch: 2\n","Training loss per 100 training steps: 0.08727484196424484\n","Training loss per 100 training steps: 0.07879812563631204\n","Training loss per 100 training steps: 0.07726074302967507\n","Training loss per 100 training steps: 0.08127337706699175\n","Training loss per 100 training steps: 0.08201379684192545\n","Training loss per 100 training steps: 0.08265968294490776\n","Training loss per 100 training steps: 0.08280927143191388\n","Training loss epoch: 0.08307582772438472\n","Training accuracy epoch: 0.9734971085941605\n","Validating model...\n","Validation Loss: 0.14413362591491116\n","Validation Accuracy: 0.9558517756845752\n","Training epoch: 3\n","Training loss per 100 training steps: 0.06463295221328735\n","Training loss per 100 training steps: 0.04469309301382982\n","Training loss per 100 training steps: 0.0454506039392407\n","Training loss per 100 training steps: 0.04753260933592965\n","Training loss per 100 training steps: 0.04611859819387316\n","Training loss per 100 training steps: 0.047035011018118904\n","Training loss per 100 training steps: 0.048352525096863955\n","Training loss epoch: 0.04919445694362696\n","Training accuracy epoch: 0.9841619244158668\n","Validating model...\n","Validation Loss: 0.16266562321598266\n","Validation Accuracy: 0.9565177516675007\n","Training epoch: 4\n","Training loss per 100 training steps: 0.04706976190209389\n","Training loss per 100 training steps: 0.034984372390231284\n","Training loss per 100 training steps: 0.036349188103178394\n","Training loss per 100 training steps: 0.03919220301539226\n","Training loss per 100 training steps: 0.03823733943609749\n","Training loss per 100 training steps: 0.037313773083461524\n","Training loss per 100 training steps: 0.03729392945829983\n","Training loss epoch: 0.03762632350404439\n","Training accuracy epoch: 0.9880707408664312\n","Validating model...\n","Validation Loss: 0.16514835395402722\n","Validation Accuracy: 0.9611422990899186\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0033571517560631037\n","Training loss per 100 training steps: 0.022721921343881967\n","Training loss per 100 training steps: 0.022727059898898005\n","Training loss per 100 training steps: 0.02331899086777678\n","Training loss per 100 training steps: 0.0227772587773267\n","Training loss per 100 training steps: 0.023302236592007648\n","Training loss per 100 training steps: 0.02434304133981556\n","Training loss epoch: 0.02502800264267377\n","Training accuracy epoch: 0.9921666252294428\n","Validating model...\n","Validation Loss: 0.17328988663948974\n","Validation Accuracy: 0.9611871588191827\n","Training epoch: 6\n","Training loss per 100 training steps: 0.04205629974603653\n","Training loss per 100 training steps: 0.017564927816211183\n","Training loss per 100 training steps: 0.01828278545944706\n","Training loss per 100 training steps: 0.01806056211169568\n","Training loss per 100 training steps: 0.01926650934195973\n","Training loss per 100 training steps: 0.020236757607733694\n","Training loss per 100 training steps: 0.020467305602718876\n","Training loss epoch: 0.021192657273171895\n","Training accuracy epoch: 0.9934250119374265\n","Validating model...\n","Validation Loss: 0.18586879020387476\n","Validation Accuracy: 0.9564992510915169\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 42.65102711666671 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14817760030726074\n","Validation Accuracy: 0.9521604846968785\n","Validation duration: 3.1185691499998938 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 83.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.81      0.82     12546\n","        test       0.82      0.86      0.84      9012\n","   treatment       0.80      0.87      0.83      9297\n","\n","   micro avg       0.82      0.84      0.83     30855\n","   macro avg       0.82      0.85      0.83     30855\n","weighted avg       0.82      0.84      0.83     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 20801\n","Points in y_train after augmentation: 20801\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.2025249004364014\n","Training loss per 100 training steps: 0.38770187166657777\n","Training loss per 100 training steps: 0.29334605885530585\n","Training loss per 100 training steps: 0.24959429270553826\n","Training loss per 100 training steps: 0.22807591795884166\n","Training loss per 100 training steps: 0.21275554055314577\n","Training loss per 100 training steps: 0.20019856439949868\n","Training loss epoch: 0.19598339379016888\n","Training accuracy epoch: 0.9380374992124312\n","Validating model...\n","Validation Loss: 0.13939411376977895\n","Validation Accuracy: 0.9552886045649642\n","Training epoch: 2\n","Training loss per 100 training steps: 0.052192606031894684\n","Training loss per 100 training steps: 0.07710499585707589\n","Training loss per 100 training steps: 0.07749619511470421\n","Training loss per 100 training steps: 0.07745094139104171\n","Training loss per 100 training steps: 0.07913025209629104\n","Training loss per 100 training steps: 0.07818545889622437\n","Training loss per 100 training steps: 0.07990829007058542\n","Training loss epoch: 0.08042622983066534\n","Training accuracy epoch: 0.9742136746129028\n","Validating model...\n","Validation Loss: 0.15180666848726862\n","Validation Accuracy: 0.9545016312054129\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0340963713824749\n","Training loss per 100 training steps: 0.042750281037412366\n","Training loss per 100 training steps: 0.04508985741995275\n","Training loss per 100 training steps: 0.046369432741652346\n","Training loss per 100 training steps: 0.04815788240232354\n","Training loss per 100 training steps: 0.04875331339537874\n","Training loss per 100 training steps: 0.04977818517697767\n","Training loss epoch: 0.05053486997660782\n","Training accuracy epoch: 0.9841709611787063\n","Validating model...\n","Validation Loss: 0.16052806934994923\n","Validation Accuracy: 0.9562170814781483\n","Training epoch: 4\n","Training loss per 100 training steps: 0.04973335191607475\n","Training loss per 100 training steps: 0.032351412971753\n","Training loss per 100 training steps: 0.03174062505183713\n","Training loss per 100 training steps: 0.03496475077614782\n","Training loss per 100 training steps: 0.03611782735778005\n","Training loss per 100 training steps: 0.03649283308134286\n","Training loss per 100 training steps: 0.03567176386648123\n","Training loss epoch: 0.036203564179005436\n","Training accuracy epoch: 0.9886064448825754\n","Validating model...\n","Validation Loss: 0.17993906263697457\n","Validation Accuracy: 0.952591809953293\n","Training epoch: 5\n","Training loss per 100 training steps: 0.048148881644010544\n","Training loss per 100 training steps: 0.031175424024407372\n","Training loss per 100 training steps: 0.028918610352313898\n","Training loss per 100 training steps: 0.027919221355384865\n","Training loss per 100 training steps: 0.029186676830887107\n","Training loss per 100 training steps: 0.028921530100780943\n","Training loss per 100 training steps: 0.028296991543512725\n","Training loss epoch: 0.027914313725762703\n","Training accuracy epoch: 0.9914294635365548\n","Validating model...\n","Validation Loss: 0.1893102425277572\n","Validation Accuracy: 0.9602595778407957\n","Training epoch: 6\n","Training loss per 100 training steps: 0.012669367715716362\n","Training loss per 100 training steps: 0.021040497672177003\n","Training loss per 100 training steps: 0.022386714905576865\n","Training loss per 100 training steps: 0.02243494676705295\n","Training loss per 100 training steps: 0.023200194876405303\n","Training loss per 100 training steps: 0.023942989080762322\n","Training loss per 100 training steps: 0.02385180647503941\n","Training loss epoch: 0.024414805190501085\n","Training accuracy epoch: 0.9927719222984064\n","Validating model...\n","Validation Loss: 0.18417426262824954\n","Validation Accuracy: 0.9585062930579578\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 43.95276196666661 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14764976979414415\n","Validation Accuracy: 0.953284932815452\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation duration: 3.191627316666563 minutes\n","F1-score (test): 83.8%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.84      0.84     12546\n","        test       0.84      0.87      0.85      9012\n","   treatment       0.81      0.85      0.83      9298\n","\n","   micro avg       0.83      0.85      0.84     30856\n","   macro avg       0.83      0.85      0.84     30856\n","weighted avg       0.83      0.85      0.84     30856\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 20801\n","Points in y_train after augmentation: 20801\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.103853702545166\n","Training loss per 100 training steps: 0.3968939683077359\n","Training loss per 100 training steps: 0.30106717753988593\n","Training loss per 100 training steps: 0.2592821892511805\n","Training loss per 100 training steps: 0.23352101918059098\n","Training loss per 100 training steps: 0.21675782962265366\n","Training loss per 100 training steps: 0.20477671520211138\n","Training loss epoch: 0.19870349636928003\n","Training accuracy epoch: 0.9364517789803108\n","Validating model...\n","Validation Loss: 0.13932210656923133\n","Validation Accuracy: 0.9567486408096826\n","Training epoch: 2\n","Training loss per 100 training steps: 0.10231153666973114\n","Training loss per 100 training steps: 0.07701071986172459\n","Training loss per 100 training steps: 0.07926974490062515\n","Training loss per 100 training steps: 0.07981344859465413\n","Training loss per 100 training steps: 0.08161309360296574\n","Training loss per 100 training steps: 0.08055162105426758\n","Training loss per 100 training steps: 0.08123996325717393\n","Training loss epoch: 0.08140869795440621\n","Training accuracy epoch: 0.9739897601141985\n","Validating model...\n","Validation Loss: 0.135790176713815\n","Validation Accuracy: 0.9587426589948531\n","Training epoch: 3\n","Training loss per 100 training steps: 0.12581683695316315\n","Training loss per 100 training steps: 0.047007358526940095\n","Training loss per 100 training steps: 0.04690608687800777\n","Training loss per 100 training steps: 0.04753012199456064\n","Training loss per 100 training steps: 0.0483702219078582\n","Training loss per 100 training steps: 0.048974454507488246\n","Training loss per 100 training steps: 0.0490794513128952\n","Training loss epoch: 0.04913566163868912\n","Training accuracy epoch: 0.9842620810157965\n","Validating model...\n","Validation Loss: 0.1575934724979006\n","Validation Accuracy: 0.9595728461713142\n","Training epoch: 4\n","Training loss per 100 training steps: 0.018412739038467407\n","Training loss per 100 training steps: 0.029402316928297135\n","Training loss per 100 training steps: 0.0292490955681971\n","Training loss per 100 training steps: 0.02931200942269022\n","Training loss per 100 training steps: 0.03167686615420268\n","Training loss per 100 training steps: 0.03227947172271962\n","Training loss per 100 training steps: 0.03279757868117357\n","Training loss epoch: 0.033370790950891016\n","Training accuracy epoch: 0.9898477626077667\n","Validating model...\n","Validation Loss: 0.16623973659566277\n","Validation Accuracy: 0.9599732762694042\n","Training epoch: 5\n","Training loss per 100 training steps: 0.014135242439806461\n","Training loss per 100 training steps: 0.023440796118875097\n","Training loss per 100 training steps: 0.02552027384801513\n","Training loss per 100 training steps: 0.028147346189862855\n","Training loss per 100 training steps: 0.027778111941539948\n","Training loss per 100 training steps: 0.02829827250461531\n","Training loss per 100 training steps: 0.028444815834518522\n","Training loss epoch: 0.02828524857353542\n","Training accuracy epoch: 0.9912987677668089\n","Validating model...\n","Validation Loss: 0.1831985515868896\n","Validation Accuracy: 0.9582229249041768\n","Training epoch: 6\n","Training loss per 100 training steps: 0.03488495573401451\n","Training loss per 100 training steps: 0.02032293439819708\n","Training loss per 100 training steps: 0.019935371311652517\n","Training loss per 100 training steps: 0.02032294049371727\n","Training loss per 100 training steps: 0.02009583973126054\n","Training loss per 100 training steps: 0.020672874420857107\n","Training loss per 100 training steps: 0.021129967154452294\n","Training loss epoch: 0.02136377037437375\n","Training accuracy epoch: 0.9935981806008908\n","Validating model...\n","Validation Loss: 0.18549932734194127\n","Validation Accuracy: 0.9587592474357874\n","Training epoch: 7\n","Training loss per 100 training steps: 0.009096423164010048\n","Training loss per 100 training steps: 0.021778261428468372\n","Training loss per 100 training steps: 0.02282136157085535\n","Training loss per 100 training steps: 0.022998208947405466\n","Training loss per 100 training steps: 0.023715012593594313\n","Training loss per 100 training steps: 0.023039132748412603\n","Training loss per 100 training steps: 0.022604096948964127\n","Training loss epoch: 0.022160688451113617\n","Training accuracy epoch: 0.9932709005723653\n","Validating model...\n","Validation Loss: 0.17943426590509615\n","Validation Accuracy: 0.9605316402262726\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 49.795238583333294 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1554743057090996\n","Validation Accuracy: 0.9534168916048971\n","Validation duration: 3.1209604833333286 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 84.3%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.86      0.83     12546\n","        test       0.84      0.87      0.85      9012\n","   treatment       0.83      0.86      0.85      9297\n","\n","   micro avg       0.82      0.86      0.84     30855\n","   macro avg       0.82      0.86      0.84     30855\n","weighted avg       0.82      0.86      0.84     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n","Points in X_train after augmentation: 20801\n","Points in y_train after augmentation: 20801\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0688600540161133\n","Training loss per 100 training steps: 0.40992669097267753\n","Training loss per 100 training steps: 0.31546525868462094\n","Training loss per 100 training steps: 0.2685518115016313\n","Training loss per 100 training steps: 0.2394637105861061\n","Training loss per 100 training steps: 0.21755369172474284\n","Training loss per 100 training steps: 0.20676417054822313\n","Training loss epoch: 0.20067574406978309\n","Training accuracy epoch: 0.9366723329285217\n","Validating model...\n","Validation Loss: 0.14411925120496905\n","Validation Accuracy: 0.9524221379943514\n","Training epoch: 2\n","Training loss per 100 training steps: 0.17149588465690613\n","Training loss per 100 training steps: 0.09305436224077303\n","Training loss per 100 training steps: 0.08675134062896765\n","Training loss per 100 training steps: 0.08672573819966907\n","Training loss per 100 training steps: 0.0878542497582232\n","Training loss per 100 training steps: 0.08771364819890487\n","Training loss per 100 training steps: 0.08655710743365193\n","Training loss epoch: 0.08626231249733349\n","Training accuracy epoch: 0.9722776940173085\n","Validating model...\n","Validation Loss: 0.13961524313146417\n","Validation Accuracy: 0.9585451208634016\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0397198311984539\n","Training loss per 100 training steps: 0.048900369527095026\n","Training loss per 100 training steps: 0.046897024416656635\n","Training loss per 100 training steps: 0.04737415856394013\n","Training loss per 100 training steps: 0.04674009014527195\n","Training loss per 100 training steps: 0.04743178315161395\n","Training loss per 100 training steps: 0.04839190275457916\n","Training loss epoch: 0.048332269861435836\n","Training accuracy epoch: 0.9846566247947915\n","Validating model...\n","Validation Loss: 0.15899995144746906\n","Validation Accuracy: 0.9584104238583923\n","Training epoch: 4\n","Training loss per 100 training steps: 0.00558131281286478\n","Training loss per 100 training steps: 0.03531160606255773\n","Training loss per 100 training steps: 0.03424949228094047\n","Training loss per 100 training steps: 0.03496207197566526\n","Training loss per 100 training steps: 0.03518624530386347\n","Training loss per 100 training steps: 0.0347349679428887\n","Training loss per 100 training steps: 0.03504288170452597\n","Training loss epoch: 0.03517160122890809\n","Training accuracy epoch: 0.9890161021408332\n","Validating model...\n","Validation Loss: 0.17990524793503346\n","Validation Accuracy: 0.9562287116186146\n","Training epoch: 5\n","Training loss per 100 training steps: 0.018065357580780983\n","Training loss per 100 training steps: 0.025265589915446494\n","Training loss per 100 training steps: 0.024405139502466873\n","Training loss per 100 training steps: 0.02538453614876058\n","Training loss per 100 training steps: 0.026264401578328146\n","Training loss per 100 training steps: 0.027200211948824826\n","Training loss per 100 training steps: 0.028305620572587068\n","Training loss epoch: 0.02878127695285156\n","Training accuracy epoch: 0.9910192690994392\n","Validating model...\n","Validation Loss: 0.17496758527666717\n","Validation Accuracy: 0.9557666290383854\n","Training epoch: 6\n","Training loss per 100 training steps: 0.01848335564136505\n","Training loss per 100 training steps: 0.021000004194833635\n","Training loss per 100 training steps: 0.022112252446706986\n","Training loss per 100 training steps: 0.02394731525962931\n","Training loss per 100 training steps: 0.025125568241991122\n","Training loss per 100 training steps: 0.025030382948382914\n","Training loss per 100 training steps: 0.025583484725904233\n","Training loss epoch: 0.02600981919629608\n","Training accuracy epoch: 0.9920811324669938\n","Validating model...\n","Validation Loss: 0.19399468206449763\n","Validation Accuracy: 0.958785223876618\n","Training epoch: 7\n","Training loss per 100 training steps: 0.021255826577544212\n","Training loss per 100 training steps: 0.01638437336481333\n","Training loss per 100 training steps: 0.016870805780248094\n","Training loss per 100 training steps: 0.017798891084684847\n","Training loss per 100 training steps: 0.018228696119226052\n","Training loss per 100 training steps: 0.01997465395485748\n","Training loss per 100 training steps: 0.0203151590231118\n","Training loss epoch: 0.02010197716683919\n","Training accuracy epoch: 0.9938691746454404\n","Validating model...\n","Validation Loss: 0.18380505653920692\n","Validation Accuracy: 0.9613926029860943\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 49.77950831666664 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15369321178769935\n","Validation Accuracy: 0.9554172117883512\n","Validation duration: 3.1191551666666784 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 84.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.85      0.84     12546\n","        test       0.84      0.84      0.84      9012\n","   treatment       0.83      0.87      0.85      9297\n","\n","   micro avg       0.83      0.86      0.84     30855\n","   macro avg       0.83      0.86      0.84     30855\n","weighted avg       0.83      0.86      0.84     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n","Points in X_train after augmentation: 20801\n","Points in y_train after augmentation: 20801\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.684262990951538\n","Training loss per 100 training steps: 0.3713156041679996\n","Training loss per 100 training steps: 0.2902640110965985\n","Training loss per 100 training steps: 0.2503268397304901\n","Training loss per 100 training steps: 0.2272015057058257\n","Training loss per 100 training steps: 0.2124214571586507\n","Training loss per 100 training steps: 0.2004904180343655\n","Training loss epoch: 0.19701271226626754\n","Training accuracy epoch: 0.9373611248932994\n","Validating model...\n","Validation Loss: 0.13753708669698084\n","Validation Accuracy: 0.9550659768522999\n","Training epoch: 2\n","Training loss per 100 training steps: 0.060140907764434814\n","Training loss per 100 training steps: 0.08390822600905258\n","Training loss per 100 training steps: 0.08498058366630949\n","Training loss per 100 training steps: 0.0854566764315448\n","Training loss per 100 training steps: 0.08444273105806246\n","Training loss per 100 training steps: 0.08759284341064637\n","Training loss per 100 training steps: 0.0884500713306115\n","Training loss epoch: 0.08773519037464063\n","Training accuracy epoch: 0.9722256522269345\n","Validating model...\n","Validation Loss: 0.13614873963033225\n","Validation Accuracy: 0.9617173186754793\n","Training epoch: 3\n","Training loss per 100 training steps: 0.035951197147369385\n","Training loss per 100 training steps: 0.04561139818391587\n","Training loss per 100 training steps: 0.04695318924003647\n","Training loss per 100 training steps: 0.04766858756337995\n","Training loss per 100 training steps: 0.047454671178273206\n","Training loss per 100 training steps: 0.047598395256805204\n","Training loss per 100 training steps: 0.048882646666694056\n","Training loss epoch: 0.04902502632958846\n","Training accuracy epoch: 0.9847780428072029\n","Validating model...\n","Validation Loss: 0.15487188166128352\n","Validation Accuracy: 0.9579971489808579\n","Training epoch: 4\n","Training loss per 100 training steps: 0.02761821448802948\n","Training loss per 100 training steps: 0.025525377337166137\n","Training loss per 100 training steps: 0.028243344545883325\n","Training loss per 100 training steps: 0.029668196393764792\n","Training loss per 100 training steps: 0.034608204496624946\n","Training loss per 100 training steps: 0.03654866334015574\n","Training loss per 100 training steps: 0.037225583975572143\n","Training loss epoch: 0.03794725366725734\n","Training accuracy epoch: 0.9882676382674952\n","Validating model...\n","Validation Loss: 0.15647447118898491\n","Validation Accuracy: 0.9581154623709456\n","Training epoch: 5\n","Training loss per 100 training steps: 0.005076406989246607\n","Training loss per 100 training steps: 0.02851177034161911\n","Training loss per 100 training steps: 0.027506188648192223\n","Training loss per 100 training steps: 0.02673265686957939\n","Training loss per 100 training steps: 0.027351628957046868\n","Training loss per 100 training steps: 0.026372373148012617\n","Training loss per 100 training steps: 0.02688794500739182\n","Training loss epoch: 0.02708166499048405\n","Training accuracy epoch: 0.9917096384404576\n","Validating model...\n","Validation Loss: 0.17525727270388758\n","Validation Accuracy: 0.9570517052545161\n","Training epoch: 6\n","Training loss per 100 training steps: 0.04320578649640083\n","Training loss per 100 training steps: 0.019728280465570416\n","Training loss per 100 training steps: 0.0230691956164459\n","Training loss per 100 training steps: 0.022950655766615823\n","Training loss per 100 training steps: 0.022614080074360533\n","Training loss per 100 training steps: 0.022498481157918956\n","Training loss per 100 training steps: 0.02316674478140934\n","Training loss epoch: 0.023501019611822896\n","Training accuracy epoch: 0.9929238492309402\n","Validating model...\n","Validation Loss: 0.1766746705942243\n","Validation Accuracy: 0.9586562780648883\n","Training epoch: 7\n","Training loss per 100 training steps: 0.008478643372654915\n","Training loss per 100 training steps: 0.014962810129134703\n","Training loss per 100 training steps: 0.01698658512372394\n","Training loss per 100 training steps: 0.01700314440442701\n","Training loss per 100 training steps: 0.0181007619883036\n","Training loss per 100 training steps: 0.01873267313454787\n","Training loss per 100 training steps: 0.01980644754940309\n","Training loss epoch: 0.0196811727050709\n","Training accuracy epoch: 0.9941860391795162\n","Validating model...\n","Validation Loss: 0.19648570619529573\n","Validation Accuracy: 0.9590538240196377\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 50.056174183333376 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14633211671618349\n","Validation Accuracy: 0.9581453787398642\n","Validation duration: 3.1446583999999955 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 85.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.87      0.85     12546\n","        test       0.84      0.88      0.86      9012\n","   treatment       0.84      0.87      0.85      9297\n","\n","   micro avg       0.84      0.87      0.85     30855\n","   macro avg       0.84      0.87      0.85     30855\n","weighted avg       0.84      0.87      0.85     30855\n","\n","!!!!!! Starting model number 7 !!!!!!\n","Points in X_train after augmentation: 20801\n","Points in y_train after augmentation: 20801\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0665156841278076\n","Training loss per 100 training steps: 0.3955092245325594\n","Training loss per 100 training steps: 0.2998184721861313\n","Training loss per 100 training steps: 0.2570574754026047\n","Training loss per 100 training steps: 0.23144797409450324\n","Training loss per 100 training steps: 0.21391877332728304\n","Training loss per 100 training steps: 0.2013550149447311\n","Training loss epoch: 0.19606415925836462\n","Training accuracy epoch: 0.9379707392713024\n","Validating model...\n","Validation Loss: 0.14120524971709622\n","Validation Accuracy: 0.9539374174757209\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09290634095668793\n","Training loss per 100 training steps: 0.07685347989496619\n","Training loss per 100 training steps: 0.07921820928560412\n","Training loss per 100 training steps: 0.08266250494607659\n","Training loss per 100 training steps: 0.0819715041820508\n","Training loss per 100 training steps: 0.08221671318527526\n","Training loss per 100 training steps: 0.08324547372479457\n","Training loss epoch: 0.08299584707397054\n","Training accuracy epoch: 0.9733288593763382\n","Validating model...\n","Validation Loss: 0.1431581610692786\n","Validation Accuracy: 0.9592367088896506\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03356095030903816\n","Training loss per 100 training steps: 0.04657065768099141\n","Training loss per 100 training steps: 0.0485134739718349\n","Training loss per 100 training steps: 0.049512612265983344\n","Training loss per 100 training steps: 0.0507507015297194\n","Training loss per 100 training steps: 0.05059559198055498\n","Training loss per 100 training steps: 0.050984294226582155\n","Training loss epoch: 0.05152607430774037\n","Training accuracy epoch: 0.9836337737279022\n","Validating model...\n","Validation Loss: 0.15126976310940726\n","Validation Accuracy: 0.9604797108264453\n","Training epoch: 4\n","Training loss per 100 training steps: 0.07167664915323257\n","Training loss per 100 training steps: 0.04315748804543942\n","Training loss per 100 training steps: 0.03948576385804003\n","Training loss per 100 training steps: 0.039399352627017374\n","Training loss per 100 training steps: 0.03986753917768356\n","Training loss per 100 training steps: 0.039717256415917904\n","Training loss per 100 training steps: 0.03978788026588382\n","Training loss epoch: 0.04023950322576406\n","Training accuracy epoch: 0.9871906317873711\n","Validating model...\n","Validation Loss: 0.158697959035635\n","Validation Accuracy: 0.9566945084010748\n","Training epoch: 5\n","Training loss per 100 training steps: 0.08501671999692917\n","Training loss per 100 training steps: 0.02831062365848903\n","Training loss per 100 training steps: 0.027660224979409752\n","Training loss per 100 training steps: 0.0273044937428712\n","Training loss per 100 training steps: 0.027449186954315186\n","Training loss per 100 training steps: 0.02725738403596497\n","Training loss per 100 training steps: 0.02780285896365368\n","Training loss epoch: 0.027689199908436227\n","Training accuracy epoch: 0.9914859959262831\n","Validating model...\n","Validation Loss: 0.166064665713287\n","Validation Accuracy: 0.9613485476117729\n","Training epoch: 6\n","Training loss per 100 training steps: 0.009963994845747948\n","Training loss per 100 training steps: 0.022284246215799657\n","Training loss per 100 training steps: 0.020316854061382773\n","Training loss per 100 training steps: 0.02053591163374137\n","Training loss per 100 training steps: 0.020859254763038956\n","Training loss per 100 training steps: 0.0206139043852791\n","Training loss per 100 training steps: 0.02080084201852681\n","Training loss epoch: 0.02072497239502925\n","Training accuracy epoch: 0.9937428716879801\n","Validating model...\n","Validation Loss: 0.1852017598795136\n","Validation Accuracy: 0.9617007504146786\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 42.6587493666666 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14859687397903246\n","Validation Accuracy: 0.9535725377599514\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation duration: 3.1212255666665443 minutes\n","F1-score (test): 83.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.82      0.83     12546\n","        test       0.83      0.85      0.84      9012\n","   treatment       0.85      0.84      0.85      9297\n","\n","   micro avg       0.84      0.83      0.84     30855\n","   macro avg       0.84      0.83      0.84     30855\n","weighted avg       0.84      0.83      0.84     30855\n","\n","!!!!!! Starting model number 8 !!!!!!\n","Points in X_train after augmentation: 20801\n","Points in y_train after augmentation: 20801\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1724138259887695\n","Training loss per 100 training steps: 0.4191968671166071\n","Training loss per 100 training steps: 0.31006932684882954\n","Training loss per 100 training steps: 0.26399666057324095\n","Training loss per 100 training steps: 0.23647350563372757\n","Training loss per 100 training steps: 0.21919774501296335\n","Training loss per 100 training steps: 0.20397835349146518\n","Training loss epoch: 0.19799312840821365\n","Training accuracy epoch: 0.937152406479441\n","Validating model...\n","Validation Loss: 0.13984077963252345\n","Validation Accuracy: 0.9541937378994831\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07968904078006744\n","Training loss per 100 training steps: 0.08066484131988617\n","Training loss per 100 training steps: 0.08409806765819812\n","Training loss per 100 training steps: 0.08451889977911085\n","Training loss per 100 training steps: 0.08331760487976737\n","Training loss per 100 training steps: 0.08216612305336013\n","Training loss per 100 training steps: 0.08174275913695726\n","Training loss epoch: 0.08201111814067248\n","Training accuracy epoch: 0.973911813210055\n","Validating model...\n","Validation Loss: 0.1574100876202831\n","Validation Accuracy: 0.9523346582798161\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03599683567881584\n","Training loss per 100 training steps: 0.04410457471846649\n","Training loss per 100 training steps: 0.047323877957941435\n","Training loss per 100 training steps: 0.04660524422321407\n","Training loss per 100 training steps: 0.046788355330948224\n","Training loss per 100 training steps: 0.04934517368990296\n","Training loss per 100 training steps: 0.04905407240353959\n","Training loss epoch: 0.04956646468855166\n","Training accuracy epoch: 0.9843823242621205\n","Validating model...\n","Validation Loss: 0.16362521497460156\n","Validation Accuracy: 0.9571891892387139\n","Training epoch: 4\n","Training loss per 100 training steps: 0.024302564561367035\n","Training loss per 100 training steps: 0.027381876329107598\n","Training loss per 100 training steps: 0.026488031876917503\n","Training loss per 100 training steps: 0.028215624106602367\n","Training loss per 100 training steps: 0.03140980651674147\n","Training loss per 100 training steps: 0.03338925075297153\n","Training loss per 100 training steps: 0.034049753436335234\n","Training loss epoch: 0.03531232453468847\n","Training accuracy epoch: 0.9886690207821652\n","Validating model...\n","Validation Loss: 0.1722971127404795\n","Validation Accuracy: 0.9554185552528505\n","Training epoch: 5\n","Training loss per 100 training steps: 0.02004101686179638\n","Training loss per 100 training steps: 0.02738722343122273\n","Training loss per 100 training steps: 0.025092579259893937\n","Training loss per 100 training steps: 0.028522475884045377\n","Training loss per 100 training steps: 0.029837834000520112\n","Training loss per 100 training steps: 0.028563172929581465\n","Training loss per 100 training steps: 0.0296334923754354\n","Training loss epoch: 0.02980794100846041\n","Training accuracy epoch: 0.9909689414711363\n","Validating model...\n","Validation Loss: 0.1857470611424802\n","Validation Accuracy: 0.9560599080396341\n","Training epoch: 6\n","Training loss per 100 training steps: 0.008032411336898804\n","Training loss per 100 training steps: 0.016400503633788206\n","Training loss per 100 training steps: 0.01963631816142336\n","Training loss per 100 training steps: 0.02051142857628921\n","Training loss per 100 training steps: 0.021721102443841307\n","Training loss per 100 training steps: 0.021633051213529052\n","Training loss per 100 training steps: 0.021788101276596264\n","Training loss epoch: 0.02202189332758096\n","Training accuracy epoch: 0.9931531526201339\n","Validating model...\n","Validation Loss: 0.18933882837655483\n","Validation Accuracy: 0.9582658070115907\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 42.62052388333347 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14852375304326415\n","Validation Accuracy: 0.952623711214298\n","Validation duration: 3.114567666666699 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 83.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.84      0.82      0.83     12546\n","        test       0.83      0.85      0.84      9012\n","   treatment       0.83      0.86      0.84      9297\n","\n","   micro avg       0.83      0.84      0.84     30855\n","   macro avg       0.83      0.84      0.84     30855\n","weighted avg       0.83      0.84      0.84     30855\n","\n","!!!!!! Starting model number 9 !!!!!!\n","Points in X_train after augmentation: 20801\n","Points in y_train after augmentation: 20801\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.400984525680542\n","Training loss per 100 training steps: 0.3950181482451977\n","Training loss per 100 training steps: 0.3031724878952871\n","Training loss per 100 training steps: 0.26037711866719776\n","Training loss per 100 training steps: 0.23443766573718064\n","Training loss per 100 training steps: 0.21656325208153315\n","Training loss per 100 training steps: 0.2044392875310486\n","Training loss epoch: 0.19866680166345754\n","Training accuracy epoch: 0.9370785716737148\n","Validating model...\n","Validation Loss: 0.13186535396455945\n","Validation Accuracy: 0.9576550068391617\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06661521643400192\n","Training loss per 100 training steps: 0.08338933243499239\n","Training loss per 100 training steps: 0.08313157777788478\n","Training loss per 100 training steps: 0.08373178324454844\n","Training loss per 100 training steps: 0.08467625752044958\n","Training loss per 100 training steps: 0.08485460745174431\n","Training loss per 100 training steps: 0.08529552040054476\n","Training loss epoch: 0.08471128505407138\n","Training accuracy epoch: 0.9729904486705241\n","Validating model...\n","Validation Loss: 0.13979790052519991\n","Validation Accuracy: 0.958505445597715\n","Training epoch: 3\n","Training loss per 100 training steps: 0.026507046073675156\n","Training loss per 100 training steps: 0.04500587976602192\n","Training loss per 100 training steps: 0.04717066614142624\n","Training loss per 100 training steps: 0.05146318263037013\n","Training loss per 100 training steps: 0.052264381511290176\n","Training loss per 100 training steps: 0.0513821943884273\n","Training loss per 100 training steps: 0.052135082475063134\n","Training loss epoch: 0.05279458110319442\n","Training accuracy epoch: 0.9832020502607897\n","Validating model...\n","Validation Loss: 0.14765801907263018\n","Validation Accuracy: 0.9573697835018473\n","Training epoch: 4\n","Training loss per 100 training steps: 0.05661899223923683\n","Training loss per 100 training steps: 0.03272570762322238\n","Training loss per 100 training steps: 0.032629224230808704\n","Training loss per 100 training steps: 0.03463200490381816\n","Training loss per 100 training steps: 0.03551312887830953\n","Training loss per 100 training steps: 0.036350630614822896\n","Training loss per 100 training steps: 0.036372481376365035\n","Training loss epoch: 0.03646370348370006\n","Training accuracy epoch: 0.9886550752108623\n","Validating model...\n","Validation Loss: 0.16815486485622338\n","Validation Accuracy: 0.9582376489586609\n","Training epoch: 5\n","Training loss per 100 training steps: 0.016808295622467995\n","Training loss per 100 training steps: 0.02533773804834979\n","Training loss per 100 training steps: 0.023799008213155046\n","Training loss per 100 training steps: 0.024571422188530406\n","Training loss per 100 training steps: 0.024856389383495114\n","Training loss per 100 training steps: 0.025620726197902226\n","Training loss per 100 training steps: 0.02688532945593066\n","Training loss epoch: 0.026968492646544266\n","Training accuracy epoch: 0.9917477639636622\n","Validating model...\n","Validation Loss: 0.19486139769145808\n","Validation Accuracy: 0.9585373819207846\n","Training epoch: 6\n","Training loss per 100 training steps: 0.009383948519825935\n","Training loss per 100 training steps: 0.01503012522577889\n","Training loss per 100 training steps: 0.018102752076941474\n","Training loss per 100 training steps: 0.0216674690637227\n","Training loss per 100 training steps: 0.024423136353345257\n","Training loss per 100 training steps: 0.02521221930016587\n","Training loss per 100 training steps: 0.026570206906002623\n","Training loss epoch: 0.02685972442403407\n","Training accuracy epoch: 0.9916073166490182\n","Validating model...\n","Validation Loss: 0.20263364891727248\n","Validation Accuracy: 0.9567698921911167\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 42.98297708333339 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.1456892609507863\n","Validation Accuracy: 0.9539659870224612\n","Validation duration: 3.1396683666668346 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 83.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.82      0.82     12546\n","        test       0.83      0.88      0.85      9012\n","   treatment       0.83      0.86      0.84      9297\n","\n","   micro avg       0.83      0.85      0.84     30855\n","   macro avg       0.83      0.85      0.84     30855\n","weighted avg       0.83      0.85      0.84     30855\n","\n","!!!!!! Starting model number 10 !!!!!!\n","Points in X_train after augmentation: 20801\n","Points in y_train after augmentation: 20801\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.3730525970458984\n","Training loss per 100 training steps: 0.40096137975112045\n","Training loss per 100 training steps: 0.2949830526995718\n","Training loss per 100 training steps: 0.25333570916688325\n","Training loss per 100 training steps: 0.23060346226628284\n","Training loss per 100 training steps: 0.2144672490448176\n","Training loss per 100 training steps: 0.20241485696949202\n","Training loss epoch: 0.19727134174122238\n","Training accuracy epoch: 0.9373124958000522\n","Validating model...\n","Validation Loss: 0.1334257409847402\n","Validation Accuracy: 0.9560612018816432\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06956884264945984\n","Training loss per 100 training steps: 0.07026893212137246\n","Stopping epoch...\n","Training loss epoch: 0.07026893212137246\n","Training accuracy epoch: 0.9677344340257115\n","Validating model...\n","Validation Loss: 0.14532391325413407\n","Validation Accuracy: 0.9575644386114384\n","Training epoch: 3\n","Training loss per 100 training steps: 0.08694010972976685\n","Training loss per 100 training steps: 0.07533087688359884\n","Training loss per 100 training steps: 0.07782478795030076\n","Training loss per 100 training steps: 0.0768003796576909\n","Training loss per 100 training steps: 0.07878358251510416\n","Training loss per 100 training steps: 0.07788315357012068\n","Training loss per 100 training steps: 0.07730459596980332\n","Training loss epoch: 0.0769425108379233\n","Training accuracy epoch: 0.9758402472225662\n","Validating model...\n","Validation Loss: 0.14710517384885968\n","Validation Accuracy: 0.9585562134346817\n","Training epoch: 4\n","Training loss per 100 training steps: 0.04192398861050606\n","Training loss per 100 training steps: 0.041495106229097536\n","Training loss per 100 training steps: 0.04489621821679731\n","Training loss per 100 training steps: 0.0460238059088464\n","Training loss per 100 training steps: 0.04610835180497099\n","Training loss per 100 training steps: 0.04591029801149434\n","Training loss per 100 training steps: 0.04646312794725592\n","Training loss epoch: 0.046650189900368066\n","Training accuracy epoch: 0.9848170333423115\n","Validating model...\n","Validation Loss: 0.1567329897654134\n","Validation Accuracy: 0.9568883286218863\n","Training epoch: 5\n","Training loss per 100 training steps: 0.06405553966760635\n","Training loss per 100 training steps: 0.029687221722197857\n","Training loss per 100 training steps: 0.031202726495864603\n","Training loss per 100 training steps: 0.031672679426216606\n","Training loss per 100 training steps: 0.03204858817155484\n","Training loss per 100 training steps: 0.032290920070995266\n","Training loss per 100 training steps: 0.03288069697865556\n","Training loss epoch: 0.032630509306346214\n","Training accuracy epoch: 0.9895093802099382\n","Validating model...\n","Validation Loss: 0.17362609316969846\n","Validation Accuracy: 0.9591816243031518\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00916222296655178\n","Training loss per 100 training steps: 0.030774306243119557\n","Training loss per 100 training steps: 0.030268749551134025\n","Training loss per 100 training steps: 0.0305470859305469\n","Training loss per 100 training steps: 0.030470113172730028\n","Training loss per 100 training steps: 0.029451297706006067\n","Training loss per 100 training steps: 0.030697597445650475\n","Training loss epoch: 0.030893393415561056\n","Training accuracy epoch: 0.9904197631363035\n","Validating model...\n","Validation Loss: 0.17096362802708012\n","Validation Accuracy: 0.9627773089394703\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 36.837957816666794 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.14362680347187928\n","Validation Accuracy: 0.9548736513115592\n","Validation duration: 3.106869000000006 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 84.3%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.86      0.83     12546\n","        test       0.84      0.89      0.86      9012\n","   treatment       0.85      0.82      0.84      9297\n","\n","   micro avg       0.83      0.86      0.84     30855\n","   macro avg       0.83      0.86      0.84     30855\n","weighted avg       0.83      0.86      0.84     30855\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0.5\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"jdO4m5O4Hlo3"},{"cell_type":"code","execution_count":null,"metadata":{"id":"oKNxFPucHn_R","colab":{"base_uri":"https://localhost:8080/"},"outputId":"731c96ed-d5e0-417d-dff4-2fa60f9e0f36"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 75.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 24268\n","Points in y_train after augmentation: 24268\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.005970001220703\n","Training loss per 100 training steps: 0.3984373606520124\n","Training loss per 100 training steps: 0.2925021595029689\n","Training loss per 100 training steps: 0.2551196350768654\n","Training loss per 100 training steps: 0.23276809071123303\n","Training loss per 100 training steps: 0.211554621496868\n","Training loss per 100 training steps: 0.19950058285500266\n","Training loss per 100 training steps: 0.19022595006361412\n","Training loss epoch: 0.1848659791317382\n","Training accuracy epoch: 0.941474736283104\n","Validating model...\n","Validation Loss: 0.1454852389824855\n","Validation Accuracy: 0.9524450065278287\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04009389132261276\n","Training loss per 100 training steps: 0.07230577860396392\n","Training loss per 100 training steps: 0.08111096224029414\n","Training loss per 100 training steps: 0.08214629663346316\n","Training loss per 100 training steps: 0.08105164838541401\n","Training loss per 100 training steps: 0.08049366658668734\n","Training loss per 100 training steps: 0.07850086495602587\n","Training loss per 100 training steps: 0.07740691111565232\n","Training loss epoch: 0.077408925008657\n","Training accuracy epoch: 0.9755760599365315\n","Validating model...\n","Validation Loss: 0.16521640823452505\n","Validation Accuracy: 0.9541582408977792\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04334810748696327\n","Training loss per 100 training steps: 0.044757899597729786\n","Training loss per 100 training steps: 0.04503647274157004\n","Training loss per 100 training steps: 0.04369904516045116\n","Training loss per 100 training steps: 0.042547380580146454\n","Training loss per 100 training steps: 0.0436755863948727\n","Training loss per 100 training steps: 0.04365583890336201\n","Training loss per 100 training steps: 0.04469773833827247\n","Training loss epoch: 0.0447038748186224\n","Training accuracy epoch: 0.9858459051757954\n","Validating model...\n","Validation Loss: 0.1477646181577599\n","Validation Accuracy: 0.9592353131711772\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0812959149479866\n","Training loss per 100 training steps: 0.02663375394958265\n","Training loss per 100 training steps: 0.029397284080661296\n","Training loss per 100 training steps: 0.031040022626366046\n","Training loss per 100 training steps: 0.03149369027145658\n","Training loss per 100 training steps: 0.03425924968359687\n","Training loss per 100 training steps: 0.03404071866780653\n","Training loss per 100 training steps: 0.033951568090175535\n","Training loss epoch: 0.03408570177535611\n","Training accuracy epoch: 0.9894865631932146\n","Validating model...\n","Validation Loss: 0.17183360474353487\n","Validation Accuracy: 0.9597772969618029\n","Training epoch: 5\n","Training loss per 100 training steps: 0.07036174088716507\n","Training loss per 100 training steps: 0.019444141649908507\n","Training loss per 100 training steps: 0.022068277333251465\n","Training loss per 100 training steps: 0.022412802947861486\n","Training loss per 100 training steps: 0.023305557424056243\n","Training loss per 100 training steps: 0.024149510497552623\n","Training loss per 100 training steps: 0.024366583179460898\n","Training loss per 100 training steps: 0.0257416671222028\n","Training loss epoch: 0.026558408433754288\n","Training accuracy epoch: 0.9919261481357127\n","Validating model...\n","Validation Loss: 0.19208297762390855\n","Validation Accuracy: 0.9559324551763139\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0226595476269722\n","Training loss per 100 training steps: 0.021863238811077976\n","Training loss per 100 training steps: 0.023990185541536344\n","Training loss per 100 training steps: 0.022976956304133347\n","Training loss per 100 training steps: 0.02284168661847836\n","Training loss per 100 training steps: 0.02389137752383423\n","Training loss per 100 training steps: 0.024877707208270445\n","Training loss per 100 training steps: 0.025093665375316467\n","Training loss epoch: 0.025157878291563098\n","Training accuracy epoch: 0.9925175067381288\n","Validating model...\n","Validation Loss: 0.18923689305250133\n","Validation Accuracy: 0.9587894348993057\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 49.79654684999987 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15561804796043024\n","Validation Accuracy: 0.952808219034875\n","Validation duration: 3.14638516666649 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 83.3%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.82      0.82     12546\n","        test       0.83      0.88      0.85      9012\n","   treatment       0.80      0.87      0.83      9297\n","\n","   micro avg       0.81      0.85      0.83     30855\n","   macro avg       0.81      0.86      0.84     30855\n","weighted avg       0.81      0.85      0.83     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 24268\n","Points in y_train after augmentation: 24268\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9679245948791504\n","Training loss per 100 training steps: 0.43061621287966717\n","Training loss per 100 training steps: 0.3123315295843936\n","Training loss per 100 training steps: 0.2653210108289093\n","Training loss per 100 training steps: 0.23808397616531488\n","Training loss per 100 training steps: 0.22029771282525357\n","Training loss per 100 training steps: 0.20553279107129713\n","Training loss per 100 training steps: 0.1963478543778374\n","Training loss epoch: 0.18968584672922123\n","Training accuracy epoch: 0.9398889539537666\n","Validating model...\n","Validation Loss: 0.15155985583732653\n","Validation Accuracy: 0.9536441512573902\n","Training epoch: 2\n","Training loss per 100 training steps: 0.14661109447479248\n","Training loss per 100 training steps: 0.07825137548480589\n","Training loss per 100 training steps: 0.07704850361307165\n","Training loss per 100 training steps: 0.07667354197300154\n","Training loss per 100 training steps: 0.07909121078687564\n","Training loss per 100 training steps: 0.0773109622381464\n","Training loss per 100 training steps: 0.07663339367151856\n","Training loss per 100 training steps: 0.07736936493241328\n","Training loss epoch: 0.0767629798691921\n","Training accuracy epoch: 0.9755886383232132\n","Validating model...\n","Validation Loss: 0.1466632949841487\n","Validation Accuracy: 0.9590282561341866\n","Training epoch: 3\n","Training loss per 100 training steps: 0.00754319503903389\n","Training loss per 100 training steps: 0.04268988950805056\n","Training loss per 100 training steps: 0.04202285225489246\n","Training loss per 100 training steps: 0.04258557973681729\n","Training loss per 100 training steps: 0.04481482862040837\n","Training loss per 100 training steps: 0.04392150576582398\n","Training loss per 100 training steps: 0.04442007664901773\n","Training loss per 100 training steps: 0.04520451654424325\n","Training loss epoch: 0.04612686410279422\n","Training accuracy epoch: 0.9853752705936877\n","Validating model...\n","Validation Loss: 0.16033107973635197\n","Validation Accuracy: 0.9575395865348265\n","Training epoch: 4\n","Training loss per 100 training steps: 0.06315402686595917\n","Training loss per 100 training steps: 0.03334402569482048\n","Training loss per 100 training steps: 0.033172531582215864\n","Training loss per 100 training steps: 0.03424290925197836\n","Training loss per 100 training steps: 0.03360326024366919\n","Training loss per 100 training steps: 0.033834639173131176\n","Training loss per 100 training steps: 0.03213431703286267\n","Training loss per 100 training steps: 0.032798199941963486\n","Training loss epoch: 0.03336659883337932\n","Training accuracy epoch: 0.9896877557174484\n","Validating model...\n","Validation Loss: 0.16273610342245598\n","Validation Accuracy: 0.9593915100315232\n","Training epoch: 5\n","Training loss per 100 training steps: 0.02543533220887184\n","Training loss per 100 training steps: 0.018798764060265247\n","Training loss per 100 training steps: 0.023874242420815654\n","Training loss per 100 training steps: 0.0227051438928885\n","Training loss per 100 training steps: 0.02245945524612437\n","Training loss per 100 training steps: 0.025894554843103695\n","Training loss per 100 training steps: 0.025954436400390777\n","Training loss per 100 training steps: 0.025450061003314848\n","Training loss epoch: 0.025802647611966826\n","Training accuracy epoch: 0.9920152645341711\n","Validating model...\n","Validation Loss: 0.17908925842493773\n","Validation Accuracy: 0.9599398543188451\n","Training epoch: 6\n","Training loss per 100 training steps: 0.002462909556925297\n","Training loss per 100 training steps: 0.019193635315237805\n","Training loss per 100 training steps: 0.019331315292835476\n","Training loss per 100 training steps: 0.018652267551221312\n","Training loss per 100 training steps: 0.019035070833077705\n","Training loss per 100 training steps: 0.019842151753667617\n","Training loss per 100 training steps: 0.019814634334490464\n","Training loss per 100 training steps: 0.01953664425481177\n","Training loss epoch: 0.01977010494092239\n","Training accuracy epoch: 0.9940081307880468\n","Validating model...\n","Validation Loss: 0.1837837605664579\n","Validation Accuracy: 0.958734626290209\n","Training epoch: 7\n","Training loss per 100 training steps: 0.009182466194033623\n","Training loss per 100 training steps: 0.018063201023251887\n","Training loss per 100 training steps: 0.016100003731127743\n","Training loss per 100 training steps: 0.015420741419693875\n","Training loss per 100 training steps: 0.015769197111365797\n","Training loss per 100 training steps: 0.015553668371581578\n","Training loss per 100 training steps: 0.017264077294191358\n","Training loss per 100 training steps: 0.017055335849350498\n","Training loss epoch: 0.017402997878599454\n","Training accuracy epoch: 0.9948645310335279\n","Validating model...\n","Validation Loss: 0.19154092698515235\n","Validation Accuracy: 0.9600231560893814\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 60.493843233333365 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1663411598946604\n","Validation Accuracy: 0.9529349863703557\n","Validation duration: 3.236770916666622 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 84.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.86      0.83     12548\n","        test       0.83      0.85      0.84      9012\n","   treatment       0.84      0.85      0.85      9301\n","\n","   micro avg       0.83      0.85      0.84     30861\n","   macro avg       0.83      0.85      0.84     30861\n","weighted avg       0.83      0.85      0.84     30861\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 24268\n","Points in y_train after augmentation: 24268\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.70485520362854\n","Training loss per 100 training steps: 0.40743499404132955\n","Training loss per 100 training steps: 0.30648536787400793\n","Training loss per 100 training steps: 0.2636523578575877\n","Training loss per 100 training steps: 0.23744090150419317\n","Training loss per 100 training steps: 0.21963903641034505\n","Training loss per 100 training steps: 0.20632217278992276\n","Training loss per 100 training steps: 0.1957328044776187\n","Training loss epoch: 0.19247068699120454\n","Training accuracy epoch: 0.9392046017890855\n","Validating model...\n","Validation Loss: 0.13204641635348272\n","Validation Accuracy: 0.9568813319248185\n","Training epoch: 2\n","Training loss per 100 training steps: 0.22830891609191895\n","Training loss per 100 training steps: 0.08126468320220413\n","Training loss per 100 training steps: 0.07945426510396733\n","Training loss per 100 training steps: 0.07972235415607344\n","Training loss per 100 training steps: 0.08131661084817346\n","Training loss per 100 training steps: 0.08039452271450483\n","Training loss per 100 training steps: 0.07989670889771322\n","Training loss per 100 training steps: 0.07971020813728451\n","Training loss epoch: 0.0795659084174885\n","Training accuracy epoch: 0.9748209757744177\n","Validating model...\n","Validation Loss: 0.13993143298747865\n","Validation Accuracy: 0.9584990962338612\n","Training epoch: 3\n","Training loss per 100 training steps: 0.05213597044348717\n","Training loss per 100 training steps: 0.040921394344382356\n","Training loss per 100 training steps: 0.04398567273295415\n","Training loss per 100 training steps: 0.04687203111380735\n","Training loss per 100 training steps: 0.04876205816103187\n","Training loss per 100 training steps: 0.04909774466806246\n","Training loss per 100 training steps: 0.04901880652375656\n","Training loss per 100 training steps: 0.04977405095969814\n","Training loss epoch: 0.04996855064124674\n","Training accuracy epoch: 0.9839137785127673\n","Validating model...\n","Validation Loss: 0.14748763294237388\n","Validation Accuracy: 0.9586951600181457\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01990395411849022\n","Training loss per 100 training steps: 0.034039323397976634\n","Training loss per 100 training steps: 0.0349741244146517\n","Training loss per 100 training steps: 0.03422397500262952\n","Training loss per 100 training steps: 0.034219244155949194\n","Training loss per 100 training steps: 0.034806958013985624\n","Training loss per 100 training steps: 0.03526609631049169\n","Training loss per 100 training steps: 0.03504149886060735\n","Training loss epoch: 0.03538999450607753\n","Training accuracy epoch: 0.9890528977979621\n","Validating model...\n","Validation Loss: 0.17100461301478473\n","Validation Accuracy: 0.9584080987250458\n","Training epoch: 5\n","Training loss per 100 training steps: 0.026578474789857864\n","Training loss per 100 training steps: 0.022362409772738668\n","Training loss per 100 training steps: 0.023472039616581016\n","Training loss per 100 training steps: 0.02318955532780251\n","Training loss per 100 training steps: 0.021675462030806808\n","Training loss per 100 training steps: 0.022670040490220072\n","Training loss per 100 training steps: 0.02378622713154368\n","Training loss per 100 training steps: 0.025337732571974986\n","Training loss epoch: 0.026302765997734696\n","Training accuracy epoch: 0.991767408844878\n","Validating model...\n","Validation Loss: 0.17264120075125972\n","Validation Accuracy: 0.9580136216928445\n","Training epoch: 6\n","Training loss per 100 training steps: 0.05639395862817764\n","Training loss per 100 training steps: 0.019567516589730903\n","Training loss per 100 training steps: 0.01781385587192423\n","Training loss per 100 training steps: 0.01972555677581306\n","Training loss per 100 training steps: 0.020451951994934582\n","Training loss per 100 training steps: 0.020202541455697127\n","Training loss per 100 training steps: 0.021634749907414475\n","Training loss per 100 training steps: 0.022607579858695954\n","Training loss epoch: 0.023442847697323185\n","Training accuracy epoch: 0.9925749215058437\n","Validating model...\n","Validation Loss: 0.17934716778335633\n","Validation Accuracy: 0.955732170241532\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 49.465025500000046 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1401378643974938\n","Validation Accuracy: 0.9559033835801839\n","Validation duration: 3.116663833333344 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 84.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.85      0.84     12546\n","        test       0.82      0.89      0.85      9012\n","   treatment       0.79      0.87      0.83      9297\n","\n","   micro avg       0.81      0.87      0.84     30855\n","   macro avg       0.81      0.87      0.84     30855\n","weighted avg       0.81      0.87      0.84     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 24268\n","Points in y_train after augmentation: 24268\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.030888557434082\n","Training loss per 100 training steps: 0.3749566896274538\n","Training loss per 100 training steps: 0.28791206215151505\n","Training loss per 100 training steps: 0.2488049617488915\n","Training loss per 100 training steps: 0.22766015245730145\n","Training loss per 100 training steps: 0.21031083920580185\n","Training loss per 100 training steps: 0.19774735934053006\n","Training loss per 100 training steps: 0.18831939798927255\n","Training loss epoch: 0.18324263954635744\n","Training accuracy epoch: 0.9423582049337285\n","Validating model...\n","Validation Loss: 0.142904680851218\n","Validation Accuracy: 0.9557037964723885\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05422339588403702\n","Training loss per 100 training steps: 0.0789579123461453\n","Training loss per 100 training steps: 0.08015364522475805\n","Training loss per 100 training steps: 0.08071681944053137\n","Training loss per 100 training steps: 0.07918647196413275\n","Training loss per 100 training steps: 0.07838193153750575\n","Training loss per 100 training steps: 0.07800509381617811\n","Training loss per 100 training steps: 0.07843874790672527\n","Training loss epoch: 0.07813882439400957\n","Training accuracy epoch: 0.9751633079688564\n","Validating model...\n","Validation Loss: 0.1544133760035038\n","Validation Accuracy: 0.9559670352334296\n","Training epoch: 3\n","Training loss per 100 training steps: 0.08931683748960495\n","Training loss per 100 training steps: 0.0376838665584674\n","Training loss per 100 training steps: 0.038070841385422285\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0.75\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"oKNxFPucHn_R"},{"cell_type":"code","source":["number_of_training_models = 7\n","target_augmented_percentage = 0.75\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d9f0b9ae8d0546db80f9cb12875bbcef","03865262b13d4efd97c723b0fdd9dd63","6b7cea4a2e8d409684046d9948f604ed","f3b4bf41e84f493ebd336d2f8ebef0fa","419647acffe44cf8af8c3cdc2ac5881e","6c1cf6e4b4f845fbbcb1a69b6a831898","00b9ceb383a147afb22a910524f78027","779834bc12504206ba8290dc958e1b9a","3add213c02694bbea7b17ae5c9ef590c","bdccdad425e3455a93f14473e9ea089e","cd969dfca6fa48e59c91e149dda1f46b"]},"id":"AmYFCXmrpt1Q","outputId":"73c67deb-f66c-4673-81bd-07c3aa2972de"},"id":"AmYFCXmrpt1Q","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["!!!!!! Augmented Percentage 75.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 24268\n","Points in y_train after augmentation: 24268\n","Device:  cuda\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/422M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9f0b9ae8d0546db80f9cb12875bbcef"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.265089750289917\n","Training loss per 100 training steps: 0.3843050215503957\n","Training loss per 100 training steps: 0.2984542346267558\n","Training loss per 100 training steps: 0.2595073451532478\n","Training loss per 100 training steps: 0.234824887507054\n","Training loss per 100 training steps: 0.217509562428483\n","Training loss per 100 training steps: 0.2039754932619222\n","Training loss per 100 training steps: 0.19415700057529434\n","Training loss epoch: 0.18908923381647494\n","Training accuracy epoch: 0.9408345379502077\n","Validating model...\n","Validation Loss: 0.14192415178789722\n","Validation Accuracy: 0.955069028582275\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0677732452750206\n","Training loss per 100 training steps: 0.09137875837559747\n","Training loss per 100 training steps: 0.08303509409358698\n","Training loss per 100 training steps: 0.07930348680178291\n","Training loss per 100 training steps: 0.0788143465662389\n","Training loss per 100 training steps: 0.07956180998501544\n","Training loss per 100 training steps: 0.07971079219690526\n","Training loss per 100 training steps: 0.08104501650954321\n","Training loss epoch: 0.08154136349958747\n","Training accuracy epoch: 0.9745307168616004\n","Validating model...\n","Validation Loss: 0.13981249913960309\n","Validation Accuracy: 0.9574858266274161\n","Training epoch: 3\n","Training loss per 100 training steps: 0.053944408893585205\n","Training loss per 100 training steps: 0.051371660632182764\n","Training loss per 100 training steps: 0.04807530337740755\n","Training loss per 100 training steps: 0.04877491218449418\n","Training loss per 100 training steps: 0.04742257965686836\n","Training loss per 100 training steps: 0.047274102973649486\n","Training loss per 100 training steps: 0.046365178330412475\n","Training loss per 100 training steps: 0.047289139202552795\n","Training loss epoch: 0.04748819175953038\n","Training accuracy epoch: 0.985174425826798\n","Validating model...\n","Validation Loss: 0.1653033382223024\n","Validation Accuracy: 0.9550626911617681\n","Training epoch: 4\n","Training loss per 100 training steps: 0.018026888370513916\n","Training loss per 100 training steps: 0.03228211691049804\n","Training loss per 100 training steps: 0.032110253251065035\n","Training loss per 100 training steps: 0.03209759321634618\n","Training loss per 100 training steps: 0.032288408990336255\n","Training loss per 100 training steps: 0.03373321215482707\n","Training loss per 100 training steps: 0.03370024508912079\n","Training loss per 100 training steps: 0.034303707970251805\n","Training loss epoch: 0.03503058078543594\n","Training accuracy epoch: 0.9892613124597165\n","Validating model...\n","Validation Loss: 0.16199367701426728\n","Validation Accuracy: 0.9581292210886141\n","Training epoch: 5\n","Training loss per 100 training steps: 0.03164798393845558\n","Training loss per 100 training steps: 0.022915168136293716\n","Training loss per 100 training steps: 0.023419513264022286\n","Training loss per 100 training steps: 0.024021364174523326\n","Training loss per 100 training steps: 0.023572681328871675\n","Training loss per 100 training steps: 0.024494757953642712\n","Training loss per 100 training steps: 0.026063038483099352\n","Training loss per 100 training steps: 0.025458081109172262\n","Training loss epoch: 0.025528616233644774\n","Training accuracy epoch: 0.9922834646002413\n","Validating model...\n","Validation Loss: 0.17038111042158752\n","Validation Accuracy: 0.962660589796227\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0030791943427175283\n","Training loss per 100 training steps: 0.018252020557687647\n","Training loss per 100 training steps: 0.017767509049678044\n","Training loss per 100 training steps: 0.01860762437580438\n","Training loss per 100 training steps: 0.01948096722357458\n","Training loss per 100 training steps: 0.01928083746288085\n","Training loss per 100 training steps: 0.02077580353202718\n","Training loss per 100 training steps: 0.0216582624624751\n","Training loss epoch: 0.02219994464592839\n","Training accuracy epoch: 0.9932860301730427\n","Validating model...\n","Validation Loss: 0.18800911128327444\n","Validation Accuracy: 0.9573425413083622\n","Training epoch: 7\n","Training loss per 100 training steps: 0.033847566694021225\n","Training loss per 100 training steps: 0.018937940809571435\n","Training loss per 100 training steps: 0.018670312376850427\n","Training loss per 100 training steps: 0.017767071364442832\n","Training loss per 100 training steps: 0.017815042723886475\n","Training loss per 100 training steps: 0.017644637583465895\n","Training loss per 100 training steps: 0.0194658077700248\n","Training loss per 100 training steps: 0.02100844820720554\n","Training loss epoch: 0.021459346281441864\n","Training accuracy epoch: 0.993248408631619\n","Validating model...\n","Validation Loss: 0.19319139434139596\n","Validation Accuracy: 0.95901511471905\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 55.97009121666667 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.15123517394143468\n","Validation Accuracy: 0.9554844441733311\n","Validation duration: 3.1109734500000057 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 84.8%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.85      0.84     12546\n","        test       0.84      0.87      0.86      9012\n","   treatment       0.83      0.87      0.85      9297\n","\n","   micro avg       0.83      0.86      0.85     30855\n","   macro avg       0.83      0.86      0.85     30855\n","weighted avg       0.83      0.86      0.85     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 24268\n","Points in y_train after augmentation: 24268\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.238736629486084\n","Training loss per 100 training steps: 0.4285471218057198\n","Training loss per 100 training steps: 0.3172726249183292\n","Training loss per 100 training steps: 0.2666466032646819\n","Training loss per 100 training steps: 0.23724172054383522\n","Training loss per 100 training steps: 0.22098474091517473\n","Training loss per 100 training steps: 0.2093102959373628\n","Training loss per 100 training steps: 0.1999109758385663\n","Training loss epoch: 0.19365784877786052\n","Training accuracy epoch: 0.939101459745389\n","Validating model...\n","Validation Loss: 0.15846093020752652\n","Validation Accuracy: 0.9466454192406505\n","Training epoch: 2\n","Training loss per 100 training steps: 0.11046714335680008\n","Training loss per 100 training steps: 0.08345198341746732\n","Training loss per 100 training steps: 0.08478744791366567\n","Training loss per 100 training steps: 0.08579515209081165\n","Training loss per 100 training steps: 0.08344953769627503\n","Training loss per 100 training steps: 0.08375833590260284\n","Training loss per 100 training steps: 0.08315263125431815\n","Training loss per 100 training steps: 0.08272408992158363\n","Training loss epoch: 0.08174305605641977\n","Training accuracy epoch: 0.9744831625941248\n","Validating model...\n","Validation Loss: 0.15321270866900102\n","Validation Accuracy: 0.9597640076056069\n","Training epoch: 3\n","Training loss per 100 training steps: 0.07343951612710953\n","Training loss per 100 training steps: 0.04269414850612088\n","Training loss per 100 training steps: 0.04673841232619253\n","Training loss per 100 training steps: 0.046140070754007445\n","Training loss per 100 training steps: 0.04717137513942366\n","Training loss per 100 training steps: 0.04826145952506113\n","Training loss per 100 training steps: 0.04919340405744902\n","Training loss per 100 training steps: 0.04960376920062948\n","Training loss epoch: 0.05000443874958937\n","Training accuracy epoch: 0.9847428663237028\n","Validating model...\n","Validation Loss: 0.16135502748142977\n","Validation Accuracy: 0.957878288206695\n","Training epoch: 4\n","Training loss per 100 training steps: 0.013567023910582066\n","Training loss per 100 training steps: 0.026401534314626957\n","Training loss per 100 training steps: 0.028783920323545698\n","Training loss per 100 training steps: 0.03020342864038924\n","Training loss per 100 training steps: 0.031015255383652476\n","Training loss per 100 training steps: 0.03197342321902194\n","Training loss per 100 training steps: 0.0320109807895481\n","Training loss per 100 training steps: 0.03301326358294282\n","Training loss epoch: 0.03354747491359235\n","Training accuracy epoch: 0.989760728544137\n","Validating model...\n","Validation Loss: 0.1842749153638815\n","Validation Accuracy: 0.9565860974527475\n","Training epoch: 5\n","Training loss per 100 training steps: 0.007263944484293461\n","Training loss per 100 training steps: 0.027169657044693606\n","Training loss per 100 training steps: 0.029848075594604756\n","Training loss per 100 training steps: 0.027576592263914148\n","Training loss per 100 training steps: 0.026568445933580938\n","Training loss per 100 training steps: 0.027019307983736182\n","Training loss per 100 training steps: 0.027315584560523055\n","Training loss per 100 training steps: 0.027729495510043105\n","Training loss epoch: 0.02782821289447108\n","Training accuracy epoch: 0.9914117927213539\n","Validating model...\n","Validation Loss: 0.1938378196935375\n","Validation Accuracy: 0.9555919162433352\n","Training epoch: 6\n","Training loss per 100 training steps: 0.02607002481818199\n","Training loss per 100 training steps: 0.021102306388645884\n","Training loss per 100 training steps: 0.022081648961893418\n","Training loss per 100 training steps: 0.022344519163170935\n","Training loss per 100 training steps: 0.022727308096509295\n","Training loss per 100 training steps: 0.022854179664986197\n","Training loss per 100 training steps: 0.022864307965614526\n","Training loss per 100 training steps: 0.02436032222732357\n","Training loss epoch: 0.02456299994502533\n","Training accuracy epoch: 0.992597953728326\n","Validating model...\n","Validation Loss: 0.19774778853714853\n","Validation Accuracy: 0.9578121143418797\n","Training epoch: 7\n","Training loss per 100 training steps: 0.005621203687041998\n","Training loss per 100 training steps: 0.019011405368086577\n","Training loss per 100 training steps: 0.018746418356015093\n","Training loss per 100 training steps: 0.01838876772691276\n","Training loss per 100 training steps: 0.019399566912647347\n","Training loss per 100 training steps: 0.01948751613243061\n","Training loss per 100 training steps: 0.01952578579311952\n","Training loss per 100 training steps: 0.020241503353820536\n","Training loss epoch: 0.020610844516115598\n","Training accuracy epoch: 0.9941170630746337\n","Validating model...\n","Validation Loss: 0.19777144065925054\n","Validation Accuracy: 0.9585306225540499\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 57.161541616666675 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.16160805247178628\n","Validation Accuracy: 0.9564495149017015\n","Validation duration: 3.1850954166666723 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 85.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.88      0.85     12546\n","        test       0.83      0.88      0.86      9012\n","   treatment       0.84      0.86      0.85      9297\n","\n","   micro avg       0.83      0.88      0.85     30855\n","   macro avg       0.83      0.87      0.85     30855\n","weighted avg       0.83      0.88      0.85     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 24268\n","Points in y_train after augmentation: 24268\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9797914028167725\n","Training loss per 100 training steps: 0.3907171476005328\n","Training loss per 100 training steps: 0.28899531870783857\n","Training loss per 100 training steps: 0.2508267923645007\n","Training loss per 100 training steps: 0.2289808863527757\n","Training loss per 100 training steps: 0.21455072039764322\n","Training loss per 100 training steps: 0.2025717328087165\n","Training loss per 100 training steps: 0.19173890762243648\n","Training loss epoch: 0.1875529342474556\n","Training accuracy epoch: 0.9405105598742591\n","Validating model...\n","Validation Loss: 0.13055799410424448\n","Validation Accuracy: 0.9574680615037529\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05992136895656586\n","Training loss per 100 training steps: 0.07452051532869734\n","Training loss per 100 training steps: 0.07592681978611433\n","Training loss per 100 training steps: 0.07846291793782598\n","Training loss per 100 training steps: 0.07953902819261252\n","Training loss per 100 training steps: 0.07878932334062552\n","Training loss per 100 training steps: 0.07954441777317352\n","Training loss per 100 training steps: 0.0797323447880674\n","Training loss epoch: 0.07947559760820871\n","Training accuracy epoch: 0.9751839868039041\n","Validating model...\n","Validation Loss: 0.1499297735220813\n","Validation Accuracy: 0.9568321650394539\n","Training epoch: 3\n","Training loss per 100 training steps: 0.044320426881313324\n","Training loss per 100 training steps: 0.04234800067739469\n","Training loss per 100 training steps: 0.043320910033274124\n","Training loss per 100 training steps: 0.04353528624118934\n","Training loss per 100 training steps: 0.04275892934810714\n","Training loss per 100 training steps: 0.04496806097809902\n","Training loss per 100 training steps: 0.04643988302101485\n","Training loss per 100 training steps: 0.04634756080609628\n","Training loss epoch: 0.04714205058055963\n","Training accuracy epoch: 0.9853713729014792\n","Validating model...\n","Validation Loss: 0.14825755258562504\n","Validation Accuracy: 0.9566574669731287\n","Training epoch: 4\n","Training loss per 100 training steps: 0.018425090238451958\n","Training loss per 100 training steps: 0.02264353470406541\n","Training loss per 100 training steps: 0.024340131615151868\n","Training loss per 100 training steps: 0.027329140497283372\n","Training loss per 100 training steps: 0.029711492841411846\n","Training loss per 100 training steps: 0.031515992417240964\n","Training loss per 100 training steps: 0.03211493071609529\n","Training loss per 100 training steps: 0.03268905228535949\n","Training loss epoch: 0.03329282081412944\n","Training accuracy epoch: 0.9896994829042941\n","Validating model...\n","Validation Loss: 0.16559713917433636\n","Validation Accuracy: 0.959942444471654\n","Training epoch: 5\n","Training loss per 100 training steps: 0.005756603088229895\n","Training loss per 100 training steps: 0.021024141854855537\n","Training loss per 100 training steps: 0.022810037557408677\n","Training loss per 100 training steps: 0.027116239161781373\n","Training loss per 100 training steps: 0.02786661155824956\n","Training loss per 100 training steps: 0.027753465725973384\n","Training loss per 100 training steps: 0.027801451102610425\n","Training loss per 100 training steps: 0.02737899415253777\n","Training loss epoch: 0.027882943574749595\n","Training accuracy epoch: 0.9910846000246698\n","Validating model...\n","Validation Loss: 0.1791526580156831\n","Validation Accuracy: 0.9578280777677047\n","Training epoch: 6\n","Training loss per 100 training steps: 0.009229779243469238\n","Training loss per 100 training steps: 0.01711464664002069\n","Training loss per 100 training steps: 0.017582383585123075\n","Training loss per 100 training steps: 0.017697527384086885\n","Training loss per 100 training steps: 0.017850477030841017\n","Training loss per 100 training steps: 0.017459329646038906\n","Training loss per 100 training steps: 0.019568589173033432\n","Training loss per 100 training steps: 0.02087320421764909\n","Training loss epoch: 0.021209862627158352\n","Training accuracy epoch: 0.9933410799389725\n","Validating model...\n","Validation Loss: 0.19752159942086642\n","Validation Accuracy: 0.9549045588845423\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 47.84348968333334 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.14301128401550361\n","Validation Accuracy: 0.9529960516840921\n","Validation duration: 3.0823407999999897 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 84.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.88      0.84     12546\n","        test       0.86      0.85      0.85      9012\n","   treatment       0.80      0.87      0.83      9297\n","\n","   micro avg       0.81      0.87      0.84     30855\n","   macro avg       0.82      0.87      0.84     30855\n","weighted avg       0.81      0.87      0.84     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 24268\n","Points in y_train after augmentation: 24268\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.493988275527954\n","Training loss per 100 training steps: 0.40528133511543274\n","Training loss per 100 training steps: 0.30326657497615955\n","Training loss per 100 training steps: 0.2606210237325624\n","Training loss per 100 training steps: 0.23486331553010276\n","Training loss per 100 training steps: 0.21660803631691639\n","Training loss per 100 training steps: 0.2045799660404986\n","Training loss per 100 training steps: 0.19384067650677134\n","Training loss epoch: 0.18682322182909775\n","Training accuracy epoch: 0.940913542568207\n","Validating model...\n","Validation Loss: 0.1272990307589243\n","Validation Accuracy: 0.9588042674811375\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07159654796123505\n","Training loss per 100 training steps: 0.080885478396817\n","Training loss per 100 training steps: 0.07950654474378967\n","Training loss per 100 training steps: 0.07770586855697176\n","Training loss per 100 training steps: 0.07851411779631774\n","Training loss per 100 training steps: 0.07831601679563047\n","Training loss per 100 training steps: 0.07712540355822484\n","Training loss per 100 training steps: 0.07620230247831229\n","Training loss epoch: 0.0769119838452671\n","Training accuracy epoch: 0.975312364653335\n","Validating model...\n","Validation Loss: 0.1412383159985403\n","Validation Accuracy: 0.9596889437357048\n","Training epoch: 3\n","Training loss per 100 training steps: 0.07682371884584427\n","Training loss per 100 training steps: 0.0524089262073878\n","Training loss per 100 training steps: 0.04622404469380999\n","Training loss per 100 training steps: 0.044787648624347594\n","Training loss per 100 training steps: 0.04661699943012207\n","Training loss per 100 training steps: 0.048279571583022374\n","Training loss per 100 training steps: 0.050151460522788884\n","Training loss per 100 training steps: 0.04984417866673666\n","Training loss epoch: 0.0498345813686973\n","Training accuracy epoch: 0.98450836020097\n","Validating model...\n","Validation Loss: 0.15113883272006914\n","Validation Accuracy: 0.9609330311566263\n","Training epoch: 4\n","Training loss per 100 training steps: 0.04488331824541092\n","Training loss per 100 training steps: 0.02313301851857675\n","Training loss per 100 training steps: 0.027596693163371613\n","Training loss per 100 training steps: 0.029509739298218755\n","Training loss per 100 training steps: 0.032417191595461525\n","Training loss per 100 training steps: 0.033080366171037635\n","Training loss per 100 training steps: 0.03287539746788192\n","Training loss per 100 training steps: 0.032800681406290624\n","Training loss epoch: 0.032443051599917075\n","Training accuracy epoch: 0.9896519092115527\n","Validating model...\n","Validation Loss: 0.1774145619967928\n","Validation Accuracy: 0.9575532791885947\n","Training epoch: 5\n","Training loss per 100 training steps: 0.003289189888164401\n","Training loss per 100 training steps: 0.024848948344058073\n","Training loss per 100 training steps: 0.023032619791344012\n","Training loss per 100 training steps: 0.02157223996751945\n","Training loss per 100 training steps: 0.023329674249876087\n","Training loss per 100 training steps: 0.024207783206398534\n","Training loss per 100 training steps: 0.024172597664029502\n","Training loss per 100 training steps: 0.024579589539051414\n","Training loss epoch: 0.024964801419807944\n","Training accuracy epoch: 0.9923169627442056\n","Validating model...\n","Validation Loss: 0.19191011800974994\n","Validation Accuracy: 0.9594615587226218\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0024830149486660957\n","Training loss per 100 training steps: 0.016284050225132688\n","Training loss per 100 training steps: 0.017808326083468273\n","Training loss per 100 training steps: 0.017574877231524934\n","Training loss per 100 training steps: 0.018943983862107442\n","Training loss per 100 training steps: 0.019341254855997345\n","Training loss per 100 training steps: 0.01942747092373652\n","Training loss per 100 training steps: 0.020749398908279267\n","Training loss epoch: 0.02119058786084776\n","Training accuracy epoch: 0.993521707334956\n","Validating model...\n","Validation Loss: 0.2013482955925457\n","Validation Accuracy: 0.9571221039240635\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 47.83060421666666 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.13497852707277397\n","Validation Accuracy: 0.9577486821589126\n","Validation duration: 3.06111868333334 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 85.1%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.85      0.84     12546\n","        test       0.85      0.87      0.86      9012\n","   treatment       0.85      0.86      0.86      9297\n","\n","   micro avg       0.84      0.86      0.85     30855\n","   macro avg       0.84      0.86      0.85     30855\n","weighted avg       0.84      0.86      0.85     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n","Points in X_train after augmentation: 24268\n","Points in y_train after augmentation: 24268\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7267733812332153\n","Training loss per 100 training steps: 0.39620400817677526\n","Training loss per 100 training steps: 0.2982636620452748\n","Training loss per 100 training steps: 0.2518573114493757\n","Training loss per 100 training steps: 0.22978659353202716\n","Training loss per 100 training steps: 0.21261553885694034\n","Training loss per 100 training steps: 0.20189146081391665\n","Training loss per 100 training steps: 0.19143045452368923\n","Training loss epoch: 0.18696633131489923\n","Training accuracy epoch: 0.9411796833484103\n","Validating model...\n","Validation Loss: 0.14450274357064205\n","Validation Accuracy: 0.9535357395532642\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05393189936876297\n","Training loss per 100 training steps: 0.07588962732012024\n","Training loss per 100 training steps: 0.07444844772548076\n","Training loss per 100 training steps: 0.07715220436410503\n","Training loss per 100 training steps: 0.07672810969186802\n","Training loss per 100 training steps: 0.07671032959275587\n","Training loss per 100 training steps: 0.07647222899188738\n","Training loss per 100 training steps: 0.07712789331383461\n","Stopping epoch...\n","Training loss epoch: 0.07712789331383461\n","Training accuracy epoch: 0.9742236240736241\n","Validating model...\n","Validation Loss: 0.1334105645149172\n","Validation Accuracy: 0.9594147658777906\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03244367241859436\n","Training loss per 100 training steps: 0.04497493334612487\n","Training loss per 100 training steps: 0.04929705334604898\n","Training loss per 100 training steps: 0.04946514700486811\n","Training loss per 100 training steps: 0.05010942496740238\n","Training loss per 100 training steps: 0.04983241655055188\n","Training loss per 100 training steps: 0.05041210779597899\n","Training loss per 100 training steps: 0.05075777549503873\n","Training loss epoch: 0.05142927097649914\n","Training accuracy epoch: 0.9846348711708419\n","Validating model...\n","Validation Loss: 0.16025495322348624\n","Validation Accuracy: 0.9554256947500861\n","Training epoch: 4\n","Training loss per 100 training steps: 0.020504634827375412\n","Training loss per 100 training steps: 0.03073302413323101\n","Training loss per 100 training steps: 0.034601398491745455\n","Training loss per 100 training steps: 0.03440589503736306\n","Training loss per 100 training steps: 0.03526427252293608\n","Training loss per 100 training steps: 0.03656438991874494\n","Training loss per 100 training steps: 0.03603838324820322\n","Training loss per 100 training steps: 0.03547175558527716\n","Training loss epoch: 0.03562604269790138\n","Training accuracy epoch: 0.9889833088698052\n","Validating model...\n","Validation Loss: 0.16499079069630665\n","Validation Accuracy: 0.9597204445688796\n","Training epoch: 5\n","Training loss per 100 training steps: 0.013095101341605186\n","Training loss per 100 training steps: 0.022919819104752624\n","Training loss per 100 training steps: 0.02073325200379358\n","Training loss per 100 training steps: 0.022557688671615953\n","Training loss per 100 training steps: 0.023706058411570984\n","Training loss per 100 training steps: 0.024730846927847022\n","Training loss per 100 training steps: 0.02502405634882105\n","Training loss per 100 training steps: 0.025298428657456712\n","Training loss epoch: 0.02553161264508251\n","Training accuracy epoch: 0.9922227620467426\n","Validating model...\n","Validation Loss: 0.18438452288097182\n","Validation Accuracy: 0.9583825190687818\n","Training epoch: 6\n","Training loss per 100 training steps: 0.11816074699163437\n","Training loss per 100 training steps: 0.020920442742304785\n","Training loss per 100 training steps: 0.02122410336643717\n","Training loss per 100 training steps: 0.021219644584519744\n","Training loss per 100 training steps: 0.020980685223834564\n","Training loss per 100 training steps: 0.020646922689762166\n","Training loss per 100 training steps: 0.020671321152354562\n","Training loss per 100 training steps: 0.021394490230975994\n","Training loss epoch: 0.02191229387768084\n","Training accuracy epoch: 0.9934779355380043\n","Validating model...\n","Validation Loss: 0.17076012184964373\n","Validation Accuracy: 0.959915015344953\n","Training epoch: 7\n","Training loss per 100 training steps: 0.03000325709581375\n","Training loss per 100 training steps: 0.020381800731238308\n","Training loss per 100 training steps: 0.020885760453993\n","Training loss per 100 training steps: 0.02082560624288352\n","Training loss per 100 training steps: 0.020711318110005508\n","Training loss per 100 training steps: 0.02024229159409054\n","Training loss per 100 training steps: 0.020734969388274013\n","Training loss per 100 training steps: 0.020750502406789877\n","Training loss epoch: 0.020335271712042864\n","Training accuracy epoch: 0.9940755317438015\n","Validating model...\n","Validation Loss: 0.2148221569353497\n","Validation Accuracy: 0.9572610559452862\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 55.19627366666664 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.15085487904596245\n","Validation Accuracy: 0.9555450422978194\n","Validation duration: 3.0834381499999535 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 84.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.87      0.85     12546\n","        test       0.84      0.86      0.85      9012\n","   treatment       0.83      0.86      0.85      9297\n","\n","   micro avg       0.83      0.86      0.85     30855\n","   macro avg       0.83      0.86      0.85     30855\n","weighted avg       0.83      0.86      0.85     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n","Points in X_train after augmentation: 24268\n","Points in y_train after augmentation: 24268\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7166835069656372\n","Training loss per 100 training steps: 0.40241963910584405\n","Training loss per 100 training steps: 0.2959689086127044\n","Training loss per 100 training steps: 0.25665935259498035\n","Training loss per 100 training steps: 0.23443479694314578\n","Training loss per 100 training steps: 0.21528849776038628\n","Training loss per 100 training steps: 0.2026179850584953\n","Training loss per 100 training steps: 0.190972428891101\n","Training loss epoch: 0.18571827758461903\n","Training accuracy epoch: 0.9407664842193755\n","Validating model...\n","Validation Loss: 0.1410094447095286\n","Validation Accuracy: 0.9544174020334125\n","Training epoch: 2\n","Training loss per 100 training steps: 0.08920860290527344\n","Training loss per 100 training steps: 0.0657078799708645\n","Training loss per 100 training steps: 0.07052838254201027\n","Training loss per 100 training steps: 0.07313913498630753\n","Training loss per 100 training steps: 0.07404670536406617\n","Training loss per 100 training steps: 0.07420921831032978\n","Training loss per 100 training steps: 0.07421541982059197\n","Training loss per 100 training steps: 0.07361552893342224\n","Training loss epoch: 0.07379847368451231\n","Training accuracy epoch: 0.9765688997938778\n","Validating model...\n","Validation Loss: 0.14787642065096984\n","Validation Accuracy: 0.9572028528891846\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0236689280718565\n","Training loss per 100 training steps: 0.038483437383547425\n","Training loss per 100 training steps: 0.04116621067566769\n","Training loss per 100 training steps: 0.04277974655743429\n","Training loss per 100 training steps: 0.044169957320463665\n","Training loss per 100 training steps: 0.04556016935762427\n","Training loss per 100 training steps: 0.04656635882982212\n","Training loss per 100 training steps: 0.046077798641141976\n","Training loss epoch: 0.04567922060795089\n","Training accuracy epoch: 0.9854353838969628\n","Validating model...\n","Validation Loss: 0.16486862553404524\n","Validation Accuracy: 0.9578449396715744\n","Training epoch: 4\n","Training loss per 100 training steps: 0.06087089329957962\n","Training loss per 100 training steps: 0.029271956633472134\n","Training loss per 100 training steps: 0.028058398003569476\n","Training loss per 100 training steps: 0.028243818148224926\n","Training loss per 100 training steps: 0.029198840749101652\n","Training loss per 100 training steps: 0.02944470543286321\n","Training loss per 100 training steps: 0.02981482947617343\n","Training loss per 100 training steps: 0.031006137733375946\n","Training loss epoch: 0.03201149121143583\n","Training accuracy epoch: 0.9901852228228242\n","Validating model...\n","Validation Loss: 0.15341396034731494\n","Validation Accuracy: 0.9607301251821102\n","Training epoch: 5\n","Training loss per 100 training steps: 0.008220802061259747\n","Training loss per 100 training steps: 0.022657304882339323\n","Training loss per 100 training steps: 0.028803153174340873\n","Training loss per 100 training steps: 0.02965655012568304\n","Training loss per 100 training steps: 0.03000282297407897\n","Training loss per 100 training steps: 0.030758009330293316\n","Training loss per 100 training steps: 0.030554549739899087\n","Training loss per 100 training steps: 0.03000733275737045\n","Training loss epoch: 0.03020046136589851\n","Training accuracy epoch: 0.9907741563841567\n","Validating model...\n","Validation Loss: 0.17179128900170326\n","Validation Accuracy: 0.9594923815340117\n","Training epoch: 6\n","Training loss per 100 training steps: 0.01702214404940605\n","Training loss per 100 training steps: 0.01717012461579156\n","Stopping epoch...\n","Training loss epoch: 0.01717012461579156\n","Training accuracy epoch: 0.9850402894500933\n","Validating model...\n","Validation Loss: 0.190582474451754\n","Validation Accuracy: 0.9596573776811653\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 42.168753200000054 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.14417171905019874\n","Validation Accuracy: 0.9542097071801529\n","Validation duration: 3.143380833333322 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 83.9%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.86      0.84     12546\n","        test       0.84      0.86      0.85      9012\n","   treatment       0.84      0.82      0.83      9297\n","\n","   micro avg       0.83      0.85      0.84     30855\n","   macro avg       0.83      0.85      0.84     30855\n","weighted avg       0.83      0.85      0.84     30855\n","\n","!!!!!! Starting model number 7 !!!!!!\n","Points in X_train after augmentation: 24268\n","Points in y_train after augmentation: 24268\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0494983196258545\n","Training loss per 100 training steps: 0.4178587710945913\n","Training loss per 100 training steps: 0.30598175911167963\n","Training loss per 100 training steps: 0.26081146814696415\n","Training loss per 100 training steps: 0.2335792874308893\n","Training loss per 100 training steps: 0.21779255954894478\n","Training loss per 100 training steps: 0.2035030739849895\n","Training loss per 100 training steps: 0.1925123784792066\n","Training loss epoch: 0.18686485092728664\n","Training accuracy epoch: 0.941051152035666\n","Validating model...\n","Validation Loss: 0.14923491986928047\n","Validation Accuracy: 0.9542614751644503\n","Training epoch: 2\n","Training loss per 100 training steps: 0.11127478629350662\n","Training loss per 100 training steps: 0.07875074854692315\n","Training loss per 100 training steps: 0.0794115937569767\n","Training loss per 100 training steps: 0.07691579881244869\n","Training loss per 100 training steps: 0.07741658564336468\n","Training loss per 100 training steps: 0.07567939307250662\n","Training loss per 100 training steps: 0.07570524876022994\n","Training loss per 100 training steps: 0.07602799055531897\n","Training loss epoch: 0.07640861090007625\n","Training accuracy epoch: 0.975757935398385\n","Validating model...\n","Validation Loss: 0.14078447500896918\n","Validation Accuracy: 0.9582854003260354\n","Training epoch: 3\n","Training loss per 100 training steps: 0.08577048778533936\n","Training loss per 100 training steps: 0.04840131396759707\n","Training loss per 100 training steps: 0.04391561304937251\n","Training loss per 100 training steps: 0.04563330626115203\n","Training loss per 100 training steps: 0.044554122129078964\n","Training loss per 100 training steps: 0.045999578295085955\n","Training loss per 100 training steps: 0.04636591955935722\n","Training loss per 100 training steps: 0.04617982902584037\n","Training loss epoch: 0.04670589029720257\n","Training accuracy epoch: 0.9851521907825106\n","Validating model...\n","Validation Loss: 0.1607477141471652\n","Validation Accuracy: 0.9565648968961674\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03045053407549858\n","Training loss per 100 training steps: 0.027959618505348664\n","Training loss per 100 training steps: 0.029523870824321882\n","Training loss per 100 training steps: 0.029136801471135447\n","Training loss per 100 training steps: 0.031524306899424356\n","Training loss per 100 training steps: 0.03228285940347273\n","Training loss per 100 training steps: 0.03329180548790402\n","Training loss per 100 training steps: 0.03464784365600392\n","Training loss epoch: 0.03446438951784075\n","Training accuracy epoch: 0.9892993600347157\n","Validating model...\n","Validation Loss: 0.1765308810712455\n","Validation Accuracy: 0.9574150985612571\n","Training epoch: 5\n","Training loss per 100 training steps: 0.018628843128681183\n","Training loss per 100 training steps: 0.022633867873118656\n","Training loss per 100 training steps: 0.02229469460093495\n","Training loss per 100 training steps: 0.0229999439818305\n","Training loss per 100 training steps: 0.02281821459723971\n","Training loss per 100 training steps: 0.024419970556321235\n","Training loss per 100 training steps: 0.026018071998032383\n","Training loss per 100 training steps: 0.026126627604704293\n","Training loss epoch: 0.026162453104370077\n","Training accuracy epoch: 0.9920030749471327\n","Validating model...\n","Validation Loss: 0.17472055945061632\n","Validation Accuracy: 0.9584013429282728\n","Training epoch: 6\n","Training loss per 100 training steps: 0.008479245938360691\n","Training loss per 100 training steps: 0.018609318039080332\n","Training loss per 100 training steps: 0.019396175092042178\n","Training loss per 100 training steps: 0.021031120200865776\n","Training loss per 100 training steps: 0.020126291557227928\n","Training loss per 100 training steps: 0.019584404038913185\n","Training loss per 100 training steps: 0.02095145510655662\n","Training loss per 100 training steps: 0.02196546799156844\n","Training loss epoch: 0.023048185735109\n","Training accuracy epoch: 0.9929747918400398\n","Validating model...\n","Validation Loss: 0.18206386495526736\n","Validation Accuracy: 0.9586270879703872\n","Training epoch: 7\n","Training loss per 100 training steps: 0.015530630946159363\n","Training loss per 100 training steps: 0.014024910189690862\n","Training loss per 100 training steps: 0.016969818750451972\n","Training loss per 100 training steps: 0.017165688975935376\n","Training loss per 100 training steps: 0.017417424055050937\n"]}]},{"cell_type":"code","source":["number_of_training_models = 1\n","target_augmented_percentage = 0.75\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["4540e38595734cf380d94e6f61cbb8ea","49241c6fd92f4e899c6cb9f91e717bd7","45608647c0144eb688eb1367cd18b6b8","5a39acef2b134c2591bdb849fef7d623","f8be1d6450f744a0b6295c5fb2f76de1","fd5596ef8d434aa693b50f8956c14dbe","8b60a63c41ff4741bb5e301cc2ccdd85","84b7cfe97c0541e48dd33cd5ebf3cb66","e9d7ebf6b3da4c30a38cc01da2637a9d","f47f45870cec4ef89c8cbb95058e49cc","04123fb9f52c4dd7b2f50a488e995bd3"]},"id":"8a2WYpOmXr9o","executionInfo":{"status":"ok","timestamp":1663134959517,"user_tz":240,"elapsed":3183722,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}},"outputId":"46d1e239-f1aa-4d5e-9988-f81ce4cfa440"},"id":"8a2WYpOmXr9o","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["!!!!!! Augmented Percentage 75.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 24268\n","Points in y_train after augmentation: 24268\n","Device:  cuda\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/422M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4540e38595734cf380d94e6f61cbb8ea"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.09049916267395\n","Training loss per 100 training steps: 0.37597489917632376\n","Training loss per 100 training steps: 0.287595744230854\n","Training loss per 100 training steps: 0.25180979477755255\n","Training loss per 100 training steps: 0.22813820942976232\n","Training loss per 100 training steps: 0.21218734951745608\n","Training loss per 100 training steps: 0.1980217415870426\n","Training loss per 100 training steps: 0.18852653698769853\n","Training loss epoch: 0.18451250587959378\n","Training accuracy epoch: 0.9415694921043162\n","Validating model...\n","Validation Loss: 0.13637350446411542\n","Validation Accuracy: 0.9554869761616003\n","Training epoch: 2\n","Training loss per 100 training steps: 0.08194512873888016\n","Training loss per 100 training steps: 0.07588282811206461\n","Training loss per 100 training steps: 0.07757344202541594\n","Training loss per 100 training steps: 0.07773821835601052\n","Training loss per 100 training steps: 0.07882856279658038\n","Training loss per 100 training steps: 0.07827730652896646\n","Training loss per 100 training steps: 0.07841066852639647\n","Training loss per 100 training steps: 0.07758350368621049\n","Training loss epoch: 0.07713825899705154\n","Training accuracy epoch: 0.9757545716842884\n","Validating model...\n","Validation Loss: 0.15203532254831356\n","Validation Accuracy: 0.9566763877287828\n","Training epoch: 3\n","Training loss per 100 training steps: 0.06457069516181946\n","Training loss per 100 training steps: 0.043596695358219494\n","Training loss per 100 training steps: 0.04094241381291559\n","Training loss per 100 training steps: 0.04243117459915096\n","Training loss per 100 training steps: 0.042405288605230795\n","Training loss per 100 training steps: 0.043749074360770274\n","Training loss per 100 training steps: 0.04382668288146454\n","Training loss per 100 training steps: 0.04459013920506534\n","Training loss epoch: 0.04507033562496898\n","Training accuracy epoch: 0.9858366346652807\n","Validating model...\n","Validation Loss: 0.1667153910044339\n","Validation Accuracy: 0.9557866952228078\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0068265111185610294\n","Training loss per 100 training steps: 0.03351944746302053\n","Training loss per 100 training steps: 0.03205172033385091\n","Training loss per 100 training steps: 0.031382534222482425\n","Training loss per 100 training steps: 0.03206208459667146\n","Training loss per 100 training steps: 0.03216739260510703\n","Training loss per 100 training steps: 0.03247284199155328\n","Training loss per 100 training steps: 0.0325426030005614\n","Training loss epoch: 0.03327722546898506\n","Training accuracy epoch: 0.989562002224602\n","Validating model...\n","Validation Loss: 0.16012746881838744\n","Validation Accuracy: 0.9578263528926684\n","Training epoch: 5\n","Training loss per 100 training steps: 0.04319467768073082\n","Training loss per 100 training steps: 0.02804289362278057\n","Training loss per 100 training steps: 0.026725726807374155\n","Training loss per 100 training steps: 0.02676972124626569\n","Training loss per 100 training steps: 0.027207055473421466\n","Training loss per 100 training steps: 0.027322399884484663\n","Training loss per 100 training steps: 0.027089759439850588\n","Training loss per 100 training steps: 0.0273687529591704\n","Training loss epoch: 0.02705226762458616\n","Training accuracy epoch: 0.99177661666893\n","Validating model...\n","Validation Loss: 0.1870137839215239\n","Validation Accuracy: 0.9604557434166421\n","Training epoch: 6\n","Training loss per 100 training steps: 0.029737360775470734\n","Training loss per 100 training steps: 0.02012049477999237\n","Training loss per 100 training steps: 0.01903021462268627\n","Training loss per 100 training steps: 0.020566672890406857\n","Training loss per 100 training steps: 0.020931265700406435\n","Training loss per 100 training steps: 0.021920704123184843\n","Training loss per 100 training steps: 0.02324388882365332\n","Training loss per 100 training steps: 0.023402733301405746\n","Training loss epoch: 0.023065864389571478\n","Training accuracy epoch: 0.9930072522652824\n","Validating model...\n","Validation Loss: 0.20317815324025496\n","Validation Accuracy: 0.9576440557275044\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 49.452029833333334 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.15449238797710105\n","Validation Accuracy: 0.950665213912921\n","Validation duration: 3.2327251500000025 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 82.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.87      0.82     12546\n","        test       0.75      0.89      0.82      9012\n","   treatment       0.82      0.86      0.84      9297\n","\n","   micro avg       0.79      0.87      0.83     30855\n","   macro avg       0.79      0.87      0.83     30855\n","weighted avg       0.79      0.87      0.83     30855\n","\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1tBh5gOBHpN1","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["908d38bb2069469e86b2a9338735ea85","7a2d330ca7d840078a3ead3b7295957f","49c05e88700b4280bfe2910723bf7dfb","8cb8e6767b3a443fa27734bbf4e6ee2f","288dedb070714051b9c0c9d89905007f","9ae59914c7ff4c20b04c962c3f8ac275","800cb31c06854f188635cd1e173a7329","a096ae440f114c639fb725b4e8c16d97","53287cb9687e4ec792b7d03379057f4b","ae5569ff5a654eb79e05bd513bd9c7eb","d220d0b9129f463e86acd33cb6351e4e"]},"outputId":"13d2d011-449f-466a-d892-a8986de7be6c","executionInfo":{"status":"ok","timestamp":1663237717504,"user_tz":240,"elapsed":38023948,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["!!!!!! Augmented Percentage 100% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 27734\n","Points in y_train after augmentation: 27734\n","Device:  cuda\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"908d38bb2069469e86b2a9338735ea85"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.24198842048645\n","Training loss per 100 training steps: 0.3997209549392804\n","Training loss per 100 training steps: 0.30673714230457944\n","Training loss per 100 training steps: 0.25858663773764407\n","Training loss per 100 training steps: 0.23362703907519505\n","Training loss per 100 training steps: 0.21430909329144185\n","Training loss per 100 training steps: 0.2025249271611753\n","Training loss per 100 training steps: 0.19263174322389928\n","Training loss per 100 training steps: 0.18398317594671815\n","Training loss epoch: 0.1791777274213654\n","Training accuracy epoch: 0.9433731421667741\n","Validating model...\n","Validation Loss: 0.13659156399307312\n","Validation Accuracy: 0.9567568457592217\n","Training epoch: 2\n","Training loss per 100 training steps: 0.13529081642627716\n","Training loss per 100 training steps: 0.07839965148100464\n","Training loss per 100 training steps: 0.0717820344928337\n","Training loss per 100 training steps: 0.07260755785552173\n","Training loss per 100 training steps: 0.07139982682004795\n","Training loss per 100 training steps: 0.07337238922428913\n","Training loss per 100 training steps: 0.07272185507414866\n","Training loss per 100 training steps: 0.0715343428359828\n","Training loss per 100 training steps: 0.07094814021026392\n","Training loss epoch: 0.07189789335614\n","Training accuracy epoch: 0.9774180621621581\n","Validating model...\n","Validation Loss: 0.1361772558083395\n","Validation Accuracy: 0.9572085386707058\n","Training epoch: 3\n","Training loss per 100 training steps: 0.017984429374337196\n","Training loss per 100 training steps: 0.04373756276517369\n","Training loss per 100 training steps: 0.044015311531778144\n","Training loss per 100 training steps: 0.04376839950488899\n","Training loss per 100 training steps: 0.04289188822893951\n","Training loss per 100 training steps: 0.042814742111528435\n","Training loss per 100 training steps: 0.04303110938499095\n","Training loss per 100 training steps: 0.04458918542927995\n","Training loss per 100 training steps: 0.04546946193354341\n","Training loss epoch: 0.04637440364682164\n","Training accuracy epoch: 0.9856678821572354\n","Validating model...\n","Validation Loss: 0.15910638878484826\n","Validation Accuracy: 0.9575556874817304\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03985140100121498\n","Training loss per 100 training steps: 0.025691785262943717\n","Training loss per 100 training steps: 0.027174115927533167\n","Training loss per 100 training steps: 0.028677470727198666\n","Training loss per 100 training steps: 0.0289911639077143\n","Training loss per 100 training steps: 0.029605049706629277\n","Training loss per 100 training steps: 0.029422636275387333\n","Training loss per 100 training steps: 0.030798308099766185\n","Training loss per 100 training steps: 0.03170415852175265\n","Training loss epoch: 0.03169978686891423\n","Training accuracy epoch: 0.9903191198610214\n","Validating model...\n","Validation Loss: 0.17388944023034789\n","Validation Accuracy: 0.9573449162502083\n","Training epoch: 5\n","Training loss per 100 training steps: 0.010991978459060192\n","Training loss per 100 training steps: 0.020387497718450567\n","Training loss per 100 training steps: 0.02269902793471632\n","Training loss per 100 training steps: 0.024525098803730067\n","Training loss per 100 training steps: 0.024052336687620433\n","Training loss per 100 training steps: 0.023494991014233815\n","Training loss per 100 training steps: 0.023145420561442323\n","Training loss per 100 training steps: 0.023665642697123623\n","Training loss per 100 training steps: 0.023857707239265384\n","Training loss epoch: 0.024360085770406145\n","Training accuracy epoch: 0.9925401465652758\n","Validating model...\n","Validation Loss: 0.1790002685451469\n","Validation Accuracy: 0.9580636662041692\n","Training epoch: 6\n","Training loss per 100 training steps: 0.004923705477267504\n","Training loss per 100 training steps: 0.01830193567629166\n","Training loss per 100 training steps: 0.021458673898468898\n","Training loss per 100 training steps: 0.020570602354228473\n","Training loss per 100 training steps: 0.020520621019722126\n","Training loss per 100 training steps: 0.020789730676520474\n","Training loss per 100 training steps: 0.02052665383257855\n","Training loss per 100 training steps: 0.020846195726807543\n","Training loss per 100 training steps: 0.021152080900077076\n","Training loss epoch: 0.02145184155086575\n","Training accuracy epoch: 0.9934831056390618\n","Validating model...\n","Validation Loss: 0.20244518841628906\n","Validation Accuracy: 0.9565438833161269\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0044160564430058\n","Training loss per 100 training steps: 0.0179669160308261\n","Training loss per 100 training steps: 0.018290971476174613\n","Training loss per 100 training steps: 0.01866355370939013\n","Training loss per 100 training steps: 0.01897504522106343\n","Training loss per 100 training steps: 0.018965766623898775\n","Training loss per 100 training steps: 0.01994944908660054\n","Training loss per 100 training steps: 0.019735560357287\n","Training loss per 100 training steps: 0.019130298300569507\n","Training loss epoch: 0.019537554601999053\n","Training accuracy epoch: 0.993954339308237\n","Validating model...\n","Validation Loss: 0.22366590921271157\n","Validation Accuracy: 0.9533848472812709\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 65.32609773333334 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.14610360722764637\n","Validation Accuracy: 0.9545688898757666\n","Validation duration: 3.131634266666674 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 84.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.86      0.83     12546\n","        test       0.81      0.87      0.84      9012\n","   treatment       0.86      0.84      0.85      9297\n","\n","   micro avg       0.83      0.85      0.84     30855\n","   macro avg       0.83      0.85      0.84     30855\n","weighted avg       0.83      0.85      0.84     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 27734\n","Points in y_train after augmentation: 27734\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9454354047775269\n","Training loss per 100 training steps: 0.38304319328600817\n","Training loss per 100 training steps: 0.29077696722390045\n","Training loss per 100 training steps: 0.2490088641148469\n","Training loss per 100 training steps: 0.22072831263528797\n","Training loss per 100 training steps: 0.20595753366153635\n","Training loss per 100 training steps: 0.19624019024301687\n","Training loss per 100 training steps: 0.18744479514626566\n","Training loss per 100 training steps: 0.17907473542140367\n","Training loss epoch: 0.174252322375465\n","Training accuracy epoch: 0.944776936649262\n","Validating model...\n","Validation Loss: 0.14590840365786056\n","Validation Accuracy: 0.9550600084505406\n","Training epoch: 2\n","Training loss per 100 training steps: 0.023938171565532684\n","Training loss per 100 training steps: 0.06855037754014282\n","Training loss per 100 training steps: 0.06663566965387384\n","Training loss per 100 training steps: 0.06910115106037487\n","Training loss per 100 training steps: 0.07107014933419867\n","Training loss per 100 training steps: 0.07139016057693673\n","Training loss per 100 training steps: 0.07199218790178588\n","Training loss per 100 training steps: 0.07330741507589775\n","Training loss per 100 training steps: 0.07263734706499603\n","Training loss epoch: 0.07270228328138177\n","Training accuracy epoch: 0.9769004929334995\n","Validating model...\n","Validation Loss: 0.16770400164963364\n","Validation Accuracy: 0.9550050721527334\n","Training epoch: 3\n","Training loss per 100 training steps: 0.031541261821985245\n","Training loss per 100 training steps: 0.04226116000647002\n","Training loss per 100 training steps: 0.04080270568779971\n","Training loss per 100 training steps: 0.04165043973633122\n","Training loss per 100 training steps: 0.04228819034322446\n","Training loss per 100 training steps: 0.04243433561980977\n","Training loss per 100 training steps: 0.04348261702802658\n","Training loss per 100 training steps: 0.04369482995820007\n","Training loss per 100 training steps: 0.04412694727960095\n","Training loss epoch: 0.04427545096520055\n","Training accuracy epoch: 0.9863900839350418\n","Validating model...\n","Validation Loss: 0.15978110761853395\n","Validation Accuracy: 0.9590038140924612\n","Training epoch: 4\n","Training loss per 100 training steps: 0.056794505566358566\n","Training loss per 100 training steps: 0.025735311970889272\n","Training loss per 100 training steps: 0.02674743503943753\n","Training loss per 100 training steps: 0.02666361324266342\n","Training loss per 100 training steps: 0.027693160996537777\n","Training loss per 100 training steps: 0.02868013736325318\n","Training loss per 100 training steps: 0.02905526640786233\n","Training loss per 100 training steps: 0.02903662501773219\n","Training loss per 100 training steps: 0.03007490449723382\n","Training loss epoch: 0.030021071021532106\n","Training accuracy epoch: 0.9907569224566058\n","Validating model...\n","Validation Loss: 0.18938574392058247\n","Validation Accuracy: 0.9593344643742974\n","Training epoch: 5\n","Training loss per 100 training steps: 0.08606594055891037\n","Training loss per 100 training steps: 0.021128234801592656\n","Training loss per 100 training steps: 0.023843478576502583\n","Training loss per 100 training steps: 0.02341748447392594\n","Training loss per 100 training steps: 0.024995305023546285\n","Training loss per 100 training steps: 0.024354206031920785\n","Training loss per 100 training steps: 0.024524710836127624\n","Training loss per 100 training steps: 0.025043201547769695\n","Training loss per 100 training steps: 0.02557659449233684\n","Training loss epoch: 0.025427173123686364\n","Training accuracy epoch: 0.9919166306245911\n","Validating model...\n","Validation Loss: 0.2049857536209868\n","Validation Accuracy: 0.9545348550990759\n","Training epoch: 6\n","Training loss per 100 training steps: 0.02096291072666645\n","Training loss per 100 training steps: 0.01540516757107764\n","Training loss per 100 training steps: 0.01751419284571523\n","Training loss per 100 training steps: 0.017747738320195577\n","Training loss per 100 training steps: 0.01823523760705889\n","Training loss per 100 training steps: 0.0183917372919686\n","Training loss per 100 training steps: 0.01837517490812706\n","Training loss per 100 training steps: 0.018955930470111654\n","Training loss per 100 training steps: 0.019642216981430486\n","Training loss epoch: 0.0197650792675776\n","Training accuracy epoch: 0.994016087253586\n","Validating model...\n","Validation Loss: 0.19959667554826704\n","Validation Accuracy: 0.9567752030823494\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 55.849767600000014 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.15298486920504797\n","Validation Accuracy: 0.9529792382084366\n","Validation duration: 3.1225308500000057 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 82.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.77      0.83      0.80     12546\n","        test       0.78      0.88      0.82      9012\n","   treatment       0.82      0.87      0.84      9297\n","\n","   micro avg       0.79      0.86      0.82     30855\n","   macro avg       0.79      0.86      0.82     30855\n","weighted avg       0.79      0.86      0.82     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 27734\n","Points in y_train after augmentation: 27734\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.305788278579712\n","Training loss per 100 training steps: 0.4032565616440065\n","Training loss per 100 training steps: 0.3030319329147315\n","Training loss per 100 training steps: 0.25900648385162567\n","Training loss per 100 training steps: 0.2330653988930427\n","Training loss per 100 training steps: 0.21477988786519525\n","Training loss per 100 training steps: 0.199860981791071\n","Training loss per 100 training steps: 0.19169273536211243\n","Training loss per 100 training steps: 0.18311110987664014\n","Training loss epoch: 0.17789652469678596\n","Training accuracy epoch: 0.9438828160055591\n","Validating model...\n","Validation Loss: 0.14133601865501372\n","Validation Accuracy: 0.9541558360847523\n","Training epoch: 2\n","Training loss per 100 training steps: 0.03502702713012695\n","Training loss per 100 training steps: 0.07377165698879722\n","Training loss per 100 training steps: 0.07305195075065936\n","Training loss per 100 training steps: 0.07364194176200023\n","Training loss per 100 training steps: 0.07491300984325254\n","Training loss per 100 training steps: 0.07610024261788396\n","Training loss per 100 training steps: 0.07659110432636371\n","Training loss per 100 training steps: 0.07653904257052592\n","Training loss per 100 training steps: 0.07528117194175302\n","Training loss epoch: 0.07469770027085013\n","Training accuracy epoch: 0.9765160302807365\n","Validating model...\n","Validation Loss: 0.13408755041755638\n","Validation Accuracy: 0.9607950137417329\n","Training epoch: 3\n","Training loss per 100 training steps: 0.035367202013731\n","Training loss per 100 training steps: 0.03901822076151424\n","Training loss per 100 training steps: 0.04224478768240383\n","Training loss per 100 training steps: 0.043687989645207495\n","Training loss per 100 training steps: 0.042837695127464555\n","Training loss per 100 training steps: 0.04331870818884296\n","Training loss per 100 training steps: 0.043404654039925404\n","Training loss per 100 training steps: 0.043802529994262845\n","Training loss per 100 training steps: 0.04378044876600203\n","Training loss epoch: 0.044456711952277\n","Training accuracy epoch: 0.9861690964525411\n","Validating model...\n","Validation Loss: 0.14835494347884284\n","Validation Accuracy: 0.958398612018868\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03812985494732857\n","Training loss per 100 training steps: 0.029965885656097407\n","Training loss per 100 training steps: 0.03132853467759922\n","Training loss per 100 training steps: 0.030843212749218054\n","Training loss per 100 training steps: 0.029198099459588824\n","Training loss per 100 training steps: 0.031710638501077235\n","Training loss per 100 training steps: 0.03259350374122515\n","Training loss per 100 training steps: 0.032850848395276425\n","Training loss per 100 training steps: 0.03314822313440301\n","Training loss epoch: 0.03313734908891689\n","Training accuracy epoch: 0.9895499022386616\n","Validating model...\n","Validation Loss: 0.17821044906635175\n","Validation Accuracy: 0.9565835040992865\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0024503914173692465\n","Training loss per 100 training steps: 0.022713269205017032\n","Training loss per 100 training steps: 0.024453006661612892\n","Training loss per 100 training steps: 0.024924562157184332\n","Training loss per 100 training steps: 0.02408598817332167\n","Training loss per 100 training steps: 0.02416615127613712\n","Training loss per 100 training steps: 0.026386726753377106\n","Training loss per 100 training steps: 0.026961821608362288\n","Training loss per 100 training steps: 0.02681243960244509\n","Training loss epoch: 0.027064953036278684\n","Training accuracy epoch: 0.9920051812263267\n","Validating model...\n","Validation Loss: 0.17839697381941141\n","Validation Accuracy: 0.9578325303824563\n","Training epoch: 6\n","Training loss per 100 training steps: 0.03363249823451042\n","Training loss per 100 training steps: 0.019124486270397534\n","Training loss per 100 training steps: 0.019884405110323272\n","Training loss per 100 training steps: 0.018479275564350608\n","Training loss per 100 training steps: 0.017674146220523473\n","Training loss per 100 training steps: 0.017271177964391905\n","Training loss per 100 training steps: 0.016822244366330674\n","Training loss per 100 training steps: 0.017095645728094914\n","Training loss per 100 training steps: 0.017664065335032248\n","Training loss epoch: 0.01858907149518\n","Training accuracy epoch: 0.994223606527681\n","Validating model...\n","Validation Loss: 0.1878661197132443\n","Validation Accuracy: 0.9585275577282345\n","Training epoch: 7\n","Training loss per 100 training steps: 0.01730838231742382\n","Training loss per 100 training steps: 0.015843881590932717\n","Training loss per 100 training steps: 0.0190766888733754\n","Training loss per 100 training steps: 0.018571686234976476\n","Training loss per 100 training steps: 0.018998722857888554\n","Training loss per 100 training steps: 0.018185539702288138\n","Training loss per 100 training steps: 0.01780910240538564\n","Training loss per 100 training steps: 0.017963726196437078\n","Training loss per 100 training steps: 0.01858227581359689\n","Training loss epoch: 0.018547468825202862\n","Training accuracy epoch: 0.9945036578499497\n","Validating model...\n","Validation Loss: 0.20297491952002822\n","Validation Accuracy: 0.9576699909470442\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 66.67880246666668 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.1572143005086454\n","Validation Accuracy: 0.9548586928868631\n","Validation duration: 3.1953408833333317 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 83.9%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.87      0.84     12546\n","        test       0.81      0.87      0.84      9012\n","   treatment       0.82      0.87      0.85      9297\n","\n","   micro avg       0.81      0.87      0.84     30855\n","   macro avg       0.81      0.87      0.84     30855\n","weighted avg       0.81      0.87      0.84     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 27734\n","Points in y_train after augmentation: 27734\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.047151803970337\n","Training loss per 100 training steps: 0.40046503018624713\n","Training loss per 100 training steps: 0.29867433560131795\n","Training loss per 100 training steps: 0.25367170906443137\n","Training loss per 100 training steps: 0.23357836667104553\n","Training loss per 100 training steps: 0.21590871073885592\n","Training loss per 100 training steps: 0.20370658939571032\n","Training loss per 100 training steps: 0.1918600336641881\n","Training loss per 100 training steps: 0.18334187597696774\n","Training loss epoch: 0.17838520271168654\n","Training accuracy epoch: 0.9439086608242082\n","Validating model...\n","Validation Loss: 0.13831371088306627\n","Validation Accuracy: 0.9576722014187924\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05812374874949455\n","Training loss per 100 training steps: 0.07370243959202624\n","Training loss per 100 training steps: 0.06909705898654994\n","Training loss per 100 training steps: 0.07056710363498755\n","Training loss per 100 training steps: 0.07096290946276185\n","Training loss per 100 training steps: 0.07113199491618934\n","Training loss per 100 training steps: 0.07139675213743045\n","Training loss per 100 training steps: 0.07139507518315982\n","Training loss per 100 training steps: 0.07185366830571129\n","Training loss epoch: 0.0718639037467651\n","Training accuracy epoch: 0.9778088651581124\n","Validating model...\n","Validation Loss: 0.14976557450635092\n","Validation Accuracy: 0.9562969571975138\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0710856169462204\n","Training loss per 100 training steps: 0.03988505701193273\n","Training loss per 100 training steps: 0.040715646452794026\n","Training loss per 100 training steps: 0.03958647063333059\n","Training loss per 100 training steps: 0.037709336622764454\n","Training loss per 100 training steps: 0.03948946436913591\n","Training loss per 100 training steps: 0.04327465430368513\n","Training loss per 100 training steps: 0.04397063358745321\n","Training loss per 100 training steps: 0.04507643086271833\n","Training loss epoch: 0.04616252822031277\n","Training accuracy epoch: 0.9858727174069379\n","Validating model...\n","Validation Loss: 0.1431871595756187\n","Validation Accuracy: 0.9582796892305406\n","Training epoch: 4\n","Training loss per 100 training steps: 0.016357164829969406\n","Training loss per 100 training steps: 0.03254470149041292\n","Training loss per 100 training steps: 0.032651171735163534\n","Training loss per 100 training steps: 0.03399736159504314\n","Training loss per 100 training steps: 0.033239460519185186\n","Training loss per 100 training steps: 0.033596484628859204\n","Training loss per 100 training steps: 0.032997021928682195\n","Training loss per 100 training steps: 0.033280250895868044\n","Training loss per 100 training steps: 0.033117148200992944\n","Training loss epoch: 0.03277860650394731\n","Training accuracy epoch: 0.9899108080840897\n","Validating model...\n","Validation Loss: 0.18675114726798922\n","Validation Accuracy: 0.9566746288489291\n","Training epoch: 5\n","Training loss per 100 training steps: 0.02576581761240959\n","Training loss per 100 training steps: 0.025183741978397317\n","Training loss per 100 training steps: 0.027085473268079707\n","Training loss per 100 training steps: 0.027835216232810628\n","Training loss per 100 training steps: 0.027292228466715023\n","Training loss per 100 training steps: 0.026838848478288137\n","Training loss per 100 training steps: 0.02746123649048605\n","Training loss per 100 training steps: 0.02851003111855256\n","Training loss per 100 training steps: 0.02793381067507955\n","Training loss epoch: 0.027784201135131668\n","Training accuracy epoch: 0.991335533914247\n","Validating model...\n","Validation Loss: 0.18320953680274935\n","Validation Accuracy: 0.9580553618613912\n","Training epoch: 6\n","Training loss per 100 training steps: 0.005785019136965275\n","Training loss per 100 training steps: 0.02319629320939357\n","Training loss per 100 training steps: 0.020315229853056834\n","Training loss per 100 training steps: 0.019092560902414256\n","Training loss per 100 training steps: 0.017851948227438415\n","Training loss per 100 training steps: 0.01918951386098793\n","Training loss per 100 training steps: 0.020373393846179876\n","Training loss per 100 training steps: 0.020646546263438377\n","Training loss per 100 training steps: 0.021127723269097707\n","Training loss epoch: 0.021400943463396993\n","Training accuracy epoch: 0.9934865189411077\n","Validating model...\n","Validation Loss: 0.2000356107744594\n","Validation Accuracy: 0.9558270584611828\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 57.13206698333333 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.1581716710589481\n","Validation Accuracy: 0.951280666619877\n","Validation duration: 3.197289900000002 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 82.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.77      0.87      0.82     12546\n","        test       0.84      0.85      0.84      9012\n","   treatment       0.81      0.83      0.82      9297\n","\n","   micro avg       0.80      0.85      0.83     30855\n","   macro avg       0.81      0.85      0.83     30855\n","weighted avg       0.80      0.85      0.83     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n","Points in X_train after augmentation: 27734\n","Points in y_train after augmentation: 27734\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1248934268951416\n","Training loss per 100 training steps: 0.4597519100597589\n","Training loss per 100 training steps: 0.33813551805950515\n","Training loss per 100 training steps: 0.2888353005967465\n","Training loss per 100 training steps: 0.2562513680120656\n","Training loss per 100 training steps: 0.2337353177286848\n","Training loss per 100 training steps: 0.21817387898023335\n","Training loss per 100 training steps: 0.2059102261547908\n","Training loss per 100 training steps: 0.19586139762269497\n","Training loss epoch: 0.18987713154564337\n","Training accuracy epoch: 0.9404946518344958\n","Validating model...\n","Validation Loss: 0.13821047116312887\n","Validation Accuracy: 0.9550341679824418\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07624765485525131\n","Training loss per 100 training steps: 0.08625453714244437\n","Training loss per 100 training steps: 0.07659361334934608\n","Training loss per 100 training steps: 0.0789038021414482\n","Training loss per 100 training steps: 0.08128599936323719\n","Training loss per 100 training steps: 0.07993062417173458\n","Training loss per 100 training steps: 0.08046090803085865\n","Training loss per 100 training steps: 0.0787622270847906\n","Training loss per 100 training steps: 0.078539474798685\n","Training loss epoch: 0.07871751742482598\n","Training accuracy epoch: 0.9750666614448991\n","Validating model...\n","Validation Loss: 0.14289299826827143\n","Validation Accuracy: 0.9551322478260071\n","Training epoch: 3\n","Training loss per 100 training steps: 0.06078730523586273\n","Training loss per 100 training steps: 0.04632947197423713\n","Training loss per 100 training steps: 0.046671111509667254\n","Training loss per 100 training steps: 0.04534586115378231\n","Training loss per 100 training steps: 0.045794925504965604\n","Training loss per 100 training steps: 0.04509153001116377\n","Training loss per 100 training steps: 0.0453088111166661\n","Training loss per 100 training steps: 0.04501515696789756\n","Training loss per 100 training steps: 0.045135864853386894\n","Training loss epoch: 0.04506270087220961\n","Training accuracy epoch: 0.9856629957147619\n","Validating model...\n","Validation Loss: 0.16647568630514206\n","Validation Accuracy: 0.957129469696228\n","Training epoch: 4\n","Training loss per 100 training steps: 0.006374130491167307\n","Training loss per 100 training steps: 0.02750356055999009\n","Training loss per 100 training steps: 0.02782247413589216\n","Training loss per 100 training steps: 0.027090713804884755\n","Training loss per 100 training steps: 0.02796381465890944\n","Training loss per 100 training steps: 0.028539403139552225\n","Training loss per 100 training steps: 0.030071239343754476\n","Training loss per 100 training steps: 0.031015223839928725\n","Training loss per 100 training steps: 0.033042217498864934\n","Training loss epoch: 0.03307519464943163\n","Training accuracy epoch: 0.9896799496989834\n","Validating model...\n","Validation Loss: 0.15699331427307486\n","Validation Accuracy: 0.9594476074619238\n","Training epoch: 5\n","Training loss per 100 training steps: 0.004081861115992069\n","Training loss per 100 training steps: 0.02150802121101187\n","Training loss per 100 training steps: 0.023459365418231792\n","Training loss per 100 training steps: 0.025026991396780402\n","Training loss per 100 training steps: 0.0268301823802938\n","Training loss per 100 training steps: 0.026746674556751733\n","Training loss per 100 training steps: 0.026694440128693913\n","Training loss per 100 training steps: 0.026541249687715665\n","Training loss per 100 training steps: 0.02640024362540061\n","Training loss epoch: 0.026465110731340145\n","Training accuracy epoch: 0.991736772024716\n","Validating model...\n","Validation Loss: 0.17375469828242218\n","Validation Accuracy: 0.9608577243828954\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0019248785683885217\n","Training loss per 100 training steps: 0.016101328750592794\n","Training loss per 100 training steps: 0.016298331035473686\n","Training loss per 100 training steps: 0.01768318205374522\n","Training loss per 100 training steps: 0.01787653323786944\n","Training loss per 100 training steps: 0.01835901049824809\n","Training loss per 100 training steps: 0.020228642825772924\n","Training loss per 100 training steps: 0.02198829238110198\n","Training loss per 100 training steps: 0.022440453082026295\n","Training loss epoch: 0.022830516235512705\n","Training accuracy epoch: 0.9928263063121192\n","Validating model...\n","Validation Loss: 0.17176234370170088\n","Validation Accuracy: 0.9606168011197074\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 55.89342435000002 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.14927219748130516\n","Validation Accuracy: 0.9536427085457883\n","Validation duration: 3.1223008499999803 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 83.8%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.85      0.84     12546\n","        test       0.82      0.85      0.83      9012\n","   treatment       0.84      0.84      0.84      9297\n","\n","   micro avg       0.83      0.85      0.84     30855\n","   macro avg       0.83      0.85      0.84     30855\n","weighted avg       0.83      0.85      0.84     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n","Points in X_train after augmentation: 27734\n","Points in y_train after augmentation: 27734\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7090061902999878\n","Training loss per 100 training steps: 0.3799455144470281\n","Training loss per 100 training steps: 0.28827348894518406\n","Training loss per 100 training steps: 0.2437939070585954\n","Training loss per 100 training steps: 0.22206509331626786\n","Training loss per 100 training steps: 0.2065468446059736\n","Training loss per 100 training steps: 0.1949307722800385\n","Training loss per 100 training steps: 0.18525522141670875\n","Training loss per 100 training steps: 0.17761172255624397\n","Training loss epoch: 0.1723647167328251\n","Training accuracy epoch: 0.9452506834308013\n","Validating model...\n","Validation Loss: 0.15244103203733245\n","Validation Accuracy: 0.9528767361552833\n","Training epoch: 2\n","Training loss per 100 training steps: 0.12190026044845581\n","Training loss per 100 training steps: 0.06648616745865138\n","Training loss per 100 training steps: 0.06786468001870226\n","Training loss per 100 training steps: 0.07118375705511765\n","Training loss per 100 training steps: 0.07030029209130943\n","Training loss per 100 training steps: 0.06979966947359001\n","Training loss per 100 training steps: 0.06979647123668585\n","Training loss per 100 training steps: 0.07116231792466915\n","Training loss per 100 training steps: 0.070606536417967\n","Training loss epoch: 0.0708935780186451\n","Training accuracy epoch: 0.9779975690451518\n","Validating model...\n","Validation Loss: 0.15310643119858458\n","Validation Accuracy: 0.9569082802382544\n","Training epoch: 3\n","Training loss per 100 training steps: 0.13620436191558838\n","Training loss per 100 training steps: 0.043679621506316386\n","Training loss per 100 training steps: 0.04273184954735511\n","Training loss per 100 training steps: 0.04267572929101851\n","Training loss per 100 training steps: 0.042634018141186406\n","Training loss per 100 training steps: 0.04345930036586782\n","Training loss per 100 training steps: 0.04264075507970834\n","Training loss per 100 training steps: 0.04233741124868712\n","Training loss per 100 training steps: 0.04261718045445752\n","Training loss epoch: 0.042661540039987955\n","Training accuracy epoch: 0.9867058573562728\n","Validating model...\n","Validation Loss: 0.15820158430822678\n","Validation Accuracy: 0.9587869108882486\n","Training epoch: 4\n","Training loss per 100 training steps: 0.08491110801696777\n","Training loss per 100 training steps: 0.02920702062685522\n","Training loss per 100 training steps: 0.02964034473838572\n","Training loss per 100 training steps: 0.029351872549797608\n","Training loss per 100 training steps: 0.03059497562079154\n","Training loss per 100 training steps: 0.03109738529574297\n","Training loss per 100 training steps: 0.03202241475398679\n","Training loss per 100 training steps: 0.032540484189890195\n","Training loss per 100 training steps: 0.0328052535292096\n","Training loss epoch: 0.03267913874622215\n","Training accuracy epoch: 0.9901972574320458\n","Validating model...\n","Validation Loss: 0.18961609999177517\n","Validation Accuracy: 0.9579755120203023\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0028709399048238993\n","Training loss per 100 training steps: 0.02675359321891856\n","Training loss per 100 training steps: 0.025938557832158954\n","Training loss per 100 training steps: 0.026471230632275886\n","Training loss per 100 training steps: 0.02511995526041111\n","Training loss per 100 training steps: 0.024573158150252527\n","Training loss per 100 training steps: 0.025653815778869573\n","Training loss per 100 training steps: 0.025666984692767274\n","Training loss per 100 training steps: 0.025427052019263957\n","Training loss epoch: 0.02630899022032551\n","Training accuracy epoch: 0.9920353232421312\n","Validating model...\n","Validation Loss: 0.16640752827893798\n","Validation Accuracy: 0.957079630714282\n","Training epoch: 6\n","Training loss per 100 training steps: 0.048707909882068634\n","Training loss per 100 training steps: 0.02330554986146675\n","Training loss per 100 training steps: 0.022775714887150873\n","Training loss per 100 training steps: 0.02221350810909025\n","Training loss per 100 training steps: 0.02190173436011399\n","Training loss per 100 training steps: 0.021454266796238023\n","Training loss per 100 training steps: 0.02093363207671559\n","Training loss per 100 training steps: 0.020993990205761745\n","Training loss per 100 training steps: 0.02087902272490438\n","Training loss epoch: 0.02091513696715296\n","Training accuracy epoch: 0.9935436428840536\n","Validating model...\n","Validation Loss: 0.1966472039749096\n","Validation Accuracy: 0.9600487592752919\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 55.93407036666661 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.15723995333192525\n","Validation Accuracy: 0.9508670231379809\n","Validation duration: 3.1208703499999806 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 83.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.87      0.83     12546\n","        test       0.81      0.88      0.84      9012\n","   treatment       0.83      0.83      0.83      9297\n","\n","   micro avg       0.81      0.86      0.83     30855\n","   macro avg       0.81      0.86      0.83     30855\n","weighted avg       0.81      0.86      0.83     30855\n","\n","!!!!!! Starting model number 7 !!!!!!\n","Points in X_train after augmentation: 27734\n","Points in y_train after augmentation: 27734\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1171014308929443\n","Training loss per 100 training steps: 0.4050177073124612\n","Training loss per 100 training steps: 0.30362542511070545\n","Training loss per 100 training steps: 0.2627178274862394\n","Training loss per 100 training steps: 0.2352279519889866\n","Training loss per 100 training steps: 0.21785170662248443\n","Training loss per 100 training steps: 0.20407235856088943\n","Training loss per 100 training steps: 0.1927348836039468\n","Training loss per 100 training steps: 0.18404903615151674\n","Training loss epoch: 0.1791216037660459\n","Training accuracy epoch: 0.9440098441066554\n","Validating model...\n","Validation Loss: 0.1326983076846832\n","Validation Accuracy: 0.957742050902093\n","Training epoch: 2\n","Training loss per 100 training steps: 0.02510913461446762\n","Training loss per 100 training steps: 0.0801877872372913\n","Training loss per 100 training steps: 0.07702963026842816\n","Training loss per 100 training steps: 0.07691344443671529\n","Training loss per 100 training steps: 0.07565962632843978\n","Training loss per 100 training steps: 0.07442203666196909\n","Training loss per 100 training steps: 0.07445256697779487\n","Training loss per 100 training steps: 0.07385546035570399\n","Training loss per 100 training steps: 0.07396201852571857\n","Training loss epoch: 0.07356577443771038\n","Training accuracy epoch: 0.9765556617785038\n","Validating model...\n","Validation Loss: 0.15005094906339397\n","Validation Accuracy: 0.9573454468711282\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03237539529800415\n","Training loss per 100 training steps: 0.04522268921551802\n","Training loss per 100 training steps: 0.043389867570723835\n","Training loss per 100 training steps: 0.041448405898946564\n","Training loss per 100 training steps: 0.042949397364826385\n","Training loss per 100 training steps: 0.041824745756486606\n","Training loss per 100 training steps: 0.043195723612155894\n","Training loss per 100 training steps: 0.04376055466970389\n","Training loss per 100 training steps: 0.0444855392322214\n","Training loss epoch: 0.045011247883120074\n","Training accuracy epoch: 0.9858481738203565\n","Validating model...\n","Validation Loss: 0.14730380707746976\n","Validation Accuracy: 0.9572103881711481\n","Training epoch: 4\n","Training loss per 100 training steps: 0.023600002750754356\n","Training loss per 100 training steps: 0.02318463654437167\n","Training loss per 100 training steps: 0.021765764331241225\n","Training loss per 100 training steps: 0.023862180681790898\n","Training loss per 100 training steps: 0.026734535933351445\n","Training loss per 100 training steps: 0.026439147075859388\n","Training loss per 100 training steps: 0.0280763181346777\n","Training loss per 100 training steps: 0.02893543094343449\n","Training loss per 100 training steps: 0.02928005912679523\n","Training loss epoch: 0.029445551260484055\n","Training accuracy epoch: 0.990794543113834\n","Validating model...\n","Validation Loss: 0.16760072616751415\n","Validation Accuracy: 0.9569791613054818\n","Training epoch: 5\n","Training loss per 100 training steps: 0.034521330147981644\n","Training loss per 100 training steps: 0.018752325451840638\n","Training loss per 100 training steps: 0.022060985700690663\n","Training loss per 100 training steps: 0.021750207679258022\n","Training loss per 100 training steps: 0.0219877996896231\n","Training loss per 100 training steps: 0.022905849407732805\n","Training loss per 100 training steps: 0.02331050967566356\n","Training loss per 100 training steps: 0.02260733141021447\n","Training loss per 100 training steps: 0.023187724056118256\n","Training loss epoch: 0.02368659675025973\n","Training accuracy epoch: 0.9926469048387339\n","Validating model...\n","Validation Loss: 0.18448674811848573\n","Validation Accuracy: 0.9574245153911154\n","Training epoch: 6\n","Training loss per 100 training steps: 0.05538497492671013\n","Training loss per 100 training steps: 0.025457276099956235\n","Training loss per 100 training steps: 0.024553810507499274\n","Training loss per 100 training steps: 0.02459585047257365\n","Training loss per 100 training steps: 0.02498089647799628\n","Training loss per 100 training steps: 0.024570349272072852\n","Training loss per 100 training steps: 0.024762683241982972\n","Training loss per 100 training steps: 0.02536533205665664\n","Training loss per 100 training steps: 0.025527872727688555\n","Training loss epoch: 0.02574388140591233\n","Training accuracy epoch: 0.9921812030246963\n","Validating model...\n","Validation Loss: 0.21358727450881684\n","Validation Accuracy: 0.9552227498504462\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 56.07193333333331 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.1488219529338595\n","Validation Accuracy: 0.9531582523741812\n","Validation duration: 3.1463288333333064 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 83.1%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.85      0.83     12546\n","        test       0.80      0.85      0.83      9012\n","   treatment       0.84      0.83      0.84      9297\n","\n","   micro avg       0.82      0.84      0.83     30855\n","   macro avg       0.82      0.84      0.83     30855\n","weighted avg       0.82      0.84      0.83     30855\n","\n","!!!!!! Starting model number 8 !!!!!!\n","Points in X_train after augmentation: 27734\n","Points in y_train after augmentation: 27734\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.902662754058838\n","Training loss per 100 training steps: 0.42281734729462334\n","Training loss per 100 training steps: 0.31382372263652175\n","Training loss per 100 training steps: 0.2626196486980614\n","Training loss per 100 training steps: 0.2369631355131356\n","Training loss per 100 training steps: 0.21753308970384494\n","Training loss per 100 training steps: 0.20544616967910737\n","Training loss per 100 training steps: 0.19544474385710653\n","Training loss per 100 training steps: 0.18585806766457474\n","Training loss epoch: 0.18083236035230252\n","Training accuracy epoch: 0.943428361118922\n","Validating model...\n","Validation Loss: 0.14299205799478215\n","Validation Accuracy: 0.9539750335207152\n","Training epoch: 2\n","Training loss per 100 training steps: 0.11953049898147583\n","Training loss per 100 training steps: 0.0740714999801009\n","Training loss per 100 training steps: 0.07422583360301414\n","Training loss per 100 training steps: 0.07281165462075438\n","Training loss per 100 training steps: 0.07192393598823746\n","Training loss per 100 training steps: 0.07255573352699367\n","Training loss per 100 training steps: 0.07253140821520661\n","Training loss per 100 training steps: 0.07349753832214043\n","Training loss per 100 training steps: 0.0743088464727323\n","Training loss epoch: 0.07373709824259018\n","Training accuracy epoch: 0.9770051917710662\n","Validating model...\n","Validation Loss: 0.14049034164129914\n","Validation Accuracy: 0.9603334413577571\n","Training epoch: 3\n","Training loss per 100 training steps: 0.06158396601676941\n","Training loss per 100 training steps: 0.03686294462624015\n","Training loss per 100 training steps: 0.038765232688029165\n","Training loss per 100 training steps: 0.03852720858615845\n","Training loss per 100 training steps: 0.03975480267234574\n","Training loss per 100 training steps: 0.04128650498358968\n","Training loss per 100 training steps: 0.04173911185764681\n","Training loss per 100 training steps: 0.04228831077998932\n","Training loss per 100 training steps: 0.043171725725957406\n","Training loss epoch: 0.04360085778419603\n","Training accuracy epoch: 0.9866027701230446\n","Validating model...\n","Validation Loss: 0.18796478081252668\n","Validation Accuracy: 0.9568237613006021\n","Training epoch: 4\n","Training loss per 100 training steps: 0.028974317014217377\n","Training loss per 100 training steps: 0.03114178291600345\n","Training loss per 100 training steps: 0.03237860908775836\n","Training loss per 100 training steps: 0.03306211781358513\n","Training loss per 100 training steps: 0.03338597106130125\n","Training loss per 100 training steps: 0.03153961329609843\n","Training loss per 100 training steps: 0.03240660908517696\n","Training loss per 100 training steps: 0.03212866120659195\n","Training loss per 100 training steps: 0.03148716991053971\n","Training loss epoch: 0.03147308238190647\n","Training accuracy epoch: 0.9902159643038865\n","Validating model...\n","Validation Loss: 0.17954535736375815\n","Validation Accuracy: 0.9568954749256331\n","Training epoch: 5\n","Training loss per 100 training steps: 0.029258213937282562\n","Training loss per 100 training steps: 0.02227349463841039\n","Training loss per 100 training steps: 0.021797604810224094\n","Training loss per 100 training steps: 0.02325249092531177\n","Training loss per 100 training steps: 0.023245076723065822\n","Training loss per 100 training steps: 0.02327810324360886\n","Training loss per 100 training steps: 0.024034835876255434\n","Training loss per 100 training steps: 0.025473072771155694\n","Training loss per 100 training steps: 0.02595540019276595\n","Training loss epoch: 0.026187144211281817\n","Training accuracy epoch: 0.9920159677087111\n","Validating model...\n","Validation Loss: 0.2004580305913439\n","Validation Accuracy: 0.954381582964051\n","Training epoch: 6\n","Training loss per 100 training steps: 0.029776202514767647\n","Training loss per 100 training steps: 0.025959086814194475\n","Training loss per 100 training steps: 0.023939152815221666\n","Training loss per 100 training steps: 0.026153650251217186\n","Training loss per 100 training steps: 0.025405384856363306\n","Training loss per 100 training steps: 0.025682811725567727\n","Training loss per 100 training steps: 0.025330294109861554\n","Training loss per 100 training steps: 0.024789263644357334\n","Training loss per 100 training steps: 0.02431700434298842\n","Training loss epoch: 0.024115679725656026\n","Training accuracy epoch: 0.9927245258630769\n","Validating model...\n","Validation Loss: 0.18481417111568638\n","Validation Accuracy: 0.9595848614552658\n","Training epoch: 7\n","Training loss per 100 training steps: 0.01662418805062771\n","Training loss per 100 training steps: 0.012865021295780961\n","Training loss per 100 training steps: 0.013599637830085515\n","Training loss per 100 training steps: 0.016270822030685507\n","Training loss per 100 training steps: 0.016553757086766655\n","Training loss per 100 training steps: 0.017049090311831855\n","Training loss per 100 training steps: 0.018493990945752197\n","Training loss per 100 training steps: 0.0186848864194302\n","Training loss per 100 training steps: 0.018413756327798354\n","Training loss epoch: 0.018427932373585875\n","Training accuracy epoch: 0.9945252028687146\n","Validating model...\n","Validation Loss: 0.18730296663843193\n","Validation Accuracy: 0.9588015678390169\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 66.08548141666664 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.15742240458860546\n","Validation Accuracy: 0.9547669190335225\n","Validation duration: 3.1577486833333146 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 84.3%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.87      0.84     12546\n","        test       0.81      0.88      0.84      9012\n","   treatment       0.84      0.84      0.84      9297\n","\n","   micro avg       0.82      0.86      0.84     30855\n","   macro avg       0.82      0.86      0.84     30855\n","weighted avg       0.82      0.86      0.84     30855\n","\n","!!!!!! Starting model number 9 !!!!!!\n","Points in X_train after augmentation: 27734\n","Points in y_train after augmentation: 27734\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.5021992921829224\n","Training loss per 100 training steps: 0.39420475346027034\n","Training loss per 100 training steps: 0.29242621662456597\n","Training loss per 100 training steps: 0.2529058433277068\n","Training loss per 100 training steps: 0.22639600604661086\n","Training loss per 100 training steps: 0.21169863222631627\n","Training loss per 100 training steps: 0.19817935266902365\n","Training loss per 100 training steps: 0.18851451470002467\n","Training loss per 100 training steps: 0.18069964328248253\n","Training loss epoch: 0.17649058050625327\n","Training accuracy epoch: 0.9440501297971017\n","Validating model...\n","Validation Loss: 0.15926654457852438\n","Validation Accuracy: 0.9494945284162771\n","Training epoch: 2\n","Training loss per 100 training steps: 0.11091938614845276\n","Training loss per 100 training steps: 0.07216402900285356\n","Training loss per 100 training steps: 0.0758605756708861\n","Training loss per 100 training steps: 0.07326803294527175\n","Training loss per 100 training steps: 0.0730145326014283\n","Training loss per 100 training steps: 0.0740874329983385\n","Training loss per 100 training steps: 0.07518070118312728\n","Training loss per 100 training steps: 0.07424811171048909\n","Training loss per 100 training steps: 0.07450013629424754\n","Training loss epoch: 0.07430540215741788\n","Training accuracy epoch: 0.9764483955216081\n","Validating model...\n","Validation Loss: 0.1439382725866971\n","Validation Accuracy: 0.9567964810104793\n","Training epoch: 3\n","Training loss per 100 training steps: 0.055000778287649155\n","Training loss per 100 training steps: 0.044227754591161954\n","Training loss per 100 training steps: 0.04310788314057449\n","Training loss per 100 training steps: 0.04433192634503311\n","Training loss per 100 training steps: 0.04393378112748488\n","Training loss per 100 training steps: 0.04436632698148995\n","Training loss per 100 training steps: 0.04415299128175414\n","Training loss per 100 training steps: 0.044486579526755186\n","Training loss per 100 training steps: 0.04483200657616292\n","Training loss epoch: 0.04481018783557932\n","Training accuracy epoch: 0.9860682785229861\n","Validating model...\n","Validation Loss: 0.16653181418970034\n","Validation Accuracy: 0.9573056030871949\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03690927103161812\n","Training loss per 100 training steps: 0.03140781138387352\n","Training loss per 100 training steps: 0.02976237295950712\n","Training loss per 100 training steps: 0.030375415912560152\n","Training loss per 100 training steps: 0.030129739802163512\n","Training loss per 100 training steps: 0.030220147904042087\n","Training loss per 100 training steps: 0.030564171993506827\n","Training loss per 100 training steps: 0.031996632387765955\n","Training loss per 100 training steps: 0.03287152148121631\n","Training loss epoch: 0.03283617202962739\n","Training accuracy epoch: 0.9897343946479749\n","Validating model...\n","Validation Loss: 0.16974041431948736\n","Validation Accuracy: 0.9603264915326262\n","Training epoch: 5\n","Training loss per 100 training steps: 0.002883251989260316\n","Training loss per 100 training steps: 0.013304570372248676\n","Training loss per 100 training steps: 0.016733050101960256\n","Training loss per 100 training steps: 0.01878471333422138\n","Training loss per 100 training steps: 0.021630082699816276\n","Training loss per 100 training steps: 0.02338125638105161\n","Training loss per 100 training steps: 0.023122023506138085\n","Training loss per 100 training steps: 0.02323074335864773\n","Training loss per 100 training steps: 0.023379753203074286\n","Training loss epoch: 0.02390803742376097\n","Training accuracy epoch: 0.9925496710385417\n","Validating model...\n","Validation Loss: 0.1917273866718744\n","Validation Accuracy: 0.9579773030144378\n","Training epoch: 6\n","Training loss per 100 training steps: 0.019791699945926666\n","Training loss per 100 training steps: 0.02187143231506948\n","Training loss per 100 training steps: 0.02259493615641606\n","Training loss per 100 training steps: 0.023704635723303707\n","Training loss per 100 training steps: 0.02365251927258577\n","Training loss per 100 training steps: 0.02383799467316202\n","Training loss per 100 training steps: 0.024676012017740133\n","Training loss per 100 training steps: 0.024180012664919752\n","Training loss per 100 training steps: 0.02425297937828573\n","Training loss epoch: 0.02471652210970982\n","Training accuracy epoch: 0.9924761432263038\n","Validating model...\n","Validation Loss: 0.1657967293671296\n","Validation Accuracy: 0.9591419074953662\n","Training epoch: 7\n","Training loss per 100 training steps: 0.020824044942855835\n","Training loss per 100 training steps: 0.015914747731225327\n","Training loss per 100 training steps: 0.016531016518777718\n","Training loss per 100 training steps: 0.01583303109674244\n","Training loss per 100 training steps: 0.01478734905767647\n","Training loss per 100 training steps: 0.015139643479781802\n","Training loss per 100 training steps: 0.01529712028535681\n","Training loss per 100 training steps: 0.015819803097092026\n","Training loss per 100 training steps: 0.016208701643708526\n","Training loss epoch: 0.016412586677669642\n","Training accuracy epoch: 0.9950894840711461\n","Validating model...\n","Validation Loss: 0.19921213122955583\n","Validation Accuracy: 0.960074567169162\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 65.37171968333332 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.15501432445846688\n","Validation Accuracy: 0.9546324981978228\n","Validation duration: 3.1249002166667195 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 84.3%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.85      0.84     12546\n","        test       0.84      0.86      0.85      9012\n","   treatment       0.82      0.87      0.85      9297\n","\n","   micro avg       0.83      0.86      0.84     30855\n","   macro avg       0.83      0.86      0.84     30855\n","weighted avg       0.83      0.86      0.84     30855\n","\n","!!!!!! Starting model number 10 !!!!!!\n","Points in X_train after augmentation: 27734\n","Points in y_train after augmentation: 27734\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.2619760036468506\n","Training loss per 100 training steps: 0.4084230771306718\n","Training loss per 100 training steps: 0.30084728199376987\n","Training loss per 100 training steps: 0.26202162268549894\n","Training loss per 100 training steps: 0.2327193546101934\n","Training loss per 100 training steps: 0.21401126817716454\n","Training loss per 100 training steps: 0.2008923930077257\n","Training loss per 100 training steps: 0.1923910577551657\n","Training loss per 100 training steps: 0.18433930870894338\n","Training loss epoch: 0.17974187564555955\n","Training accuracy epoch: 0.9430422524240276\n","Validating model...\n","Validation Loss: 0.13942411326646031\n","Validation Accuracy: 0.957031176947727\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09861543774604797\n","Training loss per 100 training steps: 0.06883475327366355\n","Training loss per 100 training steps: 0.07266367930659459\n","Training loss per 100 training steps: 0.07174854006222217\n","Training loss per 100 training steps: 0.07368465902009733\n","Training loss per 100 training steps: 0.07465827177667213\n","Training loss per 100 training steps: 0.07478607371728402\n","Training loss per 100 training steps: 0.07291328195966089\n","Training loss per 100 training steps: 0.0726910810103726\n","Training loss epoch: 0.07265139378353765\n","Training accuracy epoch: 0.9769482563726052\n","Validating model...\n","Validation Loss: 0.14435237438067214\n","Validation Accuracy: 0.9570047637896776\n","Training epoch: 3\n","Training loss per 100 training steps: 0.10457507520914078\n","Training loss per 100 training steps: 0.040504355287861706\n","Training loss per 100 training steps: 0.041573860112633275\n","Training loss per 100 training steps: 0.04082248385290173\n","Training loss per 100 training steps: 0.04111684399989069\n","Training loss per 100 training steps: 0.04217740852839338\n","Training loss per 100 training steps: 0.04151224840808963\n","Training loss per 100 training steps: 0.0415316761452067\n","Training loss per 100 training steps: 0.0424801272577891\n","Training loss epoch: 0.04278018977358774\n","Training accuracy epoch: 0.9864092672657366\n","Validating model...\n","Validation Loss: 0.16190503919859986\n","Validation Accuracy: 0.9588350145413144\n","Training epoch: 4\n","Training loss per 100 training steps: 0.014714074321091175\n","Training loss per 100 training steps: 0.03181504065489009\n","Training loss per 100 training steps: 0.03010219485505915\n","Training loss per 100 training steps: 0.028205392681885252\n","Training loss per 100 training steps: 0.029255104172240916\n","Training loss per 100 training steps: 0.030291088604407306\n","Training loss per 100 training steps: 0.030600689203569825\n","Training loss per 100 training steps: 0.03115881576562186\n","Training loss per 100 training steps: 0.03123020151581792\n","Training loss epoch: 0.031795180407127165\n","Training accuracy epoch: 0.9900775775767944\n","Validating model...\n","Validation Loss: 0.17782047620139918\n","Validation Accuracy: 0.9575945153966755\n","Training epoch: 5\n","Training loss per 100 training steps: 0.017513779923319817\n","Training loss per 100 training steps: 0.023059146696618658\n","Training loss per 100 training steps: 0.022549910316202067\n","Training loss per 100 training steps: 0.02193564818390766\n","Training loss per 100 training steps: 0.024579751042839593\n","Training loss per 100 training steps: 0.02487333511230545\n","Training loss per 100 training steps: 0.024063741220234927\n","Training loss per 100 training steps: 0.024615813818505798\n","Training loss per 100 training steps: 0.025062427346402204\n","Training loss epoch: 0.024665456816941853\n","Training accuracy epoch: 0.9921900077406861\n","Validating model...\n","Validation Loss: 0.19813796727881802\n","Validation Accuracy: 0.9593810803031273\n","Training epoch: 6\n","Training loss per 100 training steps: 0.006160910241305828\n","Training loss per 100 training steps: 0.018990125624684266\n","Training loss per 100 training steps: 0.02047122781488127\n","Training loss per 100 training steps: 0.020691157907496618\n","Training loss per 100 training steps: 0.020870052245962306\n","Training loss per 100 training steps: 0.02265046486464197\n","Training loss per 100 training steps: 0.022032403346354888\n","Training loss per 100 training steps: 0.022991668865315153\n","Training loss per 100 training steps: 0.02339442034309251\n","Training loss epoch: 0.023279973792504075\n","Training accuracy epoch: 0.9928517461393953\n","Validating model...\n","Validation Loss: 0.2108958729409746\n","Validation Accuracy: 0.9576530504842825\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 56.65005299999999 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.1451999728289795\n","Validation Accuracy: 0.953876892146082\n","Validation duration: 3.1541892333333332 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 83.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.86      0.83     12546\n","        test       0.80      0.86      0.83      9012\n","   treatment       0.84      0.85      0.85      9297\n","\n","   micro avg       0.81      0.86      0.83     30855\n","   macro avg       0.81      0.86      0.83     30855\n","weighted avg       0.81      0.86      0.83     30855\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 1\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"1tBh5gOBHpN1"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zjhn7-LqHri0","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4f02a602-6adb-496d-927b-3180587177ff"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 200% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 41601\n","Points in y_train after augmentation: 41601\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.010075807571411\n","Training loss per 100 training steps: 0.4149974119840282\n","Training loss per 100 training steps: 0.30325951545837504\n","Training loss per 100 training steps: 0.25665378826747703\n","Training loss per 100 training steps: 0.2323367825042726\n","Training loss per 100 training steps: 0.21677361118668567\n","Training loss per 100 training steps: 0.20176916089398592\n","Training loss per 100 training steps: 0.1927356032864556\n","Training loss per 100 training steps: 0.1849950370303217\n","Training loss per 100 training steps: 0.17566849284502498\n","Training loss per 100 training steps: 0.16890365501063748\n","Training loss per 100 training steps: 0.16245313477935058\n","Training loss per 100 training steps: 0.15697574723344435\n","Training loss per 100 training steps: 0.1525219567800134\n","Training loss epoch: 0.1525219567800134\n","Training accuracy epoch: 0.9525041599832104\n","Validating model...\n","Validation Loss: 0.14742410896563685\n","Validation Accuracy: 0.954544989515034\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06470658630132675\n","Training loss per 100 training steps: 0.06232041415140623\n","Training loss per 100 training steps: 0.06232313654010198\n","Training loss per 100 training steps: 0.060791677174984515\n","Training loss per 100 training steps: 0.06002433244673131\n","Training loss per 100 training steps: 0.05942120401099503\n","Training loss per 100 training steps: 0.05948497363894607\n","Training loss per 100 training steps: 0.05911406735489716\n","Training loss per 100 training steps: 0.0590719555245338\n","Training loss per 100 training steps: 0.059290260917400646\n","Stopping epoch...\n","Training loss epoch: 0.059290260917400646\n","Training accuracy epoch: 0.98038732830559\n","Validating model...\n","Validation Loss: 0.15888156478184384\n","Validation Accuracy: 0.9527319044353237\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02022489905357361\n","Training loss per 100 training steps: 0.04200481677584645\n","Training loss per 100 training steps: 0.04211030054990369\n","Training loss per 100 training steps: 0.042008411954543814\n","Training loss per 100 training steps: 0.04235666823408513\n","Training loss per 100 training steps: 0.04441917740076245\n","Training loss per 100 training steps: 0.04678278289558661\n","Training loss per 100 training steps: 0.0466088817179862\n","Training loss per 100 training steps: 0.045789972863296106\n","Training loss per 100 training steps: 0.045098983598707634\n","Training loss per 100 training steps: 0.04435507056175859\n","Training loss per 100 training steps: 0.04490725529933353\n","Training loss per 100 training steps: 0.04474413927142771\n","Training loss per 100 training steps: 0.04484283806295047\n","Training loss epoch: 0.04484283806295047\n","Training accuracy epoch: 0.9861740049265074\n","Validating model...\n","Validation Loss: 0.17860637723722242\n","Validation Accuracy: 0.952171017819973\n","Training epoch: 4\n","Training loss per 100 training steps: 0.013770204968750477\n","Training loss per 100 training steps: 0.0285903216768425\n","Training loss per 100 training steps: 0.027340144934874046\n","Training loss per 100 training steps: 0.027452113844401688\n","Training loss per 100 training steps: 0.027478290254661253\n","Training loss per 100 training steps: 0.027288606132430854\n","Training loss per 100 training steps: 0.028634786908011172\n","Training loss per 100 training steps: 0.028639382729240388\n","Training loss per 100 training steps: 0.02873784719185018\n","Training loss per 100 training steps: 0.029015314310725022\n","Training loss per 100 training steps: 0.02916095975658984\n","Training loss per 100 training steps: 0.028626577441325136\n","Training loss per 100 training steps: 0.029245768082335897\n","Training loss per 100 training steps: 0.029814100224133434\n","Training loss epoch: 0.029814100224133434\n","Training accuracy epoch: 0.9910273007168559\n","Validating model...\n","Validation Loss: 0.20094077395541327\n","Validation Accuracy: 0.9528757595165486\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0024093587417155504\n","Training loss per 100 training steps: 0.021806482393940042\n","Training loss per 100 training steps: 0.02158148096183973\n","Training loss per 100 training steps: 0.021176122208249652\n","Training loss per 100 training steps: 0.0211416482228665\n","Training loss per 100 training steps: 0.02127537467868296\n","Training loss per 100 training steps: 0.021400708491048512\n","Training loss per 100 training steps: 0.021263334739882865\n","Training loss per 100 training steps: 0.021422981647175786\n","Training loss per 100 training steps: 0.021502337363260703\n","Training loss per 100 training steps: 0.021345604201439175\n","Training loss per 100 training steps: 0.021689787985406796\n","Training loss per 100 training steps: 0.02149148546072998\n","Training loss per 100 training steps: 0.021680702492051566\n","Training loss epoch: 0.021680702492051566\n","Training accuracy epoch: 0.9935192648443502\n","Validating model...\n","Validation Loss: 0.20037267694564223\n","Validation Accuracy: 0.9569048923405146\n","Training epoch: 6\n","Training loss per 100 training steps: 0.016212573274970055\n","Training loss per 100 training steps: 0.015915315639744007\n","Training loss per 100 training steps: 0.016174955447019072\n","Training loss per 100 training steps: 0.015238423204239755\n","Training loss per 100 training steps: 0.015803880199466012\n","Training loss per 100 training steps: 0.016238324412357567\n","Training loss per 100 training steps: 0.01608273110648047\n","Training loss per 100 training steps: 0.015876790891420068\n","Training loss per 100 training steps: 0.01727353253872128\n","Training loss per 100 training steps: 0.01791482701751359\n","Training loss per 100 training steps: 0.018768133150916508\n","Training loss per 100 training steps: 0.019530184109190683\n","Training loss per 100 training steps: 0.019860688120494678\n","Training loss per 100 training steps: 0.020426276386019643\n","Training loss epoch: 0.020426276386019643\n","Training accuracy epoch: 0.9940404122657917\n","Validating model...\n","Validation Loss: 0.21044864185009296\n","Validation Accuracy: 0.9584285808132776\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 79.74291523333328 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1588137621325182\n","Validation Accuracy: 0.9515782158459871\n","Validation duration: 3.1197731666667097 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 83.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.87      0.83     12546\n","        test       0.84      0.85      0.84      9012\n","   treatment       0.83      0.83      0.83      9297\n","\n","   micro avg       0.81      0.85      0.83     30855\n","   macro avg       0.82      0.85      0.83     30855\n","weighted avg       0.81      0.85      0.83     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 41601\n","Points in y_train after augmentation: 41601\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.042382001876831\n","Training loss per 100 training steps: 0.3905816233099097\n","Training loss per 100 training steps: 0.2930016631436585\n","Training loss per 100 training steps: 0.2497188864009721\n","Training loss per 100 training steps: 0.2263659679997443\n","Training loss per 100 training steps: 0.20849631046746187\n","Training loss per 100 training steps: 0.194507790391586\n","Training loss per 100 training steps: 0.18538765822365857\n","Training loss per 100 training steps: 0.17615771069006528\n","Training loss per 100 training steps: 0.16953637587789294\n","Training loss per 100 training steps: 0.16369834150393286\n","Training loss per 100 training steps: 0.15913055407950868\n","Training loss per 100 training steps: 0.15495951761949892\n","Training loss per 100 training steps: 0.15181437899486708\n","Training loss epoch: 0.15181437899486708\n","Training accuracy epoch: 0.952405563797784\n","Validating model...\n","Validation Loss: 0.15019333319036993\n","Validation Accuracy: 0.9532445024687858\n","Training epoch: 2\n","Training loss per 100 training steps: 0.16023601591587067\n","Training loss per 100 training steps: 0.06435373052954674\n","Training loss per 100 training steps: 0.06346753272065772\n","Training loss per 100 training steps: 0.06181400429544061\n","Training loss per 100 training steps: 0.05915684155548488\n","Training loss per 100 training steps: 0.05906930741316782\n","Training loss per 100 training steps: 0.05768969107710581\n","Training loss per 100 training steps: 0.057738922380267\n","Training loss per 100 training steps: 0.05857409273661422\n","Training loss per 100 training steps: 0.05811405194857128\n","Training loss per 100 training steps: 0.0582185387392747\n","Training loss per 100 training steps: 0.05829633483756249\n","Training loss per 100 training steps: 0.05825042280389444\n","Stopping epoch...\n","Training loss epoch: 0.05825042280389444\n","Training accuracy epoch: 0.981132317064234\n","Validating model...\n","Validation Loss: 0.16693340041130394\n","Validation Accuracy: 0.9545966163272507\n","Training epoch: 3\n","Training loss per 100 training steps: 0.01324558537453413\n","Training loss per 100 training steps: 0.03225001124065775\n","Training loss per 100 training steps: 0.032485013353911726\n","Training loss per 100 training steps: 0.03150260212724453\n","Training loss per 100 training steps: 0.0348562477484573\n","Training loss per 100 training steps: 0.0353104767588036\n","Training loss per 100 training steps: 0.03573314644556691\n","Training loss per 100 training steps: 0.036417269944904185\n","Training loss per 100 training steps: 0.03697024868553\n","Training loss per 100 training steps: 0.037528734515549264\n","Training loss per 100 training steps: 0.03762404300790228\n","Training loss per 100 training steps: 0.03790290565913007\n","Training loss per 100 training steps: 0.03819244919873256\n","Training loss per 100 training steps: 0.039378865821974966\n","Training loss epoch: 0.039378865821974966\n","Training accuracy epoch: 0.9874157085275673\n","Validating model...\n","Validation Loss: 0.17768969250141414\n","Validation Accuracy: 0.9500187024308837\n","Training epoch: 4\n","Training loss per 100 training steps: 0.024788441136479378\n","Training loss per 100 training steps: 0.04306947183334223\n","Training loss per 100 training steps: 0.03665774026989881\n","Training loss per 100 training steps: 0.034153280452905575\n","Training loss per 100 training steps: 0.03146715219883931\n","Training loss per 100 training steps: 0.03190083134554126\n","Training loss per 100 training steps: 0.031831912416848546\n","Training loss per 100 training steps: 0.03070814857297921\n","Training loss per 100 training steps: 0.030252327673519715\n","Training loss per 100 training steps: 0.029918542467977656\n","Training loss per 100 training steps: 0.029069590053616926\n","Training loss per 100 training steps: 0.02917293366932942\n","Training loss per 100 training steps: 0.029141100102005765\n","Training loss per 100 training steps: 0.02886699514453164\n","Training loss epoch: 0.02886699514453164\n","Training accuracy epoch: 0.9911920547990174\n","Validating model...\n","Validation Loss: 0.18026659884429597\n","Validation Accuracy: 0.9559842520495275\n","Training epoch: 5\n","Training loss per 100 training steps: 0.052454449236392975\n","Training loss per 100 training steps: 0.014868312793677802\n","Training loss per 100 training steps: 0.01638146446130484\n","Training loss per 100 training steps: 0.018269789921494195\n","Training loss per 100 training steps: 0.019342393142013276\n","Training loss per 100 training steps: 0.018959311547781157\n","Training loss per 100 training steps: 0.019386551038113372\n","Training loss per 100 training steps: 0.0195158896727797\n","Training loss per 100 training steps: 0.019515702978154987\n","Training loss per 100 training steps: 0.019762353165673152\n","Training loss per 100 training steps: 0.019769801468994062\n","Training loss per 100 training steps: 0.019903228551273713\n","Training loss per 100 training steps: 0.020307837416077473\n","Training loss per 100 training steps: 0.020211131883683387\n","Training loss epoch: 0.020211131883683387\n","Training accuracy epoch: 0.9938257260452714\n","Validating model...\n","Validation Loss: 0.21104205849689323\n","Validation Accuracy: 0.9560800775600066\n","Training epoch: 6\n","Training loss per 100 training steps: 0.006908138748258352\n","Training loss per 100 training steps: 0.020790742101069393\n","Training loss per 100 training steps: 0.01957043215854844\n","Training loss per 100 training steps: 0.017948373131325586\n","Training loss per 100 training steps: 0.016982104916542423\n","Training loss per 100 training steps: 0.017452710233080367\n","Training loss per 100 training steps: 0.01770168888505034\n","Training loss per 100 training steps: 0.017990446183747465\n","Training loss per 100 training steps: 0.01810669195560678\n","Training loss per 100 training steps: 0.01785799394052612\n","Training loss per 100 training steps: 0.018083413025470344\n","Training loss per 100 training steps: 0.017868935051287435\n","Training loss per 100 training steps: 0.017789868607579713\n","Training loss per 100 training steps: 0.017588413412595903\n","Training loss epoch: 0.017588413412595903\n","Training accuracy epoch: 0.9946941460954614\n","Validating model...\n","Validation Loss: 0.23387288452162372\n","Validation Accuracy: 0.9556891750776966\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 84.79772604999998 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.16515622294671764\n","Validation Accuracy: 0.9483405062771652\n","Validation duration: 3.1953679499999756 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 80.8%\n","              precision    recall  f1-score   support\n","\n","     problem       0.75      0.87      0.80     12547\n","        test       0.72      0.87      0.79      9012\n","   treatment       0.83      0.84      0.83      9299\n","\n","   micro avg       0.76      0.86      0.81     30858\n","   macro avg       0.77      0.86      0.81     30858\n","weighted avg       0.77      0.86      0.81     30858\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 41601\n","Points in y_train after augmentation: 41601\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.243306875228882\n","Training loss per 100 training steps: 0.40481647672039445\n","Training loss per 100 training steps: 0.2955372916970087\n","Training loss per 100 training steps: 0.2535651013428389\n","Training loss per 100 training steps: 0.226630063072553\n","Training loss per 100 training steps: 0.21000113374667015\n","Training loss per 100 training steps: 0.19698637201700253\n","Training loss per 100 training steps: 0.1873381582783607\n","Training loss per 100 training steps: 0.1790279693780618\n","Training loss per 100 training steps: 0.17188174366024833\n","Training loss per 100 training steps: 0.16599871838776084\n","Training loss per 100 training steps: 0.1607807302368732\n","Training loss per 100 training steps: 0.15595258825104202\n","Training loss per 100 training steps: 0.15131377770875415\n","Training loss epoch: 0.15131377770875415\n","Training accuracy epoch: 0.9520899029242016\n","Validating model...\n","Validation Loss: 0.14527385560916617\n","Validation Accuracy: 0.9524751841916674\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04584845155477524\n","Training loss per 100 training steps: 0.05833466853577607\n","Training loss per 100 training steps: 0.053139369955647796\n","Training loss per 100 training steps: 0.05446514601593348\n","Training loss per 100 training steps: 0.05590595112779082\n","Training loss per 100 training steps: 0.0574213484434147\n","Training loss per 100 training steps: 0.058304865595833484\n","Training loss per 100 training steps: 0.0587644852543736\n","Training loss per 100 training steps: 0.058726113763976184\n","Training loss per 100 training steps: 0.059236683731859384\n","Training loss per 100 training steps: 0.0591553219256329\n","Training loss per 100 training steps: 0.058798921663740435\n","Stopping epoch...\n","Training loss epoch: 0.058798921663740435\n","Training accuracy epoch: 0.9808366980533508\n","Validating model...\n","Validation Loss: 0.15044030102042408\n","Validation Accuracy: 0.9589916726984141\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02141806297004223\n","Training loss per 100 training steps: 0.03351838266624525\n","Training loss per 100 training steps: 0.03769283936780632\n","Training loss per 100 training steps: 0.03886164875199827\n","Training loss per 100 training steps: 0.039126037736133004\n","Training loss per 100 training steps: 0.038945247252804495\n","Training loss per 100 training steps: 0.039377195776878746\n","Training loss per 100 training steps: 0.04013973874267132\n","Training loss per 100 training steps: 0.04052233352609556\n","Training loss per 100 training steps: 0.04073419239703818\n","Training loss per 100 training steps: 0.041260534361773335\n","Training loss per 100 training steps: 0.04123618710108548\n","Training loss per 100 training steps: 0.04129590374920874\n","Training loss per 100 training steps: 0.04120080510324739\n","Training loss epoch: 0.04120080510324739\n","Training accuracy epoch: 0.9871846067704303\n","Validating model...\n","Validation Loss: 0.15354778645439193\n","Validation Accuracy: 0.9587475304272637\n","Training epoch: 4\n","Training loss per 100 training steps: 0.04378059506416321\n","Training loss per 100 training steps: 0.024028485644341326\n","Training loss per 100 training steps: 0.022384476367805838\n","Training loss per 100 training steps: 0.02420218519911331\n","Training loss per 100 training steps: 0.025932004520822866\n","Training loss per 100 training steps: 0.02631264503177594\n","Training loss per 100 training steps: 0.02710191753722755\n","Training loss per 100 training steps: 0.027378724821622\n","Training loss per 100 training steps: 0.02728517005371497\n","Training loss per 100 training steps: 0.027449532621888987\n","Training loss per 100 training steps: 0.027592025145799476\n","Training loss per 100 training steps: 0.027837801358720066\n","Training loss per 100 training steps: 0.028045123986505147\n","Training loss per 100 training steps: 0.028002682117262798\n","Training loss epoch: 0.028002682117262798\n","Training accuracy epoch: 0.9913759496400207\n","Validating model...\n","Validation Loss: 0.18488108032903114\n","Validation Accuracy: 0.9599489627904174\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0031880056485533714\n","Training loss per 100 training steps: 0.01883209038336789\n","Training loss per 100 training steps: 0.019571464844696705\n","Training loss per 100 training steps: 0.018652221290537764\n","Training loss per 100 training steps: 0.019259047815782318\n","Training loss per 100 training steps: 0.019981152527143494\n","Training loss per 100 training steps: 0.020695524142651016\n","Training loss per 100 training steps: 0.021396350218542783\n","Training loss per 100 training steps: 0.02213672405669376\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 2\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"Zjhn7-LqHri0"},{"cell_type":"code","source":["number_of_training_models = 8\n","target_augmented_percentage = 2\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["65a5364e7cb946558f037973127bbee2","8dd40c66167a47bcb40e64e3e81c1a28","72d26184d1ca4882b74ccccaa6542f2f","297c75c68bdf4e7d9b2a92b67a9a3a69","bb79c41b0232465287119cdfbb454937","9c613aed72374a31bb8ebc8439359402","a80baad4a02f4bc68e7fee3278c94162","607144b6c030463caa32a45112de63dc","9cd598e0c3be4a349c1816e7b3472bd9","f0fc6b995cc04e3e84401148965aa57c","62dff514a5154d5e8ac66208f12d1074"]},"id":"JIL7ziYC_I1M","executionInfo":{"status":"ok","timestamp":1663316969892,"user_tz":240,"elapsed":1197866,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}},"outputId":"b42d103f-f2a8-4dde-e7f7-28c475a6a3e7"},"id":"JIL7ziYC_I1M","execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 200% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 41601\n","Points in y_train after augmentation: 41601\n","Device:  cuda\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"65a5364e7cb946558f037973127bbee2","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.974623203277588\n","Training loss per 100 training steps: 0.4110132823928748\n","Training loss per 100 training steps: 0.3049025844541652\n","Training loss per 100 training steps: 0.262792158574856\n","Training loss per 100 training steps: 0.23476395801527244\n","Training loss per 100 training steps: 0.21712400005041008\n","Training loss per 100 training steps: 0.20323655318574183\n","Training loss per 100 training steps: 0.19111643630091882\n","Training loss per 100 training steps: 0.18221273452750456\n","Training loss per 100 training steps: 0.17397428144567484\n","Training loss per 100 training steps: 0.16842563163031352\n","Training loss per 100 training steps: 0.16243470880921107\n","Training loss per 100 training steps: 0.1576885602357088\n","Training loss per 100 training steps: 0.1533158504426319\n","Training loss epoch: 0.1533158504426319\n","Training accuracy epoch: 0.9515631599519669\n","Validating model...\n","Validation Loss: 0.1497343113137917\n","Validation Accuracy: 0.9536585398798801\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04632359370589256\n","Training loss per 100 training steps: 0.06827099849977115\n","Training loss per 100 training steps: 0.0668995458938515\n","Training loss per 100 training steps: 0.06434026943129856\n","Training loss per 100 training steps: 0.06341592367143925\n","Training loss per 100 training steps: 0.06286557451886926\n","Training loss per 100 training steps: 0.06246756850904514\n","Training loss per 100 training steps: 0.0628314028758444\n","Training loss per 100 training steps: 0.061874871834596334\n","Training loss per 100 training steps: 0.061365624947099226\n","Training loss per 100 training steps: 0.06100420836781661\n","Training loss per 100 training steps: 0.06148291269205612\n","Training loss per 100 training steps: 0.06113183776926339\n","Training loss per 100 training steps: 0.060763025873443996\n","Training loss epoch: 0.060763025873443996\n","Training accuracy epoch: 0.9807059753666016\n","Validating model...\n","Validation Loss: 0.1578652723752833\n","Validation Accuracy: 0.9565200448189299\n","Training epoch: 3\n","Training loss per 100 training steps: 0.06394024938344955\n","Training loss per 100 training steps: 0.03020062303345761\n","Training loss per 100 training steps: 0.03343707197160455\n","Training loss per 100 training steps: 0.03408574331025794\n","Training loss per 100 training steps: 0.034319152455762995\n","Training loss per 100 training steps: 0.035057368548633436\n","Training loss per 100 training steps: 0.035404417033310355\n","Training loss per 100 training steps: 0.03572361615467179\n","Training loss per 100 training steps: 0.03563590467074414\n","Training loss per 100 training steps: 0.03526505708839686\n","Training loss per 100 training steps: 0.035590832819348085\n","Training loss per 100 training steps: 0.035618696330799525\n","Training loss per 100 training steps: 0.03555241419608433\n","Training loss per 100 training steps: 0.035358245932027486\n","Stopping epoch...\n","Training loss epoch: 0.035358245932027486\n","Training accuracy epoch: 0.9881326725597144\n","Validating model...\n","Validation Loss: 0.18406442110124346\n","Validation Accuracy: 0.9554522877901659\n","Training epoch: 4\n","Training loss per 100 training steps: 0.005468377377837896\n","Training loss per 100 training steps: 0.0297317289595151\n","Training loss per 100 training steps: 0.025939877108793558\n","Training loss per 100 training steps: 0.02569792399889143\n","Training loss per 100 training steps: 0.02559432719222751\n","Training loss per 100 training steps: 0.026633339662996202\n","Training loss per 100 training steps: 0.025790157956756904\n","Training loss per 100 training steps: 0.025837823156630767\n","Training loss per 100 training steps: 0.025700897819446296\n","Training loss per 100 training steps: 0.02590136841579354\n","Training loss per 100 training steps: 0.026792633632145874\n","Training loss per 100 training steps: 0.02673524859945859\n","Training loss per 100 training steps: 0.026795468989877554\n","Training loss per 100 training steps: 0.026995386786022108\n","Training loss epoch: 0.026995386786022108\n","Training accuracy epoch: 0.9916774779921188\n","Validating model...\n","Validation Loss: 0.18772977846069866\n","Validation Accuracy: 0.9571715140317977\n","Training epoch: 5\n","Training loss per 100 training steps: 0.01155360322445631\n","Training loss per 100 training steps: 0.017164641429928344\n","Training loss per 100 training steps: 0.015061864818490357\n","Training loss per 100 training steps: 0.01548441457720721\n","Training loss per 100 training steps: 0.016495947362454445\n","Training loss per 100 training steps: 0.017943011849961558\n","Training loss per 100 training steps: 0.018460841535066816\n","Training loss per 100 training steps: 0.01961081653013666\n","Training loss per 100 training steps: 0.02064016097360122\n","Training loss per 100 training steps: 0.021415082227307414\n","Training loss per 100 training steps: 0.021662330524784258\n","Training loss per 100 training steps: 0.021493365723108088\n","Training loss per 100 training steps: 0.02197567610052468\n","Training loss per 100 training steps: 0.02186310275724991\n","Training loss epoch: 0.02186310275724991\n","Training accuracy epoch: 0.9932222745453918\n","Validating model...\n","Validation Loss: 0.21866427432721505\n","Validation Accuracy: 0.9561311387910585\n","Training epoch: 6\n","Training loss per 100 training steps: 0.002628637244924903\n","Training loss per 100 training steps: 0.014958614847705802\n","Training loss per 100 training steps: 0.015675562766927355\n","Training loss per 100 training steps: 0.01641985224016503\n","Training loss per 100 training steps: 0.0179095910202353\n","Training loss per 100 training steps: 0.018646715726425032\n","Training loss per 100 training steps: 0.01939424863008638\n","Training loss per 100 training steps: 0.018783958794387354\n","Training loss per 100 training steps: 0.018662080837676148\n","Training loss per 100 training steps: 0.019179651020351875\n","Training loss per 100 training steps: 0.018825127279587586\n","Training loss per 100 training steps: 0.018810854201970813\n","Training loss per 100 training steps: 0.018733743822391492\n","Training loss per 100 training steps: 0.01865225524790918\n","Training loss epoch: 0.01865225524790918\n","Training accuracy epoch: 0.9944706334701837\n","Validating model...\n","Validation Loss: 0.2165375483500493\n","Validation Accuracy: 0.9570568513064007\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 82.29468961666666 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1569541174421492\n","Validation Accuracy: 0.9517401584799833\n","Validation duration: 3.088307716666653 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 82.8%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.82      0.82     12546\n","        test       0.80      0.86      0.83      9012\n","   treatment       0.83      0.84      0.84      9297\n","\n","   micro avg       0.82      0.84      0.83     30855\n","   macro avg       0.82      0.84      0.83     30855\n","weighted avg       0.82      0.84      0.83     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 41601\n","Points in y_train after augmentation: 41601\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.404677629470825\n","Training loss per 100 training steps: 0.3917122958320202\n","Training loss per 100 training steps: 0.2962731351677458\n","Training loss per 100 training steps: 0.2520351322163577\n","Training loss per 100 training steps: 0.22477049947230893\n","Training loss per 100 training steps: 0.20482998446165446\n","Training loss per 100 training steps: 0.19145637901868678\n","Training loss per 100 training steps: 0.1819886425496763\n","Training loss per 100 training steps: 0.17409132847494996\n","Training loss per 100 training steps: 0.16749446991661546\n","Training loss per 100 training steps: 0.1615673519380681\n","Training loss per 100 training steps: 0.15702300891280174\n","Training loss per 100 training steps: 0.15339454165275995\n","Training loss per 100 training steps: 0.15138051339026418\n","Training loss epoch: 0.15138051339026418\n","Training accuracy epoch: 0.9528598683638918\n","Validating model...\n","Validation Loss: 0.17519436452489395\n","Validation Accuracy: 0.9448531418906226\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09872708469629288\n","Training loss per 100 training steps: 0.09903946760488619\n","Stopping epoch...\n","Training loss epoch: 0.09903946760488619\n","Training accuracy epoch: 0.9610975324525604\n","Validating model...\n","Validation Loss: 0.17266984554854306\n","Validation Accuracy: 0.9523866591376142\n","Training epoch: 3\n","Training loss per 100 training steps: 0.12415394186973572\n","Training loss per 100 training steps: 0.06287579019876695\n","Training loss per 100 training steps: 0.0625668994500881\n","Training loss per 100 training steps: 0.062346339177037045\n","Training loss per 100 training steps: 0.061970403662388054\n","Training loss per 100 training steps: 0.061533519827636204\n","Training loss per 100 training steps: 0.061164985552272094\n","Training loss per 100 training steps: 0.061028148527569354\n","Training loss per 100 training steps: 0.060455372620701844\n","Training loss per 100 training steps: 0.05959922054159216\n","Training loss per 100 training steps: 0.05895729941831386\n","Training loss per 100 training steps: 0.05899432642012327\n","Training loss per 100 training steps: 0.05886666913094971\n","Training loss per 100 training steps: 0.05855829697488868\n","Training loss epoch: 0.05855829697488868\n","Training accuracy epoch: 0.9817082399626547\n","Validating model...\n","Validation Loss: 0.16737573071346654\n","Validation Accuracy: 0.9515290568519169\n","Training epoch: 4\n","Training loss per 100 training steps: 0.06630726903676987\n","Training loss per 100 training steps: 0.04319362886858606\n","Training loss per 100 training steps: 0.04251131610203516\n","Training loss per 100 training steps: 0.03936572445199153\n","Training loss per 100 training steps: 0.03738815010034077\n","Training loss per 100 training steps: 0.037152005298185846\n","Training loss per 100 training steps: 0.037213989210387884\n","Training loss per 100 training steps: 0.03699163869242536\n","Training loss per 100 training steps: 0.037604871935289025\n","Training loss per 100 training steps: 0.03756125191496385\n","Training loss per 100 training steps: 0.03670975192846334\n","Training loss per 100 training steps: 0.03708166049790825\n","Training loss per 100 training steps: 0.03725124986378552\n","Training loss per 100 training steps: 0.03752239947241275\n","Training loss epoch: 0.03752239947241275\n","Training accuracy epoch: 0.9884298355381409\n","Validating model...\n","Validation Loss: 0.1740809098950454\n","Validation Accuracy: 0.9565283027764225\n","Training epoch: 5\n","Training loss per 100 training steps: 0.004465190693736076\n","Training loss per 100 training steps: 0.023175165566643424\n","Training loss per 100 training steps: 0.02250891684239443\n","Training loss per 100 training steps: 0.021642995218164676\n","Training loss per 100 training steps: 0.020731863953310187\n","Training loss per 100 training steps: 0.022936449588105423\n","Training loss per 100 training steps: 0.024141290131917598\n","Training loss per 100 training steps: 0.025435354037990212\n","Training loss per 100 training steps: 0.025916070110378518\n","Training loss per 100 training steps: 0.026421828881799184\n","Training loss per 100 training steps: 0.026668744596450793\n","Training loss per 100 training steps: 0.027164651980039093\n","Training loss per 100 training steps: 0.02724585465845116\n","Training loss per 100 training steps: 0.02733594157449725\n","Training loss epoch: 0.02733594157449725\n","Training accuracy epoch: 0.9915235265076973\n","Validating model...\n","Validation Loss: 0.19092676004806122\n","Validation Accuracy: 0.9569080047650718\n","Training epoch: 6\n","Training loss per 100 training steps: 0.02772892266511917\n","Training loss per 100 training steps: 0.015460137809778904\n","Training loss per 100 training steps: 0.016325481223818192\n","Training loss per 100 training steps: 0.01683832272079671\n","Training loss per 100 training steps: 0.01710032364016775\n","Training loss per 100 training steps: 0.016548746629472182\n","Training loss per 100 training steps: 0.018151267465864915\n","Training loss per 100 training steps: 0.018992150799499508\n","Training loss per 100 training steps: 0.019227971682399418\n","Training loss per 100 training steps: 0.019266939870137143\n","Training loss per 100 training steps: 0.019298728952543916\n","Training loss per 100 training steps: 0.020144122000159838\n","Training loss per 100 training steps: 0.020520348920396527\n","Training loss per 100 training steps: 0.020869799076953903\n","Training loss epoch: 0.020869799076953903\n","Training accuracy epoch: 0.9935055862074492\n","Validating model...\n","Validation Loss: 0.2086530144193343\n","Validation Accuracy: 0.9550825290566909\n","Training epoch: 7\n","Training loss per 100 training steps: 0.059882353991270065\n","Training loss per 100 training steps: 0.017316418426747592\n","Training loss per 100 training steps: 0.01492323979807193\n","Training loss per 100 training steps: 0.01660781269011233\n","Training loss per 100 training steps: 0.015746119623031803\n","Training loss per 100 training steps: 0.015375040878775063\n","Training loss per 100 training steps: 0.01693954826979596\n","Training loss per 100 training steps: 0.017253182526676517\n","Training loss per 100 training steps: 0.01792183655862651\n","Training loss per 100 training steps: 0.01841178607097677\n","Training loss per 100 training steps: 0.019278664169107358\n","Training loss per 100 training steps: 0.019923339360609284\n","Training loss per 100 training steps: 0.020157728366302537\n","Training loss per 100 training steps: 0.020033659069669318\n","Training loss epoch: 0.020033659069669318\n","Training accuracy epoch: 0.9940102395362957\n","Validating model...\n","Validation Loss: 0.1975429039471178\n","Validation Accuracy: 0.95608483691762\n","Training epoch: 8\n","Training loss per 100 training steps: 0.005713608581572771\n","Training loss per 100 training steps: 0.012219198660159686\n","Training loss per 100 training steps: 0.013787602388360236\n","Training loss per 100 training steps: 0.013497739026448272\n","Training loss per 100 training steps: 0.012969794915118104\n","Training loss per 100 training steps: 0.014839830977852436\n","Training loss per 100 training steps: 0.014917550313215976\n","Training loss per 100 training steps: 0.015357279332574542\n","Training loss per 100 training steps: 0.015300517887062801\n","Training loss per 100 training steps: 0.01571901386878794\n","Training loss per 100 training steps: 0.01585740549992849\n","Training loss per 100 training steps: 0.01572514992043081\n","Training loss per 100 training steps: 0.015658167849042236\n","Training loss per 100 training steps: 0.01590703189093208\n","Training loss epoch: 0.01590703189093208\n","Training accuracy epoch: 0.9951886508279664\n","Validating model...\n","Validation Loss: 0.23934722382291038\n","Validation Accuracy: 0.9545988056202921\n","Training epoch: 9\n","Patience limit reached\n","Training duration: 97.99568694999999 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.18469022665629853\n","Validation Accuracy: 0.9477891012866573\n","Validation duration: 3.0914538666666886 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 81.3%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.82      0.82     12546\n","        test       0.75      0.86      0.80      9012\n","   treatment       0.78      0.85      0.82      9299\n","\n","   micro avg       0.79      0.84      0.81     30857\n","   macro avg       0.78      0.84      0.81     30857\n","weighted avg       0.79      0.84      0.81     30857\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 41601\n","Points in y_train after augmentation: 41601\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.007469654083252\n","Training loss per 100 training steps: 0.38753615009902725\n","Training loss per 100 training steps: 0.2870749646417834\n","Training loss per 100 training steps: 0.24685402516510796\n","Training loss per 100 training steps: 0.22395717453889716\n","Training loss per 100 training steps: 0.20662999372862415\n","Training loss per 100 training steps: 0.19185080875746421\n","Training loss per 100 training steps: 0.1810973188447927\n","Training loss per 100 training steps: 0.17407208480424574\n","Training loss per 100 training steps: 0.16781205518768644\n","Training loss per 100 training steps: 0.16292843148744965\n","Training loss per 100 training steps: 0.15795688489139026\n","Training loss per 100 training steps: 0.1529945514702256\n","Training loss per 100 training steps: 0.14914318509124289\n","Training loss epoch: 0.14914318509124289\n","Training accuracy epoch: 0.9533225518273156\n","Validating model...\n","Validation Loss: 0.14626040791052503\n","Validation Accuracy: 0.9537525460272535\n","Training epoch: 2\n","Training loss per 100 training steps: 0.03084666281938553\n","Training loss per 100 training steps: 0.05909348290302966\n","Training loss per 100 training steps: 0.05809708389532359\n","Training loss per 100 training steps: 0.06120255369185609\n","Training loss per 100 training steps: 0.06254973841605806\n","Training loss per 100 training steps: 0.06168720028697775\n","Training loss per 100 training steps: 0.06091417541716576\n","Training loss per 100 training steps: 0.06109317626303245\n","Training loss per 100 training steps: 0.06127151045523881\n","Training loss per 100 training steps: 0.06062589819464506\n","Training loss per 100 training steps: 0.05974988857694491\n","Training loss per 100 training steps: 0.06033016654128187\n","Training loss per 100 training steps: 0.060053216419659626\n","Training loss per 100 training steps: 0.059478146112277\n","Training loss epoch: 0.059478146112277\n","Training accuracy epoch: 0.9814257173653184\n","Validating model...\n","Validation Loss: 0.15474742776774741\n","Validation Accuracy: 0.9575376401646164\n","Training epoch: 3\n","Training loss per 100 training steps: 0.011832274496555328\n","Training loss per 100 training steps: 0.028665864641898044\n","Training loss per 100 training steps: 0.03231893259503726\n","Training loss per 100 training steps: 0.03287433959316289\n","Training loss per 100 training steps: 0.0331106022946151\n","Training loss per 100 training steps: 0.03444959777904611\n","Training loss per 100 training steps: 0.03500796643689355\n","Training loss per 100 training steps: 0.034380242755117106\n","Training loss per 100 training steps: 0.0349082261761104\n","Training loss per 100 training steps: 0.03530119300910895\n","Training loss per 100 training steps: 0.03556121553556731\n","Training loss per 100 training steps: 0.035394925046813665\n","Training loss per 100 training steps: 0.035677094045068004\n","Training loss per 100 training steps: 0.03628273532034358\n","Training loss epoch: 0.03628273532034358\n","Training accuracy epoch: 0.9887253618555465\n","Validating model...\n","Validation Loss: 0.18323998685394013\n","Validation Accuracy: 0.9574168167576548\n","Training epoch: 4\n","Training loss per 100 training steps: 0.008828558959066868\n","Training loss per 100 training steps: 0.023587216414501982\n","Training loss per 100 training steps: 0.021989818276091484\n","Training loss per 100 training steps: 0.023226040735704657\n","Training loss per 100 training steps: 0.02275307077253725\n","Training loss per 100 training steps: 0.022694805401615323\n","Training loss per 100 training steps: 0.023601810613100085\n","Training loss per 100 training steps: 0.02497881649679155\n","Training loss per 100 training steps: 0.025126151219806804\n","Training loss per 100 training steps: 0.024697860473465613\n","Training loss per 100 training steps: 0.025555023705978952\n","Training loss per 100 training steps: 0.026040310839533242\n","Training loss per 100 training steps: 0.026242388974125733\n","Training loss per 100 training steps: 0.026425768079411174\n","Training loss epoch: 0.026425768079411174\n","Training accuracy epoch: 0.9918909289437066\n","Validating model...\n","Validation Loss: 0.20446661146139944\n","Validation Accuracy: 0.9557971390373837\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0007492854492738843\n","Training loss per 100 training steps: 0.02115415550980459\n","Training loss per 100 training steps: 0.021123379584174807\n","Training loss per 100 training steps: 0.021424431553763335\n","Training loss per 100 training steps: 0.02063130863658861\n","Training loss per 100 training steps: 0.01944340555643999\n","Training loss per 100 training steps: 0.019040800826831298\n","Training loss per 100 training steps: 0.019408335346725574\n","Training loss per 100 training steps: 0.0198622666154805\n","Training loss per 100 training steps: 0.020291216170112165\n","Training loss per 100 training steps: 0.021038901183137122\n","Training loss per 100 training steps: 0.02109840154245713\n","Training loss per 100 training steps: 0.02189654327150559\n","Training loss per 100 training steps: 0.0219363358852174\n","Training loss epoch: 0.0219363358852174\n","Training accuracy epoch: 0.9934739864407901\n","Validating model...\n","Validation Loss: 0.19064648497801323\n","Validation Accuracy: 0.9574790758597497\n","Training epoch: 6\n","Training loss per 100 training steps: 0.020728012546896935\n","Training loss per 100 training steps: 0.014257131676341748\n","Training loss per 100 training steps: 0.016821312825821007\n","Training loss per 100 training steps: 0.01614313183282347\n","Training loss per 100 training steps: 0.01674117652180853\n","Training loss per 100 training steps: 0.01722701873963498\n","Training loss per 100 training steps: 0.017025212717192952\n","Training loss per 100 training steps: 0.017064553158420512\n","Training loss per 100 training steps: 0.017186291649573995\n","Training loss per 100 training steps: 0.017158143710184554\n","Training loss per 100 training steps: 0.017787052790947645\n","Training loss per 100 training steps: 0.01869486859843848\n","Training loss per 100 training steps: 0.018608778791588777\n","Training loss per 100 training steps: 0.01845971633512544\n","Training loss epoch: 0.01845971633512544\n","Training accuracy epoch: 0.9944428512615975\n","Validating model...\n","Validation Loss: 0.21150882064376947\n","Validation Accuracy: 0.9569997880973286\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 80.04184065 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15574762852931465\n","Validation Accuracy: 0.9513653582102587\n","Validation duration: 3.0211496500000066 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 82.9%\n","              precision    recall  f1-score   support\n","\n","     problem       0.78      0.87      0.82     12546\n","        test       0.83      0.83      0.83      9012\n","   treatment       0.82      0.87      0.84      9297\n","\n","   micro avg       0.80      0.86      0.83     30855\n","   macro avg       0.81      0.86      0.83     30855\n","weighted avg       0.80      0.86      0.83     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 41601\n","Points in y_train after augmentation: 41601\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.904477596282959\n","Training loss per 100 training steps: 0.37824048817452816\n","Training loss per 100 training steps: 0.284826249143674\n","Training loss per 100 training steps: 0.24561063660636692\n","Training loss per 100 training steps: 0.2253557850892407\n","Training loss per 100 training steps: 0.2111045988629797\n","Training loss per 100 training steps: 0.19800947631977361\n","Training loss per 100 training steps: 0.1868098378340885\n","Training loss per 100 training steps: 0.17779735363229235\n","Training loss per 100 training steps: 0.16982676728848745\n","Training loss per 100 training steps: 0.16354305703345534\n","Training loss per 100 training steps: 0.15794411621020124\n","Training loss per 100 training steps: 0.15296877107639595\n","Training loss per 100 training steps: 0.14842859749196094\n","Training loss epoch: 0.14842859749196094\n","Training accuracy epoch: 0.9532391512702042\n","Validating model...\n","Validation Loss: 0.14471512820039475\n","Validation Accuracy: 0.9538684370290169\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06153777614235878\n","Training loss per 100 training steps: 0.06581817943565917\n","Training loss per 100 training steps: 0.05631883084526128\n","Training loss per 100 training steps: 0.05623242801459091\n","Training loss per 100 training steps: 0.0580533641042708\n","Training loss per 100 training steps: 0.05652873619053394\n","Training loss per 100 training steps: 0.05600325211192235\n","Training loss per 100 training steps: 0.056412661019161335\n","Training loss per 100 training steps: 0.05685654298048327\n","Training loss per 100 training steps: 0.057427553552643215\n","Training loss per 100 training steps: 0.05747062132959454\n","Training loss per 100 training steps: 0.058259975112789394\n","Training loss per 100 training steps: 0.05878832652402203\n","Training loss per 100 training steps: 0.05862680025939915\n","Training loss epoch: 0.05862680025939915\n","Training accuracy epoch: 0.9818597379024255\n","Validating model...\n","Validation Loss: 0.15378498226742854\n","Validation Accuracy: 0.9558535330618348\n","Training epoch: 3\n","Training loss per 100 training steps: 0.014427851885557175\n","Training loss per 100 training steps: 0.0376872582278113\n","Training loss per 100 training steps: 0.03548458033005026\n","Training loss per 100 training steps: 0.034922046251935374\n","Training loss per 100 training steps: 0.03514153352779501\n","Training loss per 100 training steps: 0.0349783840551582\n","Training loss per 100 training steps: 0.035871080489567296\n","Training loss per 100 training steps: 0.036639059699982796\n","Training loss per 100 training steps: 0.03671372868222406\n","Training loss per 100 training steps: 0.03674904530241023\n","Training loss per 100 training steps: 0.036246091404536204\n","Training loss per 100 training steps: 0.03623078909347749\n","Training loss per 100 training steps: 0.0367795118160017\n","Training loss per 100 training steps: 0.037640772259444844\n","Training loss epoch: 0.037640772259444844\n","Training accuracy epoch: 0.988260974308916\n","Validating model...\n","Validation Loss: 0.14839623431832372\n","Validation Accuracy: 0.9605405495315092\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01655333861708641\n","Training loss per 100 training steps: 0.04218594271615885\n","Training loss per 100 training steps: 0.03672779123275657\n","Training loss per 100 training steps: 0.03384671704162939\n","Training loss per 100 training steps: 0.03200181723140329\n","Training loss per 100 training steps: 0.030913308560485745\n","Training loss per 100 training steps: 0.03117327606317102\n","Training loss per 100 training steps: 0.030869237082338123\n","Training loss per 100 training steps: 0.030072061038464448\n","Training loss per 100 training steps: 0.029361268080815933\n","Training loss per 100 training steps: 0.02872797067898868\n","Training loss per 100 training steps: 0.028221328319805325\n","Training loss per 100 training steps: 0.02829036882212525\n","Training loss per 100 training steps: 0.02768743723199532\n","Training loss epoch: 0.02768743723199532\n","Training accuracy epoch: 0.9912313531662829\n","Validating model...\n","Validation Loss: 0.1970920347753767\n","Validation Accuracy: 0.9582668572335182\n","Training epoch: 5\n","Training loss per 100 training steps: 0.006392241455614567\n","Training loss per 100 training steps: 0.019695293516759752\n","Training loss per 100 training steps: 0.018157674360207158\n","Training loss per 100 training steps: 0.017583841536669028\n","Training loss per 100 training steps: 0.01702890470693645\n","Training loss per 100 training steps: 0.017614409355158563\n","Training loss per 100 training steps: 0.0181723363572978\n","Training loss per 100 training steps: 0.01865277599439373\n","Training loss per 100 training steps: 0.018472899025167744\n","Training loss per 100 training steps: 0.01899425989093381\n","Training loss per 100 training steps: 0.019113453697286672\n","Training loss per 100 training steps: 0.019128304147613035\n","Training loss per 100 training steps: 0.01897857299410012\n","Training loss per 100 training steps: 0.019431816449668134\n","Training loss epoch: 0.019431816449668134\n","Training accuracy epoch: 0.9941184465745905\n","Validating model...\n","Validation Loss: 0.19324346214484472\n","Validation Accuracy: 0.9586394366443671\n","Training epoch: 6\n","Training loss per 100 training steps: 0.020487332716584206\n","Training loss per 100 training steps: 0.015455019925398255\n","Training loss per 100 training steps: 0.014653254335830729\n","Training loss per 100 training steps: 0.015028027210487486\n","Training loss per 100 training steps: 0.015303392083360292\n","Training loss per 100 training steps: 0.016792357049196002\n","Training loss per 100 training steps: 0.016512649129394725\n","Training loss per 100 training steps: 0.01701022113196601\n","Training loss per 100 training steps: 0.017787389246813463\n","Training loss per 100 training steps: 0.017617944322329285\n","Training loss per 100 training steps: 0.017798449657491076\n","Training loss per 100 training steps: 0.018058137971116738\n","Training loss per 100 training steps: 0.018346009385626846\n","Training loss per 100 training steps: 0.018413488396405532\n","Training loss epoch: 0.018413488396405532\n","Training accuracy epoch: 0.9943097816291451\n","Validating model...\n","Validation Loss: 0.24168098906611468\n","Validation Accuracy: 0.9525720135508766\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 80.12252311666667 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1589900766277289\n","Validation Accuracy: 0.9516453556031017\n","Validation duration: 3.0174483500000253 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 83.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.85      0.84     12546\n","        test       0.82      0.85      0.83      9012\n","   treatment       0.82      0.86      0.84      9297\n","\n","   micro avg       0.83      0.85      0.84     30855\n","   macro avg       0.83      0.85      0.84     30855\n","weighted avg       0.83      0.85      0.84     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n","Points in X_train after augmentation: 41601\n","Points in y_train after augmentation: 41601\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0362625122070312\n","Training loss per 100 training steps: 0.37865265680126625\n","Training loss per 100 training steps: 0.28177319652405547\n","Training loss per 100 training steps: 0.24478300756146743\n","Training loss per 100 training steps: 0.21839448006038653\n","Training loss per 100 training steps: 0.20235018925127868\n","Training loss per 100 training steps: 0.18957168868620464\n","Training loss per 100 training steps: 0.18180722027443105\n","Training loss per 100 training steps: 0.1728729326696543\n","Training loss per 100 training steps: 0.1665044876867771\n","Training loss per 100 training steps: 0.16078101132031564\n","Training loss per 100 training steps: 0.15578211073363563\n","Training loss per 100 training steps: 0.151574041759541\n","Training loss per 100 training steps: 0.1470145445485613\n","Training loss epoch: 0.1470145445485613\n","Training accuracy epoch: 0.9539116718760928\n","Validating model...\n","Validation Loss: 0.16400545046894582\n","Validation Accuracy: 0.9491078183368958\n","Training epoch: 2\n","Training loss per 100 training steps: 0.055296096950769424\n","Training loss per 100 training steps: 0.06493947818174516\n","Training loss per 100 training steps: 0.060539782649619664\n","Training loss per 100 training steps: 0.060584119997572065\n","Training loss per 100 training steps: 0.05971092468318053\n","Training loss per 100 training steps: 0.058800444642673\n","Training loss per 100 training steps: 0.058863530821862714\n","Training loss per 100 training steps: 0.05857865402233201\n","Training loss per 100 training steps: 0.059476333945877986\n","Training loss per 100 training steps: 0.06008117515325017\n","Training loss per 100 training steps: 0.060055443758403625\n","Training loss per 100 training steps: 0.05929143914612827\n","Training loss per 100 training steps: 0.058642129094295704\n","Training loss per 100 training steps: 0.05810272034880799\n","Training loss epoch: 0.05810272034880799\n","Training accuracy epoch: 0.9817658379758177\n","Validating model...\n","Validation Loss: 0.16004774136492958\n","Validation Accuracy: 0.9558929057073849\n","Training epoch: 3\n","Training loss per 100 training steps: 0.06588339060544968\n","Training loss per 100 training steps: 0.028167694039403064\n","Training loss per 100 training steps: 0.03618939733364392\n","Training loss per 100 training steps: 0.03657823220279031\n","Training loss per 100 training steps: 0.03641212945414981\n","Training loss per 100 training steps: 0.035419711228525136\n","Training loss per 100 training steps: 0.03535156088207884\n","Training loss per 100 training steps: 0.034862060168427224\n","Training loss per 100 training steps: 0.03458416701911294\n","Training loss per 100 training steps: 0.03468394946613423\n","Training loss per 100 training steps: 0.034410081521540944\n","Training loss per 100 training steps: 0.03451252852358875\n","Training loss per 100 training steps: 0.03505399146361151\n","Training loss per 100 training steps: 0.035317343177528354\n","Training loss epoch: 0.035317343177528354\n","Training accuracy epoch: 0.9890819065396622\n","Validating model...\n","Validation Loss: 0.1651078685029567\n","Validation Accuracy: 0.9563981071432598\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01578129455447197\n","Training loss per 100 training steps: 0.02081923877260196\n","Training loss per 100 training steps: 0.019944066652797618\n","Training loss per 100 training steps: 0.0223332094810818\n","Training loss per 100 training steps: 0.02282933142226935\n","Training loss per 100 training steps: 0.02253745392550707\n","Training loss per 100 training steps: 0.02373846086462109\n","Training loss per 100 training steps: 0.025102099035934647\n","Training loss per 100 training steps: 0.025378701085558734\n","Training loss per 100 training steps: 0.024917907280555165\n","Training loss per 100 training steps: 0.025000340267500656\n","Training loss per 100 training steps: 0.025142154640833858\n","Training loss per 100 training steps: 0.025602834549412437\n","Training loss per 100 training steps: 0.025703260199411833\n","Training loss epoch: 0.025703260199411833\n","Training accuracy epoch: 0.9921026937938976\n","Validating model...\n","Validation Loss: 0.17834470254768217\n","Validation Accuracy: 0.9566639069799536\n","Training epoch: 5\n","Training loss per 100 training steps: 0.04802097752690315\n","Training loss per 100 training steps: 0.01657853167766871\n","Training loss per 100 training steps: 0.01827493483048345\n","Training loss per 100 training steps: 0.019753187769413632\n","Training loss per 100 training steps: 0.019710368830916772\n","Training loss per 100 training steps: 0.020841967496366152\n","Training loss per 100 training steps: 0.020379317373150848\n","Training loss per 100 training steps: 0.020099788321158548\n","Training loss per 100 training steps: 0.019791340950759333\n","Training loss per 100 training steps: 0.020329877044510697\n","Training loss per 100 training steps: 0.02012272574488175\n","Training loss per 100 training steps: 0.020717847866280475\n","Training loss per 100 training steps: 0.021001123219460356\n","Training loss per 100 training steps: 0.02080042311171593\n","Training loss epoch: 0.02080042311171593\n","Training accuracy epoch: 0.9937920151158273\n","Validating model...\n","Validation Loss: 0.19256331067677443\n","Validation Accuracy: 0.9563126434580109\n","Training epoch: 6\n","Training loss per 100 training steps: 0.010756448842585087\n","Training loss per 100 training steps: 0.015331265550005333\n","Training loss per 100 training steps: 0.01601435053185444\n","Training loss per 100 training steps: 0.017911178163141382\n","Training loss per 100 training steps: 0.017916298250753682\n","Training loss per 100 training steps: 0.01777532737295026\n","Training loss per 100 training steps: 0.017340841358713496\n","Training loss per 100 training steps: 0.01756843547393221\n","Training loss per 100 training steps: 0.017183105511586187\n","Training loss per 100 training steps: 0.01725532864312177\n","Training loss per 100 training steps: 0.017868416249188227\n","Training loss per 100 training steps: 0.017971849519540332\n","Training loss per 100 training steps: 0.01798290669871339\n","Training loss per 100 training steps: 0.01809134009353896\n","Training loss epoch: 0.01809134009353896\n","Training accuracy epoch: 0.9944959936077769\n","Validating model...\n","Validation Loss: 0.21022430096160283\n","Validation Accuracy: 0.9566950959254408\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0024376963265240192\n","Training loss per 100 training steps: 0.0130639339268143\n","Training loss per 100 training steps: 0.01402605285715145\n","Training loss per 100 training steps: 0.014488996934970265\n","Training loss per 100 training steps: 0.013985536262631635\n","Training loss per 100 training steps: 0.014139858301362523\n","Training loss per 100 training steps: 0.014083782248403343\n","Training loss per 100 training steps: 0.014624490968876561\n","Training loss per 100 training steps: 0.014490364230393848\n","Training loss per 100 training steps: 0.014493619248520486\n","Training loss per 100 training steps: 0.01490215127608196\n","Training loss per 100 training steps: 0.01535064296752879\n","Training loss per 100 training steps: 0.015410617899491245\n","Training loss per 100 training steps: 0.015566716002446057\n","Training loss epoch: 0.015566716002446057\n","Training accuracy epoch: 0.9953377365710809\n","Validating model...\n","Validation Loss: 0.19636520007988076\n","Validation Accuracy: 0.9585142913267156\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 93.43372753333333 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.17795622726057278\n","Validation Accuracy: 0.9520357799827548\n","Validation duration: 3.018986983333343 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 83.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.78      0.88      0.82     12546\n","        test       0.81      0.86      0.84      9012\n","   treatment       0.82      0.86      0.84      9297\n","\n","   micro avg       0.80      0.87      0.83     30855\n","   macro avg       0.80      0.87      0.83     30855\n","weighted avg       0.80      0.87      0.83     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n","Points in X_train after augmentation: 41601\n","Points in y_train after augmentation: 41601\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7650362253189087\n","Training loss per 100 training steps: 0.39012951337464963\n","Training loss per 100 training steps: 0.29563514880873076\n","Training loss per 100 training steps: 0.25080321356654167\n","Training loss per 100 training steps: 0.22710479838666772\n","Training loss per 100 training steps: 0.20957486677223336\n","Training loss per 100 training steps: 0.1974365580331119\n","Training loss per 100 training steps: 0.18543811738570773\n","Training loss per 100 training steps: 0.17836275022272277\n","Training loss per 100 training steps: 0.1721958637901155\n","Training loss per 100 training steps: 0.16646586147255146\n","Training loss per 100 training steps: 0.16067360351784163\n","Training loss per 100 training steps: 0.15602263498300692\n","Training loss per 100 training steps: 0.15156217860265547\n","Training loss epoch: 0.15156217860265547\n","Training accuracy epoch: 0.9526400303237055\n","Validating model...\n","Validation Loss: 0.1455045211818311\n","Validation Accuracy: 0.9558395029158085\n","Training epoch: 2\n","Training loss per 100 training steps: 0.043521951884031296\n","Training loss per 100 training steps: 0.06573369827047729\n","Training loss per 100 training steps: 0.0631435229373512\n","Training loss per 100 training steps: 0.061140357696163494\n","Training loss per 100 training steps: 0.06270357816157272\n","Training loss per 100 training steps: 0.062282855545324894\n","Training loss per 100 training steps: 0.06340213746108275\n","Training loss per 100 training steps: 0.062135418604318045\n","Training loss per 100 training steps: 0.06213074846317603\n","Training loss per 100 training steps: 0.06202046445841704\n","Training loss per 100 training steps: 0.06219923525483912\n","Training loss per 100 training steps: 0.06161282402057231\n","Stopping epoch...\n","Training loss epoch: 0.06161282402057231\n","Training accuracy epoch: 0.9797298925797999\n","Validating model...\n","Validation Loss: 0.16308027406694828\n","Validation Accuracy: 0.9550948233349918\n","Training epoch: 3\n","Training loss per 100 training steps: 0.18662121891975403\n","Training loss per 100 training steps: 0.036951690053539626\n","Training loss per 100 training steps: 0.04106364659536445\n","Training loss per 100 training steps: 0.041706589828369105\n","Training loss per 100 training steps: 0.043148858068299545\n","Training loss per 100 training steps: 0.043304690966399356\n","Training loss per 100 training steps: 0.0444157489584356\n","Training loss per 100 training steps: 0.04396989687758441\n","Training loss per 100 training steps: 0.04405014960315618\n","Training loss per 100 training steps: 0.0433246189464539\n","Training loss per 100 training steps: 0.042906615641558885\n","Training loss per 100 training steps: 0.042335514488103854\n","Training loss per 100 training steps: 0.042308198105560135\n","Training loss per 100 training steps: 0.041775327550693284\n","Training loss epoch: 0.041775327550693284\n","Training accuracy epoch: 0.9870446322681561\n","Validating model...\n","Validation Loss: 0.171622428849533\n","Validation Accuracy: 0.957360302119377\n","Training epoch: 4\n","Training loss per 100 training steps: 0.04760143533349037\n","Training loss per 100 training steps: 0.023376168108010426\n","Training loss per 100 training steps: 0.022831985841919922\n","Training loss per 100 training steps: 0.024296958918800807\n","Training loss per 100 training steps: 0.0255765023384652\n","Training loss per 100 training steps: 0.026062821831829296\n","Training loss per 100 training steps: 0.025150798134677757\n","Training loss per 100 training steps: 0.025175463941732763\n","Training loss per 100 training steps: 0.026121121431414863\n","Training loss per 100 training steps: 0.026701313243275994\n","Training loss per 100 training steps: 0.026904208759777712\n","Training loss per 100 training steps: 0.027293912823141538\n","Training loss per 100 training steps: 0.0278548299077395\n","Training loss per 100 training steps: 0.028398523279467524\n","Training loss epoch: 0.028398523279467524\n","Training accuracy epoch: 0.9911374518117401\n","Validating model...\n","Validation Loss: 0.174719044999159\n","Validation Accuracy: 0.9568402587840921\n","Training epoch: 5\n","Training loss per 100 training steps: 0.003168358700349927\n","Training loss per 100 training steps: 0.016132811882007537\n","Training loss per 100 training steps: 0.015541413883199054\n","Training loss per 100 training steps: 0.01679544767695154\n","Training loss per 100 training steps: 0.017235018515133732\n","Training loss per 100 training steps: 0.01681111830144009\n","Training loss per 100 training steps: 0.017490921797058058\n","Training loss per 100 training steps: 0.02020520342757378\n","Training loss per 100 training steps: 0.020178826085434816\n","Training loss per 100 training steps: 0.020994542139457263\n","Training loss per 100 training steps: 0.021507178847031384\n","Training loss per 100 training steps: 0.022049634308100835\n","Training loss per 100 training steps: 0.02207577907971551\n","Training loss per 100 training steps: 0.02255208181980768\n","Training loss epoch: 0.02255208181980768\n","Training accuracy epoch: 0.9931616100289504\n","Validating model...\n","Validation Loss: 0.17374463439858578\n","Validation Accuracy: 0.9608121193936888\n","Training epoch: 6\n","Training loss per 100 training steps: 0.022637832909822464\n","Training loss per 100 training steps: 0.01750351667477943\n","Training loss per 100 training steps: 0.019700085973906892\n","Training loss per 100 training steps: 0.019746190304612662\n","Training loss per 100 training steps: 0.020160998479478255\n","Training loss per 100 training steps: 0.019350529994356432\n","Training loss per 100 training steps: 0.01939762081629744\n","Training loss per 100 training steps: 0.01938258152720472\n","Training loss per 100 training steps: 0.019390851197681143\n","Training loss per 100 training steps: 0.01942658851916264\n","Stopping epoch...\n","Training loss epoch: 0.01942658851916264\n","Training accuracy epoch: 0.9929185550248556\n","Validating model...\n","Validation Loss: 0.1957086364121793\n","Validation Accuracy: 0.9572228439705552\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 76.1655163666667 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15868182318808977\n","Validation Accuracy: 0.9533974229862484\n","Validation duration: 3.08949886666663 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 83.3%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.84      0.83     12546\n","        test       0.79      0.88      0.84      9012\n","   treatment       0.83      0.84      0.84      9297\n","\n","   micro avg       0.82      0.85      0.83     30855\n","   macro avg       0.82      0.85      0.83     30855\n","weighted avg       0.82      0.85      0.83     30855\n","\n","!!!!!! Starting model number 7 !!!!!!\n","Points in X_train after augmentation: 41601\n","Points in y_train after augmentation: 41601\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7099825143814087\n","Training loss per 100 training steps: 0.38705183086123796\n","Training loss per 100 training steps: 0.29790394599387304\n","Training loss per 100 training steps: 0.25428212315240173\n","Training loss per 100 training steps: 0.22640339157862258\n","Training loss per 100 training steps: 0.20911690332887772\n","Training loss per 100 training steps: 0.19628099767110013\n","Training loss per 100 training steps: 0.18530594281979787\n","Training loss per 100 training steps: 0.1779104272036182\n","Training loss per 100 training steps: 0.17066256360633592\n","Training loss per 100 training steps: 0.16508924840139105\n","Training loss per 100 training steps: 0.15984914244848772\n","Training loss per 100 training steps: 0.15503002569423702\n","Training loss per 100 training steps: 0.15045752057947576\n","Training loss epoch: 0.15045752057947576\n","Training accuracy epoch: 0.9533331531506418\n","Validating model...\n","Validation Loss: 0.15123731993719355\n","Validation Accuracy: 0.955687462093217\n","Training epoch: 2\n","Training loss per 100 training steps: 0.08709029853343964\n","Training loss per 100 training steps: 0.06054918610924246\n","Training loss per 100 training steps: 0.05971180958979165\n","Training loss per 100 training steps: 0.06280661661307825\n","Training loss per 100 training steps: 0.06137515998740409\n","Training loss per 100 training steps: 0.062106217338541846\n","Training loss per 100 training steps: 0.061513585265502706\n","Training loss per 100 training steps: 0.06140718510714539\n","Training loss per 100 training steps: 0.06061682053963734\n","Training loss per 100 training steps: 0.0601145210805102\n","Training loss per 100 training steps: 0.060213964237328194\n","Training loss per 100 training steps: 0.060318909865676285\n","Training loss per 100 training steps: 0.06052565168752975\n","Stopping epoch...\n","Training loss epoch: 0.06052565168752975\n","Training accuracy epoch: 0.9802203782260474\n","Validating model...\n","Validation Loss: 0.1468948959917217\n","Validation Accuracy: 0.9562990048014195\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02140749990940094\n","Training loss per 100 training steps: 0.040898056719267724\n","Training loss per 100 training steps: 0.03899471640623921\n","Training loss per 100 training steps: 0.03887428096928742\n","Training loss per 100 training steps: 0.03804077659536181\n","Training loss per 100 training steps: 0.03743177751068048\n","Training loss per 100 training steps: 0.03715580432968657\n","Training loss per 100 training steps: 0.03718159194522871\n","Training loss per 100 training steps: 0.03713068378113731\n","Training loss per 100 training steps: 0.03676297880148931\n","Training loss per 100 training steps: 0.037178484594577794\n","Training loss per 100 training steps: 0.03774805426395428\n","Training loss per 100 training steps: 0.03801984438803714\n","Training loss per 100 training steps: 0.03810551763708338\n","Training loss epoch: 0.03810551763708338\n","Training accuracy epoch: 0.9883588983850473\n","Validating model...\n","Validation Loss: 0.17900161324189856\n","Validation Accuracy: 0.9569556805346149\n","Training epoch: 4\n","Training loss per 100 training steps: 0.030446656048297882\n","Training loss per 100 training steps: 0.026961850776397022\n","Training loss per 100 training steps: 0.025489117996825083\n","Training loss per 100 training steps: 0.024490864403070915\n","Training loss per 100 training steps: 0.024363628410510114\n","Training loss per 100 training steps: 0.02411643124778965\n","Training loss per 100 training steps: 0.0244731338139346\n","Training loss per 100 training steps: 0.02468407818622098\n","Training loss per 100 training steps: 0.02539050427186111\n","Training loss per 100 training steps: 0.026013130484317862\n","Training loss per 100 training steps: 0.02665339760824463\n","Training loss per 100 training steps: 0.027090823903946726\n","Training loss per 100 training steps: 0.02697689616276249\n","Training loss per 100 training steps: 0.027222939087690027\n","Training loss epoch: 0.027222939087690027\n","Training accuracy epoch: 0.9916038365899693\n","Validating model...\n","Validation Loss: 0.1829701422338749\n","Validation Accuracy: 0.9576622406829816\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0039046553429216146\n","Training loss per 100 training steps: 0.018149721571636194\n","Training loss per 100 training steps: 0.019922242917042848\n","Training loss per 100 training steps: 0.01837856427455426\n","Training loss per 100 training steps: 0.020094122975992685\n","Training loss per 100 training steps: 0.019766937635983983\n","Training loss per 100 training steps: 0.020965140750290774\n","Training loss per 100 training steps: 0.021163477400615385\n","Training loss per 100 training steps: 0.021626815774407383\n","Training loss per 100 training steps: 0.021408559117856673\n","Training loss per 100 training steps: 0.021647919331751458\n","Training loss per 100 training steps: 0.02174074124121598\n","Training loss per 100 training steps: 0.021738807293537\n","Training loss per 100 training steps: 0.02207965252211487\n","Training loss epoch: 0.02207965252211487\n","Training accuracy epoch: 0.9932818538758132\n","Validating model...\n","Validation Loss: 0.18424794402021866\n","Validation Accuracy: 0.9581299261286175\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0020524465944617987\n","Training loss per 100 training steps: 0.015379782672740962\n","Training loss per 100 training steps: 0.018605395971562258\n","Training loss per 100 training steps: 0.019050778014422162\n","Training loss per 100 training steps: 0.017481372604306853\n","Training loss per 100 training steps: 0.01774702114069336\n","Training loss per 100 training steps: 0.01778843563242572\n","Training loss per 100 training steps: 0.017898240518429386\n","Training loss per 100 training steps: 0.01791113936195508\n","Training loss per 100 training steps: 0.018711373915616215\n","Training loss per 100 training steps: 0.018555903980509842\n","Training loss per 100 training steps: 0.01874237571652432\n","Training loss per 100 training steps: 0.018728148427954353\n","Training loss per 100 training steps: 0.01863231098183869\n","Stopping epoch...\n","Training loss epoch: 0.01863231098183869\n","Training accuracy epoch: 0.9937087507958555\n","Validating model...\n","Validation Loss: 0.2162886984138326\n","Validation Accuracy: 0.9580474611426851\n","Training epoch: 7\n","Training loss per 100 training steps: 0.034712325781583786\n","Training loss per 100 training steps: 0.014786754496796702\n","Training loss per 100 training steps: 0.015789440633214788\n","Training loss per 100 training steps: 0.015842903913246262\n","Training loss per 100 training steps: 0.01560457831203933\n","Training loss per 100 training steps: 0.016127053305609877\n","Training loss per 100 training steps: 0.016880173970458597\n","Training loss per 100 training steps: 0.017180873898610928\n","Training loss per 100 training steps: 0.017669283741288358\n","Training loss per 100 training steps: 0.01800036429774226\n","Training loss per 100 training steps: 0.017818383499334515\n","Training loss per 100 training steps: 0.017920949068970404\n","Training loss per 100 training steps: 0.018159742463300807\n","Training loss per 100 training steps: 0.018227300374597945\n","Training loss epoch: 0.018227300374597945\n","Training accuracy epoch: 0.9946733855532857\n","Validating model...\n","Validation Loss: 0.21678255124065976\n","Validation Accuracy: 0.9568041242661773\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 93.22337700000001 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1639969109490738\n","Validation Accuracy: 0.952997733659435\n","Validation duration: 3.0483469333333537 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 83.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.86      0.83     12546\n","        test       0.83      0.85      0.84      9012\n","   treatment       0.81      0.86      0.84      9297\n","\n","   micro avg       0.81      0.86      0.83     30855\n","   macro avg       0.81      0.86      0.83     30855\n","weighted avg       0.81      0.86      0.83     30855\n","\n","!!!!!! Starting model number 8 !!!!!!\n","Points in X_train after augmentation: 41601\n","Points in y_train after augmentation: 41601\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8796814680099487\n","Training loss per 100 training steps: 0.3753049540342671\n","Training loss per 100 training steps: 0.2819372369208146\n","Training loss per 100 training steps: 0.24627463952746503\n","Training loss per 100 training steps: 0.22236292728424964\n","Training loss per 100 training steps: 0.2044330209701837\n","Training loss per 100 training steps: 0.19268414660197328\n","Training loss per 100 training steps: 0.18201892895786126\n","Training loss per 100 training steps: 0.17344480032768664\n","Training loss per 100 training steps: 0.1669551840756961\n","Training loss per 100 training steps: 0.1618677316481\n","Training loss per 100 training steps: 0.15843517687188616\n","Training loss per 100 training steps: 0.15382358500521498\n","Training loss per 100 training steps: 0.14921612727551004\n","Training loss epoch: 0.14921612727551004\n","Training accuracy epoch: 0.9529395406931035\n","Validating model...\n","Validation Loss: 0.14825875549153847\n","Validation Accuracy: 0.9544873702059586\n","Training epoch: 2\n","Training loss per 100 training steps: 0.03552538901567459\n","Training loss per 100 training steps: 0.0586397781516287\n","Training loss per 100 training steps: 0.06065172182433122\n","Training loss per 100 training steps: 0.06198917487883736\n","Training loss per 100 training steps: 0.06030786337860467\n","Training loss per 100 training steps: 0.05914185858961797\n","Training loss per 100 training steps: 0.06044614678729146\n","Training loss per 100 training steps: 0.05992781498154543\n","Training loss per 100 training steps: 0.05934476224675347\n","Training loss per 100 training steps: 0.059061128030077334\n","Training loss per 100 training steps: 0.05844611708878667\n","Training loss per 100 training steps: 0.05828597799720045\n","Training loss per 100 training steps: 0.05874584177524459\n","Training loss per 100 training steps: 0.058607378278055955\n","Training loss epoch: 0.058607378278055955\n","Training accuracy epoch: 0.981233745154563\n","Validating model...\n","Validation Loss: 0.16443271862415523\n","Validation Accuracy: 0.9527557965817895\n","Training epoch: 3\n","Training loss per 100 training steps: 0.013555963523685932\n","Training loss per 100 training steps: 0.034704207578710844\n","Training loss per 100 training steps: 0.03471553912536885\n","Training loss per 100 training steps: 0.03418597889649511\n","Training loss per 100 training steps: 0.03336752708705184\n","Training loss per 100 training steps: 0.03295260175812558\n","Training loss per 100 training steps: 0.03365385502064678\n","Training loss per 100 training steps: 0.03438832307285556\n","Training loss per 100 training steps: 0.034267380183095233\n","Training loss per 100 training steps: 0.034383694972319905\n","Training loss per 100 training steps: 0.035127510479255976\n","Training loss per 100 training steps: 0.035661915866159015\n","Training loss per 100 training steps: 0.035714783686966164\n","Training loss per 100 training steps: 0.03640814751809353\n","Training loss epoch: 0.03640814751809353\n","Training accuracy epoch: 0.9885637402036467\n","Validating model...\n","Validation Loss: 0.15968735834777162\n","Validation Accuracy: 0.9581539336802861\n","Training epoch: 4\n","Training loss per 100 training steps: 0.006967324297875166\n","Training loss per 100 training steps: 0.0232523196575112\n","Training loss per 100 training steps: 0.02267500365312809\n","Training loss per 100 training steps: 0.02119581141250759\n","Training loss per 100 training steps: 0.021971644869973033\n","Training loss per 100 training steps: 0.02462795332093684\n","Training loss per 100 training steps: 0.02550916439995399\n","Training loss per 100 training steps: 0.02529422558007759\n","Training loss per 100 training steps: 0.02573872350151075\n","Training loss per 100 training steps: 0.026420398461286156\n","Training loss per 100 training steps: 0.02604226589608299\n","Training loss per 100 training steps: 0.026114718359990213\n","Training loss per 100 training steps: 0.02631983485244033\n","Training loss per 100 training steps: 0.026214876787002683\n","Training loss epoch: 0.026214876787002683\n","Training accuracy epoch: 0.9921246346225048\n","Validating model...\n","Validation Loss: 0.18586086535028049\n","Validation Accuracy: 0.9591454323404589\n","Training epoch: 5\n","Training loss per 100 training steps: 0.06327681988477707\n","Training loss per 100 training steps: 0.014411482542734777\n","Training loss per 100 training steps: 0.01550614459536256\n","Training loss per 100 training steps: 0.01764688589064825\n","Training loss per 100 training steps: 0.018027643266829554\n","Training loss per 100 training steps: 0.02016972153000961\n","Training loss per 100 training steps: 0.020319879195554502\n","Training loss per 100 training steps: 0.021746290097768402\n","Training loss per 100 training steps: 0.02127723388237816\n","Training loss per 100 training steps: 0.022314200696424806\n","Training loss per 100 training steps: 0.02286881860485161\n","Training loss per 100 training steps: 0.0226971653267254\n","Training loss per 100 training steps: 0.022872960965312338\n","Training loss per 100 training steps: 0.022955992363621842\n","Training loss epoch: 0.022955992363621842\n","Training accuracy epoch: 0.9930352143283577\n","Validating model...\n","Validation Loss: 0.21149136940041532\n","Validation Accuracy: 0.9552683042631424\n","Training epoch: 6\n","Training loss per 100 training steps: 0.03745798021554947\n","Training loss per 100 training steps: 0.015071314131370792\n","Training loss per 100 training steps: 0.015509536244416498\n","Training loss per 100 training steps: 0.015266581898244976\n","Training loss per 100 training steps: 0.016212184956059802\n","Training loss per 100 training steps: 0.01678854553371681\n","Training loss per 100 training steps: 0.017025408195709413\n","Training loss per 100 training steps: 0.017551829086222385\n","Training loss per 100 training steps: 0.0175695466362716\n","Training loss per 100 training steps: 0.01753089692405881\n","Training loss per 100 training steps: 0.01832097327318294\n","Training loss per 100 training steps: 0.018575104714304017\n","Training loss per 100 training steps: 0.018946474492390928\n","Training loss per 100 training steps: 0.01894027890062957\n","Training loss epoch: 0.01894027890062957\n","Training accuracy epoch: 0.9942467227395557\n","Validating model...\n","Validation Loss: 0.2118515320751187\n","Validation Accuracy: 0.9555042870748435\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 80.13354291666668 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.16338701398086009\n","Validation Accuracy: 0.9504317654080873\n","Validation duration: 3.0236391833333376 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 83.1%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.84      0.83     12546\n","        test       0.78      0.88      0.83      9012\n","   treatment       0.82      0.85      0.84      9297\n","\n","   micro avg       0.81      0.86      0.83     30855\n","   macro avg       0.81      0.86      0.83     30855\n","weighted avg       0.81      0.86      0.83     30855\n","\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TTDq-xbgHqXQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d8a2647b-95f2-4808-b317-95dc17716e74"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 500% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 83202\n","Points in y_train after augmentation: 83202\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.2063629627227783\n","Training loss per 100 training steps: 0.37625131018386027\n","Training loss per 100 training steps: 0.28920307799951356\n","Training loss per 100 training steps: 0.24716964123950053\n","Training loss per 100 training steps: 0.2239173087674632\n","Training loss per 100 training steps: 0.2063446414327907\n","Training loss per 100 training steps: 0.19096778461185845\n","Training loss per 100 training steps: 0.17911007190747624\n","Training loss per 100 training steps: 0.1700042739566346\n","Training loss per 100 training steps: 0.163561316231859\n","Training loss per 100 training steps: 0.15780220775828732\n","Training loss per 100 training steps: 0.15232470261185116\n","Training loss per 100 training steps: 0.14770530949856195\n","Training loss per 100 training steps: 0.14306238603969315\n","Training loss per 100 training steps: 0.13962953406413334\n","Training loss per 100 training steps: 0.13591156227031423\n","Training loss per 100 training steps: 0.13227368914507687\n","Training loss per 100 training steps: 0.1295688053054285\n","Training loss per 100 training steps: 0.1267137182261102\n","Training loss per 100 training steps: 0.12392517876885302\n","Training loss per 100 training steps: 0.121411159817969\n","Training loss per 100 training steps: 0.11916868376817336\n","Training loss per 100 training steps: 0.11679542535194101\n","Training loss per 100 training steps: 0.11471920235382829\n","Training loss per 100 training steps: 0.11258443349721015\n","Training loss per 100 training steps: 0.11066168180170853\n","Training loss per 100 training steps: 0.10898419079673002\n","Training loss epoch: 0.10898419079673002\n","Training accuracy epoch: 0.9659722128920585\n","Validating model...\n","Validation Loss: 0.15354158956702654\n","Validation Accuracy: 0.9546353709907421\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05078154057264328\n","Training loss per 100 training steps: 0.03894779569985769\n","Training loss per 100 training steps: 0.04072236182371998\n","Training loss per 100 training steps: 0.04004696180790267\n","Training loss per 100 training steps: 0.04271663497771111\n","Training loss per 100 training steps: 0.04477591690014371\n","Training loss per 100 training steps: 0.04476665612852539\n","Training loss per 100 training steps: 0.0447685306558994\n","Training loss per 100 training steps: 0.044909648559162026\n","Training loss per 100 training steps: 0.04485082565641421\n","Stopping epoch...\n","Training loss epoch: 0.04485082565641421\n","Training accuracy epoch: 0.985280431512108\n","Validating model...\n","Validation Loss: 0.20767955690041764\n","Validation Accuracy: 0.9510791277196311\n","Training epoch: 3\n","Training loss per 100 training steps: 0.01918870396912098\n","Training loss per 100 training steps: 0.033163939381368676\n","Training loss per 100 training steps: 0.03251678371554083\n","Training loss per 100 training steps: 0.034393090374560474\n","Training loss per 100 training steps: 0.03645780664506343\n","Training loss per 100 training steps: 0.03612611699127174\n","Training loss per 100 training steps: 0.036484967559047614\n","Training loss per 100 training steps: 0.03666850529493533\n","Training loss per 100 training steps: 0.03730408550015117\n","Training loss per 100 training steps: 0.03876508285018091\n","Training loss per 100 training steps: 0.03884544808438027\n","Training loss per 100 training steps: 0.03856234663660104\n","Training loss per 100 training steps: 0.038640100588024806\n","Training loss per 100 training steps: 0.03877581771356494\n","Stopping epoch...\n","Training loss epoch: 0.03877581771356494\n","Training accuracy epoch: 0.9871680770467027\n","Validating model...\n","Validation Loss: 0.1936390781170362\n","Validation Accuracy: 0.9515017786349812\n","Training epoch: 4\n","Training loss per 100 training steps: 0.030959291383624077\n","Training loss per 100 training steps: 0.03318005429792891\n","Training loss per 100 training steps: 0.029466332089033126\n","Training loss per 100 training steps: 0.02950511038503718\n","Training loss per 100 training steps: 0.030109967675699883\n","Training loss per 100 training steps: 0.029958630887258933\n","Training loss per 100 training steps: 0.029964659958473482\n","Training loss per 100 training steps: 0.029527045951454705\n","Training loss per 100 training steps: 0.02932718134463094\n","Training loss per 100 training steps: 0.02970701868678924\n","Training loss per 100 training steps: 0.029071425199280722\n","Training loss per 100 training steps: 0.029252504470160097\n","Training loss per 100 training steps: 0.02930452573876192\n","Training loss per 100 training steps: 0.029027822350587075\n","Training loss per 100 training steps: 0.029631049119731773\n","Training loss per 100 training steps: 0.02981187298296418\n","Training loss per 100 training steps: 0.029944634204643134\n","Training loss per 100 training steps: 0.029991741575791268\n","Training loss per 100 training steps: 0.030450701910582502\n","Training loss per 100 training steps: 0.030646448113699824\n","Training loss per 100 training steps: 0.030829045242329278\n","Training loss per 100 training steps: 0.030868051934571514\n","Training loss per 100 training steps: 0.030920514960568916\n","Training loss per 100 training steps: 0.03060651948389762\n","Training loss per 100 training steps: 0.030742341383899106\n","Training loss per 100 training steps: 0.030742448088048293\n","Training loss per 100 training steps: 0.030573499620117035\n","Training loss epoch: 0.030573499620117035\n","Training accuracy epoch: 0.9907051804311174\n","Validating model...\n","Validation Loss: 0.1976551107771985\n","Validation Accuracy: 0.9537188059324845\n","Training epoch: 5\n","Training loss per 100 training steps: 0.02813948690891266\n","Training loss per 100 training steps: 0.017126211116786604\n","Training loss per 100 training steps: 0.021161139708427035\n","Training loss per 100 training steps: 0.020488328400394412\n","Training loss per 100 training steps: 0.019595804247869286\n","Training loss per 100 training steps: 0.01983872526676158\n","Training loss per 100 training steps: 0.01993677920257803\n","Training loss per 100 training steps: 0.0206287186939074\n","Training loss per 100 training steps: 0.021277246326027895\n","Training loss per 100 training steps: 0.02066184281509527\n","Training loss per 100 training steps: 0.020968361468460005\n","Training loss per 100 training steps: 0.02088242887840103\n","Training loss per 100 training steps: 0.021218962827668317\n","Training loss per 100 training steps: 0.020867404598652526\n","Training loss per 100 training steps: 0.020943732287978713\n","Training loss per 100 training steps: 0.020673737644963556\n","Training loss per 100 training steps: 0.02070848272921332\n","Training loss per 100 training steps: 0.020624339724412497\n","Training loss per 100 training steps: 0.020640692207978435\n","Training loss per 100 training steps: 0.020624763324545298\n","Stopping epoch...\n","Training loss epoch: 0.020624763324545298\n","Training accuracy epoch: 0.9933076038786913\n","Validating model...\n","Validation Loss: 0.2417589584365487\n","Validation Accuracy: 0.9508142157065678\n","Training epoch: 6\n","Training loss per 100 training steps: 0.008169666863977909\n","Training loss per 100 training steps: 0.017562865380469785\n","Training loss per 100 training steps: 0.015965821254194542\n","Training loss per 100 training steps: 0.01592555207900774\n","Training loss per 100 training steps: 0.01688275778190897\n","Training loss per 100 training steps: 0.017461615175479547\n","Training loss per 100 training steps: 0.017959217508619854\n","Training loss per 100 training steps: 0.01777511423480426\n","Training loss per 100 training steps: 0.018540457873068895\n","Training loss per 100 training steps: 0.018550390726079148\n","Training loss per 100 training steps: 0.018053452759298712\n","Training loss per 100 training steps: 0.017757253506077923\n","Training loss per 100 training steps: 0.01821328713261033\n","Training loss per 100 training steps: 0.018540662921437898\n","Training loss per 100 training steps: 0.019336637680086078\n","Training loss per 100 training steps: 0.01966247550941052\n","Training loss per 100 training steps: 0.01996486238338464\n","Training loss per 100 training steps: 0.020185257813301667\n","Training loss per 100 training steps: 0.020324923068320927\n","Training loss per 100 training steps: 0.020390664252797574\n","Training loss per 100 training steps: 0.02040514784707359\n","Training loss per 100 training steps: 0.020437063238172255\n","Training loss per 100 training steps: 0.020510081526191704\n","Stopping epoch...\n","Training loss epoch: 0.020510081526191704\n","Training accuracy epoch: 0.9932514883339073\n","Validating model...\n","Validation Loss: 0.21451271669455357\n","Validation Accuracy: 0.9555671823116066\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 125.1286032 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1772441737379672\n","Validation Accuracy: 0.9482306787775909\n","Validation duration: 3.1265578500000024 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 81.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.84      0.83     12548\n","        test       0.79      0.79      0.79      9012\n","   treatment       0.78      0.86      0.82      9301\n","\n","   micro avg       0.80      0.83      0.82     30861\n","   macro avg       0.80      0.83      0.81     30861\n","weighted avg       0.80      0.83      0.82     30861\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 83202\n","Points in y_train after augmentation: 83202\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1272826194763184\n","Training loss per 100 training steps: 0.38319502918436976\n","Training loss per 100 training steps: 0.2877727269162586\n","Training loss per 100 training steps: 0.24166450496651604\n","Training loss per 100 training steps: 0.2160369236245194\n","Training loss per 100 training steps: 0.199152286690539\n","Training loss per 100 training steps: 0.18694712466152755\n","Training loss per 100 training steps: 0.17654593491504306\n","Training loss per 100 training steps: 0.17036808497120118\n","Training loss per 100 training steps: 0.16365171218607225\n","Training loss per 100 training steps: 0.15734754392893968\n","Training loss per 100 training steps: 0.151360542521889\n","Training loss per 100 training steps: 0.14633185615829758\n","Training loss per 100 training steps: 0.14144574000724203\n","Training loss per 100 training steps: 0.1374761661123099\n","Training loss per 100 training steps: 0.13423227986660868\n","Training loss per 100 training steps: 0.13080067678542573\n","Training loss per 100 training steps: 0.12785025250778775\n","Training loss per 100 training steps: 0.12572117218425055\n","Training loss per 100 training steps: 0.12302706917250104\n","Training loss per 100 training steps: 0.12076248537990145\n","Training loss per 100 training steps: 0.1185590679680167\n","Training loss per 100 training steps: 0.11627414373906057\n","Training loss per 100 training steps: 0.11386973131427792\n","Training loss per 100 training steps: 0.11223761453896432\n","Training loss per 100 training steps: 0.11039732205143414\n","Training loss per 100 training steps: 0.10869646933986399\n","Training loss epoch: 0.10869646933986399\n","Training accuracy epoch: 0.9662712229214578\n","Validating model...\n","Validation Loss: 0.1593948540023782\n","Validation Accuracy: 0.9512499341892892\n","Training epoch: 2\n","Training loss per 100 training steps: 0.025584198534488678\n","Training loss per 100 training steps: 0.0398243384073848\n","Training loss per 100 training steps: 0.04110063184967811\n","Training loss per 100 training steps: 0.04182535681782284\n","Training loss per 100 training steps: 0.04135615020401618\n","Training loss per 100 training steps: 0.04042448524033424\n","Training loss per 100 training steps: 0.04056882879757996\n","Training loss per 100 training steps: 0.040642811437655565\n","Training loss per 100 training steps: 0.04102105973041343\n","Training loss per 100 training steps: 0.04175973676967349\n","Training loss per 100 training steps: 0.04238963268637252\n","Training loss per 100 training steps: 0.04235526954585587\n","Training loss per 100 training steps: 0.04232658770082318\n","Training loss per 100 training steps: 0.04180543796600649\n","Training loss per 100 training steps: 0.041959611813073776\n","Training loss per 100 training steps: 0.04193097680053555\n","Training loss per 100 training steps: 0.042251692171182964\n","Training loss per 100 training steps: 0.04178544194928958\n","Training loss per 100 training steps: 0.041703181082151645\n","Training loss per 100 training steps: 0.04155089849340869\n","Training loss per 100 training steps: 0.041628685066076664\n","Training loss per 100 training steps: 0.041334678629878246\n","Training loss per 100 training steps: 0.04132056583698859\n","Stopping epoch...\n","Training loss epoch: 0.04132056583698859\n","Training accuracy epoch: 0.98673268508902\n","Validating model...\n","Validation Loss: 0.1778738731881241\n","Validation Accuracy: 0.9522581645567099\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04335784912109375\n","Training loss per 100 training steps: 0.024485969940191227\n","Training loss per 100 training steps: 0.023434697415225615\n","Training loss per 100 training steps: 0.023822335663647623\n","Training loss per 100 training steps: 0.023317505253950353\n","Training loss per 100 training steps: 0.024394688675618784\n","Training loss per 100 training steps: 0.025027186402155337\n","Training loss per 100 training steps: 0.024852977078155578\n","Training loss per 100 training steps: 0.02474033677489491\n","Training loss per 100 training steps: 0.024479510841196553\n","Training loss per 100 training steps: 0.02482799985087835\n","Training loss per 100 training steps: 0.02513620328062132\n","Training loss per 100 training steps: 0.025728600476845186\n","Training loss per 100 training steps: 0.026026827306916175\n","Training loss per 100 training steps: 0.02659460996783842\n","Training loss per 100 training steps: 0.027227010094339796\n","Training loss per 100 training steps: 0.0273673483021505\n","Training loss per 100 training steps: 0.027591050721785443\n","Training loss per 100 training steps: 0.027449419040598496\n","Training loss per 100 training steps: 0.027709059315897244\n","Training loss per 100 training steps: 0.027660204630195237\n","Training loss per 100 training steps: 0.027853416181049764\n","Training loss per 100 training steps: 0.02789827864459491\n","Training loss per 100 training steps: 0.027855875567734032\n","Stopping epoch...\n","Training loss epoch: 0.027855875567734032\n","Training accuracy epoch: 0.9911166369589883\n","Validating model...\n","Validation Loss: 0.17867414171916324\n","Validation Accuracy: 0.9565628063548502\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0036100971046835184\n","Training loss per 100 training steps: 0.01693251606833079\n","Training loss per 100 training steps: 0.017217612589028344\n","Training loss per 100 training steps: 0.016888457182964986\n","Training loss per 100 training steps: 0.018279215719689035\n","Training loss per 100 training steps: 0.018477253280900708\n","Training loss per 100 training steps: 0.018965095777189307\n","Training loss per 100 training steps: 0.019721041884145085\n","Training loss per 100 training steps: 0.019921183284836008\n","Training loss per 100 training steps: 0.019709080663319993\n","Training loss per 100 training steps: 0.020067277823959326\n","Training loss per 100 training steps: 0.020620734822204875\n","Training loss per 100 training steps: 0.020567298712880412\n","Training loss per 100 training steps: 0.02104725017773201\n","Training loss per 100 training steps: 0.021520955671309006\n","Training loss per 100 training steps: 0.02165986059103558\n","Training loss per 100 training steps: 0.021770467557990895\n","Training loss per 100 training steps: 0.021799130723258696\n","Training loss per 100 training steps: 0.02182362257002148\n","Training loss per 100 training steps: 0.0219033767582152\n","Training loss per 100 training steps: 0.02181837086762785\n","Stopping epoch...\n","Training loss epoch: 0.02181837086762785\n","Training accuracy epoch: 0.9928145899083438\n","Validating model...\n","Validation Loss: 0.20897072911649556\n","Validation Accuracy: 0.9556856856753152\n","Training epoch: 5\n","Training loss per 100 training steps: 0.004762568511068821\n","Training loss per 100 training steps: 0.015278579842409875\n","Training loss per 100 training steps: 0.016204017086767716\n","Training loss per 100 training steps: 0.017286898772482857\n","Training loss per 100 training steps: 0.016919135168877587\n","Training loss per 100 training steps: 0.01653461462378682\n","Training loss per 100 training steps: 0.016968492333734247\n","Training loss per 100 training steps: 0.01684557880634826\n","Training loss per 100 training steps: 0.016672992714357793\n","Training loss per 100 training steps: 0.0167651138140238\n","Training loss per 100 training steps: 0.01707627402793441\n","Training loss per 100 training steps: 0.017242635339999708\n","Training loss per 100 training steps: 0.01739194344834453\n","Training loss per 100 training steps: 0.018001910106632945\n","Training loss per 100 training steps: 0.017849329184000576\n","Training loss per 100 training steps: 0.017814318031756062\n","Training loss per 100 training steps: 0.01776743753825423\n","Training loss per 100 training steps: 0.017868951132031283\n","Training loss per 100 training steps: 0.01795355190608228\n","Training loss per 100 training steps: 0.018332842926771946\n","Training loss per 100 training steps: 0.018285003472972468\n","Training loss per 100 training steps: 0.018185144022672524\n","Training loss per 100 training steps: 0.01823830064946256\n","Training loss per 100 training steps: 0.018468314030928953\n","Training loss per 100 training steps: 0.018522531455543677\n","Training loss per 100 training steps: 0.018639633885217232\n","Training loss per 100 training steps: 0.018741792949660968\n","Training loss epoch: 0.018741792949660968\n","Training accuracy epoch: 0.9943238716991188\n","Validating model...\n","Validation Loss: 0.21961452578521007\n","Validation Accuracy: 0.9526937726436877\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0032066982239484787\n","Training loss per 100 training steps: 0.013641915237127647\n","Training loss per 100 training steps: 0.013632320031374276\n","Training loss per 100 training steps: 0.013512090463953191\n","Training loss per 100 training steps: 0.014096416806540292\n","Training loss per 100 training steps: 0.013609291468762065\n","Training loss per 100 training steps: 0.01346863873978281\n","Training loss per 100 training steps: 0.013490789867034973\n","Training loss per 100 training steps: 0.013459306088831833\n","Training loss per 100 training steps: 0.01357269961738426\n","Training loss per 100 training steps: 0.013594256005187466\n","Stopping epoch...\n","Training loss epoch: 0.013594256005187466\n","Training accuracy epoch: 0.9949011877063036\n","Validating model...\n","Validation Loss: 0.24852029013435367\n","Validation Accuracy: 0.9533745142030723\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 133.42241076666676 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1751249382699219\n","Validation Accuracy: 0.9480330148765682\n","Validation duration: 3.0897444166666292 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 82.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.78      0.86      0.82     12546\n","        test       0.80      0.86      0.83      9012\n","   treatment       0.81      0.85      0.83      9297\n","\n","   micro avg       0.79      0.86      0.82     30855\n","   macro avg       0.80      0.86      0.83     30855\n","weighted avg       0.79      0.86      0.82     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 83202\n","Points in y_train after augmentation: 83202\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9705694913864136\n","Training loss per 100 training steps: 0.41399133286558754\n","Training loss per 100 training steps: 0.29720505834811956\n","Training loss per 100 training steps: 0.25287122445249083\n","Training loss per 100 training steps: 0.22513829739276608\n","Training loss per 100 training steps: 0.2061699655449795\n","Training loss per 100 training steps: 0.1937076566235694\n","Training loss per 100 training steps: 0.18355035747583429\n","Training loss per 100 training steps: 0.17457987280671813\n","Training loss per 100 training steps: 0.16724851328495074\n","Training loss per 100 training steps: 0.1617290272594213\n","Training loss per 100 training steps: 0.15605288843280019\n","Training loss per 100 training steps: 0.15200408343551408\n","Training loss per 100 training steps: 0.14748955821957752\n","Training loss per 100 training steps: 0.1438380074358248\n","Training loss per 100 training steps: 0.13937913837081328\n","Training loss per 100 training steps: 0.13628172817850004\n","Training loss per 100 training steps: 0.13316251353022895\n","Training loss per 100 training steps: 0.13037189164730012\n","Training loss per 100 training steps: 0.12771501026259854\n","Training loss per 100 training steps: 0.12529436346219813\n","Training loss per 100 training steps: 0.12275892611316404\n","Training loss per 100 training steps: 0.12035949947016279\n","Training loss per 100 training steps: 0.1182310081326663\n","Training loss per 100 training steps: 0.11639657180899074\n","Training loss per 100 training steps: 0.1144829192796483\n","Training loss per 100 training steps: 0.11266425752351941\n","Training loss epoch: 0.11266425752351941\n","Training accuracy epoch: 0.9647687648181396\n","Validating model...\n","Validation Loss: 0.1704964331508457\n","Validation Accuracy: 0.9492032215995577\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05926216021180153\n","Training loss per 100 training steps: 0.03872821186576961\n","Training loss per 100 training steps: 0.040299173270755294\n","Training loss per 100 training steps: 0.041516080630967934\n","Training loss per 100 training steps: 0.04135053417618686\n","Training loss per 100 training steps: 0.04155830078885636\n","Training loss per 100 training steps: 0.04144294904804511\n","Training loss per 100 training steps: 0.04087220356263587\n","Training loss per 100 training steps: 0.04157215032186452\n","Training loss per 100 training steps: 0.04164185381965292\n","Training loss per 100 training steps: 0.041863244225189174\n","Training loss per 100 training steps: 0.04196825710733884\n","Training loss per 100 training steps: 0.04152409018583047\n","Training loss per 100 training steps: 0.04162744945801041\n","Training loss per 100 training steps: 0.04225042722609059\n","Training loss per 100 training steps: 0.04258241420582267\n","Training loss per 100 training steps: 0.042760144419465525\n","Training loss per 100 training steps: 0.04264990096106394\n","Training loss per 100 training steps: 0.04271722440946556\n","Training loss per 100 training steps: 0.04284218719365298\n","Stopping epoch...\n","Training loss epoch: 0.04284218719365298\n","Training accuracy epoch: 0.9860950798418456\n","Validating model...\n","Validation Loss: 0.16375760903412645\n","Validation Accuracy: 0.9550350343411937\n","Training epoch: 3\n","Training loss per 100 training steps: 0.014801057986915112\n","Training loss per 100 training steps: 0.03418758527680051\n","Training loss per 100 training steps: 0.03145820189577838\n","Training loss per 100 training steps: 0.03089458813838215\n","Training loss per 100 training steps: 0.030996980445756765\n","Training loss per 100 training steps: 0.030048830791129293\n","Training loss per 100 training steps: 0.029970866645618145\n","Training loss per 100 training steps: 0.029905765199968685\n","Training loss per 100 training steps: 0.029926866438436308\n","Training loss per 100 training steps: 0.029968744557176186\n","Stopping epoch...\n","Training loss epoch: 0.029968744557176186\n","Training accuracy epoch: 0.9898391338283387\n","Validating model...\n","Validation Loss: 0.18255721336206446\n","Validation Accuracy: 0.9538182864828584\n","Training epoch: 4\n","Training loss per 100 training steps: 0.025785664096474648\n","Training loss per 100 training steps: 0.025172460868051\n","Training loss per 100 training steps: 0.023926771892262482\n","Training loss per 100 training steps: 0.024397718553056946\n","Training loss per 100 training steps: 0.025132165242804032\n","Training loss per 100 training steps: 0.025525930125690148\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 5\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"TTDq-xbgHqXQ"},{"cell_type":"code","source":["number_of_training_models = 8\n","target_augmented_percentage = 5\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["b225be86d07d4db9987d26aaab4848b1","6124d1d32ec444c9bbe4bd62b41ec435","1d5bb6cd6c6646acb38c164ebcb1ad27","8aadb65a590f41f08a9f2f8f0f652ad3","d3a245bd74264a4a9c02a232aafce636","1e24de523e5646f38725edf6482aa433","d7c912c2bc89499eb7b143a5d230e434","e811917f717a4c7ebbc6ff7baecfca55","8d04b0ff93c4474e9721e9d84ca0b6ed","1104db95d33d42f59a92904f7cfc06e9","cabc71478c534ef3ae57587ee2a50b21"]},"id":"EvNFD9zkJBMs","executionInfo":{"status":"ok","timestamp":1663634550053,"user_tz":240,"elapsed":1068534,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}},"outputId":"ad951a8f-7249-4aba-db85-c4518f0575dd"},"id":"EvNFD9zkJBMs","execution_count":9,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 500% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 83202\n","Points in y_train after augmentation: 83202\n","Device:  cuda\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b225be86d07d4db9987d26aaab4848b1","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.101039409637451\n","Training loss per 100 training steps: 0.3725968300558553\n","Training loss per 100 training steps: 0.27889087781384214\n","Training loss per 100 training steps: 0.23576738012094434\n","Training loss per 100 training steps: 0.21052535133264458\n","Training loss per 100 training steps: 0.19533296932509084\n","Training loss per 100 training steps: 0.1824679731138782\n","Training loss per 100 training steps: 0.17267120954781218\n","Training loss per 100 training steps: 0.16502182460744655\n","Training loss per 100 training steps: 0.15782819734214412\n","Training loss per 100 training steps: 0.15115578189961143\n","Training loss per 100 training steps: 0.1469936748293248\n","Training loss per 100 training steps: 0.14342024664066538\n","Training loss per 100 training steps: 0.14017410204601943\n","Training loss per 100 training steps: 0.1364542839498253\n","Training loss per 100 training steps: 0.13316418716701356\n","Training loss per 100 training steps: 0.13033224557666603\n","Training loss per 100 training steps: 0.1273363151435337\n","Training loss per 100 training steps: 0.12485550910824995\n","Training loss per 100 training steps: 0.12247268200730968\n","Training loss per 100 training steps: 0.12071893580778242\n","Training loss per 100 training steps: 0.11855235911736434\n","Training loss per 100 training steps: 0.11645056244585898\n","Training loss per 100 training steps: 0.11426516700643675\n","Training loss per 100 training steps: 0.11215325461712972\n","Training loss per 100 training steps: 0.1101364257707462\n","Training loss per 100 training steps: 0.10850130048802825\n","Training loss epoch: 0.10850130048802825\n","Training accuracy epoch: 0.9658577744428091\n","Validating model...\n","Validation Loss: 0.16134425131725028\n","Validation Accuracy: 0.954633755616948\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07598524540662766\n","Training loss per 100 training steps: 0.03894340736090694\n","Training loss per 100 training steps: 0.039166448665643804\n","Training loss per 100 training steps: 0.03965567409306876\n","Training loss per 100 training steps: 0.042858868783068126\n","Training loss per 100 training steps: 0.04481924324135618\n","Training loss per 100 training steps: 0.04402217811563156\n","Training loss per 100 training steps: 0.0449749798271154\n","Training loss per 100 training steps: 0.045102103284999646\n","Training loss per 100 training steps: 0.044661147653933544\n","Training loss per 100 training steps: 0.04537983261270692\n","Training loss per 100 training steps: 0.04538193585693271\n","Training loss per 100 training steps: 0.04511972160055709\n","Training loss per 100 training steps: 0.04473974566710189\n","Training loss per 100 training steps: 0.044913270622162785\n","Training loss per 100 training steps: 0.04472205889444466\n","Training loss per 100 training steps: 0.04448119924570388\n","Training loss per 100 training steps: 0.04415534174381572\n","Training loss per 100 training steps: 0.043961538355536386\n","Training loss per 100 training steps: 0.0432282266723774\n","Training loss per 100 training steps: 0.043217881436765505\n","Training loss per 100 training steps: 0.042891061814259855\n","Training loss per 100 training steps: 0.04259624686441754\n","Training loss per 100 training steps: 0.042606986270492364\n","Training loss per 100 training steps: 0.0424393332690229\n","Training loss per 100 training steps: 0.04230793488533759\n","Training loss per 100 training steps: 0.0423594562165872\n","Stopping epoch...\n","Training loss epoch: 0.0423594562165872\n","Training accuracy epoch: 0.9861844898165456\n","Validating model...\n","Validation Loss: 0.1681849296603884\n","Validation Accuracy: 0.9566011759802061\n","Training epoch: 3\n","Training loss per 100 training steps: 0.05201815441250801\n","Training loss per 100 training steps: 0.024723645680039975\n","Training loss per 100 training steps: 0.023234892302929466\n","Training loss per 100 training steps: 0.02347680395879037\n","Training loss per 100 training steps: 0.02387567043410117\n","Training loss per 100 training steps: 0.023455873792600668\n","Training loss per 100 training steps: 0.023359500841019107\n","Training loss per 100 training steps: 0.02307235278931849\n","Training loss per 100 training steps: 0.02321871222007308\n","Training loss per 100 training steps: 0.023471232691519253\n","Training loss per 100 training steps: 0.023105448339547082\n","Training loss per 100 training steps: 0.023779527281191485\n","Training loss per 100 training steps: 0.02380015503522668\n","Training loss per 100 training steps: 0.023866517254978927\n","Training loss per 100 training steps: 0.024238586549841262\n","Training loss per 100 training steps: 0.024339969105584836\n","Training loss per 100 training steps: 0.02416560851557554\n","Training loss per 100 training steps: 0.024451289262132844\n","Training loss per 100 training steps: 0.024530355594691557\n","Training loss per 100 training steps: 0.0248046938526451\n","Training loss per 100 training steps: 0.024885602916774947\n","Training loss per 100 training steps: 0.025013834344743326\n","Training loss per 100 training steps: 0.025038101132613212\n","Training loss per 100 training steps: 0.025116682964684105\n","Training loss per 100 training steps: 0.025634411809478584\n","Training loss per 100 training steps: 0.02597145668032379\n","Training loss per 100 training steps: 0.02598804353320495\n","Training loss epoch: 0.02598804353320495\n","Training accuracy epoch: 0.992022666087028\n","Validating model...\n","Validation Loss: 0.1786023960751179\n","Validation Accuracy: 0.9549960034190742\n","Training epoch: 4\n","Training loss per 100 training steps: 0.02707744762301445\n","Training loss per 100 training steps: 0.01751489136575509\n","Training loss per 100 training steps: 0.015390205579802314\n","Training loss per 100 training steps: 0.014035557006273815\n","Training loss per 100 training steps: 0.015424674925971497\n","Training loss per 100 training steps: 0.016237942863580122\n","Training loss per 100 training steps: 0.016204375883207164\n","Training loss per 100 training steps: 0.016709762405186956\n","Training loss per 100 training steps: 0.0174674561600981\n","Training loss per 100 training steps: 0.017511116606599396\n","Training loss per 100 training steps: 0.01810852742170567\n","Training loss per 100 training steps: 0.01897753859772013\n","Training loss per 100 training steps: 0.01954056933963459\n","Training loss per 100 training steps: 0.019493988912060806\n","Training loss per 100 training steps: 0.019729042540837495\n","Training loss per 100 training steps: 0.019674779855388545\n","Training loss per 100 training steps: 0.02006760140671744\n","Training loss per 100 training steps: 0.020223562930475045\n","Training loss per 100 training steps: 0.02015191448295811\n","Training loss per 100 training steps: 0.020178700779117757\n","Training loss per 100 training steps: 0.020264472414545463\n","Stopping epoch...\n","Training loss epoch: 0.020264472414545463\n","Training accuracy epoch: 0.9932734035804451\n","Validating model...\n","Validation Loss: 0.20119872906958902\n","Validation Accuracy: 0.9563670164161728\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0038002529181540012\n","Training loss per 100 training steps: 0.014351010595167074\n","Training loss per 100 training steps: 0.01437841438218043\n","Training loss per 100 training steps: 0.015547134990276355\n","Training loss per 100 training steps: 0.01539356053076415\n","Training loss per 100 training steps: 0.01487451891297244\n","Training loss per 100 training steps: 0.014807925555318867\n","Training loss per 100 training steps: 0.015157943487349371\n","Training loss per 100 training steps: 0.014759301403293226\n","Training loss per 100 training steps: 0.0146960194738681\n","Training loss per 100 training steps: 0.014253515786862096\n","Training loss per 100 training steps: 0.014494149161326774\n","Training loss per 100 training steps: 0.014921355066806634\n","Training loss per 100 training steps: 0.015045363250785192\n","Training loss per 100 training steps: 0.015206857265167996\n","Training loss per 100 training steps: 0.015518970006743668\n","Training loss per 100 training steps: 0.015761329417271385\n","Training loss per 100 training steps: 0.016032269629137893\n","Training loss per 100 training steps: 0.01642311642865347\n","Training loss per 100 training steps: 0.01626514169055114\n","Training loss per 100 training steps: 0.016336436029991366\n","Training loss per 100 training steps: 0.016596048604142894\n","Training loss per 100 training steps: 0.016988339756640002\n","Training loss per 100 training steps: 0.017075495039322222\n","Training loss per 100 training steps: 0.017045969022015616\n","Training loss per 100 training steps: 0.017008560304447577\n","Training loss per 100 training steps: 0.017317115462327202\n","Training loss epoch: 0.017317115462327202\n","Training accuracy epoch: 0.994705855696515\n","Validating model...\n","Validation Loss: 0.23057231689234833\n","Validation Accuracy: 0.9504223450453448\n","Training epoch: 6\n","Training loss per 100 training steps: 0.043601371347904205\n","Training loss per 100 training steps: 0.01749346728536351\n","Training loss per 100 training steps: 0.01527844604493677\n","Training loss per 100 training steps: 0.015408502190218746\n","Training loss per 100 training steps: 0.015949814202285143\n","Training loss per 100 training steps: 0.01607035038630388\n","Training loss per 100 training steps: 0.015736024909306624\n","Training loss per 100 training steps: 0.015265931529334226\n","Training loss per 100 training steps: 0.015068610460167086\n","Training loss per 100 training steps: 0.014761348910396273\n","Training loss per 100 training steps: 0.01466940548591054\n","Training loss per 100 training steps: 0.014844917098126758\n","Training loss per 100 training steps: 0.014867351566583168\n","Training loss per 100 training steps: 0.014702671392523965\n","Training loss per 100 training steps: 0.014570630519904065\n","Training loss per 100 training steps: 0.014465107917242348\n","Training loss per 100 training steps: 0.014526768271050499\n","Training loss per 100 training steps: 0.01464347894421935\n","Training loss per 100 training steps: 0.014495101503695016\n","Training loss per 100 training steps: 0.01431017030843406\n","Training loss per 100 training steps: 0.014376068094898055\n","Training loss per 100 training steps: 0.014348265724626216\n","Training loss per 100 training steps: 0.01449971525721315\n","Training loss per 100 training steps: 0.014647330978095733\n","Training loss per 100 training steps: 0.014784324911126\n","Training loss per 100 training steps: 0.014653550038876731\n","Training loss per 100 training steps: 0.014695637870873302\n","Training loss epoch: 0.014695637870873302\n","Training accuracy epoch: 0.9955446854441033\n","Validating model...\n","Validation Loss: 0.24387637582039098\n","Validation Accuracy: 0.9514094546340167\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 162.00892146666666 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1743878731353174\n","Validation Accuracy: 0.9506018560859142\n","Validation duration: 3.144151683333348 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 82.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.83      0.81     12548\n","        test       0.80      0.86      0.83      9012\n","   treatment       0.83      0.85      0.84      9301\n","\n","   micro avg       0.81      0.84      0.82     30861\n","   macro avg       0.81      0.85      0.83     30861\n","weighted avg       0.81      0.84      0.82     30861\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 83202\n","Points in y_train after augmentation: 83202\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0968611240386963\n","Training loss per 100 training steps: 0.40914903433606176\n","Training loss per 100 training steps: 0.29846866606776395\n","Training loss per 100 training steps: 0.25840877434641024\n","Training loss per 100 training steps: 0.23152641133588744\n","Training loss per 100 training steps: 0.21224650708649925\n","Training loss per 100 training steps: 0.1976661140443184\n","Training loss per 100 training steps: 0.18715690294235476\n","Training loss per 100 training steps: 0.17729301611601042\n","Training loss per 100 training steps: 0.16945208358029512\n","Training loss per 100 training steps: 0.1617587148970166\n","Training loss per 100 training steps: 0.1569899800127807\n","Training loss per 100 training steps: 0.15233013744572244\n","Training loss per 100 training steps: 0.14745261925533928\n","Training loss per 100 training steps: 0.14316371557695642\n","Training loss per 100 training steps: 0.13910096544688003\n","Training loss per 100 training steps: 0.135846601937869\n","Training loss per 100 training steps: 0.1331807063995964\n","Training loss per 100 training steps: 0.12995882077051585\n","Training loss per 100 training steps: 0.12715633053588302\n","Training loss per 100 training steps: 0.12419892143879806\n","Training loss per 100 training steps: 0.12162455523462841\n","Training loss per 100 training steps: 0.11966977734901502\n","Training loss per 100 training steps: 0.11741099458148153\n","Training loss per 100 training steps: 0.11555701049152561\n","Training loss per 100 training steps: 0.11372391498762696\n","Training loss per 100 training steps: 0.11188322066220031\n","Training loss epoch: 0.11188322066220031\n","Training accuracy epoch: 0.9647624956583533\n","Validating model...\n","Validation Loss: 0.16467391955968622\n","Validation Accuracy: 0.9508378382039209\n","Training epoch: 2\n","Training loss per 100 training steps: 0.052082162350416183\n","Training loss per 100 training steps: 0.04425597871598409\n","Training loss per 100 training steps: 0.04357812090415452\n","Training loss per 100 training steps: 0.043412720005606545\n","Training loss per 100 training steps: 0.04190813305327887\n","Training loss per 100 training steps: 0.042183590072538045\n","Training loss per 100 training steps: 0.0428708604885228\n","Training loss per 100 training steps: 0.04395547445289546\n","Training loss per 100 training steps: 0.043949756962880865\n","Training loss per 100 training steps: 0.04389622355201442\n","Training loss per 100 training steps: 0.04317744013938967\n","Training loss per 100 training steps: 0.043296974318120615\n","Training loss per 100 training steps: 0.042731979412672656\n","Training loss per 100 training steps: 0.04265640188759475\n","Training loss per 100 training steps: 0.04275625493699189\n","Training loss per 100 training steps: 0.0427149572364085\n","Training loss per 100 training steps: 0.04334038565314022\n","Training loss per 100 training steps: 0.04382642819672092\n","Training loss per 100 training steps: 0.04387181557403119\n","Training loss per 100 training steps: 0.04366607506093675\n","Training loss per 100 training steps: 0.043822459434845605\n","Training loss per 100 training steps: 0.043814652078101916\n","Stopping epoch...\n","Training loss epoch: 0.043814652078101916\n","Training accuracy epoch: 0.9859235520884728\n","Validating model...\n","Validation Loss: 0.1790736968108973\n","Validation Accuracy: 0.9523216728515739\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02527373842895031\n","Training loss per 100 training steps: 0.0305764349016112\n","Training loss per 100 training steps: 0.03360525440350545\n","Training loss per 100 training steps: 0.03192124610683228\n","Training loss per 100 training steps: 0.031196462210532547\n","Training loss per 100 training steps: 0.030111719569876353\n","Training loss per 100 training steps: 0.02890336007248229\n","Training loss per 100 training steps: 0.02927331867541111\n","Training loss per 100 training steps: 0.029625156113645933\n","Training loss per 100 training steps: 0.030084336465744033\n","Training loss per 100 training steps: 0.03035880181596258\n","Training loss per 100 training steps: 0.030218626864664307\n","Training loss per 100 training steps: 0.030561414178486814\n","Training loss per 100 training steps: 0.030743939265117357\n","Training loss per 100 training steps: 0.030576984024515905\n","Training loss per 100 training steps: 0.030553553608358763\n","Training loss per 100 training steps: 0.030735572564555537\n","Stopping epoch...\n","Training loss epoch: 0.030735572564555537\n","Training accuracy epoch: 0.989941519782294\n","Validating model...\n","Validation Loss: 0.1915220276077653\n","Validation Accuracy: 0.9516930475378155\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03013351373374462\n","Training loss per 100 training steps: 0.032303137479967776\n","Training loss per 100 training steps: 0.028485731718093342\n","Training loss per 100 training steps: 0.030664133269608988\n","Training loss per 100 training steps: 0.028633061597562695\n","Training loss per 100 training steps: 0.027200841488959845\n","Training loss per 100 training steps: 0.026353880848670488\n","Training loss per 100 training steps: 0.02616513819538705\n","Training loss per 100 training steps: 0.025982739883457565\n","Training loss per 100 training steps: 0.026628258406286947\n","Training loss per 100 training steps: 0.026487317476347163\n","Training loss per 100 training steps: 0.026162833857701517\n","Training loss per 100 training steps: 0.02651682399453899\n","Training loss per 100 training steps: 0.02613945325082569\n","Training loss per 100 training steps: 0.026402086078471502\n","Training loss per 100 training steps: 0.02668928063556342\n","Training loss per 100 training steps: 0.02674935896154365\n","Training loss per 100 training steps: 0.026562613417637555\n","Training loss per 100 training steps: 0.02632644271145423\n","Training loss per 100 training steps: 0.02629664103666013\n","Training loss per 100 training steps: 0.02607833411772505\n","Training loss per 100 training steps: 0.02601556833412898\n","Training loss per 100 training steps: 0.026136469573216442\n","Training loss per 100 training steps: 0.026321818683805814\n","Training loss per 100 training steps: 0.026235965489928084\n","Training loss per 100 training steps: 0.026148763090948903\n","Training loss per 100 training steps: 0.026373735184573286\n","Stopping epoch...\n","Training loss epoch: 0.026373735184573286\n","Training accuracy epoch: 0.991570253706401\n","Validating model...\n","Validation Loss: 0.2202294415177463\n","Validation Accuracy: 0.9506575519696671\n","Training epoch: 5\n","Training loss per 100 training steps: 0.007537800818681717\n","Training loss per 100 training steps: 0.014612177609336922\n","Training loss per 100 training steps: 0.013106616611959672\n","Training loss per 100 training steps: 0.016142615826744\n","Training loss per 100 training steps: 0.017083814035461834\n","Training loss per 100 training steps: 0.017872414221425267\n","Training loss per 100 training steps: 0.017374310278368204\n","Training loss per 100 training steps: 0.01789026847927095\n","Training loss per 100 training steps: 0.0186833943933677\n","Training loss per 100 training steps: 0.018646737869660195\n","Training loss per 100 training steps: 0.018784041805747574\n","Training loss per 100 training steps: 0.019032229888239167\n","Training loss per 100 training steps: 0.019109429686761995\n","Training loss per 100 training steps: 0.01919043553180346\n","Training loss per 100 training steps: 0.019347707403038157\n","Training loss per 100 training steps: 0.019774652490995578\n","Training loss per 100 training steps: 0.019864937245230196\n","Training loss per 100 training steps: 0.020160673636291423\n","Training loss per 100 training steps: 0.020461616433292928\n","Training loss per 100 training steps: 0.020334292100428916\n","Training loss per 100 training steps: 0.0204106000531427\n","Training loss per 100 training steps: 0.02023908719907621\n","Training loss per 100 training steps: 0.020100998665034606\n","Training loss per 100 training steps: 0.02004528261706285\n","Training loss per 100 training steps: 0.020034055413550238\n","Training loss per 100 training steps: 0.019885174336353093\n","Training loss per 100 training steps: 0.019780184773708156\n","Training loss epoch: 0.019780184773708156\n","Training accuracy epoch: 0.9940673502113108\n","Validating model...\n","Validation Loss: 0.21881793507120825\n","Validation Accuracy: 0.9546706809113414\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0043029882945120335\n","Training loss per 100 training steps: 0.016777700190155738\n","Training loss per 100 training steps: 0.015928667712845464\n","Training loss per 100 training steps: 0.014677632176854874\n","Training loss per 100 training steps: 0.015714151172798844\n","Training loss per 100 training steps: 0.016852749376943494\n","Training loss per 100 training steps: 0.01644495086505786\n","Training loss per 100 training steps: 0.016753716030694178\n","Training loss per 100 training steps: 0.01681963870478864\n","Training loss per 100 training steps: 0.017151369598252777\n","Training loss per 100 training steps: 0.01765220765023028\n","Training loss per 100 training steps: 0.017507947794469216\n","Training loss per 100 training steps: 0.01721730184908817\n","Training loss per 100 training steps: 0.01726123332648182\n","Training loss per 100 training steps: 0.016857454259673815\n","Training loss per 100 training steps: 0.016603002135922945\n","Training loss per 100 training steps: 0.016355277084229777\n","Training loss per 100 training steps: 0.0161698129794209\n","Training loss per 100 training steps: 0.01632834005858528\n","Training loss per 100 training steps: 0.016292811378283093\n","Training loss per 100 training steps: 0.01631548347968478\n","Training loss per 100 training steps: 0.016387829365711475\n","Training loss per 100 training steps: 0.016303986358912084\n","Stopping epoch...\n","Training loss epoch: 0.016303986358912084\n","Training accuracy epoch: 0.9946404035990688\n","Validating model...\n","Validation Loss: 0.26071328534321353\n","Validation Accuracy: 0.9523591091575626\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 141.22015658333336 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.17951102820397527\n","Validation Accuracy: 0.9469960617785992\n","Validation duration: 3.0587016499999664 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 81.3%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.82      0.81     12546\n","        test       0.77      0.82      0.79      9012\n","   treatment       0.81      0.86      0.83      9297\n","\n","   micro avg       0.79      0.83      0.81     30855\n","   macro avg       0.79      0.84      0.81     30855\n","weighted avg       0.79      0.83      0.81     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 83202\n","Points in y_train after augmentation: 83202\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7456865310668945\n","Training loss per 100 training steps: 0.3878498909497025\n","Training loss per 100 training steps: 0.2926787205448198\n","Training loss per 100 training steps: 0.24484798414911146\n","Training loss per 100 training steps: 0.2163781261354908\n","Training loss per 100 training steps: 0.19875193471665273\n","Training loss per 100 training steps: 0.18698718968450329\n","Training loss per 100 training steps: 0.17580455458708394\n","Training loss per 100 training steps: 0.16903643197520693\n","Training loss per 100 training steps: 0.16285373400545344\n","Training loss per 100 training steps: 0.15769291280784628\n","Training loss per 100 training steps: 0.1524605903923376\n","Training loss per 100 training steps: 0.14774691338940127\n","Training loss per 100 training steps: 0.14321792870330452\n","Training loss per 100 training steps: 0.13938310111924038\n","Training loss per 100 training steps: 0.13589394275132544\n","Training loss per 100 training steps: 0.13208945201090924\n","Training loss per 100 training steps: 0.1294679469073072\n","Training loss per 100 training steps: 0.12667187909491728\n","Training loss per 100 training steps: 0.12411855921361875\n","Training loss per 100 training steps: 0.12167638289704472\n","Training loss per 100 training steps: 0.11952926681267505\n","Training loss per 100 training steps: 0.117222736698145\n","Training loss per 100 training steps: 0.11512935986404009\n","Training loss per 100 training steps: 0.11323305020172433\n","Training loss per 100 training steps: 0.11130757436997107\n","Training loss per 100 training steps: 0.10967603008008946\n","Training loss epoch: 0.10967603008008946\n","Training accuracy epoch: 0.966139816964678\n","Validating model...\n","Validation Loss: 0.17385743292314665\n","Validation Accuracy: 0.9502805574482489\n","Training epoch: 2\n","Training loss per 100 training steps: 0.024546189233660698\n","Training loss per 100 training steps: 0.03703586480552607\n","Training loss per 100 training steps: 0.03553518804777136\n","Training loss per 100 training steps: 0.037931466093395164\n","Training loss per 100 training steps: 0.04035622036076404\n","Training loss per 100 training steps: 0.041288663737500036\n","Training loss per 100 training steps: 0.041806847566216505\n","Training loss per 100 training steps: 0.042593178051170466\n","Training loss per 100 training steps: 0.04223472018770934\n","Training loss per 100 training steps: 0.042875312352847604\n","Training loss per 100 training steps: 0.04353638684791564\n","Training loss per 100 training steps: 0.043757684237736495\n","Training loss per 100 training steps: 0.04410731798062313\n","Training loss per 100 training steps: 0.04424420875315694\n","Training loss per 100 training steps: 0.04396630589302488\n","Training loss per 100 training steps: 0.044031817779744756\n","Training loss per 100 training steps: 0.044145747145558176\n","Stopping epoch...\n","Training loss epoch: 0.044145747145558176\n","Training accuracy epoch: 0.9854890660568146\n","Validating model...\n","Validation Loss: 0.1619610825868009\n","Validation Accuracy: 0.9543656029702006\n","Training epoch: 3\n","Training loss per 100 training steps: 0.028111303225159645\n","Training loss per 100 training steps: 0.030143542966740853\n","Training loss per 100 training steps: 0.028814294601359695\n","Training loss per 100 training steps: 0.029665218380765614\n","Training loss per 100 training steps: 0.030121581149902984\n","Training loss per 100 training steps: 0.031453361403394095\n","Training loss per 100 training steps: 0.031103221750345557\n","Training loss per 100 training steps: 0.030827375916869095\n","Training loss per 100 training steps: 0.031076269478772008\n","Training loss per 100 training steps: 0.031090037940578075\n","Training loss per 100 training steps: 0.031142920427725415\n","Training loss per 100 training steps: 0.03133146959177424\n","Training loss per 100 training steps: 0.031249659708951157\n","Stopping epoch...\n","Training loss epoch: 0.031249659708951157\n","Training accuracy epoch: 0.9896553013440411\n","Validating model...\n","Validation Loss: 0.20587106039384742\n","Validation Accuracy: 0.9530980013944252\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03454742580652237\n","Training loss per 100 training steps: 0.02259945773316713\n","Training loss per 100 training steps: 0.02416415202005104\n","Training loss per 100 training steps: 0.02685809767057816\n","Training loss per 100 training steps: 0.026370925975712643\n","Training loss per 100 training steps: 0.027019262041045194\n","Training loss per 100 training steps: 0.02693454315498496\n","Training loss per 100 training steps: 0.027523382565872837\n","Training loss per 100 training steps: 0.02813195723711226\n","Training loss per 100 training steps: 0.02757365510723534\n","Training loss per 100 training steps: 0.027843308786826244\n","Training loss per 100 training steps: 0.028280876293316565\n","Training loss per 100 training steps: 0.028488643844297883\n","Training loss per 100 training steps: 0.028358838496784135\n","Training loss per 100 training steps: 0.028081852619135372\n","Training loss per 100 training steps: 0.0280419888688319\n","Training loss per 100 training steps: 0.02811006415097408\n","Training loss per 100 training steps: 0.02802765904183197\n","Training loss per 100 training steps: 0.02819764766521387\n","Stopping epoch...\n","Training loss epoch: 0.02819764766521387\n","Training accuracy epoch: 0.9908179164170507\n","Validating model...\n","Validation Loss: 0.1868342991386141\n","Validation Accuracy: 0.9539695571658585\n","Training epoch: 5\n","Training loss per 100 training steps: 0.054337892681360245\n","Training loss per 100 training steps: 0.020414308100214947\n","Training loss per 100 training steps: 0.018780299299338655\n","Training loss per 100 training steps: 0.019833186521245928\n","Training loss per 100 training steps: 0.021477419723195727\n","Training loss per 100 training steps: 0.022759821366434153\n","Training loss per 100 training steps: 0.022310438522956288\n","Training loss per 100 training steps: 0.022488073550854557\n","Training loss per 100 training steps: 0.022648678196557203\n","Training loss per 100 training steps: 0.02298676052439434\n","Training loss per 100 training steps: 0.023252671933762\n","Training loss per 100 training steps: 0.02311283741681879\n","Training loss per 100 training steps: 0.023050988151492757\n","Training loss per 100 training steps: 0.022916413468279575\n","Training loss per 100 training steps: 0.02289791036573213\n","Training loss per 100 training steps: 0.022795795964014758\n","Training loss per 100 training steps: 0.022630281478872197\n","Training loss per 100 training steps: 0.022610328958057983\n","Training loss per 100 training steps: 0.022428224968963375\n","Training loss per 100 training steps: 0.022329911241478834\n","Training loss per 100 training steps: 0.022133984778512517\n","Training loss per 100 training steps: 0.022276803275741712\n","Training loss per 100 training steps: 0.02231005396484651\n","Training loss per 100 training steps: 0.022383922974441726\n","Training loss per 100 training steps: 0.022303974177408207\n","Training loss per 100 training steps: 0.022376670902981732\n","Stopping epoch...\n","Training loss epoch: 0.022376670902981732\n","Training accuracy epoch: 0.9928225931899943\n","Validating model...\n","Validation Loss: 0.20885232554494657\n","Validation Accuracy: 0.954507358489351\n","Training epoch: 6\n","Training loss per 100 training steps: 0.002333113458007574\n","Training loss per 100 training steps: 0.017385232314181577\n","Training loss per 100 training steps: 0.015916022205370854\n","Training loss per 100 training steps: 0.014926465225299244\n","Training loss per 100 training steps: 0.015404268284546016\n","Training loss per 100 training steps: 0.01668079390950146\n","Training loss per 100 training steps: 0.01680313585196876\n","Training loss per 100 training steps: 0.017210673387423117\n","Training loss per 100 training steps: 0.01711663126301796\n","Training loss per 100 training steps: 0.01706178697232068\n","Training loss per 100 training steps: 0.01649781891884939\n","Training loss per 100 training steps: 0.01712122718235994\n","Training loss per 100 training steps: 0.01723714310660447\n","Training loss per 100 training steps: 0.01736843062020773\n","Training loss per 100 training steps: 0.01728391754356207\n","Training loss per 100 training steps: 0.01739729676440018\n","Training loss per 100 training steps: 0.017264873127267318\n","Stopping epoch...\n","Training loss epoch: 0.017264873127267318\n","Training accuracy epoch: 0.9940604827162023\n","Validating model...\n","Validation Loss: 0.21696909158430122\n","Validation Accuracy: 0.9530752286804097\n","Training epoch: 7\n","Training loss per 100 training steps: 0.004384878557175398\n","Training loss per 100 training steps: 0.012631512175563096\n","Training loss per 100 training steps: 0.012663018537004158\n","Training loss per 100 training steps: 0.013604149335115046\n","Training loss per 100 training steps: 0.01455874806934819\n","Training loss per 100 training steps: 0.015283078064341767\n","Training loss per 100 training steps: 0.01499329856272435\n","Training loss per 100 training steps: 0.015532587169506487\n","Training loss per 100 training steps: 0.015855351719953243\n","Training loss per 100 training steps: 0.015581254548330913\n","Training loss per 100 training steps: 0.015526585189804024\n","Training loss per 100 training steps: 0.015642624653371046\n","Training loss per 100 training steps: 0.015597318625605885\n","Training loss per 100 training steps: 0.015707125799829028\n","Training loss per 100 training steps: 0.015801320122549083\n","Training loss per 100 training steps: 0.015809831483902158\n","Training loss per 100 training steps: 0.016113376090003337\n","Training loss per 100 training steps: 0.016123558453656924\n","Training loss per 100 training steps: 0.016233055150661996\n","Training loss per 100 training steps: 0.016264755005883577\n","Training loss per 100 training steps: 0.01615997806569256\n","Stopping epoch...\n","Training loss epoch: 0.01615997806569256\n","Training accuracy epoch: 0.9947095344793184\n","Validating model...\n","Validation Loss: 0.2167619654013739\n","Validation Accuracy: 0.9553543516255643\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 140.0884764166667 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.18124475761443912\n","Validation Accuracy: 0.9501212782450947\n","Validation duration: 3.1061767500000013 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 83.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.78      0.87      0.82     12546\n","        test       0.82      0.85      0.84      9012\n","   treatment       0.82      0.87      0.84      9297\n","\n","   micro avg       0.80      0.86      0.83     30855\n","   macro avg       0.81      0.86      0.83     30855\n","weighted avg       0.80      0.86      0.83     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 83202\n","Points in y_train after augmentation: 83202\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8307474851608276\n","Training loss per 100 training steps: 0.3630616762260399\n","Training loss per 100 training steps: 0.2722763981280932\n","Training loss per 100 training steps: 0.23643346957590097\n","Training loss per 100 training steps: 0.21416938604968147\n","Training loss per 100 training steps: 0.19885284195611339\n","Training loss per 100 training steps: 0.18669675377363373\n","Training loss per 100 training steps: 0.17784106272794892\n","Training loss per 100 training steps: 0.1692786927401238\n","Training loss per 100 training steps: 0.16167867819589463\n","Training loss per 100 training steps: 0.15602593601204\n","Training loss per 100 training steps: 0.15130738291608595\n","Training loss per 100 training steps: 0.14706558731852176\n","Training loss per 100 training steps: 0.1429692584474347\n","Training loss per 100 training steps: 0.13893601592154184\n","Training loss per 100 training steps: 0.13553823290242603\n","Training loss per 100 training steps: 0.13274762962888378\n","Training loss per 100 training steps: 0.12949738800657068\n","Training loss per 100 training steps: 0.1271516387606829\n","Training loss per 100 training steps: 0.12468370122796826\n","Training loss per 100 training steps: 0.121772652903366\n","Training loss per 100 training steps: 0.11975135186687999\n","Training loss per 100 training steps: 0.11704442474012793\n","Training loss per 100 training steps: 0.11476761521650126\n","Training loss per 100 training steps: 0.11297842103119836\n","Training loss per 100 training steps: 0.11117288571090156\n","Training loss per 100 training steps: 0.10967537458761896\n","Training loss epoch: 0.10967537458761896\n","Training accuracy epoch: 0.966100654209176\n","Validating model...\n","Validation Loss: 0.18626251623228\n","Validation Accuracy: 0.949641967021057\n","Training epoch: 2\n","Training loss per 100 training steps: 0.03649536147713661\n","Training loss per 100 training steps: 0.05514004887173893\n","Training loss per 100 training steps: 0.050567932898382566\n","Training loss per 100 training steps: 0.047266711920277024\n","Training loss per 100 training steps: 0.04556068321724801\n","Training loss per 100 training steps: 0.04390836293305347\n","Training loss per 100 training steps: 0.04358032439678858\n","Training loss per 100 training steps: 0.04351550149272984\n","Training loss per 100 training steps: 0.043338557177417435\n","Training loss per 100 training steps: 0.043250102376654234\n","Training loss per 100 training steps: 0.04391339746397826\n","Training loss per 100 training steps: 0.04350407221959354\n","Training loss per 100 training steps: 0.04355981909409382\n","Training loss per 100 training steps: 0.04325806487406777\n","Training loss per 100 training steps: 0.04311830691842337\n","Training loss per 100 training steps: 0.04304003443982797\n","Training loss per 100 training steps: 0.04344356366081849\n","Training loss per 100 training steps: 0.04314184756492369\n","Stopping epoch...\n","Training loss epoch: 0.04314184756492369\n","Training accuracy epoch: 0.9859554822493161\n","Validating model...\n","Validation Loss: 0.18405740420249375\n","Validation Accuracy: 0.9514549642081066\n","Training epoch: 3\n","Training loss per 100 training steps: 0.01720319502055645\n","Training loss per 100 training steps: 0.028540917252660683\n","Training loss per 100 training steps: 0.03136902816468544\n","Training loss per 100 training steps: 0.03271771992009096\n","Training loss per 100 training steps: 0.031069952777140957\n","Training loss per 100 training steps: 0.030517185703124443\n","Training loss per 100 training steps: 0.030460641359113864\n","Training loss per 100 training steps: 0.030704916751453287\n","Training loss per 100 training steps: 0.030169908503639035\n","Training loss per 100 training steps: 0.03089820898510619\n","Training loss per 100 training steps: 0.03205722230581937\n","Training loss per 100 training steps: 0.032157007653370234\n","Training loss per 100 training steps: 0.032521289507982526\n","Training loss per 100 training steps: 0.03194411698509391\n","Training loss per 100 training steps: 0.031978284950676554\n","Training loss per 100 training steps: 0.031902302338165926\n","Training loss per 100 training steps: 0.03182084788502875\n","Training loss per 100 training steps: 0.031884276313936644\n","Stopping epoch...\n","Training loss epoch: 0.031884276313936644\n","Training accuracy epoch: 0.9897017388799144\n","Validating model...\n","Validation Loss: 0.21067160687276296\n","Validation Accuracy: 0.9495230115836035\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0021370036993175745\n","Training loss per 100 training steps: 0.024151480613774298\n","Training loss per 100 training steps: 0.025047388912956995\n","Training loss per 100 training steps: 0.024596062950067457\n","Training loss per 100 training steps: 0.02479483859983396\n","Training loss per 100 training steps: 0.02410767666681599\n","Training loss per 100 training steps: 0.02468051797412638\n","Training loss per 100 training steps: 0.025211697406414164\n","Training loss per 100 training steps: 0.025179598734767283\n","Training loss per 100 training steps: 0.025740146702341527\n","Training loss per 100 training steps: 0.025912613933115124\n","Training loss per 100 training steps: 0.025841070960388332\n","Training loss per 100 training steps: 0.026065260699781885\n","Training loss per 100 training steps: 0.026000236948310676\n","Training loss per 100 training steps: 0.02578569452690797\n","Training loss per 100 training steps: 0.025697210792381985\n","Training loss per 100 training steps: 0.025826719201165256\n","Training loss per 100 training steps: 0.025891481757945305\n","Training loss per 100 training steps: 0.026136705489828667\n","Training loss per 100 training steps: 0.02608982588539046\n","Training loss per 100 training steps: 0.026174837805057083\n","Training loss per 100 training steps: 0.026001914957817954\n","Training loss per 100 training steps: 0.026115207584172417\n","Stopping epoch...\n","Training loss epoch: 0.026115207584172417\n","Training accuracy epoch: 0.9915652376342895\n","Validating model...\n","Validation Loss: 0.22123374040057134\n","Validation Accuracy: 0.9507376420609709\n","Training epoch: 5\n","Training loss per 100 training steps: 0.00184668879956007\n","Training loss per 100 training steps: 0.018694582378542476\n","Training loss per 100 training steps: 0.019433211972786402\n","Training loss per 100 training steps: 0.019015538362141055\n","Training loss per 100 training steps: 0.018925262219824147\n","Training loss per 100 training steps: 0.01830045672511392\n","Training loss per 100 training steps: 0.018446537565830055\n","Training loss per 100 training steps: 0.018913477791708093\n","Training loss per 100 training steps: 0.01903773679469361\n","Training loss per 100 training steps: 0.019412699793112703\n","Training loss per 100 training steps: 0.01940201720548817\n","Training loss per 100 training steps: 0.019240574962703753\n","Training loss per 100 training steps: 0.01913706210214\n","Training loss per 100 training steps: 0.019427922866984575\n","Training loss per 100 training steps: 0.01954709494589987\n","Training loss per 100 training steps: 0.0196850687352029\n","Training loss per 100 training steps: 0.02027443904838473\n","Training loss per 100 training steps: 0.020480699244625745\n","Training loss per 100 training steps: 0.02034302442491666\n","Training loss per 100 training steps: 0.0203050737642505\n","Training loss per 100 training steps: 0.020323741293941294\n","Training loss per 100 training steps: 0.02024625057512985\n","Training loss per 100 training steps: 0.02081928634242538\n","Training loss per 100 training steps: 0.020764110467076623\n","Training loss per 100 training steps: 0.020646637523696054\n","Training loss per 100 training steps: 0.020711381760105525\n","Training loss per 100 training steps: 0.020760003184786092\n","Stopping epoch...\n","Training loss epoch: 0.020760003184786092\n","Training accuracy epoch: 0.9932639772401286\n","Validating model...\n","Validation Loss: 0.21544933456975918\n","Validation Accuracy: 0.9528045817418701\n","Training epoch: 6\n","Training loss per 100 training steps: 0.001770189730450511\n","Training loss per 100 training steps: 0.011456506296826324\n","Training loss per 100 training steps: 0.01413874820526921\n","Training loss per 100 training steps: 0.013336728780744659\n","Training loss per 100 training steps: 0.015085936330117754\n","Training loss per 100 training steps: 0.016417708430830073\n","Training loss per 100 training steps: 0.01682883429024508\n","Training loss per 100 training steps: 0.017112045164237307\n","Training loss per 100 training steps: 0.017048106050076946\n","Training loss per 100 training steps: 0.01727477255957997\n","Training loss per 100 training steps: 0.017791248379404528\n","Training loss per 100 training steps: 0.017885431602997343\n","Training loss per 100 training steps: 0.017706548839014218\n","Training loss per 100 training steps: 0.01739453242390705\n","Training loss per 100 training steps: 0.01712852580499251\n","Training loss per 100 training steps: 0.017130349466037677\n","Training loss per 100 training steps: 0.017050077460795236\n","Training loss per 100 training steps: 0.017088562906795713\n","Training loss per 100 training steps: 0.016953316606360274\n","Training loss per 100 training steps: 0.01699551922815846\n","Training loss per 100 training steps: 0.016894522697668522\n","Training loss per 100 training steps: 0.01701696046946053\n","Training loss per 100 training steps: 0.017027263173780914\n","Stopping epoch...\n","Training loss epoch: 0.017027263173780914\n","Training accuracy epoch: 0.9943724522464733\n","Validating model...\n","Validation Loss: 0.22185889619414684\n","Validation Accuracy: 0.951130878916083\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0042927502654492855\n","Training loss per 100 training steps: 0.010770572515263333\n","Training loss per 100 training steps: 0.01064905392844983\n","Training loss per 100 training steps: 0.011283940862602418\n","Training loss per 100 training steps: 0.011379529994239211\n","Training loss per 100 training steps: 0.012490264374032911\n","Training loss per 100 training steps: 0.012721554150400232\n","Training loss per 100 training steps: 0.01304631338487748\n","Training loss per 100 training steps: 0.01288921689270131\n","Training loss per 100 training steps: 0.01320482602353106\n","Training loss per 100 training steps: 0.013348647111043038\n","Training loss per 100 training steps: 0.013605242585150595\n","Training loss per 100 training steps: 0.013530961405794597\n","Training loss per 100 training steps: 0.013644895807508491\n","Training loss per 100 training steps: 0.013636744048112045\n","Training loss per 100 training steps: 0.013421966767239184\n","Training loss per 100 training steps: 0.013695299370061061\n","Training loss per 100 training steps: 0.013754421123744906\n","Training loss per 100 training steps: 0.014071513705964855\n","Training loss per 100 training steps: 0.014260474815096942\n","Training loss per 100 training steps: 0.014355513550868693\n","Training loss per 100 training steps: 0.014355043059029661\n","Training loss per 100 training steps: 0.014290842657464716\n","Training loss per 100 training steps: 0.014459647637651181\n","Training loss per 100 training steps: 0.01455013367062272\n","Training loss per 100 training steps: 0.014594584563837816\n","Training loss per 100 training steps: 0.014583670205603326\n","Training loss epoch: 0.014583670205603326\n","Training accuracy epoch: 0.9956626596847827\n","Validating model...\n","Validation Loss: 0.27831817594925307\n","Validation Accuracy: 0.9475992936014335\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 167.1187928333333 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.19561785328982365\n","Validation Accuracy: 0.9495324912605285\n","Validation duration: 3.1364072000000305 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 82.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.83      0.82     12548\n","        test       0.81      0.85      0.83      9012\n","   treatment       0.78      0.87      0.82      9301\n","\n","   micro avg       0.80      0.85      0.83     30861\n","   macro avg       0.80      0.85      0.83     30861\n","weighted avg       0.80      0.85      0.83     30861\n","\n","!!!!!! Starting model number 5 !!!!!!\n","Points in X_train after augmentation: 83202\n","Points in y_train after augmentation: 83202\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0375478267669678\n","Training loss per 100 training steps: 0.38752145224278517\n","Training loss per 100 training steps: 0.28660002400848406\n","Training loss per 100 training steps: 0.2446321423515133\n","Training loss per 100 training steps: 0.21889906956296312\n","Training loss per 100 training steps: 0.20179389862198674\n","Training loss per 100 training steps: 0.18807344900416256\n","Training loss per 100 training steps: 0.1785768804003547\n","Training loss per 100 training steps: 0.17050898937245693\n","Training loss per 100 training steps: 0.16384791799166656\n","Training loss per 100 training steps: 0.1575308730341978\n","Training loss per 100 training steps: 0.15213986888247036\n","Training loss per 100 training steps: 0.1476608339866172\n","Training loss per 100 training steps: 0.1428006252010484\n","Training loss per 100 training steps: 0.13896963214548272\n","Training loss per 100 training steps: 0.13519277571912092\n","Training loss per 100 training steps: 0.13293672520678948\n","Training loss per 100 training steps: 0.1300573676577093\n","Training loss per 100 training steps: 0.12717366417604128\n","Training loss per 100 training steps: 0.12394402021501039\n","Training loss per 100 training steps: 0.12175229232249105\n","Training loss per 100 training steps: 0.11994531256714565\n","Training loss per 100 training steps: 0.11802767872131653\n","Training loss per 100 training steps: 0.115993982703886\n","Training loss per 100 training steps: 0.1138294953115902\n","Training loss per 100 training steps: 0.11216935882831171\n","Training loss per 100 training steps: 0.11011349365597835\n","Training loss epoch: 0.11011349365597835\n","Training accuracy epoch: 0.9655958398283024\n","Validating model...\n","Validation Loss: 0.14906992920517148\n","Validation Accuracy: 0.9556564003669088\n","Training epoch: 2\n","Training loss per 100 training steps: 0.061024900525808334\n","Training loss per 100 training steps: 0.044717916264429246\n","Training loss per 100 training steps: 0.044463383374429906\n","Training loss per 100 training steps: 0.043862522660176026\n","Training loss per 100 training steps: 0.04334089211176644\n","Training loss per 100 training steps: 0.042837941152380106\n","Training loss per 100 training steps: 0.04390242481999372\n","Training loss per 100 training steps: 0.04381312446545188\n","Training loss per 100 training steps: 0.044158107857190806\n","Training loss per 100 training steps: 0.04384421721151456\n","Training loss per 100 training steps: 0.043969206975077044\n","Stopping epoch...\n","Training loss epoch: 0.043969206975077044\n","Training accuracy epoch: 0.985141780596918\n","Validating model...\n","Validation Loss: 0.18465026729292683\n","Validation Accuracy: 0.9521292235197776\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03275686874985695\n","Training loss per 100 training steps: 0.03332349407200766\n","Training loss per 100 training steps: 0.0321550713759379\n","Training loss per 100 training steps: 0.03270256183453622\n","Training loss per 100 training steps: 0.032627469721247915\n","Training loss per 100 training steps: 0.03318978187013715\n","Training loss per 100 training steps: 0.033563173635391685\n","Training loss per 100 training steps: 0.03363095553121536\n","Training loss per 100 training steps: 0.033069955736756806\n","Training loss per 100 training steps: 0.034136016621356714\n","Training loss per 100 training steps: 0.03473470387603533\n","Training loss per 100 training steps: 0.03450943473787838\n","Training loss per 100 training steps: 0.03425435015831304\n","Training loss per 100 training steps: 0.03416097624258544\n","Training loss per 100 training steps: 0.03419551685592725\n","Training loss per 100 training steps: 0.03464552143208315\n","Training loss per 100 training steps: 0.034441991244093154\n","Training loss per 100 training steps: 0.03456037037642886\n","Training loss per 100 training steps: 0.03473250992903315\n","Training loss per 100 training steps: 0.03459677481516776\n","Stopping epoch...\n","Training loss epoch: 0.03459677481516776\n","Training accuracy epoch: 0.9887795157556222\n","Validating model...\n","Validation Loss: 0.18251335583385322\n","Validation Accuracy: 0.9536827383491466\n","Training epoch: 4\n","Training loss per 100 training steps: 0.05040284991264343\n","Training loss per 100 training steps: 0.023774303173148395\n","Training loss per 100 training steps: 0.023603187778394725\n","Training loss per 100 training steps: 0.02391168521369105\n","Training loss per 100 training steps: 0.023490083701165388\n","Training loss per 100 training steps: 0.024217253830655667\n","Training loss per 100 training steps: 0.024875311885639628\n","Training loss per 100 training steps: 0.025703890904114606\n","Training loss per 100 training steps: 0.02623217290922239\n","Training loss per 100 training steps: 0.02683485534847595\n","Training loss per 100 training steps: 0.026890430285501855\n","Training loss per 100 training steps: 0.026795087128060936\n","Training loss per 100 training steps: 0.027133683666912954\n","Training loss per 100 training steps: 0.026840915616862453\n","Training loss per 100 training steps: 0.027074902269371526\n","Training loss per 100 training steps: 0.027201663424349487\n","Training loss per 100 training steps: 0.02709489808784554\n","Training loss per 100 training steps: 0.026918886209873545\n","Training loss per 100 training steps: 0.027184249973154058\n","Training loss per 100 training steps: 0.02692177017004232\n","Training loss per 100 training steps: 0.026855112613582664\n","Training loss per 100 training steps: 0.026811213744269563\n","Training loss per 100 training steps: 0.02682999155151925\n","Training loss per 100 training steps: 0.02684523081932869\n","Stopping epoch...\n","Training loss epoch: 0.02684523081932869\n","Training accuracy epoch: 0.9914467093780553\n","Validating model...\n","Validation Loss: 0.18537350047331352\n","Validation Accuracy: 0.955866238936866\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0018554673297330737\n","Training loss per 100 training steps: 0.013559632840114508\n","Training loss per 100 training steps: 0.016808176485865623\n","Training loss per 100 training steps: 0.017184624557292083\n","Training loss per 100 training steps: 0.01687498896036116\n","Training loss per 100 training steps: 0.017456271582837968\n","Training loss per 100 training steps: 0.017583358257380586\n","Training loss per 100 training steps: 0.017854529770573443\n","Training loss per 100 training steps: 0.01836856587790825\n","Training loss per 100 training steps: 0.018444895145062618\n","Training loss per 100 training steps: 0.01851595080721394\n","Training loss per 100 training steps: 0.019014941652943648\n","Training loss per 100 training steps: 0.019382262626729926\n","Training loss per 100 training steps: 0.019132439576291252\n","Training loss per 100 training steps: 0.019512211045522514\n","Training loss per 100 training steps: 0.019476728503793034\n","Training loss per 100 training steps: 0.019620578224559274\n","Training loss per 100 training steps: 0.019717592338531518\n","Training loss per 100 training steps: 0.019728902778236596\n","Training loss per 100 training steps: 0.019601321063766983\n","Training loss per 100 training steps: 0.019859616421711124\n","Training loss per 100 training steps: 0.019777385337375324\n","Training loss per 100 training steps: 0.019824058147214364\n","Training loss per 100 training steps: 0.01991316562099868\n","Training loss per 100 training steps: 0.01992198923656132\n","Stopping epoch...\n","Training loss epoch: 0.01992198923656132\n","Training accuracy epoch: 0.9936002725922272\n","Validating model...\n","Validation Loss: 0.22072009624937525\n","Validation Accuracy: 0.9548434179569749\n","Training epoch: 6\n","Training loss per 100 training steps: 0.09851696342229843\n","Training loss per 100 training steps: 0.016876218562120442\n","Training loss per 100 training steps: 0.01633706649453194\n","Training loss per 100 training steps: 0.015609516038952328\n","Training loss per 100 training steps: 0.015519188121431495\n","Training loss per 100 training steps: 0.015437586414032874\n","Training loss per 100 training steps: 0.015116868062344257\n","Training loss per 100 training steps: 0.01575347592189115\n","Training loss per 100 training steps: 0.015568303425260615\n","Training loss per 100 training steps: 0.015514963327062788\n","Training loss per 100 training steps: 0.015654030195003575\n","Training loss per 100 training steps: 0.015874806073041495\n","Training loss per 100 training steps: 0.016327152936181387\n","Training loss per 100 training steps: 0.016610778728585015\n","Training loss per 100 training steps: 0.0168779652847948\n","Training loss per 100 training steps: 0.017156060457195955\n","Training loss per 100 training steps: 0.017487117738068436\n","Training loss per 100 training steps: 0.0175136219912213\n","Training loss per 100 training steps: 0.017538438138794018\n","Training loss per 100 training steps: 0.017287666028535\n","Training loss per 100 training steps: 0.017315868733111937\n","Training loss per 100 training steps: 0.017377053165077136\n","Training loss per 100 training steps: 0.017559702581036726\n","Training loss per 100 training steps: 0.017537457473449182\n","Training loss per 100 training steps: 0.017495741597390826\n","Training loss per 100 training steps: 0.01760674727053001\n","Training loss per 100 training steps: 0.017518475832283244\n","Stopping epoch...\n","Training loss epoch: 0.017518475832283244\n","Training accuracy epoch: 0.9943228191267282\n","Validating model...\n","Validation Loss: 0.22152055693524225\n","Validation Accuracy: 0.9548173715857599\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 134.00775759999996 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.17857006824299418\n","Validation Accuracy: 0.9482450153074505\n","Validation duration: 3.0995529499999974 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 82.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.78      0.85      0.81     12546\n","        test       0.82      0.86      0.84      9012\n","   treatment       0.80      0.86      0.83      9297\n","\n","   micro avg       0.80      0.85      0.83     30855\n","   macro avg       0.80      0.85      0.83     30855\n","weighted avg       0.80      0.85      0.83     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n","Points in X_train after augmentation: 83202\n","Points in y_train after augmentation: 83202\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.991724967956543\n","Training loss per 100 training steps: 0.4105449859606157\n","Training loss per 100 training steps: 0.3065356417230113\n","Training loss per 100 training steps: 0.26162573144433904\n","Training loss per 100 training steps: 0.22768044251567704\n","Training loss per 100 training steps: 0.20936104080485488\n","Training loss per 100 training steps: 0.19410125331677336\n","Training loss per 100 training steps: 0.18343895208356256\n","Training loss per 100 training steps: 0.17409562272427792\n","Training loss per 100 training steps: 0.16693314048384092\n","Training loss per 100 training steps: 0.16044128065897184\n","Training loss per 100 training steps: 0.15454633176989926\n","Training loss per 100 training steps: 0.14920665453157878\n","Training loss per 100 training steps: 0.14542757325249508\n","Training loss per 100 training steps: 0.14117099890494714\n","Training loss per 100 training steps: 0.13779615872675463\n","Training loss per 100 training steps: 0.13430880692361072\n","Training loss per 100 training steps: 0.13140482821560376\n","Training loss per 100 training steps: 0.12856016415680682\n","Training loss per 100 training steps: 0.1254795406788768\n","Training loss per 100 training steps: 0.12317314100540665\n","Training loss per 100 training steps: 0.12056635866524108\n","Training loss per 100 training steps: 0.11873492705967888\n","Training loss per 100 training steps: 0.11630663155974325\n","Training loss per 100 training steps: 0.11438800444398253\n","Training loss per 100 training steps: 0.11287000725159003\n","Training loss per 100 training steps: 0.1110286464979489\n","Training loss epoch: 0.1110286464979489\n","Training accuracy epoch: 0.9654074366012996\n","Validating model...\n","Validation Loss: 0.16556321627569276\n","Validation Accuracy: 0.9501561180134004\n","Training epoch: 2\n","Training loss per 100 training steps: 0.046877145767211914\n","Training loss per 100 training steps: 0.04453195637497719\n","Training loss per 100 training steps: 0.042667506714420975\n","Training loss per 100 training steps: 0.04208019714913891\n","Training loss per 100 training steps: 0.041228290932355194\n","Training loss per 100 training steps: 0.04201706533669727\n","Training loss per 100 training steps: 0.04159668775720091\n","Training loss per 100 training steps: 0.041339450090998694\n","Training loss per 100 training steps: 0.041486525331994754\n","Training loss per 100 training steps: 0.04135997028510757\n","Training loss per 100 training steps: 0.04154421067861775\n","Stopping epoch...\n","Training loss epoch: 0.04154421067861775\n","Training accuracy epoch: 0.9861407137116024\n","Validating model...\n","Validation Loss: 0.17603253181298056\n","Validation Accuracy: 0.9550677845056731\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03264661878347397\n","Training loss per 100 training steps: 0.03933985045382587\n","Training loss per 100 training steps: 0.03608972730522799\n","Training loss per 100 training steps: 0.036611314244534315\n","Training loss per 100 training steps: 0.03590083110728011\n","Training loss per 100 training steps: 0.0361188600244588\n","Training loss per 100 training steps: 0.03584975543173926\n","Training loss per 100 training steps: 0.035884923798021474\n","Training loss per 100 training steps: 0.035403818193213844\n","Training loss per 100 training steps: 0.03523310103487806\n","Training loss per 100 training steps: 0.0353617180964782\n","Training loss per 100 training steps: 0.03490121680211198\n","Training loss per 100 training steps: 0.0351233016279837\n","Training loss per 100 training steps: 0.03547730361983727\n","Training loss per 100 training steps: 0.03504053151610904\n","Training loss per 100 training steps: 0.03482548576454848\n","Training loss per 100 training steps: 0.03508773736903231\n","Training loss per 100 training steps: 0.03562019622893177\n","Training loss per 100 training steps: 0.03552002259259935\n","Training loss per 100 training steps: 0.03577986225611464\n","Training loss per 100 training steps: 0.03588285667572528\n","Training loss per 100 training steps: 0.03563708462153979\n","Training loss per 100 training steps: 0.03563124275741348\n","Training loss per 100 training steps: 0.03544768067494703\n","Training loss per 100 training steps: 0.03541762442259185\n","Training loss per 100 training steps: 0.03531882684284606\n","Stopping epoch...\n","Training loss epoch: 0.03531882684284606\n","Training accuracy epoch: 0.988777762380487\n","Validating model...\n","Validation Loss: 0.20333982453766195\n","Validation Accuracy: 0.9534430356189912\n","Training epoch: 4\n","Training loss per 100 training steps: 0.06271333247423172\n","Training loss per 100 training steps: 0.020372677026178208\n","Training loss per 100 training steps: 0.022140958239278058\n","Training loss per 100 training steps: 0.021512758981535502\n","Training loss per 100 training steps: 0.021390008525150665\n","Training loss per 100 training steps: 0.022014540327948046\n","Training loss per 100 training steps: 0.022023361113105284\n","Training loss per 100 training steps: 0.022462859500522396\n","Training loss per 100 training steps: 0.022717194613383226\n","Training loss per 100 training steps: 0.02246632040493794\n","Training loss per 100 training steps: 0.022541305520625266\n","Training loss per 100 training steps: 0.02290204136739599\n","Training loss per 100 training steps: 0.023025674106367862\n","Training loss per 100 training steps: 0.02334485560134633\n","Training loss per 100 training steps: 0.023269903813802877\n","Training loss per 100 training steps: 0.023388741162661736\n","Training loss per 100 training steps: 0.023683673434337887\n","Training loss per 100 training steps: 0.023577362056108445\n","Training loss per 100 training steps: 0.02349650403385804\n","Training loss per 100 training steps: 0.023540030517435334\n","Training loss per 100 training steps: 0.02352423157484416\n","Stopping epoch...\n","Training loss epoch: 0.02352423157484416\n","Training accuracy epoch: 0.9921760471151359\n","Validating model...\n","Validation Loss: 0.202199030163329\n","Validation Accuracy: 0.9536832160737361\n","Training epoch: 5\n","Training loss per 100 training steps: 0.00938067864626646\n","Training loss per 100 training steps: 0.016583372045787845\n","Training loss per 100 training steps: 0.017076408448258404\n","Training loss per 100 training steps: 0.018701831104335966\n","Training loss per 100 training steps: 0.018965828894960353\n","Training loss per 100 training steps: 0.01958531975497988\n","Training loss per 100 training steps: 0.019438205339935004\n","Training loss per 100 training steps: 0.01921626393221247\n","Training loss per 100 training steps: 0.019346747409608147\n","Training loss per 100 training steps: 0.019180821002637773\n","Training loss per 100 training steps: 0.018996476529647116\n","Training loss per 100 training steps: 0.01871908190869536\n","Training loss per 100 training steps: 0.018876695727753443\n","Training loss per 100 training steps: 0.01906289527886014\n","Training loss per 100 training steps: 0.01896566994892743\n","Training loss per 100 training steps: 0.018925449176183308\n","Training loss per 100 training steps: 0.01944981950616172\n","Training loss per 100 training steps: 0.019564803809966173\n","Training loss per 100 training steps: 0.01960411695789971\n","Training loss per 100 training steps: 0.019679301314349622\n","Training loss per 100 training steps: 0.01963367217192673\n","Training loss per 100 training steps: 0.019515473440883266\n","Stopping epoch...\n","Training loss epoch: 0.019515473440883266\n","Training accuracy epoch: 0.993689107259573\n","Validating model...\n","Validation Loss: 0.21783371861153222\n","Validation Accuracy: 0.9537202696413108\n","Training epoch: 6\n","Training loss per 100 training steps: 0.011699765920639038\n","Training loss per 100 training steps: 0.013434287077357698\n","Training loss per 100 training steps: 0.015160412333450462\n","Training loss per 100 training steps: 0.014254711467314022\n","Training loss per 100 training steps: 0.014382157559164607\n","Training loss per 100 training steps: 0.01582642402140909\n","Training loss per 100 training steps: 0.016402699777784024\n","Training loss per 100 training steps: 0.016158030789791236\n","Training loss per 100 training steps: 0.01673263006489875\n","Training loss per 100 training steps: 0.016225285578066108\n","Training loss per 100 training steps: 0.01653234875205877\n","Training loss per 100 training steps: 0.01641300443556607\n","Training loss per 100 training steps: 0.016379579729689432\n","Training loss per 100 training steps: 0.016469608923124306\n","Training loss per 100 training steps: 0.016564430139306068\n","Training loss per 100 training steps: 0.01659261385946976\n","Training loss per 100 training steps: 0.01663009615889579\n","Training loss per 100 training steps: 0.017013343789536443\n","Training loss per 100 training steps: 0.017226468216444777\n","Training loss per 100 training steps: 0.0171893765894022\n","Training loss per 100 training steps: 0.017217526422853794\n","Training loss per 100 training steps: 0.017425271366607188\n","Training loss per 100 training steps: 0.01744476656967593\n","Training loss per 100 training steps: 0.017436411162468603\n","Training loss per 100 training steps: 0.017407670686875192\n","Training loss per 100 training steps: 0.017320601684655282\n","Stopping epoch...\n","Training loss epoch: 0.017320601684655282\n","Training accuracy epoch: 0.9943487515014144\n","Validating model...\n","Validation Loss: 0.2238036725404007\n","Validation Accuracy: 0.9536330774615751\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 133.60994015000009 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.18721288787761564\n","Validation Accuracy: 0.9461422707108583\n","Validation duration: 3.0975777500001036 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 81.1%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.80      0.81     12547\n","        test       0.76      0.83      0.79      9012\n","   treatment       0.83      0.84      0.83      9299\n","\n","   micro avg       0.80      0.82      0.81     30858\n","   macro avg       0.80      0.82      0.81     30858\n","weighted avg       0.80      0.82      0.81     30858\n","\n","!!!!!! Starting model number 7 !!!!!!\n","Points in X_train after augmentation: 83202\n","Points in y_train after augmentation: 83202\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8829822540283203\n","Training loss per 100 training steps: 0.3826124471160445\n","Training loss per 100 training steps: 0.2853148246360062\n","Training loss per 100 training steps: 0.2407117448747158\n","Training loss per 100 training steps: 0.2167297122893191\n","Training loss per 100 training steps: 0.19859939308729238\n","Training loss per 100 training steps: 0.18888031088819918\n","Training loss per 100 training steps: 0.17893455556983104\n","Training loss per 100 training steps: 0.17025685985659839\n","Training loss per 100 training steps: 0.16312426408043712\n","Training loss per 100 training steps: 0.156445732129948\n","Training loss per 100 training steps: 0.1508907511370167\n","Training loss per 100 training steps: 0.14658486658085346\n","Training loss per 100 training steps: 0.1427636213964288\n","Training loss per 100 training steps: 0.13877572091449208\n","Training loss per 100 training steps: 0.13500384586322792\n","Training loss per 100 training steps: 0.13246979941145692\n","Training loss per 100 training steps: 0.12957482265285503\n","Training loss per 100 training steps: 0.1263540525945769\n","Training loss per 100 training steps: 0.12393213700351728\n","Training loss per 100 training steps: 0.12148964791353895\n","Training loss per 100 training steps: 0.11936107587908394\n","Training loss per 100 training steps: 0.11740921544169636\n","Training loss per 100 training steps: 0.11512654070395965\n","Training loss per 100 training steps: 0.11315075335750703\n","Training loss per 100 training steps: 0.11169873267841912\n","Training loss per 100 training steps: 0.10955112260453335\n","Training loss epoch: 0.10955112260453335\n","Training accuracy epoch: 0.9656256716154832\n","Validating model...\n","Validation Loss: 0.1626900075027695\n","Validation Accuracy: 0.9548853106889179\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04014401510357857\n","Training loss per 100 training steps: 0.03855012249349073\n","Training loss per 100 training steps: 0.036457999266535784\n","Training loss per 100 training steps: 0.03576708367741063\n","Training loss per 100 training steps: 0.038262088372583436\n","Training loss per 100 training steps: 0.03811738397015218\n","Training loss per 100 training steps: 0.038635320893292024\n","Training loss per 100 training steps: 0.03892519601624719\n","Training loss per 100 training steps: 0.039602830324126655\n","Training loss per 100 training steps: 0.04050512403274548\n","Training loss per 100 training steps: 0.04167247149576019\n","Training loss per 100 training steps: 0.04212533297113648\n","Training loss per 100 training steps: 0.042049673670898194\n","Training loss per 100 training steps: 0.04222228848139149\n","Training loss per 100 training steps: 0.042113781885226007\n","Training loss per 100 training steps: 0.041865579869075714\n","Stopping epoch...\n","Training loss epoch: 0.041865579869075714\n","Training accuracy epoch: 0.9863952384566897\n","Validating model...\n","Validation Loss: 0.17193338753921644\n","Validation Accuracy: 0.9491108929710843\n","Training epoch: 3\n","Training loss per 100 training steps: 0.09874771535396576\n","Training loss per 100 training steps: 0.043675884433865254\n","Training loss per 100 training steps: 0.03857341203004567\n","Training loss per 100 training steps: 0.03813085621037208\n","Training loss per 100 training steps: 0.03727403058010871\n","Training loss per 100 training steps: 0.03689216518172336\n","Training loss per 100 training steps: 0.03758738723082992\n","Training loss per 100 training steps: 0.03684402867877981\n","Training loss per 100 training steps: 0.036194604302648356\n","Training loss per 100 training steps: 0.035248754041106105\n","Training loss per 100 training steps: 0.03486549784452631\n","Training loss per 100 training steps: 0.03439923256807381\n","Training loss per 100 training steps: 0.03410000431626263\n","Training loss per 100 training steps: 0.03375730980624324\n","Training loss per 100 training steps: 0.03344305732661724\n","Training loss per 100 training steps: 0.03319296302558664\n","Training loss per 100 training steps: 0.0328560117402374\n","Training loss per 100 training steps: 0.03243676134215302\n","Training loss per 100 training steps: 0.032421422835256127\n","Training loss per 100 training steps: 0.032148023062136495\n","Training loss per 100 training steps: 0.032235104546060496\n","Training loss per 100 training steps: 0.03213488667847514\n","Stopping epoch...\n","Training loss epoch: 0.03213488667847514\n","Training accuracy epoch: 0.9895011999846003\n","Validating model...\n","Validation Loss: 0.18849395769466828\n","Validation Accuracy: 0.9560427257782468\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01696542650461197\n","Training loss per 100 training steps: 0.02513197348695156\n","Training loss per 100 training steps: 0.022519850749256023\n","Training loss per 100 training steps: 0.02123609205968585\n","Training loss per 100 training steps: 0.021319084458791666\n","Training loss per 100 training steps: 0.022499358613195526\n","Training loss per 100 training steps: 0.022429069769611357\n","Training loss per 100 training steps: 0.023335790357365806\n","Training loss per 100 training steps: 0.023384503649821513\n","Training loss per 100 training steps: 0.023274628339039698\n","Training loss per 100 training steps: 0.023013112077779778\n","Training loss per 100 training steps: 0.023346182080298716\n","Training loss per 100 training steps: 0.023392730692326308\n","Training loss per 100 training steps: 0.023847090922176857\n","Training loss per 100 training steps: 0.02414431856440109\n","Training loss per 100 training steps: 0.024396099176356812\n","Training loss per 100 training steps: 0.02438965916964746\n","Training loss per 100 training steps: 0.02417668711199293\n","Training loss per 100 training steps: 0.02435688322466482\n","Training loss per 100 training steps: 0.02450527020710237\n","Training loss per 100 training steps: 0.024500089052513982\n","Training loss per 100 training steps: 0.024508739880568522\n","Training loss per 100 training steps: 0.02438851716450675\n","Stopping epoch...\n","Training loss epoch: 0.02438851716450675\n","Training accuracy epoch: 0.992201831231209\n","Validating model...\n","Validation Loss: 0.19917235402511313\n","Validation Accuracy: 0.9549100663929388\n","Training epoch: 5\n","Training loss per 100 training steps: 0.003059177892282605\n","Training loss per 100 training steps: 0.019359453026859992\n","Training loss per 100 training steps: 0.018602436350192875\n","Training loss per 100 training steps: 0.019449130519628956\n","Training loss per 100 training steps: 0.020270267089955427\n","Training loss per 100 training steps: 0.019940612681987074\n","Training loss per 100 training steps: 0.01953669152400393\n","Training loss per 100 training steps: 0.019560403358865497\n","Training loss per 100 training steps: 0.01937901609813848\n","Training loss per 100 training steps: 0.02027705685815957\n","Training loss per 100 training steps: 0.02084349251208505\n","Training loss per 100 training steps: 0.02073771566748712\n","Training loss per 100 training steps: 0.02069456628666257\n","Training loss per 100 training steps: 0.020788875792927534\n","Training loss per 100 training steps: 0.020867540211266213\n","Stopping epoch...\n","Training loss epoch: 0.020867540211266213\n","Training accuracy epoch: 0.993161147643592\n","Validating model...\n","Validation Loss: 0.2113987055982088\n","Validation Accuracy: 0.9535942856866279\n","Training epoch: 6\n","Training loss per 100 training steps: 0.002723751589655876\n","Training loss per 100 training steps: 0.01470234760516646\n","Training loss per 100 training steps: 0.013848176888747381\n","Training loss per 100 training steps: 0.01485581619193564\n","Training loss per 100 training steps: 0.013912809962982154\n","Training loss per 100 training steps: 0.014003995074432793\n","Training loss per 100 training steps: 0.014790383111633216\n","Training loss per 100 training steps: 0.015271209325708154\n","Training loss per 100 training steps: 0.015494825374374292\n","Training loss per 100 training steps: 0.015450216837044646\n","Training loss per 100 training steps: 0.01524293916740131\n","Training loss per 100 training steps: 0.015226150389307549\n","Training loss per 100 training steps: 0.015334746657945736\n","Training loss per 100 training steps: 0.0158711305906383\n","Training loss per 100 training steps: 0.016173569612866628\n","Training loss per 100 training steps: 0.016484319614205382\n","Training loss per 100 training steps: 0.016953169322742944\n","Training loss per 100 training steps: 0.017098771241362255\n","Training loss per 100 training steps: 0.017032563305726358\n","Training loss per 100 training steps: 0.01724947952695212\n","Training loss per 100 training steps: 0.017273371331587455\n","Training loss per 100 training steps: 0.01734976275424896\n","Training loss per 100 training steps: 0.017277257246847436\n","Training loss per 100 training steps: 0.0173076571725692\n","Stopping epoch...\n","Training loss epoch: 0.0173076571725692\n","Training accuracy epoch: 0.9942664346179757\n","Validating model...\n","Validation Loss: 0.21539015821241714\n","Validation Accuracy: 0.9538340801027826\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 128.88411698333329 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.18037044283873574\n","Validation Accuracy: 0.9506503446895981\n","Validation duration: 3.1259606333333068 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 82.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.78      0.83      0.80     12548\n","        test       0.79      0.85      0.82      9012\n","   treatment       0.84      0.86      0.85      9301\n","\n","   micro avg       0.80      0.84      0.82     30861\n","   macro avg       0.80      0.85      0.82     30861\n","weighted avg       0.80      0.84      0.82     30861\n","\n","!!!!!! Starting model number 8 !!!!!!\n","Points in X_train after augmentation: 83202\n","Points in y_train after augmentation: 83202\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0014495849609375\n","Training loss per 100 training steps: 0.42280963284544426\n","Training loss per 100 training steps: 0.3025663006513273\n","Training loss per 100 training steps: 0.256340440758736\n","Training loss per 100 training steps: 0.23409228255400932\n","Training loss per 100 training steps: 0.21247773108159948\n","Training loss per 100 training steps: 0.19903493724056767\n","Training loss per 100 training steps: 0.18712008432000238\n","Training loss per 100 training steps: 0.17657806330852294\n","Training loss per 100 training steps: 0.16821919478161818\n","Training loss per 100 training steps: 0.16174801896613736\n","Training loss per 100 training steps: 0.15593996510369793\n","Training loss per 100 training steps: 0.15107514045909234\n","Training loss per 100 training steps: 0.1474779526123936\n","Training loss per 100 training steps: 0.1431659379306593\n","Training loss per 100 training steps: 0.13913944478132462\n","Training loss per 100 training steps: 0.13550824775819495\n","Training loss per 100 training steps: 0.13200504845692648\n","Training loss per 100 training steps: 0.12875034071728464\n","Training loss per 100 training steps: 0.12612986867499784\n","Training loss per 100 training steps: 0.12361822274747654\n","Training loss per 100 training steps: 0.12089859738525735\n","Training loss per 100 training steps: 0.11873394149168988\n","Training loss per 100 training steps: 0.116750894016224\n","Training loss per 100 training steps: 0.11487986883482136\n","Training loss per 100 training steps: 0.11294226626698367\n","Training loss per 100 training steps: 0.11118592802017659\n","Training loss epoch: 0.11118592802017659\n","Training accuracy epoch: 0.9654883714750474\n","Validating model...\n","Validation Loss: 0.16472708204059633\n","Validation Accuracy: 0.9474084000204299\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06005224585533142\n","Training loss per 100 training steps: 0.04321591924797596\n","Training loss per 100 training steps: 0.04184142884911867\n","Training loss per 100 training steps: 0.04191653885255162\n","Training loss per 100 training steps: 0.04083736076256599\n","Training loss per 100 training steps: 0.04068202938942123\n","Training loss per 100 training steps: 0.040935856863909\n","Training loss per 100 training steps: 0.041440488514523637\n","Training loss per 100 training steps: 0.0421647190098324\n","Training loss per 100 training steps: 0.04291092572536332\n","Training loss per 100 training steps: 0.04245737960937058\n","Training loss per 100 training steps: 0.04220052004781646\n","Training loss per 100 training steps: 0.04221262226170464\n","Training loss per 100 training steps: 0.04200515681201253\n","Training loss per 100 training steps: 0.04186173236621763\n","Training loss per 100 training steps: 0.041711425430902706\n","Training loss per 100 training steps: 0.041896359923893095\n","Training loss per 100 training steps: 0.041925289721388606\n","Stopping epoch...\n","Training loss epoch: 0.041925289721388606\n","Training accuracy epoch: 0.9864640414396018\n","Validating model...\n","Validation Loss: 0.16986959368329158\n","Validation Accuracy: 0.9552626501657031\n","Training epoch: 3\n","Training loss per 100 training steps: 0.015246318653225899\n","Training loss per 100 training steps: 0.03586556086786977\n","Training loss per 100 training steps: 0.03353973372899626\n","Training loss per 100 training steps: 0.03324287861007021\n","Training loss per 100 training steps: 0.031213742456726378\n","Training loss per 100 training steps: 0.03140848995271899\n","Training loss per 100 training steps: 0.0317724783611972\n","Training loss per 100 training steps: 0.03199420323443949\n","Training loss per 100 training steps: 0.03218420055961136\n","Training loss per 100 training steps: 0.031921483904224605\n","Training loss per 100 training steps: 0.032668350133709945\n","Training loss per 100 training steps: 0.03250191696212339\n","Training loss per 100 training steps: 0.032478313710556816\n","Training loss per 100 training steps: 0.03271071270666945\n","Training loss per 100 training steps: 0.032588350339719546\n","Stopping epoch...\n","Training loss epoch: 0.032588350339719546\n","Training accuracy epoch: 0.9892320074221697\n","Validating model...\n","Validation Loss: 0.1972409798824168\n","Validation Accuracy: 0.9490257680200216\n","Training epoch: 4\n","Training loss per 100 training steps: 0.015547476708889008\n","Training loss per 100 training steps: 0.030652146145590756\n","Training loss per 100 training steps: 0.026284112449647366\n","Training loss per 100 training steps: 0.025025989650284557\n","Training loss per 100 training steps: 0.025597678378115215\n","Training loss per 100 training steps: 0.02581124321209962\n","Training loss per 100 training steps: 0.026281638523430476\n","Training loss per 100 training steps: 0.026525575399748216\n","Training loss per 100 training steps: 0.026647986267192218\n","Training loss per 100 training steps: 0.02787969756269875\n","Training loss per 100 training steps: 0.027972088395999364\n","Training loss per 100 training steps: 0.02783497083700811\n","Training loss per 100 training steps: 0.02829114813367285\n","Training loss per 100 training steps: 0.027948817257450135\n","Training loss per 100 training steps: 0.02789534203745398\n","Training loss per 100 training steps: 0.02811428427315881\n","Training loss per 100 training steps: 0.028265637930524508\n","Training loss per 100 training steps: 0.027854589911915258\n","Training loss per 100 training steps: 0.027822856610812307\n","Training loss per 100 training steps: 0.027582663904402997\n","Training loss per 100 training steps: 0.027517826246588245\n","Training loss per 100 training steps: 0.02746335420545203\n","Training loss per 100 training steps: 0.027385014637625365\n","Training loss per 100 training steps: 0.02734170271734242\n","Stopping epoch...\n","Training loss epoch: 0.02734170271734242\n","Training accuracy epoch: 0.991291251440042\n","Validating model...\n","Validation Loss: 0.20332794742244478\n","Validation Accuracy: 0.9558581514615886\n","Training epoch: 5\n","Training loss per 100 training steps: 0.040941230952739716\n","Training loss per 100 training steps: 0.019873311083837605\n","Training loss per 100 training steps: 0.02007907279853973\n","Training loss per 100 training steps: 0.019924467039275976\n","Training loss per 100 training steps: 0.01805119517205882\n","Training loss per 100 training steps: 0.018889244858216414\n","Training loss per 100 training steps: 0.01962374665111167\n","Training loss per 100 training steps: 0.019952310641633664\n","Training loss per 100 training steps: 0.02006828116448352\n","Training loss per 100 training steps: 0.019749385200866748\n","Training loss per 100 training steps: 0.019879045399286404\n","Training loss per 100 training steps: 0.020269595112849946\n","Training loss per 100 training steps: 0.019957458617171114\n","Training loss per 100 training steps: 0.020167022764131206\n","Training loss per 100 training steps: 0.02018130818765968\n","Training loss per 100 training steps: 0.020747120516785147\n","Training loss per 100 training steps: 0.02098008232159356\n","Training loss per 100 training steps: 0.021187197491825\n","Training loss per 100 training steps: 0.021624554244365476\n","Training loss per 100 training steps: 0.02184429738748606\n","Training loss per 100 training steps: 0.021859255572047917\n","Training loss per 100 training steps: 0.02188131722883374\n","Training loss per 100 training steps: 0.021881229569722917\n","Training loss per 100 training steps: 0.021916592791901154\n","Stopping epoch...\n","Training loss epoch: 0.021916592791901154\n","Training accuracy epoch: 0.9929445678030541\n","Validating model...\n","Validation Loss: 0.20400673251405552\n","Validation Accuracy: 0.9569787001288371\n","Training epoch: 6\n","Training loss per 100 training steps: 0.021588250994682312\n","Training loss per 100 training steps: 0.012500092907610469\n","Training loss per 100 training steps: 0.014252458112192716\n","Training loss per 100 training steps: 0.013986941343161781\n","Training loss per 100 training steps: 0.014486036462342934\n","Training loss per 100 training steps: 0.014495092667657845\n","Training loss per 100 training steps: 0.014716046076646066\n","Training loss per 100 training steps: 0.015002141446081096\n","Training loss per 100 training steps: 0.014954301253436122\n","Training loss per 100 training steps: 0.014988041556610588\n","Training loss per 100 training steps: 0.014826683162178446\n","Training loss per 100 training steps: 0.015119022509374138\n","Training loss per 100 training steps: 0.015522898722972743\n","Training loss per 100 training steps: 0.015708456383133985\n","Training loss per 100 training steps: 0.015578937850397965\n","Training loss per 100 training steps: 0.01568283954897643\n","Training loss per 100 training steps: 0.015594238992519768\n","Training loss per 100 training steps: 0.015467810782050999\n","Training loss per 100 training steps: 0.015537339866726358\n","Training loss per 100 training steps: 0.015509084958015064\n","Training loss per 100 training steps: 0.01532961524078629\n","Training loss per 100 training steps: 0.015622100290482858\n","Training loss per 100 training steps: 0.016021808845423473\n","Training loss per 100 training steps: 0.016098168963978858\n","Training loss per 100 training steps: 0.016166787742027528\n","Training loss per 100 training steps: 0.016206477108978067\n","Training loss per 100 training steps: 0.016118436678834086\n","Training loss epoch: 0.016118436678834086\n","Training accuracy epoch: 0.9950520062325203\n","Validating model...\n","Validation Loss: 0.2146888319161031\n","Validation Accuracy: 0.9561339298966758\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 137.72177719999988 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.18926556571817924\n","Validation Accuracy: 0.9438891725054955\n","Validation duration: 3.131263383333377 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 80.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.81      0.80     12548\n","        test       0.75      0.88      0.81      9012\n","   treatment       0.78      0.82      0.80      9301\n","\n","   micro avg       0.78      0.83      0.80     30861\n","   macro avg       0.78      0.84      0.80     30861\n","weighted avg       0.78      0.83      0.80     30861\n","\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1aa98f24e0024ff9ba67e1dddee39c08":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d67670e9322c40e2a4f67642052ad546","placeholder":"","style":"IPY_MODEL_5c8d5f8e35e042ce937e4f5d5ee39578","value":"Downloading pytorch_model.bin:   7%"}},"2c4fd583a8714239b7d9f6e99654f8cb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"396b64ee561c479289f0238ae6bea65d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4c1ec8567f3478cb9ee6d68ded7bb19","placeholder":"","style":"IPY_MODEL_907861512bcb48cc96a447265d1f74d6","value":" 31.3M/422M [00:00&lt;00:09, 42.6MB/s]"}},"5c8d5f8e35e042ce937e4f5d5ee39578":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6dfe806144ec40bb92d63fc132ecbe94":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c4fd583a8714239b7d9f6e99654f8cb","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b163a08dddc7447da9cf9d104dbac0c0","value":32870400}},"8913f1d345c045c99f3edd59a93a97a2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"907861512bcb48cc96a447265d1f74d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b163a08dddc7447da9cf9d104dbac0c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b538a6c7a2fe45f9a51565f066469c7c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1aa98f24e0024ff9ba67e1dddee39c08","IPY_MODEL_6dfe806144ec40bb92d63fc132ecbe94","IPY_MODEL_396b64ee561c479289f0238ae6bea65d"],"layout":"IPY_MODEL_8913f1d345c045c99f3edd59a93a97a2"}},"c4c1ec8567f3478cb9ee6d68ded7bb19":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d67670e9322c40e2a4f67642052ad546":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9f0b9ae8d0546db80f9cb12875bbcef":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_03865262b13d4efd97c723b0fdd9dd63","IPY_MODEL_6b7cea4a2e8d409684046d9948f604ed","IPY_MODEL_f3b4bf41e84f493ebd336d2f8ebef0fa"],"layout":"IPY_MODEL_419647acffe44cf8af8c3cdc2ac5881e"}},"03865262b13d4efd97c723b0fdd9dd63":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c1cf6e4b4f845fbbcb1a69b6a831898","placeholder":"","style":"IPY_MODEL_00b9ceb383a147afb22a910524f78027","value":"Downloading pytorch_model.bin: 100%"}},"6b7cea4a2e8d409684046d9948f604ed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_779834bc12504206ba8290dc958e1b9a","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3add213c02694bbea7b17ae5c9ef590c","value":442221694}},"f3b4bf41e84f493ebd336d2f8ebef0fa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bdccdad425e3455a93f14473e9ea089e","placeholder":"","style":"IPY_MODEL_cd969dfca6fa48e59c91e149dda1f46b","value":" 422M/422M [00:07&lt;00:00, 64.7MB/s]"}},"419647acffe44cf8af8c3cdc2ac5881e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c1cf6e4b4f845fbbcb1a69b6a831898":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00b9ceb383a147afb22a910524f78027":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"779834bc12504206ba8290dc958e1b9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3add213c02694bbea7b17ae5c9ef590c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bdccdad425e3455a93f14473e9ea089e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd969dfca6fa48e59c91e149dda1f46b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4540e38595734cf380d94e6f61cbb8ea":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_49241c6fd92f4e899c6cb9f91e717bd7","IPY_MODEL_45608647c0144eb688eb1367cd18b6b8","IPY_MODEL_5a39acef2b134c2591bdb849fef7d623"],"layout":"IPY_MODEL_f8be1d6450f744a0b6295c5fb2f76de1"}},"49241c6fd92f4e899c6cb9f91e717bd7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd5596ef8d434aa693b50f8956c14dbe","placeholder":"","style":"IPY_MODEL_8b60a63c41ff4741bb5e301cc2ccdd85","value":"Downloading pytorch_model.bin: 100%"}},"45608647c0144eb688eb1367cd18b6b8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_84b7cfe97c0541e48dd33cd5ebf3cb66","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e9d7ebf6b3da4c30a38cc01da2637a9d","value":442221694}},"5a39acef2b134c2591bdb849fef7d623":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f47f45870cec4ef89c8cbb95058e49cc","placeholder":"","style":"IPY_MODEL_04123fb9f52c4dd7b2f50a488e995bd3","value":" 422M/422M [00:11&lt;00:00, 42.0MB/s]"}},"f8be1d6450f744a0b6295c5fb2f76de1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd5596ef8d434aa693b50f8956c14dbe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b60a63c41ff4741bb5e301cc2ccdd85":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"84b7cfe97c0541e48dd33cd5ebf3cb66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9d7ebf6b3da4c30a38cc01da2637a9d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f47f45870cec4ef89c8cbb95058e49cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04123fb9f52c4dd7b2f50a488e995bd3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"908d38bb2069469e86b2a9338735ea85":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7a2d330ca7d840078a3ead3b7295957f","IPY_MODEL_49c05e88700b4280bfe2910723bf7dfb","IPY_MODEL_8cb8e6767b3a443fa27734bbf4e6ee2f"],"layout":"IPY_MODEL_288dedb070714051b9c0c9d89905007f"}},"7a2d330ca7d840078a3ead3b7295957f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ae59914c7ff4c20b04c962c3f8ac275","placeholder":"","style":"IPY_MODEL_800cb31c06854f188635cd1e173a7329","value":"Downloading: 100%"}},"49c05e88700b4280bfe2910723bf7dfb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a096ae440f114c639fb725b4e8c16d97","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_53287cb9687e4ec792b7d03379057f4b","value":442221694}},"8cb8e6767b3a443fa27734bbf4e6ee2f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae5569ff5a654eb79e05bd513bd9c7eb","placeholder":"","style":"IPY_MODEL_d220d0b9129f463e86acd33cb6351e4e","value":" 442M/442M [00:10&lt;00:00, 41.2MB/s]"}},"288dedb070714051b9c0c9d89905007f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ae59914c7ff4c20b04c962c3f8ac275":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"800cb31c06854f188635cd1e173a7329":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a096ae440f114c639fb725b4e8c16d97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53287cb9687e4ec792b7d03379057f4b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ae5569ff5a654eb79e05bd513bd9c7eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d220d0b9129f463e86acd33cb6351e4e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"65a5364e7cb946558f037973127bbee2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8dd40c66167a47bcb40e64e3e81c1a28","IPY_MODEL_72d26184d1ca4882b74ccccaa6542f2f","IPY_MODEL_297c75c68bdf4e7d9b2a92b67a9a3a69"],"layout":"IPY_MODEL_bb79c41b0232465287119cdfbb454937"}},"8dd40c66167a47bcb40e64e3e81c1a28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c613aed72374a31bb8ebc8439359402","placeholder":"","style":"IPY_MODEL_a80baad4a02f4bc68e7fee3278c94162","value":"Downloading: 100%"}},"72d26184d1ca4882b74ccccaa6542f2f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_607144b6c030463caa32a45112de63dc","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9cd598e0c3be4a349c1816e7b3472bd9","value":442221694}},"297c75c68bdf4e7d9b2a92b67a9a3a69":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0fc6b995cc04e3e84401148965aa57c","placeholder":"","style":"IPY_MODEL_62dff514a5154d5e8ac66208f12d1074","value":" 442M/442M [00:06&lt;00:00, 69.0MB/s]"}},"bb79c41b0232465287119cdfbb454937":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c613aed72374a31bb8ebc8439359402":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a80baad4a02f4bc68e7fee3278c94162":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"607144b6c030463caa32a45112de63dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cd598e0c3be4a349c1816e7b3472bd9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f0fc6b995cc04e3e84401148965aa57c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62dff514a5154d5e8ac66208f12d1074":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3b7323cf80084dddb8c1a520523170e6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d749038c8dee42aeb42b9198e13b490d","IPY_MODEL_ad006cfb44774b099da11d1ebb9bd63a","IPY_MODEL_f8875275143546a7860d72e31edccfe5"],"layout":"IPY_MODEL_e7338e015ed54b80978a15dc25e21f11"}},"d749038c8dee42aeb42b9198e13b490d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7c09472bf1245a6a4373d24df9294f8","placeholder":"","style":"IPY_MODEL_ade7bd522df9481e9393e8fc4466a3dc","value":""}},"ad006cfb44774b099da11d1ebb9bd63a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff858519fd9f482c8b2fbe2c55aacae1","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_27eba65c3a894f9c95ca703f16f029cf","value":0}},"f8875275143546a7860d72e31edccfe5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_987f4c8c81224b5c85254f53b6805925","placeholder":"","style":"IPY_MODEL_bbad552ca57645e68eaa039144ada49f","value":" 0/0 [00:00&lt;?, ?it/s]"}},"e7338e015ed54b80978a15dc25e21f11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7c09472bf1245a6a4373d24df9294f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ade7bd522df9481e9393e8fc4466a3dc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ff858519fd9f482c8b2fbe2c55aacae1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"27eba65c3a894f9c95ca703f16f029cf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"987f4c8c81224b5c85254f53b6805925":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbad552ca57645e68eaa039144ada49f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df65ac411f7445309329a28cc2e33c59":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6e461950e0cf4ce29c4b4085e79730c8","IPY_MODEL_56a57aa2aed34ef7b072b335e3e40d72","IPY_MODEL_5f2394d47e2e4eb7bfcc923215e9f37a"],"layout":"IPY_MODEL_803b80c9864b467c8e109def365995dd"}},"6e461950e0cf4ce29c4b4085e79730c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6835fd4ff179464a9f7330d6be2d9cd3","placeholder":"","style":"IPY_MODEL_40220d404dc946569b6387d066987b76","value":"Downloading: 100%"}},"56a57aa2aed34ef7b072b335e3e40d72":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f387e763931420c845d739b81caa89b","max":385,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b0f048a3e0bd437ca0020da6a69a0e82","value":385}},"5f2394d47e2e4eb7bfcc923215e9f37a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1e88e93edc54a4b8d071415434c9e9a","placeholder":"","style":"IPY_MODEL_ee41b1973be54488ab3e30183220e8ad","value":" 385/385 [00:00&lt;00:00, 16.0kB/s]"}},"803b80c9864b467c8e109def365995dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6835fd4ff179464a9f7330d6be2d9cd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40220d404dc946569b6387d066987b76":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f387e763931420c845d739b81caa89b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0f048a3e0bd437ca0020da6a69a0e82":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c1e88e93edc54a4b8d071415434c9e9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee41b1973be54488ab3e30183220e8ad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa34af90bcc04ade8b334782828fc62b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e77a320267b943a8b0085e4a73510080","IPY_MODEL_fc6b18b894374ea3a28611ce694ca4b6","IPY_MODEL_3616f57241ee43e0b09ec074672df150"],"layout":"IPY_MODEL_04af653d421a4f30bfd83a4ce9e41c94"}},"e77a320267b943a8b0085e4a73510080":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4641bd47b0ea44a2903400718b3e7436","placeholder":"","style":"IPY_MODEL_ee7428bb7dbb410bb562f65400eb1fa9","value":"Downloading: 100%"}},"fc6b18b894374ea3a28611ce694ca4b6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e5c69cfc28145e8bebfbd62b8667146","max":227845,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2b9b038b885440a691c22b54e3392335","value":227845}},"3616f57241ee43e0b09ec074672df150":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15625f38cd0443f58226c2b4f60aecd6","placeholder":"","style":"IPY_MODEL_fe3ab85597514df0a57d74bbab41b700","value":" 228k/228k [00:00&lt;00:00, 619kB/s]"}},"04af653d421a4f30bfd83a4ce9e41c94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4641bd47b0ea44a2903400718b3e7436":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee7428bb7dbb410bb562f65400eb1fa9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e5c69cfc28145e8bebfbd62b8667146":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b9b038b885440a691c22b54e3392335":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"15625f38cd0443f58226c2b4f60aecd6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe3ab85597514df0a57d74bbab41b700":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b225be86d07d4db9987d26aaab4848b1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6124d1d32ec444c9bbe4bd62b41ec435","IPY_MODEL_1d5bb6cd6c6646acb38c164ebcb1ad27","IPY_MODEL_8aadb65a590f41f08a9f2f8f0f652ad3"],"layout":"IPY_MODEL_d3a245bd74264a4a9c02a232aafce636"}},"6124d1d32ec444c9bbe4bd62b41ec435":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e24de523e5646f38725edf6482aa433","placeholder":"","style":"IPY_MODEL_d7c912c2bc89499eb7b143a5d230e434","value":"Downloading: 100%"}},"1d5bb6cd6c6646acb38c164ebcb1ad27":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e811917f717a4c7ebbc6ff7baecfca55","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8d04b0ff93c4474e9721e9d84ca0b6ed","value":442221694}},"8aadb65a590f41f08a9f2f8f0f652ad3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1104db95d33d42f59a92904f7cfc06e9","placeholder":"","style":"IPY_MODEL_cabc71478c534ef3ae57587ee2a50b21","value":" 442M/442M [00:06&lt;00:00, 69.0MB/s]"}},"d3a245bd74264a4a9c02a232aafce636":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e24de523e5646f38725edf6482aa433":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7c912c2bc89499eb7b143a5d230e434":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e811917f717a4c7ebbc6ff7baecfca55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d04b0ff93c4474e9721e9d84ca0b6ed":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1104db95d33d42f59a92904f7cfc06e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cabc71478c534ef3ae57587ee2a50b21":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}