{"cells":[{"cell_type":"markdown","metadata":{"id":"FFh7WVoJH5dr"},"source":["Adapted from [ner_with_bilstm_and_crf](https://www.kaggle.com/nikkisharma536/ner-with-bilstm-and-crf/notebook)\n","Altigran Soares da Silva\n","IComp/UFAM - 15/03/2021\n"],"id":"FFh7WVoJH5dr"},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zvip_oC0j5-y","executionInfo":{"status":"ok","timestamp":1667797803918,"user_tz":240,"elapsed":75692,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"}},"outputId":"7bb02e7c-7f93-4ea8-cac1-f74c647c7bac"},"outputs":[{"output_type":"stream","name":"stdout","text":["Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 30.6 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n","\u001b[K     |████████████████████████████████| 5.5 MB 27.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n","\u001b[K     |████████████████████████████████| 163 kB 60.4 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 66.0 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.24.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 2.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=cd490b82c7832ac6dd39c718788b1d89298dcefa7dc48e24e50345f1932100d9\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n","[26483, 24534]\n","[3, 3]\n","[2848, 10024, 5874, 20329, 6229, 11620, 6197, 4706, 18921, 17253, 6514, 26123]\n","[6, 4, 4, 4, 4, 4, 3, 1, 5, 5, 5, 3]\n","[20375, 18072, 6274]\n","[3, 3, 3]\n","11207\n","0\n","I-treatment\n","1.15\n","28388\n","7\n"]}],"source":["# Uncomment this cell if you want to load saved data\n","\n","# Re-import necessary libs\n","import pandas as pd\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","import pickle, math\n","from requests import get\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import random\n","import time\n","%tensorflow_version 2.x\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import torch\n","from torch import cuda\n","from torch.utils.data import Dataset, DataLoader\n","!pip install sentencepiece\n","!pip install transformers\n","from transformers import BertForTokenClassification, AutoTokenizer\n","import matplotlib.pyplot as plt\n","!pip install seqeval\n","from seqeval.metrics import f1_score, classification_report\n","\n","BACKUP_FOLDER_ID = '1YWR4Ip8w94RwFMyMtNpRa9M0FpiJtqd5'\n","notebook_filename = get('http://172.28.0.2:9000/api/sessions').json()[0]['name'].replace(\"_CWR\",\"\")\n","\n","X_train_filename = f'{notebook_filename}_X_train.csv'\n","y_train_filename = f'{notebook_filename}_y_train.csv'\n","X_dev_filename = f'{notebook_filename}_X_dev.csv'\n","y_dev_filename = f'{notebook_filename}_y_dev.csv'\n","X_test_filename = f'{notebook_filename}_X_test.csv'\n","y_test_filename = f'{notebook_filename}_y_test.csv'\n","\n","word2idx_filename = f'{notebook_filename}_word2idx.pkl'\n","idx2word_filename = f'{notebook_filename}_idx2word.pkl'\n","tag2idx_filename = f'{notebook_filename}_tag2idx.pkl'\n","idx2tag_filename = f'{notebook_filename}_idx2tag.pkl'\n","\n","others_filename = f'{notebook_filename}_others.pkl'\n","\n","# Re-get important variables\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","def get_backup_files_ids(folder_id):\n","  file_list = drive.ListFile({'q': \"'{}' in parents and trashed=false\".format(folder_id)}).GetList()\n","  return file_list\n","\n","def load_backup_dataset(file_id):\n","  downloaded = drive.CreateFile({'id':file_id})\n","  downloaded.GetContentFile(f\"{file_id}.csv\")\n","\n","  dataset = pd.read_csv(f\"{file_id}.csv\", encoding=\"latin1\")\n","  dataset = dataset.values.tolist()\n","  dataset = [ [ int(word) for word in sentence if str(word) != 'nan' ] for sentence in dataset]\n","  return dataset\n","\n","def load_backup_dict(file_id):\n","  downloaded = drive.CreateFile({'id':file_id})\n","  downloaded.GetContentFile(f\"{file_id}.pkl\")\n","\n","  dict_file = open(f\"{file_id}.pkl\", \"rb\")\n","  out_dict = pickle.load(dict_file)\n","  return out_dict\n","\n","backup_file_list = get_backup_files_ids(BACKUP_FOLDER_ID)\n","\n","X_train_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == X_train_filename][0]['id']\n","y_train_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == y_train_filename][0]['id']\n","X_dev_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == X_dev_filename][0]['id']\n","y_dev_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == y_dev_filename][0]['id']\n","X_test_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == X_test_filename][0]['id']\n","y_test_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == y_test_filename][0]['id']\n","\n","word2idx_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == word2idx_filename][0]['id']\n","idx2word_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == idx2word_filename][0]['id']\n","tag2idx_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == tag2idx_filename][0]['id']\n","idx2tag_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == idx2tag_filename][0]['id']\n","\n","others_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == others_filename][0]['id']\n","\n","X_train = load_backup_dataset(X_train_file_id)\n","y_train = load_backup_dataset(y_train_file_id)\n","X_dev = load_backup_dataset(X_dev_file_id)\n","y_dev = load_backup_dataset(y_dev_file_id)\n","X_test = load_backup_dataset(X_test_file_id)\n","y_test = load_backup_dataset(y_test_file_id)\n","\n","word2idx = load_backup_dict(word2idx_file_id)\n","idx2word = load_backup_dict(idx2word_file_id)\n","tag2idx = load_backup_dict(tag2idx_file_id)\n","idx2tag = load_backup_dict(idx2tag_file_id)\n","\n","others = load_backup_dict(others_file_id)\n","\n","n_words = others[\"n_words\"]\n","n_tags = others[\"n_tags\"]\n","\n","# Check some points after loading data to see if they match the ones before saving\n","print(X_train[0])\n","print(y_train[0])\n","print(X_dev[0])\n","print(y_dev[0])\n","print(X_test[0])\n","print(y_test[0])\n","print(word2idx['comprehension'])\n","print(tag2idx['B-treatment'])\n","print(idx2tag[2])\n","print(idx2word[100])\n","print(n_words)\n","print(n_tags)"],"id":"zvip_oC0j5-y"},{"cell_type":"code","execution_count":2,"metadata":{"id":"2wRVTj71hovp","colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["a597acaf35a1469185fc7a89fe70dde4","93b9b161283244089549759c9c0fd24a","67b58a95215347868df26cb778b575a8","de81c01f633a408db46b9b73ffbc6bec","283f3d23a7904c4b927680f96bc7b550","ff9d0bffaabb443cad356406d7256347","04727ef5b45b493bbef6ba131bd5bd52","29ca83bef6ca47699e97bc36371dcc67","ece7ebd9778849e6a541e12f0a184714","38c852b918d743e3ade15bdb8d403522","1291306c22ec461d836c3ef46b7fa8b2","0dfeadadc3c74f79a8b5b4882ab8654e","a75016ef8f60474482afb2b1da6971c1","597cc625aca343e0b241b27fbab118e7","479116aa11c441518b8b2e4d01dec3c2","39801022ab7d48b093537995f128a38e","69f0a6b9ca1b4e1dbdff3e02a07aeb5c","0f085775a15840dabeb079575d3dd116","420fe38e2d3e4b1b92bcdff4fc610aea","db3eb91106ec460fb8041f521450cd40","3c12afde4ad2463e9706a654626590a2","6c51a30f67d0435cbd25b0cea0abd992"]},"executionInfo":{"status":"ok","timestamp":1667797815192,"user_tz":240,"elapsed":11279,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"}},"outputId":"5344c5ae-a259-41c0-83c5-466022925268"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/385 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a597acaf35a1469185fc7a89fe70dde4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/228k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dfeadadc3c74f79a8b5b4882ab8654e"}},"metadata":{}}],"source":["tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n","\n","from transformers import pipeline\n","from future.utils import iteritems\n","\n","# Augmentation function using entity replacement technique.\n","# It will generate a new dataset, with X% more points based on\n","# the original dataset. E.g.: if you set augmentation percentage as 0.5 and dataset has\n","# 1000 points, it will generate a dataset with 1500 points.\n","\n","def generate_sentences(dataset, labels, augmented_set_size_percentage):\n","    if augmented_set_size_percentage < 0:\n","        raise Exception(\"Invalid augmented set size percentage\")\n","\n","    unmasker = pipeline('fill-mask', model='allenai/scibert_scivocab_uncased')\n","    \n","    number_of_new_sentences = math.ceil(augmented_set_size_percentage * len(dataset))\n","\n","    valid_dataset_idxs = [i for i,labels in enumerate(labels) if tag2idx[\"O\"] in labels]\n","    valid_dataset_sents = [sent for i,sent in enumerate(dataset) if i in valid_dataset_idxs]\n","    valid_dataset_labels = [labels for i,labels in enumerate(labels) if i in valid_dataset_idxs]\n","\n","    random_idxs = np.random.choice(len(valid_dataset_sents), number_of_new_sentences, replace=True)\n","    base_labels = [valid_dataset_labels[i] for i in random_idxs]\n","\n","    if not all([tag2idx[\"O\"] in labels for labels in base_labels]):\n","        raise Exception(\"Sentence without 'O'-tagged token in the dataset!!!\")\n","\n","    base_sequences = [valid_dataset_sents[i] for i in random_idxs]\n","\n","    new_sequences = []\n","    new_labels = []\n","    \n","    for k, sequence in enumerate(base_sequences):\n","      sequence_str = [idx2word[word] for word in sequence]\n","\n","      # check max number of tokens bert support and truncate sentence before augmentation\n","      # augmented sentence will be shorter than original sentence if higher than bert limit\n","      encoding = tokenizer(sequence_str,\n","                             is_split_into_words=True, \n","                             return_offsets_mapping=True, \n","                             truncation=True, \n","                             max_length=512)\n","      \n","      max_n_of_tokens = len([mapping for mapping in encoding[\"offset_mapping\"] if mapping[0] == 0 and mapping[1] != 0])\n","\n","      truncated_sequence_str = sequence_str[:max_n_of_tokens]\n","      truncated_labels = base_labels[k][:max_n_of_tokens]\n","\n","      # print(len(sequence_str),len(truncated_sequence_str),len(base_labels[k]),len(truncated_labels))\n","\n","      replaceable_indices = [i for i,label in enumerate(truncated_labels) if label == tag2idx[\"O\"]]\n","      replace_percent = round(random.uniform(0.1, 1), 1)\n","      replace_qty = max(math.floor(replace_percent*len(replaceable_indices)), 1)\n","      replace_indices = random.sample(replaceable_indices, k=replace_qty)\n","      replace_indices.sort()\n","\n","      masked_text_list = [\"[MASK]\" if i in replace_indices else word for i,word in enumerate(truncated_sequence_str)]\n","      new_mask_sent = ' '.join(masked_text_list)\n","      augmented_text_list = unmasker(new_mask_sent)\n","\n","      augmented_sentence = truncated_sequence_str.copy()\n","      if len(replace_indices) == 1:\n","        augmented_text_list = [augmented_text_list]\n","\n","      for i,index in enumerate(replace_indices):\n","        available_words = [word[\"token_str\"] for word in augmented_text_list[i] if word[\"token_str\"] != truncated_sequence_str[index]]\n","        new_word = random.choice(available_words)\n","        if new_word != \"[UNK]\":\n","          augmented_sentence[index] = new_word\n","\n","      # print(\"Original text->\",len(sequence_str),sequence_str)\n","      # print(\"Augmented text->\",len(sequence_str),augmented_sentence)\n","\n","      new_sequences.append(augmented_sentence)\n","      new_labels.append(truncated_labels)\n","\n","    all_words = list(set([word for seq in new_sequences for word in seq]))\n","    updated_word2idx = word2idx.copy()\n","    updated_idx2word = idx2word.copy()\n","    for word in all_words:\n","      try:\n","        updated_word2idx[word]\n","      except:\n","        updated_word2idx[word] = len(updated_word2idx)\n","    updated_idx2word = {i: w for w, i in iteritems(updated_word2idx)}\n","\n","    new_sequences = [[updated_word2idx[word] for word in seq] for seq in new_sequences]\n","\n","    augmented_X_train = dataset + new_sequences\n","    augmented_y_train = labels + new_labels\n","\n","    print(f\"Points in X_train after augmentation: {len(augmented_X_train)}\")\n","    print(f\"Points in y_train after augmentation: {len(augmented_y_train)}\")\n","\n","    return augmented_X_train, augmented_y_train, updated_word2idx, updated_idx2word"],"id":"2wRVTj71hovp"},{"cell_type":"code","execution_count":3,"metadata":{"id":"mYHzTnzZZfBg","executionInfo":{"status":"ok","timestamp":1667797817989,"user_tz":240,"elapsed":2801,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"}}},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n","\n","class dataset(Dataset):\n","  def __init__(self, dataframe, tokenizer, max_len):\n","        self.len = len(dataframe)\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","  def __getitem__(self, index):\n","        # step 1: get the sentence and word labels\n","        sentence = self.data.sentence[index]\n","        word_labels = self.data.word_labels[index].split(\",\") \n","\n","        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n","        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n","        encoding = self.tokenizer(sentence,\n","                             is_split_into_words=True, \n","                             return_offsets_mapping=True, \n","                             padding='max_length', \n","                             truncation=True, \n","                             max_length=self.max_len)\n","        \n","        # step 3: create token labels only for first word pieces of each tokenized word\n","        labels = [tag2idx[label] for label in word_labels] \n","        # code based on https://huggingface.co/transformers/custom_datasets.html#tok-ner\n","        # create an empty array of -100 of length max_length\n","        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n","        \n","        # set only labels whose first offset position is 0 and the second is not 0\n","        i = 0\n","        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n","          if mapping[0] == 0 and mapping[1] != 0:\n","            # overwrite label\n","            encoded_labels[idx] = labels[i]\n","            i += 1\n","\n","        # step 4: turn everything into PyTorch tensors\n","        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n","        item['labels'] = torch.as_tensor(encoded_labels)\n","        \n","        return item\n","\n","  def __len__(self):\n","        return self.len"],"id":"mYHzTnzZZfBg"},{"cell_type":"code","execution_count":4,"metadata":{"id":"d8H1s-6b_-pM","executionInfo":{"status":"ok","timestamp":1667797817990,"user_tz":240,"elapsed":10,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"}}},"outputs":[],"source":["# some configuration variables\n","LEARNING_RATE = 5e-05\n","MAX_GRAD_NORM = 10\n","TRAINING_STOP_LOSS_PERCENTAGE = 1\n","\n","# Model creation function\n","def create_model(maxlen, n_labels, training_set, testing_set, validation_set):\n","  device = 'cuda' if cuda.is_available() else 'cpu'\n","  print(\"Device: \", device)\n","\n","  model = BertForTokenClassification.from_pretrained('allenai/scibert_scivocab_uncased', num_labels=n_labels)\n","  model.to(device)\n","\n","  optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n","\n","  TRAIN_BATCH_SIZE = round(0.05*len(training_set))\n","  if TRAIN_BATCH_SIZE > 32:\n","    TRAIN_BATCH_SIZE = 32\n","  if TRAIN_BATCH_SIZE < 10:\n","    TRAIN_BATCH_SIZE = 10\n","\n","  VALID_BATCH_SIZE = round(0.1*len(validation_set))\n","  if VALID_BATCH_SIZE > 32:\n","    VALID_BATCH_SIZE = 32\n","  if VALID_BATCH_SIZE < 10:\n","    VALID_BATCH_SIZE = 10\n","\n","  train_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                  'shuffle': True,\n","                  'num_workers': 0\n","                  }\n","\n","  test_params = {'batch_size': VALID_BATCH_SIZE,\n","                  'shuffle': True,\n","                  'num_workers': 0\n","                  }\n","\n","  training_loader = DataLoader(training_set, **train_params)\n","  testing_loader = DataLoader(testing_set, **test_params)\n","  validation_loader = DataLoader(validation_set, **test_params)\n","\n","  return model, device, optimizer, training_loader, testing_loader, validation_loader"],"id":"d8H1s-6b_-pM"},{"cell_type":"code","execution_count":5,"metadata":{"id":"cjp-jXx4AmiV","executionInfo":{"status":"ok","timestamp":1667797817990,"user_tz":240,"elapsed":9,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"}}},"outputs":[],"source":["# Model training function\n","def train(model, device, optimizer, training_loader, epoch, training_stop_loss_percentage):\n","    tr_loss, tr_accuracy = 0, 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","    tr_preds, tr_labels = [], []\n","    losses = []\n","    # put model in training mode\n","    model.train()\n","    \n","    for idx, batch in enumerate(training_loader):\n","        \n","        ids = batch['input_ids'].to(device, dtype = torch.long)\n","        mask = batch['attention_mask'].to(device, dtype = torch.long)\n","        labels = batch['labels'].to(device, dtype = torch.long)\n","\n","        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels, return_dict = False)\n","        tr_loss += loss.item()\n","\n","        nb_tr_steps += 1\n","        nb_tr_examples += labels.size(0)\n","        \n","        if idx % 100==0:\n","            loss_step = tr_loss/nb_tr_steps\n","            print(f\"Training loss per 100 training steps: {loss_step}\")\n","            losses.append(loss_step)\n","            last_5_losses = losses[-5:]\n","            loss_min = min(last_5_losses)\n","            loss_max = max(last_5_losses)\n","            if len(last_5_losses) > 1 and (loss_max - loss_min)/loss_max < training_stop_loss_percentage/100:\n","              print(\"Stopping epoch...\")\n","              break\n","           \n","        # compute training accuracy\n","        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","        \n","        # only compute accuracy at active labels\n","        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n","        \n","        labels = torch.masked_select(flattened_targets, active_accuracy)\n","        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","        \n","        tr_labels.extend(labels)\n","        tr_preds.extend(predictions)\n","\n","        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n","        tr_accuracy += tmp_tr_accuracy\n","    \n","        # gradient clipping\n","        torch.nn.utils.clip_grad_norm_(\n","            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n","        )\n","        \n","        # backward pass\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    epoch_loss = tr_loss / nb_tr_steps\n","    tr_accuracy = tr_accuracy / nb_tr_steps\n","    print(f\"Training loss epoch: {epoch_loss}\")\n","    print(f\"Training accuracy epoch: {tr_accuracy}\")"],"id":"cjp-jXx4AmiV"},{"cell_type":"code","execution_count":6,"metadata":{"id":"JvdztU6FA8Bd","executionInfo":{"status":"ok","timestamp":1667797817990,"user_tz":240,"elapsed":9,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"}}},"outputs":[],"source":["# Model testing function\n","def test(model, device, testing_loader):\n","    print(\"Validating model...\")\n","    # put model in evaluation mode\n","    model.eval()\n","    \n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_examples, nb_eval_steps = 0, 0\n","    eval_preds, eval_labels = [], []\n","    \n","    with torch.no_grad():\n","        for idx, batch in enumerate(testing_loader):\n","            \n","            ids = batch['input_ids'].to(device, dtype = torch.long)\n","            mask = batch['attention_mask'].to(device, dtype = torch.long)\n","            labels = batch['labels'].to(device, dtype = torch.long)\n","            \n","            loss, eval_logits = model(input_ids=ids, attention_mask=mask, labels=labels, return_dict = False)\n","            \n","            eval_loss += loss.item()\n","\n","            nb_eval_steps += 1\n","            nb_eval_examples += labels.size(0)\n","        \n","            # compute evaluation accuracy\n","            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","            \n","            # only compute accuracy at active labels\n","            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","        \n","            labels = torch.masked_select(flattened_targets, active_accuracy)\n","            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","            \n","            eval_labels.extend(labels)\n","            eval_preds.extend(predictions)\n","            \n","            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n","            eval_accuracy += tmp_eval_accuracy\n","\n","    labels = [idx2tag[id.item()] for id in eval_labels]\n","    predictions = [idx2tag[id.item()] for id in eval_preds]\n","    \n","    eval_loss = eval_loss / nb_eval_steps\n","    eval_accuracy = eval_accuracy / nb_eval_steps\n","    print(f\"Validation Loss: {eval_loss}\")\n","    print(f\"Validation Accuracy: {eval_accuracy}\")\n","\n","    return labels, predictions, eval_loss"],"id":"JvdztU6FA8Bd"},{"cell_type":"code","execution_count":7,"metadata":{"id":"jMknjbDrh6Fk","executionInfo":{"status":"ok","timestamp":1667797817991,"user_tz":240,"elapsed":9,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"}}},"outputs":[],"source":["def create_train_and_validate_model(augmented_percentage):\n","\n","  augmented_X_train, augmented_y_train, updated_word2idx, updated_idx2word = generate_sentences(X_train, y_train, augmented_percentage)\n","\n","  maxlen_X_train = max([len(s) for s in augmented_X_train])\n","  maxlen_X_test = max([len(s) for s in X_test])\n","  maxlen_X_dev = max([len(s) for s in X_dev])\n","  maxlen_y_train = max([len(s) for s in augmented_y_train])\n","  maxlen_y_test = max([len(s) for s in y_test])\n","  maxlen_y_dev = max([len(s) for s in y_dev])\n","\n","  maxlen = max([maxlen_X_train, maxlen_X_test, maxlen_X_dev, maxlen_y_train, maxlen_y_test, maxlen_y_dev])\n","\n","  if maxlen > 512:\n","    maxlen = 512\n","\n","  augmented_X_train_words = [[updated_idx2word[word] for word in sentence] for sentence in augmented_X_train]\n","  X_dev_words = [[updated_idx2word[word] for word in sentence] for sentence in X_dev]\n","  X_test_words = [[updated_idx2word[word] for word in sentence] for sentence in X_test]\n","  augmented_y_train_tags = [','.join([idx2tag[tag] for tag in sentence]) for sentence in augmented_y_train]\n","  y_dev_tags = [','.join([idx2tag[tag] for tag in sentence]) for sentence in y_dev]\n","  y_test_tags = [','.join([idx2tag[tag] for tag in sentence]) for sentence in y_test]\n","\n","  new_train_df = pd.DataFrame({\"sentence\": augmented_X_train_words, \"word_labels\": augmented_y_train_tags}).reset_index(drop=True)\n","  new_test_df = pd.DataFrame({\"sentence\": X_test_words, \"word_labels\": y_test_tags}).reset_index(drop=True)\n","  new_val_df = pd.DataFrame({\"sentence\": X_dev_words, \"word_labels\": y_dev_tags}).reset_index(drop=True)\n","\n","  training_set = dataset(new_train_df, tokenizer, maxlen)\n","  testing_set = dataset(new_test_df, tokenizer, maxlen)\n","  validation_set = dataset(new_val_df, tokenizer, maxlen)\n","\n","  model, device, optimizer, training_loader, testing_loader, val_loader = create_model(maxlen, len(tag2idx), training_set, testing_set, validation_set)\n","\n","  training_start_time = time.clock()\n","  min_val_loss = 0\n","  MAX_PATIENCE = 5\n","  patience = 0\n","\n","  for epoch in range(100):\n","    print(f\"Training epoch: {epoch + 1}\")\n","    if patience == MAX_PATIENCE:\n","      print(\"Patience limit reached\")\n","      break\n","    train(model, device, optimizer, training_loader, epoch, TRAINING_STOP_LOSS_PERCENTAGE)\n","    labels, predictions, val_loss = test(model, device, val_loader)\n","    if ((min_val_loss == 0) or (min_val_loss != 0 and val_loss < min_val_loss)):\n","      min_val_loss = val_loss\n","      torch.save(model.state_dict(), 'checkpoint.pt')\n","      patience = 0\n","    else:\n","      patience = patience + 1\n","  print(f\"Training duration: {(time.clock() - training_start_time)/60} minutes\")\n","\n","  checkpoint = torch.load('checkpoint.pt')\n","  model.load_state_dict(checkpoint)\n","\n","  validation_start_time = time.clock()\n","  labels, predictions, test_loss = test(model, device, testing_loader)\n","  labels = [labels]\n","  predictions = [predictions]\n","  print(f\"Validation duration: {(time.clock() - validation_start_time)/60} minutes\")\n","\n","  print(\"F1-score (test): {:.1%}\".format(f1_score(labels, predictions)))\n","  print(classification_report(labels, predictions))"],"id":"jMknjbDrh6Fk"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jhz9BiIwGCsV","outputId":"d34fb9eb-adde-4fd5-d369-2b613e22689e"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 25.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 17334\n","Points in y_train after augmentation: 17334\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.168198347091675\n","Training loss per 100 training steps: 0.4051372572632119\n","Training loss per 100 training steps: 0.307923156564212\n","Training loss per 100 training steps: 0.2635520098118291\n","Training loss per 100 training steps: 0.23431593083086752\n","Training loss per 100 training steps: 0.21718181335105152\n","Training loss epoch: 0.21059694321915454\n","Training accuracy epoch: 0.9334829766770548\n","Validating model...\n","Validation Loss: 0.14697707618598815\n","Validation Accuracy: 0.9539365324921293\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07280921936035156\n","Training loss per 100 training steps: 0.08427293193849301\n","Training loss per 100 training steps: 0.09262706132244262\n","Training loss per 100 training steps: 0.09341680094216057\n","Training loss per 100 training steps: 0.09225379029274954\n","Training loss per 100 training steps: 0.09272857921982477\n","Training loss epoch: 0.09262097663352631\n","Training accuracy epoch: 0.9701586615949327\n","Validating model...\n","Validation Loss: 0.1483361122573351\n","Validation Accuracy: 0.957731175471863\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04009479656815529\n","Training loss per 100 training steps: 0.040542368113183146\n","Training loss per 100 training steps: 0.04866975203819054\n","Training loss per 100 training steps: 0.052043501938232206\n","Training loss per 100 training steps: 0.052674232691205906\n","Training loss per 100 training steps: 0.05329871813844733\n","Training loss epoch: 0.05309260503098547\n","Training accuracy epoch: 0.9831109567691216\n","Validating model...\n","Validation Loss: 0.14366722010172805\n","Validation Accuracy: 0.9608758539458901\n","Training epoch: 4\n","Training loss per 100 training steps: 0.021550297737121582\n","Training loss per 100 training steps: 0.03437866437212002\n","Training loss per 100 training steps: 0.035796378702110616\n","Training loss per 100 training steps: 0.03620772993662379\n","Training loss per 100 training steps: 0.036284723872448923\n","Training loss per 100 training steps: 0.03799749871468666\n","Training loss epoch: 0.038025692885404805\n","Training accuracy epoch: 0.988189448396333\n","Validating model...\n","Validation Loss: 0.16481510561878804\n","Validation Accuracy: 0.9580459508657487\n","Training epoch: 5\n","Training loss per 100 training steps: 0.015577886253595352\n","Training loss per 100 training steps: 0.031255453361640914\n","Training loss per 100 training steps: 0.026986589074941045\n","Training loss per 100 training steps: 0.029446041332155566\n","Training loss per 100 training steps: 0.03154076281714339\n","Training loss per 100 training steps: 0.030949160738749627\n","Training loss epoch: 0.030837480261461377\n","Training accuracy epoch: 0.9903881296604187\n","Validating model...\n","Validation Loss: 0.1812128537370787\n","Validation Accuracy: 0.9574237886222143\n","Training epoch: 6\n","Training loss per 100 training steps: 0.018947681412100792\n","Training loss per 100 training steps: 0.024773911275615047\n","Training loss per 100 training steps: 0.025715144991988213\n","Training loss per 100 training steps: 0.026562901671884576\n","Training loss per 100 training steps: 0.02689154432944842\n","Training loss per 100 training steps: 0.027036246009210046\n","Training loss epoch: 0.027813121409463005\n","Training accuracy epoch: 0.9914419208400955\n","Validating model...\n","Validation Loss: 0.1814456432815883\n","Validation Accuracy: 0.9576624113838437\n","Training epoch: 7\n","Training loss per 100 training steps: 0.07033360749483109\n","Training loss per 100 training steps: 0.02259446457281967\n","Training loss per 100 training steps: 0.0233375724936159\n","Training loss per 100 training steps: 0.022475878801467546\n","Training loss per 100 training steps: 0.021812976582122136\n","Training loss per 100 training steps: 0.021901780473367643\n","Training loss epoch: 0.02201165377855734\n","Training accuracy epoch: 0.9932624480319926\n","Validating model...\n","Validation Loss: 0.1909667562282124\n","Validation Accuracy: 0.9597304612949368\n","Training epoch: 8\n","Training loss per 100 training steps: 0.00579707371070981\n","Training loss per 100 training steps: 0.014017925823642181\n","Training loss per 100 training steps: 0.014296890436544255\n","Training loss per 100 training steps: 0.0149232555481302\n","Training loss per 100 training steps: 0.015980003909248523\n","Training loss per 100 training steps: 0.016221696984705082\n","Training loss epoch: 0.017022287538807798\n","Training accuracy epoch: 0.9950565904637683\n","Validating model...\n","Validation Loss: 0.1891342198306864\n","Validation Accuracy: 0.960882541162142\n","Training epoch: 9\n","Patience limit reached\n","Training duration: 75.13722993333334 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16738670413421156\n","Validation Accuracy: 0.9573031450869595\n","Validation duration: 5.45981303333333 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.84      0.86      0.85     12546\n","        test       0.87      0.87      0.87      9012\n","   treatment       0.85      0.85      0.85      9297\n","\n","   micro avg       0.85      0.86      0.86     30855\n","   macro avg       0.85      0.86      0.86     30855\n","weighted avg       0.85      0.86      0.86     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 17334\n","Points in y_train after augmentation: 17334\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.29876708984375\n","Training loss per 100 training steps: 0.422058308331093\n","Training loss per 100 training steps: 0.3145659555176004\n","Training loss per 100 training steps: 0.2655375968058442\n","Training loss per 100 training steps: 0.23662355917498953\n","Training loss per 100 training steps: 0.21917898118674398\n","Training loss epoch: 0.21418478097285512\n","Training accuracy epoch: 0.931189790294156\n","Validating model...\n","Validation Loss: 0.13907481430025845\n","Validation Accuracy: 0.954286640536471\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07327891886234283\n","Training loss per 100 training steps: 0.09088404590983203\n","Training loss per 100 training steps: 0.08682789490905715\n","Training loss per 100 training steps: 0.08874379460115073\n","Training loss per 100 training steps: 0.08897115430676208\n","Training loss per 100 training steps: 0.09083253425358238\n","Training loss epoch: 0.09045860815855135\n","Training accuracy epoch: 0.9711011649940425\n","Validating model...\n","Validation Loss: 0.1326917503150059\n","Validation Accuracy: 0.960588175955181\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0769125446677208\n","Training loss per 100 training steps: 0.054689235487344244\n","Training loss per 100 training steps: 0.053593119256550546\n","Training loss per 100 training steps: 0.057562454933133535\n","Training loss per 100 training steps: 0.05598169149473272\n","Training loss per 100 training steps: 0.056622526905835864\n","Training loss epoch: 0.05660654010759784\n","Training accuracy epoch: 0.982028650167035\n","Validating model...\n","Validation Loss: 0.14364495756128778\n","Validation Accuracy: 0.9601463683643777\n","Training epoch: 4\n","Training loss per 100 training steps: 0.02116740494966507\n","Training loss per 100 training steps: 0.03659685055430204\n","Training loss per 100 training steps: 0.034428877614100295\n","Training loss per 100 training steps: 0.037988954682778756\n","Training loss per 100 training steps: 0.039919490969804884\n","Training loss per 100 training steps: 0.040187989508207074\n","Training loss epoch: 0.03988468180633085\n","Training accuracy epoch: 0.987223914830564\n","Validating model...\n","Validation Loss: 0.16170765856861488\n","Validation Accuracy: 0.9600272387023691\n","Training epoch: 5\n","Training loss per 100 training steps: 0.05060789734125137\n","Training loss per 100 training steps: 0.024340202132848526\n","Training loss per 100 training steps: 0.029461933606864874\n","Training loss per 100 training steps: 0.026635060046236357\n","Training loss per 100 training steps: 0.02798367006195584\n","Training loss per 100 training steps: 0.029650272104420703\n","Training loss epoch: 0.030182173193820726\n","Training accuracy epoch: 0.9905910912470488\n","Validating model...\n","Validation Loss: 0.16839602850861363\n","Validation Accuracy: 0.9595230030647806\n","Training epoch: 6\n","Training loss per 100 training steps: 0.04728195443749428\n","Training loss per 100 training steps: 0.024327496634358264\n","Training loss per 100 training steps: 0.0232142455941321\n","Training loss per 100 training steps: 0.022862844161017862\n","Training loss per 100 training steps: 0.023582980202213673\n","Training loss per 100 training steps: 0.024392960367244695\n","Training loss epoch: 0.024607037247985093\n","Training accuracy epoch: 0.9925438261770537\n","Validating model...\n","Validation Loss: 0.17347772444549997\n","Validation Accuracy: 0.9595976985822574\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0060655344277620316\n","Training loss per 100 training steps: 0.01783380736274147\n","Training loss per 100 training steps: 0.019204858819078376\n","Training loss per 100 training steps: 0.018878010417407446\n","Training loss per 100 training steps: 0.018739821313110475\n","Training loss per 100 training steps: 0.019936693257985902\n","Training loss epoch: 0.020454093574729278\n","Training accuracy epoch: 0.9935357139153886\n","Validating model...\n","Validation Loss: 0.20669944475513774\n","Validation Accuracy: 0.9570120410134706\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 65.74577699999999 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14636364556133263\n","Validation Accuracy: 0.9569903682732271\n","Validation duration: 5.414153716666685 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.1%\n","              precision    recall  f1-score   support\n","\n","     problem       0.84      0.87      0.85     12546\n","        test       0.85      0.86      0.85      9012\n","   treatment       0.85      0.84      0.85      9297\n","\n","   micro avg       0.84      0.86      0.85     30855\n","   macro avg       0.85      0.86      0.85     30855\n","weighted avg       0.85      0.86      0.85     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 17334\n","Points in y_train after augmentation: 17334\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0176756381988525\n","Training loss per 100 training steps: 0.4210520706849523\n","Training loss per 100 training steps: 0.30715366768006663\n","Training loss per 100 training steps: 0.2599897243305298\n","Training loss per 100 training steps: 0.23838707589151853\n","Training loss per 100 training steps: 0.2191672878797183\n","Training loss epoch: 0.21275722291801688\n","Training accuracy epoch: 0.9324397192349596\n","Validating model...\n","Validation Loss: 0.12878843474310714\n","Validation Accuracy: 0.9577397394122513\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0419163778424263\n","Training loss per 100 training steps: 0.09227841662814712\n","Training loss per 100 training steps: 0.09630392035886423\n","Training loss per 100 training steps: 0.09439747331608273\n","Training loss per 100 training steps: 0.0945317366710885\n","Training loss per 100 training steps: 0.09177093114889787\n","Training loss epoch: 0.09167926013469696\n","Training accuracy epoch: 0.9702589359994488\n","Validating model...\n","Validation Loss: 0.13963278014116087\n","Validation Accuracy: 0.9582986095074482\n","Training epoch: 3\n","Training loss per 100 training steps: 0.10148484259843826\n","Training loss per 100 training steps: 0.0485996898646365\n","Training loss per 100 training steps: 0.051790364256907084\n","Training loss per 100 training steps: 0.054148679397276224\n","Training loss per 100 training steps: 0.05482830228736889\n","Training loss per 100 training steps: 0.0550319813428904\n","Training loss epoch: 0.0550443609197868\n","Training accuracy epoch: 0.9827592503597783\n","Validating model...\n","Validation Loss: 0.14156024315237226\n","Validation Accuracy: 0.9590675072227477\n","Training epoch: 4\n","Training loss per 100 training steps: 0.031589325517416\n","Training loss per 100 training steps: 0.03924355617180319\n","Training loss per 100 training steps: 0.03620160753671914\n","Training loss per 100 training steps: 0.036749265702020535\n","Training loss per 100 training steps: 0.036053195794895666\n","Training loss per 100 training steps: 0.036622160270033094\n","Training loss epoch: 0.03751967058429405\n","Training accuracy epoch: 0.9884548229973422\n","Validating model...\n","Validation Loss: 0.17398345049519043\n","Validation Accuracy: 0.9558574703686279\n","Training epoch: 5\n","Training loss per 100 training steps: 0.01432534959167242\n","Training loss per 100 training steps: 0.030219595530070364\n","Training loss per 100 training steps: 0.031948840460480556\n","Training loss per 100 training steps: 0.032633385951692656\n","Training loss per 100 training steps: 0.03231137137926251\n","Training loss per 100 training steps: 0.03208029913709512\n","Training loss epoch: 0.03256458339536549\n","Training accuracy epoch: 0.9897377580727988\n","Validating model...\n","Validation Loss: 0.1768574715446826\n","Validation Accuracy: 0.9592962739805019\n","Training epoch: 6\n","Training loss per 100 training steps: 0.031203635036945343\n","Training loss per 100 training steps: 0.021698921898121733\n","Training loss per 100 training steps: 0.023757353013807637\n","Training loss per 100 training steps: 0.022125123627947958\n","Training loss per 100 training steps: 0.02369510202449131\n","Training loss per 100 training steps: 0.02515121245247399\n","Training loss epoch: 0.025362679692297982\n","Training accuracy epoch: 0.9917603168814206\n","Validating model...\n","Validation Loss: 0.19551287571500456\n","Validation Accuracy: 0.9570560825474174\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 56.32268539999998 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14694547029945101\n","Validation Accuracy: 0.9527513794436783\n","Validation duration: 5.390246866666682 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.85      0.84     12546\n","        test       0.83      0.85      0.84      9012\n","   treatment       0.82      0.85      0.84      9297\n","\n","   micro avg       0.82      0.85      0.84     30855\n","   macro avg       0.82      0.85      0.84     30855\n","weighted avg       0.82      0.85      0.84     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 17334\n","Points in y_train after augmentation: 17334\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7868108749389648\n","Training loss per 100 training steps: 0.4112996411057982\n","Training loss per 100 training steps: 0.3062226851818277\n","Training loss per 100 training steps: 0.25892857941133635\n","Training loss per 100 training steps: 0.2322417140527259\n","Training loss per 100 training steps: 0.2135355003910537\n","Training loss epoch: 0.207176168186322\n","Training accuracy epoch: 0.9349129760707926\n","Validating model...\n","Validation Loss: 0.13478568786537493\n","Validation Accuracy: 0.9530423879544111\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06874042004346848\n","Training loss per 100 training steps: 0.08460541951036689\n","Training loss per 100 training steps: 0.08514740333813636\n","Training loss per 100 training steps: 0.0858519974495733\n","Training loss per 100 training steps: 0.08444466386594231\n","Training loss per 100 training steps: 0.08505829645064242\n","Training loss epoch: 0.08546853976709101\n","Training accuracy epoch: 0.9729673806407758\n","Validating model...\n","Validation Loss: 0.1428118526403393\n","Validation Accuracy: 0.9573808218651331\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02380409464240074\n","Training loss per 100 training steps: 0.052860441350258226\n","Training loss per 100 training steps: 0.059337158629494666\n","Training loss per 100 training steps: 0.05465095851452792\n","Training loss per 100 training steps: 0.05472468542622546\n","Training loss per 100 training steps: 0.05587949471068596\n","Training loss epoch: 0.05585184225956892\n","Training accuracy epoch: 0.9820700022138164\n","Validating model...\n","Validation Loss: 0.1458980307200706\n","Validation Accuracy: 0.9589543599851517\n","Training epoch: 4\n","Training loss per 100 training steps: 0.02559947781264782\n","Training loss per 100 training steps: 0.027406940084540903\n","Training loss per 100 training steps: 0.0353733060049792\n","Training loss per 100 training steps: 0.037316935125311396\n","Training loss per 100 training steps: 0.03859292824538959\n","Training loss per 100 training steps: 0.0384117598787597\n","Training loss epoch: 0.03830495349782763\n","Training accuracy epoch: 0.9878218324618193\n","Validating model...\n","Validation Loss: 0.17632601886697405\n","Validation Accuracy: 0.9599634949918651\n","Training epoch: 5\n","Training loss per 100 training steps: 0.008463445119559765\n","Training loss per 100 training steps: 0.030897309751212965\n","Training loss per 100 training steps: 0.03023154760504707\n","Training loss per 100 training steps: 0.029109820296161767\n","Training loss per 100 training steps: 0.02819930724195783\n","Training loss per 100 training steps: 0.028562861213324863\n","Training loss epoch: 0.02941665453110337\n","Training accuracy epoch: 0.9907175840591224\n","Validating model...\n","Validation Loss: 0.17106546948409893\n","Validation Accuracy: 0.9578061835641244\n","Training epoch: 6\n","Training loss per 100 training steps: 0.02066858485341072\n","Training loss per 100 training steps: 0.02006010340854046\n","Training loss per 100 training steps: 0.021482127817377763\n","Training loss per 100 training steps: 0.02235127275247294\n","Training loss per 100 training steps: 0.025016606041286003\n","Training loss per 100 training steps: 0.027354252532806746\n","Training loss epoch: 0.02785709377432352\n","Training accuracy epoch: 0.9913639969681588\n","Validating model...\n","Validation Loss: 0.1881525306055298\n","Validation Accuracy: 0.9573669412310629\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 56.33627468333334 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1523553983899075\n","Validation Accuracy: 0.9496608146888919\n","Validation duration: 5.3961714333333175 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.78      0.86      0.81     12546\n","        test       0.82      0.86      0.84      9012\n","   treatment       0.80      0.86      0.83      9297\n","\n","   micro avg       0.80      0.86      0.83     30855\n","   macro avg       0.80      0.86      0.83     30855\n","weighted avg       0.80      0.86      0.83     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 17334\n","Points in y_train after augmentation: 17334\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.083451509475708\n","Training loss per 100 training steps: 0.41105398417699457\n","Training loss per 100 training steps: 0.306511048023677\n","Training loss per 100 training steps: 0.25970272776791425\n","Training loss per 100 training steps: 0.23599504350575426\n","Training loss per 100 training steps: 0.21868446976422312\n","Training loss epoch: 0.21271143287997624\n","Training accuracy epoch: 0.9326184338789855\n","Validating model...\n","Validation Loss: 0.1255261969038999\n","Validation Accuracy: 0.9584009309539341\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06714039295911789\n","Training loss per 100 training steps: 0.08992008680459296\n","Training loss per 100 training steps: 0.08626668699623193\n","Training loss per 100 training steps: 0.09060655337792398\n","Training loss per 100 training steps: 0.08938494734140925\n","Training loss per 100 training steps: 0.08957714975594047\n","Training loss epoch: 0.09030507488616113\n","Training accuracy epoch: 0.9710902449215476\n","Validating model...\n","Validation Loss: 0.14069937665450882\n","Validation Accuracy: 0.9581737156571407\n","Training epoch: 3\n","Training loss per 100 training steps: 0.09246190637350082\n","Training loss per 100 training steps: 0.05598452881826918\n","Training loss per 100 training steps: 0.05939275077752658\n","Training loss per 100 training steps: 0.05969446597070096\n","Training loss per 100 training steps: 0.06044728455930354\n","Training loss per 100 training steps: 0.06068278922180751\n","Training loss epoch: 0.05963694343748897\n","Training accuracy epoch: 0.980980269075063\n","Validating model...\n","Validation Loss: 0.1357436076217851\n","Validation Accuracy: 0.9636140963778369\n","Training epoch: 4\n","Training loss per 100 training steps: 0.06500758230686188\n","Training loss per 100 training steps: 0.035183424350233874\n","Training loss per 100 training steps: 0.03262135813381078\n","Training loss per 100 training steps: 0.03230057958709973\n","Training loss per 100 training steps: 0.032488564040077536\n","Training loss per 100 training steps: 0.03351258708302586\n","Training loss epoch: 0.03374520791939381\n","Training accuracy epoch: 0.9894210571150334\n","Validating model...\n","Validation Loss: 0.1675262407145717\n","Validation Accuracy: 0.9603165626390437\n","Training epoch: 5\n","Training loss per 100 training steps: 0.08842339366674423\n","Training loss per 100 training steps: 0.02557260158361111\n","Training loss per 100 training steps: 0.024785156044367682\n","Training loss per 100 training steps: 0.02533778475374726\n","Training loss per 100 training steps: 0.02612716070448334\n","Training loss per 100 training steps: 0.026542962405611267\n","Training loss epoch: 0.026644328307760777\n","Training accuracy epoch: 0.9918497892522377\n","Validating model...\n","Validation Loss: 0.19487751987399896\n","Validation Accuracy: 0.9571225348824491\n","Training epoch: 6\n","Training loss per 100 training steps: 0.011783000081777573\n","Training loss per 100 training steps: 0.021712946590257458\n","Training loss per 100 training steps: 0.020488225015555625\n","Training loss per 100 training steps: 0.022378868211746877\n","Training loss per 100 training steps: 0.02180816363297958\n","Training loss per 100 training steps: 0.02319883775090782\n","Training loss epoch: 0.02357002846945835\n","Training accuracy epoch: 0.9926215459693083\n","Validating model...\n","Validation Loss: 0.2107214034329374\n","Validation Accuracy: 0.9551744249274776\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 56.3881903333333 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14253644174163196\n","Validation Accuracy: 0.9539565977307434\n","Validation duration: 5.399557166666697 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.3%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.87      0.85     12546\n","        test       0.80      0.89      0.84      9012\n","   treatment       0.82      0.86      0.84      9297\n","\n","   micro avg       0.82      0.87      0.84     30855\n","   macro avg       0.82      0.87      0.84     30855\n","weighted avg       0.82      0.87      0.84     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 17334\n","Points in y_train after augmentation: 17334\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1413180828094482\n","Training loss per 100 training steps: 0.39912775284287955\n","Training loss per 100 training steps: 0.2926671159504658\n","Training loss per 100 training steps: 0.25360756705938975\n","Training loss per 100 training steps: 0.22948243937680401\n","Training loss per 100 training steps: 0.21133282021089586\n","Training loss epoch: 0.20583997867534082\n","Training accuracy epoch: 0.9340876342645543\n","Validating model...\n","Validation Loss: 0.13768819937264765\n","Validation Accuracy: 0.9559581132968906\n","Training epoch: 2\n","Training loss per 100 training steps: 0.12624534964561462\n","Training loss per 100 training steps: 0.09009353748273731\n","Training loss per 100 training steps: 0.08779582833009425\n","Training loss per 100 training steps: 0.08857711914468841\n","Training loss per 100 training steps: 0.08920186942447897\n","Training loss per 100 training steps: 0.08960612398570407\n","Training loss epoch: 0.08992397231548145\n","Training accuracy epoch: 0.97112945010832\n","Validating model...\n","Validation Loss: 0.14107982124891374\n","Validation Accuracy: 0.9561769167222495\n","Training epoch: 3\n","Training loss per 100 training steps: 0.024880001321434975\n","Training loss per 100 training steps: 0.049462017879849024\n","Training loss per 100 training steps: 0.05160185886750841\n","Training loss per 100 training steps: 0.05147550960204431\n","Training loss per 100 training steps: 0.05413661287410041\n","Training loss per 100 training steps: 0.0562218747514406\n","Training loss epoch: 0.05706074459708512\n","Training accuracy epoch: 0.9814587719166697\n","Validating model...\n","Validation Loss: 0.1546363349423393\n","Validation Accuracy: 0.9602292505572309\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03931521996855736\n","Training loss per 100 training steps: 0.03497893981045425\n","Training loss per 100 training steps: 0.03535097117989847\n","Training loss per 100 training steps: 0.03737966653324688\n","Training loss per 100 training steps: 0.03724789159300451\n","Training loss per 100 training steps: 0.03829964380869326\n","Training loss epoch: 0.03833543289430453\n","Training accuracy epoch: 0.9879876218624275\n","Validating model...\n","Validation Loss: 0.16922014934772794\n","Validation Accuracy: 0.9591152776990711\n","Training epoch: 5\n","Training loss per 100 training steps: 0.04895840212702751\n","Training loss per 100 training steps: 0.025760615669827135\n","Training loss per 100 training steps: 0.03118986234159223\n","Training loss per 100 training steps: 0.03227933881103535\n","Training loss per 100 training steps: 0.03093789743945848\n","Training loss per 100 training steps: 0.03075801740175563\n","Training loss epoch: 0.03086196846110451\n","Training accuracy epoch: 0.9902453239708938\n","Validating model...\n","Validation Loss: 0.17654052751695182\n","Validation Accuracy: 0.958638702860488\n","Training epoch: 6\n","Training loss per 100 training steps: 0.005642645992338657\n","Training loss per 100 training steps: 0.01709938716399253\n","Training loss per 100 training steps: 0.017665459969328876\n","Training loss per 100 training steps: 0.020290282999894015\n","Training loss per 100 training steps: 0.021066665277378563\n","Training loss per 100 training steps: 0.021314462859572995\n","Training loss epoch: 0.02267581464800506\n","Training accuracy epoch: 0.9929970032105545\n","Validating model...\n","Validation Loss: 0.16237232456733655\n","Validation Accuracy: 0.9591714787875225\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 56.36124330000003 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14577062781986402\n","Validation Accuracy: 0.9544658109627419\n","Validation duration: 5.397275316666674 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.84      0.83     12546\n","        test       0.81      0.88      0.84      9012\n","   treatment       0.83      0.84      0.83      9297\n","\n","   micro avg       0.82      0.85      0.84     30855\n","   macro avg       0.82      0.85      0.84     30855\n","weighted avg       0.82      0.85      0.84     30855\n","\n","!!!!!! Starting model number 7 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 17334\n","Points in y_train after augmentation: 17334\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.092904567718506\n","Training loss per 100 training steps: 0.4091402713467579\n","Training loss per 100 training steps: 0.3090439099651664\n","Training loss per 100 training steps: 0.2644700445977358\n","Training loss per 100 training steps: 0.24011322996228412\n","Training loss per 100 training steps: 0.22159363276617017\n","Training loss epoch: 0.21503747559781444\n","Training accuracy epoch: 0.931539772562228\n","Validating model...\n","Validation Loss: 0.13837547684935006\n","Validation Accuracy: 0.9557310233054056\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04161296784877777\n","Training loss per 100 training steps: 0.09167566380952255\n","Training loss per 100 training steps: 0.09189123085778744\n","Training loss per 100 training steps: 0.09221828643517241\n","Training loss per 100 training steps: 0.09303271550304278\n","Training loss per 100 training steps: 0.09116010164503685\n","Training loss epoch: 0.09068008583396453\n","Training accuracy epoch: 0.9706953764591416\n","Validating model...\n","Validation Loss: 0.14052643035478019\n","Validation Accuracy: 0.9562392369682963\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03265247121453285\n","Training loss per 100 training steps: 0.05852587726243799\n","Training loss per 100 training steps: 0.059869806497677494\n","Training loss per 100 training steps: 0.058950540663804424\n","Training loss per 100 training steps: 0.05742105768129527\n","Training loss per 100 training steps: 0.05799280806070941\n","Training loss epoch: 0.05823564617654027\n","Training accuracy epoch: 0.9818174874187834\n","Validating model...\n","Validation Loss: 0.14403343325263107\n","Validation Accuracy: 0.9602869548688935\n","Training epoch: 4\n","Training loss per 100 training steps: 0.06362289190292358\n","Training loss per 100 training steps: 0.02933200729300849\n","Training loss per 100 training steps: 0.031704405388118355\n","Training loss per 100 training steps: 0.03221001998448676\n","Training loss per 100 training steps: 0.03417934638713986\n","Training loss per 100 training steps: 0.03593375530078107\n","Training loss epoch: 0.03627434714222189\n","Training accuracy epoch: 0.9885966064240718\n","Validating model...\n","Validation Loss: 0.1732478029663106\n","Validation Accuracy: 0.9585091165381455\n","Training epoch: 5\n","Training loss per 100 training steps: 0.10850013792514801\n","Training loss per 100 training steps: 0.031058495115064602\n","Training loss per 100 training steps: 0.029709793955657576\n","Training loss per 100 training steps: 0.030225942038197652\n","Training loss per 100 training steps: 0.03038010131532879\n","Training loss per 100 training steps: 0.030595028480633855\n","Training loss epoch: 0.030079000302361894\n","Training accuracy epoch: 0.9908803094532365\n","Validating model...\n","Validation Loss: 0.18586072611150803\n","Validation Accuracy: 0.9576078336496836\n","Training epoch: 6\n","Training loss per 100 training steps: 0.01334364339709282\n","Training loss per 100 training steps: 0.021664030924854374\n","Training loss per 100 training steps: 0.021609815588193155\n","Training loss per 100 training steps: 0.022863249115389075\n","Training loss per 100 training steps: 0.02363721457422662\n","Training loss per 100 training steps: 0.025755859837781808\n","Training loss epoch: 0.02529431749208284\n","Training accuracy epoch: 0.9922095901537593\n","Validating model...\n","Validation Loss: 0.2078241565470378\n","Validation Accuracy: 0.9560279297132985\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 56.376570700000045 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1463708020488007\n","Validation Accuracy: 0.955139667529444\n","Validation duration: 5.395910683333326 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.84      0.85      0.84     12546\n","        test       0.86      0.84      0.85      9012\n","   treatment       0.83      0.84      0.83      9297\n","\n","   micro avg       0.84      0.84      0.84     30855\n","   macro avg       0.84      0.84      0.84     30855\n","weighted avg       0.84      0.84      0.84     30855\n","\n","!!!!!! Starting model number 8 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 17334\n","Points in y_train after augmentation: 17334\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.2253565788269043\n","Training loss per 100 training steps: 0.42607486930371513\n","Training loss per 100 training steps: 0.3141075155665329\n","Training loss per 100 training steps: 0.26544058085280003\n","Training loss per 100 training steps: 0.23647759670851534\n","Training loss per 100 training steps: 0.21867359770153336\n","Training loss epoch: 0.21237429912198624\n","Training accuracy epoch: 0.9321095861750622\n","Validating model...\n","Validation Loss: 0.1442808285355568\n","Validation Accuracy: 0.9521810836373216\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09317672252655029\n","Training loss per 100 training steps: 0.09447270002916898\n","Training loss per 100 training steps: 0.09202969619142476\n","Training loss per 100 training steps: 0.09146410587438664\n","Training loss per 100 training steps: 0.09136563376349367\n","Training loss per 100 training steps: 0.09056023720506869\n","Training loss epoch: 0.09055658422558263\n","Training accuracy epoch: 0.9712117411178618\n","Validating model...\n","Validation Loss: 0.13743214466451825\n","Validation Accuracy: 0.9579926734913903\n","Training epoch: 3\n","Training loss per 100 training steps: 0.022751973941922188\n","Training loss per 100 training steps: 0.05081524897717161\n","Training loss per 100 training steps: 0.054103988160226324\n","Training loss per 100 training steps: 0.05739652481319946\n","Training loss per 100 training steps: 0.058004549640623335\n","Training loss per 100 training steps: 0.05784970028567576\n","Training loss epoch: 0.05784190984312239\n","Training accuracy epoch: 0.9815317613618296\n","Validating model...\n","Validation Loss: 0.15252014123774194\n","Validation Accuracy: 0.9590014102057366\n","Training epoch: 4\n","Training loss per 100 training steps: 0.07238958030939102\n","Training loss per 100 training steps: 0.0438081560481229\n","Training loss per 100 training steps: 0.0411627660192716\n","Training loss per 100 training steps: 0.03939327537283252\n","Training loss per 100 training steps: 0.039444338841517074\n","Training loss per 100 training steps: 0.039315976512464074\n","Training loss epoch: 0.03947926852190558\n","Training accuracy epoch: 0.9876058249526308\n","Validating model...\n","Validation Loss: 0.16059682721441443\n","Validation Accuracy: 0.9602107037459795\n","Training epoch: 5\n","Training loss per 100 training steps: 0.048675354570150375\n","Training loss per 100 training steps: 0.028073911438696086\n","Training loss per 100 training steps: 0.029372390932449838\n","Training loss per 100 training steps: 0.027343528717098775\n","Training loss per 100 training steps: 0.02752432762108107\n","Training loss per 100 training steps: 0.028566255010064958\n","Training loss epoch: 0.028913277136810585\n","Training accuracy epoch: 0.9911274903069778\n","Validating model...\n","Validation Loss: 0.16835538416423582\n","Validation Accuracy: 0.9589993852424998\n","Training epoch: 6\n","Training loss per 100 training steps: 0.023364877328276634\n","Training loss per 100 training steps: 0.02289295096658078\n","Training loss per 100 training steps: 0.02119565263027974\n","Training loss per 100 training steps: 0.022254284438592044\n","Training loss per 100 training steps: 0.02275603021157701\n","Training loss per 100 training steps: 0.02415747324247824\n","Training loss epoch: 0.02365172832460672\n","Training accuracy epoch: 0.9927900711205175\n","Validating model...\n","Validation Loss: 0.18611346571041004\n","Validation Accuracy: 0.9609663574700635\n","Training epoch: 7\n","Training loss per 100 training steps: 0.00787393655627966\n","Training loss per 100 training steps: 0.020065113564948597\n","Training loss per 100 training steps: 0.020859103272518432\n","Training loss per 100 training steps: 0.020149423210553675\n","Training loss per 100 training steps: 0.02192336913375904\n","Training loss per 100 training steps: 0.022784027299553734\n","Training loss epoch: 0.022830445926191417\n","Training accuracy epoch: 0.9931731362398623\n","Validating model...\n","Validation Loss: 0.18555897537183452\n","Validation Accuracy: 0.9600924713340693\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 65.64212645000006 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15297063933879448\n","Validation Accuracy: 0.9551253099787331\n","Validation duration: 5.364832283333332 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.86      0.84      0.85     12546\n","        test       0.84      0.84      0.84      9012\n","   treatment       0.85      0.84      0.84      9297\n","\n","   micro avg       0.85      0.84      0.85     30855\n","   macro avg       0.85      0.84      0.84     30855\n","weighted avg       0.85      0.84      0.85     30855\n","\n","!!!!!! Starting model number 9 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 17334\n","Points in y_train after augmentation: 17334\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.107208251953125\n","Training loss per 100 training steps: 0.43703396950322804\n","Training loss per 100 training steps: 0.3150797186243297\n","Training loss per 100 training steps: 0.27180235452974755\n","Training loss per 100 training steps: 0.24504337957746666\n","Training loss per 100 training steps: 0.22381697912624257\n","Training loss epoch: 0.2168394472807426\n","Training accuracy epoch: 0.9314684049949715\n","Validating model...\n","Validation Loss: 0.13731824030930345\n","Validation Accuracy: 0.956246644074368\n","Training epoch: 2\n","Training loss per 100 training steps: 0.12251102924346924\n","Training loss per 100 training steps: 0.07622856020669241\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0.25\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"Jhz9BiIwGCsV"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["59834b2eebd7484f8f824139d52dd2d3","4d177a0fe92c499786d4214738a702a5","fbe95058a4b74382a476622f99a2bfab","dd8439b8cd3d4e1dba3f501ed853eacf","d4b190f51eea40d59a89fb16e416931e","99ad0a784c3743efbca135e1f3d45fa7","3272d17ca3bb4a1bb693729b9334616f","870531d1294f4cf3ae3b0497a7da2eaf","c84182275ab644ec8c2397ba53c56e05","25cb7be8e237491d9a1f270a46980b44","7e589cfd202547928af1738ee3190bd5"]},"executionInfo":{"elapsed":5018635,"status":"ok","timestamp":1667347388857,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"v6Y1n1aDKltL","outputId":"faffb8c7-92f9-446b-cf7d-a36c25f58df6"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 25.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"59834b2eebd7484f8f824139d52dd2d3","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 17334\n","Points in y_train after augmentation: 17334\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7895307540893555\n","Training loss per 100 training steps: 0.3965668586073535\n","Training loss per 100 training steps: 0.2910103294535063\n","Training loss per 100 training steps: 0.2525409285684559\n","Training loss per 100 training steps: 0.2283859809865232\n","Training loss per 100 training steps: 0.2099442799573768\n","Training loss epoch: 0.20491502651896643\n","Training accuracy epoch: 0.9349403675303204\n","Validating model...\n","Validation Loss: 0.1312686703712135\n","Validation Accuracy: 0.9560881707404256\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0999687910079956\n","Training loss per 100 training steps: 0.08771512685989094\n","Training loss per 100 training steps: 0.08516727551002408\n","Training loss per 100 training steps: 0.08663842561608336\n","Training loss per 100 training steps: 0.08839120579758042\n","Training loss per 100 training steps: 0.08850531896461032\n","Training loss epoch: 0.08820365038717586\n","Training accuracy epoch: 0.9720468857356204\n","Validating model...\n","Validation Loss: 0.1566660779395274\n","Validation Accuracy: 0.9542215111319942\n","Training epoch: 3\n","Training loss per 100 training steps: 0.030197808519005775\n","Training loss per 100 training steps: 0.04731701558345173\n","Training loss per 100 training steps: 0.050412473146020625\n","Training loss per 100 training steps: 0.050490755227354175\n","Training loss per 100 training steps: 0.05183445263486774\n","Training loss per 100 training steps: 0.05278023398721111\n","Training loss epoch: 0.053700946123645094\n","Training accuracy epoch: 0.9828382923240525\n","Validating model...\n","Validation Loss: 0.1706305400698216\n","Validation Accuracy: 0.9559325080776868\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01960335671901703\n","Training loss per 100 training steps: 0.03869369759288902\n","Training loss per 100 training steps: 0.03522649111077931\n","Training loss per 100 training steps: 0.034357702778420256\n","Training loss per 100 training steps: 0.036097470099313134\n","Training loss per 100 training steps: 0.03699846754009518\n","Training loss epoch: 0.03670825912746879\n","Training accuracy epoch: 0.988282285130914\n","Validating model...\n","Validation Loss: 0.17435399851120717\n","Validation Accuracy: 0.9574410784905083\n","Training epoch: 5\n","Training loss per 100 training steps: 0.022410543635487556\n","Training loss per 100 training steps: 0.024676973820839186\n","Training loss per 100 training steps: 0.026435209879540462\n","Training loss per 100 training steps: 0.025943186978014354\n","Training loss per 100 training steps: 0.027375313680400686\n","Training loss per 100 training steps: 0.02784523652762383\n","Training loss epoch: 0.02788583773344659\n","Training accuracy epoch: 0.9914980510422231\n","Validating model...\n","Validation Loss: 0.2145990664502243\n","Validation Accuracy: 0.9561379835286098\n","Training epoch: 6\n","Training loss per 100 training steps: 0.007957621477544308\n","Training loss per 100 training steps: 0.021312099140907387\n","Training loss per 100 training steps: 0.022193132070604416\n","Training loss per 100 training steps: 0.02141086687179177\n","Training loss per 100 training steps: 0.021821883343626974\n","Training loss per 100 training steps: 0.022195166088649985\n","Training loss epoch: 0.022269055220458273\n","Training accuracy epoch: 0.993160494565503\n","Validating model...\n","Validation Loss: 0.18112536921776687\n","Validation Accuracy: 0.9605692370149931\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 57.26111276666667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14173268428378463\n","Validation Accuracy: 0.954270987739915\n","Validation duration: 5.535278983333327 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.84      0.83     12546\n","        test       0.86      0.88      0.87      9012\n","   treatment       0.80      0.87      0.83      9297\n","\n","   micro avg       0.83      0.86      0.84     30855\n","   macro avg       0.83      0.86      0.85     30855\n","weighted avg       0.83      0.86      0.84     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 17334\n","Points in y_train after augmentation: 17334\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1808688640594482\n","Training loss per 100 training steps: 0.4092727118346951\n","Training loss per 100 training steps: 0.30983935897030046\n","Training loss per 100 training steps: 0.2645765508082618\n","Training loss per 100 training steps: 0.24108144467199533\n","Training loss per 100 training steps: 0.22048887523437688\n","Training loss epoch: 0.214591501658693\n","Training accuracy epoch: 0.9316496522682105\n","Validating model...\n","Validation Loss: 0.131456860377417\n","Validation Accuracy: 0.9589063541755927\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09687907993793488\n","Training loss per 100 training steps: 0.08512830844905117\n","Training loss per 100 training steps: 0.09129693042208899\n","Training loss per 100 training steps: 0.0910409860486208\n","Training loss per 100 training steps: 0.09049791344290511\n","Training loss per 100 training steps: 0.0914729395119135\n","Training loss epoch: 0.09167348601721309\n","Training accuracy epoch: 0.9707261333184581\n","Validating model...\n","Validation Loss: 0.14059635447701077\n","Validation Accuracy: 0.9592898534546498\n","Training epoch: 3\n","Training loss per 100 training steps: 0.013491712510585785\n","Training loss per 100 training steps: 0.043913869768159815\n","Training loss per 100 training steps: 0.048253190499818445\n","Training loss per 100 training steps: 0.05207653627406026\n","Training loss per 100 training steps: 0.051221836722941325\n","Training loss per 100 training steps: 0.05318997947391338\n","Training loss epoch: 0.0547647321883699\n","Training accuracy epoch: 0.9824903739880314\n","Validating model...\n","Validation Loss: 0.15427691346735922\n","Validation Accuracy: 0.9586800609315019\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03987528383731842\n","Training loss per 100 training steps: 0.03585770058371864\n","Training loss per 100 training steps: 0.03956190837936392\n","Training loss per 100 training steps: 0.040890804959145495\n","Training loss per 100 training steps: 0.04236651232298882\n","Training loss per 100 training steps: 0.04251690790709666\n","Training loss epoch: 0.04286078050710274\n","Training accuracy epoch: 0.9865810917728404\n","Validating model...\n","Validation Loss: 0.1624982033360314\n","Validation Accuracy: 0.9584107780073294\n","Training epoch: 5\n","Training loss per 100 training steps: 0.025764118880033493\n","Training loss per 100 training steps: 0.032876175906656695\n","Training loss per 100 training steps: 0.02894516486676864\n","Training loss per 100 training steps: 0.02847841804505997\n","Training loss per 100 training steps: 0.02924023247065552\n","Training loss per 100 training steps: 0.029720223308359637\n","Training loss epoch: 0.029966318905435167\n","Training accuracy epoch: 0.9906050196310024\n","Validating model...\n","Validation Loss: 0.1853976311016973\n","Validation Accuracy: 0.9589528674075146\n","Training epoch: 6\n","Training loss per 100 training steps: 0.010987839661538601\n","Training loss per 100 training steps: 0.027103154454380274\n","Training loss per 100 training steps: 0.025907789886377715\n","Training loss per 100 training steps: 0.025365569085761458\n","Training loss per 100 training steps: 0.025154067433330037\n","Training loss per 100 training steps: 0.027036028157105436\n","Training loss epoch: 0.02725392230528637\n","Training accuracy epoch: 0.9914886454490068\n","Validating model...\n","Validation Loss: 0.18240072313157915\n","Validation Accuracy: 0.9587399603559383\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 57.16464161666668 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14293708744959008\n","Validation Accuracy: 0.9551874208898307\n","Validation duration: 5.49330466666667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.3%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.85      0.84     12546\n","        test       0.84      0.86      0.85      9012\n","   treatment       0.84      0.85      0.84      9297\n","\n","   micro avg       0.83      0.85      0.84     30855\n","   macro avg       0.83      0.85      0.84     30855\n","weighted avg       0.83      0.85      0.84     30855\n","\n"]}],"source":["number_of_training_models = 2\n","target_augmented_percentage = 0.25\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"v6Y1n1aDKltL"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31917004,"status":"ok","timestamp":1667396047994,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"jdO4m5O4Hlo3","outputId":"3b0cfe33-1556-47ee-d112-e2298048b664"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 50.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 20801\n","Points in y_train after augmentation: 20801\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8073434829711914\n","Training loss per 100 training steps: 0.4044900108682047\n","Training loss per 100 training steps: 0.30017968111518606\n","Training loss per 100 training steps: 0.2587639229415461\n","Training loss per 100 training steps: 0.23731037753255588\n","Training loss per 100 training steps: 0.21974041681000572\n","Training loss per 100 training steps: 0.20982266461070684\n","Training loss epoch: 0.2062764485422436\n","Training accuracy epoch: 0.9348444338560578\n","Validating model...\n","Validation Loss: 0.147430142170036\n","Validation Accuracy: 0.9541219623845801\n","Training epoch: 2\n","Training loss per 100 training steps: 0.10353777557611465\n","Training loss per 100 training steps: 0.0987968636621343\n","Training loss per 100 training steps: 0.09176476430425894\n","Training loss per 100 training steps: 0.08769748517717436\n","Training loss per 100 training steps: 0.08714340028220653\n","Training loss per 100 training steps: 0.08761427128230205\n","Training loss per 100 training steps: 0.08607311904610146\n","Training loss epoch: 0.0856995598558167\n","Training accuracy epoch: 0.9723932086129613\n","Validating model...\n","Validation Loss: 0.14577468228224036\n","Validation Accuracy: 0.9566969435239647\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0198493804782629\n","Training loss per 100 training steps: 0.055603657950564184\n","Training loss per 100 training steps: 0.056060901833744486\n","Training loss per 100 training steps: 0.05358088585823477\n","Training loss per 100 training steps: 0.054633123579520985\n","Training loss per 100 training steps: 0.055989134539022836\n","Training loss per 100 training steps: 0.0576773394347043\n","Training loss epoch: 0.05788517122538889\n","Training accuracy epoch: 0.981473587262896\n","Validating model...\n","Validation Loss: 0.17314927804876457\n","Validation Accuracy: 0.9513576142480654\n","Training epoch: 4\n","Training loss per 100 training steps: 0.05093402788043022\n","Training loss per 100 training steps: 0.04761399064526552\n","Training loss per 100 training steps: 0.044501500713884534\n","Training loss per 100 training steps: 0.042736071112420275\n","Training loss per 100 training steps: 0.04152409112756779\n","Training loss per 100 training steps: 0.04170322257090368\n","Training loss per 100 training steps: 0.04163561556093122\n","Training loss epoch: 0.04154916683990886\n","Training accuracy epoch: 0.9867468817167667\n","Validating model...\n","Validation Loss: 0.16306455147924362\n","Validation Accuracy: 0.9584951660474055\n","Training epoch: 5\n","Training loss per 100 training steps: 0.02704017609357834\n","Training loss per 100 training steps: 0.02683762878197992\n","Stopping epoch...\n","Training loss epoch: 0.02683762878197992\n","Training accuracy epoch: 0.9812403520355021\n","Validating model...\n","Validation Loss: 0.18817691469879508\n","Validation Accuracy: 0.9592584041633448\n","Training epoch: 6\n","Training loss per 100 training steps: 0.003400432877242565\n","Training loss per 100 training steps: 0.020850856366594978\n","Training loss per 100 training steps: 0.023468364452924672\n","Training loss per 100 training steps: 0.02516443962447865\n","Training loss per 100 training steps: 0.025872674698075117\n","Training loss per 100 training steps: 0.02566034643131935\n","Training loss per 100 training steps: 0.025780965486144686\n","Training loss epoch: 0.026382648112603657\n","Training accuracy epoch: 0.9916703716302906\n","Validating model...\n","Validation Loss: 0.19473356886633805\n","Validation Accuracy: 0.9538441825355012\n","Training epoch: 7\n","Training loss per 100 training steps: 0.01460102666169405\n","Training loss per 100 training steps: 0.01955779326392688\n","Training loss per 100 training steps: 0.01987975094419909\n","Training loss per 100 training steps: 0.019085462569441658\n","Training loss per 100 training steps: 0.020623862379325782\n","Training loss per 100 training steps: 0.021323552987437894\n","Training loss per 100 training steps: 0.021543145564538946\n","Training loss epoch: 0.02183630694619118\n","Training accuracy epoch: 0.9932844236895343\n","Validating model...\n","Validation Loss: 0.19023202350000282\n","Validation Accuracy: 0.9588474341071245\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 70.3094564 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1614868975184099\n","Validation Accuracy: 0.9526129725256316\n","Validation duration: 5.472936566666673 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.85      0.84     12546\n","        test       0.84      0.84      0.84      9012\n","   treatment       0.82      0.84      0.83      9297\n","\n","   micro avg       0.83      0.85      0.84     30855\n","   macro avg       0.83      0.84      0.84     30855\n","weighted avg       0.83      0.85      0.84     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 20801\n","Points in y_train after augmentation: 20801\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9656524658203125\n","Training loss per 100 training steps: 0.37440282711298156\n","Training loss per 100 training steps: 0.2891358184391883\n","Training loss per 100 training steps: 0.2485024830159357\n","Training loss per 100 training steps: 0.22718556315877342\n","Training loss per 100 training steps: 0.21043141513780325\n","Training loss per 100 training steps: 0.19677604892649092\n","Training loss epoch: 0.19132567100089543\n","Training accuracy epoch: 0.9386518519922401\n","Validating model...\n","Validation Loss: 0.1275239552117207\n","Validation Accuracy: 0.9602342660354913\n","Training epoch: 2\n","Training loss per 100 training steps: 0.03448477014899254\n","Training loss per 100 training steps: 0.08972078819971273\n","Training loss per 100 training steps: 0.08538507203112787\n","Training loss per 100 training steps: 0.08279146087290935\n","Training loss per 100 training steps: 0.08149691257495759\n","Training loss per 100 training steps: 0.08277366230052388\n","Training loss per 100 training steps: 0.08328020424208606\n","Training loss epoch: 0.08274377769820633\n","Training accuracy epoch: 0.9737021130847914\n","Validating model...\n","Validation Loss: 0.14259020737432815\n","Validation Accuracy: 0.9576921586218198\n","Training epoch: 3\n","Training loss per 100 training steps: 0.013852535746991634\n","Training loss per 100 training steps: 0.043190529399394696\n","Training loss per 100 training steps: 0.044424077574701154\n","Training loss per 100 training steps: 0.04537415575000931\n","Training loss per 100 training steps: 0.046895975031032974\n","Training loss per 100 training steps: 0.04860397969500836\n","Training loss per 100 training steps: 0.04917133135795469\n","Training loss epoch: 0.04982540980210319\n","Training accuracy epoch: 0.9845880651727507\n","Validating model...\n","Validation Loss: 0.1626359982682126\n","Validation Accuracy: 0.9567665765833303\n","Training epoch: 4\n","Training loss per 100 training steps: 0.05247092992067337\n","Training loss per 100 training steps: 0.041494296471781954\n","Training loss per 100 training steps: 0.04323194502848224\n","Training loss per 100 training steps: 0.0421773214279937\n","Training loss per 100 training steps: 0.04260169719043943\n","Training loss per 100 training steps: 0.04297993143698844\n","Training loss per 100 training steps: 0.04160285516744309\n","Training loss epoch: 0.04150910928208161\n","Training accuracy epoch: 0.9871507364625877\n","Validating model...\n","Validation Loss: 0.18285823939972884\n","Validation Accuracy: 0.9577494870591652\n","Training epoch: 5\n","Training loss per 100 training steps: 0.019292093813419342\n","Training loss per 100 training steps: 0.02354827178480786\n","Training loss per 100 training steps: 0.02240526588084593\n","Training loss per 100 training steps: 0.02561856579442394\n","Training loss per 100 training steps: 0.025194714885458182\n","Training loss per 100 training steps: 0.026129326958556895\n","Training loss per 100 training steps: 0.026881293812844154\n","Training loss epoch: 0.027485627714993743\n","Training accuracy epoch: 0.9912947927325583\n","Validating model...\n","Validation Loss: 0.17658840118629204\n","Validation Accuracy: 0.9592026476781078\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0022208455484360456\n","Training loss per 100 training steps: 0.019815178563827557\n","Training loss per 100 training steps: 0.019923609365194814\n","Training loss per 100 training steps: 0.020499340898629613\n","Training loss per 100 training steps: 0.024394713792464513\n","Training loss per 100 training steps: 0.02669023335730088\n","Training loss per 100 training steps: 0.026121156318938382\n","Training loss epoch: 0.026183481959487668\n","Training accuracy epoch: 0.9918123176561333\n","Validating model...\n","Validation Loss: 0.19649115403170708\n","Validation Accuracy: 0.9571623890074734\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 68.12516971666668 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1378915870532014\n","Validation Accuracy: 0.9564275388689825\n","Validation duration: 5.480230033333343 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.9%\n","              precision    recall  f1-score   support\n","\n","     problem       0.84      0.86      0.85     12546\n","        test       0.83      0.88      0.85      9012\n","   treatment       0.82      0.87      0.85      9297\n","\n","   micro avg       0.83      0.87      0.85     30855\n","   macro avg       0.83      0.87      0.85     30855\n","weighted avg       0.83      0.87      0.85     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 20801\n","Points in y_train after augmentation: 20801\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9386218786239624\n","Training loss per 100 training steps: 0.41126632151922377\n","Training loss per 100 training steps: 0.30890714073210807\n","Training loss per 100 training steps: 0.26149320045479907\n","Training loss per 100 training steps: 0.23753408911147914\n","Training loss per 100 training steps: 0.21734527001034715\n","Training loss per 100 training steps: 0.20440211181781454\n","Training loss epoch: 0.1988361204864197\n","Training accuracy epoch: 0.9366514236204875\n","Validating model...\n","Validation Loss: 0.12779258150462205\n","Validation Accuracy: 0.9574918693163899\n","Training epoch: 2\n","Training loss per 100 training steps: 0.1143929585814476\n","Training loss per 100 training steps: 0.08136612402810024\n","Training loss per 100 training steps: 0.0791496367967544\n","Training loss per 100 training steps: 0.08056386237796953\n","Training loss per 100 training steps: 0.08290852169202004\n","Training loss per 100 training steps: 0.0838657543769556\n","Training loss per 100 training steps: 0.08406165892106424\n","Training loss epoch: 0.08384463888835864\n","Training accuracy epoch: 0.9729270180501494\n","Validating model...\n","Validation Loss: 0.13538014612995186\n","Validation Accuracy: 0.9610752823937582\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04158424958586693\n","Training loss per 100 training steps: 0.04374459382183481\n","Training loss per 100 training steps: 0.048326904498578155\n","Training loss per 100 training steps: 0.04905802858730413\n","Training loss per 100 training steps: 0.05102199741448752\n","Training loss per 100 training steps: 0.05169553643402954\n","Training loss per 100 training steps: 0.051625940270377896\n","Training loss epoch: 0.052429310819913796\n","Training accuracy epoch: 0.983653325725952\n","Validating model...\n","Validation Loss: 0.14771062263904453\n","Validation Accuracy: 0.9586492689917036\n","Training epoch: 4\n","Training loss per 100 training steps: 0.04728073999285698\n","Training loss per 100 training steps: 0.028262030010545017\n","Training loss per 100 training steps: 0.028984259054718065\n","Training loss per 100 training steps: 0.029167671570712175\n","Training loss per 100 training steps: 0.031631953799760346\n","Training loss per 100 training steps: 0.031204139297231363\n","Training loss per 100 training steps: 0.032825967855015445\n","Training loss epoch: 0.03359793891855692\n","Training accuracy epoch: 0.9892205319931984\n","Validating model...\n","Validation Loss: 0.16304261557902996\n","Validation Accuracy: 0.9574823126914719\n","Training epoch: 5\n","Training loss per 100 training steps: 0.019928639754652977\n","Training loss per 100 training steps: 0.03004193400945699\n","Training loss per 100 training steps: 0.02755702134634169\n","Training loss per 100 training steps: 0.026823845596835514\n","Training loss per 100 training steps: 0.027658210162705095\n","Training loss per 100 training steps: 0.028475509225920646\n","Training loss per 100 training steps: 0.02817339515863622\n","Training loss epoch: 0.028208012192992182\n","Training accuracy epoch: 0.991250551793928\n","Validating model...\n","Validation Loss: 0.171312072931172\n","Validation Accuracy: 0.9585114535508976\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0014592325314879417\n","Training loss per 100 training steps: 0.021214829793541074\n","Training loss per 100 training steps: 0.019646144179286743\n","Training loss per 100 training steps: 0.022952238866862876\n","Training loss per 100 training steps: 0.02332951385278761\n","Training loss per 100 training steps: 0.024089341625704166\n","Training loss per 100 training steps: 0.025320174892804123\n","Training loss epoch: 0.02557055755100283\n","Training accuracy epoch: 0.9920739354467064\n","Validating model...\n","Validation Loss: 0.18149496997138123\n","Validation Accuracy: 0.9596629030750349\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 68.13255465000002 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14003317175579635\n","Validation Accuracy: 0.9563734557725003\n","Validation duration: 5.4734658333333455 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.85      0.84     12546\n","        test       0.86      0.86      0.86      9012\n","   treatment       0.85      0.84      0.85      9297\n","\n","   micro avg       0.84      0.85      0.85     30855\n","   macro avg       0.84      0.85      0.85     30855\n","weighted avg       0.84      0.85      0.85     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 20801\n","Points in y_train after augmentation: 20801\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0162739753723145\n","Training loss per 100 training steps: 0.4006699294146925\n","Training loss per 100 training steps: 0.3072202716078331\n","Training loss per 100 training steps: 0.25928346718045764\n","Training loss per 100 training steps: 0.23191084144660212\n","Training loss per 100 training steps: 0.2156606041408049\n","Training loss per 100 training steps: 0.2011692459585018\n","Training loss epoch: 0.19528296178123827\n","Training accuracy epoch: 0.9387496808033668\n","Validating model...\n","Validation Loss: 0.13051058739036708\n","Validation Accuracy: 0.9560261107879197\n","Training epoch: 2\n","Training loss per 100 training steps: 0.08764147758483887\n","Training loss per 100 training steps: 0.0843101915082719\n","Training loss per 100 training steps: 0.08791800223253853\n","Training loss per 100 training steps: 0.08484306652408304\n","Training loss per 100 training steps: 0.08465450284003914\n","Training loss per 100 training steps: 0.08526339169271929\n","Training loss per 100 training steps: 0.08582671469669423\n","Training loss epoch: 0.08599815353001547\n","Training accuracy epoch: 0.972715904732517\n","Validating model...\n","Validation Loss: 0.1500374082137238\n","Validation Accuracy: 0.954442235334506\n","Training epoch: 3\n","Training loss per 100 training steps: 0.017563704401254654\n","Training loss per 100 training steps: 0.052384662681655716\n","Training loss per 100 training steps: 0.05100168000017084\n","Training loss per 100 training steps: 0.050741808996396603\n","Training loss per 100 training steps: 0.05047512470054768\n","Training loss per 100 training steps: 0.051775626864232226\n","Training loss per 100 training steps: 0.051711174648196225\n","Training loss epoch: 0.05137908501735103\n","Training accuracy epoch: 0.9838989517394611\n","Validating model...\n","Validation Loss: 0.1643899960425235\n","Validation Accuracy: 0.959035362729745\n","Training epoch: 4\n","Training loss per 100 training steps: 0.10246575623750687\n","Training loss per 100 training steps: 0.03297898262776065\n","Training loss per 100 training steps: 0.03506537304208869\n","Training loss per 100 training steps: 0.03460817564467581\n","Training loss per 100 training steps: 0.035411587098794536\n","Training loss per 100 training steps: 0.035296629460904\n","Training loss per 100 training steps: 0.035826607408759786\n","Training loss epoch: 0.03558761335354293\n","Training accuracy epoch: 0.988902191650215\n","Validating model...\n","Validation Loss: 0.18154066530140964\n","Validation Accuracy: 0.9581048200127047\n","Training epoch: 5\n","Training loss per 100 training steps: 0.10503437370061874\n","Training loss per 100 training steps: 0.02930047174012012\n","Training loss per 100 training steps: 0.027285310230681217\n","Training loss per 100 training steps: 0.027438295621462043\n","Training loss per 100 training steps: 0.02673368976263334\n","Training loss per 100 training steps: 0.025984697846719945\n","Training loss per 100 training steps: 0.02697596376339135\n","Training loss epoch: 0.027100438378073886\n","Training accuracy epoch: 0.991592622525879\n","Validating model...\n","Validation Loss: 0.19672484910599403\n","Validation Accuracy: 0.9569801138433476\n","Training epoch: 6\n","Training loss per 100 training steps: 0.014734188094735146\n","Training loss per 100 training steps: 0.026085130297486662\n","Training loss per 100 training steps: 0.026135804665631694\n","Training loss per 100 training steps: 0.02723163869185528\n","Training loss per 100 training steps: 0.02665554762654183\n","Training loss per 100 training steps: 0.026403041167729378\n","Training loss per 100 training steps: 0.02602942235229929\n","Training loss epoch: 0.025976065035928905\n","Training accuracy epoch: 0.9921173804496245\n","Validating model...\n","Validation Loss: 0.1954797419973395\n","Validation Accuracy: 0.9572593075793101\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 67.98335275000002 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14545851045059627\n","Validation Accuracy: 0.9546901892099624\n","Validation duration: 5.4627745499999945 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.3%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.85      0.83     12546\n","        test       0.86      0.88      0.87      9012\n","   treatment       0.80      0.87      0.83      9297\n","\n","   micro avg       0.82      0.86      0.84     30855\n","   macro avg       0.83      0.86      0.84     30855\n","weighted avg       0.82      0.86      0.84     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 20801\n","Points in y_train after augmentation: 20801\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.2096478939056396\n","Training loss per 100 training steps: 0.40473801797569386\n","Training loss per 100 training steps: 0.30858353440144765\n","Training loss per 100 training steps: 0.2621891313786324\n","Training loss per 100 training steps: 0.23898321860226016\n","Training loss per 100 training steps: 0.21863849726905246\n","Training loss per 100 training steps: 0.20879451703968244\n","Training loss epoch: 0.2026607651784215\n","Training accuracy epoch: 0.9354851720139113\n","Validating model...\n","Validation Loss: 0.13966770160507846\n","Validation Accuracy: 0.9564723307260706\n","Training epoch: 2\n","Training loss per 100 training steps: 0.11913399398326874\n","Training loss per 100 training steps: 0.07960214684394622\n","Training loss per 100 training steps: 0.0808808908042549\n","Training loss per 100 training steps: 0.0804164351746935\n","Training loss per 100 training steps: 0.08052543122692968\n","Training loss per 100 training steps: 0.08307576768598454\n","Training loss per 100 training steps: 0.08317302454870423\n","Training loss epoch: 0.08354888627943675\n","Training accuracy epoch: 0.9734759480982756\n","Validating model...\n","Validation Loss: 0.1435537410827426\n","Validation Accuracy: 0.9570936187482666\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0698944553732872\n","Training loss per 100 training steps: 0.04118229062434765\n","Training loss per 100 training steps: 0.04474292745389767\n","Training loss per 100 training steps: 0.046895605380851094\n","Training loss per 100 training steps: 0.05012549479414205\n","Training loss per 100 training steps: 0.050637251393778435\n","Training loss per 100 training steps: 0.05086723156525179\n","Training loss epoch: 0.051813370250444434\n","Training accuracy epoch: 0.9837673966423918\n","Validating model...\n","Validation Loss: 0.15827666266591517\n","Validation Accuracy: 0.9583828548180409\n","Training epoch: 4\n","Training loss per 100 training steps: 0.029648592695593834\n","Training loss per 100 training steps: 0.03372141185774477\n","Training loss per 100 training steps: 0.03711124035455657\n","Training loss per 100 training steps: 0.03825972256895798\n","Training loss per 100 training steps: 0.038603533439958315\n","Training loss per 100 training steps: 0.03809484960014064\n","Training loss per 100 training steps: 0.03868691555085668\n","Training loss epoch: 0.03858433577698171\n","Training accuracy epoch: 0.9881970195166424\n","Validating model...\n","Validation Loss: 0.16432324971084472\n","Validation Accuracy: 0.959137631863957\n","Training epoch: 5\n","Training loss per 100 training steps: 0.013373333029448986\n","Training loss per 100 training steps: 0.02147194117625788\n","Training loss per 100 training steps: 0.021256983494478746\n","Training loss per 100 training steps: 0.02239123910980336\n","Training loss per 100 training steps: 0.023593800068813193\n","Training loss per 100 training steps: 0.02465109665287443\n","Training loss per 100 training steps: 0.026244397438150643\n","Training loss epoch: 0.02654834732886464\n","Training accuracy epoch: 0.9917404956790038\n","Validating model...\n","Validation Loss: 0.216243312040997\n","Validation Accuracy: 0.9558683652748847\n","Training epoch: 6\n","Training loss per 100 training steps: 0.001750736846588552\n","Training loss per 100 training steps: 0.03176404057776021\n","Training loss per 100 training steps: 0.031320401934781736\n","Training loss per 100 training steps: 0.02740752050131745\n","Training loss per 100 training steps: 0.026384293573485814\n","Training loss per 100 training steps: 0.026617546274095304\n","Training loss per 100 training steps: 0.026215410259139326\n","Training loss epoch: 0.02570607925462286\n","Training accuracy epoch: 0.9921112666772165\n","Validating model...\n","Validation Loss: 0.19680701254250169\n","Validation Accuracy: 0.9591321358939373\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 68.11765469999997 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14653218257094355\n","Validation Accuracy: 0.9539126950981562\n","Validation duration: 5.466130066666665 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.87      0.84     12546\n","        test       0.82      0.90      0.86      9012\n","   treatment       0.82      0.86      0.84      9297\n","\n","   micro avg       0.82      0.87      0.85     30855\n","   macro avg       0.82      0.87      0.85     30855\n","weighted avg       0.82      0.87      0.85     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 20801\n","Points in y_train after augmentation: 20801\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7230030298233032\n","Training loss per 100 training steps: 0.4120749558257584\n","Training loss per 100 training steps: 0.3071985332601106\n","Training loss per 100 training steps: 0.26218191732302853\n","Training loss per 100 training steps: 0.2353065399606329\n","Training loss per 100 training steps: 0.21923841388818033\n","Training loss per 100 training steps: 0.20509738926334112\n","Training loss epoch: 0.20083780678322813\n","Training accuracy epoch: 0.9363385450205137\n","Validating model...\n","Validation Loss: 0.15231345352027323\n","Validation Accuracy: 0.951705235807097\n","Training epoch: 2\n","Training loss per 100 training steps: 0.1158929169178009\n","Training loss per 100 training steps: 0.09040549107006576\n","Training loss per 100 training steps: 0.08831993183260088\n","Training loss per 100 training steps: 0.08877902763100508\n","Training loss per 100 training steps: 0.08744949394688382\n","Training loss per 100 training steps: 0.08709769968794819\n","Training loss per 100 training steps: 0.08722316228494842\n","Training loss epoch: 0.08718981273892906\n","Training accuracy epoch: 0.9721355719503777\n","Validating model...\n","Validation Loss: 0.13350101398279915\n","Validation Accuracy: 0.9604628774593041\n","Training epoch: 3\n","Training loss per 100 training steps: 0.028574930503964424\n","Training loss per 100 training steps: 0.04848331130930398\n","Training loss per 100 training steps: 0.047542839854334794\n","Training loss per 100 training steps: 0.04889775790735163\n","Training loss per 100 training steps: 0.05036438999760273\n","Training loss per 100 training steps: 0.051228291868602116\n","Training loss per 100 training steps: 0.05225481556770322\n","Training loss epoch: 0.05303410168421725\n","Training accuracy epoch: 0.9831239519644756\n","Validating model...\n","Validation Loss: 0.14929754932882724\n","Validation Accuracy: 0.9572819541699177\n","Training epoch: 4\n","Training loss per 100 training steps: 0.050419606268405914\n","Training loss per 100 training steps: 0.03285324638063955\n","Training loss per 100 training steps: 0.030678958400379663\n","Training loss per 100 training steps: 0.031965361763429255\n","Training loss per 100 training steps: 0.0331541109073006\n","Training loss per 100 training steps: 0.034829730769812675\n","Training loss per 100 training steps: 0.03471264666831198\n","Training loss epoch: 0.03511693022362659\n","Training accuracy epoch: 0.989135197972294\n","Validating model...\n","Validation Loss: 0.16436000843230006\n","Validation Accuracy: 0.9575265034363233\n","Training epoch: 5\n","Training loss per 100 training steps: 0.023727264255285263\n","Training loss per 100 training steps: 0.025177044687921753\n","Training loss per 100 training steps: 0.027361011700195014\n","Training loss per 100 training steps: 0.02765828470600478\n","Training loss per 100 training steps: 0.029686675005780528\n","Training loss per 100 training steps: 0.03046502947027492\n","Training loss per 100 training steps: 0.03064053136829795\n","Training loss epoch: 0.031060851147053578\n","Training accuracy epoch: 0.9899889369563961\n","Validating model...\n","Validation Loss: 0.17757727789946579\n","Validation Accuracy: 0.9584947804724392\n","Training epoch: 6\n","Training loss per 100 training steps: 0.004100081045180559\n","Training loss per 100 training steps: 0.017558182073332887\n","Training loss per 100 training steps: 0.018307568322385278\n","Training loss per 100 training steps: 0.020349873805362916\n","Training loss per 100 training steps: 0.022385619987473543\n","Training loss per 100 training steps: 0.023019871416784257\n","Training loss per 100 training steps: 0.02316552542340624\n","Training loss epoch: 0.023130114416818663\n","Training accuracy epoch: 0.9926963005020439\n","Validating model...\n","Validation Loss: 0.1905704384984134\n","Validation Accuracy: 0.9591589981565032\n","Training epoch: 7\n","Training loss per 100 training steps: 0.006860004272311926\n","Training loss per 100 training steps: 0.013603589880178766\n","Training loss per 100 training steps: 0.015533189252493857\n","Training loss per 100 training steps: 0.01534854888991821\n","Training loss per 100 training steps: 0.01662899181348367\n","Training loss per 100 training steps: 0.017275813389095493\n","Training loss per 100 training steps: 0.01834489349620618\n","Training loss epoch: 0.019060638828879758\n","Training accuracy epoch: 0.9942902599775278\n","Validating model...\n","Validation Loss: 0.19970125434073535\n","Validation Accuracy: 0.956784127391163\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 79.45273136666668 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15138699860243057\n","Validation Accuracy: 0.9558510038176945\n","Validation duration: 5.464740033333388 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.85      0.86      0.86     12546\n","        test       0.81      0.88      0.84      9012\n","   treatment       0.84      0.82      0.83      9297\n","\n","   micro avg       0.84      0.85      0.85     30855\n","   macro avg       0.83      0.85      0.84     30855\n","weighted avg       0.84      0.85      0.84     30855\n","\n","!!!!!! Starting model number 7 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 20801\n","Points in y_train after augmentation: 20801\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.877136468887329\n","Training loss per 100 training steps: 0.4122371353430323\n","Training loss per 100 training steps: 0.30813465652922495\n","Training loss per 100 training steps: 0.2647265772647735\n","Training loss per 100 training steps: 0.23976581801481525\n","Training loss per 100 training steps: 0.2215375832045923\n","Training loss per 100 training steps: 0.206798891690304\n","Training loss epoch: 0.20158687853375978\n","Training accuracy epoch: 0.9365071410777787\n","Validating model...\n","Validation Loss: 0.1330452644592756\n","Validation Accuracy: 0.9586693215930113\n","Training epoch: 2\n","Training loss per 100 training steps: 0.1082298681139946\n","Training loss per 100 training steps: 0.10732875991206949\n","Stopping epoch...\n","Training loss epoch: 0.10732875991206949\n","Training accuracy epoch: 0.9563973709285172\n","Validating model...\n","Validation Loss: 0.13701139475134286\n","Validation Accuracy: 0.9579096875224434\n","Training epoch: 3\n","Training loss per 100 training steps: 0.11607436835765839\n","Training loss per 100 training steps: 0.08856732401959967\n","Training loss per 100 training steps: 0.08994070088388909\n","Training loss per 100 training steps: 0.08900027079786177\n","Training loss per 100 training steps: 0.09013203044010888\n","Training loss per 100 training steps: 0.08809023278908518\n","Training loss per 100 training steps: 0.08766070342066383\n","Training loss epoch: 0.08757253021671338\n","Training accuracy epoch: 0.971497615293431\n","Validating model...\n","Validation Loss: 0.14194623990492386\n","Validation Accuracy: 0.9594496843703723\n","Training epoch: 4\n","Training loss per 100 training steps: 0.07098190486431122\n","Training loss per 100 training steps: 0.047871456859578\n","Training loss per 100 training steps: 0.049719116801108736\n","Training loss per 100 training steps: 0.04937722830974382\n","Training loss per 100 training steps: 0.04993795438151705\n","Training loss per 100 training steps: 0.05073512163563462\n","Training loss per 100 training steps: 0.05098878353920931\n","Training loss epoch: 0.051323611730961456\n","Training accuracy epoch: 0.9836461399325648\n","Validating model...\n","Validation Loss: 0.15163109752700313\n","Validation Accuracy: 0.9580494543164831\n","Training epoch: 5\n","Training loss per 100 training steps: 0.061118971556425095\n","Training loss per 100 training steps: 0.04024829998114469\n","Training loss per 100 training steps: 0.03944003792706673\n","Training loss per 100 training steps: 0.03746872158733466\n","Training loss per 100 training steps: 0.03861514154816989\n","Training loss per 100 training steps: 0.038652808646190015\n","Training loss per 100 training steps: 0.038739736209749034\n","Training loss epoch: 0.039811035738356655\n","Training accuracy epoch: 0.987151977064947\n","Validating model...\n","Validation Loss: 0.15403950120044219\n","Validation Accuracy: 0.9595916401004396\n","Training epoch: 6\n","Training loss per 100 training steps: 0.01481770072132349\n","Training loss per 100 training steps: 0.03141568773564431\n","Training loss per 100 training steps: 0.0322574500240089\n","Training loss per 100 training steps: 0.03093641889637392\n","Training loss per 100 training steps: 0.03219030198973239\n","Training loss per 100 training steps: 0.03254508482898305\n","Training loss per 100 training steps: 0.03291313564552059\n","Training loss epoch: 0.03298589467702608\n","Training accuracy epoch: 0.9898670793238388\n","Validating model...\n","Validation Loss: 0.18406450068245508\n","Validation Accuracy: 0.9580800447929472\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 58.88199260000001 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14869536329880012\n","Validation Accuracy: 0.9547382257248732\n","Validation duration: 5.469064733333289 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.9%\n","              precision    recall  f1-score   support\n","\n","     problem       0.84      0.86      0.85     12546\n","        test       0.87      0.85      0.86      9012\n","   treatment       0.81      0.87      0.84      9297\n","\n","   micro avg       0.84      0.86      0.85     30855\n","   macro avg       0.84      0.86      0.85     30855\n","weighted avg       0.84      0.86      0.85     30855\n","\n","!!!!!! Starting model number 8 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 20801\n","Points in y_train after augmentation: 20801\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0150578022003174\n","Training loss per 100 training steps: 0.3905931405059182\n","Training loss per 100 training steps: 0.303899769573959\n","Training loss per 100 training steps: 0.25881289184539025\n","Training loss per 100 training steps: 0.23530132907844542\n","Training loss per 100 training steps: 0.2201058980664926\n","Training loss per 100 training steps: 0.206061436504919\n","Training loss epoch: 0.200109771388467\n","Training accuracy epoch: 0.9365946417595868\n","Validating model...\n","Validation Loss: 0.15315426194242068\n","Validation Accuracy: 0.9521434137005996\n","Training epoch: 2\n","Training loss per 100 training steps: 0.16515177488327026\n","Training loss per 100 training steps: 0.08557825019158939\n","Training loss per 100 training steps: 0.08595214970873215\n","Training loss per 100 training steps: 0.0890606216888293\n","Training loss per 100 training steps: 0.08933446133634693\n","Training loss per 100 training steps: 0.08894821326666606\n","Training loss per 100 training steps: 0.08746445531059621\n","Training loss epoch: 0.08661211377614894\n","Training accuracy epoch: 0.9722285009525975\n","Validating model...\n","Validation Loss: 0.14106223643938828\n","Validation Accuracy: 0.9585011275223261\n","Training epoch: 3\n","Training loss per 100 training steps: 0.046456336975097656\n","Training loss per 100 training steps: 0.05059312735822531\n","Training loss per 100 training steps: 0.048199609985380476\n","Training loss per 100 training steps: 0.04692766915363232\n","Training loss per 100 training steps: 0.047822273086682146\n","Training loss per 100 training steps: 0.049091795423140606\n","Training loss per 100 training steps: 0.050924799746729914\n","Training loss epoch: 0.051754105879786426\n","Training accuracy epoch: 0.9834024846855689\n","Validating model...\n","Validation Loss: 0.1637698258575681\n","Validation Accuracy: 0.9547743025420556\n","Training epoch: 4\n","Training loss per 100 training steps: 0.028031179681420326\n","Training loss per 100 training steps: 0.03477779094424873\n","Training loss per 100 training steps: 0.0332560060981346\n","Training loss per 100 training steps: 0.03413249762648364\n","Training loss per 100 training steps: 0.034245645745826926\n","Training loss per 100 training steps: 0.03489839675057375\n","Training loss per 100 training steps: 0.03634550673546217\n","Training loss epoch: 0.03713772108844702\n","Training accuracy epoch: 0.9885005273336448\n","Validating model...\n","Validation Loss: 0.18102394487079862\n","Validation Accuracy: 0.9564654428148536\n","Training epoch: 5\n","Training loss per 100 training steps: 0.014352036640048027\n","Training loss per 100 training steps: 0.02738127183736219\n","Training loss per 100 training steps: 0.02598492709476158\n","Training loss per 100 training steps: 0.02522754716432415\n","Training loss per 100 training steps: 0.025695709203180633\n","Training loss per 100 training steps: 0.025963414822562883\n","Training loss per 100 training steps: 0.026631879665871026\n","Training loss epoch: 0.027989949784978378\n","Training accuracy epoch: 0.9911068074039512\n","Validating model...\n","Validation Loss: 0.19054322509252308\n","Validation Accuracy: 0.9583701495402379\n","Training epoch: 6\n","Training loss per 100 training steps: 0.03838825598359108\n","Training loss per 100 training steps: 0.06203329442345565\n","Training loss per 100 training steps: 0.04889002298086011\n","Training loss per 100 training steps: 0.04113987311171646\n","Training loss per 100 training steps: 0.037664648494683206\n","Training loss per 100 training steps: 0.036018052075416994\n","Training loss per 100 training steps: 0.034871392430483476\n","Training loss epoch: 0.03451389119975769\n","Training accuracy epoch: 0.98915057729476\n","Validating model...\n","Validation Loss: 0.1912084019126056\n","Validation Accuracy: 0.9583375294579318\n","Training epoch: 7\n","Training loss per 100 training steps: 0.006066292989999056\n","Training loss per 100 training steps: 0.020435507939482976\n","Training loss per 100 training steps: 0.019656818092363974\n","Training loss per 100 training steps: 0.018428916958306896\n","Training loss per 100 training steps: 0.01791402494075866\n","Training loss per 100 training steps: 0.018594740559716435\n","Training loss per 100 training steps: 0.019166814961430762\n","Training loss epoch: 0.019281765069924437\n","Training accuracy epoch: 0.9940213360010696\n","Validating model...\n","Validation Loss: 0.19789418258534913\n","Validation Accuracy: 0.9579356835127116\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 79.41427113333326 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1506128996390746\n","Validation Accuracy: 0.9560393574346615\n","Validation duration: 5.480457050000041 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.85      0.86      0.86     12546\n","        test       0.85      0.89      0.87      9012\n","   treatment       0.82      0.87      0.85      9297\n","\n","   micro avg       0.84      0.87      0.86     30855\n","   macro avg       0.84      0.87      0.86     30855\n","weighted avg       0.84      0.87      0.86     30855\n","\n","!!!!!! Starting model number 9 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 20801\n","Points in y_train after augmentation: 20801\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.083423137664795\n","Training loss per 100 training steps: 0.4174735574143948\n","Training loss per 100 training steps: 0.3141918273929933\n","Training loss per 100 training steps: 0.2651027780508876\n","Training loss per 100 training steps: 0.23894067715268183\n","Training loss per 100 training steps: 0.22110783379011884\n","Training loss per 100 training steps: 0.20779909563875337\n","Training loss epoch: 0.20399795022348555\n","Training accuracy epoch: 0.9353628897579936\n","Validating model...\n","Validation Loss: 0.12424887772407625\n","Validation Accuracy: 0.9582779315670674\n","Training epoch: 2\n","Training loss per 100 training steps: 0.13607670366764069\n","Training loss per 100 training steps: 0.08252631627613365\n","Training loss per 100 training steps: 0.08375886996364712\n","Training loss per 100 training steps: 0.08568931178520882\n","Training loss per 100 training steps: 0.0833888416993722\n","Training loss per 100 training steps: 0.0858386656708138\n","Training loss per 100 training steps: 0.0860072518040282\n","Training loss epoch: 0.08729130896194602\n","Training accuracy epoch: 0.9720760624148117\n","Validating model...\n","Validation Loss: 0.14934105931648187\n","Validation Accuracy: 0.9556371005747833\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03182509168982506\n","Training loss per 100 training steps: 0.04660658240041668\n","Training loss per 100 training steps: 0.0477913540987233\n","Training loss per 100 training steps: 0.05006934890672069\n","Training loss per 100 training steps: 0.05161735068477152\n","Training loss per 100 training steps: 0.05163799861851269\n","Training loss per 100 training steps: 0.05218272930717781\n","Training loss epoch: 0.053283958986956634\n","Training accuracy epoch: 0.9828799221386213\n","Validating model...\n","Validation Loss: 0.1497469801673448\n","Validation Accuracy: 0.9597509359913424\n","Training epoch: 4\n","Training loss per 100 training steps: 0.017963269725441933\n","Training loss per 100 training steps: 0.034905377685525776\n","Training loss per 100 training steps: 0.03555612054894405\n","Training loss per 100 training steps: 0.03497804755010825\n","Training loss per 100 training steps: 0.03680550928884871\n","Training loss per 100 training steps: 0.036508825132641906\n","Training loss per 100 training steps: 0.03657603242760757\n","Training loss epoch: 0.03706882481006176\n","Training accuracy epoch: 0.9883660859223461\n","Validating model...\n","Validation Loss: 0.17372696935017776\n","Validation Accuracy: 0.9581114994535854\n","Training epoch: 5\n","Training loss per 100 training steps: 0.023296181112527847\n","Training loss per 100 training steps: 0.026376949187534134\n","Training loss per 100 training steps: 0.025532151082419415\n","Training loss per 100 training steps: 0.02603319188482453\n","Training loss per 100 training steps: 0.028186182389581607\n","Training loss per 100 training steps: 0.02803698040757834\n","Training loss per 100 training steps: 0.029616889397585812\n","Training loss epoch: 0.029453811443342144\n","Training accuracy epoch: 0.9909486725396639\n","Validating model...\n","Validation Loss: 0.1839317115471251\n","Validation Accuracy: 0.9595955188437685\n","Training epoch: 6\n","Training loss per 100 training steps: 0.03852130100131035\n","Training loss per 100 training steps: 0.026363131009263567\n","Training loss per 100 training steps: 0.02750012199266985\n","Training loss per 100 training steps: 0.026451732236404665\n","Training loss per 100 training steps: 0.026974373662401865\n","Training loss per 100 training steps: 0.026885259224514582\n","Training loss per 100 training steps: 0.027142354719938956\n","Training loss epoch: 0.027142083906732124\n","Training accuracy epoch: 0.9915492536320965\n","Validating model...\n","Validation Loss: 0.1926273967006377\n","Validation Accuracy: 0.958375193926112\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 68.09856810000007 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14095660530599868\n","Validation Accuracy: 0.9556949215858426\n","Validation duration: 5.462395450000016 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.8%\n","              precision    recall  f1-score   support\n","\n","     problem       0.84      0.86      0.85     12546\n","        test       0.86      0.87      0.86      9012\n","   treatment       0.80      0.87      0.83      9297\n","\n","   micro avg       0.83      0.86      0.85     30855\n","   macro avg       0.83      0.86      0.85     30855\n","weighted avg       0.83      0.86      0.85     30855\n","\n","!!!!!! Starting model number 10 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 20801\n","Points in y_train after augmentation: 20801\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1586520671844482\n","Training loss per 100 training steps: 0.4108186817110175\n","Training loss per 100 training steps: 0.3179320009490151\n","Training loss per 100 training steps: 0.265442995348345\n","Training loss per 100 training steps: 0.23864087265477216\n","Training loss per 100 training steps: 0.2206671557792587\n","Training loss per 100 training steps: 0.2074703975067708\n","Training loss epoch: 0.20248788848219615\n","Training accuracy epoch: 0.9358652232392383\n","Validating model...\n","Validation Loss: 0.14202746352205028\n","Validation Accuracy: 0.9540895856722519\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05328585207462311\n","Training loss per 100 training steps: 0.08276211891765936\n","Training loss per 100 training steps: 0.08343743203689728\n","Training loss per 100 training steps: 0.08432869287207723\n","Training loss per 100 training steps: 0.08324882878743094\n","Training loss per 100 training steps: 0.08528257665984675\n","Training loss per 100 training steps: 0.08494967204470578\n","Training loss epoch: 0.08490859545529827\n","Training accuracy epoch: 0.9727128226322723\n","Validating model...\n","Validation Loss: 0.14078871476427687\n","Validation Accuracy: 0.9604258878886511\n","Training epoch: 3\n","Training loss per 100 training steps: 0.06158791854977608\n","Training loss per 100 training steps: 0.05012203788956498\n","Training loss per 100 training steps: 0.05236388723926609\n","Training loss per 100 training steps: 0.052045926306260586\n","Training loss per 100 training steps: 0.05247236419692078\n","Training loss per 100 training steps: 0.05313672890752821\n","Training loss per 100 training steps: 0.05320236940144526\n","Training loss epoch: 0.05380991725794708\n","Training accuracy epoch: 0.9827236789196491\n","Validating model...\n","Validation Loss: 0.15446333659740238\n","Validation Accuracy: 0.958664087768146\n","Training epoch: 4\n","Training loss per 100 training steps: 0.020367154851555824\n","Training loss per 100 training steps: 0.048800247585364054\n","Training loss per 100 training steps: 0.040510119952548725\n","Training loss per 100 training steps: 0.039801460157838524\n","Training loss per 100 training steps: 0.03992591326141224\n","Training loss per 100 training steps: 0.03984423717270102\n","Training loss per 100 training steps: 0.038808722253935335\n","Training loss epoch: 0.03892859577604737\n","Training accuracy epoch: 0.9878762212374627\n","Validating model...\n","Validation Loss: 0.19273604248202852\n","Validation Accuracy: 0.9554990685228335\n","Training epoch: 5\n","Training loss per 100 training steps: 0.04428552836179733\n","Training loss per 100 training steps: 0.026035349395951386\n","Training loss per 100 training steps: 0.023904966471649577\n","Training loss per 100 training steps: 0.024432976454213273\n","Training loss per 100 training steps: 0.027041914076933363\n","Training loss per 100 training steps: 0.027571197308366654\n","Training loss per 100 training steps: 0.02859268807614309\n","Training loss epoch: 0.02852230407406695\n","Training accuracy epoch: 0.9912436901897416\n","Validating model...\n","Validation Loss: 0.19032620326555394\n","Validation Accuracy: 0.9540345381817117\n","Training epoch: 6\n","Training loss per 100 training steps: 0.03619978949427605\n","Training loss per 100 training steps: 0.017580288088313387\n","Training loss per 100 training steps: 0.019916434873090083\n","Training loss per 100 training steps: 0.01983079319114741\n","Training loss per 100 training steps: 0.019753706247904023\n","Training loss per 100 training steps: 0.021205100167262462\n","Training loss per 100 training steps: 0.02140369950414995\n","Training loss epoch: 0.021538631642244815\n","Training accuracy epoch: 0.993412248273762\n","Validating model...\n","Validation Loss: 0.19699591077719028\n","Validation Accuracy: 0.9590864477823771\n","Training epoch: 7\n","Training loss per 100 training steps: 0.03411586210131645\n","Training loss per 100 training steps: 0.01912837613277174\n","Training loss per 100 training steps: 0.020657307872043652\n","Training loss per 100 training steps: 0.020555681193965267\n","Training loss per 100 training steps: 0.022218668447114166\n","Training loss per 100 training steps: 0.02217087446804439\n","Training loss per 100 training steps: 0.02166460504720124\n","Training loss epoch: 0.02126586610252308\n","Training accuracy epoch: 0.9933606798101564\n","Validating model...\n","Validation Loss: 0.20552922190203296\n","Validation Accuracy: 0.9609536408213337\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 79.49534351666662 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15694136043721638\n","Validation Accuracy: 0.955550924114294\n","Validation duration: 5.482890700000038 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.87      0.85     12546\n","        test       0.82      0.89      0.85      9012\n","   treatment       0.83      0.86      0.85      9297\n","\n","   micro avg       0.83      0.87      0.85     30855\n","   macro avg       0.83      0.88      0.85     30855\n","weighted avg       0.83      0.87      0.85     30855\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0.5\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"jdO4m5O4Hlo3"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oKNxFPucHn_R","outputId":"d3c0c4a3-d3e2-4d7f-bb07-39972c1d8f99"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 75.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 24268\n","Points in y_train after augmentation: 24268\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8476709127426147\n","Training loss per 100 training steps: 0.4092931141062538\n","Training loss per 100 training steps: 0.3070901362271748\n","Training loss per 100 training steps: 0.26342757907618713\n","Training loss per 100 training steps: 0.23882094243926896\n","Training loss per 100 training steps: 0.21935514718323887\n","Training loss per 100 training steps: 0.20596249398470123\n","Training loss per 100 training steps: 0.19587809397186684\n","Training loss epoch: 0.19002788337450646\n","Training accuracy epoch: 0.9392558544031948\n","Validating model...\n","Validation Loss: 0.14639625587053112\n","Validation Accuracy: 0.95540140471595\n","Training epoch: 2\n","Training loss per 100 training steps: 0.10981884598731995\n","Training loss per 100 training steps: 0.08380769572156195\n","Training loss per 100 training steps: 0.08260262126464453\n","Training loss per 100 training steps: 0.08073673744769488\n","Training loss per 100 training steps: 0.08157146346994543\n","Training loss per 100 training steps: 0.08192407499864965\n","Training loss per 100 training steps: 0.08138572356156919\n","Training loss per 100 training steps: 0.0810084544247104\n","Training loss epoch: 0.08105232761694273\n","Training accuracy epoch: 0.9738986560016756\n","Validating model...\n","Validation Loss: 0.15320176851343026\n","Validation Accuracy: 0.9588186914941373\n","Training epoch: 3\n","Training loss per 100 training steps: 0.025979019701480865\n","Training loss per 100 training steps: 0.052233056123783386\n","Training loss per 100 training steps: 0.04842908519890104\n","Training loss per 100 training steps: 0.051529484343068345\n","Training loss per 100 training steps: 0.05101220573221991\n","Training loss per 100 training steps: 0.0513161540546356\n","Training loss per 100 training steps: 0.050460296709357005\n","Training loss per 100 training steps: 0.0505220688155091\n","Training loss epoch: 0.050282060098588925\n","Training accuracy epoch: 0.9839987408509795\n","Validating model...\n","Validation Loss: 0.16870873150500384\n","Validation Accuracy: 0.9578584823544989\n","Training epoch: 4\n","Training loss per 100 training steps: 0.09967804700136185\n","Training loss per 100 training steps: 0.037598739186818206\n","Training loss per 100 training steps: 0.03707885431978314\n","Training loss per 100 training steps: 0.03605682621756414\n","Training loss per 100 training steps: 0.036607474768580756\n","Training loss per 100 training steps: 0.03612158422454998\n","Training loss per 100 training steps: 0.03633849793338463\n","Training loss per 100 training steps: 0.037661525941641204\n","Training loss epoch: 0.037922504458304036\n","Training accuracy epoch: 0.9879411168070384\n","Validating model...\n","Validation Loss: 0.19670440130806588\n","Validation Accuracy: 0.9482128837127924\n","Training epoch: 5\n","Training loss per 100 training steps: 0.07171911001205444\n","Training loss per 100 training steps: 0.03408977886117847\n","Training loss per 100 training steps: 0.032599377233896464\n","Training loss per 100 training steps: 0.03184299165014784\n","Training loss per 100 training steps: 0.029697017525578212\n","Training loss per 100 training steps: 0.029289387756709508\n","Training loss per 100 training steps: 0.029652312260427933\n","Training loss per 100 training steps: 0.02973687734033716\n","Training loss epoch: 0.03019726880438312\n","Training accuracy epoch: 0.9903632045522234\n","Validating model...\n","Validation Loss: 0.18552134475102286\n","Validation Accuracy: 0.9592880619153576\n","Training epoch: 6\n","Training loss per 100 training steps: 0.013815011829137802\n","Training loss per 100 training steps: 0.021764539201780786\n","Training loss per 100 training steps: 0.022498125662165348\n","Training loss per 100 training steps: 0.022338687867874532\n","Training loss per 100 training steps: 0.02225343058129048\n","Training loss per 100 training steps: 0.022166758341302988\n","Training loss per 100 training steps: 0.02210834332477974\n","Training loss per 100 training steps: 0.02207160034685591\n","Training loss epoch: 0.02208269919750093\n","Training accuracy epoch: 0.9929643012297173\n","Validating model...\n","Validation Loss: 0.22269346037359497\n","Validation Accuracy: 0.9553015791027566\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 78.96844151666664 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16002162578257006\n","Validation Accuracy: 0.9534699419643793\n","Validation duration: 5.47148368333316 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.85      0.83      0.84     12546\n","        test       0.83      0.84      0.83      9012\n","   treatment       0.84      0.81      0.83      9297\n","\n","   micro avg       0.84      0.83      0.83     30855\n","   macro avg       0.84      0.83      0.83     30855\n","weighted avg       0.84      0.83      0.83     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 24268\n","Points in y_train after augmentation: 24268\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0992424488067627\n","Training loss per 100 training steps: 0.4089868397700905\n","Training loss per 100 training steps: 0.31024294756167564\n","Training loss per 100 training steps: 0.27046586601589606\n","Training loss per 100 training steps: 0.24342020247085136\n","Training loss per 100 training steps: 0.2259734465281466\n","Training loss per 100 training steps: 0.2103936736210065\n","Training loss per 100 training steps: 0.19981020201428046\n","Training loss epoch: 0.1934812913804618\n","Training accuracy epoch: 0.9386818132354123\n","Validating model...\n","Validation Loss: 0.13256121371183302\n","Validation Accuracy: 0.9597544543171445\n","Training epoch: 2\n","Training loss per 100 training steps: 0.11699153482913971\n","Training loss per 100 training steps: 0.08221823336685648\n","Training loss per 100 training steps: 0.08008490361514228\n","Training loss per 100 training steps: 0.08044837788985021\n","Training loss per 100 training steps: 0.0809013419540743\n","Training loss per 100 training steps: 0.08190864873696825\n","Training loss per 100 training steps: 0.08079225729264554\n","Training loss per 100 training steps: 0.08109371779691135\n","Training loss epoch: 0.08046661994428582\n","Training accuracy epoch: 0.9740860057705453\n","Validating model...\n","Validation Loss: 0.14800239918003608\n","Validation Accuracy: 0.9587629861159681\n","Training epoch: 3\n","Training loss per 100 training steps: 0.09404673427343369\n","Training loss per 100 training steps: 0.04675749778323392\n","Training loss per 100 training steps: 0.04406873276920535\n","Training loss per 100 training steps: 0.048148311218215875\n","Training loss per 100 training steps: 0.047443690237140936\n","Training loss per 100 training steps: 0.047844200001884545\n","Training loss per 100 training steps: 0.048842508409376845\n","Training loss per 100 training steps: 0.051489930088431196\n","Training loss epoch: 0.051855761635120914\n","Training accuracy epoch: 0.9835383062662253\n","Validating model...\n","Validation Loss: 0.15533818628687363\n","Validation Accuracy: 0.9578512522216127\n","Training epoch: 4\n","Training loss per 100 training steps: 0.06389528512954712\n","Training loss per 100 training steps: 0.03091873032603376\n","Training loss per 100 training steps: 0.033315856722114026\n","Training loss per 100 training steps: 0.03399948587879365\n","Training loss per 100 training steps: 0.03435390662260242\n","Training loss per 100 training steps: 0.03483269896363828\n","Training loss per 100 training steps: 0.03502576496760468\n","Training loss per 100 training steps: 0.035535502461078824\n","Training loss epoch: 0.036432105520241974\n","Training accuracy epoch: 0.9885629922090531\n","Validating model...\n","Validation Loss: 0.17256680948587208\n","Validation Accuracy: 0.9538933542393425\n","Training epoch: 5\n","Training loss per 100 training steps: 0.029173284769058228\n","Training loss per 100 training steps: 0.02418303955692134\n","Training loss per 100 training steps: 0.02515947520304286\n","Training loss per 100 training steps: 0.024547610892929707\n","Training loss per 100 training steps: 0.02615417516500018\n","Training loss per 100 training steps: 0.02724139101593244\n","Training loss per 100 training steps: 0.028146915410113785\n","Training loss per 100 training steps: 0.028139822969223755\n","Training loss epoch: 0.027908656616543074\n","Training accuracy epoch: 0.9908893162818909\n","Validating model...\n","Validation Loss: 0.18989191651828102\n","Validation Accuracy: 0.9571105426176792\n","Training epoch: 6\n","Training loss per 100 training steps: 0.007145797833800316\n","Training loss per 100 training steps: 0.016872978890268592\n","Training loss per 100 training steps: 0.01630024222277142\n","Training loss per 100 training steps: 0.018673435960466233\n","Training loss per 100 training steps: 0.019790887163180924\n","Training loss per 100 training steps: 0.019700862087719255\n","Training loss per 100 training steps: 0.02008245533385303\n","Training loss per 100 training steps: 0.02037996827666588\n","Training loss epoch: 0.020777071613422075\n","Training accuracy epoch: 0.9935593172411328\n","Validating model...\n","Validation Loss: 0.19021946312738702\n","Validation Accuracy: 0.9567598249936207\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 78.97006244999987 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14446108738775365\n","Validation Accuracy: 0.956236691429889\n","Validation duration: 5.481664400000105 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.1%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.87      0.85     12546\n","        test       0.83      0.89      0.86      9012\n","   treatment       0.85      0.84      0.85      9297\n","\n","   micro avg       0.83      0.87      0.85     30855\n","   macro avg       0.84      0.87      0.85     30855\n","weighted avg       0.83      0.87      0.85     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 24268\n","Points in y_train after augmentation: 24268\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.058645486831665\n","Training loss per 100 training steps: 0.4149274974692576\n","Training loss per 100 training steps: 0.30126062571186923\n","Training loss per 100 training steps: 0.25732060761942815\n","Training loss per 100 training steps: 0.22889860083077315\n","Training loss per 100 training steps: 0.21423911142670465\n","Training loss per 100 training steps: 0.20246212995811033\n","Training loss per 100 training steps: 0.1925105469157858\n","Training loss epoch: 0.18765686038999335\n","Training accuracy epoch: 0.9403252238330612\n","Validating model...\n","Validation Loss: 0.13232847927259161\n","Validation Accuracy: 0.9578835350351628\n","Training epoch: 2\n","Training loss per 100 training steps: 0.17270410060882568\n","Training loss per 100 training steps: 0.07837733786811332\n","Training loss per 100 training steps: 0.07884929859223057\n","Training loss per 100 training steps: 0.07739245809886938\n","Training loss per 100 training steps: 0.07829475589793296\n","Training loss per 100 training steps: 0.07726382728324024\n","Training loss per 100 training steps: 0.07862756125002901\n","Training loss per 100 training steps: 0.07911554357028977\n","Training loss epoch: 0.07924232859414793\n","Training accuracy epoch: 0.9748016127793868\n","Validating model...\n","Validation Loss: 0.15369210602691422\n","Validation Accuracy: 0.9536492844192206\n","Training epoch: 3\n","Training loss per 100 training steps: 0.038177844136953354\n","Training loss per 100 training steps: 0.04342312013988595\n","Training loss per 100 training steps: 0.04513035662384213\n","Training loss per 100 training steps: 0.04722678833300761\n","Training loss per 100 training steps: 0.048326528685148855\n","Training loss per 100 training steps: 0.04777233392983571\n","Training loss per 100 training steps: 0.049006623960179144\n","Training loss per 100 training steps: 0.05014855584253247\n","Training loss epoch: 0.04990647809625369\n","Training accuracy epoch: 0.9839052372582173\n","Validating model...\n","Validation Loss: 0.1625024491993638\n","Validation Accuracy: 0.9590008618602045\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0050912173464894295\n","Training loss per 100 training steps: 0.02967426356730411\n","Training loss per 100 training steps: 0.027638922616913544\n","Training loss per 100 training steps: 0.028801864141094008\n","Training loss per 100 training steps: 0.029982211588512633\n","Training loss per 100 training steps: 0.031239049694130938\n","Training loss per 100 training steps: 0.03208363267280062\n","Training loss per 100 training steps: 0.032444798677878056\n","Training loss epoch: 0.03239983918264322\n","Training accuracy epoch: 0.9899088882554434\n","Validating model...\n","Validation Loss: 0.16977751131665397\n","Validation Accuracy: 0.9600577634185621\n","Training epoch: 5\n","Training loss per 100 training steps: 0.009849580936133862\n","Training loss per 100 training steps: 0.024101286856063747\n","Training loss per 100 training steps: 0.025511464618836403\n","Training loss per 100 training steps: 0.026127648779639318\n","Training loss per 100 training steps: 0.026261423224166868\n","Training loss per 100 training steps: 0.026228991257121317\n","Training loss per 100 training steps: 0.028104410447663868\n","Training loss epoch: 0.028949954646991686\n","Training accuracy epoch: 0.9911697231123201\n","Validating model...\n","Validation Loss: 0.17780949221319192\n","Validation Accuracy: 0.9581854688428101\n","Training epoch: 6\n","Training loss per 100 training steps: 0.024275053292512894\n","Training loss per 100 training steps: 0.019580148735618457\n","Training loss per 100 training steps: 0.021563040857685182\n","Training loss per 100 training steps: 0.02077275349203949\n","Training loss per 100 training steps: 0.021236009492121982\n","Training loss per 100 training steps: 0.022409550915913706\n","Training loss per 100 training steps: 0.023461450632338485\n","Training loss per 100 training steps: 0.02367611423298549\n","Training loss epoch: 0.024013672431771996\n","Training accuracy epoch: 0.9925442023052563\n","Validating model...\n","Validation Loss: 0.19622860302507586\n","Validation Accuracy: 0.9539519008006828\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 79.01554430000009 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14192207361985412\n","Validation Accuracy: 0.956752319304924\n","Validation duration: 5.461200600000059 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.9%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.87      0.85     12546\n","        test       0.87      0.84      0.86      9012\n","   treatment       0.86      0.82      0.84      9297\n","\n","   micro avg       0.85      0.85      0.85     30855\n","   macro avg       0.85      0.84      0.85     30855\n","weighted avg       0.85      0.85      0.85     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 24268\n","Points in y_train after augmentation: 24268\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.4230027198791504\n","Training loss per 100 training steps: 0.3718595569676692\n","Training loss per 100 training steps: 0.2899197517565234\n","Training loss per 100 training steps: 0.24670680492274785\n","Training loss per 100 training steps: 0.22325298202193883\n","Training loss per 100 training steps: 0.2070115891818753\n","Training loss per 100 training steps: 0.19741702014068993\n","Training loss per 100 training steps: 0.18828048896623747\n","Training loss epoch: 0.1838291278783826\n","Training accuracy epoch: 0.9413575505759265\n","Validating model...\n","Validation Loss: 0.1290811716349094\n","Validation Accuracy: 0.9585323038444907\n","Training epoch: 2\n","Training loss per 100 training steps: 0.13690008223056793\n","Training loss per 100 training steps: 0.0672934230343245\n","Training loss per 100 training steps: 0.07168245218249399\n","Training loss per 100 training steps: 0.07753391543471339\n","Training loss per 100 training steps: 0.07865978816658853\n","Training loss per 100 training steps: 0.07793560119516806\n","Training loss per 100 training steps: 0.07860581515381693\n","Training loss per 100 training steps: 0.07913606186807899\n","Training loss epoch: 0.07891288082568129\n","Training accuracy epoch: 0.974605835176508\n","Validating model...\n","Validation Loss: 0.12836902329770775\n","Validation Accuracy: 0.96009470017977\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03227848932147026\n","Training loss per 100 training steps: 0.04003491373456056\n","Training loss per 100 training steps: 0.041242926393111994\n","Training loss per 100 training steps: 0.044041414223797\n","Training loss per 100 training steps: 0.04445311216001127\n","Training loss per 100 training steps: 0.045143765086929\n","Training loss per 100 training steps: 0.04723263397261178\n","Training loss per 100 training steps: 0.047684584195578146\n","Training loss epoch: 0.0480823347232107\n","Training accuracy epoch: 0.9846268865110087\n","Validating model...\n","Validation Loss: 0.15164656885718178\n","Validation Accuracy: 0.9598201083411722\n","Training epoch: 4\n","Training loss per 100 training steps: 0.014666592702269554\n","Training loss per 100 training steps: 0.03186306323957547\n","Training loss per 100 training steps: 0.03301986070947527\n","Training loss per 100 training steps: 0.034992643247553426\n","Training loss per 100 training steps: 0.03577854338931175\n","Training loss per 100 training steps: 0.035572896618581935\n","Training loss per 100 training steps: 0.03599107698301092\n","Training loss per 100 training steps: 0.03655948839665187\n","Training loss epoch: 0.03641342766977459\n","Training accuracy epoch: 0.9884759964641346\n","Validating model...\n","Validation Loss: 0.18545478185662975\n","Validation Accuracy: 0.9554240912074824\n","Training epoch: 5\n","Training loss per 100 training steps: 0.029928790405392647\n","Training loss per 100 training steps: 0.036001020521478785\n","Training loss per 100 training steps: 0.03372405804531528\n","Training loss per 100 training steps: 0.03046043656582316\n","Training loss per 100 training steps: 0.029735109238987534\n","Training loss per 100 training steps: 0.02919703424014077\n","Training loss per 100 training steps: 0.02950870166509451\n","Training loss per 100 training steps: 0.029251243135614186\n","Training loss epoch: 0.02901011544993891\n","Training accuracy epoch: 0.9907896373747618\n","Validating model...\n","Validation Loss: 0.20562742975262271\n","Validation Accuracy: 0.9553594946232085\n","Training epoch: 6\n","Training loss per 100 training steps: 0.043743446469306946\n","Training loss per 100 training steps: 0.015080092971600444\n","Training loss per 100 training steps: 0.013807480664812584\n","Training loss per 100 training steps: 0.016481829816444568\n","Training loss per 100 training steps: 0.016316149900249318\n","Training loss per 100 training steps: 0.017826556897895994\n","Training loss per 100 training steps: 0.019548073383191516\n","Training loss per 100 training steps: 0.02028841637106501\n","Training loss epoch: 0.020310199866976283\n","Training accuracy epoch: 0.9938769228139815\n","Validating model...\n","Validation Loss: 0.19352104069737644\n","Validation Accuracy: 0.9591793473952801\n","Training epoch: 7\n","Training loss per 100 training steps: 0.011113722808659077\n","Training loss per 100 training steps: 0.015421510636599016\n","Training loss per 100 training steps: 0.016514101819788563\n","Training loss per 100 training steps: 0.02032798822184845\n","Training loss per 100 training steps: 0.02102172160271481\n","Training loss per 100 training steps: 0.02147989147626228\n","Training loss per 100 training steps: 0.021754684690277585\n","Training loss per 100 training steps: 0.021469112946326377\n","Training loss epoch: 0.021314747682088502\n","Training accuracy epoch: 0.9933622676651492\n","Validating model...\n","Validation Loss: 0.22356080982301915\n","Validation Accuracy: 0.9585390356131851\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 92.14323269999998 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14234085806324234\n","Validation Accuracy: 0.9573868139272422\n","Validation duration: 5.486332533333431 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.9%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.88      0.85     12546\n","        test       0.85      0.89      0.87      9012\n","   treatment       0.85      0.86      0.85      9297\n","\n","   micro avg       0.84      0.88      0.86     30855\n","   macro avg       0.84      0.88      0.86     30855\n","weighted avg       0.84      0.88      0.86     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 24268\n","Points in y_train after augmentation: 24268\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8911306858062744\n","Training loss per 100 training steps: 0.4393847055069291\n","Training loss per 100 training steps: 0.3209535529957482\n","Training loss per 100 training steps: 0.27722769985563334\n","Training loss per 100 training steps: 0.25047484035615314\n","Training loss per 100 training steps: 0.22991723098797712\n","Training loss per 100 training steps: 0.2138433275053188\n","Training loss per 100 training steps: 0.20272618400121636\n","Training loss epoch: 0.1964179231700572\n","Training accuracy epoch: 0.9373602171441278\n","Validating model...\n","Validation Loss: 0.14104921569104317\n","Validation Accuracy: 0.955051400711043\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09556116908788681\n","Training loss per 100 training steps: 0.08120522565567995\n","Training loss per 100 training steps: 0.08591401891375136\n","Training loss per 100 training steps: 0.08638633023854654\n","Training loss per 100 training steps: 0.0872932100062377\n","Training loss per 100 training steps: 0.08785783287282743\n","Training loss per 100 training steps: 0.08557828721480316\n","Training loss per 100 training steps: 0.08450244627587401\n","Training loss epoch: 0.08374406662199042\n","Training accuracy epoch: 0.9725056064618234\n","Validating model...\n","Validation Loss: 0.14348711939407632\n","Validation Accuracy: 0.9590857927920028\n","Training epoch: 3\n","Training loss per 100 training steps: 0.040990833193063736\n","Training loss per 100 training steps: 0.0460691330078436\n","Training loss per 100 training steps: 0.048834661044995877\n","Training loss per 100 training steps: 0.050161811668561936\n","Training loss per 100 training steps: 0.049791321351176636\n","Training loss per 100 training steps: 0.04821685338931943\n","Training loss per 100 training steps: 0.04928782748015049\n","Training loss per 100 training steps: 0.05075917428641045\n","Training loss epoch: 0.05090309013287403\n","Training accuracy epoch: 0.9838189966044607\n","Validating model...\n","Validation Loss: 0.1531815203269581\n","Validation Accuracy: 0.9582334074623494\n","Training epoch: 4\n","Training loss per 100 training steps: 0.032393187284469604\n","Training loss per 100 training steps: 0.03294338399802547\n","Training loss per 100 training steps: 0.031244212795693\n","Training loss per 100 training steps: 0.031360537106514694\n","Training loss per 100 training steps: 0.03197426976260968\n","Training loss per 100 training steps: 0.034716239501815106\n","Training loss per 100 training steps: 0.03603611037056868\n","Training loss per 100 training steps: 0.03571044420856669\n","Training loss epoch: 0.03622108357357247\n","Training accuracy epoch: 0.9887178018182287\n","Validating model...\n","Validation Loss: 0.16310707789349865\n","Validation Accuracy: 0.9581984511398745\n","Training epoch: 5\n","Training loss per 100 training steps: 0.05423983186483383\n","Training loss per 100 training steps: 0.028397880023170154\n","Training loss per 100 training steps: 0.03168852690118481\n","Training loss per 100 training steps: 0.030393471645479064\n","Training loss per 100 training steps: 0.030511865472453565\n","Training loss per 100 training steps: 0.03051102685903807\n","Training loss per 100 training steps: 0.030047016468762223\n","Training loss per 100 training steps: 0.029386686696903447\n","Training loss epoch: 0.030161143655732903\n","Training accuracy epoch: 0.9904846940022645\n","Validating model...\n","Validation Loss: 0.16754130528054453\n","Validation Accuracy: 0.9592358461564001\n","Training epoch: 6\n","Training loss per 100 training steps: 0.010181399062275887\n","Training loss per 100 training steps: 0.020922902383666377\n","Training loss per 100 training steps: 0.022806362060144247\n","Training loss per 100 training steps: 0.022022835666660304\n","Training loss per 100 training steps: 0.021628597917899194\n","Training loss per 100 training steps: 0.02195734367090112\n","Training loss per 100 training steps: 0.022629245001409736\n","Training loss per 100 training steps: 0.022677600306951005\n","Training loss epoch: 0.0222444820694953\n","Training accuracy epoch: 0.9929784807082084\n","Validating model...\n","Validation Loss: 0.18863144903988033\n","Validation Accuracy: 0.9619256078626027\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 78.98714659999993 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1512448555009474\n","Validation Accuracy: 0.9535443961274879\n","Validation duration: 5.459405133333348 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.9%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.85      0.84     12546\n","        test       0.85      0.87      0.86      9012\n","   treatment       0.82      0.82      0.82      9297\n","\n","   micro avg       0.83      0.85      0.84     30855\n","   macro avg       0.83      0.85      0.84     30855\n","weighted avg       0.83      0.85      0.84     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 24268\n","Points in y_train after augmentation: 24268\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8851579427719116\n","Training loss per 100 training steps: 0.4145177287778052\n","Training loss per 100 training steps: 0.3111238608238709\n","Training loss per 100 training steps: 0.2642696158483971\n","Training loss per 100 training steps: 0.2400694651775378\n","Training loss per 100 training steps: 0.22248787623263167\n","Training loss per 100 training steps: 0.20917975421554832\n","Training loss per 100 training steps: 0.19729479425154978\n","Training loss epoch: 0.19092286903072486\n","Training accuracy epoch: 0.9392613617333484\n","Validating model...\n","Validation Loss: 0.13416963290761819\n","Validation Accuracy: 0.9581208239526251\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0865752249956131\n","Training loss per 100 training steps: 0.07945160833325716\n","Training loss per 100 training steps: 0.08068422874000239\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0.75\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"oKNxFPucHn_R"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["745e010dcfd6469bb22d274e7f2c10ab","848bf7050ad94d3db7e5d0317ed98481","9af6cd09bfd144e2a60458438e377c82","ae9d467f2c874c67a96e1d306c9075c8","792731224c3442bda5e050d71b3803f2","083ecc03cefa41bfb34227e21eee1095","7651edbfe2774e1193dcb3c2bf62b9c5","b1a09cc96e5e470ea02e2409c04fd426","bd05427d6d0844828ec8ada2327d151c","706477f978144426893c226859819cd2","46a83366bdf44445bf9758ea1f4ee1f9"]},"executionInfo":{"elapsed":2096438,"status":"ok","timestamp":1667459004268,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"u68MxnTodZ7P","outputId":"82765f2a-c74a-4447-fca9-3fcaf9f586a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 75.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"745e010dcfd6469bb22d274e7f2c10ab","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 24268\n","Points in y_train after augmentation: 24268\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.383392810821533\n","Training loss per 100 training steps: 0.4290075994069033\n","Training loss per 100 training steps: 0.3108494797749306\n","Training loss per 100 training steps: 0.2654871730709393\n","Training loss per 100 training steps: 0.23957159997258995\n","Training loss per 100 training steps: 0.22317463798288575\n","Training loss per 100 training steps: 0.20925214335619907\n","Training loss per 100 training steps: 0.19801730727418174\n","Training loss epoch: 0.1934908537957351\n","Training accuracy epoch: 0.9379984975232718\n","Validating model...\n","Validation Loss: 0.1398341302070525\n","Validation Accuracy: 0.956777346486943\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06902777403593063\n","Training loss per 100 training steps: 0.07377442811606544\n","Training loss per 100 training steps: 0.07354584191717319\n","Training loss per 100 training steps: 0.07635024649112723\n","Training loss per 100 training steps: 0.07709162107708299\n","Training loss per 100 training steps: 0.0762685949388081\n","Training loss per 100 training steps: 0.0795450702979045\n","Training loss per 100 training steps: 0.07960531223145514\n","Training loss epoch: 0.08021967219034203\n","Training accuracy epoch: 0.9742627417005566\n","Validating model...\n","Validation Loss: 0.14062726708104858\n","Validation Accuracy: 0.9580769220703278\n","Training epoch: 3\n","Training loss per 100 training steps: 0.08200313150882721\n","Training loss per 100 training steps: 0.04576629039711586\n","Training loss per 100 training steps: 0.05147880331997699\n","Training loss per 100 training steps: 0.05497479063158613\n","Training loss per 100 training steps: 0.0536386264729641\n","Training loss per 100 training steps: 0.054466394235393005\n","Training loss per 100 training steps: 0.054507066897068565\n","Training loss per 100 training steps: 0.054462602769905506\n","Training loss epoch: 0.05441740236265955\n","Training accuracy epoch: 0.9826416747238946\n","Validating model...\n","Validation Loss: 0.16053178841127203\n","Validation Accuracy: 0.9576671364497858\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01799403503537178\n","Training loss per 100 training steps: 0.022932164004478273\n","Training loss per 100 training steps: 0.026752646417074387\n","Training loss per 100 training steps: 0.02908256624444725\n","Training loss per 100 training steps: 0.030094139047717197\n","Training loss per 100 training steps: 0.032456475605829406\n","Training loss per 100 training steps: 0.03353571603729385\n","Training loss per 100 training steps: 0.034345046100445815\n","Training loss epoch: 0.03470806341801742\n","Training accuracy epoch: 0.9892940696382787\n","Validating model...\n","Validation Loss: 0.18543472932046884\n","Validation Accuracy: 0.9560584420538311\n","Training epoch: 5\n","Training loss per 100 training steps: 0.019582079723477364\n","Training loss per 100 training steps: 0.022193573932808887\n","Training loss per 100 training steps: 0.02261892694803835\n","Training loss per 100 training steps: 0.02346905507766131\n","Training loss per 100 training steps: 0.02408136831459466\n","Training loss per 100 training steps: 0.025129158548943833\n","Training loss per 100 training steps: 0.02541638047805524\n","Training loss per 100 training steps: 0.026363502810582966\n","Training loss epoch: 0.026419343663028616\n","Training accuracy epoch: 0.9915571513876932\n","Validating model...\n","Validation Loss: 0.18449182612458606\n","Validation Accuracy: 0.958300155378152\n","Training epoch: 6\n","Training loss per 100 training steps: 0.003094803774729371\n","Training loss per 100 training steps: 0.015162798577785897\n","Training loss per 100 training steps: 0.017147472504739514\n","Training loss per 100 training steps: 0.020021135427995253\n","Training loss per 100 training steps: 0.020840060450380525\n","Training loss per 100 training steps: 0.022020459048470442\n","Training loss per 100 training steps: 0.02221875992574932\n","Training loss per 100 training steps: 0.023073749944066812\n","Training loss epoch: 0.023003233948996112\n","Training accuracy epoch: 0.9927216079973079\n","Validating model...\n","Validation Loss: 0.2071185771666177\n","Validation Accuracy: 0.9537540474119971\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 83.86058888333334 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14825908901036233\n","Validation Accuracy: 0.9554154878165432\n","Validation duration: 5.955291433333332 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.85      0.84     12546\n","        test       0.78      0.88      0.83      9012\n","   treatment       0.85      0.83      0.84      9297\n","\n","   micro avg       0.82      0.85      0.84     30855\n","   macro avg       0.82      0.85      0.84     30855\n","weighted avg       0.82      0.85      0.84     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 24268\n","Points in y_train after augmentation: 24268\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9263293743133545\n","Training loss per 100 training steps: 0.4427136272782146\n","Training loss per 100 training steps: 0.32749377965778853\n","Training loss per 100 training steps: 0.2766522202281857\n","Training loss per 100 training steps: 0.2486077557199465\n","Training loss per 100 training steps: 0.22883277165586363\n","Training loss per 100 training steps: 0.21255691210660285\n","Training loss per 100 training steps: 0.19972638950580876\n","Training loss epoch: 0.1939777656015357\n","Training accuracy epoch: 0.938031756731603\n","Validating model...\n","Validation Loss: 0.15354049602499256\n","Validation Accuracy: 0.9541698440959225\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0945599228143692\n","Training loss per 100 training steps: 0.08421699108906311\n","Training loss per 100 training steps: 0.07743748818148873\n","Training loss per 100 training steps: 0.08111109410681795\n","Training loss per 100 training steps: 0.08194423968580893\n","Training loss per 100 training steps: 0.08321803762854454\n","Training loss per 100 training steps: 0.08125025920644278\n","Training loss per 100 training steps: 0.08052277941118591\n","Training loss epoch: 0.08091240388627148\n","Training accuracy epoch: 0.9740104626030983\n","Validating model...\n","Validation Loss: 0.14757648023305\n","Validation Accuracy: 0.954360609259832\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04718656465411186\n","Training loss per 100 training steps: 0.0564813107842266\n","Training loss per 100 training steps: 0.054376313933148165\n","Training loss per 100 training steps: 0.052679226594509874\n","Training loss per 100 training steps: 0.05345787858460423\n","Training loss per 100 training steps: 0.05241608231081191\n","Training loss per 100 training steps: 0.05174943715482702\n","Training loss per 100 training steps: 0.0506993871788028\n","Training loss epoch: 0.050570122108025396\n","Training accuracy epoch: 0.9839966819538287\n","Validating model...\n","Validation Loss: 0.15970621318495892\n","Validation Accuracy: 0.9586044973753328\n","Training epoch: 4\n","Training loss per 100 training steps: 0.009697872214019299\n","Training loss per 100 training steps: 0.029906093055327043\n","Training loss per 100 training steps: 0.028431738100700377\n","Training loss per 100 training steps: 0.02929204795161491\n","Training loss per 100 training steps: 0.030465385882111912\n","Training loss per 100 training steps: 0.03137542610916452\n","Training loss per 100 training steps: 0.03206210354085045\n","Training loss per 100 training steps: 0.03251836256399092\n","Training loss epoch: 0.03268385807920998\n","Training accuracy epoch: 0.989659576644117\n","Validating model...\n","Validation Loss: 0.17731516592978658\n","Validation Accuracy: 0.9600030004085115\n","Training epoch: 5\n","Training loss per 100 training steps: 0.024055082350969315\n","Training loss per 100 training steps: 0.0222823979790636\n","Training loss per 100 training steps: 0.02807730711175277\n","Training loss per 100 training steps: 0.0275793303524769\n","Training loss per 100 training steps: 0.02679071061941969\n","Training loss per 100 training steps: 0.027237460295927197\n","Training loss per 100 training steps: 0.027358321992803625\n","Training loss per 100 training steps: 0.027252818675251405\n","Training loss epoch: 0.02718783903240296\n","Training accuracy epoch: 0.9913192129336598\n","Validating model...\n","Validation Loss: 0.18367679551388924\n","Validation Accuracy: 0.9572342360394239\n","Training epoch: 6\n","Training loss per 100 training steps: 0.011914007365703583\n","Training loss per 100 training steps: 0.01932777100620736\n","Training loss per 100 training steps: 0.023824592720687075\n","Training loss per 100 training steps: 0.02130342417406661\n","Training loss per 100 training steps: 0.02185604569430758\n","Training loss per 100 training steps: 0.022041393785636142\n","Training loss per 100 training steps: 0.022480669462090257\n","Training loss per 100 training steps: 0.022589154028252015\n","Training loss epoch: 0.0224409554112575\n","Training accuracy epoch: 0.9932448915655961\n","Validating model...\n","Validation Loss: 0.19883322592389274\n","Validation Accuracy: 0.9574097321481095\n","Training epoch: 7\n","Training loss per 100 training steps: 0.00552927004173398\n","Training loss per 100 training steps: 0.01623523268977752\n","Training loss per 100 training steps: 0.01687175653896883\n","Training loss per 100 training steps: 0.017052105091128537\n","Training loss per 100 training steps: 0.017892343298406655\n","Training loss per 100 training steps: 0.01824877015071012\n","Training loss per 100 training steps: 0.018467481582895844\n","Training loss per 100 training steps: 0.018139841500586684\n","Training loss epoch: 0.018196011678949464\n","Training accuracy epoch: 0.9942636165177577\n","Validating model...\n","Validation Loss: 0.20183213028524602\n","Validation Accuracy: 0.9586377777173498\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 97.79873168333333 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15661854149894444\n","Validation Accuracy: 0.9514137740044296\n","Validation duration: 5.956083699999999 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.1%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.83      0.83     12546\n","        test       0.81      0.84      0.83      9012\n","   treatment       0.82      0.86      0.84      9297\n","\n","   micro avg       0.82      0.84      0.83     30855\n","   macro avg       0.82      0.84      0.83     30855\n","weighted avg       0.82      0.84      0.83     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 24268\n","Points in y_train after augmentation: 24268\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.092130184173584\n","Training loss per 100 training steps: 0.43067661717091454\n","Training loss per 100 training steps: 0.3157816856209911\n","Training loss per 100 training steps: 0.27442827142552284\n","Training loss per 100 training steps: 0.2447440553447255\n","Training loss per 100 training steps: 0.2259488062275027\n","Training loss per 100 training steps: 0.2116390923890417\n","Training loss per 100 training steps: 0.2003132766551111\n","Training loss epoch: 0.1944715475985027\n","Training accuracy epoch: 0.9382606247774978\n","Validating model...\n","Validation Loss: 0.1361927322124119\n","Validation Accuracy: 0.9539589761728994\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07720938324928284\n","Training loss per 100 training steps: 0.0911309402436018\n","Training loss per 100 training steps: 0.08699609498627743\n","Training loss per 100 training steps: 0.08461734924180761\n","Training loss per 100 training steps: 0.08131944626671939\n","Training loss per 100 training steps: 0.07984932268711324\n","Training loss per 100 training steps: 0.08032874328962926\n","Training loss per 100 training steps: 0.08016070291883552\n","Training loss epoch: 0.07962136167654957\n","Training accuracy epoch: 0.9747256470576686\n","Validating model...\n","Validation Loss: 0.13311177490932213\n","Validation Accuracy: 0.9604196671194479\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03830733150243759\n","Training loss per 100 training steps: 0.04663106319863386\n","Training loss per 100 training steps: 0.04896827028318313\n","Training loss per 100 training steps: 0.05109324929168281\n","Training loss per 100 training steps: 0.0511063349060482\n","Training loss per 100 training steps: 0.051404550959711186\n","Training loss per 100 training steps: 0.05182066477196734\n","Training loss per 100 training steps: 0.05230720622462357\n","Training loss epoch: 0.05161616335805795\n","Training accuracy epoch: 0.9837826262647563\n","Validating model...\n","Validation Loss: 0.14465349082919685\n","Validation Accuracy: 0.9610523620465936\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03655572235584259\n","Training loss per 100 training steps: 0.026237234541233445\n","Training loss per 100 training steps: 0.02942048009561458\n","Training loss per 100 training steps: 0.03023663147753321\n","Training loss per 100 training steps: 0.03151511231482614\n","Training loss per 100 training steps: 0.03218896641742676\n","Training loss per 100 training steps: 0.03305815324708727\n","Training loss per 100 training steps: 0.03354105882671464\n","Training loss epoch: 0.033851457008329984\n","Training accuracy epoch: 0.989020268861573\n","Validating model...\n","Validation Loss: 0.1601868017104926\n","Validation Accuracy: 0.9608520056225441\n","Training epoch: 5\n","Training loss per 100 training steps: 0.021653510630130768\n","Training loss per 100 training steps: 0.01733065412684095\n","Training loss per 100 training steps: 0.019072099561879496\n","Training loss per 100 training steps: 0.020627148218330713\n","Training loss per 100 training steps: 0.020657310607068546\n","Training loss per 100 training steps: 0.023873003656644107\n","Training loss per 100 training steps: 0.025116705722791514\n","Training loss per 100 training steps: 0.024954591188815618\n","Training loss epoch: 0.02563777299865047\n","Training accuracy epoch: 0.9917028509318666\n","Validating model...\n","Validation Loss: 0.2054848580246235\n","Validation Accuracy: 0.953887462369146\n","Training epoch: 6\n","Training loss per 100 training steps: 0.023730726912617683\n","Training loss per 100 training steps: 0.025866651304739315\n","Training loss per 100 training steps: 0.023927749125043682\n","Training loss per 100 training steps: 0.022259114071126546\n","Training loss per 100 training steps: 0.021994875098910748\n","Training loss per 100 training steps: 0.02124431444807889\n","Training loss per 100 training steps: 0.02175331683116601\n","Training loss per 100 training steps: 0.022823924601799443\n","Training loss epoch: 0.022722591741417924\n","Training accuracy epoch: 0.9930484519862345\n","Validating model...\n","Validation Loss: 0.19583458421062436\n","Validation Accuracy: 0.9589262175794256\n","Training epoch: 7\n","Training loss per 100 training steps: 0.14849795401096344\n","Training loss per 100 training steps: 0.015442627890722475\n","Training loss per 100 training steps: 0.016993339867643845\n","Training loss per 100 training steps: 0.015674129420074564\n","Training loss per 100 training steps: 0.01512925256786292\n","Training loss per 100 training steps: 0.015931349072141568\n","Training loss per 100 training steps: 0.01773149705735638\n","Training loss per 100 training steps: 0.01812014483266142\n","Training loss epoch: 0.018552434478079034\n","Training accuracy epoch: 0.9943245748276638\n","Validating model...\n","Validation Loss: 0.2040212307028569\n","Validation Accuracy: 0.9561602967954722\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 97.67719890000002 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15723706238053706\n","Validation Accuracy: 0.9555033474540482\n","Validation duration: 5.915339866666667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.89      0.85     12546\n","        test       0.85      0.87      0.86      9012\n","   treatment       0.85      0.84      0.84      9297\n","\n","   micro avg       0.83      0.87      0.85     30855\n","   macro avg       0.84      0.87      0.85     30855\n","weighted avg       0.83      0.87      0.85     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 24268\n","Points in y_train after augmentation: 24268\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9623596668243408\n","Training loss per 100 training steps: 0.4100923284445659\n","Training loss per 100 training steps: 0.3092607059029501\n","Training loss per 100 training steps: 0.26795246213228996\n","Training loss per 100 training steps: 0.24086463889873533\n","Training loss per 100 training steps: 0.22331282352199575\n","Training loss per 100 training steps: 0.20864952565442008\n","Training loss per 100 training steps: 0.19660988784316774\n","Training loss epoch: 0.19121840376313654\n","Training accuracy epoch: 0.9395908157700995\n","Validating model...\n","Validation Loss: 0.1408348533433753\n","Validation Accuracy: 0.9552212086399993\n","Training epoch: 2\n","Training loss per 100 training steps: 0.020002057775855064\n","Training loss per 100 training steps: 0.08411610591234547\n","Training loss per 100 training steps: 0.08179856284025741\n","Training loss per 100 training steps: 0.08181251490649541\n","Training loss per 100 training steps: 0.08359141004367028\n","Training loss per 100 training steps: 0.08329720187564185\n","Training loss per 100 training steps: 0.08376372068230924\n","Training loss per 100 training steps: 0.08471003520540288\n","Training loss epoch: 0.08387406446022498\n","Training accuracy epoch: 0.9735118794895985\n","Validating model...\n","Validation Loss: 0.14791362677011397\n","Validation Accuracy: 0.9574050801690573\n","Training epoch: 3\n","Training loss per 100 training steps: 0.030311930924654007\n","Training loss per 100 training steps: 0.04548113909550011\n","Training loss per 100 training steps: 0.050667844519287866\n","Training loss per 100 training steps: 0.05109929531097932\n","Training loss per 100 training steps: 0.05127660438599543\n","Training loss per 100 training steps: 0.05097570195571034\n","Training loss per 100 training steps: 0.05091448695307439\n","Training loss per 100 training steps: 0.05065141947801821\n","Training loss epoch: 0.050454193736611815\n","Training accuracy epoch: 0.9840230773993254\n","Validating model...\n","Validation Loss: 0.16264915797714288\n","Validation Accuracy: 0.9564322605136828\n","Training epoch: 4\n","Training loss per 100 training steps: 0.030756307765841484\n","Training loss per 100 training steps: 0.03201225328277612\n","Training loss per 100 training steps: 0.031913013305209244\n","Training loss per 100 training steps: 0.033007309618143\n","Training loss per 100 training steps: 0.03379784355478877\n","Training loss per 100 training steps: 0.033672829491352134\n","Training loss per 100 training steps: 0.03446650109912413\n","Training loss per 100 training steps: 0.035582683133506106\n","Training loss epoch: 0.03608481188050725\n","Training accuracy epoch: 0.9886753537286289\n","Validating model...\n","Validation Loss: 0.1779956580321123\n","Validation Accuracy: 0.9587238648794607\n","Training epoch: 5\n","Training loss per 100 training steps: 0.020130885764956474\n","Training loss per 100 training steps: 0.03306475342574096\n","Training loss per 100 training steps: 0.0322497606008726\n","Training loss per 100 training steps: 0.03240818315358876\n","Training loss per 100 training steps: 0.033137439771327756\n","Training loss per 100 training steps: 0.03280209511692288\n","Training loss per 100 training steps: 0.03165684031658091\n","Training loss per 100 training steps: 0.03171200010174561\n","Training loss epoch: 0.031450446273218004\n","Training accuracy epoch: 0.9902467076336763\n","Validating model...\n","Validation Loss: 0.18571477980268272\n","Validation Accuracy: 0.9589859530625368\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00372720742598176\n","Training loss per 100 training steps: 0.02257622460982218\n","Training loss per 100 training steps: 0.02009713148410937\n","Training loss per 100 training steps: 0.01974946737948471\n","Training loss per 100 training steps: 0.02095439664188057\n","Training loss per 100 training steps: 0.02132051557680302\n","Training loss per 100 training steps: 0.021265974989956627\n","Training loss per 100 training steps: 0.021326237298284503\n","Training loss epoch: 0.021445166359257386\n","Training accuracy epoch: 0.9933153350649112\n","Validating model...\n","Validation Loss: 0.19340589628010602\n","Validation Accuracy: 0.9563302957231714\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 83.7325605 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15106845970742008\n","Validation Accuracy: 0.952083450696283\n","Validation duration: 5.918872933333357 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.3%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.88      0.84     12546\n","        test       0.83      0.90      0.86      9012\n","   treatment       0.82      0.84      0.83      9297\n","\n","   micro avg       0.81      0.87      0.84     30855\n","   macro avg       0.82      0.87      0.84     30855\n","weighted avg       0.81      0.87      0.84     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 24268\n","Points in y_train after augmentation: 24268\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8626431226730347\n","Training loss per 100 training steps: 0.4122559392806327\n","Training loss per 100 training steps: 0.3131042801918675\n","Training loss per 100 training steps: 0.27002501068172663\n","Training loss per 100 training steps: 0.2446055591961095\n","Training loss per 100 training steps: 0.22577065191493778\n","Training loss per 100 training steps: 0.20849537687025926\n","Training loss per 100 training steps: 0.19870445276803195\n","Training loss epoch: 0.19318766708145893\n","Training accuracy epoch: 0.938597807239234\n","Validating model...\n","Validation Loss: 0.14643200690096075\n","Validation Accuracy: 0.9540712781411387\n","Training epoch: 2\n","Training loss per 100 training steps: 0.1522165685892105\n","Training loss per 100 training steps: 0.08404371826586747\n","Training loss per 100 training steps: 0.0813202207852433\n","Training loss per 100 training steps: 0.08257467604468134\n","Training loss per 100 training steps: 0.08229525654839161\n","Training loss per 100 training steps: 0.08219162662125039\n","Training loss per 100 training steps: 0.0811376784883204\n","Training loss per 100 training steps: 0.07997525860150258\n","Training loss epoch: 0.07922324541666605\n","Training accuracy epoch: 0.9746038281692109\n","Validating model...\n","Validation Loss: 0.16276620722726567\n","Validation Accuracy: 0.9553216822584005\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03367430344223976\n","Training loss per 100 training steps: 0.042420805127608895\n","Training loss per 100 training steps: 0.04552957767259274\n","Training loss per 100 training steps: 0.05145290282638465\n","Training loss per 100 training steps: 0.0502568893041694\n","Training loss per 100 training steps: 0.04988368824979443\n","Training loss per 100 training steps: 0.050793049316202446\n","Training loss per 100 training steps: 0.050710937578879435\n","Training loss epoch: 0.05118683132444839\n","Training accuracy epoch: 0.9837575777736782\n","Validating model...\n","Validation Loss: 0.179152288897471\n","Validation Accuracy: 0.9554077481466603\n","Training epoch: 4\n","Training loss per 100 training steps: 0.011865295469760895\n","Training loss per 100 training steps: 0.030296237823451953\n","Training loss per 100 training steps: 0.03386552527081221\n","Training loss per 100 training steps: 0.034558577659892606\n","Training loss per 100 training steps: 0.03370076735031343\n","Training loss per 100 training steps: 0.03393969583992443\n","Training loss per 100 training steps: 0.034007354569156496\n","Training loss per 100 training steps: 0.03441399896066349\n","Training loss epoch: 0.03422152888681985\n","Training accuracy epoch: 0.9891707101895312\n","Validating model...\n","Validation Loss: 0.17538371142725667\n","Validation Accuracy: 0.9583848347399352\n","Training epoch: 5\n","Training loss per 100 training steps: 0.028971215710043907\n","Training loss per 100 training steps: 0.025255978109757646\n","Training loss per 100 training steps: 0.02277280239270194\n","Training loss per 100 training steps: 0.022429019657498925\n","Training loss per 100 training steps: 0.021552497273986865\n","Training loss per 100 training steps: 0.02250543678088296\n","Training loss per 100 training steps: 0.024258196978409852\n","Training loss per 100 training steps: 0.025068022898788938\n","Training loss epoch: 0.02542575360389306\n","Training accuracy epoch: 0.9922629639477786\n","Validating model...\n","Validation Loss: 0.19449520735191062\n","Validation Accuracy: 0.9551309397285214\n","Training epoch: 6\n","Training loss per 100 training steps: 0.003203105181455612\n","Training loss per 100 training steps: 0.020690160263491113\n","Training loss per 100 training steps: 0.020744547703991464\n","Training loss per 100 training steps: 0.020349907304548605\n","Training loss per 100 training steps: 0.020096200373008653\n","Training loss per 100 training steps: 0.019941879587411553\n","Training loss per 100 training steps: 0.020076783339569682\n","Training loss per 100 training steps: 0.021098533158270927\n","Training loss epoch: 0.021018374128354902\n","Training accuracy epoch: 0.9933529770075885\n","Validating model...\n","Validation Loss: 0.2021006712472284\n","Validation Accuracy: 0.9561785666968099\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 83.66204344999993 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.153589833976218\n","Validation Accuracy: 0.9526492894130555\n","Validation duration: 5.903497933333346 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.83      0.82     12546\n","        test       0.86      0.83      0.84      9012\n","   treatment       0.84      0.84      0.84      9297\n","\n","   micro avg       0.84      0.83      0.83     30855\n","   macro avg       0.84      0.83      0.84     30855\n","weighted avg       0.84      0.83      0.83     30855\n","\n"]}],"source":["number_of_training_models = 5\n","target_augmented_percentage = 0.75\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"u68MxnTodZ7P"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1tBh5gOBHpN1","outputId":"e5f5ae20-59a1-4d2f-e6cb-47beca25ee57"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 100% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 27734\n","Points in y_train after augmentation: 27734\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8720427751541138\n","Training loss per 100 training steps: 0.4033705595843863\n","Training loss per 100 training steps: 0.299260108180307\n","Training loss per 100 training steps: 0.2571602270279414\n","Training loss per 100 training steps: 0.23027520667659374\n","Training loss per 100 training steps: 0.21342707096697566\n","Training loss per 100 training steps: 0.1989157729954172\n","Training loss per 100 training steps: 0.18945894342516356\n","Training loss per 100 training steps: 0.1820762308451641\n","Training loss epoch: 0.17819764366268148\n","Training accuracy epoch: 0.9431762927676759\n","Validating model...\n","Validation Loss: 0.1336545334620909\n","Validation Accuracy: 0.9585326493139578\n","Training epoch: 2\n","Training loss per 100 training steps: 0.058632221072912216\n","Training loss per 100 training steps: 0.07495125058558907\n","Training loss per 100 training steps: 0.07482326958347019\n","Training loss per 100 training steps: 0.07397700208192846\n","Training loss per 100 training steps: 0.07381970903132473\n","Training loss per 100 training steps: 0.07498812662091797\n","Training loss per 100 training steps: 0.07472592878454487\n","Training loss per 100 training steps: 0.0751696804873167\n","Training loss per 100 training steps: 0.0752451511206903\n","Training loss epoch: 0.07540840381109763\n","Training accuracy epoch: 0.9761744646679963\n","Validating model...\n","Validation Loss: 0.13880838265086148\n","Validation Accuracy: 0.9587296936164773\n","Training epoch: 3\n","Training loss per 100 training steps: 0.05512470006942749\n","Training loss per 100 training steps: 0.04241477130073132\n","Training loss per 100 training steps: 0.04315627963555541\n","Training loss per 100 training steps: 0.04418231882897524\n","Training loss per 100 training steps: 0.04405926679147226\n","Training loss per 100 training steps: 0.043514513827027555\n","Training loss per 100 training steps: 0.043117050743567295\n","Training loss per 100 training steps: 0.043465288719308486\n","Training loss per 100 training steps: 0.04388412624189442\n","Training loss epoch: 0.04444249615050646\n","Training accuracy epoch: 0.98575215672887\n","Validating model...\n","Validation Loss: 0.17268852338001325\n","Validation Accuracy: 0.9580078931514456\n","Training epoch: 4\n","Training loss per 100 training steps: 0.004642860032618046\n","Training loss per 100 training steps: 0.029398725155999166\n","Training loss per 100 training steps: 0.031408700781563915\n","Training loss per 100 training steps: 0.03119182107239912\n","Training loss per 100 training steps: 0.03018907845331509\n","Training loss per 100 training steps: 0.030753212307064893\n","Training loss per 100 training steps: 0.031093178100778586\n","Training loss per 100 training steps: 0.031493575389253854\n","Training loss per 100 training steps: 0.03205471741240216\n","Training loss epoch: 0.0323934367204766\n","Training accuracy epoch: 0.9897607381625818\n","Validating model...\n","Validation Loss: 0.18186540935527196\n","Validation Accuracy: 0.9557376742167155\n","Training epoch: 5\n","Training loss per 100 training steps: 0.01112417783588171\n","Training loss per 100 training steps: 0.024664002386530364\n","Training loss per 100 training steps: 0.02469409283294588\n","Training loss per 100 training steps: 0.024039965454393075\n","Training loss per 100 training steps: 0.02408636287084091\n","Training loss per 100 training steps: 0.024528771601110777\n","Training loss per 100 training steps: 0.025298589746294987\n","Training loss per 100 training steps: 0.026100793203153647\n","Training loss per 100 training steps: 0.026383102497160922\n","Training loss epoch: 0.026073541257311855\n","Training accuracy epoch: 0.9919967197446136\n","Validating model...\n","Validation Loss: 0.2086214507845315\n","Validation Accuracy: 0.9571598465952404\n","Training epoch: 6\n","Training loss per 100 training steps: 0.02943798527121544\n","Training loss per 100 training steps: 0.017243741854153904\n","Training loss per 100 training steps: 0.019723113320144682\n","Training loss per 100 training steps: 0.019244321417164034\n","Training loss per 100 training steps: 0.018947436101357233\n","Training loss per 100 training steps: 0.018388031978864676\n","Training loss per 100 training steps: 0.019029872741541685\n","Training loss per 100 training steps: 0.020032033958049165\n","Training loss per 100 training steps: 0.020580195208279518\n","Training loss epoch: 0.02124544043845047\n","Training accuracy epoch: 0.9934013376142571\n","Validating model...\n","Validation Loss: 0.197292495422162\n","Validation Accuracy: 0.9555159049626488\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 95.0213938333333 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14561784174077697\n","Validation Accuracy: 0.9541127321142867\n","Validation duration: 5.912755933333392 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.85      0.84     12546\n","        test       0.80      0.87      0.84      9012\n","   treatment       0.83      0.86      0.84      9297\n","\n","   micro avg       0.82      0.86      0.84     30855\n","   macro avg       0.82      0.86      0.84     30855\n","weighted avg       0.82      0.86      0.84     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 27734\n","Points in y_train after augmentation: 27734\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.20076847076416\n","Training loss per 100 training steps: 0.42512346140228874\n","Training loss per 100 training steps: 0.3161128158333586\n","Training loss per 100 training steps: 0.2684197896516006\n","Training loss per 100 training steps: 0.2387145759347371\n","Training loss per 100 training steps: 0.219334143974229\n","Training loss per 100 training steps: 0.20541714251772833\n","Training loss per 100 training steps: 0.19388274602411307\n","Training loss per 100 training steps: 0.18399377609748443\n","Training loss epoch: 0.1792448599776629\n","Training accuracy epoch: 0.9429018695149676\n","Validating model...\n","Validation Loss: 0.12748765597095738\n","Validation Accuracy: 0.9587907865125704\n","Training epoch: 2\n","Training loss per 100 training steps: 0.1052887961268425\n","Training loss per 100 training steps: 0.08003824494668457\n","Training loss per 100 training steps: 0.0832737588337553\n","Training loss per 100 training steps: 0.08159511030165856\n","Training loss per 100 training steps: 0.08038317300193476\n","Training loss per 100 training steps: 0.07885163594520615\n","Training loss per 100 training steps: 0.07827156012298263\n","Training loss per 100 training steps: 0.0780807875479424\n","Training loss per 100 training steps: 0.07801723990940515\n","Training loss epoch: 0.07845148373440321\n","Training accuracy epoch: 0.9746903724275598\n","Validating model...\n","Validation Loss: 0.14327885150038577\n","Validation Accuracy: 0.9562907813109491\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04622729495167732\n","Training loss per 100 training steps: 0.04586198765295788\n","Stopping epoch...\n","Training loss epoch: 0.04586198765295788\n","Training accuracy epoch: 0.9757466062051477\n","Validating model...\n","Validation Loss: 0.15047489471927092\n","Validation Accuracy: 0.959631443229245\n","Training epoch: 4\n","Training loss per 100 training steps: 0.02604863792657852\n","Training loss per 100 training steps: 0.0441714010459583\n","Training loss per 100 training steps: 0.04727981382962409\n","Training loss per 100 training steps: 0.04678724047440132\n","Training loss per 100 training steps: 0.048701843668351376\n","Training loss per 100 training steps: 0.04915274172452485\n","Training loss per 100 training steps: 0.04956862744418114\n","Training loss per 100 training steps: 0.04991069524688447\n","Training loss per 100 training steps: 0.049323372861437884\n","Training loss epoch: 0.04903532457194208\n","Training accuracy epoch: 0.9844641853955365\n","Validating model...\n","Validation Loss: 0.17710364414016147\n","Validation Accuracy: 0.9537884542028192\n","Training epoch: 5\n","Training loss per 100 training steps: 0.008913933299481869\n","Training loss per 100 training steps: 0.029408422384023813\n","Training loss per 100 training steps: 0.027516294950132827\n","Training loss per 100 training steps: 0.028254127368157685\n","Training loss per 100 training steps: 0.02790462711310372\n","Training loss per 100 training steps: 0.028922959881000028\n","Training loss per 100 training steps: 0.028990332177838623\n","Training loss per 100 training steps: 0.029221289344105374\n","Training loss per 100 training steps: 0.029845773987413924\n","Training loss epoch: 0.031375850669125516\n","Training accuracy epoch: 0.989966044986361\n","Validating model...\n","Validation Loss: 0.17604274513175736\n","Validation Accuracy: 0.9546288838563244\n","Training epoch: 6\n","Training loss per 100 training steps: 0.017225895076990128\n","Training loss per 100 training steps: 0.022957264184075787\n","Training loss per 100 training steps: 0.024707884838762902\n","Training loss per 100 training steps: 0.02364506150431083\n","Training loss per 100 training steps: 0.023659360156240095\n","Training loss per 100 training steps: 0.02482875065560622\n","Training loss per 100 training steps: 0.024697460900793028\n","Training loss per 100 training steps: 0.024797759021080355\n","Training loss per 100 training steps: 0.02522692129127251\n","Training loss epoch: 0.02531502570256305\n","Training accuracy epoch: 0.992196764993512\n","Validating model...\n","Validation Loss: 0.19946633971163205\n","Validation Accuracy: 0.9570067134894255\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 81.52579068333326 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14160378813566812\n","Validation Accuracy: 0.9545045596017389\n","Validation duration: 5.905566433333297 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.88      0.84     12546\n","        test       0.84      0.84      0.84      9012\n","   treatment       0.83      0.86      0.84      9297\n","\n","   micro avg       0.82      0.86      0.84     30855\n","   macro avg       0.83      0.86      0.84     30855\n","weighted avg       0.82      0.86      0.84     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 27734\n","Points in y_train after augmentation: 27734\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1683566570281982\n","Training loss per 100 training steps: 0.4425726606704221\n","Training loss per 100 training steps: 0.33197869853445544\n","Training loss per 100 training steps: 0.2775577101794588\n","Training loss per 100 training steps: 0.25074906331345326\n","Training loss per 100 training steps: 0.23095863558604807\n","Training loss per 100 training steps: 0.2148802552880493\n","Training loss per 100 training steps: 0.20156094987216416\n","Training loss per 100 training steps: 0.19220076054892737\n","Training loss epoch: 0.1869170704669606\n","Training accuracy epoch: 0.9405540330285078\n","Validating model...\n","Validation Loss: 0.12046241929585283\n","Validation Accuracy: 0.9612164199511651\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05609651282429695\n","Training loss per 100 training steps: 0.07818638599745117\n","Training loss per 100 training steps: 0.07790916667908282\n","Training loss per 100 training steps: 0.07964236067106756\n","Training loss per 100 training steps: 0.07858901951540996\n","Training loss per 100 training steps: 0.07885879164695472\n","Training loss per 100 training steps: 0.07846671982765967\n","Training loss per 100 training steps: 0.0776492655748892\n","Training loss per 100 training steps: 0.07646623324572611\n","Training loss epoch: 0.07680058432742953\n","Training accuracy epoch: 0.9752383558179846\n","Validating model...\n","Validation Loss: 0.15786708944610187\n","Validation Accuracy: 0.9564447935293583\n","Training epoch: 3\n","Training loss per 100 training steps: 0.039859477430582047\n","Training loss per 100 training steps: 0.05199372056539696\n","Training loss per 100 training steps: 0.04687969953711353\n","Training loss per 100 training steps: 0.04585649956178626\n","Training loss per 100 training steps: 0.047503369640874815\n","Training loss per 100 training steps: 0.04729338988342031\n","Training loss per 100 training steps: 0.04772189467488331\n","Training loss per 100 training steps: 0.047377215342306545\n","Training loss per 100 training steps: 0.04790812705558598\n","Training loss epoch: 0.0487556843776707\n","Training accuracy epoch: 0.9847037366973345\n","Validating model...\n","Validation Loss: 0.15776835038483916\n","Validation Accuracy: 0.9571260642915116\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0354154147207737\n","Training loss per 100 training steps: 0.030214774085780476\n","Training loss per 100 training steps: 0.032069384779512364\n","Training loss per 100 training steps: 0.03455445308631218\n","Training loss per 100 training steps: 0.033663925382382984\n","Training loss per 100 training steps: 0.033208750934709985\n","Training loss per 100 training steps: 0.0330384354356571\n","Training loss per 100 training steps: 0.03323295208962286\n","Training loss per 100 training steps: 0.03263233119570133\n","Training loss epoch: 0.03315928321470847\n","Training accuracy epoch: 0.9895636612008284\n","Validating model...\n","Validation Loss: 0.16854654854865042\n","Validation Accuracy: 0.95811270306616\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0068306406028568745\n","Training loss per 100 training steps: 0.024605072672838475\n","Training loss per 100 training steps: 0.022075820095091132\n","Training loss per 100 training steps: 0.024634500279360486\n","Training loss per 100 training steps: 0.026076816680244266\n","Training loss per 100 training steps: 0.025643594332965102\n","Training loss per 100 training steps: 0.026110626462523122\n","Training loss per 100 training steps: 0.025824546406428183\n","Training loss per 100 training steps: 0.027211636597274356\n","Training loss epoch: 0.02744613142282355\n","Training accuracy epoch: 0.9916682021587904\n","Validating model...\n","Validation Loss: 0.17715368424723674\n","Validation Accuracy: 0.956901933709378\n","Training epoch: 6\n","Training loss per 100 training steps: 0.01044609397649765\n","Training loss per 100 training steps: 0.021488659784640415\n","Training loss per 100 training steps: 0.020153031068209985\n","Training loss per 100 training steps: 0.019945064910758672\n","Training loss per 100 training steps: 0.019202118618570574\n","Training loss per 100 training steps: 0.020083784317214807\n","Training loss per 100 training steps: 0.020194096324543862\n","Training loss per 100 training steps: 0.020244188817814472\n","Training loss per 100 training steps: 0.02036004191972013\n","Training loss epoch: 0.020316441628261284\n","Training accuracy epoch: 0.99357217777011\n","Validating model...\n","Validation Loss: 0.2037334454959476\n","Validation Accuracy: 0.9567159662418651\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 95.09098029999998 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13870417341995225\n","Validation Accuracy: 0.9556284854268269\n","Validation duration: 5.911845549999998 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.1%\n","              precision    recall  f1-score   support\n","\n","     problem       0.84      0.87      0.85     12546\n","        test       0.83      0.88      0.85      9012\n","   treatment       0.84      0.85      0.85      9297\n","\n","   micro avg       0.84      0.87      0.85     30855\n","   macro avg       0.84      0.87      0.85     30855\n","weighted avg       0.84      0.87      0.85     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 27734\n","Points in y_train after augmentation: 27734\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1925456523895264\n","Training loss per 100 training steps: 0.4210395964212937\n","Training loss per 100 training steps: 0.3140691835340576\n","Training loss per 100 training steps: 0.26742662702287945\n","Training loss per 100 training steps: 0.24100575913812156\n","Training loss per 100 training steps: 0.22187449258125708\n","Training loss per 100 training steps: 0.20759945409294966\n","Training loss per 100 training steps: 0.19621864264929262\n","Training loss per 100 training steps: 0.18677076769204398\n","Training loss epoch: 0.18200463077403614\n","Training accuracy epoch: 0.9411912694260565\n","Validating model...\n","Validation Loss: 0.14281735922415534\n","Validation Accuracy: 0.9570547517040418\n","Training epoch: 2\n","Training loss per 100 training steps: 0.02022104524075985\n","Training loss per 100 training steps: 0.07381611754472303\n","Training loss per 100 training steps: 0.07370065029858802\n","Training loss per 100 training steps: 0.07496860715873119\n","Training loss per 100 training steps: 0.07383196844842443\n","Training loss per 100 training steps: 0.07272829168834938\n","Training loss per 100 training steps: 0.07360785655265119\n","Training loss per 100 training steps: 0.07400357528136627\n","Training loss per 100 training steps: 0.07378301043795903\n","Training loss epoch: 0.07413681894658948\n","Training accuracy epoch: 0.9760616715469057\n","Validating model...\n","Validation Loss: 0.1607290365334068\n","Validation Accuracy: 0.9545035093271018\n","Training epoch: 3\n","Training loss per 100 training steps: 0.06481926143169403\n","Training loss per 100 training steps: 0.03949994703127754\n","Training loss per 100 training steps: 0.042321878383445796\n","Training loss per 100 training steps: 0.04126298596132608\n","Training loss per 100 training steps: 0.04409835995476869\n","Training loss per 100 training steps: 0.04435981520704419\n","Training loss per 100 training steps: 0.04447010149574915\n","Training loss per 100 training steps: 0.04426337338614672\n","Training loss per 100 training steps: 0.04506640870951944\n","Training loss epoch: 0.04587681735076242\n","Training accuracy epoch: 0.9853182618620909\n","Validating model...\n","Validation Loss: 0.1579372254623608\n","Validation Accuracy: 0.9584724765267771\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0348515659570694\n","Training loss per 100 training steps: 0.02864977802117678\n","Training loss per 100 training steps: 0.02722716671634762\n","Training loss per 100 training steps: 0.028415356245606618\n","Training loss per 100 training steps: 0.02811488651518392\n","Training loss per 100 training steps: 0.028824242184165412\n","Training loss per 100 training steps: 0.029986891498054672\n","Training loss per 100 training steps: 0.02988484576271419\n","Training loss per 100 training steps: 0.030678791780700296\n","Training loss epoch: 0.03111541719066308\n","Training accuracy epoch: 0.9899715388053657\n","Validating model...\n","Validation Loss: 0.16910047053855348\n","Validation Accuracy: 0.958680115659063\n","Training epoch: 5\n","Training loss per 100 training steps: 0.010340557433664799\n","Training loss per 100 training steps: 0.01956762820436149\n","Training loss per 100 training steps: 0.019669427074531363\n","Training loss per 100 training steps: 0.020391908489930385\n","Training loss per 100 training steps: 0.021482154035893156\n","Training loss per 100 training steps: 0.02315186721771424\n","Training loss per 100 training steps: 0.023697365109538335\n","Training loss per 100 training steps: 0.02397147415479188\n","Training loss per 100 training steps: 0.02456335839735502\n","Training loss epoch: 0.024638931935713784\n","Training accuracy epoch: 0.992393568177448\n","Validating model...\n","Validation Loss: 0.19672817126061623\n","Validation Accuracy: 0.9577854284073718\n","Training epoch: 6\n","Training loss per 100 training steps: 0.01640355959534645\n","Training loss per 100 training steps: 0.016937057188559913\n","Training loss per 100 training steps: 0.018199293134879987\n","Training loss per 100 training steps: 0.020562888618730367\n","Training loss per 100 training steps: 0.021913947493123573\n","Training loss per 100 training steps: 0.021008196536418118\n","Training loss per 100 training steps: 0.020851513708979603\n","Training loss per 100 training steps: 0.02075823727588617\n","Training loss per 100 training steps: 0.020754649960560916\n","Training loss epoch: 0.0207866700250664\n","Training accuracy epoch: 0.9937213516852411\n","Validating model...\n","Validation Loss: 0.20362791183174817\n","Validation Accuracy: 0.9566218606285181\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 95.14294901666666 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15647418168804575\n","Validation Accuracy: 0.9515932617506138\n","Validation duration: 5.927648183333561 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.86      0.83     12546\n","        test       0.85      0.81      0.83      9012\n","   treatment       0.83      0.85      0.84      9297\n","\n","   micro avg       0.82      0.84      0.83     30855\n","   macro avg       0.83      0.84      0.83     30855\n","weighted avg       0.82      0.84      0.83     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 27734\n","Points in y_train after augmentation: 27734\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.170156240463257\n","Training loss per 100 training steps: 0.43015364358330715\n","Training loss per 100 training steps: 0.31764452518960135\n","Training loss per 100 training steps: 0.27014958851064164\n","Training loss per 100 training steps: 0.24434839486332605\n","Training loss per 100 training steps: 0.22370644854363092\n","Training loss per 100 training steps: 0.20783412648665528\n","Training loss per 100 training steps: 0.19666583845378585\n","Training loss per 100 training steps: 0.1872864496427938\n","Training loss epoch: 0.1817009286909883\n","Training accuracy epoch: 0.9416223246315566\n","Validating model...\n","Validation Loss: 0.14030120925760114\n","Validation Accuracy: 0.9553916222311416\n","Training epoch: 2\n","Training loss per 100 training steps: 0.021591126918792725\n","Training loss per 100 training steps: 0.07177188816378907\n","Training loss per 100 training steps: 0.07183406041907285\n","Training loss per 100 training steps: 0.07354165861797689\n","Training loss per 100 training steps: 0.07572987010502756\n","Training loss per 100 training steps: 0.07601811496648722\n","Training loss per 100 training steps: 0.07609661653042832\n","Training loss per 100 training steps: 0.07554700961416207\n","Training loss per 100 training steps: 0.07496547856927382\n","Training loss epoch: 0.07498762196127536\n","Training accuracy epoch: 0.9764212350129986\n","Validating model...\n","Validation Loss: 0.14959123498433596\n","Validation Accuracy: 0.9548759303021147\n","Training epoch: 3\n","Training loss per 100 training steps: 0.033179353922605515\n","Training loss per 100 training steps: 0.04182191549496043\n","Training loss per 100 training steps: 0.04289004751318945\n","Training loss per 100 training steps: 0.04205935296797475\n","Training loss per 100 training steps: 0.04248441954461528\n","Training loss per 100 training steps: 0.04353936427661372\n","Training loss per 100 training steps: 0.043893434475726155\n","Training loss per 100 training steps: 0.04489236186556093\n","Training loss per 100 training steps: 0.045224441798780574\n","Training loss epoch: 0.04563243094710322\n","Training accuracy epoch: 0.985510259376153\n","Validating model...\n","Validation Loss: 0.16607875495471738\n","Validation Accuracy: 0.9551784367498966\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03433596342802048\n","Training loss per 100 training steps: 0.02816473124641003\n","Training loss per 100 training steps: 0.030379905363090744\n","Training loss per 100 training steps: 0.028939060878048827\n","Training loss per 100 training steps: 0.029974497542623664\n","Training loss per 100 training steps: 0.02974243661409203\n","Training loss per 100 training steps: 0.02935501232862584\n","Training loss per 100 training steps: 0.03061951475467708\n","Training loss per 100 training steps: 0.032290377305325274\n","Training loss epoch: 0.03243352356326531\n","Training accuracy epoch: 0.9899516668693187\n","Validating model...\n","Validation Loss: 0.18858974350785668\n","Validation Accuracy: 0.9549145410348956\n","Training epoch: 5\n","Training loss per 100 training steps: 0.05802813172340393\n","Training loss per 100 training steps: 0.0240667180958121\n","Training loss per 100 training steps: 0.027206361384144916\n","Training loss per 100 training steps: 0.026222891085688333\n","Training loss per 100 training steps: 0.02695782201282188\n","Training loss per 100 training steps: 0.028838673888374782\n","Training loss per 100 training steps: 0.028787431060940883\n","Training loss per 100 training steps: 0.029008319243867105\n","Training loss per 100 training steps: 0.028811207198254186\n","Training loss epoch: 0.028348534237464508\n","Training accuracy epoch: 0.9911874759274052\n","Validating model...\n","Validation Loss: 0.22717435204411868\n","Validation Accuracy: 0.953448333891516\n","Training epoch: 6\n","Training loss per 100 training steps: 0.020316706970334053\n","Training loss per 100 training steps: 0.01674672286256705\n","Training loss per 100 training steps: 0.01761621212649312\n","Training loss per 100 training steps: 0.019148932736052938\n","Training loss per 100 training steps: 0.01992146030722762\n","Training loss per 100 training steps: 0.01936905521436124\n","Training loss per 100 training steps: 0.01969391355837638\n","Training loss per 100 training steps: 0.020340107365982334\n","Training loss per 100 training steps: 0.02158991207934616\n","Training loss epoch: 0.02149928823877996\n","Training accuracy epoch: 0.9933643919216136\n","Validating model...\n","Validation Loss: 0.21758966586346945\n","Validation Accuracy: 0.9570633356025932\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 95.20212179999993 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.151510619329875\n","Validation Accuracy: 0.9530530582052834\n","Validation duration: 5.912729949999872 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.85      0.82     12546\n","        test       0.84      0.85      0.85      9012\n","   treatment       0.81      0.87      0.84      9297\n","\n","   micro avg       0.81      0.85      0.83     30855\n","   macro avg       0.82      0.86      0.84     30855\n","weighted avg       0.82      0.85      0.83     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 27734\n","Points in y_train after augmentation: 27734\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.963544249534607\n","Training loss per 100 training steps: 0.4052271862136255\n","Training loss per 100 training steps: 0.2994518158818359\n","Training loss per 100 training steps: 0.2593276060102786\n","Training loss per 100 training steps: 0.23616045156024637\n","Training loss per 100 training steps: 0.21665966648333324\n","Training loss per 100 training steps: 0.20410343302652462\n","Training loss per 100 training steps: 0.19334317736072565\n","Training loss per 100 training steps: 0.18554406742171178\n","Training loss epoch: 0.18001361204377853\n","Training accuracy epoch: 0.9427008183033242\n","Validating model...\n","Validation Loss: 0.14251851856515005\n","Validation Accuracy: 0.9548371966005381\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05000755935907364\n","Training loss per 100 training steps: 0.07659518502947718\n","Training loss per 100 training steps: 0.07754149030551166\n","Training loss per 100 training steps: 0.07801758690560824\n","Training loss per 100 training steps: 0.07566417772857068\n","Training loss per 100 training steps: 0.07574749319626393\n","Training loss per 100 training steps: 0.07592642236231344\n","Training loss per 100 training steps: 0.07551317060360958\n","Training loss per 100 training steps: 0.07481673269470998\n","Training loss epoch: 0.07509944606046036\n","Training accuracy epoch: 0.9758960799764463\n","Validating model...\n","Validation Loss: 0.14247895034586455\n","Validation Accuracy: 0.9580269918796807\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03083045221865177\n","Training loss per 100 training steps: 0.0409974096467405\n","Training loss per 100 training steps: 0.04196438010995142\n","Training loss per 100 training steps: 0.043494183989396425\n","Training loss per 100 training steps: 0.04369628304055894\n","Training loss per 100 training steps: 0.04343861392178682\n","Training loss per 100 training steps: 0.04468787622331222\n","Training loss per 100 training steps: 0.04415558891526335\n","Training loss per 100 training steps: 0.04451312252655207\n","Training loss epoch: 0.0444890376523614\n","Training accuracy epoch: 0.9857090368428056\n","Validating model...\n","Validation Loss: 0.17637563208964738\n","Validation Accuracy: 0.957477698314985\n","Training epoch: 4\n","Training loss per 100 training steps: 0.04954681918025017\n","Training loss per 100 training steps: 0.031963726627815624\n","Training loss per 100 training steps: 0.029584765062431125\n","Training loss per 100 training steps: 0.030470269601838507\n","Training loss per 100 training steps: 0.03101851449242359\n","Training loss per 100 training steps: 0.030442492801467415\n","Training loss per 100 training steps: 0.030736883993170684\n","Training loss per 100 training steps: 0.030215517912952152\n","Training loss per 100 training steps: 0.030548878088427798\n","Training loss epoch: 0.031401224760996604\n","Training accuracy epoch: 0.9898788206533302\n","Validating model...\n","Validation Loss: 0.1858563277289852\n","Validation Accuracy: 0.9532762955615957\n","Training epoch: 5\n","Training loss per 100 training steps: 0.030411716550588608\n","Training loss per 100 training steps: 0.021905422770870056\n","Training loss per 100 training steps: 0.022888311550695338\n","Training loss per 100 training steps: 0.02473848764270241\n","Training loss per 100 training steps: 0.02524285893925022\n","Training loss per 100 training steps: 0.025186547252815217\n","Training loss per 100 training steps: 0.026197298359108032\n","Training loss per 100 training steps: 0.026328866440519166\n","Training loss per 100 training steps: 0.0267844196571329\n","Training loss epoch: 0.026966484337725548\n","Training accuracy epoch: 0.9916079649747712\n","Validating model...\n","Validation Loss: 0.20365235305016305\n","Validation Accuracy: 0.9587283865882044\n","Training epoch: 6\n","Training loss per 100 training steps: 0.003554617054760456\n","Training loss per 100 training steps: 0.01881597862039499\n","Training loss per 100 training steps: 0.02243707314656644\n","Training loss per 100 training steps: 0.02191995305542531\n","Training loss per 100 training steps: 0.021632638881334272\n","Training loss per 100 training steps: 0.021075421678433993\n","Training loss per 100 training steps: 0.020405573207697522\n","Training loss per 100 training steps: 0.02097459792122298\n","Training loss per 100 training steps: 0.02143372303152808\n","Training loss epoch: 0.021600380715188456\n","Training accuracy epoch: 0.993522741992887\n","Validating model...\n","Validation Loss: 0.20090910600038706\n","Validation Accuracy: 0.956242133484841\n","Training epoch: 7\n","Training loss per 100 training steps: 0.009894439950585365\n","Training loss per 100 training steps: 0.01694417924800021\n","Training loss per 100 training steps: 0.01619391602351659\n","Training loss per 100 training steps: 0.015229353497784887\n","Training loss per 100 training steps: 0.015436540748166302\n","Training loss per 100 training steps: 0.016343327878917215\n","Training loss per 100 training steps: 0.016270812360659713\n","Training loss per 100 training steps: 0.016615335082903655\n","Training loss per 100 training steps: 0.016814066522107107\n","Training loss epoch: 0.016930397125009357\n","Training accuracy epoch: 0.9946421529919715\n","Validating model...\n","Validation Loss: 0.20887761578786296\n","Validation Accuracy: 0.9591380970867482\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 110.99561548333344 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15662232585277203\n","Validation Accuracy: 0.9561765450449022\n","Validation duration: 5.910043583333512 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.9%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.84      0.83     12546\n","        test       0.83      0.86      0.85      9012\n","   treatment       0.84      0.85      0.84      9297\n","\n","   micro avg       0.83      0.85      0.84     30855\n","   macro avg       0.83      0.85      0.84     30855\n","weighted avg       0.83      0.85      0.84     30855\n","\n","!!!!!! Starting model number 7 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 27734\n","Points in y_train after augmentation: 27734\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.4688260555267334\n","Training loss per 100 training steps: 0.42111828274065904\n","Training loss per 100 training steps: 0.31333218507505767\n","Training loss per 100 training steps: 0.2717809931953682\n","Training loss per 100 training steps: 0.24451949142681392\n","Training loss per 100 training steps: 0.22622979044200417\n","Training loss per 100 training steps: 0.21189548283468268\n","Training loss per 100 training steps: 0.2008243904006634\n","Training loss per 100 training steps: 0.1904443209402533\n","Training loss epoch: 0.18551986180933358\n","Training accuracy epoch: 0.9412425296539442\n","Validating model...\n","Validation Loss: 0.13850196973456966\n","Validation Accuracy: 0.9552660252829195\n","Training epoch: 2\n","Training loss per 100 training steps: 0.031408242881298065\n","Training loss per 100 training steps: 0.07542280478421415\n","Training loss per 100 training steps: 0.08000247325025388\n","Training loss per 100 training steps: 0.07884040674151377\n","Training loss per 100 training steps: 0.08067319085333784\n","Training loss per 100 training steps: 0.07864888714711941\n","Training loss per 100 training steps: 0.07890049922287762\n","Training loss per 100 training steps: 0.07899507891370805\n","Training loss per 100 training steps: 0.07842890990923593\n","Training loss epoch: 0.07896764232909184\n","Training accuracy epoch: 0.9747350596117322\n","Validating model...\n","Validation Loss: 0.15361746446556085\n","Validation Accuracy: 0.957034870237195\n","Training epoch: 3\n","Training loss per 100 training steps: 0.06022794544696808\n","Training loss per 100 training steps: 0.04798756848725647\n","Training loss per 100 training steps: 0.043126843654230904\n","Training loss per 100 training steps: 0.04543469393582538\n","Training loss per 100 training steps: 0.04653574981984503\n","Training loss per 100 training steps: 0.048368287586910044\n","Training loss per 100 training steps: 0.049700715980444496\n","Training loss per 100 training steps: 0.050896877572392134\n","Training loss per 100 training steps: 0.051407419771802486\n","Training loss epoch: 0.05156947332600856\n","Training accuracy epoch: 0.984053628374051\n","Validating model...\n","Validation Loss: 0.1610627371255405\n","Validation Accuracy: 0.9558478866460068\n","Training epoch: 4\n","Training loss per 100 training steps: 0.029504531994462013\n","Training loss per 100 training steps: 0.029945178109562338\n","Training loss per 100 training steps: 0.031760585756129146\n","Training loss per 100 training steps: 0.03255656933523343\n","Training loss per 100 training steps: 0.03318582619383625\n","Training loss per 100 training steps: 0.03342375026559439\n","Training loss per 100 training steps: 0.03352505498865585\n","Training loss per 100 training steps: 0.034611893286523324\n","Training loss per 100 training steps: 0.034605029923899494\n","Training loss epoch: 0.03473987837848141\n","Training accuracy epoch: 0.9890718365963581\n","Validating model...\n","Validation Loss: 0.18783371215807154\n","Validation Accuracy: 0.9569429170217033\n","Training epoch: 5\n","Training loss per 100 training steps: 0.01796559989452362\n","Training loss per 100 training steps: 0.022014274374849284\n","Training loss per 100 training steps: 0.02254906560720607\n","Training loss per 100 training steps: 0.024182565303548762\n","Training loss per 100 training steps: 0.02525781491493221\n","Training loss per 100 training steps: 0.026043142337178228\n","Training loss per 100 training steps: 0.025927928831802522\n","Training loss per 100 training steps: 0.026081987260326015\n","Training loss per 100 training steps: 0.02733863529319888\n","Training loss epoch: 0.027397350337710274\n","Training accuracy epoch: 0.9915092048534636\n","Validating model...\n","Validation Loss: 0.2081923908856395\n","Validation Accuracy: 0.9567885759244477\n","Training epoch: 6\n","Training loss per 100 training steps: 0.05098859965801239\n","Training loss per 100 training steps: 0.017735682411746372\n","Training loss per 100 training steps: 0.017542851897244995\n","Training loss per 100 training steps: 0.018621779227860586\n","Training loss per 100 training steps: 0.02145221571232183\n","Training loss per 100 training steps: 0.023434705768482753\n","Training loss per 100 training steps: 0.024122945860850727\n","Training loss per 100 training steps: 0.025510164987408462\n","Training loss per 100 training steps: 0.025376459049052513\n","Training loss epoch: 0.02567597036971657\n","Training accuracy epoch: 0.9921148540200003\n","Validating model...\n","Validation Loss: 0.1918558192699422\n","Validation Accuracy: 0.9578335860456224\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 95.17263311666684 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15014746297081863\n","Validation Accuracy: 0.9520200988468889\n","Validation duration: 5.9061068500001666 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.8%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.88      0.84     12546\n","        test       0.83      0.89      0.86      9012\n","   treatment       0.83      0.87      0.85      9297\n","\n","   micro avg       0.82      0.88      0.85     30855\n","   macro avg       0.82      0.88      0.85     30855\n","weighted avg       0.82      0.88      0.85     30855\n","\n","!!!!!! Starting model number 8 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 27734\n","Points in y_train after augmentation: 27734\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.204498052597046\n","Training loss per 100 training steps: 0.4409452753491921\n","Training loss per 100 training steps: 0.326266653020287\n","Training loss per 100 training steps: 0.2732430236457392\n","Training loss per 100 training steps: 0.2444884229423548\n","Training loss per 100 training steps: 0.22376725690331525\n","Training loss per 100 training steps: 0.20691957230836203\n","Training loss per 100 training steps: 0.19669001619630466\n","Training loss per 100 training steps: 0.18945648008201751\n","Training loss epoch: 0.1842107070994487\n","Training accuracy epoch: 0.9414976652901976\n","Validating model...\n","Validation Loss: 0.13960513293549612\n","Validation Accuracy: 0.956573874829049\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07675891369581223\n","Training loss per 100 training steps: 0.082202932004365\n","Training loss per 100 training steps: 0.07989111581622664\n","Training loss per 100 training steps: 0.07904563808621858\n","Training loss per 100 training steps: 0.07707145554768363\n","Training loss per 100 training steps: 0.077606950095574\n","Training loss per 100 training steps: 0.07786744357181245\n","Training loss per 100 training steps: 0.07831167542281296\n","Training loss per 100 training steps: 0.07724164160824243\n","Training loss epoch: 0.07742756042433978\n","Training accuracy epoch: 0.9753237105653204\n","Validating model...\n","Validation Loss: 0.14261671816083518\n","Validation Accuracy: 0.9583719149891804\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0680379718542099\n","Training loss per 100 training steps: 0.044204686030671736\n","Training loss per 100 training steps: 0.04514433039973179\n","Training loss per 100 training steps: 0.0455733757308279\n","Training loss per 100 training steps: 0.046282646528438214\n","Training loss per 100 training steps: 0.04566989641054766\n","Training loss per 100 training steps: 0.04560867116550997\n","Training loss per 100 training steps: 0.04479048482458587\n","Training loss per 100 training steps: 0.04445549370064057\n","Training loss epoch: 0.045058931754966454\n","Training accuracy epoch: 0.9858795071719797\n","Validating model...\n","Validation Loss: 0.155496961836304\n","Validation Accuracy: 0.9589847567397956\n","Training epoch: 4\n","Training loss per 100 training steps: 0.010639436542987823\n","Training loss per 100 training steps: 0.03225451912315987\n","Training loss per 100 training steps: 0.032154453723153925\n","Training loss per 100 training steps: 0.029528044167661614\n","Training loss per 100 training steps: 0.02873872683535648\n","Training loss per 100 training steps: 0.029913818616115168\n","Training loss per 100 training steps: 0.030662563153520884\n","Training loss per 100 training steps: 0.030447295452561095\n","Training loss per 100 training steps: 0.030530715460067012\n","Training loss epoch: 0.031159105003331255\n","Training accuracy epoch: 0.9901264418499602\n","Validating model...\n","Validation Loss: 0.19022623715656145\n","Validation Accuracy: 0.9566997159183122\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0321931317448616\n","Training loss per 100 training steps: 0.019392051081643394\n","Training loss per 100 training steps: 0.023670529909617273\n","Training loss per 100 training steps: 0.025419721020961124\n","Training loss per 100 training steps: 0.027805105994102495\n","Training loss per 100 training steps: 0.027839393901941692\n","Training loss per 100 training steps: 0.028760977778792964\n","Training loss per 100 training steps: 0.02914195763861917\n","Training loss per 100 training steps: 0.028819113015662298\n","Training loss epoch: 0.02884009106161509\n","Training accuracy epoch: 0.9912975631959022\n","Validating model...\n","Validation Loss: 0.18244042665419447\n","Validation Accuracy: 0.9574656711553975\n","Training epoch: 6\n","Training loss per 100 training steps: 0.013264906592667103\n","Training loss per 100 training steps: 0.023151683919638913\n","Training loss per 100 training steps: 0.020033944425965424\n","Training loss per 100 training steps: 0.019644094358795505\n","Training loss per 100 training steps: 0.018943281792292366\n","Training loss per 100 training steps: 0.01907758228486625\n","Training loss per 100 training steps: 0.020218951167810334\n","Training loss per 100 training steps: 0.020189972061502113\n","Training loss per 100 training steps: 0.02003126873118953\n","Training loss epoch: 0.020148286903528132\n","Training accuracy epoch: 0.9938257484271846\n","Validating model...\n","Validation Loss: 0.19326328226159534\n","Validation Accuracy: 0.9595047699303637\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 95.20814274999988 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1491390427928073\n","Validation Accuracy: 0.9531552244849306\n","Validation duration: 5.898089833333263 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.1%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.88      0.84     12546\n","        test       0.82      0.87      0.85      9012\n","   treatment       0.86      0.83      0.84      9297\n","\n","   micro avg       0.82      0.86      0.84     30855\n","   macro avg       0.83      0.86      0.84     30855\n","weighted avg       0.82      0.86      0.84     30855\n","\n","!!!!!! Starting model number 9 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 27734\n","Points in y_train after augmentation: 27734\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9997519254684448\n","Training loss per 100 training steps: 0.4257138368516865\n","Training loss per 100 training steps: 0.31614880545518886\n","Training loss per 100 training steps: 0.2668455343235569\n","Training loss per 100 training steps: 0.24159235793381856\n","Training loss per 100 training steps: 0.22330762837044968\n","Training loss per 100 training steps: 0.21077968259520222\n","Training loss per 100 training steps: 0.2009393734307415\n","Training loss per 100 training steps: 0.19066735822126066\n","Training loss epoch: 0.18538315400627314\n","Training accuracy epoch: 0.9406316233275773\n","Validating model...\n","Validation Loss: 0.1306018584540912\n","Validation Accuracy: 0.9594008260454019\n","Training epoch: 2\n","Training loss per 100 training steps: 0.11376073956489563\n","Training loss per 100 training steps: 0.07747072999430175\n","Training loss per 100 training steps: 0.07602310217268284\n","Training loss per 100 training steps: 0.07522019870777265\n","Training loss per 100 training steps: 0.07472597385879765\n","Training loss per 100 training steps: 0.0756832679246595\n","Training loss per 100 training steps: 0.07642555764927443\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 1\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"1tBh5gOBHpN1"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d27ccdf24b974ac59a435501ede57f78","1fdc8c9cadab46ceababad1a49f87076","448cf9a5c4b8438fbfb2c6db8a067a1a","74b80c38bc09482b9130d5ec8c44b338","710019bff2a84f67b7719458712fa4b8","7029f43c14494e07996368dec8b6bce7","7b13cef2c08349a09362046256fab06b","63e165900fd34c9d839963f6e94eb2ee","63e7608199f74d0eaa43cc324b6ed0d8","5d94c549ef004827b1c16379bf1d42fa","da5976392c014387b70793fcae85e4bc"]},"executionInfo":{"elapsed":12282808,"status":"ok","timestamp":1667531919585,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"chJEiXMH58S1","outputId":"470eaaba-163f-46a1-f47c-51791d8dcc72"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 100% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d27ccdf24b974ac59a435501ede57f78","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 27734\n","Points in y_train after augmentation: 27734\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1070234775543213\n","Training loss per 100 training steps: 0.4390068107312269\n","Training loss per 100 training steps: 0.33099284438203225\n","Training loss per 100 training steps: 0.2824417961841802\n","Training loss per 100 training steps: 0.2519089912071341\n","Training loss per 100 training steps: 0.23324725641580873\n","Training loss per 100 training steps: 0.217809900790205\n","Training loss per 100 training steps: 0.20544529916152635\n","Training loss per 100 training steps: 0.1961765607002746\n","Training loss epoch: 0.18906711305318682\n","Training accuracy epoch: 0.9392347067580941\n","Validating model...\n","Validation Loss: 0.1408293169814271\n","Validation Accuracy: 0.9564214763376495\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0827406719326973\n","Training loss per 100 training steps: 0.08334417768412887\n","Stopping epoch...\n","Training loss epoch: 0.08334417768412887\n","Training accuracy epoch: 0.9638652551538075\n","Validating model...\n","Validation Loss: 0.14513632611601385\n","Validation Accuracy: 0.9582382146039273\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04739418625831604\n","Training loss per 100 training steps: 0.07338961849155107\n","Training loss per 100 training steps: 0.07639972657539804\n","Training loss per 100 training steps: 0.07928384592032611\n","Training loss per 100 training steps: 0.0769132156298958\n","Training loss per 100 training steps: 0.07744522046152792\n","Training loss per 100 training steps: 0.07764457783951562\n","Training loss per 100 training steps: 0.07688683410442186\n","Training loss per 100 training steps: 0.075522143465261\n","Training loss epoch: 0.07486077495114803\n","Training accuracy epoch: 0.9764326700488365\n","Validating model...\n","Validation Loss: 0.15364308016640799\n","Validation Accuracy: 0.9580196432422784\n","Training epoch: 4\n","Training loss per 100 training steps: 0.1103292852640152\n","Training loss per 100 training steps: 0.04065585623744248\n","Training loss per 100 training steps: 0.04271131008863449\n","Training loss per 100 training steps: 0.04143270671652302\n","Training loss per 100 training steps: 0.0426706768621103\n","Training loss per 100 training steps: 0.04388374347005508\n","Training loss per 100 training steps: 0.04445021635482395\n","Training loss per 100 training steps: 0.044790021804813694\n","Training loss per 100 training steps: 0.04424718371330855\n","Training loss epoch: 0.04427998683833213\n","Training accuracy epoch: 0.9861981468815414\n","Validating model...\n","Validation Loss: 0.16085161138084028\n","Validation Accuracy: 0.9591149963039951\n","Training epoch: 5\n","Training loss per 100 training steps: 0.009537839330732822\n","Training loss per 100 training steps: 0.030712644684838482\n","Training loss per 100 training steps: 0.029417600800093282\n","Training loss per 100 training steps: 0.030504728538259567\n","Training loss per 100 training steps: 0.03055496971259948\n","Training loss per 100 training steps: 0.03143286710361506\n","Training loss per 100 training steps: 0.0324509940687381\n","Training loss per 100 training steps: 0.03298075376882267\n","Training loss per 100 training steps: 0.03399921043371356\n","Training loss epoch: 0.03462938106116101\n","Training accuracy epoch: 0.988745843480745\n","Validating model...\n","Validation Loss: 0.19708762494484325\n","Validation Accuracy: 0.9512405234298614\n","Training epoch: 6\n","Training loss per 100 training steps: 0.06192253902554512\n","Training loss per 100 training steps: 0.028144169763067165\n","Training loss per 100 training steps: 0.027633354144543872\n","Training loss per 100 training steps: 0.026266289598956716\n","Training loss per 100 training steps: 0.025021695975066763\n","Training loss per 100 training steps: 0.025217647876979936\n","Training loss per 100 training steps: 0.02701845403035061\n","Training loss per 100 training steps: 0.0272749412479178\n","Training loss per 100 training steps: 0.027537548017601474\n","Training loss epoch: 0.027257164897941773\n","Training accuracy epoch: 0.9914917560419766\n","Validating model...\n","Validation Loss: 0.20122010236630192\n","Validation Accuracy: 0.9569803890185019\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 80.13786645 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1500369859083245\n","Validation Accuracy: 0.9541045216850798\n","Validation duration: 5.784809666666661 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.85      0.84     12546\n","        test       0.80      0.89      0.84      9012\n","   treatment       0.84      0.84      0.84      9297\n","\n","   micro avg       0.82      0.86      0.84     30855\n","   macro avg       0.82      0.86      0.84     30855\n","weighted avg       0.82      0.86      0.84     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 27734\n","Points in y_train after augmentation: 27734\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.014305830001831\n","Training loss per 100 training steps: 0.4102206894814378\n","Training loss per 100 training steps: 0.3172812980428264\n","Training loss per 100 training steps: 0.2725097456099187\n","Training loss per 100 training steps: 0.2452533059100855\n","Training loss per 100 training steps: 0.226525910927388\n","Training loss per 100 training steps: 0.21042421469449402\n","Training loss per 100 training steps: 0.20038889665767742\n","Training loss per 100 training steps: 0.19057704134380327\n","Training loss epoch: 0.18542923889581583\n","Training accuracy epoch: 0.940347741950055\n","Validating model...\n","Validation Loss: 0.15294757383790883\n","Validation Accuracy: 0.9528572680678852\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04976136237382889\n","Training loss per 100 training steps: 0.08855883103085331\n","Training loss per 100 training steps: 0.08722791507080271\n","Training loss per 100 training steps: 0.08685872741848032\n","Training loss per 100 training steps: 0.08322690772659092\n","Training loss per 100 training steps: 0.07987140739028029\n","Training loss per 100 training steps: 0.07840629898712113\n","Training loss per 100 training steps: 0.07928901492683124\n","Training loss per 100 training steps: 0.07926271133213193\n","Training loss epoch: 0.07869585458782202\n","Training accuracy epoch: 0.9749376651650019\n","Validating model...\n","Validation Loss: 0.15397704090294126\n","Validation Accuracy: 0.954858531271204\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04146188125014305\n","Training loss per 100 training steps: 0.04321354102933466\n","Training loss per 100 training steps: 0.04583103027639549\n","Training loss per 100 training steps: 0.04581211120945299\n","Training loss per 100 training steps: 0.046010290494913286\n","Training loss per 100 training steps: 0.04562216990826254\n","Training loss per 100 training steps: 0.0463498034096089\n","Training loss per 100 training steps: 0.0466903097962113\n","Training loss per 100 training steps: 0.0465719534110943\n","Training loss epoch: 0.04615060585811992\n","Training accuracy epoch: 0.985611115394823\n","Validating model...\n","Validation Loss: 0.18813648764285948\n","Validation Accuracy: 0.9543794512537055\n","Training epoch: 4\n","Training loss per 100 training steps: 0.024214517325162888\n","Training loss per 100 training steps: 0.02991275273558527\n","Training loss per 100 training steps: 0.031926568270897245\n","Training loss per 100 training steps: 0.03293425017392319\n","Training loss per 100 training steps: 0.033829985916883944\n","Training loss per 100 training steps: 0.03348093281105949\n","Training loss per 100 training steps: 0.0329942547533345\n","Training loss per 100 training steps: 0.03283700463860249\n","Training loss per 100 training steps: 0.03357804218625717\n","Training loss epoch: 0.034470997847973306\n","Training accuracy epoch: 0.9890053369950689\n","Validating model...\n","Validation Loss: 0.19367297105007358\n","Validation Accuracy: 0.9518688191939163\n","Training epoch: 5\n","Training loss per 100 training steps: 0.023997336626052856\n","Training loss per 100 training steps: 0.03705054755774465\n","Training loss per 100 training steps: 0.03329930402713814\n","Training loss per 100 training steps: 0.030648817952205597\n","Training loss per 100 training steps: 0.02956345025769335\n","Training loss per 100 training steps: 0.028243027860763485\n","Training loss per 100 training steps: 0.028213106158163134\n","Training loss per 100 training steps: 0.02857057635038666\n","Training loss per 100 training steps: 0.029133891492916942\n","Training loss epoch: 0.029048217729597665\n","Training accuracy epoch: 0.9907856293029715\n","Validating model...\n","Validation Loss: 0.18491616112167958\n","Validation Accuracy: 0.9590149784816954\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0036166375502943993\n","Training loss per 100 training steps: 0.01625165821336634\n","Training loss per 100 training steps: 0.018441950212248984\n","Training loss per 100 training steps: 0.017226165860188984\n","Training loss per 100 training steps: 0.01707778879826856\n","Training loss per 100 training steps: 0.018334657955308725\n","Training loss per 100 training steps: 0.019202654660228462\n","Training loss per 100 training steps: 0.01952263008686548\n","Training loss per 100 training steps: 0.0202794390537697\n","Training loss epoch: 0.021211956821356803\n","Training accuracy epoch: 0.9933321166330618\n","Validating model...\n","Validation Loss: 0.20498740854491662\n","Validation Accuracy: 0.9573271272194233\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 93.66566423333333 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15992463226387002\n","Validation Accuracy: 0.9512565916292789\n","Validation duration: 5.8083830999999915 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.84      0.83      0.83     12546\n","        test       0.79      0.88      0.83      9012\n","   treatment       0.83      0.84      0.83      9297\n","\n","   micro avg       0.82      0.85      0.83     30855\n","   macro avg       0.82      0.85      0.83     30855\n","weighted avg       0.82      0.85      0.83     30855\n","\n"]}],"source":["number_of_training_models = 2\n","target_augmented_percentage = 1\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"chJEiXMH58S1"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zjhn7-LqHri0","outputId":"a74a71b5-eab0-4f72-a786-e5d0ae69f01a"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 200% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 41601\n","Points in y_train after augmentation: 41601\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.091369152069092\n","Training loss per 100 training steps: 0.41374972462654114\n","Training loss per 100 training steps: 0.31226620834265184\n","Training loss per 100 training steps: 0.26646763021961795\n","Training loss per 100 training steps: 0.24028424211218025\n","Training loss per 100 training steps: 0.2216598903221225\n","Training loss per 100 training steps: 0.20780321049152217\n","Training loss per 100 training steps: 0.19751777444380242\n","Training loss per 100 training steps: 0.18820518982618786\n","Training loss per 100 training steps: 0.18028633485235002\n","Training loss per 100 training steps: 0.17355765333468026\n","Training loss per 100 training steps: 0.16737052413561362\n","Training loss per 100 training steps: 0.16182611544122555\n","Training loss per 100 training steps: 0.15677721681405105\n","Training loss epoch: 0.15677721681405105\n","Training accuracy epoch: 0.9491513106485758\n","Validating model...\n","Validation Loss: 0.14371919433598396\n","Validation Accuracy: 0.9556007900916073\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0449049137532711\n","Training loss per 100 training steps: 0.06884706493854376\n","Training loss per 100 training steps: 0.06685712512591807\n","Training loss per 100 training steps: 0.06674010900198869\n","Training loss per 100 training steps: 0.06690853664261333\n","Training loss per 100 training steps: 0.06681579370850961\n","Training loss per 100 training steps: 0.06585126614334455\n","Training loss per 100 training steps: 0.06608143212544744\n","Training loss per 100 training steps: 0.06536149357000225\n","Training loss per 100 training steps: 0.06540289632283507\n","Training loss per 100 training steps: 0.06528601564465092\n","Training loss per 100 training steps: 0.06498120546461059\n","Training loss per 100 training steps: 0.06453851745933059\n","Training loss per 100 training steps: 0.0637975360968309\n","Training loss epoch: 0.0637975360968309\n","Training accuracy epoch: 0.9793749817853729\n","Validating model...\n","Validation Loss: 0.17385174708997275\n","Validation Accuracy: 0.9527670902002284\n","Training epoch: 3\n","Training loss per 100 training steps: 0.029447510838508606\n","Training loss per 100 training steps: 0.034250434762383306\n","Training loss per 100 training steps: 0.038466220448229144\n","Training loss per 100 training steps: 0.03938758540805739\n","Training loss per 100 training steps: 0.03803852984061618\n","Training loss per 100 training steps: 0.038325241833326675\n","Training loss per 100 training steps: 0.038455899121641136\n","Training loss per 100 training steps: 0.03889509949839133\n","Training loss per 100 training steps: 0.03898335896189977\n","Training loss per 100 training steps: 0.03945202483822975\n","Training loss per 100 training steps: 0.03904592199332465\n","Training loss per 100 training steps: 0.0382918764268861\n","Training loss per 100 training steps: 0.03815541911195982\n","Training loss per 100 training steps: 0.037959915920610626\n","Training loss epoch: 0.037959915920610626\n","Training accuracy epoch: 0.9876729421282663\n","Validating model...\n","Validation Loss: 0.20083598644992748\n","Validation Accuracy: 0.952962142284135\n","Training epoch: 4\n","Training loss per 100 training steps: 0.044049639254808426\n","Training loss per 100 training steps: 0.023793674906310024\n","Training loss per 100 training steps: 0.025040815111170917\n","Training loss per 100 training steps: 0.02523630049251379\n","Training loss per 100 training steps: 0.025321522092985504\n","Training loss per 100 training steps: 0.02709581793802688\n","Training loss per 100 training steps: 0.028574883154889385\n","Training loss per 100 training steps: 0.029315636842511594\n","Training loss per 100 training steps: 0.02886501098366759\n","Training loss per 100 training steps: 0.02891839317086935\n","Training loss per 100 training steps: 0.028902513599679148\n","Training loss per 100 training steps: 0.029290439634601654\n","Training loss per 100 training steps: 0.029454583530318143\n","Training loss per 100 training steps: 0.029109232719832113\n","Training loss epoch: 0.029109232719832113\n","Training accuracy epoch: 0.9907687918269067\n","Validating model...\n","Validation Loss: 0.21800178986091118\n","Validation Accuracy: 0.9546798049223013\n","Training epoch: 5\n","Training loss per 100 training steps: 0.026123706251382828\n","Training loss per 100 training steps: 0.01933923480331455\n","Training loss per 100 training steps: 0.019065869235391938\n","Training loss per 100 training steps: 0.01956985447926298\n","Training loss per 100 training steps: 0.019818131973911215\n","Training loss per 100 training steps: 0.019379434812820503\n","Training loss per 100 training steps: 0.019674328884040897\n","Training loss per 100 training steps: 0.01975556847563986\n","Training loss per 100 training steps: 0.020453605261156346\n","Training loss per 100 training steps: 0.020886985481921874\n","Training loss per 100 training steps: 0.021364504437520075\n","Training loss per 100 training steps: 0.021451321715727147\n","Training loss per 100 training steps: 0.02151550903723852\n","Training loss per 100 training steps: 0.021390754345653653\n","Training loss epoch: 0.021390754345653653\n","Training accuracy epoch: 0.9934737046793394\n","Validating model...\n","Validation Loss: 0.22334458466087068\n","Validation Accuracy: 0.954096558006356\n","Training epoch: 6\n","Training loss per 100 training steps: 0.001127015333622694\n","Training loss per 100 training steps: 0.012530164756825987\n","Training loss per 100 training steps: 0.014709552739276575\n","Training loss per 100 training steps: 0.015706283045179237\n","Training loss per 100 training steps: 0.015498667535316339\n","Training loss per 100 training steps: 0.015916144896039326\n","Training loss per 100 training steps: 0.016549081925032336\n","Training loss per 100 training steps: 0.017385474745547545\n","Training loss per 100 training steps: 0.017241524568117676\n","Training loss per 100 training steps: 0.017294694141024303\n","Training loss per 100 training steps: 0.017014047694033137\n","Training loss per 100 training steps: 0.017653336243300684\n","Training loss per 100 training steps: 0.01800801755766327\n","Training loss per 100 training steps: 0.01821239624792287\n","Training loss epoch: 0.01821239624792287\n","Training accuracy epoch: 0.9944873546090196\n","Validating model...\n","Validation Loss: 0.22345857948137374\n","Validation Accuracy: 0.9536651553507156\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 139.13557686666664 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15710906561084645\n","Validation Accuracy: 0.9525307176057696\n","Validation duration: 5.783867499999967 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.84      0.83     12546\n","        test       0.85      0.88      0.87      9012\n","   treatment       0.85      0.84      0.84      9297\n","\n","   micro avg       0.83      0.85      0.84     30855\n","   macro avg       0.84      0.85      0.84     30855\n","weighted avg       0.83      0.85      0.84     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 41601\n","Points in y_train after augmentation: 41601\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0288949012756348\n","Training loss per 100 training steps: 0.42258516632684384\n","Training loss per 100 training steps: 0.3179056218533374\n","Training loss per 100 training steps: 0.2711964319166155\n","Training loss per 100 training steps: 0.2439839955874512\n","Training loss per 100 training steps: 0.22329585571697133\n","Training loss per 100 training steps: 0.21228716369352602\n","Training loss per 100 training steps: 0.19894427643522897\n","Training loss per 100 training steps: 0.18865446362658386\n","Training loss per 100 training steps: 0.18096850631132178\n","Training loss per 100 training steps: 0.17432444337029734\n","Training loss per 100 training steps: 0.16892644500006312\n","Training loss per 100 training steps: 0.16342741830024765\n","Training loss per 100 training steps: 0.15872015911662704\n","Training loss epoch: 0.15872015911662704\n","Training accuracy epoch: 0.9492084550930288\n","Validating model...\n","Validation Loss: 0.15362758032203494\n","Validation Accuracy: 0.9507629406273623\n","Training epoch: 2\n","Training loss per 100 training steps: 0.1496429145336151\n","Training loss per 100 training steps: 0.0709877747968577\n","Training loss per 100 training steps: 0.07120824487536997\n","Training loss per 100 training steps: 0.07136338316461077\n","Training loss per 100 training steps: 0.07033018299269297\n","Training loss per 100 training steps: 0.06791793151819955\n","Training loss per 100 training steps: 0.06671462719485213\n","Training loss per 100 training steps: 0.06638662215553426\n","Training loss per 100 training steps: 0.06570529196116046\n","Training loss per 100 training steps: 0.06603446791928415\n","Training loss per 100 training steps: 0.06555962126811857\n","Training loss per 100 training steps: 0.06562967323397813\n","Training loss per 100 training steps: 0.06446051157640292\n","Training loss per 100 training steps: 0.06375027795743395\n","Training loss epoch: 0.06375027795743395\n","Training accuracy epoch: 0.9795452948651007\n","Validating model...\n","Validation Loss: 0.16474037039299289\n","Validation Accuracy: 0.9573653768703351\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02101188898086548\n","Training loss per 100 training steps: 0.03702752279938374\n","Training loss per 100 training steps: 0.03873659439259834\n","Training loss per 100 training steps: 0.037566515311143946\n","Training loss per 100 training steps: 0.03719047533709351\n","Training loss per 100 training steps: 0.03598894024646084\n","Training loss per 100 training steps: 0.03624208913995929\n","Training loss per 100 training steps: 0.03648530001956013\n","Training loss per 100 training steps: 0.037096273550064944\n","Training loss per 100 training steps: 0.03797703123686072\n","Training loss per 100 training steps: 0.03829592196552267\n","Training loss per 100 training steps: 0.03806670803289529\n","Training loss per 100 training steps: 0.038164175536113634\n","Training loss per 100 training steps: 0.03843258092777675\n","Training loss epoch: 0.03843258092777675\n","Training accuracy epoch: 0.9878191385119376\n","Validating model...\n","Validation Loss: 0.19077285722672166\n","Validation Accuracy: 0.9535991256976911\n","Training epoch: 4\n","Training loss per 100 training steps: 0.04747841879725456\n","Training loss per 100 training steps: 0.026540738839361044\n","Training loss per 100 training steps: 0.027541013089916785\n","Training loss per 100 training steps: 0.027659473393462055\n","Training loss per 100 training steps: 0.02815932766830507\n","Training loss per 100 training steps: 0.028584911840030935\n","Training loss per 100 training steps: 0.029001413496248362\n","Training loss per 100 training steps: 0.028183792951249766\n","Training loss per 100 training steps: 0.0283039200579522\n","Training loss per 100 training steps: 0.02817548337841115\n","Training loss per 100 training steps: 0.02814659542942812\n","Training loss per 100 training steps: 0.028215892289593463\n","Stopping epoch...\n","Training loss epoch: 0.028215892289593463\n","Training accuracy epoch: 0.9902932032969944\n","Validating model...\n","Validation Loss: 0.20729416316109045\n","Validation Accuracy: 0.9552498816160723\n","Training epoch: 5\n","Training loss per 100 training steps: 0.013190461322665215\n","Training loss per 100 training steps: 0.018822170407880135\n","Training loss per 100 training steps: 0.01816702223225353\n","Training loss per 100 training steps: 0.019356774626086246\n","Training loss per 100 training steps: 0.01987811787189809\n","Training loss per 100 training steps: 0.02053148484163306\n","Training loss per 100 training steps: 0.021168042319290613\n","Training loss per 100 training steps: 0.02139018196811881\n","Training loss per 100 training steps: 0.021825628386247676\n","Training loss per 100 training steps: 0.023571307626648493\n","Training loss per 100 training steps: 0.023707108340748528\n","Training loss per 100 training steps: 0.024118682992533374\n","Training loss per 100 training steps: 0.02452312173940463\n","Training loss per 100 training steps: 0.024402589757998704\n","Training loss epoch: 0.024402589757998704\n","Training accuracy epoch: 0.9922458429030532\n","Validating model...\n","Validation Loss: 0.22313653343877235\n","Validation Accuracy: 0.9534813711164812\n","Training epoch: 6\n","Training loss per 100 training steps: 0.014039840549230576\n","Training loss per 100 training steps: 0.018296595855320962\n","Training loss per 100 training steps: 0.016989069219634622\n","Training loss per 100 training steps: 0.016938169083814833\n","Training loss per 100 training steps: 0.016435484791771413\n","Training loss per 100 training steps: 0.019058078778870478\n","Training loss per 100 training steps: 0.018915887957786717\n","Training loss per 100 training steps: 0.01850352477277802\n","Training loss per 100 training steps: 0.01807928234883049\n","Training loss per 100 training steps: 0.018947534010502417\n","Training loss per 100 training steps: 0.01911239638428816\n","Training loss per 100 training steps: 0.018849719496549393\n","Training loss per 100 training steps: 0.019226778040898476\n","Training loss per 100 training steps: 0.019324636649322706\n","Training loss epoch: 0.019324636649322706\n","Training accuracy epoch: 0.994042144562669\n","Validating model...\n","Validation Loss: 0.2192805585384901\n","Validation Accuracy: 0.9550665080727277\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 135.51109366666665 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15816707068329883\n","Validation Accuracy: 0.9505180680598383\n","Validation duration: 5.796994166666627 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.1%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.86      0.82     12546\n","        test       0.87      0.84      0.86      9012\n","   treatment       0.82      0.82      0.82      9297\n","\n","   micro avg       0.82      0.84      0.83     30855\n","   macro avg       0.83      0.84      0.83     30855\n","weighted avg       0.82      0.84      0.83     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 41601\n","Points in y_train after augmentation: 41601\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9025806188583374\n","Training loss per 100 training steps: 0.39762250319270803\n","Training loss per 100 training steps: 0.29313578793955086\n","Training loss per 100 training steps: 0.25370975894438863\n","Training loss per 100 training steps: 0.23090891671039518\n","Training loss per 100 training steps: 0.2134037541370549\n","Training loss per 100 training steps: 0.20064347482188769\n","Training loss per 100 training steps: 0.19064834505617193\n","Training loss per 100 training steps: 0.18153548588076335\n","Training loss per 100 training steps: 0.17445671232572274\n","Training loss per 100 training steps: 0.1685088537503164\n","Training loss per 100 training steps: 0.16325481760262306\n","Training loss per 100 training steps: 0.1578447494537978\n","Training loss per 100 training steps: 0.15314779856559363\n","Training loss epoch: 0.15314779856559363\n","Training accuracy epoch: 0.9506152769966598\n","Validating model...\n","Validation Loss: 0.14312381495709542\n","Validation Accuracy: 0.9582509037406991\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09297044575214386\n","Training loss per 100 training steps: 0.08170634285906458\n","Training loss per 100 training steps: 0.0723598442140003\n","Training loss per 100 training steps: 0.06826638081575129\n","Training loss per 100 training steps: 0.06603576468961067\n","Training loss per 100 training steps: 0.06572318720229774\n","Training loss per 100 training steps: 0.06424206302938254\n","Training loss per 100 training steps: 0.06368302201590476\n","Training loss per 100 training steps: 0.0633704148563725\n","Training loss per 100 training steps: 0.06290058368175072\n","Training loss per 100 training steps: 0.06260057495135654\n","Training loss per 100 training steps: 0.062405109783418\n","Training loss per 100 training steps: 0.06281747053095064\n","Training loss per 100 training steps: 0.06290350343762173\n","Stopping epoch...\n","Training loss epoch: 0.06290350343762173\n","Training accuracy epoch: 0.978989323540453\n","Validating model...\n","Validation Loss: 0.1769779220997513\n","Validation Accuracy: 0.9510989519935561\n","Training epoch: 3\n","Training loss per 100 training steps: 0.046017203480005264\n","Training loss per 100 training steps: 0.048936145707485404\n","Training loss per 100 training steps: 0.04571977456387559\n","Training loss per 100 training steps: 0.04307644824115281\n","Training loss per 100 training steps: 0.04216701627106283\n","Training loss per 100 training steps: 0.04162289966162696\n","Training loss per 100 training steps: 0.04247629122879083\n","Training loss per 100 training steps: 0.04196936546372497\n","Training loss per 100 training steps: 0.041748240396651336\n","Training loss per 100 training steps: 0.0418173799304949\n","Training loss per 100 training steps: 0.041657056381621704\n","Training loss per 100 training steps: 0.04118078212804845\n","Training loss per 100 training steps: 0.04110197963148082\n","Training loss per 100 training steps: 0.04061935690245402\n","Training loss epoch: 0.04061935690245402\n","Training accuracy epoch: 0.9870118791584631\n","Validating model...\n","Validation Loss: 0.1950310913773326\n","Validation Accuracy: 0.952111261757171\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03069179318845272\n","Training loss per 100 training steps: 0.020393290411736265\n","Training loss per 100 training steps: 0.023624800283471074\n","Training loss per 100 training steps: 0.023403291801297015\n","Training loss per 100 training steps: 0.02350621244131571\n","Training loss per 100 training steps: 0.023183455946111677\n","Training loss per 100 training steps: 0.023755187920477556\n","Training loss per 100 training steps: 0.023780367965245363\n","Training loss per 100 training steps: 0.023745943428820623\n","Training loss per 100 training steps: 0.024071201228058083\n","Training loss per 100 training steps: 0.024271692732929603\n","Training loss per 100 training steps: 0.02437257822784853\n","Training loss per 100 training steps: 0.024277522766146094\n","Training loss per 100 training steps: 0.0243317050296315\n","Training loss epoch: 0.0243317050296315\n","Training accuracy epoch: 0.9920429822996842\n","Validating model...\n","Validation Loss: 0.20129130787953928\n","Validation Accuracy: 0.9547943427712559\n","Training epoch: 5\n","Training loss per 100 training steps: 0.030569549649953842\n","Training loss per 100 training steps: 0.02041785038447487\n","Training loss per 100 training steps: 0.01970265910726745\n","Training loss per 100 training steps: 0.019058866417453163\n","Training loss per 100 training steps: 0.017856798198467767\n","Training loss per 100 training steps: 0.018046296678112632\n","Training loss per 100 training steps: 0.01994300260026079\n","Training loss per 100 training steps: 0.021410639692823964\n","Training loss per 100 training steps: 0.022349129047040735\n","Training loss per 100 training steps: 0.022191680763919447\n","Training loss per 100 training steps: 0.022469302269766903\n","Training loss per 100 training steps: 0.022924730893424106\n","Training loss per 100 training steps: 0.022731543509782036\n","Training loss per 100 training steps: 0.022555457661286294\n","Training loss epoch: 0.022555457661286294\n","Training accuracy epoch: 0.9929490789768091\n","Validating model...\n","Validation Loss: 0.2229984137290097\n","Validation Accuracy: 0.9554681505091076\n","Training epoch: 6\n","Training loss per 100 training steps: 0.030316466465592384\n","Training loss per 100 training steps: 0.01904296828203346\n","Training loss per 100 training steps: 0.017105267578921286\n","Training loss per 100 training steps: 0.015202052106562943\n","Training loss per 100 training steps: 0.015665947444868468\n","Training loss per 100 training steps: 0.016216330079924353\n","Training loss per 100 training steps: 0.01681209045506184\n","Training loss per 100 training steps: 0.016728141125144282\n","Training loss per 100 training steps: 0.01692606533629969\n","Training loss per 100 training steps: 0.017778783704332626\n","Training loss per 100 training steps: 0.017530326895964364\n","Training loss per 100 training steps: 0.017449533107052818\n","Training loss per 100 training steps: 0.01788718023142445\n","Training loss per 100 training steps: 0.017924964655622277\n","Training loss epoch: 0.017924964655622277\n","Training accuracy epoch: 0.9943581086991963\n","Validating model...\n","Validation Loss: 0.23248198709462758\n","Validation Accuracy: 0.9556568132984983\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 138.9287917166667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15569817288067295\n","Validation Accuracy: 0.9545842266927744\n","Validation duration: 5.793420049999986 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.84      0.83     12546\n","        test       0.87      0.85      0.86      9012\n","   treatment       0.81      0.87      0.84      9297\n","\n","   micro avg       0.83      0.85      0.84     30855\n","   macro avg       0.83      0.85      0.84     30855\n","weighted avg       0.83      0.85      0.84     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 41601\n","Points in y_train after augmentation: 41601\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8553463220596313\n","Training loss per 100 training steps: 0.4020755338196707\n","Training loss per 100 training steps: 0.30413810845779543\n","Training loss per 100 training steps: 0.2618933499007922\n","Training loss per 100 training steps: 0.23412856493061618\n","Training loss per 100 training steps: 0.2184770553486195\n","Training loss per 100 training steps: 0.2055680785086409\n","Training loss per 100 training steps: 0.19531860554885763\n","Training loss per 100 training steps: 0.18654950698384185\n","Training loss per 100 training steps: 0.17845158220850732\n","Training loss per 100 training steps: 0.1720071253399332\n","Training loss per 100 training steps: 0.16674033372572453\n","Training loss per 100 training steps: 0.16134266341981368\n","Training loss per 100 training steps: 0.1565079993582253\n","Training loss epoch: 0.1565079993582253\n","Training accuracy epoch: 0.9501112205241321\n","Validating model...\n","Validation Loss: 0.15730926268673562\n","Validation Accuracy: 0.9540907519229367\n","Training epoch: 2\n","Training loss per 100 training steps: 0.047959305346012115\n","Training loss per 100 training steps: 0.06988382945298263\n","Training loss per 100 training steps: 0.06703071110413887\n","Training loss per 100 training steps: 0.0691095325984432\n","Training loss per 100 training steps: 0.06738371163968954\n","Training loss per 100 training steps: 0.06575490482813287\n","Training loss per 100 training steps: 0.0656639192262649\n","Training loss per 100 training steps: 0.06509788187563462\n","Training loss per 100 training steps: 0.06465275534027524\n","Training loss per 100 training steps: 0.06439130476285207\n","Training loss per 100 training steps: 0.06440447260798714\n","Training loss per 100 training steps: 0.06359691396639001\n","Training loss per 100 training steps: 0.06347291342286761\n","Training loss per 100 training steps: 0.06313092900816993\n","Training loss epoch: 0.06313092900816993\n","Training accuracy epoch: 0.9796909475134952\n","Validating model...\n","Validation Loss: 0.15477799735479542\n","Validation Accuracy: 0.9585878164954296\n","Training epoch: 3\n","Training loss per 100 training steps: 0.013479422777891159\n","Training loss per 100 training steps: 0.03352882618102992\n","Training loss per 100 training steps: 0.03435954542376509\n","Training loss per 100 training steps: 0.0341980702690842\n","Training loss per 100 training steps: 0.03378284897276681\n","Training loss per 100 training steps: 0.03530268657844729\n","Training loss per 100 training steps: 0.035438620993253865\n","Training loss per 100 training steps: 0.03566058521616019\n","Training loss per 100 training steps: 0.03620072377243366\n","Training loss per 100 training steps: 0.036355190576787016\n","Training loss per 100 training steps: 0.036736907467216286\n","Training loss per 100 training steps: 0.03697617241408977\n","Training loss per 100 training steps: 0.0368074367176059\n","Training loss per 100 training steps: 0.03695086957324872\n","Training loss epoch: 0.03695086957324872\n","Training accuracy epoch: 0.9886584398156952\n","Validating model...\n","Validation Loss: 0.178656908520195\n","Validation Accuracy: 0.9564299638405487\n","Training epoch: 4\n","Training loss per 100 training steps: 0.012785051017999649\n","Training loss per 100 training steps: 0.02715751915215745\n","Training loss per 100 training steps: 0.028484756046783327\n","Training loss per 100 training steps: 0.02698330576063607\n","Training loss per 100 training steps: 0.02603473506755825\n","Training loss per 100 training steps: 0.0257535158788289\n","Training loss per 100 training steps: 0.02794495431701273\n","Training loss per 100 training steps: 0.02875732202370174\n","Training loss per 100 training steps: 0.029378129549184406\n","Training loss per 100 training steps: 0.030150589837755214\n","Training loss per 100 training steps: 0.030453818779451296\n","Training loss per 100 training steps: 0.030695159842319818\n","Training loss per 100 training steps: 0.030827315638648684\n","Training loss per 100 training steps: 0.030708598450327695\n","Training loss epoch: 0.030708598450327695\n","Training accuracy epoch: 0.9903827382132693\n","Validating model...\n","Validation Loss: 0.19822720494484167\n","Validation Accuracy: 0.9561583404030093\n","Training epoch: 5\n","Training loss per 100 training steps: 0.015069233253598213\n","Training loss per 100 training steps: 0.019795365498740097\n","Training loss per 100 training steps: 0.0200043110521823\n","Training loss per 100 training steps: 0.01934658986911954\n","Training loss per 100 training steps: 0.019948998675667136\n","Training loss per 100 training steps: 0.020734417180383408\n","Training loss per 100 training steps: 0.020687868841255497\n","Training loss per 100 training steps: 0.020320903467964023\n","Training loss per 100 training steps: 0.020189227858061532\n","Training loss per 100 training steps: 0.020250624099576568\n","Training loss per 100 training steps: 0.020536282234544914\n","Training loss per 100 training steps: 0.020719062482685884\n","Training loss per 100 training steps: 0.020777584560409144\n","Training loss per 100 training steps: 0.020692310967859076\n","Training loss epoch: 0.020692310967859076\n","Training accuracy epoch: 0.9937070520233968\n","Validating model...\n","Validation Loss: 0.21973105723207648\n","Validation Accuracy: 0.9542803668419675\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0023848593700677156\n","Training loss per 100 training steps: 0.014375311045879774\n","Training loss per 100 training steps: 0.017489442215776023\n","Training loss per 100 training steps: 0.0196069613166008\n","Training loss per 100 training steps: 0.019670918901616992\n","Training loss per 100 training steps: 0.020822071942139208\n","Training loss per 100 training steps: 0.02076486294778039\n","Training loss per 100 training steps: 0.0209140971458428\n","Training loss per 100 training steps: 0.021675473218682\n","Training loss per 100 training steps: 0.02136796267105465\n","Training loss per 100 training steps: 0.020789960041476114\n","Training loss per 100 training steps: 0.020377735886416167\n","Training loss per 100 training steps: 0.020389520510672308\n","Training loss per 100 training steps: 0.02033617100830055\n","Training loss epoch: 0.02033617100830055\n","Training accuracy epoch: 0.9935956477979503\n","Validating model...\n","Validation Loss: 0.2173207820931377\n","Validation Accuracy: 0.9579267003093145\n","Training epoch: 7\n","Training loss per 100 training steps: 0.014020385220646858\n","Training loss per 100 training steps: 0.013332476189053423\n","Training loss per 100 training steps: 0.013226071563033868\n","Training loss per 100 training steps: 0.013903584759322728\n","Training loss per 100 training steps: 0.014533470418307689\n","Training loss per 100 training steps: 0.01487226437138507\n","Training loss per 100 training steps: 0.01460355436292821\n","Training loss per 100 training steps: 0.015472195323162411\n","Training loss per 100 training steps: 0.01617057326069705\n","Training loss per 100 training steps: 0.016344082789291697\n","Training loss per 100 training steps: 0.016276708828755416\n","Training loss per 100 training steps: 0.016180190432430384\n","Training loss per 100 training steps: 0.016122740481763598\n","Training loss per 100 training steps: 0.01599746763789962\n","Training loss epoch: 0.01599746763789962\n","Training accuracy epoch: 0.9950676174665886\n","Validating model...\n","Validation Loss: 0.24388305938427712\n","Validation Accuracy: 0.9548753873125637\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 162.0811338833333 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.18277326860212875\n","Validation Accuracy: 0.9527624687356344\n","Validation duration: 5.789780666666532 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.84      0.84      0.84     12546\n","        test       0.83      0.89      0.86      9012\n","   treatment       0.84      0.83      0.84      9297\n","\n","   micro avg       0.84      0.85      0.84     30855\n","   macro avg       0.84      0.85      0.84     30855\n","weighted avg       0.84      0.85      0.84     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 41601\n","Points in y_train after augmentation: 41601\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7370096445083618\n","Training loss per 100 training steps: 0.41008959695844366\n","Training loss per 100 training steps: 0.3081732560597842\n","Training loss per 100 training steps: 0.2670549186955259\n","Training loss per 100 training steps: 0.24320489695839156\n","Training loss per 100 training steps: 0.22465507051500375\n","Training loss per 100 training steps: 0.2119116883278637\n","Training loss per 100 training steps: 0.20001277484042243\n","Training loss per 100 training steps: 0.18916266764306025\n","Training loss per 100 training steps: 0.18098993851213027\n","Training loss per 100 training steps: 0.17404825146217923\n","Training loss per 100 training steps: 0.1686536454960203\n","Training loss per 100 training steps: 0.16338117059000723\n","Training loss per 100 training steps: 0.1593783861233765\n","Training loss epoch: 0.1593783861233765\n","Training accuracy epoch: 0.9486961263124883\n","Validating model...\n","Validation Loss: 0.15147529934327325\n","Validation Accuracy: 0.9539555862076059\n","Training epoch: 2\n","Training loss per 100 training steps: 0.140810027718544\n","Training loss per 100 training steps: 0.06709635991713789\n","Training loss per 100 training steps: 0.06767191594948445\n","Training loss per 100 training steps: 0.06816441123141749\n","Training loss per 100 training steps: 0.0680872025096004\n","Training loss per 100 training steps: 0.06618974335536272\n","Training loss per 100 training steps: 0.06535423707105405\n","Training loss per 100 training steps: 0.0653512088200622\n","Training loss per 100 training steps: 0.06479381773819666\n","Training loss per 100 training steps: 0.06482925257629009\n","Training loss per 100 training steps: 0.0643899064205427\n","Training loss per 100 training steps: 0.06378301365498106\n","Training loss per 100 training steps: 0.06334185549546557\n","Training loss per 100 training steps: 0.06297221227493673\n","Training loss epoch: 0.06297221227493673\n","Training accuracy epoch: 0.9796034953380585\n","Validating model...\n","Validation Loss: 0.17226803155204692\n","Validation Accuracy: 0.9531426337364909\n","Training epoch: 3\n","Training loss per 100 training steps: 0.012392282485961914\n","Training loss per 100 training steps: 0.040438398253172636\n","Training loss per 100 training steps: 0.039673934904951136\n","Training loss per 100 training steps: 0.03816755117262185\n","Training loss per 100 training steps: 0.03847860626236505\n","Training loss per 100 training steps: 0.03785092355158299\n","Training loss per 100 training steps: 0.03807026715410684\n","Training loss per 100 training steps: 0.037671633542863424\n","Training loss per 100 training steps: 0.03811238113876209\n","Training loss per 100 training steps: 0.038198259567762294\n","Training loss per 100 training steps: 0.038197940795219036\n","Training loss per 100 training steps: 0.038185171878450025\n","Training loss per 100 training steps: 0.038195271706336534\n","Stopping epoch...\n","Training loss epoch: 0.038195271706336534\n","Training accuracy epoch: 0.9869208914409638\n","Validating model...\n","Validation Loss: 0.18769462746507548\n","Validation Accuracy: 0.9536751642897675\n","Training epoch: 4\n","Training loss per 100 training steps: 0.025069868192076683\n","Training loss per 100 training steps: 0.02618645981304569\n","Training loss per 100 training steps: 0.02447705160344566\n","Training loss per 100 training steps: 0.02394660719766272\n","Training loss per 100 training steps: 0.02448597629212001\n","Training loss per 100 training steps: 0.024772961146919476\n","Training loss per 100 training steps: 0.02462897367330699\n","Training loss per 100 training steps: 0.02542347113964561\n","Training loss per 100 training steps: 0.026491229068493695\n","Training loss per 100 training steps: 0.02691503782815028\n","Training loss per 100 training steps: 0.027226477727544243\n","Training loss per 100 training steps: 0.027582878026443887\n","Training loss per 100 training steps: 0.02750784674443019\n","Training loss per 100 training steps: 0.02770276461378783\n","Training loss epoch: 0.02770276461378783\n","Training accuracy epoch: 0.9911051859906697\n","Validating model...\n","Validation Loss: 0.1996669688975656\n","Validation Accuracy: 0.9542392184489623\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0014657616848126054\n","Training loss per 100 training steps: 0.014491618401140417\n","Training loss per 100 training steps: 0.015582149779129847\n","Training loss per 100 training steps: 0.018024828880011997\n","Training loss per 100 training steps: 0.019482077029272404\n","Training loss per 100 training steps: 0.020636429154395893\n","Training loss per 100 training steps: 0.021643294665161305\n","Training loss per 100 training steps: 0.02192605644983961\n","Training loss per 100 training steps: 0.021407770002830527\n","Training loss per 100 training steps: 0.021938506512671138\n","Training loss per 100 training steps: 0.021955011607651096\n","Training loss per 100 training steps: 0.022290257423850525\n","Training loss per 100 training steps: 0.02246079575169605\n","Training loss per 100 training steps: 0.022629805369924347\n","Training loss epoch: 0.022629805369924347\n","Training accuracy epoch: 0.9929998197579517\n","Validating model...\n","Validation Loss: 0.20713278418406844\n","Validation Accuracy: 0.953463137482741\n","Training epoch: 6\n","Training loss per 100 training steps: 0.01153868529945612\n","Training loss per 100 training steps: 0.017179546767089625\n","Training loss per 100 training steps: 0.016750940132135555\n","Training loss per 100 training steps: 0.018079712791437982\n","Training loss per 100 training steps: 0.018468878664798627\n","Training loss per 100 training steps: 0.018320340364836825\n","Training loss per 100 training steps: 0.017933472586732155\n","Training loss per 100 training steps: 0.01788055814371528\n","Training loss per 100 training steps: 0.018628779577033783\n","Training loss per 100 training steps: 0.01932161153626466\n","Training loss per 100 training steps: 0.019199357199418423\n","Training loss per 100 training steps: 0.01917637354118257\n","Training loss per 100 training steps: 0.01973448466611553\n","Training loss per 100 training steps: 0.019761341011672755\n","Training loss epoch: 0.019761341011672755\n","Training accuracy epoch: 0.9938173841367736\n","Validating model...\n","Validation Loss: 0.23156384557679102\n","Validation Accuracy: 0.9535089106048891\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 137.38081051666668 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1558004069752146\n","Validation Accuracy: 0.9520402693907642\n","Validation duration: 5.794904033333296 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.86      0.84     12546\n","        test       0.82      0.87      0.84      9012\n","   treatment       0.80      0.86      0.83      9297\n","\n","   micro avg       0.81      0.86      0.84     30855\n","   macro avg       0.81      0.86      0.84     30855\n","weighted avg       0.81      0.86      0.84     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 41601\n","Points in y_train after augmentation: 41601\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.855415940284729\n","Training loss per 100 training steps: 0.39767745218359596\n","Training loss per 100 training steps: 0.30047857209076334\n","Training loss per 100 training steps: 0.25944898521335813\n","Training loss per 100 training steps: 0.23164843547708375\n","Training loss per 100 training steps: 0.2147369759153582\n","Training loss per 100 training steps: 0.2015117311326418\n","Training loss per 100 training steps: 0.19217397118473528\n","Training loss per 100 training steps: 0.18253224379802763\n","Training loss per 100 training steps: 0.17572334772192943\n","Training loss per 100 training steps: 0.16924068162945302\n","Training loss per 100 training steps: 0.16330120889901384\n","Training loss per 100 training steps: 0.15740498286019777\n","Training loss per 100 training steps: 0.1525014972287931\n","Training loss epoch: 0.1525014972287931\n","Training accuracy epoch: 0.9506829472111225\n","Validating model...\n","Validation Loss: 0.1447575996545228\n","Validation Accuracy: 0.9571754072394311\n","Training epoch: 2\n","Training loss per 100 training steps: 0.040644530206918716\n","Training loss per 100 training steps: 0.06122135137678078\n","Training loss per 100 training steps: 0.06243296237245424\n","Training loss per 100 training steps: 0.06021724873225505\n","Training loss per 100 training steps: 0.05902554495364632\n","Training loss per 100 training steps: 0.05935323833740742\n","Training loss per 100 training steps: 0.06041832864803639\n","Training loss per 100 training steps: 0.060199974667740595\n","Training loss per 100 training steps: 0.05931357935986036\n","Training loss per 100 training steps: 0.059045190986227264\n","Training loss per 100 training steps: 0.0596881325840001\n","Training loss per 100 training steps: 0.06029691724220864\n","Training loss per 100 training steps: 0.059634463076629396\n","Training loss per 100 training steps: 0.05968583572660748\n","Training loss epoch: 0.05968583572660748\n","Training accuracy epoch: 0.9809699680932533\n","Validating model...\n","Validation Loss: 0.17843889117289286\n","Validation Accuracy: 0.9526638291579101\n","Training epoch: 3\n","Training loss per 100 training steps: 0.018893374130129814\n","Training loss per 100 training steps: 0.04067198857711167\n","Training loss per 100 training steps: 0.03923416111863853\n","Training loss per 100 training steps: 0.03840660269873408\n","Training loss per 100 training steps: 0.036880473549967804\n","Training loss per 100 training steps: 0.03591241079109336\n","Training loss per 100 training steps: 0.03530581164159835\n","Training loss per 100 training steps: 0.03484181858769906\n","Training loss per 100 training steps: 0.03492363938232174\n","Training loss per 100 training steps: 0.03494996554967632\n","Training loss per 100 training steps: 0.034616482259657286\n","Training loss per 100 training steps: 0.03508344696361832\n","Training loss per 100 training steps: 0.035092056182396913\n","Training loss per 100 training steps: 0.03547582426036835\n","Training loss epoch: 0.03547582426036835\n","Training accuracy epoch: 0.9886843321570512\n","Validating model...\n","Validation Loss: 0.20480164379945823\n","Validation Accuracy: 0.9546848602901158\n","Training epoch: 4\n","Training loss per 100 training steps: 0.00940404087305069\n","Training loss per 100 training steps: 0.029392767650315003\n","Training loss per 100 training steps: 0.02614809816531763\n","Training loss per 100 training steps: 0.024778262585977037\n","Training loss per 100 training steps: 0.025037421826900278\n","Training loss per 100 training steps: 0.026176433726780846\n","Training loss per 100 training steps: 0.026190802368944426\n","Training loss per 100 training steps: 0.026088231814475185\n","Training loss per 100 training steps: 0.026679687093991027\n","Training loss per 100 training steps: 0.026797344608746106\n","Training loss per 100 training steps: 0.02705166004942386\n","Training loss per 100 training steps: 0.026797558443636026\n","Training loss per 100 training steps: 0.026468208222417355\n","Training loss per 100 training steps: 0.02649638564615789\n","Training loss epoch: 0.02649638564615789\n","Training accuracy epoch: 0.9915330062525867\n","Validating model...\n","Validation Loss: 0.19976010345309586\n","Validation Accuracy: 0.956682639107174\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0017979335971176624\n","Training loss per 100 training steps: 0.014666139406364152\n","Training loss per 100 training steps: 0.018237137803008584\n","Training loss per 100 training steps: 0.01754591858093364\n","Training loss per 100 training steps: 0.018033154721330026\n","Training loss per 100 training steps: 0.02049185267018485\n","Training loss per 100 training steps: 0.020709266488637138\n","Training loss per 100 training steps: 0.02074283193919765\n","Training loss per 100 training steps: 0.020809597371145502\n","Training loss per 100 training steps: 0.020582498933514735\n","Training loss per 100 training steps: 0.020226549674090665\n","Training loss per 100 training steps: 0.020097111727203666\n","Training loss per 100 training steps: 0.020208491201471418\n","Training loss per 100 training steps: 0.020304410399335417\n","Training loss epoch: 0.020304410399335417\n","Training accuracy epoch: 0.9937248781877767\n","Validating model...\n","Validation Loss: 0.21335611615765404\n","Validation Accuracy: 0.955381025721202\n","Training epoch: 6\n","Training loss per 100 training steps: 0.005328605882823467\n","Training loss per 100 training steps: 0.011951259754616583\n","Training loss per 100 training steps: 0.013832320431096766\n","Training loss per 100 training steps: 0.015538693122771504\n","Training loss per 100 training steps: 0.016102253967150582\n","Training loss per 100 training steps: 0.015644074306463612\n","Training loss per 100 training steps: 0.01531150538740469\n","Training loss per 100 training steps: 0.014925150427493677\n","Training loss per 100 training steps: 0.01525194607664902\n","Training loss per 100 training steps: 0.01605811342202927\n","Training loss per 100 training steps: 0.016558354370820278\n","Training loss per 100 training steps: 0.016289833434781298\n","Training loss per 100 training steps: 0.016174514646882108\n","Training loss per 100 training steps: 0.016205205041234225\n","Training loss epoch: 0.016205205041234225\n","Training accuracy epoch: 0.9950396390133048\n","Validating model...\n","Validation Loss: 0.218088929756097\n","Validation Accuracy: 0.9558026848150054\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 139.04114088333347 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15928444429947478\n","Validation Accuracy: 0.9537062374820495\n","Validation duration: 5.779978916666733 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.86      0.84     12546\n","        test       0.85      0.82      0.84      9012\n","   treatment       0.79      0.86      0.82      9297\n","\n","   micro avg       0.82      0.85      0.83     30855\n","   macro avg       0.82      0.85      0.83     30855\n","weighted avg       0.82      0.85      0.83     30855\n","\n","!!!!!! Starting model number 7 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 41601\n","Points in y_train after augmentation: 41601\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9580841064453125\n","Training loss per 100 training steps: 0.45335533492045826\n","Training loss per 100 training steps: 0.3247355412302622\n","Training loss per 100 training steps: 0.2814563764847097\n","Training loss per 100 training steps: 0.2507278857209216\n","Training loss per 100 training steps: 0.22891762048496814\n","Training loss per 100 training steps: 0.21529607101345122\n","Training loss per 100 training steps: 0.20387097379291025\n","Training loss per 100 training steps: 0.19266099686247207\n","Training loss per 100 training steps: 0.18480258049251105\n","Training loss per 100 training steps: 0.17805116319401817\n","Training loss per 100 training steps: 0.17154944407416137\n","Training loss per 100 training steps: 0.16593919971416535\n","Training loss per 100 training steps: 0.15982511001080257\n","Training loss epoch: 0.15982511001080257\n","Training accuracy epoch: 0.9489095543759973\n","Validating model...\n","Validation Loss: 0.1450446346266703\n","Validation Accuracy: 0.9567845648504639\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06560348719358444\n","Training loss per 100 training steps: 0.06732987330322808\n","Training loss per 100 training steps: 0.06873803113619635\n","Training loss per 100 training steps: 0.06829980989156965\n","Training loss per 100 training steps: 0.06782129296378007\n","Training loss per 100 training steps: 0.066662508531468\n","Training loss per 100 training steps: 0.0660760148696465\n","Training loss per 100 training steps: 0.0660239429440291\n","Training loss per 100 training steps: 0.06560819408973766\n","Training loss per 100 training steps: 0.06606746639293534\n","Training loss per 100 training steps: 0.06508737390481314\n","Training loss per 100 training steps: 0.06400956400457793\n","Training loss per 100 training steps: 0.06366322305538907\n","Training loss per 100 training steps: 0.06302353597391429\n","Training loss epoch: 0.06302353597391429\n","Training accuracy epoch: 0.9797082912215551\n","Validating model...\n","Validation Loss: 0.17005605295348863\n","Validation Accuracy: 0.9575420630669192\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04687678813934326\n","Training loss per 100 training steps: 0.042378470161007625\n","Training loss per 100 training steps: 0.037582309914877945\n","Training loss per 100 training steps: 0.03887974384721938\n","Training loss per 100 training steps: 0.03948150582273637\n","Training loss per 100 training steps: 0.03905480316103047\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 2\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"Zjhn7-LqHri0"},{"cell_type":"code","execution_count":8,"metadata":{"id":"GWfZZ6eTqXZM","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["b1ff0b87cead4216870f86e88cc7289b"]},"executionInfo":{"status":"ok","timestamp":1667638409221,"user_tz":240,"elapsed":6268201,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"}},"outputId":"8f8aa8c9-95af-4762-f6e0-ab93c49a123f"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 200% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b1ff0b87cead4216870f86e88cc7289b","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 41601\n","Points in y_train after augmentation: 41601\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.035003185272217\n","Training loss per 100 training steps: 0.4229041098958195\n","Training loss per 100 training steps: 0.31523886389696776\n","Training loss per 100 training steps: 0.270628385146789\n","Training loss per 100 training steps: 0.2416087431261813\n","Training loss per 100 training steps: 0.22559344291523425\n","Training loss per 100 training steps: 0.21154128091282734\n","Training loss per 100 training steps: 0.20053937657870427\n","Training loss per 100 training steps: 0.1913637410867936\n","Training loss per 100 training steps: 0.18372828367638602\n","Training loss per 100 training steps: 0.17606872632600865\n","Training loss per 100 training steps: 0.16894291148780693\n","Training loss per 100 training steps: 0.16339210157812287\n","Training loss per 100 training steps: 0.1588319721943101\n","Training loss epoch: 0.1588319721943101\n","Training accuracy epoch: 0.9494039597930988\n","Validating model...\n","Validation Loss: 0.14520870282181672\n","Validation Accuracy: 0.9543345957249587\n","Training epoch: 2\n","Training loss per 100 training steps: 0.08287438005208969\n","Training loss per 100 training steps: 0.06487997153331296\n","Training loss per 100 training steps: 0.06868734738247385\n","Training loss per 100 training steps: 0.06936962230663214\n","Training loss per 100 training steps: 0.07029158217330786\n","Training loss per 100 training steps: 0.07036729655442332\n","Training loss per 100 training steps: 0.06917091854809226\n","Training loss per 100 training steps: 0.0682019461324962\n","Training loss per 100 training steps: 0.06715076268661056\n","Training loss per 100 training steps: 0.06618980188635938\n","Training loss per 100 training steps: 0.06586562439596483\n","Training loss per 100 training steps: 0.06543916310957691\n","Training loss per 100 training steps: 0.06504563211837937\n","Training loss per 100 training steps: 0.06472933111466442\n","Training loss epoch: 0.06472933111466442\n","Training accuracy epoch: 0.9793643245050234\n","Validating model...\n","Validation Loss: 0.1765089974823323\n","Validation Accuracy: 0.9549674239432742\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02571887895464897\n","Training loss per 100 training steps: 0.0397759022255714\n","Training loss per 100 training steps: 0.042466164010563\n","Training loss per 100 training steps: 0.041771555563861945\n","Training loss per 100 training steps: 0.041592529144584015\n","Training loss per 100 training steps: 0.04176752320574429\n","Training loss per 100 training steps: 0.0434454239133169\n","Training loss per 100 training steps: 0.043333795284998526\n","Training loss per 100 training steps: 0.04214349104970526\n","Training loss per 100 training steps: 0.04240899140813226\n","Training loss per 100 training steps: 0.04201568085090867\n","Training loss per 100 training steps: 0.04225959715735401\n","Training loss per 100 training steps: 0.042147890584765126\n","Stopping epoch...\n","Training loss epoch: 0.042147890584765126\n","Training accuracy epoch: 0.9859455200369668\n","Validating model...\n","Validation Loss: 0.17540310387342395\n","Validation Accuracy: 0.9534923538685085\n","Training epoch: 4\n","Training loss per 100 training steps: 0.017687533050775528\n","Training loss per 100 training steps: 0.02714029892283206\n","Training loss per 100 training steps: 0.027194198509400237\n","Training loss per 100 training steps: 0.02724841879982427\n","Training loss per 100 training steps: 0.027899135979173467\n","Training loss per 100 training steps: 0.028728126999717614\n","Training loss per 100 training steps: 0.029226972822048787\n","Training loss per 100 training steps: 0.02868541461925757\n","Training loss per 100 training steps: 0.028565961675507397\n","Training loss per 100 training steps: 0.02877052812264678\n","Training loss per 100 training steps: 0.028477390212033382\n","Training loss per 100 training steps: 0.029084324311170234\n","Training loss per 100 training steps: 0.028934866018435507\n","Training loss per 100 training steps: 0.02893233642016171\n","Training loss epoch: 0.02893233642016171\n","Training accuracy epoch: 0.9911134207647009\n","Validating model...\n","Validation Loss: 0.20990101383793375\n","Validation Accuracy: 0.9557040898171847\n","Training epoch: 5\n","Training loss per 100 training steps: 0.009785771369934082\n","Training loss per 100 training steps: 0.022430385196682914\n","Training loss per 100 training steps: 0.022407443493729765\n","Training loss per 100 training steps: 0.02350152669817927\n","Training loss per 100 training steps: 0.023742210046513623\n","Training loss per 100 training steps: 0.023707610022178117\n","Training loss per 100 training steps: 0.023512100232741834\n","Training loss per 100 training steps: 0.024855011674215468\n","Training loss per 100 training steps: 0.025298967156687127\n","Training loss per 100 training steps: 0.02523695919187233\n","Training loss per 100 training steps: 0.025566027685232296\n","Training loss per 100 training steps: 0.025581650656384063\n","Training loss per 100 training steps: 0.02588303265021067\n","Training loss per 100 training steps: 0.025372856379123145\n","Training loss epoch: 0.025372856379123145\n","Training accuracy epoch: 0.9921598005500084\n","Validating model...\n","Validation Loss: 0.2006226373570306\n","Validation Accuracy: 0.9577559197208209\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0027224686928093433\n","Training loss per 100 training steps: 0.016987744015687617\n","Training loss per 100 training steps: 0.0154796077291231\n","Training loss per 100 training steps: 0.01761172101229578\n","Training loss per 100 training steps: 0.017053263266994724\n","Training loss per 100 training steps: 0.01741474233879085\n","Training loss per 100 training steps: 0.01760677874218843\n","Training loss per 100 training steps: 0.019237554652969117\n","Training loss per 100 training steps: 0.019939517024971345\n","Training loss per 100 training steps: 0.020473505043167285\n","Training loss per 100 training steps: 0.020546648438301656\n","Training loss per 100 training steps: 0.02029172679611129\n","Training loss per 100 training steps: 0.020371600411980446\n","Training loss per 100 training steps: 0.02040007964576239\n","Training loss epoch: 0.02040007964576239\n","Training accuracy epoch: 0.993673037867635\n","Validating model...\n","Validation Loss: 0.22631400507722085\n","Validation Accuracy: 0.9571869894404875\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 138.54237023333334 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15510833753419487\n","Validation Accuracy: 0.952113298090009\n","Validation duration: 5.871376833333337 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 83.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.85      0.82     12546\n","        test       0.82      0.86      0.84      9012\n","   treatment       0.81      0.85      0.83      9297\n","\n","   micro avg       0.81      0.85      0.83     30855\n","   macro avg       0.81      0.85      0.83     30855\n","weighted avg       0.81      0.85      0.83     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 41601\n","Points in y_train after augmentation: 41601\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.139817953109741\n","Training loss per 100 training steps: 0.42438035532094465\n","Training loss per 100 training steps: 0.31063066801028466\n","Training loss per 100 training steps: 0.2691118065205919\n","Training loss per 100 training steps: 0.24257375540541593\n","Training loss per 100 training steps: 0.22348452919346842\n","Training loss per 100 training steps: 0.21130851521381425\n","Training loss per 100 training steps: 0.19885130833765324\n","Training loss per 100 training steps: 0.18931782919769355\n","Training loss per 100 training steps: 0.18097471455721956\n","Training loss per 100 training steps: 0.17535228204246348\n","Training loss per 100 training steps: 0.16948998801674114\n","Training loss per 100 training steps: 0.16369709360733517\n","Training loss per 100 training steps: 0.15801657110253645\n","Training loss epoch: 0.15801657110253645\n","Training accuracy epoch: 0.9488111343946536\n","Validating model...\n","Validation Loss: 0.1622097080017065\n","Validation Accuracy: 0.9542582660100759\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05702519789338112\n","Training loss per 100 training steps: 0.06458086240114552\n","Training loss per 100 training steps: 0.06367505405709814\n","Training loss per 100 training steps: 0.06446772949318355\n","Training loss per 100 training steps: 0.06412862341948541\n","Training loss per 100 training steps: 0.06302611050107693\n","Training loss per 100 training steps: 0.06319128512501711\n","Training loss per 100 training steps: 0.06313916427444018\n","Training loss per 100 training steps: 0.06371147882384591\n","Training loss per 100 training steps: 0.06318184768858073\n","Training loss per 100 training steps: 0.06306519324472128\n","Training loss per 100 training steps: 0.06308655497576994\n","Training loss per 100 training steps: 0.06244061660608176\n","Training loss per 100 training steps: 0.06222520274796729\n","Training loss epoch: 0.06222520274796729\n","Training accuracy epoch: 0.9801252970988483\n","Validating model...\n","Validation Loss: 0.16327285764182542\n","Validation Accuracy: 0.9548326239032298\n","Training epoch: 3\n","Training loss per 100 training steps: 0.020731646567583084\n","Training loss per 100 training steps: 0.030907833927984137\n","Training loss per 100 training steps: 0.03683703477420283\n","Training loss per 100 training steps: 0.03544899301782894\n","Training loss per 100 training steps: 0.035992068539029844\n","Training loss per 100 training steps: 0.037454132894806924\n","Training loss per 100 training steps: 0.03820082748958844\n","Training loss per 100 training steps: 0.039146967274243126\n","Training loss per 100 training steps: 0.03893915381786598\n","Training loss per 100 training steps: 0.03817019588585331\n","Training loss per 100 training steps: 0.03904153464571829\n","Training loss per 100 training steps: 0.03903188773984517\n","Training loss per 100 training steps: 0.03895208268838513\n","Training loss per 100 training steps: 0.038604382343195784\n","Training loss epoch: 0.038604382343195784\n","Training accuracy epoch: 0.9877900503499097\n","Validating model...\n","Validation Loss: 0.21039374458131851\n","Validation Accuracy: 0.9535765919104839\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0763733759522438\n","Training loss per 100 training steps: 0.01828006835018128\n","Training loss per 100 training steps: 0.020952577589181672\n","Training loss per 100 training steps: 0.022021107578285015\n","Training loss per 100 training steps: 0.023690045366186806\n","Training loss per 100 training steps: 0.023726336391941976\n","Training loss per 100 training steps: 0.02459933094489706\n","Training loss per 100 training steps: 0.024647584125052836\n","Training loss per 100 training steps: 0.02526171595981919\n","Training loss per 100 training steps: 0.025554836369517542\n","Training loss per 100 training steps: 0.02545037612351091\n","Training loss per 100 training steps: 0.02686119871140017\n","Training loss per 100 training steps: 0.027400722298255464\n","Training loss per 100 training steps: 0.02746457128227768\n","Training loss epoch: 0.02746457128227768\n","Training accuracy epoch: 0.9913974527235287\n","Validating model...\n","Validation Loss: 0.2150626476225141\n","Validation Accuracy: 0.9570560352966802\n","Training epoch: 5\n","Training loss per 100 training steps: 0.029483439400792122\n","Training loss per 100 training steps: 0.01849209445662391\n","Training loss per 100 training steps: 0.018866198066163308\n","Training loss per 100 training steps: 0.020406900590635293\n","Training loss per 100 training steps: 0.019502154560155815\n","Training loss per 100 training steps: 0.01923696506113658\n","Training loss per 100 training steps: 0.018659314845755275\n","Training loss per 100 training steps: 0.019533921961311235\n","Training loss per 100 training steps: 0.01998865052190878\n","Training loss per 100 training steps: 0.019807706104752222\n","Training loss per 100 training steps: 0.02053586940578121\n","Training loss per 100 training steps: 0.02116851192694132\n","Training loss per 100 training steps: 0.021090654429712478\n","Training loss per 100 training steps: 0.021134414171627675\n","Training loss epoch: 0.021134414171627675\n","Training accuracy epoch: 0.9934324176112156\n","Validating model...\n","Validation Loss: 0.22621444225698323\n","Validation Accuracy: 0.9534128777279888\n","Training epoch: 6\n","Training loss per 100 training steps: 0.007697430904954672\n","Training loss per 100 training steps: 0.015658924665006967\n","Training loss per 100 training steps: 0.01608223270390887\n","Training loss per 100 training steps: 0.017727838625916377\n","Training loss per 100 training steps: 0.018400673928845934\n","Training loss per 100 training steps: 0.01836017531190837\n","Training loss per 100 training steps: 0.018385172519502006\n","Training loss per 100 training steps: 0.01786207533403288\n","Training loss per 100 training steps: 0.017524148064308548\n","Training loss per 100 training steps: 0.017614516392391543\n","Training loss per 100 training steps: 0.017480665571942507\n","Training loss per 100 training steps: 0.017511835203095374\n","Training loss per 100 training steps: 0.017706681738105867\n","Training loss per 100 training steps: 0.017743887728345956\n","Training loss epoch: 0.017743887728345956\n","Training accuracy epoch: 0.9944941265730939\n","Validating model...\n","Validation Loss: 0.24966298537207887\n","Validation Accuracy: 0.9529716991188114\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 140.66046945000005 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1755798629908693\n","Validation Accuracy: 0.9509902216226758\n","Validation duration: 5.8723507 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 83.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.86      0.83     12546\n","        test       0.78      0.90      0.83      9012\n","   treatment       0.86      0.80      0.83      9297\n","\n","   micro avg       0.81      0.85      0.83     30855\n","   macro avg       0.81      0.85      0.83     30855\n","weighted avg       0.81      0.85      0.83     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 41601\n","Points in y_train after augmentation: 41601\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8886945247650146\n","Training loss per 100 training steps: 0.4405670574691036\n","Training loss per 100 training steps: 0.3261238089322451\n","Training loss per 100 training steps: 0.27528648507902\n","Training loss per 100 training steps: 0.24804783433657185\n","Training loss per 100 training steps: 0.22890610702544034\n","Training loss per 100 training steps: 0.21419086132799825\n","Training loss per 100 training steps: 0.2017244456545815\n","Training loss per 100 training steps: 0.1922111448723725\n","Training loss per 100 training steps: 0.1825844156891769\n","Training loss per 100 training steps: 0.17462660296523308\n","Training loss per 100 training steps: 0.16798845224495262\n","Training loss per 100 training steps: 0.16323865881169541\n","Training loss per 100 training steps: 0.1580850898748483\n","Training loss epoch: 0.1580850898748483\n","Training accuracy epoch: 0.9492153724917844\n","Validating model...\n","Validation Loss: 0.14185693577028713\n","Validation Accuracy: 0.9543094038114047\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0534006804227829\n","Training loss per 100 training steps: 0.0677876577961563\n","Training loss per 100 training steps: 0.06404750543502878\n","Training loss per 100 training steps: 0.06587941190877626\n","Training loss per 100 training steps: 0.06441731660503736\n","Training loss per 100 training steps: 0.06436843615668471\n","Training loss per 100 training steps: 0.06424220588086127\n","Training loss per 100 training steps: 0.06401295507241694\n","Training loss per 100 training steps: 0.06436894035208668\n","Stopping epoch...\n","Training loss epoch: 0.06436894035208668\n","Training accuracy epoch: 0.9778948147294866\n","Validating model...\n","Validation Loss: 0.15352536155539867\n","Validation Accuracy: 0.9555122352673818\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0355122908949852\n","Training loss per 100 training steps: 0.0386305469766001\n","Training loss per 100 training steps: 0.043587006479084714\n","Training loss per 100 training steps: 0.04432175471602113\n","Training loss per 100 training steps: 0.04490457852533612\n","Training loss per 100 training steps: 0.045124555806426735\n","Training loss per 100 training steps: 0.04720253553884584\n","Training loss per 100 training steps: 0.047319396145870316\n","Training loss per 100 training steps: 0.04760421815673622\n","Training loss per 100 training steps: 0.048687548124408155\n","Training loss per 100 training steps: 0.04887222507284707\n","Training loss per 100 training steps: 0.04836298800183529\n","Training loss per 100 training steps: 0.04854330792557836\n","Training loss per 100 training steps: 0.04778317045829618\n","Training loss epoch: 0.04778317045829618\n","Training accuracy epoch: 0.9848181611320348\n","Validating model...\n","Validation Loss: 0.18485661082018118\n","Validation Accuracy: 0.9549753042525884\n","Training epoch: 4\n","Training loss per 100 training steps: 0.08465464413166046\n","Training loss per 100 training steps: 0.02356217471919585\n","Training loss per 100 training steps: 0.025907570453342143\n","Training loss per 100 training steps: 0.02861942054875554\n","Training loss per 100 training steps: 0.03031088900462053\n","Training loss per 100 training steps: 0.030633287105110738\n","Training loss per 100 training steps: 0.030881036245364837\n","Training loss per 100 training steps: 0.030798117502392554\n","Training loss per 100 training steps: 0.030820894193211767\n","Training loss per 100 training steps: 0.031077667637239754\n","Training loss per 100 training steps: 0.03064151993957576\n","Training loss per 100 training steps: 0.03052724841065395\n","Training loss per 100 training steps: 0.03066040823771366\n","Training loss per 100 training steps: 0.030423613751264535\n","Training loss epoch: 0.030423613751264535\n","Training accuracy epoch: 0.9903502224561523\n","Validating model...\n","Validation Loss: 0.20131290694335838\n","Validation Accuracy: 0.9547538046806092\n","Training epoch: 5\n","Training loss per 100 training steps: 0.00456835376098752\n","Training loss per 100 training steps: 0.01925434954095595\n","Training loss per 100 training steps: 0.017525215872704742\n","Training loss per 100 training steps: 0.021536555663532457\n","Training loss per 100 training steps: 0.02167853669996752\n","Training loss per 100 training steps: 0.02094928991431073\n","Training loss per 100 training steps: 0.021252157935890494\n","Training loss per 100 training steps: 0.021699013178766213\n","Training loss per 100 training steps: 0.021839585441636146\n","Training loss per 100 training steps: 0.02167380828526415\n","Training loss per 100 training steps: 0.021927258349547105\n","Training loss per 100 training steps: 0.022362675412537295\n","Training loss per 100 training steps: 0.022766251503313496\n","Training loss per 100 training steps: 0.02284502354946027\n","Training loss epoch: 0.02284502354946027\n","Training accuracy epoch: 0.9929208397559347\n","Validating model...\n","Validation Loss: 0.21044737251789927\n","Validation Accuracy: 0.9560393874200794\n","Training epoch: 6\n","Training loss per 100 training steps: 0.002963886596262455\n","Training loss per 100 training steps: 0.016894173656249106\n","Training loss per 100 training steps: 0.017520280130930356\n","Training loss per 100 training steps: 0.017217556923547407\n","Training loss per 100 training steps: 0.016696875013873805\n","Training loss per 100 training steps: 0.017612663887781807\n","Training loss per 100 training steps: 0.01798496287616904\n","Training loss per 100 training steps: 0.018207101934576492\n","Training loss per 100 training steps: 0.018091010339010203\n","Training loss per 100 training steps: 0.01806313262837753\n","Training loss per 100 training steps: 0.017982318969442277\n","Training loss per 100 training steps: 0.018251917508174263\n","Training loss per 100 training steps: 0.017769786417746968\n","Training loss per 100 training steps: 0.01774432162330006\n","Training loss epoch: 0.01774432162330006\n","Training accuracy epoch: 0.9944422011664663\n","Validating model...\n","Validation Loss: 0.2478148961476014\n","Validation Accuracy: 0.9532215989350525\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 131.85890184999997 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15867034476293526\n","Validation Accuracy: 0.9526486922715784\n","Validation duration: 5.881701083333367 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 83.8%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.86      0.82     12546\n","        test       0.86      0.87      0.87      9012\n","   treatment       0.84      0.82      0.83      9297\n","\n","   micro avg       0.83      0.85      0.84     30855\n","   macro avg       0.83      0.85      0.84     30855\n","weighted avg       0.83      0.85      0.84     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 41601\n","Points in y_train after augmentation: 41601\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9384740591049194\n","Training loss per 100 training steps: 0.41133052272961873\n","Training loss per 100 training steps: 0.30611726337700934\n","Training loss per 100 training steps: 0.2623340600971566\n","Training loss per 100 training steps: 0.23754203588959583\n","Training loss per 100 training steps: 0.21908741481527835\n","Training loss per 100 training steps: 0.20531918556303927\n","Training loss per 100 training steps: 0.19332759239353484\n","Training loss per 100 training steps: 0.18282688301424035\n","Training loss per 100 training steps: 0.17647578370251943\n","Training loss per 100 training steps: 0.17047292499297803\n","Training loss per 100 training steps: 0.1640937839373337\n","Training loss per 100 training steps: 0.159742266195613\n","Training loss per 100 training steps: 0.15566560922965098\n","Training loss epoch: 0.15566560922965098\n","Training accuracy epoch: 0.9495583346994362\n","Validating model...\n","Validation Loss: 0.13696407429970703\n","Validation Accuracy: 0.956456302038555\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06462723761796951\n","Training loss per 100 training steps: 0.06648058859207252\n","Training loss per 100 training steps: 0.06383467977403186\n","Training loss per 100 training steps: 0.06669480792800601\n","Training loss per 100 training steps: 0.06523513489117164\n","Training loss per 100 training steps: 0.06430617590507347\n","Training loss per 100 training steps: 0.06435129210932457\n","Training loss per 100 training steps: 0.06383501518200206\n","Training loss per 100 training steps: 0.06384499606585708\n","Training loss per 100 training steps: 0.06300508301445674\n","Training loss per 100 training steps: 0.06257028285470734\n","Training loss per 100 training steps: 0.06301243848219805\n","Training loss per 100 training steps: 0.06258919446955556\n","Training loss per 100 training steps: 0.06256831480497257\n","Stopping epoch...\n","Training loss epoch: 0.06256831480497257\n","Training accuracy epoch: 0.9788992046675463\n","Validating model...\n","Validation Loss: 0.15104968146747583\n","Validation Accuracy: 0.9565123384123909\n","Training epoch: 3\n","Training loss per 100 training steps: 0.008523058146238327\n","Training loss per 100 training steps: 0.03832748189734498\n","Training loss per 100 training steps: 0.038327905973790224\n","Training loss per 100 training steps: 0.03678893886098137\n","Training loss per 100 training steps: 0.038041271033587676\n","Training loss per 100 training steps: 0.038845154424263034\n","Training loss per 100 training steps: 0.039275903414552116\n","Training loss per 100 training steps: 0.038949035778183344\n","Training loss per 100 training steps: 0.038520423534265796\n","Training loss per 100 training steps: 0.038982847597595766\n","Training loss per 100 training steps: 0.03929470814859865\n","Training loss per 100 training steps: 0.03918867575169222\n","Training loss per 100 training steps: 0.03913465517677357\n","Training loss per 100 training steps: 0.03926868654608936\n","Stopping epoch...\n","Training loss epoch: 0.03926868654608936\n","Training accuracy epoch: 0.9868124418165738\n","Validating model...\n","Validation Loss: 0.16700478247669223\n","Validation Accuracy: 0.9580812162640484\n","Training epoch: 4\n","Training loss per 100 training steps: 0.02462713234126568\n","Training loss per 100 training steps: 0.027348179764363288\n","Training loss per 100 training steps: 0.026869335162003908\n","Training loss per 100 training steps: 0.02786526447115621\n","Training loss per 100 training steps: 0.027156424465382523\n","Training loss per 100 training steps: 0.0268741380344303\n","Training loss per 100 training steps: 0.02629175622476429\n","Training loss per 100 training steps: 0.026532843839855446\n","Training loss per 100 training steps: 0.026792920519250182\n","Training loss per 100 training steps: 0.027122222947511827\n","Training loss per 100 training steps: 0.02742279256781476\n","Training loss per 100 training steps: 0.02768068607591201\n","Training loss per 100 training steps: 0.027612189342384904\n","Training loss per 100 training steps: 0.027742784397431542\n","Training loss epoch: 0.027742784397431542\n","Training accuracy epoch: 0.9914012251432679\n","Validating model...\n","Validation Loss: 0.21499276172079437\n","Validation Accuracy: 0.9541382728988818\n","Training epoch: 5\n","Training loss per 100 training steps: 0.012800122611224651\n","Training loss per 100 training steps: 0.017915329929339783\n","Training loss per 100 training steps: 0.017277943580272372\n","Training loss per 100 training steps: 0.01804910028029227\n","Training loss per 100 training steps: 0.019313205101909325\n","Training loss per 100 training steps: 0.02021123865071383\n","Training loss per 100 training steps: 0.020148098020407196\n","Training loss per 100 training steps: 0.020393993841398166\n","Training loss per 100 training steps: 0.019934274769670385\n","Training loss per 100 training steps: 0.019923829972648632\n","Training loss per 100 training steps: 0.020453346879555277\n","Training loss per 100 training steps: 0.021230435317531725\n","Training loss per 100 training steps: 0.02202622988258859\n","Training loss per 100 training steps: 0.022115449214741255\n","Training loss epoch: 0.022115449214741255\n","Training accuracy epoch: 0.993113145694087\n","Validating model...\n","Validation Loss: 0.1995375868924833\n","Validation Accuracy: 0.9552568867455006\n","Training epoch: 6\n","Training loss per 100 training steps: 0.022149112075567245\n","Training loss per 100 training steps: 0.018180912661384607\n","Training loss per 100 training steps: 0.018910409018237477\n","Training loss per 100 training steps: 0.02163762097019529\n","Training loss per 100 training steps: 0.021566348421088934\n","Training loss per 100 training steps: 0.020885033011780366\n","Training loss per 100 training steps: 0.020156567879276856\n","Training loss per 100 training steps: 0.01986576071455437\n","Training loss per 100 training steps: 0.019813920563588574\n","Training loss per 100 training steps: 0.01977212434410005\n","Training loss per 100 training steps: 0.01997147669171827\n","Training loss per 100 training steps: 0.019924299863117834\n","Stopping epoch...\n","Training loss epoch: 0.019924299863117834\n","Training accuracy epoch: 0.9929133327616594\n","Validating model...\n","Validation Loss: 0.23293179754990262\n","Validation Accuracy: 0.9544639248275507\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 137.16216375000005 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.156235516280436\n","Validation Accuracy: 0.9529880162043136\n","Validation duration: 5.893790099999993 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 83.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.86      0.83     12546\n","        test       0.85      0.85      0.85      9012\n","   treatment       0.81      0.83      0.82      9297\n","\n","   micro avg       0.82      0.85      0.84     30855\n","   macro avg       0.82      0.85      0.84     30855\n","weighted avg       0.82      0.85      0.84     30855\n","\n"]}],"source":["number_of_training_models = 4\n","target_augmented_percentage = 2\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"GWfZZ6eTqXZM"},{"cell_type":"code","execution_count":null,"metadata":{"id":"TTDq-xbgHqXQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b4ee4f92-486a-4be1-f80e-86c38258d2b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["!!!!!! Augmented Percentage 500% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 83202\n","Points in y_train after augmentation: 83202\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1980996131896973\n","Training loss per 100 training steps: 0.42355837400006774\n","Training loss per 100 training steps: 0.322912358155298\n","Training loss per 100 training steps: 0.2757925982788156\n","Training loss per 100 training steps: 0.24857371486723423\n","Training loss per 100 training steps: 0.22973740332482936\n","Training loss per 100 training steps: 0.21417102546503958\n","Training loss per 100 training steps: 0.20284043458395354\n","Training loss per 100 training steps: 0.1915138118717815\n","Training loss per 100 training steps: 0.18351385222497776\n","Training loss per 100 training steps: 0.17542836051359847\n","Training loss per 100 training steps: 0.1689757181477008\n","Training loss per 100 training steps: 0.16301259505550852\n","Training loss per 100 training steps: 0.15860110619459744\n","Training loss per 100 training steps: 0.15414818595871488\n","Training loss per 100 training steps: 0.1499222036827105\n","Training loss per 100 training steps: 0.14616146057711532\n","Training loss per 100 training steps: 0.14232867607339858\n","Training loss per 100 training steps: 0.13901110938173625\n","Training loss per 100 training steps: 0.13581273602424626\n","Training loss per 100 training steps: 0.13236357765118667\n","Training loss per 100 training steps: 0.12961836577371394\n","Training loss per 100 training steps: 0.12688048815237074\n","Training loss per 100 training steps: 0.12480177037233324\n","Training loss per 100 training steps: 0.12241572188155284\n","Training loss per 100 training steps: 0.12027282700142185\n","Training loss per 100 training steps: 0.1182053099270113\n","Training loss epoch: 0.1182053099270113\n","Training accuracy epoch: 0.961814186612655\n","Validating model...\n","Validation Loss: 0.15483877977186983\n","Validation Accuracy: 0.9553400274709943\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04860039800405502\n","Training loss per 100 training steps: 0.039936365190856526\n","Training loss per 100 training steps: 0.04185943305492401\n","Training loss per 100 training steps: 0.04265828998728448\n","Training loss per 100 training steps: 0.04410385597552965\n","Training loss per 100 training steps: 0.044216316263981446\n","Training loss per 100 training steps: 0.04539157368998956\n","Training loss per 100 training steps: 0.045075273868653086\n","Training loss per 100 training steps: 0.04514608574454462\n","Training loss per 100 training steps: 0.04526617773369236\n","Training loss per 100 training steps: 0.04472346652739241\n","Training loss per 100 training steps: 0.044857596708918424\n","Training loss per 100 training steps: 0.04486383643442553\n","Training loss per 100 training steps: 0.04544195201091159\n","Training loss per 100 training steps: 0.0461888936456947\n","Training loss per 100 training steps: 0.04650282681060906\n","Training loss per 100 training steps: 0.046343347380405464\n","Training loss per 100 training steps: 0.04616246567253376\n","Training loss per 100 training steps: 0.045879793039102654\n","Training loss per 100 training steps: 0.04564182220287974\n","Training loss per 100 training steps: 0.0455006901301613\n","Training loss per 100 training steps: 0.04509872607547685\n","Training loss per 100 training steps: 0.04475525566234995\n","Training loss per 100 training steps: 0.04419756335447559\n","Training loss per 100 training steps: 0.04397226309918507\n","Training loss per 100 training steps: 0.04363942696008741\n","Training loss per 100 training steps: 0.043241709006519864\n","Training loss epoch: 0.043241709006519864\n","Training accuracy epoch: 0.9860833016281745\n","Validating model...\n","Validation Loss: 0.20950037554245104\n","Validation Accuracy: 0.9523350923647041\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02199370227754116\n","Training loss per 100 training steps: 0.0236577042925983\n","Training loss per 100 training steps: 0.026306791508753334\n","Training loss per 100 training steps: 0.02509491018714241\n","Training loss per 100 training steps: 0.02444918180102868\n","Training loss per 100 training steps: 0.025122576270497844\n","Training loss per 100 training steps: 0.02541100811492187\n","Training loss per 100 training steps: 0.025440984540924527\n","Training loss per 100 training steps: 0.02537177726071207\n","Training loss per 100 training steps: 0.025952874764373173\n","Training loss per 100 training steps: 0.02608212082008073\n","Training loss per 100 training steps: 0.02612370760279448\n","Training loss per 100 training steps: 0.02652743790420059\n","Training loss per 100 training steps: 0.026548276930083905\n","Training loss per 100 training steps: 0.026870306236749193\n","Training loss per 100 training steps: 0.026789165374175767\n","Training loss per 100 training steps: 0.026907349490199347\n","Training loss per 100 training steps: 0.026643615283018885\n","Training loss per 100 training steps: 0.02659162298086767\n","Training loss per 100 training steps: 0.026371517533019747\n","Training loss per 100 training steps: 0.026369400704874126\n","Training loss per 100 training steps: 0.02628243743331291\n","Training loss per 100 training steps: 0.026470062682818308\n","Training loss per 100 training steps: 0.02635283883046727\n","Stopping epoch...\n","Training loss epoch: 0.02635283883046727\n","Training accuracy epoch: 0.9913298814659961\n","Validating model...\n","Validation Loss: 0.2509000180168198\n","Validation Accuracy: 0.9499798955796332\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0014961945125833154\n","Training loss per 100 training steps: 0.02110465361718273\n","Training loss per 100 training steps: 0.02307902682811226\n","Training loss per 100 training steps: 0.021724498737139313\n","Training loss per 100 training steps: 0.020678214873698194\n","Training loss per 100 training steps: 0.021166122013083967\n","Training loss per 100 training steps: 0.022480145316244027\n","Training loss per 100 training steps: 0.02285497282886115\n","Training loss per 100 training steps: 0.022806745015413788\n","Training loss per 100 training steps: 0.022554708150790158\n","Training loss per 100 training steps: 0.022320416731028154\n","Training loss per 100 training steps: 0.02177525456508598\n","Training loss per 100 training steps: 0.022052921435078816\n","Training loss per 100 training steps: 0.02225316315303255\n","Training loss per 100 training steps: 0.022194219027025338\n","Training loss per 100 training steps: 0.02200539999035436\n","Training loss per 100 training steps: 0.021892687684285112\n","Training loss per 100 training steps: 0.021846680578397646\n","Training loss per 100 training steps: 0.021864185354555764\n","Training loss per 100 training steps: 0.02187582999931429\n","Stopping epoch...\n","Training loss epoch: 0.02187582999931429\n","Training accuracy epoch: 0.9926111348764163\n","Validating model...\n","Validation Loss: 0.2793062102872056\n","Validation Accuracy: 0.9467819792473551\n","Training epoch: 5\n","Training loss per 100 training steps: 0.013928109779953957\n","Training loss per 100 training steps: 0.013904477198179442\n","Stopping epoch...\n","Training loss epoch: 0.013904477198179442\n","Training accuracy epoch: 0.986263468939547\n","Validating model...\n","Validation Loss: 0.2655498483157777\n","Validation Accuracy: 0.9492279593427608\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0039037528913468122\n","Training loss per 100 training steps: 0.02256164428061059\n","Training loss per 100 training steps: 0.019263647136160297\n","Training loss per 100 training steps: 0.019070358692913587\n","Training loss per 100 training steps: 0.018340831031477628\n","Training loss per 100 training steps: 0.018930693594387968\n","Training loss per 100 training steps: 0.018398848479021318\n","Training loss per 100 training steps: 0.018196779718885288\n","Training loss per 100 training steps: 0.01761081491422737\n","Training loss per 100 training steps: 0.01755255022854079\n","Training loss per 100 training steps: 0.017684764235535614\n","Training loss per 100 training steps: 0.01769612314168226\n","Training loss per 100 training steps: 0.017618334180832283\n","Stopping epoch...\n","Training loss epoch: 0.017618334180832283\n","Training accuracy epoch: 0.9937007075753918\n","Validating model...\n","Validation Loss: 0.27128464607642844\n","Validation Accuracy: 0.9466885064674831\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 192.54372209999988 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.1686109147526117\n","Validation Accuracy: 0.9527188759939982\n","Validation duration: 5.885068700000072 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 83.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.84      0.83     12546\n","        test       0.83      0.84      0.84      9012\n","   treatment       0.83      0.85      0.84      9297\n","\n","   micro avg       0.83      0.85      0.84     30855\n","   macro avg       0.83      0.85      0.84     30855\n","weighted avg       0.83      0.85      0.84     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 83202\n","Points in y_train after augmentation: 83202\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8408125638961792\n","Training loss per 100 training steps: 0.43382328756079813\n","Training loss per 100 training steps: 0.32382058611704934\n","Training loss per 100 training steps: 0.2747643697895481\n","Training loss per 100 training steps: 0.24730699602282255\n","Training loss per 100 training steps: 0.22800517828015987\n","Training loss per 100 training steps: 0.21281973584965738\n","Training loss per 100 training steps: 0.20214933173707056\n","Training loss per 100 training steps: 0.19245828801391648\n","Training loss per 100 training steps: 0.18402065749959265\n","Training loss per 100 training steps: 0.1778779793363232\n","Training loss per 100 training steps: 0.1709874046079943\n","Training loss per 100 training steps: 0.16566453571760908\n","Training loss per 100 training steps: 0.1597263758921914\n","Training loss per 100 training steps: 0.15493994327973332\n","Training loss per 100 training steps: 0.15092726438855386\n","Training loss per 100 training steps: 0.14713743998192666\n","Training loss per 100 training steps: 0.1433543026067321\n","Training loss per 100 training steps: 0.14005603594886454\n","Training loss per 100 training steps: 0.13694845845110554\n","Training loss per 100 training steps: 0.1335934676289994\n","Training loss per 100 training steps: 0.1310032357702006\n","Training loss per 100 training steps: 0.12811604208600239\n","Training loss per 100 training steps: 0.12535926358133184\n","Training loss per 100 training steps: 0.12307364134403448\n","Training loss per 100 training steps: 0.12090607708124894\n","Training loss per 100 training steps: 0.11868959578235377\n","Training loss epoch: 0.11868959578235377\n","Training accuracy epoch: 0.9616648716659104\n","Validating model...\n","Validation Loss: 0.1896117760182975\n","Validation Accuracy: 0.9477748504579924\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05016421899199486\n","Training loss per 100 training steps: 0.04862249526886804\n","Training loss per 100 training steps: 0.04869700730106427\n","Training loss per 100 training steps: 0.04678993877580396\n","Training loss per 100 training steps: 0.04670150178203596\n","Training loss per 100 training steps: 0.0461698873033617\n","Training loss per 100 training steps: 0.047028500688248334\n","Training loss per 100 training steps: 0.04659580232804049\n","Training loss per 100 training steps: 0.04596205484633626\n","Training loss per 100 training steps: 0.046055081548514495\n","Training loss per 100 training steps: 0.04574897129634781\n","Training loss per 100 training steps: 0.045632589171741234\n","Training loss per 100 training steps: 0.0449438793807648\n","Training loss per 100 training steps: 0.044842807599504424\n","Training loss per 100 training steps: 0.044709311020617065\n","Training loss per 100 training steps: 0.0443468510716481\n","Training loss per 100 training steps: 0.04375856694809599\n","Training loss per 100 training steps: 0.04378103118620896\n","Training loss per 100 training steps: 0.043585131930726176\n","Training loss per 100 training steps: 0.04333482665264061\n","Training loss per 100 training steps: 0.043351218812861136\n","Training loss per 100 training steps: 0.04353866469093298\n","Training loss per 100 training steps: 0.043594451896213283\n","Stopping epoch...\n","Training loss epoch: 0.043594451896213283\n","Training accuracy epoch: 0.98567475412177\n","Validating model...\n","Validation Loss: 0.18543496916626956\n","Validation Accuracy: 0.9497462219831136\n","Training epoch: 3\n","Training loss per 100 training steps: 0.006315112579613924\n","Training loss per 100 training steps: 0.025348066448552146\n","Training loss per 100 training steps: 0.027406769943370286\n","Training loss per 100 training steps: 0.028674544745466775\n","Training loss per 100 training steps: 0.0284420671253558\n","Training loss per 100 training steps: 0.028097144167609105\n","Training loss per 100 training steps: 0.028524585119653927\n","Training loss per 100 training steps: 0.02960493478725748\n","Training loss per 100 training steps: 0.030402935113738663\n","Training loss per 100 training steps: 0.030066436273885683\n","Training loss per 100 training steps: 0.03015612934656268\n","Training loss per 100 training steps: 0.03024894035996304\n","Training loss per 100 training steps: 0.03020477863006351\n","Training loss per 100 training steps: 0.0299355047378674\n","Training loss per 100 training steps: 0.03022674834491156\n","Training loss per 100 training steps: 0.030029588462690264\n","Training loss per 100 training steps: 0.030067054053347066\n","Stopping epoch...\n","Training loss epoch: 0.030067054053347066\n","Training accuracy epoch: 0.9899204644436714\n","Validating model...\n","Validation Loss: 0.20967356502017997\n","Validation Accuracy: 0.9519660262065641\n","Training epoch: 4\n","Training loss per 100 training steps: 0.005837826058268547\n","Training loss per 100 training steps: 0.02037156061361553\n","Training loss per 100 training steps: 0.02143513265272037\n","Training loss per 100 training steps: 0.023776280375018072\n","Training loss per 100 training steps: 0.023038285766423975\n","Training loss per 100 training steps: 0.02433813910953656\n","Training loss per 100 training steps: 0.02499213045503256\n","Training loss per 100 training steps: 0.024737026510539648\n","Training loss per 100 training steps: 0.023942686023598145\n","Training loss per 100 training steps: 0.02405975101567075\n","Training loss per 100 training steps: 0.024078209132300812\n","Training loss per 100 training steps: 0.02404510623972726\n","Training loss per 100 training steps: 0.0242510154404907\n","Training loss per 100 training steps: 0.023925175041729495\n","Training loss per 100 training steps: 0.02398724614165266\n","Training loss per 100 training steps: 0.02369418744476193\n","Training loss per 100 training steps: 0.023686743879761735\n","Training loss per 100 training steps: 0.023612527805558465\n","Training loss per 100 training steps: 0.023556934051920993\n","Training loss per 100 training steps: 0.023803746114033755\n","Training loss per 100 training steps: 0.02416776475389076\n","Training loss per 100 training steps: 0.02416255949222452\n","Training loss per 100 training steps: 0.0241319039232076\n","Training loss per 100 training steps: 0.024102469522763823\n","Training loss per 100 training steps: 0.02400731475589745\n","Stopping epoch...\n","Training loss epoch: 0.02400731475589745\n","Training accuracy epoch: 0.9921401699280994\n","Validating model...\n","Validation Loss: 0.25585423180131944\n","Validation Accuracy: 0.9495783921404644\n","Training epoch: 5\n","Training loss per 100 training steps: 0.01513439416885376\n","Training loss per 100 training steps: 0.01589568978403741\n","Training loss per 100 training steps: 0.019344512547831982\n","Training loss per 100 training steps: 0.02045407552392751\n","Training loss per 100 training steps: 0.018573614660832807\n","Training loss per 100 training steps: 0.019401828258250934\n","Training loss per 100 training steps: 0.01935215580731184\n","Training loss per 100 training steps: 0.019526110747138226\n","Training loss per 100 training steps: 0.01918208040693076\n","Training loss per 100 training steps: 0.019247572336568923\n","Training loss per 100 training steps: 0.01945041704678803\n","Training loss per 100 training steps: 0.01958591746402457\n","Training loss per 100 training steps: 0.019935489619612348\n","Training loss per 100 training steps: 0.02000847435791241\n","Training loss per 100 training steps: 0.019745695474466175\n","Training loss per 100 training steps: 0.019642420645409525\n","Training loss per 100 training steps: 0.01958096718860192\n","Training loss per 100 training steps: 0.019516829033701163\n","Training loss per 100 training steps: 0.01942193524770181\n","Training loss per 100 training steps: 0.01921822568642976\n","Training loss per 100 training steps: 0.01925736979314027\n","Training loss per 100 training steps: 0.019071665001798844\n","Training loss per 100 training steps: 0.01905409918742268\n","Training loss per 100 training steps: 0.01920138527411034\n","Training loss per 100 training steps: 0.01922536133553853\n","Training loss per 100 training steps: 0.019200454930495953\n","Stopping epoch...\n","Training loss epoch: 0.019200454930495953\n","Training accuracy epoch: 0.9936056534244493\n","Validating model...\n","Validation Loss: 0.24281390562847063\n","Validation Accuracy: 0.9503784274338556\n","Training epoch: 6\n","Training loss per 100 training steps: 0.009366561658680439\n","Training loss per 100 training steps: 0.011451292240710948\n","Training loss per 100 training steps: 0.011888793608247863\n","Training loss per 100 training steps: 0.012609139711176822\n","Training loss per 100 training steps: 0.01260791842415209\n","Training loss per 100 training steps: 0.0136979822046867\n","Training loss per 100 training steps: 0.014054507250256818\n","Training loss per 100 training steps: 0.014713696523064005\n","Training loss per 100 training steps: 0.014926569670511144\n","Training loss per 100 training steps: 0.015309187440367283\n","Training loss per 100 training steps: 0.015527595728643928\n","Training loss per 100 training steps: 0.01556033408367092\n","Training loss per 100 training steps: 0.015476359913990656\n","Training loss per 100 training steps: 0.015488608121864074\n","Training loss per 100 training steps: 0.015572424015534814\n","Stopping epoch...\n","Training loss epoch: 0.015572424015534814\n","Training accuracy epoch: 0.9944885447730042\n","Validating model...\n","Validation Loss: 0.23775375467519483\n","Validation Accuracy: 0.9510932749022917\n","Training epoch: 7\n","Training loss per 100 training steps: 0.11728446185588837\n","Training loss per 100 training steps: 0.017773644735294365\n","Training loss per 100 training steps: 0.014904125173117466\n","Training loss per 100 training steps: 0.01308258057545261\n","Training loss per 100 training steps: 0.012649180459182598\n","Training loss per 100 training steps: 0.012527767546751913\n","Training loss per 100 training steps: 0.012623851416725897\n","Training loss per 100 training steps: 0.012686992228569558\n","Training loss per 100 training steps: 0.01281561433306672\n","Training loss per 100 training steps: 0.012906550078868057\n","Training loss per 100 training steps: 0.013124255311594425\n","Training loss per 100 training steps: 0.013364771641131075\n","Training loss per 100 training steps: 0.013275868386981294\n","Training loss per 100 training steps: 0.013267930180150593\n","Training loss per 100 training steps: 0.013356858240241892\n","Training loss per 100 training steps: 0.01349074602532939\n","Training loss per 100 training steps: 0.013347240902415403\n","Training loss per 100 training steps: 0.013422001966118959\n","Training loss per 100 training steps: 0.013269189506345664\n","Training loss per 100 training steps: 0.01333394768798773\n","Training loss per 100 training steps: 0.013298550996748646\n","Training loss per 100 training steps: 0.013651198089982284\n","Training loss per 100 training steps: 0.013767808577704198\n","Training loss per 100 training steps: 0.013791342136713805\n","Training loss per 100 training steps: 0.013962430499148078\n","Training loss per 100 training steps: 0.013901521068906355\n","Training loss per 100 training steps: 0.01399135352244081\n","Training loss epoch: 0.01399135352244081\n","Training accuracy epoch: 0.9957693002446739\n","Validating model...\n","Validation Loss: 0.2508047406331866\n","Validation Accuracy: 0.9511531363186599\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 273.11366290000007 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.2141315997642879\n","Validation Accuracy: 0.9459620330038497\n","Validation duration: 5.892047849999896 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 81.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.78      0.80      0.79     12546\n","        test       0.83      0.85      0.84      9012\n","   treatment       0.80      0.83      0.81      9297\n","\n","   micro avg       0.80      0.82      0.81     30855\n","   macro avg       0.80      0.83      0.81     30855\n","weighted avg       0.80      0.82      0.81     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 83202\n","Points in y_train after augmentation: 83202\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.6085652112960815\n","Training loss per 100 training steps: 0.4154039885443036\n","Training loss per 100 training steps: 0.3149358435946317\n","Training loss per 100 training steps: 0.2772734447373108\n","Training loss per 100 training steps: 0.24799445330948008\n","Training loss per 100 training steps: 0.22800543838126694\n","Training loss per 100 training steps: 0.21389070524525722\n","Training loss per 100 training steps: 0.20250755740587364\n","Training loss per 100 training steps: 0.19220566345302018\n","Training loss per 100 training steps: 0.18447485759949414\n","Training loss per 100 training steps: 0.17643300973932136\n","Training loss per 100 training steps: 0.1708132947713042\n","Training loss per 100 training steps: 0.1651369324713933\n","Training loss per 100 training steps: 0.15982779769368646\n","Training loss per 100 training steps: 0.15577057141512846\n","Training loss per 100 training steps: 0.15068060083831006\n","Training loss per 100 training steps: 0.14641854814809283\n","Training loss per 100 training steps: 0.14312103985869565\n","Training loss per 100 training steps: 0.13992204636243327\n","Training loss per 100 training steps: 0.137196664931865\n","Training loss per 100 training steps: 0.1342686416429078\n","Training loss per 100 training steps: 0.13159173408032052\n","Training loss per 100 training steps: 0.12942533265492087\n","Training loss per 100 training steps: 0.12712065112562135\n","Training loss per 100 training steps: 0.12520648714993576\n","Training loss per 100 training steps: 0.12295652672153909\n","Training loss per 100 training steps: 0.12078277719311248\n","Training loss epoch: 0.12078277719311248\n","Training accuracy epoch: 0.9607817318780164\n","Validating model...\n","Validation Loss: 0.1747763200917027\n","Validation Accuracy: 0.9543206911285146\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06631223857402802\n","Training loss per 100 training steps: 0.047050832282051\n","Training loss per 100 training steps: 0.04796613523718062\n","Training loss per 100 training steps: 0.04940009501103646\n","Training loss per 100 training steps: 0.04918631165174586\n","Training loss per 100 training steps: 0.04852358176802358\n","Training loss per 100 training steps: 0.047193675952422715\n","Training loss per 100 training steps: 0.04672814996218237\n","Training loss per 100 training steps: 0.04638276162113152\n","Training loss per 100 training steps: 0.04703618777677061\n","Training loss per 100 training steps: 0.04653415667264351\n","Training loss per 100 training steps: 0.046832047006348784\n","Training loss per 100 training steps: 0.04645544904800633\n","Training loss per 100 training steps: 0.04622436087627929\n","Training loss per 100 training steps: 0.046515352911828386\n","Training loss per 100 training steps: 0.046417502172168425\n","Training loss per 100 training steps: 0.046818921840583894\n","Training loss per 100 training steps: 0.04649332301761804\n","Training loss per 100 training steps: 0.04610064292628047\n","Training loss per 100 training steps: 0.04599731768528465\n","Training loss per 100 training steps: 0.04570636177830666\n","Training loss per 100 training steps: 0.04591006198069032\n","Training loss per 100 training steps: 0.04588694249477401\n","Stopping epoch...\n","Training loss epoch: 0.04588694249477401\n","Training accuracy epoch: 0.9851275131529851\n","Validating model...\n","Validation Loss: 0.20469358969818463\n","Validation Accuracy: 0.9498427467974353\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02880864031612873\n","Training loss per 100 training steps: 0.02967954871456812\n","Training loss per 100 training steps: 0.03081123270059644\n","Training loss per 100 training steps: 0.030397900246761343\n","Training loss per 100 training steps: 0.030112259948981503\n","Training loss per 100 training steps: 0.02991194567506475\n","Training loss per 100 training steps: 0.030406721047290017\n","Training loss per 100 training steps: 0.03080584020413639\n","Training loss per 100 training steps: 0.03194046398995679\n","Training loss per 100 training steps: 0.03326230348794867\n","Training loss per 100 training steps: 0.0335886947839492\n","Training loss per 100 training steps: 0.03349878654103019\n","Training loss per 100 training steps: 0.03325841023649115\n","Training loss per 100 training steps: 0.03276236510662352\n","Training loss per 100 training steps: 0.03274319570649184\n","Training loss per 100 training steps: 0.03260632947712099\n","Training loss per 100 training steps: 0.03257963997788895\n","Training loss per 100 training steps: 0.032777400773365176\n","Stopping epoch...\n","Training loss epoch: 0.032777400773365176\n","Training accuracy epoch: 0.9891197710443616\n","Validating model...\n","Validation Loss: 0.20705820174960346\n","Validation Accuracy: 0.953734743980395\n","Training epoch: 4\n","Training loss per 100 training steps: 0.06456045061349869\n","Training loss per 100 training steps: 0.024772645397305414\n","Training loss per 100 training steps: 0.023952977224461623\n","Training loss per 100 training steps: 0.024432596145661862\n","Training loss per 100 training steps: 0.024001514352161316\n","Training loss per 100 training steps: 0.023316135893979233\n","Training loss per 100 training steps: 0.023346731690465226\n","Training loss per 100 training steps: 0.02305591513594405\n","Training loss per 100 training steps: 0.023252036026591778\n","Training loss per 100 training steps: 0.023305382737584958\n","Training loss per 100 training steps: 0.022750860204446603\n","Training loss per 100 training steps: 0.022791813144191327\n","Training loss per 100 training steps: 0.022541516565746447\n","Training loss per 100 training steps: 0.022671493780290954\n","Training loss per 100 training steps: 0.023023836726411184\n","Training loss per 100 training steps: 0.023325805229660393\n","Training loss per 100 training steps: 0.023567375197275416\n","Training loss per 100 training steps: 0.023996973888297565\n","Training loss per 100 training steps: 0.02393696473572436\n","Training loss per 100 training steps: 0.023967545305433605\n","Training loss per 100 training steps: 0.02404132542474524\n","Training loss per 100 training steps: 0.024356607621615893\n","Training loss per 100 training steps: 0.024381480711662056\n","Training loss per 100 training steps: 0.024131864300305294\n","Training loss per 100 training steps: 0.024367461228678805\n","Training loss per 100 training steps: 0.024223735401049773\n","Training loss per 100 training steps: 0.024211507699196683\n","Training loss epoch: 0.024211507699196683\n","Training accuracy epoch: 0.9925738082658353\n","Validating model...\n","Validation Loss: 0.24151017144322395\n","Validation Accuracy: 0.9491419195726806\n","Training epoch: 5\n","Training loss per 100 training steps: 0.01790325529873371\n","Training loss per 100 training steps: 0.01632370731659639\n","Training loss per 100 training steps: 0.01970012884399395\n","Training loss per 100 training steps: 0.01996378583077069\n","Training loss per 100 training steps: 0.01975746159382255\n","Training loss per 100 training steps: 0.01983201699399951\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 5\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"TTDq-xbgHqXQ"},{"cell_type":"code","source":["number_of_training_models = 8\n","target_augmented_percentage = 5\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["c314e9ffb26f47e09a2fcdab16b62856","a49020960edb43d1bb105b4bce69262d","47bea9d3556a4084aa0f0158bf9215f0","eb98ff57b533422792982b7f110a31e9","0a8d498b6a7f4add9a5afa542f527d91","be9797caa49b48f7bc6c26230c37e5b9","4a649775e9cf405787de06a99b3dd222","d1a0555df7184fa4a771c2071f6991c3","f5b2fbcebead48c4961053e89bb53b24","66fd9e81137b4e67b57821722f1dd7e4","8dab5366ac854d0f99f5298179f8f248"]},"id":"7vLSmffKUGhF","outputId":"a099059b-b4ab-4212-8ffc-c7b8676fa5d8"},"id":"7vLSmffKUGhF","execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 500% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c314e9ffb26f47e09a2fcdab16b62856","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 83202\n","Points in y_train after augmentation: 83202\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9796066284179688\n","Training loss per 100 training steps: 0.4230798375193435\n","Training loss per 100 training steps: 0.3201304228225751\n","Training loss per 100 training steps: 0.27159508810288885\n","Training loss per 100 training steps: 0.2437757006625731\n","Training loss per 100 training steps: 0.22369520046828154\n","Training loss per 100 training steps: 0.20732360369465413\n","Training loss per 100 training steps: 0.19597864241608964\n","Training loss per 100 training steps: 0.1893264605488149\n","Training loss per 100 training steps: 0.18081686242000838\n","Training loss per 100 training steps: 0.17374056806000737\n","Training loss per 100 training steps: 0.1665593898482113\n","Training loss per 100 training steps: 0.16072526389343678\n","Training loss per 100 training steps: 0.15612959037023058\n","Training loss per 100 training steps: 0.15127972780868443\n","Training loss per 100 training steps: 0.14700808974391197\n","Training loss per 100 training steps: 0.14318920912827218\n","Training loss per 100 training steps: 0.13915914916726313\n","Training loss per 100 training steps: 0.13585603914364783\n","Training loss per 100 training steps: 0.13282496612352457\n","Training loss per 100 training steps: 0.13008875843846815\n","Training loss per 100 training steps: 0.1274098301082956\n","Training loss per 100 training steps: 0.12491431510222333\n","Training loss per 100 training steps: 0.12236996707034947\n","Training loss per 100 training steps: 0.12027374777969273\n","Training loss per 100 training steps: 0.11826639927987728\n","Training loss per 100 training steps: 0.11618093257102244\n","Training loss epoch: 0.11618093257102244\n","Training accuracy epoch: 0.9626393001538859\n","Validating model...\n","Validation Loss: 0.15891069028671687\n","Validation Accuracy: 0.9555282339711232\n","Training epoch: 2\n","Training loss per 100 training steps: 0.12078005820512772\n","Training loss per 100 training steps: 0.042419912971298\n","Training loss per 100 training steps: 0.041589670601435265\n","Training loss per 100 training steps: 0.04374574441106934\n","Training loss per 100 training steps: 0.04461930229379668\n","Training loss per 100 training steps: 0.04474257759121572\n","Training loss per 100 training steps: 0.0449438421373347\n","Training loss per 100 training steps: 0.04484846167559981\n","Training loss per 100 training steps: 0.04546758090436561\n","Training loss per 100 training steps: 0.044967037299751295\n","Training loss per 100 training steps: 0.04520358362413764\n","Training loss per 100 training steps: 0.04489492931484425\n","Training loss per 100 training steps: 0.045271853634081066\n","Training loss per 100 training steps: 0.04540089577605388\n","Training loss per 100 training steps: 0.04491836553390306\n","Training loss per 100 training steps: 0.044841774192692675\n","Training loss per 100 training steps: 0.045258416381224215\n","Training loss per 100 training steps: 0.04529931587438104\n","Training loss per 100 training steps: 0.04536330474277897\n","Training loss per 100 training steps: 0.04514321798864342\n","Training loss per 100 training steps: 0.04472186851795988\n","Training loss per 100 training steps: 0.044358625725223755\n","Training loss per 100 training steps: 0.04404275494435974\n","Training loss per 100 training steps: 0.04384282214215138\n","Training loss per 100 training steps: 0.043984414210032186\n","Training loss per 100 training steps: 0.04377020000479557\n","Training loss per 100 training steps: 0.04354907611224486\n","Training loss epoch: 0.04354907611224486\n","Training accuracy epoch: 0.9858289917969516\n","Validating model...\n","Validation Loss: 0.1986297293529882\n","Validation Accuracy: 0.9554562289817643\n","Training epoch: 3\n","Training loss per 100 training steps: 0.007483449298888445\n","Training loss per 100 training steps: 0.020812854374814227\n","Training loss per 100 training steps: 0.02660298148640408\n","Training loss per 100 training steps: 0.02690620428265267\n","Training loss per 100 training steps: 0.02717427985174837\n","Training loss per 100 training steps: 0.02716689386698761\n","Training loss per 100 training steps: 0.027755860808850133\n","Training loss per 100 training steps: 0.027204315147622383\n","Training loss per 100 training steps: 0.027239108456344637\n","Training loss per 100 training steps: 0.026928909878351403\n","Training loss per 100 training steps: 0.026856929191784073\n","Training loss per 100 training steps: 0.026229373041655003\n","Training loss per 100 training steps: 0.025984225003271723\n","Training loss per 100 training steps: 0.025907474294776234\n","Training loss per 100 training steps: 0.026337842927518753\n","Training loss per 100 training steps: 0.02617774484783807\n","Training loss per 100 training steps: 0.025939204192772417\n","Training loss per 100 training steps: 0.026122057103960643\n","Training loss per 100 training steps: 0.026230656936474358\n","Training loss per 100 training steps: 0.025960899470165777\n","Training loss per 100 training steps: 0.02599847890609556\n","Training loss per 100 training steps: 0.02580236524049765\n","Training loss per 100 training steps: 0.025801994951710257\n","Training loss per 100 training steps: 0.025751617940967725\n","Stopping epoch...\n","Training loss epoch: 0.025751617940967725\n","Training accuracy epoch: 0.9914281314342459\n","Validating model...\n","Validation Loss: 0.23175267693465695\n","Validation Accuracy: 0.9487793750416178\n","Training epoch: 4\n","Training loss per 100 training steps: 0.012303750030696392\n","Training loss per 100 training steps: 0.024326060385683017\n","Training loss per 100 training steps: 0.020887718619361742\n","Training loss per 100 training steps: 0.020079419537226164\n","Training loss per 100 training steps: 0.019608168755779903\n","Training loss per 100 training steps: 0.019387261949580892\n","Training loss per 100 training steps: 0.019079355835142125\n","Training loss per 100 training steps: 0.019722983520577653\n","Training loss per 100 training steps: 0.019477358231272727\n","Training loss per 100 training steps: 0.019668838198332386\n","Training loss per 100 training steps: 0.01958975346381455\n","Training loss per 100 training steps: 0.019877540038852698\n","Training loss per 100 training steps: 0.0200587262634167\n","Training loss per 100 training steps: 0.020380237448830257\n","Training loss per 100 training steps: 0.020537567548502004\n","Training loss per 100 training steps: 0.020787188663498886\n","Training loss per 100 training steps: 0.020704044454785145\n","Training loss per 100 training steps: 0.020761602290392443\n","Training loss per 100 training steps: 0.02072902204930888\n","Training loss per 100 training steps: 0.02067330375743718\n","Stopping epoch...\n","Training loss epoch: 0.02067330375743718\n","Training accuracy epoch: 0.9930464211272011\n","Validating model...\n","Validation Loss: 0.28824644076166217\n","Validation Accuracy: 0.9466887946880341\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0028298271354287863\n","Training loss per 100 training steps: 0.015834131374918292\n","Training loss per 100 training steps: 0.01575302463187025\n","Training loss per 100 training steps: 0.015071517131345476\n","Training loss per 100 training steps: 0.015959439839252697\n","Training loss per 100 training steps: 0.016561995501845644\n","Training loss per 100 training steps: 0.017739088664462048\n","Training loss per 100 training steps: 0.01701077175406027\n","Training loss per 100 training steps: 0.016480053596102055\n","Training loss per 100 training steps: 0.01640835636755096\n","Training loss per 100 training steps: 0.016923530698955323\n","Training loss per 100 training steps: 0.01702043615125304\n","Training loss per 100 training steps: 0.016659944571033553\n","Training loss per 100 training steps: 0.017139929969709863\n","Training loss per 100 training steps: 0.01708306195540121\n","Training loss per 100 training steps: 0.016895113754933754\n","Training loss per 100 training steps: 0.01690059843755849\n","Training loss per 100 training steps: 0.01697634119236035\n","Training loss per 100 training steps: 0.017072073803779703\n","Training loss per 100 training steps: 0.017184071410910325\n","Training loss per 100 training steps: 0.017150481814605375\n","Training loss per 100 training steps: 0.017692774162233905\n","Training loss per 100 training steps: 0.018202367378943565\n","Training loss per 100 training steps: 0.018156857263515\n","Training loss per 100 training steps: 0.018276632688994845\n","Training loss per 100 training steps: 0.01840670123644287\n","Training loss per 100 training steps: 0.018399413527262407\n","Training loss epoch: 0.018399413527262407\n","Training accuracy epoch: 0.9942700343121325\n","Validating model...\n","Validation Loss: 0.27325488951105575\n","Validation Accuracy: 0.9475746662338912\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0003507432120386511\n","Training loss per 100 training steps: 0.012260104430145538\n","Training loss per 100 training steps: 0.012108323213948976\n","Training loss per 100 training steps: 0.014454252980676544\n","Training loss per 100 training steps: 0.014567064205193289\n","Training loss per 100 training steps: 0.014202225277330002\n","Training loss per 100 training steps: 0.01376742296134503\n","Training loss per 100 training steps: 0.01313578327973247\n","Training loss per 100 training steps: 0.01310783278716777\n","Training loss per 100 training steps: 0.01323889836471411\n","Training loss per 100 training steps: 0.013308260095712555\n","Training loss per 100 training steps: 0.013173605006981809\n","Training loss per 100 training steps: 0.013211135655009754\n","Training loss per 100 training steps: 0.013271217395096579\n","Training loss per 100 training steps: 0.013099400796965735\n","Training loss per 100 training steps: 0.01323867201983732\n","Training loss per 100 training steps: 0.013184299643011415\n","Training loss per 100 training steps: 0.013293149017548595\n","Training loss per 100 training steps: 0.0142308991003531\n","Training loss per 100 training steps: 0.014412649290265441\n","Training loss per 100 training steps: 0.01475174879178003\n","Training loss per 100 training steps: 0.01489258526704675\n","Training loss per 100 training steps: 0.01489388785762778\n","Training loss per 100 training steps: 0.014888855441246159\n","Training loss per 100 training steps: 0.01497701600633553\n","Training loss per 100 training steps: 0.014929543344137977\n","Stopping epoch...\n","Training loss epoch: 0.014929543344137977\n","Training accuracy epoch: 0.995021180921478\n","Validating model...\n","Validation Loss: 0.2791492533567664\n","Validation Accuracy: 0.9479745350224127\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 260.39907858333333 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.17251417760875215\n","Validation Accuracy: 0.9533894003743868\n","Validation duration: 5.914620516666703 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 84.3%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.84      0.84     12546\n","        test       0.84      0.87      0.86      9012\n","   treatment       0.82      0.86      0.84      9297\n","\n","   micro avg       0.83      0.86      0.84     30855\n","   macro avg       0.83      0.86      0.84     30855\n","weighted avg       0.83      0.86      0.84     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 83202\n","Points in y_train after augmentation: 83202\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.070664167404175\n","Training loss per 100 training steps: 0.4076111486347595\n","Training loss per 100 training steps: 0.3050920213781186\n","Training loss per 100 training steps: 0.26138212234771924\n","Training loss per 100 training steps: 0.23379401933225313\n","Training loss per 100 training steps: 0.21830073796108573\n","Training loss per 100 training steps: 0.2046935945786474\n","Training loss per 100 training steps: 0.1927820098733851\n","Training loss per 100 training steps: 0.18423479404323706\n","Training loss per 100 training steps: 0.1775850850063377\n","Training loss per 100 training steps: 0.17133784296919594\n","Training loss per 100 training steps: 0.1650099137342864\n","Training loss per 100 training steps: 0.16039725048599343\n","Training loss per 100 training steps: 0.15552124665687855\n","Training loss per 100 training steps: 0.15140171258508903\n","Training loss per 100 training steps: 0.14760412225905536\n","Training loss per 100 training steps: 0.14304771157520255\n","Training loss per 100 training steps: 0.13999416139732382\n","Training loss per 100 training steps: 0.1369159687962021\n","Training loss per 100 training steps: 0.13335502491592735\n","Training loss per 100 training steps: 0.13070848941205368\n","Training loss per 100 training steps: 0.12824513456974354\n","Training loss per 100 training steps: 0.1260828609340932\n","Training loss per 100 training steps: 0.12419277906089192\n","Training loss per 100 training steps: 0.12176479270075856\n","Training loss per 100 training steps: 0.11956934085743623\n","Training loss per 100 training steps: 0.11754600560061293\n","Training loss epoch: 0.11754600560061293\n","Training accuracy epoch: 0.9617609902713609\n","Validating model...\n","Validation Loss: 0.20356476287563124\n","Validation Accuracy: 0.9470099559506164\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07396703213453293\n","Training loss per 100 training steps: 0.04780212255416087\n","Training loss per 100 training steps: 0.046200350349750466\n","Training loss per 100 training steps: 0.051231186845466695\n","Training loss per 100 training steps: 0.050073449932470766\n","Training loss per 100 training steps: 0.0491011640574679\n","Training loss per 100 training steps: 0.04910600688207752\n","Training loss per 100 training steps: 0.048122117984056814\n","Training loss per 100 training steps: 0.04812770951120706\n","Training loss per 100 training steps: 0.04766311005587905\n","Training loss per 100 training steps: 0.046806102446452544\n","Training loss per 100 training steps: 0.04645105607961588\n","Training loss per 100 training steps: 0.04608011078907582\n","Training loss per 100 training steps: 0.04554893390911214\n","Training loss per 100 training steps: 0.04531161376271134\n","Training loss per 100 training steps: 0.04533673139635863\n","Training loss per 100 training steps: 0.04531798701541967\n","Training loss per 100 training steps: 0.04523167400941174\n","Stopping epoch...\n","Training loss epoch: 0.04523167400941174\n","Training accuracy epoch: 0.985036207949697\n","Validating model...\n","Validation Loss: 0.2052277659622396\n","Validation Accuracy: 0.9519850151824651\n","Training epoch: 3\n","Training loss per 100 training steps: 0.014698299579322338\n","Training loss per 100 training steps: 0.034255377826105694\n","Training loss per 100 training steps: 0.03364388962665489\n","Training loss per 100 training steps: 0.03309076384833064\n","Training loss per 100 training steps: 0.0346776448797546\n","Training loss per 100 training steps: 0.03446511267647222\n","Training loss per 100 training steps: 0.03382405226611642\n","Training loss per 100 training steps: 0.03344817996721253\n","Training loss per 100 training steps: 0.03400260090119276\n","Training loss per 100 training steps: 0.033818749419039326\n","Training loss per 100 training steps: 0.03388037019619508\n","Training loss per 100 training steps: 0.03345416897459955\n","Training loss per 100 training steps: 0.032972037101759236\n","Training loss per 100 training steps: 0.032775567410793655\n","Training loss per 100 training steps: 0.03286401515463959\n","Training loss per 100 training steps: 0.03278623761301755\n","Training loss per 100 training steps: 0.03302529769090716\n","Stopping epoch...\n","Training loss epoch: 0.03302529769090716\n","Training accuracy epoch: 0.9890349102637664\n","Validating model...\n","Validation Loss: 0.21777091741368368\n","Validation Accuracy: 0.9485298458132905\n","Training epoch: 4\n","Training loss per 100 training steps: 0.027005493640899658\n","Training loss per 100 training steps: 0.024120445137308672\n","Training loss per 100 training steps: 0.027700381196539534\n","Training loss per 100 training steps: 0.027248347148320876\n","Training loss per 100 training steps: 0.025806222061923893\n","Training loss per 100 training steps: 0.026922073915132325\n","Training loss per 100 training steps: 0.026167917257378624\n","Training loss per 100 training steps: 0.025893310637870263\n","Training loss per 100 training steps: 0.025957898390069536\n","Training loss per 100 training steps: 0.026517180178935156\n","Training loss per 100 training steps: 0.02655485754984512\n","Training loss per 100 training steps: 0.026774555919419123\n","Training loss per 100 training steps: 0.028069339919946607\n","Training loss per 100 training steps: 0.028556961801322212\n","Training loss per 100 training steps: 0.02857304198241465\n","Training loss per 100 training steps: 0.028415557973522403\n","Training loss per 100 training steps: 0.028303788253920575\n","Training loss per 100 training steps: 0.028400986100386046\n","Stopping epoch...\n","Training loss epoch: 0.028400986100386046\n","Training accuracy epoch: 0.9906233112604836\n","Validating model...\n","Validation Loss: 0.23078467474355327\n","Validation Accuracy: 0.9498755129272285\n","Training epoch: 5\n","Training loss per 100 training steps: 0.006441907025873661\n","Training loss per 100 training steps: 0.019552095751981205\n","Training loss per 100 training steps: 0.01847880412966351\n","Training loss per 100 training steps: 0.01852646454048275\n","Training loss per 100 training steps: 0.01972404538247063\n","Training loss per 100 training steps: 0.02083510358741427\n","Training loss per 100 training steps: 0.021037914275593463\n","Training loss per 100 training steps: 0.021480466217108498\n","Training loss per 100 training steps: 0.021603714069852967\n","Training loss per 100 training steps: 0.021378958229830623\n","Training loss per 100 training steps: 0.02149604375502183\n","Training loss per 100 training steps: 0.02167055056137828\n","Training loss per 100 training steps: 0.021765272277408317\n","Training loss per 100 training steps: 0.021807644441266573\n","Training loss per 100 training steps: 0.022321184071899824\n","Training loss per 100 training steps: 0.022581983703443144\n","Training loss per 100 training steps: 0.022717020374919544\n","Training loss per 100 training steps: 0.022837533196971627\n","Training loss per 100 training steps: 0.02289174514323194\n","Training loss per 100 training steps: 0.022832305292415308\n","Training loss per 100 training steps: 0.022741503292938572\n","Stopping epoch...\n","Training loss epoch: 0.022741503292938572\n","Training accuracy epoch: 0.9924287999966802\n","Validating model...\n","Validation Loss: 0.21769954399629074\n","Validation Accuracy: 0.9541175158967474\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0064148069359362125\n","Training loss per 100 training steps: 0.018717732035559556\n","Training loss per 100 training steps: 0.016588761282688592\n","Training loss per 100 training steps: 0.0164113498846513\n","Training loss per 100 training steps: 0.01622028815231409\n","Training loss per 100 training steps: 0.01619477550863491\n","Training loss per 100 training steps: 0.016251149798130166\n","Training loss per 100 training steps: 0.01710344522816299\n","Training loss per 100 training steps: 0.016994679727174163\n","Training loss per 100 training steps: 0.017065205999684172\n","Training loss per 100 training steps: 0.017366369574534968\n","Training loss per 100 training steps: 0.01727904307361621\n","Training loss per 100 training steps: 0.01733774720153366\n","Training loss per 100 training steps: 0.017465094433678458\n","Training loss per 100 training steps: 0.01782026982758288\n","Training loss per 100 training steps: 0.01783348073381146\n","Training loss per 100 training steps: 0.01812834780967415\n","Training loss per 100 training steps: 0.01830459721533235\n","Training loss per 100 training steps: 0.018329322494805993\n","Training loss per 100 training steps: 0.018275999398921043\n","Training loss per 100 training steps: 0.018302934132266798\n","Training loss per 100 training steps: 0.018373389510427985\n","Stopping epoch...\n","Training loss epoch: 0.018373389510427985\n","Training accuracy epoch: 0.9938377541606969\n","Validating model...\n","Validation Loss: 0.2490437589585781\n","Validation Accuracy: 0.9519747496770182\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 210.8393093666667 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.22189991707758358\n","Validation Accuracy: 0.9438433923602303\n","Validation duration: 5.919121900000027 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 80.8%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.76      0.78     12546\n","        test       0.83      0.84      0.83      9012\n","   treatment       0.83      0.81      0.82      9297\n","\n","   micro avg       0.82      0.80      0.81     30855\n","   macro avg       0.82      0.80      0.81     30855\n","weighted avg       0.82      0.80      0.81     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 83202\n","Points in y_train after augmentation: 83202\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8458521366119385\n","Training loss per 100 training steps: 0.4292426640444463\n","Training loss per 100 training steps: 0.31897200039814955\n","Training loss per 100 training steps: 0.27051894577139635\n","Training loss per 100 training steps: 0.2460322505759628\n","Training loss per 100 training steps: 0.2281698678246515\n","Training loss per 100 training steps: 0.2151231947827607\n","Training loss per 100 training steps: 0.2042948728913545\n","Training loss per 100 training steps: 0.19351917727572493\n","Training loss per 100 training steps: 0.18548268434921328\n","Training loss per 100 training steps: 0.17792917556547141\n","Training loss per 100 training steps: 0.1715030651979426\n","Training loss per 100 training steps: 0.16512810484002918\n","Training loss per 100 training steps: 0.15998485317306277\n","Training loss per 100 training steps: 0.15537616482129496\n","Training loss per 100 training steps: 0.15147877805373028\n","Training loss per 100 training steps: 0.14723358973005624\n","Training loss per 100 training steps: 0.1435184020613118\n","Training loss per 100 training steps: 0.14023015896056978\n","Training loss per 100 training steps: 0.1371818222529277\n","Training loss per 100 training steps: 0.1344293612925832\n","Training loss per 100 training steps: 0.1315710976104146\n","Training loss per 100 training steps: 0.12901970124513634\n","Training loss per 100 training steps: 0.12634562531134833\n","Training loss per 100 training steps: 0.12374037071990344\n","Training loss per 100 training steps: 0.12185556901676929\n","Training loss per 100 training steps: 0.11964920826663751\n","Training loss epoch: 0.11964920826663751\n","Training accuracy epoch: 0.9612955454085652\n","Validating model...\n","Validation Loss: 0.16903223240046533\n","Validation Accuracy: 0.9544958916606066\n","Training epoch: 2\n","Training loss per 100 training steps: 0.012127380818128586\n","Training loss per 100 training steps: 0.044544816561190796\n","Training loss per 100 training steps: 0.044721250853209354\n","Training loss per 100 training steps: 0.04541246984324161\n","Training loss per 100 training steps: 0.04650360881118684\n","Training loss per 100 training steps: 0.0478628003229006\n","Training loss per 100 training steps: 0.04742233336673811\n","Training loss per 100 training steps: 0.046860281847345614\n","Training loss per 100 training steps: 0.0463193999286555\n","Training loss per 100 training steps: 0.046945795319410046\n","Training loss per 100 training steps: 0.046465925259430045\n","Training loss per 100 training steps: 0.04609337074155128\n","Training loss per 100 training steps: 0.046069213192480356\n","Training loss per 100 training steps: 0.04609357762196281\n","Training loss per 100 training steps: 0.04574674019788782\n","Training loss per 100 training steps: 0.04582470378603943\n","Stopping epoch...\n","Training loss epoch: 0.04582470378603943\n","Training accuracy epoch: 0.9844894038179511\n","Validating model...\n","Validation Loss: 0.16608134816799844\n","Validation Accuracy: 0.9585164589827945\n","Training epoch: 3\n","Training loss per 100 training steps: 0.019242487847805023\n","Training loss per 100 training steps: 0.03323257250087751\n","Training loss per 100 training steps: 0.0332356185514181\n","Training loss per 100 training steps: 0.033544132371407555\n","Training loss per 100 training steps: 0.033979468841260727\n","Training loss per 100 training steps: 0.03302145403645563\n","Training loss per 100 training steps: 0.032539933731869725\n","Training loss per 100 training steps: 0.0325193309878878\n","Training loss per 100 training steps: 0.032688737278241724\n","Training loss per 100 training steps: 0.03338759633822684\n","Training loss per 100 training steps: 0.03348733106415582\n","Training loss per 100 training steps: 0.03328793115489761\n","Training loss per 100 training steps: 0.03316954402928163\n","Training loss per 100 training steps: 0.03340473297713979\n","Stopping epoch...\n","Training loss epoch: 0.03340473297713979\n","Training accuracy epoch: 0.9885254208576868\n","Validating model...\n","Validation Loss: 0.2096099631691521\n","Validation Accuracy: 0.9516276636339724\n","Training epoch: 4\n","Training loss per 100 training steps: 0.024121377617120743\n","Training loss per 100 training steps: 0.028227320732779358\n","Training loss per 100 training steps: 0.02835952556421007\n","Training loss per 100 training steps: 0.0283995492328144\n","Training loss per 100 training steps: 0.03006121779657306\n","Training loss per 100 training steps: 0.03161650602036563\n","Training loss per 100 training steps: 0.031058483857222943\n","Training loss per 100 training steps: 0.030917556040200238\n","Training loss per 100 training steps: 0.030711198309477133\n","Training loss per 100 training steps: 0.030503260099781795\n","Training loss per 100 training steps: 0.029985672599365274\n","Training loss per 100 training steps: 0.029642315019348418\n","Training loss per 100 training steps: 0.029727563239109828\n","Training loss per 100 training steps: 0.029608708693768304\n","Training loss per 100 training steps: 0.029588103555870788\n","Training loss per 100 training steps: 0.029376185631601614\n","Training loss per 100 training steps: 0.02915490522559239\n","Training loss per 100 training steps: 0.02905613602981407\n","Training loss per 100 training steps: 0.028947905899048252\n","Training loss per 100 training steps: 0.029033906082243027\n","Training loss per 100 training steps: 0.029102931889160345\n","Stopping epoch...\n","Training loss epoch: 0.029102931889160345\n","Training accuracy epoch: 0.9903734111400543\n","Validating model...\n","Validation Loss: 0.23991147794022963\n","Validation Accuracy: 0.9453054117828488\n","Training epoch: 5\n","Training loss per 100 training steps: 0.043821144849061966\n","Training loss per 100 training steps: 0.02355311863472464\n","Training loss per 100 training steps: 0.024172248776054558\n","Training loss per 100 training steps: 0.02322975721324723\n","Training loss per 100 training steps: 0.02238288288123144\n","Training loss per 100 training steps: 0.02301317623755086\n","Training loss per 100 training steps: 0.022352778803155806\n","Training loss per 100 training steps: 0.02220458918654316\n","Training loss per 100 training steps: 0.022124781607000273\n","Training loss per 100 training steps: 0.023249182167458353\n","Training loss per 100 training steps: 0.0239631770957065\n","Training loss per 100 training steps: 0.02416796637900964\n","Training loss per 100 training steps: 0.024170164647521832\n","Training loss per 100 training steps: 0.02413967420351688\n","Training loss per 100 training steps: 0.023796504161622756\n","Training loss per 100 training steps: 0.023639193427372664\n","Training loss per 100 training steps: 0.023244891762636024\n","Training loss per 100 training steps: 0.023131021648364253\n","Training loss per 100 training steps: 0.02310978233929168\n","Training loss per 100 training steps: 0.023001994514160067\n","Training loss per 100 training steps: 0.022911933100944536\n","Training loss per 100 training steps: 0.022648748460460475\n","Training loss per 100 training steps: 0.02262632153713644\n","Training loss per 100 training steps: 0.022656176454223277\n","Training loss per 100 training steps: 0.022747166809250253\n","Training loss per 100 training steps: 0.02283157182505309\n","Stopping epoch...\n","Training loss epoch: 0.02283157182505309\n","Training accuracy epoch: 0.992474551309514\n","Validating model...\n","Validation Loss: 0.22804820063439282\n","Validation Accuracy: 0.9518915965993147\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00941003393381834\n","Training loss per 100 training steps: 0.015312650827068541\n","Training loss per 100 training steps: 0.014417666385578112\n","Training loss per 100 training steps: 0.013424128436706217\n","Training loss per 100 training steps: 0.013409368666539205\n","Training loss per 100 training steps: 0.01392195248824615\n","Training loss per 100 training steps: 0.013441633673537037\n","Training loss per 100 training steps: 0.013955164132204661\n","Training loss per 100 training steps: 0.013793437981721684\n","Training loss per 100 training steps: 0.014702888715594385\n","Training loss per 100 training steps: 0.014683067927997165\n","Training loss per 100 training steps: 0.014897613571516892\n","Training loss per 100 training steps: 0.014851175006777576\n","Training loss per 100 training steps: 0.015055913576341916\n","Training loss per 100 training steps: 0.01565667975868107\n","Training loss per 100 training steps: 0.016249899452984665\n","Training loss per 100 training steps: 0.016478217561885732\n","Training loss per 100 training steps: 0.016567041623335756\n","Training loss per 100 training steps: 0.016776698017192965\n","Training loss per 100 training steps: 0.0171782969615213\n","Training loss per 100 training steps: 0.017319504908936006\n","Training loss per 100 training steps: 0.01719961716095429\n","Training loss per 100 training steps: 0.017157514421209\n","Training loss per 100 training steps: 0.01715927366066626\n","Stopping epoch...\n","Training loss epoch: 0.01715927366066626\n","Training accuracy epoch: 0.9944251073581918\n","Validating model...\n","Validation Loss: 0.2551191197103494\n","Validation Accuracy: 0.9494082387705423\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0026603660080581903\n","Training loss per 100 training steps: 0.01216217818137461\n","Training loss per 100 training steps: 0.011562445000583186\n","Training loss per 100 training steps: 0.011594511332911627\n","Training loss per 100 training steps: 0.01233624820845687\n","Training loss per 100 training steps: 0.012784470186581345\n","Training loss per 100 training steps: 0.013483309709508059\n","Training loss per 100 training steps: 0.014125498007888641\n","Training loss per 100 training steps: 0.014273390907866324\n","Training loss per 100 training steps: 0.014155080420029434\n","Training loss per 100 training steps: 0.013935828186588112\n","Training loss per 100 training steps: 0.013925572900744629\n","Training loss per 100 training steps: 0.01397768176109088\n","Training loss per 100 training steps: 0.014293813398339643\n","Training loss per 100 training steps: 0.014302525598519076\n","Training loss per 100 training steps: 0.01427184468857928\n","Training loss per 100 training steps: 0.014198571375860884\n","Training loss per 100 training steps: 0.014319854331803565\n","Stopping epoch...\n","Training loss epoch: 0.014319854331803565\n","Training accuracy epoch: 0.9949729748418826\n","Validating model...\n","Validation Loss: 0.27187760702830244\n","Validation Accuracy: 0.9458915400873198\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 250.18986543333327 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.1952568782963445\n","Validation Accuracy: 0.9517450949705614\n","Validation duration: 5.924107950000082 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 84.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.85      0.84     12546\n","        test       0.83      0.86      0.84      9012\n","   treatment       0.82      0.85      0.83      9297\n","\n","   micro avg       0.83      0.85      0.84     30855\n","   macro avg       0.83      0.85      0.84     30855\n","weighted avg       0.83      0.85      0.84     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 83202\n","Points in y_train after augmentation: 83202\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9268749952316284\n","Training loss per 100 training steps: 0.43182026085877184\n","Training loss per 100 training steps: 0.3222516909315811\n","Training loss per 100 training steps: 0.2745603086222644\n","Training loss per 100 training steps: 0.2473804660494488\n","Training loss per 100 training steps: 0.22605553400254774\n","Training loss per 100 training steps: 0.212397796335861\n","Training loss per 100 training steps: 0.2001873062532953\n","Training loss per 100 training steps: 0.19094069109597103\n","Training loss per 100 training steps: 0.18286029819024935\n","Training loss per 100 training steps: 0.17658371017077243\n","Training loss per 100 training steps: 0.170592725541287\n","Training loss per 100 training steps: 0.16443054816669334\n","Training loss per 100 training steps: 0.15979806105316338\n","Training loss per 100 training steps: 0.15528224666983814\n","Training loss per 100 training steps: 0.15120691450332588\n","Training loss per 100 training steps: 0.14743721006708052\n","Training loss per 100 training steps: 0.14347382057660743\n","Training loss per 100 training steps: 0.14041371777967065\n","Training loss per 100 training steps: 0.1377284167080173\n","Training loss per 100 training steps: 0.1351049997562683\n","Training loss per 100 training steps: 0.13234709206745135\n","Training loss per 100 training steps: 0.12981283448607758\n","Training loss per 100 training steps: 0.12732870494708037\n","Training loss per 100 training steps: 0.12459510407165804\n","Training loss per 100 training steps: 0.122221854106128\n","Training loss per 100 training steps: 0.12014320112230605\n","Training loss epoch: 0.12014320112230605\n","Training accuracy epoch: 0.9608911513216405\n","Validating model...\n","Validation Loss: 0.16355466421741943\n","Validation Accuracy: 0.9530853299409627\n","Training epoch: 2\n","Training loss per 100 training steps: 0.029559221118688583\n","Training loss per 100 training steps: 0.04125229535292428\n","Training loss per 100 training steps: 0.03992257480143537\n","Training loss per 100 training steps: 0.04118827946385078\n","Training loss per 100 training steps: 0.041530482104614824\n","Training loss per 100 training steps: 0.04243196476252746\n","Training loss per 100 training steps: 0.04290615485248136\n","Training loss per 100 training steps: 0.04310789068372981\n","Training loss per 100 training steps: 0.04324898572397952\n","Training loss per 100 training steps: 0.04311525605858762\n","Training loss per 100 training steps: 0.04335146347483198\n","Training loss per 100 training steps: 0.04307880138489439\n","Stopping epoch...\n","Training loss epoch: 0.04307880138489439\n","Training accuracy epoch: 0.9852706898340332\n","Validating model...\n","Validation Loss: 0.19945386503278822\n","Validation Accuracy: 0.9515526522541774\n","Training epoch: 3\n","Training loss per 100 training steps: 0.007123628165572882\n","Training loss per 100 training steps: 0.038165360195838875\n","Training loss per 100 training steps: 0.03978886593258314\n","Training loss per 100 training steps: 0.04024504627444568\n","Training loss per 100 training steps: 0.03907830599797634\n","Training loss per 100 training steps: 0.039753777806846025\n","Training loss per 100 training steps: 0.039609750177240166\n","Training loss per 100 training steps: 0.0392300479270826\n","Training loss per 100 training steps: 0.038319655486816234\n","Training loss per 100 training steps: 0.03765111241683976\n","Training loss per 100 training steps: 0.03725876479868318\n","Training loss per 100 training steps: 0.03775198084237113\n","Training loss per 100 training steps: 0.03751503520900714\n","Training loss per 100 training steps: 0.037398289485804474\n","Training loss per 100 training steps: 0.03778554859721061\n","Training loss per 100 training steps: 0.038417260060232654\n","Training loss per 100 training steps: 0.03870355125627469\n","Training loss per 100 training steps: 0.038457203225883106\n","Training loss per 100 training steps: 0.03831967895883893\n","Training loss per 100 training steps: 0.03817314996577845\n","Training loss per 100 training steps: 0.038024566458202604\n","Training loss per 100 training steps: 0.03793703738097119\n","Training loss per 100 training steps: 0.03758379163020381\n","Training loss per 100 training steps: 0.03752681477003848\n","Training loss per 100 training steps: 0.037454213366726614\n","Training loss per 100 training steps: 0.03721654926887901\n","Training loss per 100 training steps: 0.03693579935846669\n","Training loss epoch: 0.03693579935846669\n","Training accuracy epoch: 0.988252574898213\n","Validating model...\n","Validation Loss: 0.2162990269021361\n","Validation Accuracy: 0.9494991811738676\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0038049407303333282\n","Training loss per 100 training steps: 0.024097235794962927\n","Training loss per 100 training steps: 0.020916488140344212\n","Training loss per 100 training steps: 0.021590880661710873\n","Training loss per 100 training steps: 0.021261601931644263\n","Training loss per 100 training steps: 0.021449900063209258\n","Training loss per 100 training steps: 0.022329425263065944\n","Training loss per 100 training steps: 0.0224820125975763\n","Training loss per 100 training steps: 0.02280609233494669\n","Training loss per 100 training steps: 0.022649826098000373\n","Training loss per 100 training steps: 0.022699419469919175\n","Training loss per 100 training steps: 0.023185019161783543\n","Training loss per 100 training steps: 0.02352334552047678\n","Training loss per 100 training steps: 0.023705358586181384\n","Training loss per 100 training steps: 0.023763591781476957\n","Training loss per 100 training steps: 0.023920510008164572\n","Training loss per 100 training steps: 0.024485483159202626\n","Training loss per 100 training steps: 0.024595163702240148\n","Training loss per 100 training steps: 0.024722376781540857\n","Training loss per 100 training steps: 0.024724293543082927\n","Training loss per 100 training steps: 0.02461131660818429\n","Stopping epoch...\n","Training loss epoch: 0.02461131660818429\n","Training accuracy epoch: 0.9918352241708367\n","Validating model...\n","Validation Loss: 0.22214145890691064\n","Validation Accuracy: 0.9533755253503771\n","Training epoch: 5\n","Training loss per 100 training steps: 0.013756666332483292\n","Training loss per 100 training steps: 0.01589084730776359\n","Training loss per 100 training steps: 0.016735423545397133\n","Training loss per 100 training steps: 0.016123777878876044\n","Training loss per 100 training steps: 0.015936215078786824\n","Training loss per 100 training steps: 0.01707985858372998\n","Training loss per 100 training steps: 0.01676710136350982\n","Training loss per 100 training steps: 0.016462571498391202\n","Training loss per 100 training steps: 0.016486837778335782\n","Training loss per 100 training steps: 0.016380618382441696\n","Training loss per 100 training steps: 0.016507944056508853\n","Training loss per 100 training steps: 0.0166285486506881\n","Training loss per 100 training steps: 0.016958663779598575\n","Training loss per 100 training steps: 0.01697361402412759\n","Training loss per 100 training steps: 0.01724390029664757\n","Training loss per 100 training steps: 0.01715328491252641\n","Training loss per 100 training steps: 0.017225553310454576\n","Training loss per 100 training steps: 0.017271154766544665\n","Training loss per 100 training steps: 0.01756623155480524\n","Training loss per 100 training steps: 0.017816471579026695\n","Training loss per 100 training steps: 0.017868806114739694\n","Training loss per 100 training steps: 0.018192408235401986\n","Training loss per 100 training steps: 0.018310800294719425\n","Training loss per 100 training steps: 0.01843922815616959\n","Training loss per 100 training steps: 0.018479955638833992\n","Training loss per 100 training steps: 0.018367639484557705\n","Training loss per 100 training steps: 0.01832068008693626\n","Stopping epoch...\n","Training loss epoch: 0.01832068008693626\n","Training accuracy epoch: 0.9939066275297649\n","Validating model...\n","Validation Loss: 0.24366177008910614\n","Validation Accuracy: 0.9502729569832693\n","Training epoch: 6\n","Training loss per 100 training steps: 0.002026743721216917\n","Training loss per 100 training steps: 0.014901018228340378\n","Training loss per 100 training steps: 0.01623470825577544\n","Training loss per 100 training steps: 0.014875613791911407\n","Training loss per 100 training steps: 0.015874103120437584\n","Training loss per 100 training steps: 0.01568937220702695\n","Training loss per 100 training steps: 0.01496884362415113\n","Training loss per 100 training steps: 0.014399974039925486\n","Training loss per 100 training steps: 0.014707848070114944\n","Training loss per 100 training steps: 0.015096804693345907\n","Training loss per 100 training steps: 0.015451668649267584\n","Training loss per 100 training steps: 0.01610673503390049\n","Training loss per 100 training steps: 0.0161583999655156\n","Training loss per 100 training steps: 0.016331969769932845\n","Training loss per 100 training steps: 0.016285918006993534\n","Training loss per 100 training steps: 0.016468841823433427\n","Training loss per 100 training steps: 0.01629734568065614\n","Training loss per 100 training steps: 0.016288885311435727\n","Training loss per 100 training steps: 0.016438038467910754\n","Training loss per 100 training steps: 0.016244596494217233\n","Training loss per 100 training steps: 0.01623299270815359\n","Training loss per 100 training steps: 0.016150762992233936\n","Training loss per 100 training steps: 0.015982919775496665\n","Training loss per 100 training steps: 0.016134430868508638\n","Training loss per 100 training steps: 0.01620583231223422\n","Training loss per 100 training steps: 0.016385656703923192\n","Training loss per 100 training steps: 0.0165930107271133\n","Training loss epoch: 0.0165930107271133\n","Training accuracy epoch: 0.9949387359958941\n","Validating model...\n","Validation Loss: 0.2541643865406513\n","Validation Accuracy: 0.9511636359959733\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 242.45068268333344 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.18463015678140368\n","Validation Accuracy: 0.9490625056713303\n","Validation duration: 5.924279816666725 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 83.1%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.81      0.82     12546\n","        test       0.82      0.87      0.84      9012\n","   treatment       0.83      0.83      0.83      9297\n","\n","   micro avg       0.83      0.84      0.83     30855\n","   macro avg       0.83      0.84      0.83     30855\n","weighted avg       0.83      0.84      0.83     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 83202\n","Points in y_train after augmentation: 83202\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9122546911239624\n","Training loss per 100 training steps: 0.4297207003772849\n","Training loss per 100 training steps: 0.3207764986031388\n","Training loss per 100 training steps: 0.2767387292289061\n","Training loss per 100 training steps: 0.2463653104337968\n","Training loss per 100 training steps: 0.22782602419931733\n","Training loss per 100 training steps: 0.21385956490520827\n","Training loss per 100 training steps: 0.20254334794110307\n","Training loss per 100 training steps: 0.19210862360903982\n","Training loss per 100 training steps: 0.18435953219486328\n","Training loss per 100 training steps: 0.1768413827094909\n","Training loss per 100 training steps: 0.16994311258562253\n","Training loss per 100 training steps: 0.16400096336260228\n","Training loss per 100 training steps: 0.15922075828435694\n","Training loss per 100 training steps: 0.154406571681003\n","Training loss per 100 training steps: 0.15012486713710704\n","Training loss per 100 training steps: 0.1463888667280705\n","Training loss per 100 training steps: 0.142351806485179\n","Training loss per 100 training steps: 0.13919910600047966\n","Training loss per 100 training steps: 0.13620530737800104\n","Training loss per 100 training steps: 0.13282440540877388\n","Training loss per 100 training steps: 0.130357653731529\n","Training loss per 100 training steps: 0.12767429530166974\n","Training loss per 100 training steps: 0.12490407191702642\n","Training loss per 100 training steps: 0.12240593369874866\n","Training loss per 100 training steps: 0.12056347491128035\n","Training loss per 100 training steps: 0.11836647823981451\n","Training loss epoch: 0.11836647823981451\n","Training accuracy epoch: 0.9616029082833948\n","Validating model...\n","Validation Loss: 0.17198965647681194\n","Validation Accuracy: 0.9511005215978544\n","Training epoch: 2\n","Training loss per 100 training steps: 0.055849116295576096\n","Training loss per 100 training steps: 0.04906325556780442\n","Training loss per 100 training steps: 0.044845027584971775\n","Training loss per 100 training steps: 0.045605210428036426\n","Training loss per 100 training steps: 0.04536852591840592\n","Training loss per 100 training steps: 0.04526293193252233\n","Training loss per 100 training steps: 0.04583443252380609\n","Training loss per 100 training steps: 0.0448765231289113\n","Training loss per 100 training steps: 0.04463821087633091\n","Training loss per 100 training steps: 0.04488635135333381\n","Training loss per 100 training steps: 0.04472150792473356\n","Training loss per 100 training steps: 0.04464824131123644\n","Stopping epoch...\n","Training loss epoch: 0.04464824131123644\n","Training accuracy epoch: 0.9848706110986193\n","Validating model...\n","Validation Loss: 0.18635808383779867\n","Validation Accuracy: 0.9511990079513968\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03922245278954506\n","Training loss per 100 training steps: 0.037652882115712556\n","Training loss per 100 training steps: 0.0390838353526292\n","Training loss per 100 training steps: 0.0434768675243253\n","Training loss per 100 training steps: 0.04257307565385508\n","Training loss per 100 training steps: 0.04317677275653178\n","Training loss per 100 training steps: 0.042357823650310815\n","Training loss per 100 training steps: 0.0419966854333091\n","Training loss per 100 training steps: 0.04174865381681731\n","Training loss per 100 training steps: 0.04174915167165054\n","Training loss per 100 training steps: 0.041272768684496336\n","Training loss per 100 training steps: 0.04083610972711862\n","Training loss per 100 training steps: 0.04041457580899561\n","Training loss per 100 training steps: 0.03980939785558315\n","Training loss per 100 training steps: 0.03917635540087554\n","Training loss per 100 training steps: 0.03882598404168089\n","Training loss per 100 training steps: 0.038424187769110184\n","Training loss per 100 training steps: 0.038501857579563925\n","Training loss per 100 training steps: 0.03826167900816588\n","Training loss per 100 training steps: 0.037949590010747075\n","Training loss per 100 training steps: 0.03794512301995845\n","Training loss per 100 training steps: 0.03787302721989608\n","Training loss per 100 training steps: 0.037621851847819125\n","Training loss per 100 training steps: 0.03760594379556819\n","Stopping epoch...\n","Training loss epoch: 0.03760594379556819\n","Training accuracy epoch: 0.9876632393621604\n","Validating model...\n","Validation Loss: 0.23180792894359534\n","Validation Accuracy: 0.9490377611970651\n","Training epoch: 4\n","Training loss per 100 training steps: 0.003380322828888893\n","Training loss per 100 training steps: 0.016937078772075842\n","Training loss per 100 training steps: 0.018786249560389705\n","Training loss per 100 training steps: 0.02281464522753214\n","Training loss per 100 training steps: 0.0235381135094314\n","Training loss per 100 training steps: 0.023852867504071534\n","Training loss per 100 training steps: 0.023426850609358913\n","Training loss per 100 training steps: 0.023978515153653793\n","Training loss per 100 training steps: 0.023910334952769757\n","Training loss per 100 training steps: 0.024352406049131744\n","Training loss per 100 training steps: 0.024701618989645787\n","Training loss per 100 training steps: 0.024593685127474996\n","Training loss per 100 training steps: 0.02420911459558737\n","Training loss per 100 training steps: 0.024093786059858364\n","Training loss per 100 training steps: 0.023721935308364212\n","Training loss per 100 training steps: 0.02371207121716608\n","Training loss per 100 training steps: 0.023428689634581147\n","Training loss per 100 training steps: 0.023359308060908662\n","Training loss per 100 training steps: 0.023072880161396754\n","Training loss per 100 training steps: 0.023137295493220533\n","Training loss per 100 training steps: 0.023483039771212147\n","Training loss per 100 training steps: 0.02350168975419143\n","Training loss per 100 training steps: 0.023487938586389222\n","Training loss per 100 training steps: 0.02357900234136149\n","Training loss per 100 training steps: 0.023679111069575962\n","Stopping epoch...\n","Training loss epoch: 0.023679111069575962\n","Training accuracy epoch: 0.9921772547773825\n","Validating model...\n","Validation Loss: 0.24568841209659328\n","Validation Accuracy: 0.9502264152507179\n","Training epoch: 5\n","Training loss per 100 training steps: 0.021230408921837807\n","Training loss per 100 training steps: 0.01750520582190982\n","Training loss per 100 training steps: 0.019449892523351\n","Training loss per 100 training steps: 0.020396267145522482\n","Training loss per 100 training steps: 0.020528988963506297\n","Training loss per 100 training steps: 0.020449046309625622\n","Training loss per 100 training steps: 0.02035185793618487\n","Training loss per 100 training steps: 0.0205547718853343\n","Stopping epoch...\n","Training loss epoch: 0.0205547718853343\n","Training accuracy epoch: 0.9921537976360691\n","Validating model...\n","Validation Loss: 0.25246323480621563\n","Validation Accuracy: 0.9486352715640851\n","Training epoch: 6\n","Training loss per 100 training steps: 0.002908180234953761\n","Training loss per 100 training steps: 0.01615888823404687\n","Training loss per 100 training steps: 0.01848412752302076\n","Training loss per 100 training steps: 0.01823981821500662\n","Training loss per 100 training steps: 0.0179865858820238\n","Training loss per 100 training steps: 0.018784863772946588\n","Training loss per 100 training steps: 0.018293562727043182\n","Training loss per 100 training steps: 0.017989099327517678\n","Training loss per 100 training steps: 0.01759830984181885\n","Training loss per 100 training steps: 0.017535601964381396\n","Training loss per 100 training steps: 0.01748961627278798\n","Training loss per 100 training steps: 0.017379637749347122\n","Training loss per 100 training steps: 0.017030273099080173\n","Training loss per 100 training steps: 0.016738387902374117\n","Training loss per 100 training steps: 0.01704310560522938\n","Training loss per 100 training steps: 0.01762884446589396\n","Training loss per 100 training steps: 0.017737975292271214\n","Training loss per 100 training steps: 0.017805275984567267\n","Training loss per 100 training steps: 0.017830667608909605\n","Training loss per 100 training steps: 0.017969412762764304\n","Training loss per 100 training steps: 0.017983092112989835\n","Training loss per 100 training steps: 0.018237475306349765\n","Training loss per 100 training steps: 0.018347497203852557\n","Training loss per 100 training steps: 0.01841315639819784\n","Training loss per 100 training steps: 0.018622050136223985\n","Training loss per 100 training steps: 0.018570749340920574\n","Training loss per 100 training steps: 0.01860375299429594\n","Training loss epoch: 0.01860375299429594\n","Training accuracy epoch: 0.9942240884965532\n","Validating model...\n","Validation Loss: 0.275572602008167\n","Validation Accuracy: 0.9453508557519502\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 210.57982121666672 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n"]}]},{"cell_type":"code","source":["number_of_training_models = 4\n","target_augmented_percentage = 5\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d287ac473a614d0c98b2a6af58061caf","ba491358174843dda5832bb62c0057d0","188f5f35c27d40b9a541f6e54b8801dd","7dafb9bead6148ccb7f8da375e7915b5","12edc4b151f64e77ac4e3e25f5dfe8fc","84d1aafed0e645d39baa87140cea3c68","444d9e7e82fa41fb831e55975cf89ca5","a4ad4d8f741f4a368cf65870dc82c87c","311cf0e0a376447480e3cd95f62c887b","740a675c7b004462bb3e0c3a381dbaec","d4d9dcbc623248d4b152f42f16996e55"]},"id":"jHSzi_tSerw9","executionInfo":{"status":"ok","timestamp":1667869150289,"user_tz":240,"elapsed":13490775,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"}},"outputId":"f375b657-77f7-4724-bfa9-2e2ef45f936d"},"id":"jHSzi_tSerw9","execution_count":8,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 500% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d287ac473a614d0c98b2a6af58061caf","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 83202\n","Points in y_train after augmentation: 83202\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7219198942184448\n","Training loss per 100 training steps: 0.4066252974000308\n","Training loss per 100 training steps: 0.3133605293818374\n","Training loss per 100 training steps: 0.26979384261904366\n","Training loss per 100 training steps: 0.2399116901592572\n","Training loss per 100 training steps: 0.22149838354743406\n","Training loss per 100 training steps: 0.20715389498036832\n","Training loss per 100 training steps: 0.19632799257809952\n","Training loss per 100 training steps: 0.18722871501003385\n","Training loss per 100 training steps: 0.17936239462474013\n","Training loss per 100 training steps: 0.1722648038261837\n","Training loss per 100 training steps: 0.1665729264932584\n","Training loss per 100 training steps: 0.16113801368610697\n","Training loss per 100 training steps: 0.15659583647442635\n","Training loss per 100 training steps: 0.1524230771838321\n","Training loss per 100 training steps: 0.14794550103561668\n","Training loss per 100 training steps: 0.14448273459043376\n","Training loss per 100 training steps: 0.14086254768901402\n","Training loss per 100 training steps: 0.13727735284134654\n","Training loss per 100 training steps: 0.13450148674085743\n","Training loss per 100 training steps: 0.13148409569089575\n","Training loss per 100 training steps: 0.12937125064891855\n","Training loss per 100 training steps: 0.12673386828068378\n","Training loss per 100 training steps: 0.12447667937350987\n","Training loss per 100 training steps: 0.12199999751392807\n","Training loss per 100 training steps: 0.11967483511632505\n","Training loss per 100 training steps: 0.11775116667080554\n","Training loss epoch: 0.11775116667080554\n","Training accuracy epoch: 0.9618048142553905\n","Validating model...\n","Validation Loss: 0.15358431235729875\n","Validation Accuracy: 0.9570310202661342\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07483367621898651\n","Training loss per 100 training steps: 0.042346586211639836\n","Training loss per 100 training steps: 0.04299125027210354\n","Training loss per 100 training steps: 0.04314872545330937\n","Training loss per 100 training steps: 0.04430012720517415\n","Training loss per 100 training steps: 0.04394668536218898\n","Training loss per 100 training steps: 0.04448039950117215\n","Training loss per 100 training steps: 0.045439283298919726\n","Training loss per 100 training steps: 0.04537353796879185\n","Training loss per 100 training steps: 0.04529253377842218\n","Training loss per 100 training steps: 0.04430335214336893\n","Training loss per 100 training steps: 0.044592670365583516\n","Training loss per 100 training steps: 0.044809327061368705\n","Training loss per 100 training steps: 0.04526787861917872\n","Training loss per 100 training steps: 0.045073005528259706\n","Training loss per 100 training steps: 0.04532334552282067\n","Training loss per 100 training steps: 0.04539892652811079\n","Training loss per 100 training steps: 0.045170605704360815\n","Stopping epoch...\n","Training loss epoch: 0.045170605704360815\n","Training accuracy epoch: 0.9848723268036021\n","Validating model...\n","Validation Loss: 0.18801670174368404\n","Validation Accuracy: 0.9527162212945889\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03949041664600372\n","Training loss per 100 training steps: 0.03193631864586236\n","Training loss per 100 training steps: 0.03082514816688939\n","Training loss per 100 training steps: 0.029031843133038682\n","Training loss per 100 training steps: 0.02948936484806342\n","Training loss per 100 training steps: 0.03140351223223053\n","Training loss per 100 training steps: 0.03179018690460788\n","Training loss per 100 training steps: 0.032139311393639194\n","Training loss per 100 training steps: 0.03226715377249991\n","Training loss per 100 training steps: 0.03199977292997099\n","Training loss per 100 training steps: 0.03170581223765531\n","Training loss per 100 training steps: 0.03154336557606004\n","Training loss per 100 training steps: 0.03157921407765691\n","Training loss per 100 training steps: 0.0320030865656766\n","Training loss per 100 training steps: 0.03224384867294368\n","Training loss per 100 training steps: 0.03216242528795702\n","Training loss per 100 training steps: 0.03218714114066811\n","Training loss per 100 training steps: 0.03211962033475452\n","Stopping epoch...\n","Training loss epoch: 0.03211962033475452\n","Training accuracy epoch: 0.9892497704266133\n","Validating model...\n","Validation Loss: 0.2040729235083639\n","Validation Accuracy: 0.9504647570114839\n","Training epoch: 4\n","Training loss per 100 training steps: 0.019765863195061684\n","Training loss per 100 training steps: 0.021958238555874567\n","Training loss per 100 training steps: 0.02261418588482659\n","Training loss per 100 training steps: 0.02518474785038626\n","Training loss per 100 training steps: 0.02562792438629346\n","Training loss per 100 training steps: 0.02547642270378683\n","Training loss per 100 training steps: 0.025311553572709772\n","Training loss per 100 training steps: 0.02529662974953011\n","Training loss per 100 training steps: 0.025689643167933627\n","Training loss per 100 training steps: 0.02629715891903293\n","Training loss per 100 training steps: 0.026442005433240805\n","Training loss per 100 training steps: 0.026444954399635286\n","Training loss per 100 training steps: 0.02673391254360343\n","Training loss per 100 training steps: 0.02685183207131314\n","Training loss per 100 training steps: 0.026732597953989252\n","Training loss per 100 training steps: 0.02674880293941716\n","Training loss per 100 training steps: 0.026459323625764673\n","Training loss per 100 training steps: 0.026578796630212516\n","Training loss per 100 training steps: 0.02637588225322145\n","Training loss per 100 training steps: 0.026129794661871802\n","Training loss per 100 training steps: 0.02605000677510867\n","Training loss per 100 training steps: 0.02599264751515373\n","Training loss per 100 training steps: 0.02600796088249021\n","Training loss per 100 training steps: 0.02574638355376779\n","Training loss per 100 training steps: 0.025621004405486043\n","Training loss per 100 training steps: 0.02586456272726283\n","Training loss per 100 training steps: 0.025839093469143017\n","Training loss epoch: 0.025839093469143017\n","Training accuracy epoch: 0.9918585334241772\n","Validating model...\n","Validation Loss: 0.2668381386085764\n","Validation Accuracy: 0.9449691815634004\n","Training epoch: 5\n","Training loss per 100 training steps: 0.014256703667342663\n","Training loss per 100 training steps: 0.02012044739780376\n","Training loss per 100 training steps: 0.019011345557609007\n","Training loss per 100 training steps: 0.01838324534218678\n","Training loss per 100 training steps: 0.01888990876810077\n","Training loss per 100 training steps: 0.018415002121186692\n","Training loss per 100 training steps: 0.018155609029337466\n","Training loss per 100 training steps: 0.017846202471169952\n","Training loss per 100 training steps: 0.01789446184283748\n","Training loss per 100 training steps: 0.01799168740916009\n","Training loss per 100 training steps: 0.018375721692408135\n","Training loss per 100 training steps: 0.0186042105217065\n","Training loss per 100 training steps: 0.01911094455473198\n","Training loss per 100 training steps: 0.01902115177518855\n","Training loss per 100 training steps: 0.019038326656469127\n","Training loss per 100 training steps: 0.019220912026795656\n","Training loss per 100 training steps: 0.019278300733887664\n","Training loss per 100 training steps: 0.019197904537429842\n","Training loss per 100 training steps: 0.01927533925512947\n","Training loss per 100 training steps: 0.01972500979862086\n","Training loss per 100 training steps: 0.019661142517551793\n","Training loss per 100 training steps: 0.01969957347510851\n","Training loss per 100 training steps: 0.019635973227087527\n","Training loss per 100 training steps: 0.019664591878725123\n","Stopping epoch...\n","Training loss epoch: 0.019664591878725123\n","Training accuracy epoch: 0.9935773683892308\n","Validating model...\n","Validation Loss: 0.22536731687338127\n","Validation Accuracy: 0.9510571293603606\n","Training epoch: 6\n","Training loss per 100 training steps: 0.004471274092793465\n","Training loss per 100 training steps: 0.015881801766947392\n","Training loss per 100 training steps: 0.018799661751952374\n","Training loss per 100 training steps: 0.02013131895855199\n","Training loss per 100 training steps: 0.018167490596845838\n","Training loss per 100 training steps: 0.017513074557191904\n","Training loss per 100 training steps: 0.0171275802826185\n","Training loss per 100 training steps: 0.01696363554672257\n","Training loss per 100 training steps: 0.01684153440416257\n","Training loss per 100 training steps: 0.01638837140364899\n","Training loss per 100 training steps: 0.016402686726405182\n","Training loss per 100 training steps: 0.016418369035118112\n","Training loss per 100 training steps: 0.016133020181647174\n","Training loss per 100 training steps: 0.016081853264932566\n","Training loss per 100 training steps: 0.015673244044846615\n","Training loss per 100 training steps: 0.015649608587814362\n","Training loss per 100 training steps: 0.01579028018035834\n","Training loss per 100 training steps: 0.015544537975701139\n","Training loss per 100 training steps: 0.01553008603795353\n","Training loss per 100 training steps: 0.015458199343425337\n","Training loss per 100 training steps: 0.015718555218978914\n","Training loss per 100 training steps: 0.015921259101926072\n","Training loss per 100 training steps: 0.015976755017944034\n","Training loss per 100 training steps: 0.01611941082169626\n","Training loss per 100 training steps: 0.016330518292695453\n","Training loss per 100 training steps: 0.01623371072863953\n","Training loss per 100 training steps: 0.016304363810797907\n","Training loss epoch: 0.016304363810797907\n","Training accuracy epoch: 0.9949638828690881\n","Validating model...\n","Validation Loss: 0.27608633113952424\n","Validation Accuracy: 0.9481296863954781\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 246.47825359999996 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.18386022620877526\n","Validation Accuracy: 0.9499132484447541\n","Validation duration: 6.07100856666669 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 82.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.84      0.83      0.83     12546\n","        test       0.83      0.81      0.82      9012\n","   treatment       0.81      0.83      0.82      9297\n","\n","   micro avg       0.83      0.82      0.83     30855\n","   macro avg       0.83      0.82      0.83     30855\n","weighted avg       0.83      0.82      0.83     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 83202\n","Points in y_train after augmentation: 83202\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8737760782241821\n","Training loss per 100 training steps: 0.3927039317417853\n","Training loss per 100 training steps: 0.3028591586953372\n","Training loss per 100 training steps: 0.26203116301781315\n","Training loss per 100 training steps: 0.2348119091344742\n","Training loss per 100 training steps: 0.2154063104638856\n","Training loss per 100 training steps: 0.20315261006342888\n","Training loss per 100 training steps: 0.19359875527528062\n","Training loss per 100 training steps: 0.18612325620534045\n","Training loss per 100 training steps: 0.17885076615765078\n","Training loss per 100 training steps: 0.17235605096580325\n","Training loss per 100 training steps: 0.16660034943280655\n","Training loss per 100 training steps: 0.16106718218575955\n","Training loss per 100 training steps: 0.15623274322264155\n","Training loss per 100 training steps: 0.15099136621460615\n","Training loss per 100 training steps: 0.14719250710087914\n","Training loss per 100 training steps: 0.14348410556400004\n","Training loss per 100 training steps: 0.14039325443885428\n","Training loss per 100 training steps: 0.13731827719089498\n","Training loss per 100 training steps: 0.13416774199466205\n","Training loss per 100 training steps: 0.1315601232390886\n","Training loss per 100 training steps: 0.12871711436408204\n","Training loss per 100 training steps: 0.1262264539858327\n","Training loss per 100 training steps: 0.1243771036675217\n","Training loss per 100 training steps: 0.12217035120692894\n","Training loss per 100 training steps: 0.11993685942861895\n","Training loss per 100 training steps: 0.11796093030225074\n","Training loss epoch: 0.11796093030225074\n","Training accuracy epoch: 0.9616710867511838\n","Validating model...\n","Validation Loss: 0.17268516236988754\n","Validation Accuracy: 0.9524085214630377\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07279539108276367\n","Training loss per 100 training steps: 0.04474602489372586\n","Training loss per 100 training steps: 0.042947959815110286\n","Training loss per 100 training steps: 0.044067885981953124\n","Training loss per 100 training steps: 0.04622655115241273\n","Training loss per 100 training steps: 0.0464769404115687\n","Training loss per 100 training steps: 0.04724231319340835\n","Training loss per 100 training steps: 0.047901646560921565\n","Training loss per 100 training steps: 0.04813421973853969\n","Training loss per 100 training steps: 0.04805234011126213\n","Training loss per 100 training steps: 0.04756615464561633\n","Training loss per 100 training steps: 0.04703946301073249\n","Training loss per 100 training steps: 0.046674357298149\n","Training loss per 100 training steps: 0.04647220299936413\n","Training loss per 100 training steps: 0.04600627333036146\n","Training loss per 100 training steps: 0.045649567078848645\n","Training loss per 100 training steps: 0.04541413452337233\n","Training loss per 100 training steps: 0.04572989639956428\n","Training loss per 100 training steps: 0.04543717142165034\n","Training loss per 100 training steps: 0.04549073643048148\n","Stopping epoch...\n","Training loss epoch: 0.04549073643048148\n","Training accuracy epoch: 0.9847462096512124\n","Validating model...\n","Validation Loss: 0.22089282137889102\n","Validation Accuracy: 0.951325137596835\n","Training epoch: 3\n","Training loss per 100 training steps: 0.018616601824760437\n","Training loss per 100 training steps: 0.031212412945852423\n","Training loss per 100 training steps: 0.031335242837435794\n","Training loss per 100 training steps: 0.03105952075305101\n","Training loss per 100 training steps: 0.02981424139071711\n","Training loss per 100 training steps: 0.029915596123556133\n","Training loss per 100 training steps: 0.03044544207493925\n","Training loss per 100 training steps: 0.030291162546908088\n","Training loss per 100 training steps: 0.0301195421023149\n","Training loss per 100 training steps: 0.02996567953911586\n","Training loss per 100 training steps: 0.030422448154855668\n","Training loss per 100 training steps: 0.03037900268523146\n","Training loss per 100 training steps: 0.03089713153962843\n","Training loss per 100 training steps: 0.0316044066051561\n","Training loss per 100 training steps: 0.03167867817886727\n","Training loss per 100 training steps: 0.03164166498257295\n","Training loss per 100 training steps: 0.031592785365692516\n","Training loss per 100 training steps: 0.03164260092610657\n","Stopping epoch...\n","Training loss epoch: 0.03164260092610657\n","Training accuracy epoch: 0.9896157969224384\n","Validating model...\n","Validation Loss: 0.21109143888892293\n","Validation Accuracy: 0.9518215096490908\n","Training epoch: 4\n","Training loss per 100 training steps: 0.007686088792979717\n","Training loss per 100 training steps: 0.02354700939895788\n","Training loss per 100 training steps: 0.022024128888386178\n","Training loss per 100 training steps: 0.02311566128531638\n","Training loss per 100 training steps: 0.023224280399567636\n","Training loss per 100 training steps: 0.023095740033257865\n","Training loss per 100 training steps: 0.023406885725584737\n","Training loss per 100 training steps: 0.023592838409775933\n","Training loss per 100 training steps: 0.023237040060378737\n","Training loss per 100 training steps: 0.02311662646310536\n","Training loss per 100 training steps: 0.02295016240294591\n","Training loss per 100 training steps: 0.02297011632326361\n","Training loss per 100 training steps: 0.023343038775370327\n","Training loss per 100 training steps: 0.02333678648095552\n","Training loss per 100 training steps: 0.023381507473543745\n","Training loss per 100 training steps: 0.02326181915049335\n","Training loss per 100 training steps: 0.02325318870799986\n","Stopping epoch...\n","Training loss epoch: 0.02325318870799986\n","Training accuracy epoch: 0.9920646710846159\n","Validating model...\n","Validation Loss: 0.2561841375109824\n","Validation Accuracy: 0.9518428854860914\n","Training epoch: 5\n","Training loss per 100 training steps: 0.005014381837099791\n","Training loss per 100 training steps: 0.023780004141534136\n","Training loss per 100 training steps: 0.025788286057664592\n","Training loss per 100 training steps: 0.02575275550640507\n","Training loss per 100 training steps: 0.025869771479216735\n","Training loss per 100 training steps: 0.024655936360791393\n","Training loss per 100 training steps: 0.02411134138743249\n","Training loss per 100 training steps: 0.024049799047390893\n","Training loss per 100 training steps: 0.024258953969457365\n","Training loss per 100 training steps: 0.0241963434386541\n","Training loss per 100 training steps: 0.02407314016510589\n","Stopping epoch...\n","Training loss epoch: 0.02407314016510589\n","Training accuracy epoch: 0.9915998413960916\n","Validating model...\n","Validation Loss: 0.23237821002575484\n","Validation Accuracy: 0.9492072251819829\n","Training epoch: 6\n","Training loss per 100 training steps: 0.01963338628411293\n","Training loss per 100 training steps: 0.016200041664662854\n","Training loss per 100 training steps: 0.018406524739937105\n","Training loss per 100 training steps: 0.018247766217678645\n","Training loss per 100 training steps: 0.018208103582853487\n","Training loss per 100 training steps: 0.019674354570533452\n","Training loss per 100 training steps: 0.019689894470623685\n","Training loss per 100 training steps: 0.019266319457637862\n","Training loss per 100 training steps: 0.019557901797024067\n","Training loss per 100 training steps: 0.019444613708290412\n","Training loss per 100 training steps: 0.01941882878828391\n","Training loss per 100 training steps: 0.0201485706607189\n","Training loss per 100 training steps: 0.02034646664262124\n","Training loss per 100 training steps: 0.020517801074360353\n","Training loss per 100 training steps: 0.020932620392973868\n","Training loss per 100 training steps: 0.020945589588620767\n","Training loss per 100 training steps: 0.020857806196602803\n","Training loss per 100 training steps: 0.020758953871438005\n","Training loss per 100 training steps: 0.02064341436868271\n","Training loss per 100 training steps: 0.020519526919671776\n","Training loss per 100 training steps: 0.02050342753249186\n","Training loss per 100 training steps: 0.02056016471755965\n","Training loss per 100 training steps: 0.020410809136112273\n","Training loss per 100 training steps: 0.020653279635390737\n","Training loss per 100 training steps: 0.02068660305512583\n","Training loss per 100 training steps: 0.020615921108721395\n","Training loss per 100 training steps: 0.020585096806987734\n","Training loss epoch: 0.020585096806987734\n","Training accuracy epoch: 0.9935511221834111\n","Validating model...\n","Validation Loss: 0.24530920205190293\n","Validation Accuracy: 0.9511880381832453\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 208.66096513333335 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.18355331563226948\n","Validation Accuracy: 0.9497228335946202\n","Validation duration: 6.084391650000058 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 81.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.78      0.84      0.81     12546\n","        test       0.86      0.85      0.86      9012\n","   treatment       0.77      0.81      0.79      9297\n","\n","   micro avg       0.80      0.83      0.82     30855\n","   macro avg       0.81      0.83      0.82     30855\n","weighted avg       0.80      0.83      0.82     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 83202\n","Points in y_train after augmentation: 83202\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.083921194076538\n","Training loss per 100 training steps: 0.42465382681624725\n","Training loss per 100 training steps: 0.3201203492298648\n","Training loss per 100 training steps: 0.2703772608029882\n","Training loss per 100 training steps: 0.24744248769229785\n","Training loss per 100 training steps: 0.22854347083115292\n","Training loss per 100 training steps: 0.21110125993085582\n","Training loss per 100 training steps: 0.20029034357406358\n","Training loss per 100 training steps: 0.19201573331639188\n","Training loss per 100 training steps: 0.18384592006237274\n","Training loss per 100 training steps: 0.17655791631238266\n","Training loss per 100 training steps: 0.1699876829687435\n","Training loss per 100 training steps: 0.16447798063285296\n","Training loss per 100 training steps: 0.15956229957494938\n","Training loss per 100 training steps: 0.15510791760844728\n","Training loss per 100 training steps: 0.15047909059238526\n","Training loss per 100 training steps: 0.14632363865462636\n","Training loss per 100 training steps: 0.1428941594034889\n","Training loss per 100 training steps: 0.1398195608982869\n","Training loss per 100 training steps: 0.13709224865618488\n","Training loss per 100 training steps: 0.13409005278495253\n","Training loss per 100 training steps: 0.13133989733602605\n","Training loss per 100 training steps: 0.12893684307280007\n","Training loss per 100 training steps: 0.12673283292054288\n","Training loss per 100 training steps: 0.12461387775163447\n","Training loss per 100 training steps: 0.12227306769202288\n","Training loss per 100 training steps: 0.12020424704739852\n","Training loss epoch: 0.12020424704739852\n","Training accuracy epoch: 0.9610010737346388\n","Validating model...\n","Validation Loss: 0.16704413647969046\n","Validation Accuracy: 0.9526336788254205\n","Training epoch: 2\n","Training loss per 100 training steps: 0.030701730400323868\n","Training loss per 100 training steps: 0.04536353448166115\n","Training loss per 100 training steps: 0.04578213009228049\n","Training loss per 100 training steps: 0.04775009291212498\n","Training loss per 100 training steps: 0.048477717340248\n","Training loss per 100 training steps: 0.0485311534702815\n","Training loss per 100 training steps: 0.04904315137372549\n","Training loss per 100 training steps: 0.04942896818049975\n","Training loss per 100 training steps: 0.04956795314365251\n","Training loss per 100 training steps: 0.04892554803085736\n","Training loss per 100 training steps: 0.048798149604197746\n","Training loss per 100 training steps: 0.04818539065287722\n","Training loss per 100 training steps: 0.04769878433555904\n","Training loss per 100 training steps: 0.047515628200280643\n","Training loss per 100 training steps: 0.04754425971276877\n","Training loss per 100 training steps: 0.047046230884881905\n","Training loss per 100 training steps: 0.047121556187083455\n","Training loss per 100 training steps: 0.04662101145963492\n","Training loss per 100 training steps: 0.04649848735483797\n","Training loss per 100 training steps: 0.046306043296835846\n","Training loss per 100 training steps: 0.045799420986288246\n","Training loss per 100 training steps: 0.04541209088226179\n","Training loss per 100 training steps: 0.04562977178810145\n","Training loss per 100 training steps: 0.0453973356919725\n","Training loss per 100 training steps: 0.04511009819122161\n","Training loss per 100 training steps: 0.044995625378800086\n","Training loss per 100 training steps: 0.04496559284048091\n","Training loss epoch: 0.04496559284048091\n","Training accuracy epoch: 0.9856356967969914\n","Validating model...\n","Validation Loss: 0.20402914900090788\n","Validation Accuracy: 0.9480675963960794\n","Training epoch: 3\n","Training loss per 100 training steps: 0.016397293657064438\n","Training loss per 100 training steps: 0.02775556610385417\n","Training loss per 100 training steps: 0.026167362164451154\n","Training loss per 100 training steps: 0.029067239970466945\n","Training loss per 100 training steps: 0.02897045536528799\n","Training loss per 100 training steps: 0.029506250196777863\n","Training loss per 100 training steps: 0.03006016608783216\n","Training loss per 100 training steps: 0.030622657450226888\n","Training loss per 100 training steps: 0.030637909062078847\n","Training loss per 100 training steps: 0.030033026168641782\n","Training loss per 100 training steps: 0.02963142502763598\n","Training loss per 100 training steps: 0.029276520753749643\n","Training loss per 100 training steps: 0.02898141815227074\n","Training loss per 100 training steps: 0.029086861217882683\n","Training loss per 100 training steps: 0.029304129583810953\n","Training loss per 100 training steps: 0.029700890846496485\n","Training loss per 100 training steps: 0.029506250364088722\n","Training loss per 100 training steps: 0.029779014279663472\n","Training loss per 100 training steps: 0.029575782459395225\n","Training loss per 100 training steps: 0.02938819811467536\n","Training loss per 100 training steps: 0.029576728816669173\n","Training loss per 100 training steps: 0.029449544301311283\n","Training loss per 100 training steps: 0.02982860422704935\n","Training loss per 100 training steps: 0.029844783753740913\n","Training loss per 100 training steps: 0.029705022646735628\n","Training loss per 100 training steps: 0.029681763798808356\n","Training loss per 100 training steps: 0.02955193066698639\n","Stopping epoch...\n","Training loss epoch: 0.02955193066698639\n","Training accuracy epoch: 0.9902498022973871\n","Validating model...\n","Validation Loss: 0.20824189605070398\n","Validation Accuracy: 0.9528951454281575\n","Training epoch: 4\n","Training loss per 100 training steps: 0.008679788559675217\n","Training loss per 100 training steps: 0.018265708056877893\n","Training loss per 100 training steps: 0.01629920009785999\n","Training loss per 100 training steps: 0.01622957705747896\n","Training loss per 100 training steps: 0.016146576220310176\n","Training loss per 100 training steps: 0.01642211201970657\n","Training loss per 100 training steps: 0.016966981143197092\n","Training loss per 100 training steps: 0.017259141914519917\n","Training loss per 100 training steps: 0.01805524804327665\n","Training loss per 100 training steps: 0.018491754181978688\n","Training loss per 100 training steps: 0.018724059218891545\n","Training loss per 100 training steps: 0.018891290012496665\n","Training loss per 100 training steps: 0.019010318628319235\n","Training loss per 100 training steps: 0.018877972398442914\n","Training loss per 100 training steps: 0.018893743732116178\n","Training loss per 100 training steps: 0.01939413418356133\n","Training loss per 100 training steps: 0.020195700071006316\n","Training loss per 100 training steps: 0.02027087958435419\n","Training loss per 100 training steps: 0.020273051589376024\n","Training loss per 100 training steps: 0.0205844074373108\n","Training loss per 100 training steps: 0.02055399607794745\n","Training loss per 100 training steps: 0.02052170635997382\n","Training loss per 100 training steps: 0.02062409726831121\n","Training loss per 100 training steps: 0.020576201057828952\n","Stopping epoch...\n","Training loss epoch: 0.020576201057828952\n","Training accuracy epoch: 0.9931184189964759\n","Validating model...\n","Validation Loss: 0.22400981138835285\n","Validation Accuracy: 0.9508933593391358\n","Training epoch: 5\n","Training loss per 100 training steps: 0.015026474371552467\n","Training loss per 100 training steps: 0.01466614623164463\n","Training loss per 100 training steps: 0.015879507879993014\n","Training loss per 100 training steps: 0.016370937275194387\n","Training loss per 100 training steps: 0.01636966288367291\n","Training loss per 100 training steps: 0.017416977516455417\n","Training loss per 100 training steps: 0.017529385745342893\n","Training loss per 100 training steps: 0.017527838923744845\n","Training loss per 100 training steps: 0.0169388715244775\n","Training loss per 100 training steps: 0.01735530772095765\n","Training loss per 100 training steps: 0.01763584787768268\n","Training loss per 100 training steps: 0.018270416782932487\n","Training loss per 100 training steps: 0.01820706882772674\n","Training loss per 100 training steps: 0.01792806640741534\n","Training loss per 100 training steps: 0.01771281968301071\n","Training loss per 100 training steps: 0.017354718206663164\n","Training loss per 100 training steps: 0.01744385351817956\n","Training loss per 100 training steps: 0.017303938762452356\n","Training loss per 100 training steps: 0.017413911718732574\n","Training loss per 100 training steps: 0.017283117028154375\n","Stopping epoch...\n","Training loss epoch: 0.017283117028154375\n","Training accuracy epoch: 0.9942887928668098\n","Validating model...\n","Validation Loss: 0.266788668253205\n","Validation Accuracy: 0.9479083383475368\n","Training epoch: 6\n","Training loss per 100 training steps: 0.009620352648198605\n","Training loss per 100 training steps: 0.013983551412820816\n","Training loss per 100 training steps: 0.013386704689366697\n","Training loss per 100 training steps: 0.014492302578394348\n","Training loss per 100 training steps: 0.015602367821174495\n","Training loss per 100 training steps: 0.014780566736415843\n","Training loss per 100 training steps: 0.014999385554966797\n","Training loss per 100 training steps: 0.015417819613477577\n","Training loss per 100 training steps: 0.015471220446278756\n","Training loss per 100 training steps: 0.014828253074226251\n","Training loss per 100 training steps: 0.014828111508296087\n","Training loss per 100 training steps: 0.015130830102686966\n","Training loss per 100 training steps: 0.014947226857726282\n","Training loss per 100 training steps: 0.01475166647014633\n","Training loss per 100 training steps: 0.01517243989621185\n","Training loss per 100 training steps: 0.015268346471332345\n","Training loss per 100 training steps: 0.015336364760729432\n","Training loss per 100 training steps: 0.015856083932603782\n","Training loss per 100 training steps: 0.015934949394244443\n","Training loss per 100 training steps: 0.015898802765986618\n","Training loss per 100 training steps: 0.016322762419619812\n","Training loss per 100 training steps: 0.016504482743379338\n","Training loss per 100 training steps: 0.01661081759050102\n","Training loss per 100 training steps: 0.016592861597451988\n","Training loss per 100 training steps: 0.01649573691548111\n","Training loss per 100 training steps: 0.016615393633376527\n","Stopping epoch...\n","Training loss epoch: 0.016615393633376527\n","Training accuracy epoch: 0.9944351077412402\n","Validating model...\n","Validation Loss: 0.2659052722639852\n","Validation Accuracy: 0.9457916731366147\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 264.00111701666685 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.17421695352337943\n","Validation Accuracy: 0.9500858065724648\n","Validation duration: 6.059034750000137 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 82.8%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.83      0.82     12546\n","        test       0.82      0.86      0.84      9012\n","   treatment       0.81      0.85      0.83      9297\n","\n","   micro avg       0.81      0.85      0.83     30855\n","   macro avg       0.81      0.85      0.83     30855\n","weighted avg       0.81      0.85      0.83     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 83202\n","Points in y_train after augmentation: 83202\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.184457302093506\n","Training loss per 100 training steps: 0.42240308335807064\n","Training loss per 100 training steps: 0.3160239003265082\n","Training loss per 100 training steps: 0.27171268764623374\n","Training loss per 100 training steps: 0.24384321753595237\n","Training loss per 100 training steps: 0.22381627858577374\n","Training loss per 100 training steps: 0.21060620022072968\n","Training loss per 100 training steps: 0.19877146579027602\n","Training loss per 100 training steps: 0.1884053521086177\n","Training loss per 100 training steps: 0.18106846250883085\n","Training loss per 100 training steps: 0.17361030801125876\n","Training loss per 100 training steps: 0.16769127415782425\n","Training loss per 100 training steps: 0.16312876905932663\n","Training loss per 100 training steps: 0.15918067475490208\n","Training loss per 100 training steps: 0.1550212802736356\n","Training loss per 100 training steps: 0.15107925980786813\n","Training loss per 100 training steps: 0.14746970199118326\n","Training loss per 100 training steps: 0.1438473534087559\n","Training loss per 100 training steps: 0.1396929658142677\n","Training loss per 100 training steps: 0.1363147939739064\n","Training loss per 100 training steps: 0.1335888758528864\n","Training loss per 100 training steps: 0.13095843649581465\n","Training loss per 100 training steps: 0.1285978069428231\n","Training loss per 100 training steps: 0.1261762658539659\n","Training loss per 100 training steps: 0.12392572678667475\n","Training loss per 100 training steps: 0.12192357458682156\n","Training loss per 100 training steps: 0.11967337741966795\n","Training loss epoch: 0.11967337741966795\n","Training accuracy epoch: 0.9610068084206073\n","Validating model...\n","Validation Loss: 0.18617455383109582\n","Validation Accuracy: 0.9500749737573367\n","Training epoch: 2\n","Training loss per 100 training steps: 0.025049448013305664\n","Training loss per 100 training steps: 0.04970649977924653\n","Training loss per 100 training steps: 0.04865597025143789\n","Training loss per 100 training steps: 0.04820512112793188\n","Training loss per 100 training steps: 0.04739231064432577\n","Training loss per 100 training steps: 0.048119370428707724\n","Training loss per 100 training steps: 0.04876460464393872\n","Training loss per 100 training steps: 0.049979150909385754\n","Training loss per 100 training steps: 0.04936323395451198\n","Training loss per 100 training steps: 0.04911954723273742\n","Training loss per 100 training steps: 0.04823136253730877\n","Training loss per 100 training steps: 0.04779088617637449\n","Training loss per 100 training steps: 0.047660024360723356\n","Training loss per 100 training steps: 0.047860605120164934\n","Training loss per 100 training steps: 0.047345685819961625\n","Training loss per 100 training steps: 0.0472659513625446\n","Training loss per 100 training steps: 0.04703158749439646\n","Training loss per 100 training steps: 0.04665643328292704\n","Training loss per 100 training steps: 0.04645057026152579\n","Training loss per 100 training steps: 0.04599424053915825\n","Training loss per 100 training steps: 0.0457916802298259\n","Training loss per 100 training steps: 0.045485169185103425\n","Training loss per 100 training steps: 0.045244934401912414\n","Training loss per 100 training steps: 0.04495334439854891\n","Training loss per 100 training steps: 0.04472905760014221\n","Training loss per 100 training steps: 0.04501533168233985\n","Training loss per 100 training steps: 0.044841809900422386\n","Training loss epoch: 0.044841809900422386\n","Training accuracy epoch: 0.9856720163679018\n","Validating model...\n","Validation Loss: 0.19956798660992223\n","Validation Accuracy: 0.9519172745379312\n","Training epoch: 3\n","Training loss per 100 training steps: 0.009916174225509167\n","Training loss per 100 training steps: 0.027884897086677133\n","Training loss per 100 training steps: 0.024032691827528086\n","Training loss per 100 training steps: 0.024309231741299724\n","Training loss per 100 training steps: 0.025181986684905146\n","Training loss per 100 training steps: 0.02617623654118425\n","Training loss per 100 training steps: 0.02791573031282071\n","Training loss per 100 training steps: 0.029201389725911915\n","Training loss per 100 training steps: 0.02878977010105347\n","Training loss per 100 training steps: 0.028914728713520056\n","Training loss per 100 training steps: 0.028849285559788752\n","Training loss per 100 training steps: 0.028700083611606215\n","Training loss per 100 training steps: 0.028328247126829666\n","Training loss per 100 training steps: 0.02786065443698281\n","Training loss per 100 training steps: 0.027390037491732477\n","Training loss per 100 training steps: 0.027337516021601754\n","Training loss per 100 training steps: 0.027178620921221294\n","Training loss per 100 training steps: 0.027467411193403436\n","Training loss per 100 training steps: 0.02752977302872593\n","Training loss per 100 training steps: 0.027780179086361503\n","Training loss per 100 training steps: 0.02774421304610601\n","Training loss per 100 training steps: 0.027666941065407062\n","Training loss per 100 training steps: 0.02758782034270065\n","Stopping epoch...\n","Training loss epoch: 0.02758782034270065\n","Training accuracy epoch: 0.9908651890578486\n","Validating model...\n","Validation Loss: 0.215047786883139\n","Validation Accuracy: 0.9515476637167083\n","Training epoch: 4\n","Training loss per 100 training steps: 0.028064368292689323\n","Training loss per 100 training steps: 0.02430326871039106\n","Training loss per 100 training steps: 0.02121430907609284\n","Training loss per 100 training steps: 0.021222404009187627\n","Training loss per 100 training steps: 0.02122884661384842\n","Training loss per 100 training steps: 0.021031153109598487\n","Training loss per 100 training steps: 0.02027848140300157\n","Training loss per 100 training steps: 0.020563805998537486\n","Training loss per 100 training steps: 0.021145709261769653\n","Training loss per 100 training steps: 0.0212007204106736\n","Training loss per 100 training steps: 0.021095345117820224\n","Training loss per 100 training steps: 0.021061153873747518\n","Training loss per 100 training steps: 0.021230729339211222\n","Stopping epoch...\n","Training loss epoch: 0.021230729339211222\n","Training accuracy epoch: 0.9925533963190726\n","Validating model...\n","Validation Loss: 0.24864222426209356\n","Validation Accuracy: 0.9485934387259726\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0032587451860308647\n","Training loss per 100 training steps: 0.019533948388439373\n","Training loss per 100 training steps: 0.01979474459985614\n","Training loss per 100 training steps: 0.02054991339452478\n","Training loss per 100 training steps: 0.020188810668149475\n","Training loss per 100 training steps: 0.019489726723690412\n","Training loss per 100 training steps: 0.01913021287074841\n","Training loss per 100 training steps: 0.019360743227468592\n","Training loss per 100 training steps: 0.01964684094678199\n","Training loss per 100 training steps: 0.019618574434531633\n","Training loss per 100 training steps: 0.01998803488295907\n","Training loss per 100 training steps: 0.02042003158837528\n","Training loss per 100 training steps: 0.02051085451257056\n","Training loss per 100 training steps: 0.02081844443799842\n","Training loss per 100 training steps: 0.02064866439642439\n","Training loss per 100 training steps: 0.02054552182949661\n","Training loss per 100 training steps: 0.020655316216305425\n","Training loss per 100 training steps: 0.020782708346166582\n","Training loss per 100 training steps: 0.020780779262042182\n","Training loss per 100 training steps: 0.020595147496012545\n","Training loss per 100 training steps: 0.02042117411708997\n","Training loss per 100 training steps: 0.020598782661338463\n","Training loss per 100 training steps: 0.020930573118051177\n","Training loss per 100 training steps: 0.020911552734477833\n","Training loss per 100 training steps: 0.020997441153189706\n","Training loss per 100 training steps: 0.021129592139032673\n","Training loss per 100 training steps: 0.021056573041964923\n","Training loss epoch: 0.021056573041964923\n","Training accuracy epoch: 0.9933918132593782\n","Validating model...\n","Validation Loss: 0.2644474416632544\n","Validation Accuracy: 0.9477099453276558\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0037436082493513823\n","Training loss per 100 training steps: 0.011268137772060415\n","Training loss per 100 training steps: 0.013905491615255798\n","Training loss per 100 training steps: 0.017074832436657646\n","Training loss per 100 training steps: 0.017607832614422725\n","Training loss per 100 training steps: 0.017446901949075843\n","Training loss per 100 training steps: 0.017361113404774357\n","Training loss per 100 training steps: 0.017124704207082283\n","Training loss per 100 training steps: 0.01679387888408597\n","Training loss per 100 training steps: 0.01672766417358678\n","Training loss per 100 training steps: 0.016250061798946246\n","Training loss per 100 training steps: 0.016005658122832375\n","Training loss per 100 training steps: 0.015999708922753295\n","Training loss per 100 training steps: 0.016026559313077806\n","Training loss per 100 training steps: 0.016168728890024183\n","Training loss per 100 training steps: 0.016016210680320653\n","Training loss per 100 training steps: 0.016116698125471025\n","Training loss per 100 training steps: 0.016208122730639277\n","Training loss per 100 training steps: 0.016406554976646087\n","Training loss per 100 training steps: 0.016577915010858008\n","Training loss per 100 training steps: 0.016712972910055527\n","Training loss per 100 training steps: 0.016979192017060562\n","Training loss per 100 training steps: 0.016932625802808382\n","Training loss per 100 training steps: 0.016826433254188457\n","Training loss per 100 training steps: 0.016804715129683796\n","Training loss per 100 training steps: 0.016688625206829417\n","Training loss per 100 training steps: 0.016643857810412905\n","Training loss epoch: 0.016643857810412905\n","Training accuracy epoch: 0.9949497724264507\n","Validating model...\n","Validation Loss: 0.25615471243471294\n","Validation Accuracy: 0.9468315660673886\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 251.17478183333344 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.20175590373778338\n","Validation Accuracy: 0.9458112017392515\n","Validation duration: 6.031925466666629 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 81.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.82      0.81     12546\n","        test       0.80      0.83      0.82      9012\n","   treatment       0.80      0.82      0.81      9297\n","\n","   micro avg       0.80      0.82      0.81     30855\n","   macro avg       0.80      0.82      0.81     30855\n","weighted avg       0.80      0.82      0.81     30855\n","\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"083ecc03cefa41bfb34227e21eee1095":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fdc8c9cadab46ceababad1a49f87076":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7029f43c14494e07996368dec8b6bce7","placeholder":"​","style":"IPY_MODEL_7b13cef2c08349a09362046256fab06b","value":"Downloading: 100%"}},"25cb7be8e237491d9a1f270a46980b44":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3272d17ca3bb4a1bb693729b9334616f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"448cf9a5c4b8438fbfb2c6db8a067a1a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_63e165900fd34c9d839963f6e94eb2ee","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_63e7608199f74d0eaa43cc324b6ed0d8","value":442221694}},"46a83366bdf44445bf9758ea1f4ee1f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4d177a0fe92c499786d4214738a702a5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_99ad0a784c3743efbca135e1f3d45fa7","placeholder":"​","style":"IPY_MODEL_3272d17ca3bb4a1bb693729b9334616f","value":"Downloading: 100%"}},"59834b2eebd7484f8f824139d52dd2d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4d177a0fe92c499786d4214738a702a5","IPY_MODEL_fbe95058a4b74382a476622f99a2bfab","IPY_MODEL_dd8439b8cd3d4e1dba3f501ed853eacf"],"layout":"IPY_MODEL_d4b190f51eea40d59a89fb16e416931e"}},"5d94c549ef004827b1c16379bf1d42fa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63e165900fd34c9d839963f6e94eb2ee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63e7608199f74d0eaa43cc324b6ed0d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7029f43c14494e07996368dec8b6bce7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"706477f978144426893c226859819cd2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"710019bff2a84f67b7719458712fa4b8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"745e010dcfd6469bb22d274e7f2c10ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_848bf7050ad94d3db7e5d0317ed98481","IPY_MODEL_9af6cd09bfd144e2a60458438e377c82","IPY_MODEL_ae9d467f2c874c67a96e1d306c9075c8"],"layout":"IPY_MODEL_792731224c3442bda5e050d71b3803f2"}},"74b80c38bc09482b9130d5ec8c44b338":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d94c549ef004827b1c16379bf1d42fa","placeholder":"​","style":"IPY_MODEL_da5976392c014387b70793fcae85e4bc","value":" 442M/442M [00:06&lt;00:00, 62.0MB/s]"}},"7651edbfe2774e1193dcb3c2bf62b9c5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"792731224c3442bda5e050d71b3803f2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b13cef2c08349a09362046256fab06b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e589cfd202547928af1738ee3190bd5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"848bf7050ad94d3db7e5d0317ed98481":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_083ecc03cefa41bfb34227e21eee1095","placeholder":"​","style":"IPY_MODEL_7651edbfe2774e1193dcb3c2bf62b9c5","value":"Downloading: 100%"}},"870531d1294f4cf3ae3b0497a7da2eaf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99ad0a784c3743efbca135e1f3d45fa7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9af6cd09bfd144e2a60458438e377c82":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1a09cc96e5e470ea02e2409c04fd426","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bd05427d6d0844828ec8ada2327d151c","value":442221694}},"ae9d467f2c874c67a96e1d306c9075c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_706477f978144426893c226859819cd2","placeholder":"​","style":"IPY_MODEL_46a83366bdf44445bf9758ea1f4ee1f9","value":" 442M/442M [00:06&lt;00:00, 57.5MB/s]"}},"b1a09cc96e5e470ea02e2409c04fd426":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd05427d6d0844828ec8ada2327d151c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c84182275ab644ec8c2397ba53c56e05":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d27ccdf24b974ac59a435501ede57f78":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1fdc8c9cadab46ceababad1a49f87076","IPY_MODEL_448cf9a5c4b8438fbfb2c6db8a067a1a","IPY_MODEL_74b80c38bc09482b9130d5ec8c44b338"],"layout":"IPY_MODEL_710019bff2a84f67b7719458712fa4b8"}},"d4b190f51eea40d59a89fb16e416931e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da5976392c014387b70793fcae85e4bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dd8439b8cd3d4e1dba3f501ed853eacf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25cb7be8e237491d9a1f270a46980b44","placeholder":"​","style":"IPY_MODEL_7e589cfd202547928af1738ee3190bd5","value":" 442M/442M [00:06&lt;00:00, 66.6MB/s]"}},"fbe95058a4b74382a476622f99a2bfab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_870531d1294f4cf3ae3b0497a7da2eaf","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c84182275ab644ec8c2397ba53c56e05","value":442221694}},"a597acaf35a1469185fc7a89fe70dde4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_93b9b161283244089549759c9c0fd24a","IPY_MODEL_67b58a95215347868df26cb778b575a8","IPY_MODEL_de81c01f633a408db46b9b73ffbc6bec"],"layout":"IPY_MODEL_283f3d23a7904c4b927680f96bc7b550"}},"93b9b161283244089549759c9c0fd24a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff9d0bffaabb443cad356406d7256347","placeholder":"​","style":"IPY_MODEL_04727ef5b45b493bbef6ba131bd5bd52","value":"Downloading: 100%"}},"67b58a95215347868df26cb778b575a8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_29ca83bef6ca47699e97bc36371dcc67","max":385,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ece7ebd9778849e6a541e12f0a184714","value":385}},"de81c01f633a408db46b9b73ffbc6bec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_38c852b918d743e3ade15bdb8d403522","placeholder":"​","style":"IPY_MODEL_1291306c22ec461d836c3ef46b7fa8b2","value":" 385/385 [00:00&lt;00:00, 12.7kB/s]"}},"283f3d23a7904c4b927680f96bc7b550":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff9d0bffaabb443cad356406d7256347":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04727ef5b45b493bbef6ba131bd5bd52":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29ca83bef6ca47699e97bc36371dcc67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ece7ebd9778849e6a541e12f0a184714":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"38c852b918d743e3ade15bdb8d403522":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1291306c22ec461d836c3ef46b7fa8b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0dfeadadc3c74f79a8b5b4882ab8654e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a75016ef8f60474482afb2b1da6971c1","IPY_MODEL_597cc625aca343e0b241b27fbab118e7","IPY_MODEL_479116aa11c441518b8b2e4d01dec3c2"],"layout":"IPY_MODEL_39801022ab7d48b093537995f128a38e"}},"a75016ef8f60474482afb2b1da6971c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69f0a6b9ca1b4e1dbdff3e02a07aeb5c","placeholder":"​","style":"IPY_MODEL_0f085775a15840dabeb079575d3dd116","value":"Downloading: 100%"}},"597cc625aca343e0b241b27fbab118e7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_420fe38e2d3e4b1b92bcdff4fc610aea","max":227845,"min":0,"orientation":"horizontal","style":"IPY_MODEL_db3eb91106ec460fb8041f521450cd40","value":227845}},"479116aa11c441518b8b2e4d01dec3c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c12afde4ad2463e9706a654626590a2","placeholder":"​","style":"IPY_MODEL_6c51a30f67d0435cbd25b0cea0abd992","value":" 228k/228k [00:00&lt;00:00, 277kB/s]"}},"39801022ab7d48b093537995f128a38e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69f0a6b9ca1b4e1dbdff3e02a07aeb5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f085775a15840dabeb079575d3dd116":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"420fe38e2d3e4b1b92bcdff4fc610aea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db3eb91106ec460fb8041f521450cd40":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3c12afde4ad2463e9706a654626590a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c51a30f67d0435cbd25b0cea0abd992":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c314e9ffb26f47e09a2fcdab16b62856":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a49020960edb43d1bb105b4bce69262d","IPY_MODEL_47bea9d3556a4084aa0f0158bf9215f0","IPY_MODEL_eb98ff57b533422792982b7f110a31e9"],"layout":"IPY_MODEL_0a8d498b6a7f4add9a5afa542f527d91"}},"a49020960edb43d1bb105b4bce69262d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be9797caa49b48f7bc6c26230c37e5b9","placeholder":"​","style":"IPY_MODEL_4a649775e9cf405787de06a99b3dd222","value":"Downloading: 100%"}},"47bea9d3556a4084aa0f0158bf9215f0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1a0555df7184fa4a771c2071f6991c3","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f5b2fbcebead48c4961053e89bb53b24","value":442221694}},"eb98ff57b533422792982b7f110a31e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_66fd9e81137b4e67b57821722f1dd7e4","placeholder":"​","style":"IPY_MODEL_8dab5366ac854d0f99f5298179f8f248","value":" 442M/442M [00:06&lt;00:00, 69.4MB/s]"}},"0a8d498b6a7f4add9a5afa542f527d91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be9797caa49b48f7bc6c26230c37e5b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a649775e9cf405787de06a99b3dd222":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1a0555df7184fa4a771c2071f6991c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5b2fbcebead48c4961053e89bb53b24":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"66fd9e81137b4e67b57821722f1dd7e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8dab5366ac854d0f99f5298179f8f248":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d287ac473a614d0c98b2a6af58061caf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ba491358174843dda5832bb62c0057d0","IPY_MODEL_188f5f35c27d40b9a541f6e54b8801dd","IPY_MODEL_7dafb9bead6148ccb7f8da375e7915b5"],"layout":"IPY_MODEL_12edc4b151f64e77ac4e3e25f5dfe8fc"}},"ba491358174843dda5832bb62c0057d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84d1aafed0e645d39baa87140cea3c68","placeholder":"​","style":"IPY_MODEL_444d9e7e82fa41fb831e55975cf89ca5","value":"Downloading: 100%"}},"188f5f35c27d40b9a541f6e54b8801dd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4ad4d8f741f4a368cf65870dc82c87c","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_311cf0e0a376447480e3cd95f62c887b","value":442221694}},"7dafb9bead6148ccb7f8da375e7915b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_740a675c7b004462bb3e0c3a381dbaec","placeholder":"​","style":"IPY_MODEL_d4d9dcbc623248d4b152f42f16996e55","value":" 442M/442M [00:06&lt;00:00, 65.1MB/s]"}},"12edc4b151f64e77ac4e3e25f5dfe8fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84d1aafed0e645d39baa87140cea3c68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"444d9e7e82fa41fb831e55975cf89ca5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4ad4d8f741f4a368cf65870dc82c87c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"311cf0e0a376447480e3cd95f62c887b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"740a675c7b004462bb3e0c3a381dbaec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4d9dcbc623248d4b152f42f16996e55":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}