{"cells":[{"cell_type":"markdown","metadata":{"id":"FFh7WVoJH5dr"},"source":["Adapted from [ner_with_bilstm_and_crf](https://www.kaggle.com/nikkisharma536/ner-with-bilstm-and-crf/notebook)\n","Altigran Soares da Silva\n","IComp/UFAM - 15/03/2021\n"],"id":"FFh7WVoJH5dr"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10711,"status":"ok","timestamp":1657324820917,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"instant-coupon","outputId":"7a9d80cb-8e87-471f-8fb5-c153fcef19c1"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING: Tensorflow 1 is deprecated, and support will be removed on August 1, 2022.\n","After that, `%tensorflow_version 1.x` will throw an error.\n","\n","Your notebook should be updated to use Tensorflow 2.\n","See the guide at https://www.tensorflow.org/guide/migrate#migrate-from-tensorflow-1x-to-tensorflow-2.\n","\n","TensorFlow 1.x selected.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (1.2.2)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n"]}],"source":["# For this to work, use:\n","# Keras 2.3.1\n","# TensorFlow 1.15.2\n","# Also remember to use GPU in your colab notebook\n","%tensorflow_version 1.x\n","\n","# Code to read csv file into Colaboratory:\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","from math import nan\n","from future.utils import iteritems\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import math\n","import random\n","import json\n","import pickle\n","import time\n","from requests import get\n","\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import torch\n","from torch import cuda\n","from torch.utils.data import Dataset, DataLoader\n","\n","!pip install sentencepiece\n","!pip install transformers\n","from transformers import BertForTokenClassification, AutoTokenizer\n","\n","!pip install seqeval\n","from seqeval.metrics import f1_score, classification_report"],"id":"instant-coupon"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mmt06ncv89hH"},"outputs":[],"source":["# Code to read csv file from google drive into Colaboratory:\n","DATA_TRAINING_FILE_ID = '1Y2gfhNgbGX7pA0FkA2vbOxdoSmNJVHIK'\n","DATA_TRAINING_FILENAME = 'ner_training_dataset.csv'\n","DATA_DEV_FILE_ID = '1AGW9cRPwBmeJqOo3WXPPcNckrX4jMcIn'\n","DATA_DEV_FILENAME = 'ner_validation_dataset.csv'\n","DATA_TEST_FILE_ID = '1L-fnx31bK0nZAl9_DDfo7-25H7PYU0l8'\n","DATA_TEST_FILENAME = 'ner_test_dataset.csv'\n","BACKUP_FOLDER_ID = '1YWR4Ip8w94RwFMyMtNpRa9M0FpiJtqd5'\n","\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","downloaded_training = drive.CreateFile({'id': DATA_TRAINING_FILE_ID})\n","downloaded_training.GetContentFile(DATA_TRAINING_FILENAME)\n","downloaded_dev = drive.CreateFile({'id': DATA_DEV_FILE_ID})\n","downloaded_dev.GetContentFile(DATA_DEV_FILENAME)\n","downloaded_test = drive.CreateFile({'id': DATA_TEST_FILE_ID})\n","downloaded_test.GetContentFile(DATA_TEST_FILENAME)\n","\n","# Read the csv file in a dataframe called \"data\"\n","training_data = pd.read_csv(DATA_TRAINING_FILENAME, encoding=\"latin1\")\n","dev_data = pd.read_csv(DATA_DEV_FILENAME, encoding=\"latin1\")\n","test_data = pd.read_csv(DATA_TEST_FILENAME, encoding=\"latin1\")\n","# Fill NaN values using the specified method\n","# Ffill propagate last valid observation/value forward to next valid \n","training_data = training_data.fillna(method=\"ffill\")\n","dev_data = dev_data.fillna(method=\"ffill\")\n","test_data = test_data.fillna(method=\"ffill\")\n","\n","notebook_filename = get('http://172.28.0.2:9000/api/sessions').json()[0]['name']"],"id":"Mmt06ncv89hH"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":588},"executionInfo":{"elapsed":520,"status":"ok","timestamp":1657324827850,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"adverse-doctor","outputId":"731f86b6-f53f-4dcc-fbf9-ba531c80e9f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of training sentences:  13052\n","Number of dev sentences:  3263\n","Number of test sentences:  27625\n","Number of words in the training dataset:  13860\n","Number of words in the dev dataset:  6360\n","Number of words in the test dataset:  21696\n","Tags in the training dataset: ['B-treatment', 'B-test', 'I-problem', 'I-test', 'O', 'B-problem', 'I-treatment']\n","Number of Labels in the training dataset:  7\n","Tags in the dev dataset: ['B-treatment', 'B-test', 'I-problem', 'I-test', 'O', 'B-problem', 'I-treatment']\n","Number of Labels in the dev dataset:  7\n","Tags in the test dataset: ['B-treatment', 'B-test', 'I-problem', 'I-test', 'O', 'B-problem', 'I-treatment']\n","Number of Labels in the test dataset:  7\n","What the training dataset looks like:\n"]},{"data":{"text/html":["\n","  <div id=\"df-206c9b88-1250-472b-8564-2311e151fa6c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence #</th>\n","      <th>Word</th>\n","      <th>Tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sentence: 10707</td>\n","      <td>She</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sentence: 10707</td>\n","      <td>had</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sentence: 10707</td>\n","      <td>normal</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sentence: 10707</td>\n","      <td>comprehension</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sentence: 10707</td>\n","      <td>.</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Sentence: 7349</td>\n","      <td>Scott</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Sentence: 7349</td>\n","      <td>Robert</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Sentence: 7349</td>\n","      <td>NP</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Sentence: 7349</td>\n","      <td>80-AUM</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Sentence: 7349</td>\n","      <td>2017-06-29</td>\n","      <td>O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-206c9b88-1250-472b-8564-2311e151fa6c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-206c9b88-1250-472b-8564-2311e151fa6c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-206c9b88-1250-472b-8564-2311e151fa6c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["        Sentence #           Word Tag\n","0  Sentence: 10707            She   O\n","1  Sentence: 10707            had   O\n","2  Sentence: 10707         normal   O\n","3  Sentence: 10707  comprehension   O\n","4  Sentence: 10707              .   O\n","5   Sentence: 7349          Scott   O\n","6   Sentence: 7349         Robert   O\n","7   Sentence: 7349             NP   O\n","8   Sentence: 7349         80-AUM   O\n","9   Sentence: 7349     2017-06-29   O"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Explore the input dataset\n","print(\"Number of training sentences: \", len(training_data.groupby(['Sentence #'])))\n","print(\"Number of dev sentences: \", len(dev_data.groupby(['Sentence #'])))\n","print(\"Number of test sentences: \", len(test_data.groupby(['Sentence #'])))\n","\n","training_words = list(set(training_data[\"Word\"].values))\n","n_training_words = len(training_words)\n","print(\"Number of words in the training dataset: \", n_training_words)\n","dev_words = list(set(dev_data[\"Word\"].values))\n","n_dev_words = len(dev_words)\n","print(\"Number of words in the dev dataset: \", n_dev_words)\n","test_words = list(set(test_data[\"Word\"].values))\n","n_test_words = len(test_words)\n","print(\"Number of words in the test dataset: \", n_test_words)\n","\n","training_tags = list(set(training_data[\"Tag\"].values))\n","print(\"Tags in the training dataset:\", training_tags)\n","n_training_tags = len(training_tags)\n","print(\"Number of Labels in the training dataset: \", n_training_tags)\n","dev_tags = list(set(dev_data[\"Tag\"].values))\n","print(\"Tags in the dev dataset:\", dev_tags)\n","n_dev_tags = len(dev_tags)\n","print(\"Number of Labels in the dev dataset: \", n_dev_tags)\n","test_tags = list(set(test_data[\"Tag\"].values))\n","print(\"Tags in the test dataset:\", test_tags)\n","n_test_tags = len(test_tags)\n","print(\"Number of Labels in the test dataset: \", n_test_tags)\n","\n","print(\"What the training dataset looks like:\")\n","# Show the first 10 rows\n","training_data.head(n=10)"],"id":"adverse-doctor"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4834,"status":"ok","timestamp":1657324832680,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"painful-karaoke","outputId":"ca0969e9-eb26-4156-f335-dff1092008eb"},"outputs":[{"data":{"text/plain":["[('Last', 'O'),\n"," ('menstrual', 'O'),\n"," ('period', 'O'),\n"," ('2009-02-21', 'O'),\n"," ('.', 'O')]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# SentenceGetter re-organize \"data\" as an arry of sentences\n","# Each sentence is a list of pairs <word,tag> \n","class SentenceGetter(object):\n","    \n","    def __init__(self, dataset):\n","        self.n_sent = 1\n","        self.dataset = dataset\n","        self.empty = False\n","        agg_func = lambda s: [(w, t) for w,t in zip(s[\"Word\"].values.tolist(),\n","                                                        s[\"Tag\"].values.tolist())]\n","        self.grouped = self.dataset.groupby(\"Sentence #\").apply(agg_func)\n","        self.sentences = [s for s in self.grouped]\n","    \n","    def get_next(self):\n","        try:\n","            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n","            self.n_sent += 1\n","            return s\n","        except:\n","            return None\n","\n","training_getter = SentenceGetter(training_data)\n","training_sentences = training_getter.sentences\n","dev_getter = SentenceGetter(dev_data)\n","dev_sentences = dev_getter.sentences\n","test_getter = SentenceGetter(test_data)\n","test_sentences = test_getter.sentences\n","\n","# Example: training sentence #200 \n","training_sentences[200]"],"id":"painful-karaoke"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1657324832681,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"round-providence","outputId":"ad8e8837-6c83-4ff7-9b4a-26088a25351c"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Explore set of sentences\n","# Plot sentences by length\n","plt.hist([len(s) for s in training_sentences], bins=50)\n","plt.title('Token per training sentence')\n","plt.xlabel('Len (number of token)')\n","plt.ylabel('# samples')\n","plt.show()"],"id":"round-providence"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1657324832682,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"urxTzspTyPq5","outputId":"105d47a8-73c9-491e-9acd-a1529777636e"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Explore set of sentences\n","# Plot sentences by length\n","plt.hist([len(s) for s in dev_sentences], bins=50)\n","plt.title('Token per dev sentence')\n","plt.xlabel('Len (number of token)')\n","plt.ylabel('# samples')\n","plt.show()"],"id":"urxTzspTyPq5"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1657324832683,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"JJ91V_51yPw9","outputId":"b2b01d5e-96e2-4061-82c4-518db9e03e79"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Explore set of sentences\n","# Plot sentences by length\n","plt.hist([len(s) for s in test_sentences], bins=50)\n","plt.title('Token per test sentence')\n","plt.xlabel('Len (number of token)')\n","plt.ylabel('# samples')\n","plt.show()"],"id":"JJ91V_51yPw9"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1657324832683,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"juvenile-scene","outputId":"e108f86b-174b-4c79-9c0b-d36d4f878943"},"outputs":[{"name":"stdout","output_type":"stream","text":["6477\n","2017-01-07\n","0\n","O\n"]}],"source":["# Keras (and most other ML packages) expect all the ids to be numeric, \n","# this is an optimisation to save memory. \n","# We will create the following dictionaries:\n","# word2idx: assign a numeric index to each word in the dataset\n","# idx2word: inverted version of word2idx\n","# tag2idx: assign a numeric index to each tag in the dataset\n","# idx2tag: inverted version of tag2idx\n","\n","# Group training, dev and test data in order to create word-index dicts and to\n","# convert data to numeric indeces later\n","data = pd.concat([training_data, dev_data, test_data])\n","\n","# words <= list of all words in the input dataset\n","words = list(set(data[\"Word\"].values))\n","n_words = len(words)\n","\n","# tags <= list of all tags in the input dataset\n","tags = []\n","for tag in set(data[\"Tag\"].values):\n","    if tag is nan or isinstance(tag, float):\n","        tags.append('unk')\n","    else:\n","        tags.append(tag)\n","n_tags = len(tags)\n","\n","# Dictionaries\n","word2idx = {w: i for i, w in enumerate(words)}\n","idx2word = {i: w for w, i in iteritems(word2idx)}\n","tag2idx = {t: i for i, t in enumerate(tags)}\n","idx2tag = {v: k for k, v in iteritems(tag2idx)}\n","\n","# Index number for the word 'comprehension'\n","print(word2idx['comprehension'])\n","# Word of index 10\n","print(idx2word[10])\n","# Index number for the tag 'B-treatment'\n","print(tag2idx['B-treatment'])\n","# Tag of index 4\n","print(idx2tag[4])"],"id":"juvenile-scene"},{"cell_type":"code","execution_count":null,"metadata":{"id":"delayed-dryer"},"outputs":[],"source":["# Convert train, dev and test data to numeric values\n","X_train = [[word2idx[w[0]] for w in s] for s in training_sentences]\n","y_train = [[tag2idx[w[1]] for w in s] for s in training_sentences]\n","\n","X_dev = [[word2idx[w[0]] for w in s] for s in dev_sentences]\n","y_dev = [[tag2idx[w[1]] for w in s] for s in dev_sentences]\n","\n","X_test = [[word2idx[w[0]] for w in s] for s in test_sentences]\n","y_test = [[tag2idx[w[1]] for w in s] for s in test_sentences]"],"id":"delayed-dryer"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1657324832685,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"Ttsyh05Rhovo","outputId":"a45af659-2bbd-4d6b-cf88-ab9190628bd1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Points in X_train before removal: 13052\n","Points in y_train before removal: 13052\n","Points in X_train before removal: 6526\n","Points in y_train before removal: 6526\n"]}],"source":["# Use this function to randomly remove some points from training dataset\n","# Use removal percentage in decimal value. E.g.: if you set as 0.5, it will\n","# remove 50% of the dataset\n","\n","def random_remove_data_points(dataset, labels, removal_percentage):\n","    if removal_percentage < 0 or removal_percentage > 1:\n","        raise Exception(\"Invalid removal percentage\")\n","    \n","    if removal_percentage == 1:\n","        raise Exception(\"You can't remove the entire dataset\")\n","    \n","    number_of_points_remaining = round(len(dataset)*(1-removal_percentage))\n","\n","    try_again = True\n","\n","    while try_again:\n","      random_idxs = np.random.choice(len(dataset), number_of_points_remaining, replace=False)\n","      cut_dataset_sentences = [dataset[i] for i in random_idxs]\n","      cut_dataset_labels = [labels[i] for i in random_idxs]\n","      cut_tags = list(set([idx2tag[j] for sub in cut_dataset_labels for j in sub]))\n","\n","      if all(i in cut_tags for i in tags if i[:2] == \"B-\"):\n","        try_again = False\n","\n","    return cut_dataset_sentences, cut_dataset_labels \n","\n","print(f\"Points in X_train before removal: {len(X_train)}\")\n","print(f\"Points in y_train before removal: {len(y_train)}\")\n","X_train, y_train = random_remove_data_points(X_train, y_train, 0.5)\n","print(f\"Points in X_train before removal: {len(X_train)}\")\n","print(f\"Points in y_train before removal: {len(y_train)}\")"],"id":"Ttsyh05Rhovo"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0SN-NYLpgsFa"},"outputs":[],"source":["# Aux functions to save data and dicts, if data consistency is important\n","# and there is desire to not random split again\n","\n","def save_backup_dataset(dataset, filename):\n","  dataset_df = pd.DataFrame(dataset)\n","  dataset_df.to_csv(filename, index=False)\n","  gfile = drive.CreateFile({'parents': [{'id': BACKUP_FOLDER_ID}]})\n","  gfile.SetContentFile(filename)\n","  gfile.Upload()\n","\n","def save_backup_dict(dict, filename):\n","  dict_file = open(filename, \"wb\")\n","  pickle.dump(dict, dict_file)\n","  dict_file.close()\n","  gfile = drive.CreateFile({'parents': [{'id': BACKUP_FOLDER_ID}]})\n","  gfile.SetContentFile(filename)\n","  gfile.Upload()"],"id":"0SN-NYLpgsFa"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22399,"status":"ok","timestamp":1657324855067,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"MzRQfI30tuI2","outputId":"202f0a3f-b01a-4052-a56a-b74abf22090f"},"outputs":[{"name":"stdout","output_type":"stream","text":["[4967, 14980, 8645, 27211, 10642, 12573, 26848, 14123, 8352, 12671, 13594, 11032, 13491, 22572, 18311, 21228, 17168, 17174, 12435]\n","[4, 4, 4, 4, 4, 1, 3, 3, 4, 0, 4, 4, 4, 4, 4, 5, 4, 4, 4]\n","[749, 15201, 6545, 22805, 5752, 1489, 25581, 11604, 23595, 23167, 24579, 1328, 23345, 12435]\n","[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n","[17360, 2641, 23855]\n","[4, 4, 4]\n","6477\n","0\n","I-problem\n","ASHEE\n","28388\n","7\n"]}],"source":["# Uncomment this cell if you want to save data for further use\n","\n","# Check some points before saving\n","print(X_train[0])\n","print(y_train[0])\n","print(X_dev[0])\n","print(y_dev[0])\n","print(X_test[0])\n","print(y_test[0])\n","print(word2idx['comprehension'])\n","print(tag2idx['B-treatment'])\n","print(idx2tag[2])\n","print(idx2word[100])\n","print(n_words)\n","print(n_tags)\n","\n","X_train_filename = f'{notebook_filename}_X_train.csv'\n","y_train_filename = f'{notebook_filename}_y_train.csv'\n","X_dev_filename = f'{notebook_filename}_X_dev.csv'\n","y_dev_filename = f'{notebook_filename}_y_dev.csv'\n","X_test_filename = f'{notebook_filename}_X_test.csv'\n","y_test_filename = f'{notebook_filename}_y_test.csv'\n","\n","word2idx_filename = f'{notebook_filename}_word2idx.pkl'\n","idx2word_filename = f'{notebook_filename}_idx2word.pkl'\n","tag2idx_filename = f'{notebook_filename}_tag2idx.pkl'\n","idx2tag_filename = f'{notebook_filename}_idx2tag.pkl'\n","\n","others_filename = f'{notebook_filename}_others.pkl'\n","\n","save_backup_dataset(X_train, X_train_filename)\n","save_backup_dataset(y_train, y_train_filename)\n","save_backup_dataset(X_dev, X_dev_filename)\n","save_backup_dataset(y_dev, y_dev_filename)\n","save_backup_dataset(X_test, X_test_filename)\n","save_backup_dataset(y_test, y_test_filename)\n","\n","save_backup_dict(word2idx, word2idx_filename)\n","save_backup_dict(idx2word, idx2word_filename)\n","save_backup_dict(tag2idx, tag2idx_filename)\n","save_backup_dict(idx2tag, idx2tag_filename)\n","\n","save_backup_dict({\"n_words\":n_words, \"n_tags\":n_tags}, others_filename)"],"id":"MzRQfI30tuI2"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":70376,"status":"ok","timestamp":1657554121851,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"zvip_oC0j5-y","outputId":"5a11d463-ded2-4a7a-e31f-2529a4a0d52f"},"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING: Tensorflow 1 is deprecated, and support will be removed on August 1, 2022.\n","After that, `%tensorflow_version 1.x` will throw an error.\n","\n","Your notebook should be updated to use Tensorflow 2.\n","See the guide at https://www.tensorflow.org/guide/migrate#migrate-from-tensorflow-1x-to-tensorflow-2.\n","\n","TensorFlow 1.x selected.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     || 1.2 MB 16.2 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n","\u001b[K     || 4.4 MB 17.5 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     || 596 kB 76.8 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     || 6.6 MB 70.9 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     || 101 kB 12.1 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["yaml"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     || 43 kB 2.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=abed2c9c130a366331d0c1c6f1b6bfe9ed21dac0ec685cd6d8e1b697d00c0085\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n","[4967, 14980, 8645, 27211, 10642, 12573, 26848, 14123, 8352, 12671, 13594, 11032, 13491, 22572, 18311, 21228, 17168, 17174, 12435]\n","[4, 4, 4, 4, 4, 1, 3, 3, 4, 0, 4, 4, 4, 4, 4, 5, 4, 4, 4]\n","[749, 15201, 6545, 22805, 5752, 1489, 25581, 11604, 23595, 23167, 24579, 1328, 23345, 12435]\n","[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n","[17360, 2641, 23855]\n","[4, 4, 4]\n","6477\n","0\n","I-problem\n","ASHEE\n","28388\n","7\n"]}],"source":["# Uncomment this cell if you want to load saved data\n","\n","# Re-import necessary libs\n","import pandas as pd\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","import pickle, math\n","from requests import get\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import random\n","import time\n","%tensorflow_version 1.x\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import torch\n","from torch import cuda\n","from torch.utils.data import Dataset, DataLoader\n","!pip install sentencepiece\n","!pip install transformers\n","from transformers import BertForTokenClassification, AutoTokenizer\n","import matplotlib.pyplot as plt\n","!pip install seqeval\n","from seqeval.metrics import f1_score, classification_report\n","\n","BACKUP_FOLDER_ID = '1YWR4Ip8w94RwFMyMtNpRa9M0FpiJtqd5'\n","notebook_filename = get('http://172.28.0.2:9000/api/sessions').json()[0]['name']\n","\n","X_train_filename = f'{notebook_filename}_X_train.csv'\n","y_train_filename = f'{notebook_filename}_y_train.csv'\n","X_dev_filename = f'{notebook_filename}_X_dev.csv'\n","y_dev_filename = f'{notebook_filename}_y_dev.csv'\n","X_test_filename = f'{notebook_filename}_X_test.csv'\n","y_test_filename = f'{notebook_filename}_y_test.csv'\n","\n","word2idx_filename = f'{notebook_filename}_word2idx.pkl'\n","idx2word_filename = f'{notebook_filename}_idx2word.pkl'\n","tag2idx_filename = f'{notebook_filename}_tag2idx.pkl'\n","idx2tag_filename = f'{notebook_filename}_idx2tag.pkl'\n","\n","others_filename = f'{notebook_filename}_others.pkl'\n","\n","# Re-get important variables\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","def get_backup_files_ids(folder_id):\n","  file_list = drive.ListFile({'q': \"'{}' in parents and trashed=false\".format(folder_id)}).GetList()\n","  return file_list\n","\n","def load_backup_dataset(file_id):\n","  downloaded = drive.CreateFile({'id':file_id})\n","  downloaded.GetContentFile(f\"{file_id}.csv\")\n","\n","  dataset = pd.read_csv(f\"{file_id}.csv\", encoding=\"latin1\")\n","  dataset = dataset.fillna(method=\"ffill\")\n","  dataset = dataset.values.tolist()\n","  dataset = [ [ int(word) for word in sentence if str(word) != 'nan' ] for sentence in dataset]\n","  return dataset\n","\n","def load_backup_dict(file_id):\n","  downloaded = drive.CreateFile({'id':file_id})\n","  downloaded.GetContentFile(f\"{file_id}.pkl\")\n","\n","  dict_file = open(f\"{file_id}.pkl\", \"rb\")\n","  out_dict = pickle.load(dict_file)\n","  return out_dict\n","\n","backup_file_list = get_backup_files_ids(BACKUP_FOLDER_ID)\n","\n","X_train_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == X_train_filename][0]['id']\n","y_train_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == y_train_filename][0]['id']\n","X_dev_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == X_dev_filename][0]['id']\n","y_dev_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == y_dev_filename][0]['id']\n","X_test_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == X_test_filename][0]['id']\n","y_test_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == y_test_filename][0]['id']\n","\n","word2idx_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == word2idx_filename][0]['id']\n","idx2word_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == idx2word_filename][0]['id']\n","tag2idx_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == tag2idx_filename][0]['id']\n","idx2tag_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == idx2tag_filename][0]['id']\n","\n","others_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == others_filename][0]['id']\n","\n","X_train = load_backup_dataset(X_train_file_id)\n","y_train = load_backup_dataset(y_train_file_id)\n","X_dev = load_backup_dataset(X_dev_file_id)\n","y_dev = load_backup_dataset(y_dev_file_id)\n","X_test = load_backup_dataset(X_test_file_id)\n","y_test = load_backup_dataset(y_test_file_id)\n","\n","word2idx = load_backup_dict(word2idx_file_id)\n","idx2word = load_backup_dict(idx2word_file_id)\n","tag2idx = load_backup_dict(tag2idx_file_id)\n","idx2tag = load_backup_dict(idx2tag_file_id)\n","\n","others = load_backup_dict(others_file_id)\n","\n","n_words = others[\"n_words\"]\n","n_tags = others[\"n_tags\"]\n","\n","# Check some points after loading data to see if they match the ones before saving\n","print(X_train[0])\n","print(y_train[0])\n","print(X_dev[0])\n","print(y_dev[0])\n","print(X_test[0])\n","print(y_test[0])\n","print(word2idx['comprehension'])\n","print(tag2idx['B-treatment'])\n","print(idx2tag[2])\n","print(idx2word[100])\n","print(n_words)\n","print(n_tags)"],"id":"zvip_oC0j5-y"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ux5-6tyMhovp"},"outputs":[],"source":["# Aux function to help in augmentation. Generates a dict where entities\n","# are the keys, and words are the values.\n","\n","def create_entities_dict(dataset, labels, decoded_word=False):\n","    entities_dict = {}\n","    \n","    for i, sentence in enumerate(dataset):\n","        for k, word in enumerate(sentence):\n","            tag = idx2tag[labels[i][k]]\n","            if tag[:2] == \"B-\":\n","                if decoded_word:\n","                    word_list = [idx2word[word]]\n","                else:\n","                    word_list = [word]\n","                j = k + 1\n","                if j < len(labels[i]):\n","                    while idx2tag[labels[i][j]][:2] == \"I-\":\n","                        if decoded_word:\n","                            word_list.append(idx2word[dataset[i][j]])\n","                        else:\n","                            word_list.append(dataset[i][j])\n","                        j = j+1\n","                        if j == len(labels[i]):\n","                            break\n","                        \n","                if entities_dict.get(tag):\n","                    if word_list not in entities_dict[tag]:\n","                        entities_dict[tag].append(word_list)\n","                else:\n","                    entities_dict[tag] = [word_list]\n","                    \n","    return entities_dict\n","\n","entities_dict = create_entities_dict(X_train, y_train)"],"id":"ux5-6tyMhovp"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2wRVTj71hovp"},"outputs":[],"source":["# Augmentation function using entity replacement technique.\n","# It will generate a new dataset, with X% more points based on\n","# the original dataset. E.g.: if you set augmentation percentage as 0.5 and dataset has\n","# 1000 points, it will generate a dataset with 1500 points.\n","\n","def generate_sentences(dataset, labels, entities_dict, augmented_set_size_percentage):\n","    if augmented_set_size_percentage < 0:\n","        raise Exception(\"Invalid augmented set size percentage\")\n","\n","    number_of_new_sentences = math.ceil(augmented_set_size_percentage * len(dataset))\n","    random_idxs = np.random.choice(len(dataset), number_of_new_sentences, replace=True)\n","    \n","    base_sequences = [dataset[i] for i in random_idxs]\n","    base_labels = [labels[i] for i in random_idxs]\n","\n","    new_sequences = []\n","    new_labels = []\n","    \n","    for k, sequence in enumerate(base_sequences):\n","        new_sequence = []\n","        new_label = []\n","\n","        for i, word in enumerate(sequence):\n","            tag = idx2tag[base_labels[k][i]]\n","            if tag == \"O\":\n","                new_sequence.append(word)\n","                new_label.append(base_labels[k][i])\n","            elif tag[:2] == \"B-\":\n","                same_entities_type_tmp = entities_dict[tag]\n","                same_entities_type = np.array(same_entities_type_tmp, dtype=object)\n","                random_entity_idx = np.random.choice(len(same_entities_type), 1)[0]\n","                random_entity = same_entities_type[random_entity_idx]\n","                random_number_of_tokens = random.randint(1, len(random_entity))\n","                random_entity_tokens = np.random.choice(random_entity, random_number_of_tokens, replace = False).tolist()\n","                entity = tag[2:]\n","                decoded_token_labels = [f\"I-{entity}\" for token in random_entity_tokens]\n","                decoded_token_labels[0] = tag\n","                encoded_token_labels = [tag2idx[label] for label in decoded_token_labels]\n","                new_sequence = new_sequence + random_entity_tokens\n","                new_label = new_label + encoded_token_labels\n","\n","        new_sequences.append(new_sequence)\n","        new_labels.append(new_label)\n","\n","    augmented_X_train = dataset + new_sequences\n","    augmented_y_train = labels + new_labels\n","\n","    print(f\"Points in X_train after augmentation: {len(augmented_X_train)}\")\n","    print(f\"Points in y_train after augmentation: {len(augmented_y_train)}\")\n","\n","    return augmented_X_train, augmented_y_train"],"id":"2wRVTj71hovp"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["7921b2377e57436a827f369ae031347a","94b7dd99132b4d1ab44e3b12d6a2d4d3","8a2e1dccef6d4d71a481b873a33f0161","d12aa2a13f874918b417325e7ed594ec","ad80db927f7e48379eab04846d7d42b9","69eeefd6fc774efa88a3dd3a687d688d","c30986658b024283908ed62e95da3161","d48f170a84404c2fa3da6b8acbae50c3","2a68fa1180974efa89a9b26928f4273c","43cc0bc690424ba2934143b11035fc52","8aa4ec30614c48909388baed3439533a","0e8e3788f303428fa68b3dac9fb9513e","0ecd11f19e854fc281e8091e0a7804a9","f8005be957004e94a640a31f74f364af","f609d3e5ca2b4731a8f952363f2e48ed","8c947bd0452e48cabefa9bfef59a1f04","af4f256bffc84ac08f222f23ce65c912","5137196c40d94440907d12dc4f43b402","7e53623b3ce34641af45879d4f018a69","baabfddf89054bc3a88f668d66c34830","78bc3e23e00f456fa29c7fe4c179e6fa","6aa58aec0ef64080961b47db1dd7a3e5"]},"executionInfo":{"elapsed":5359,"status":"ok","timestamp":1657554128830,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"mYHzTnzZZfBg","outputId":"a38b6f88-b5db-4499-e8d5-7c2820e584bb"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/385 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7921b2377e57436a827f369ae031347a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/223k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e8e3788f303428fa68b3dac9fb9513e"}},"metadata":{}}],"source":["tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n","\n","class dataset(Dataset):\n","  def __init__(self, dataframe, tokenizer, max_len):\n","        self.len = len(dataframe)\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","  def __getitem__(self, index):\n","        # step 1: get the sentence and word labels\n","        sentence = self.data.sentence[index]\n","        word_labels = self.data.word_labels[index].split(\",\") \n","\n","        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n","        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n","        encoding = self.tokenizer(sentence,\n","                             return_offsets_mapping=True, \n","                             padding='max_length', \n","                             truncation=True, \n","                             max_length=self.max_len)\n","        \n","        # step 3: create token labels only for first word pieces of each tokenized word\n","        labels = [tag2idx[label] for label in word_labels] \n","        # code based on https://huggingface.co/transformers/custom_datasets.html#tok-ner\n","        # create an empty array of -100 of length max_length\n","        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n","        \n","        # set only labels whose first offset position is 0 and the second is not 0\n","        i = 0\n","        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n","          if mapping[0] == 0 and mapping[1] != 0:\n","            # overwrite label\n","            encoded_labels[idx] = labels[i]\n","            i += 1\n","\n","        # step 4: turn everything into PyTorch tensors\n","        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n","        item['labels'] = torch.as_tensor(encoded_labels)\n","        \n","        return item\n","\n","  def __len__(self):\n","        return self.len"],"id":"mYHzTnzZZfBg"},{"cell_type":"code","execution_count":null,"metadata":{"id":"d8H1s-6b_-pM"},"outputs":[],"source":["# some configuration variables\n","LEARNING_RATE = 5e-05\n","MAX_GRAD_NORM = 10\n","TRAINING_STOP_LOSS_PERCENTAGE = 1\n","\n","# Model creation function\n","def create_model(maxlen, n_labels, training_set, testing_set, validation_set):\n","  device = 'cuda' if cuda.is_available() else 'cpu'\n","  print(\"Device: \", device)\n","\n","  model = BertForTokenClassification.from_pretrained('allenai/scibert_scivocab_uncased', num_labels=n_labels)\n","  model.to(device)\n","\n","  optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n","\n","  TRAIN_BATCH_SIZE = round(0.05*len(training_set))\n","  if TRAIN_BATCH_SIZE > 32:\n","    TRAIN_BATCH_SIZE = 32\n","  if TRAIN_BATCH_SIZE < 10:\n","    TRAIN_BATCH_SIZE = 10\n","\n","  VALID_BATCH_SIZE = round(0.1*len(validation_set))\n","  if VALID_BATCH_SIZE > 32:\n","    VALID_BATCH_SIZE = 32\n","  if VALID_BATCH_SIZE < 10:\n","    VALID_BATCH_SIZE = 10\n","\n","  train_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                  'shuffle': True,\n","                  'num_workers': 0\n","                  }\n","\n","  test_params = {'batch_size': VALID_BATCH_SIZE,\n","                  'shuffle': True,\n","                  'num_workers': 0\n","                  }\n","\n","  training_loader = DataLoader(training_set, **train_params)\n","  testing_loader = DataLoader(testing_set, **test_params)\n","  validation_loader = DataLoader(validation_set, **test_params)\n","\n","  return model, device, optimizer, training_loader, testing_loader, validation_loader"],"id":"d8H1s-6b_-pM"},{"cell_type":"code","execution_count":null,"metadata":{"id":"cjp-jXx4AmiV"},"outputs":[],"source":["# Model training function\n","def train(model, device, optimizer, training_loader, epoch, training_stop_loss_percentage):\n","    tr_loss, tr_accuracy = 0, 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","    tr_preds, tr_labels = [], []\n","    losses = []\n","    # put model in training mode\n","    model.train()\n","    \n","    for idx, batch in enumerate(training_loader):\n","        \n","        ids = batch['input_ids'].to(device, dtype = torch.long)\n","        mask = batch['attention_mask'].to(device, dtype = torch.long)\n","        labels = batch['labels'].to(device, dtype = torch.long)\n","\n","        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels, return_dict = False)\n","        tr_loss += loss.item()\n","\n","        nb_tr_steps += 1\n","        nb_tr_examples += labels.size(0)\n","        \n","        if idx % 100==0:\n","            loss_step = tr_loss/nb_tr_steps\n","            print(f\"Training loss per 100 training steps: {loss_step}\")\n","            losses.append(loss_step)\n","            last_5_losses = losses[-5:]\n","            loss_min = min(last_5_losses)\n","            loss_max = max(last_5_losses)\n","            if len(last_5_losses) > 1 and (loss_max - loss_min)/loss_max < training_stop_loss_percentage/100:\n","              print(\"Stopping epoch...\")\n","              break\n","           \n","        # compute training accuracy\n","        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","        \n","        # only compute accuracy at active labels\n","        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n","        \n","        labels = torch.masked_select(flattened_targets, active_accuracy)\n","        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","        \n","        tr_labels.extend(labels)\n","        tr_preds.extend(predictions)\n","\n","        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n","        tr_accuracy += tmp_tr_accuracy\n","    \n","        # gradient clipping\n","        torch.nn.utils.clip_grad_norm_(\n","            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n","        )\n","        \n","        # backward pass\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    epoch_loss = tr_loss / nb_tr_steps\n","    tr_accuracy = tr_accuracy / nb_tr_steps\n","    print(f\"Training loss epoch: {epoch_loss}\")\n","    print(f\"Training accuracy epoch: {tr_accuracy}\")"],"id":"cjp-jXx4AmiV"},{"cell_type":"code","execution_count":null,"metadata":{"id":"JvdztU6FA8Bd"},"outputs":[],"source":["# Model testing function\n","def test(model, device, testing_loader):\n","    print(\"Validating model...\")\n","    # put model in evaluation mode\n","    model.eval()\n","    \n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_examples, nb_eval_steps = 0, 0\n","    eval_preds, eval_labels = [], []\n","    \n","    with torch.no_grad():\n","        for idx, batch in enumerate(testing_loader):\n","            \n","            ids = batch['input_ids'].to(device, dtype = torch.long)\n","            mask = batch['attention_mask'].to(device, dtype = torch.long)\n","            labels = batch['labels'].to(device, dtype = torch.long)\n","            \n","            loss, eval_logits = model(input_ids=ids, attention_mask=mask, labels=labels, return_dict = False)\n","            \n","            eval_loss += loss.item()\n","\n","            nb_eval_steps += 1\n","            nb_eval_examples += labels.size(0)\n","        \n","            # compute evaluation accuracy\n","            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","            \n","            # only compute accuracy at active labels\n","            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","        \n","            labels = torch.masked_select(flattened_targets, active_accuracy)\n","            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","            \n","            eval_labels.extend(labels)\n","            eval_preds.extend(predictions)\n","            \n","            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n","            eval_accuracy += tmp_eval_accuracy\n","\n","    labels = [idx2tag[id.item()] for id in eval_labels]\n","    predictions = [idx2tag[id.item()] for id in eval_preds]\n","    \n","    eval_loss = eval_loss / nb_eval_steps\n","    eval_accuracy = eval_accuracy / nb_eval_steps\n","    print(f\"Validation Loss: {eval_loss}\")\n","    print(f\"Validation Accuracy: {eval_accuracy}\")\n","\n","    return labels, predictions, eval_loss"],"id":"JvdztU6FA8Bd"},{"cell_type":"code","execution_count":null,"metadata":{"id":"jMknjbDrh6Fk"},"outputs":[],"source":["def create_train_and_validate_model(augmented_percentage):\n","\n","  augmented_X_train, augmented_y_train = generate_sentences(X_train, y_train, entities_dict, augmented_percentage)\n","\n","  maxlen_X_train = max([len(s) for s in augmented_X_train])\n","  maxlen_X_test = max([len(s) for s in X_test])\n","  maxlen_X_dev = max([len(s) for s in X_dev])\n","  maxlen_y_train = max([len(s) for s in augmented_y_train])\n","  maxlen_y_test = max([len(s) for s in y_test])\n","  maxlen_y_dev = max([len(s) for s in y_dev])\n","\n","  maxlen = max([maxlen_X_train, maxlen_X_test, maxlen_X_dev, maxlen_y_train, maxlen_y_test, maxlen_y_dev])\n","\n","  augmented_X_train_words = [' '.join([idx2word[word] for word in sentence]) for sentence in augmented_X_train]\n","  X_dev_words = [' '.join([idx2word[word] for word in sentence]) for sentence in X_dev]\n","  X_test_words = [' '.join([idx2word[word] for word in sentence]) for sentence in X_test]\n","  augmented_y_train_tags = [','.join([idx2tag[tag] for tag in sentence]) for sentence in augmented_y_train]\n","  y_dev_tags = [','.join([idx2tag[tag] for tag in sentence]) for sentence in y_dev]\n","  y_test_tags = [','.join([idx2tag[tag] for tag in sentence]) for sentence in y_test]\n","\n","  new_train_df = pd.DataFrame({\"sentence\": augmented_X_train_words, \"word_labels\": augmented_y_train_tags}).reset_index(drop=True)\n","  new_test_df = pd.DataFrame({\"sentence\": X_test_words, \"word_labels\": y_test_tags}).reset_index(drop=True)\n","  new_val_df = pd.DataFrame({\"sentence\": X_dev_words, \"word_labels\": y_dev_tags}).reset_index(drop=True)\n","\n","  training_set = dataset(new_train_df, tokenizer, maxlen)\n","  testing_set = dataset(new_test_df, tokenizer, maxlen)\n","  validation_set = dataset(new_val_df, tokenizer, maxlen)\n","\n","  model, device, optimizer, training_loader, testing_loader, val_loader = create_model(maxlen, len(tag2idx), training_set, testing_set, validation_set)\n","\n","  training_start_time = time.clock()\n","  min_val_loss = 0\n","  MAX_PATIENCE = 5\n","  patience = 0\n","\n","  for epoch in range(100):\n","    print(f\"Training epoch: {epoch + 1}\")\n","    if patience == MAX_PATIENCE:\n","      print(\"Patience limit reached\")\n","      break\n","    train(model, device, optimizer, training_loader, epoch, TRAINING_STOP_LOSS_PERCENTAGE)\n","    labels, predictions, val_loss = test(model, device, val_loader)\n","    if ((min_val_loss == 0) or (min_val_loss != 0 and val_loss < min_val_loss)):\n","      min_val_loss = val_loss\n","      torch.save(model.state_dict(), 'checkpoint.pt')\n","      patience = 0\n","    else:\n","      patience = patience + 1\n","  print(f\"Training duration: {(time.clock() - training_start_time)/60} minutes\")\n","\n","  checkpoint = torch.load('checkpoint.pt')\n","  model.load_state_dict(checkpoint)\n","\n","  validation_start_time = time.clock()\n","  labels, predictions, test_loss = test(model, device, testing_loader)\n","  labels = [labels]\n","  predictions = [predictions]\n","  print(f\"Validation duration: {(time.clock() - validation_start_time)/60} minutes\")\n","\n","  print(\"F1-score (test): {:.1%}\".format(f1_score(labels, predictions)))\n","  print(classification_report(labels, predictions))"],"id":"jMknjbDrh6Fk"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4360803,"status":"ok","timestamp":1657331983470,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"bM0wPLD5kaw4","outputId":"a3b61438-df91-47ec-be5f-2e351dcf2ba2"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 6526\n","Points in y_train after augmentation: 6526\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.5472992658615112\n","Training loss per 100 training steps: 0.2576896172791424\n","Training loss epoch: 0.2558382947509195\n","Training accuracy epoch: 0.9180404016445288\n","Validating model...\n","Validation Loss: 0.17268144974813743\n","Validation Accuracy: 0.9457623327108621\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09694258868694305\n","Training loss per 100 training steps: 0.07202090736994944\n","Training loss epoch: 0.07197994323374302\n","Training accuracy epoch: 0.979463156230234\n","Validating model...\n","Validation Loss: 0.14471593641621225\n","Validation Accuracy: 0.9586348428260192\n","Training epoch: 3\n","Training loss per 100 training steps: 0.027650577947497368\n","Training loss per 100 training steps: 0.03619511823266708\n","Training loss epoch: 0.036681475659932794\n","Training accuracy epoch: 0.9874288425047438\n","Validating model...\n","Validation Loss: 0.16666445892998108\n","Validation Accuracy: 0.9570981170245876\n","Training epoch: 4\n","Training loss per 100 training steps: 0.008092748932540417\n","Training loss per 100 training steps: 0.021990534384956233\n","Training loss epoch: 0.021985423336873818\n","Training accuracy epoch: 0.9931066176470589\n","Validating model...\n","Validation Loss: 0.17360856732143565\n","Validation Accuracy: 0.9598457438530968\n","Training epoch: 5\n","Training loss per 100 training steps: 0.04628928005695343\n","Training loss per 100 training steps: 0.01941655217877377\n","Training loss epoch: 0.019245759660478534\n","Training accuracy epoch: 0.9938725490196079\n","Validating model...\n","Validation Loss: 0.17193562703608883\n","Validation Accuracy: 0.9626079598506069\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0020637703128159046\n","Training loss per 100 training steps: 0.011597287425331053\n","Training loss epoch: 0.011502747183412258\n","Training accuracy epoch: 0.9960171568627451\n","Validating model...\n","Validation Loss: 0.20309388175933146\n","Validation Accuracy: 0.9595345082477434\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0008327745017595589\n","Training loss per 100 training steps: 0.007896544765346767\n","Training loss epoch: 0.007827961648182086\n","Training accuracy epoch: 0.9973958333333334\n","Validating model...\n","Validation Loss: 0.20116938545834273\n","Validation Accuracy: 0.9610809601618425\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 10.098231083333333 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14249752483899808\n","Validation Accuracy: 0.9578587257226738\n","Validation duration: 2.1056850000000016 minutes\n","F1-score (test): 85.7%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.85      0.79      0.82      1170\n","        test       0.89      0.87      0.88      2464\n","   treatment       0.84      0.84      0.84      1244\n","\n","   micro avg       0.87      0.84      0.86      4878\n","   macro avg       0.86      0.83      0.85      4878\n","weighted avg       0.87      0.84      0.86      4878\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 6526\n","Points in y_train after augmentation: 6526\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.6264286041259766\n","Training loss per 100 training steps: 0.25258289406647777\n","Training loss epoch: 0.250528451274423\n","Training accuracy epoch: 0.9243210388994307\n","Validating model...\n","Validation Loss: 0.14181587914479712\n","Validation Accuracy: 0.9580172346716465\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06873596459627151\n","Training loss per 100 training steps: 0.07255953678510862\n","Training loss epoch: 0.0733698744819883\n","Training accuracy epoch: 0.9785292141049968\n","Validating model...\n","Validation Loss: 0.14192735496908426\n","Validation Accuracy: 0.9595393713040772\n","Training epoch: 3\n","Training loss per 100 training steps: 0.039092060178518295\n","Training loss per 100 training steps: 0.03484917260328363\n","Training loss epoch: 0.034678343078578075\n","Training accuracy epoch: 0.9894301470588235\n","Validating model...\n","Validation Loss: 0.16514976686505856\n","Validation Accuracy: 0.9552647447868036\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01633344776928425\n","Training loss per 100 training steps: 0.024348800156454527\n","Training loss epoch: 0.02413419402243259\n","Training accuracy epoch: 0.9937193627450981\n","Validating model...\n","Validation Loss: 0.15993915154945618\n","Validation Accuracy: 0.9580172346716465\n","Training epoch: 5\n","Training loss per 100 training steps: 0.015523345209658146\n","Training loss per 100 training steps: 0.016206227850381026\n","Training loss epoch: 0.016655488212492464\n","Training accuracy epoch: 0.9955526565464896\n","Validating model...\n","Validation Loss: 0.24315096808633968\n","Validation Accuracy: 0.9540343915343915\n","Training epoch: 6\n","Training loss per 100 training steps: 0.010599867440760136\n","Training loss per 100 training steps: 0.012502694032777395\n","Training loss epoch: 0.012442377401063876\n","Training accuracy epoch: 0.9963235294117647\n","Validating model...\n","Validation Loss: 0.269373376287666\n","Validation Accuracy: 0.9503579209461562\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 8.548081866666667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1404856385779567\n","Validation Accuracy: 0.9566333912037037\n","Validation duration: 2.074618183333333 minutes\n","F1-score (test): 85.6%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.85      0.75      0.80      1170\n","        test       0.88      0.87      0.88      2464\n","   treatment       0.89      0.84      0.86      1244\n","\n","   micro avg       0.88      0.84      0.86      4878\n","   macro avg       0.87      0.82      0.85      4878\n","weighted avg       0.88      0.84      0.86      4878\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 6526\n","Points in y_train after augmentation: 6526\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0686216354370117\n","Training loss per 100 training steps: 0.26163511210591484\n","Training loss epoch: 0.26172768379397254\n","Training accuracy epoch: 0.9172645872865275\n","Validating model...\n","Validation Loss: 0.14910155348479748\n","Validation Accuracy: 0.9546519996887644\n","Training epoch: 2\n","Training loss per 100 training steps: 0.034762199968099594\n","Training loss per 100 training steps: 0.08612987835255295\n","Training loss epoch: 0.08563569609039262\n","Training accuracy epoch: 0.9728810879190386\n","Validating model...\n","Validation Loss: 0.14801860757756466\n","Validation Accuracy: 0.9598651960784313\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0073192850686609745\n","Training loss per 100 training steps: 0.03338759003603591\n","Training loss epoch: 0.03313411780696947\n","Training accuracy epoch: 0.9911151960784313\n","Validating model...\n","Validation Loss: 0.1670511820805533\n","Validation Accuracy: 0.9598457438530968\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0021447744220495224\n","Training loss per 100 training steps: 0.019784482358493796\n","Training loss epoch: 0.01973778004506968\n","Training accuracy epoch: 0.994480352624921\n","Validating model...\n","Validation Loss: 0.1729190965256124\n","Validation Accuracy: 0.9623113134142546\n","Training epoch: 5\n","Training loss per 100 training steps: 0.044246189296245575\n","Training loss per 100 training steps: 0.015801061275023228\n","Training loss epoch: 0.01573243038557634\n","Training accuracy epoch: 0.9957107843137255\n","Validating model...\n","Validation Loss: 0.22704790265975044\n","Validation Accuracy: 0.9530909586056644\n","Training epoch: 6\n","Training loss per 100 training steps: 0.059480153024196625\n","Training loss per 100 training steps: 0.014479584270099289\n","Training loss epoch: 0.014440959937786045\n","Training accuracy epoch: 0.9966299019607843\n","Validating model...\n","Validation Loss: 0.17802853315301678\n","Validation Accuracy: 0.95802209772798\n","Training epoch: 7\n","Training loss per 100 training steps: 0.002038156148046255\n","Training loss per 100 training steps: 0.020975758514648286\n","Training loss epoch: 0.02097994032459717\n","Training accuracy epoch: 0.9943321078431373\n","Validating model...\n","Validation Loss: 0.1858565664996265\n","Validation Accuracy: 0.956490234982882\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 9.956536266666667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14553819422629508\n","Validation Accuracy: 0.9588917471205962\n","Validation duration: 2.077405550000003 minutes\n","F1-score (test): 86.3%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.86      0.80      0.83      1170\n","        test       0.86      0.91      0.89      2464\n","   treatment       0.82      0.87      0.84      1244\n","\n","   micro avg       0.85      0.87      0.86      4878\n","   macro avg       0.85      0.86      0.85      4878\n","weighted avg       0.85      0.87      0.86      4878\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 6526\n","Points in y_train after augmentation: 6526\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9806544780731201\n","Training loss per 100 training steps: 0.2508576419388894\n","Training loss epoch: 0.24979038463503705\n","Training accuracy epoch: 0.9223246758380772\n","Validating model...\n","Validation Loss: 0.14174688205707306\n","Validation Accuracy: 0.9583284702769996\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05268276482820511\n","Training loss per 100 training steps: 0.07330047230854041\n","Training loss epoch: 0.07296106060875543\n","Training accuracy epoch: 0.9760979996837444\n","Validating model...\n","Validation Loss: 0.14900159054234915\n","Validation Accuracy: 0.9580075085589792\n","Training epoch: 3\n","Training loss per 100 training steps: 0.008640672080218792\n","Training loss per 100 training steps: 0.03638686605736079\n","Training loss epoch: 0.036616679873915536\n","Training accuracy epoch: 0.988965646742568\n","Validating model...\n","Validation Loss: 0.14058949377424285\n","Validation Accuracy: 0.9638285869903517\n","Training epoch: 4\n","Training loss per 100 training steps: 0.011371800675988197\n","Training loss per 100 training steps: 0.025309650924766787\n","Training loss epoch: 0.02507851806277519\n","Training accuracy epoch: 0.9911151960784313\n","Validating model...\n","Validation Loss: 0.17617494625258534\n","Validation Accuracy: 0.9595539604730781\n","Training epoch: 5\n","Training loss per 100 training steps: 0.003288495587185025\n","Training loss per 100 training steps: 0.015599368316741512\n","Training loss epoch: 0.015457220768439583\n","Training accuracy epoch: 0.9957107843137255\n","Validating model...\n","Validation Loss: 0.20900251671178816\n","Validation Accuracy: 0.958323607220666\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0024457783438265324\n","Training loss per 100 training steps: 0.014292699207625546\n","Training loss epoch: 0.014226808592759292\n","Training accuracy epoch: 0.9954044117647058\n","Validating model...\n","Validation Loss: 0.22284145817142345\n","Validation Accuracy: 0.954943783068783\n","Training epoch: 7\n","Training loss per 100 training steps: 0.03854025900363922\n","Training loss per 100 training steps: 0.019346372243408853\n","Training loss epoch: 0.019218260614662523\n","Training accuracy epoch: 0.9947916666666666\n","Validating model...\n","Validation Loss: 0.21354165776888384\n","Validation Accuracy: 0.9549583722377839\n","Training epoch: 8\n","Training loss per 100 training steps: 0.009753180667757988\n","Training loss per 100 training steps: 0.011309452146570668\n","Training loss epoch: 0.011225011787781328\n","Training accuracy epoch: 0.9967830882352942\n","Validating model...\n","Validation Loss: 0.20925740095987624\n","Validation Accuracy: 0.9577157251789604\n","Training epoch: 9\n","Patience limit reached\n","Training duration: 11.402457883333334 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15124184692588946\n","Validation Accuracy: 0.9578948947041553\n","Validation duration: 2.0854041499999996 minutes\n","F1-score (test): 85.5%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.84      0.80      0.82      1170\n","        test       0.83      0.92      0.88      2464\n","   treatment       0.89      0.80      0.84      1244\n","\n","   micro avg       0.85      0.86      0.86      4878\n","   macro avg       0.86      0.84      0.85      4878\n","weighted avg       0.85      0.86      0.85      4878\n","\n","!!!!!! Starting model number 5 !!!!!!\n","Points in X_train after augmentation: 6526\n","Points in y_train after augmentation: 6526\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.5070831775665283\n","Training loss per 100 training steps: 0.2763786874342673\n","Training loss epoch: 0.27558945535736923\n","Training accuracy epoch: 0.9155795382669197\n","Validating model...\n","Validation Loss: 0.13764326628662793\n","Validation Accuracy: 0.9574044895736072\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05789453908801079\n","Training loss per 100 training steps: 0.07826314221071724\n","Training loss epoch: 0.0776673530721489\n","Training accuracy epoch: 0.9779411764705882\n","Validating model...\n","Validation Loss: 0.15566442125276023\n","Validation Accuracy: 0.9558677637721754\n","Training epoch: 3\n","Training loss per 100 training steps: 0.015175750479102135\n","Training loss per 100 training steps: 0.031532539552686235\n","Training loss epoch: 0.031638266628279406\n","Training accuracy epoch: 0.9898847643896268\n","Validating model...\n","Validation Loss: 0.19107356561146968\n","Validation Accuracy: 0.9567820183629007\n","Training epoch: 4\n","Training loss per 100 training steps: 0.07942268252372742\n","Training loss per 100 training steps: 0.021504135960874398\n","Training loss epoch: 0.021300661575628956\n","Training accuracy epoch: 0.9935661764705882\n","Validating model...\n","Validation Loss: 0.225236580561043\n","Validation Accuracy: 0.954943783068783\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0015682566445320845\n","Training loss per 100 training steps: 0.016389338069106682\n","Training loss epoch: 0.01632918977160372\n","Training accuracy epoch: 0.9950980392156863\n","Validating model...\n","Validation Loss: 0.21964390087397953\n","Validation Accuracy: 0.9543456271397447\n","Training epoch: 6\n","Training loss per 100 training steps: 0.005363510921597481\n","Training loss per 100 training steps: 0.011921341635867732\n","Training loss epoch: 0.011831177125785354\n","Training accuracy epoch: 0.9964767156862745\n","Validating model...\n","Validation Loss: 0.21588250877239795\n","Validation Accuracy: 0.9583333333333334\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 8.542218133333336 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13333109004371282\n","Validation Accuracy: 0.9587832401761518\n","Validation duration: 2.0767467166666695 minutes\n","F1-score (test): 86.4%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.94      0.70      0.80      1170\n","        test       0.89      0.88      0.88      2464\n","   treatment       0.90      0.85      0.88      1244\n","\n","   micro avg       0.90      0.83      0.86      4878\n","   macro avg       0.91      0.81      0.85      4878\n","weighted avg       0.91      0.83      0.86      4878\n","\n","!!!!!! Starting model number 6 !!!!!!\n","Points in X_train after augmentation: 6526\n","Points in y_train after augmentation: 6526\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.344062328338623\n","Training loss per 100 training steps: 0.262694203506897\n","Training loss epoch: 0.26170669908763144\n","Training accuracy epoch: 0.9157327245414295\n","Validating model...\n","Validation Loss: 0.18019822519272566\n","Validation Accuracy: 0.9463702147525677\n","Training epoch: 2\n","Training loss per 100 training steps: 0.12048400938510895\n","Training loss per 100 training steps: 0.07966356872959007\n","Training loss epoch: 0.08021356582678124\n","Training accuracy epoch: 0.9776249209361164\n","Validating model...\n","Validation Loss: 0.15722193117892624\n","Validation Accuracy: 0.9595442343604108\n","Training epoch: 3\n","Training loss per 100 training steps: 0.016070561483502388\n","Training loss per 100 training steps: 0.035719465730610384\n","Training loss epoch: 0.03632638845295992\n","Training accuracy epoch: 0.9891188330170778\n","Validating model...\n","Validation Loss: 0.1698406242272433\n","Validation Accuracy: 0.9580123716153127\n","Training epoch: 4\n","Training loss per 100 training steps: 0.011630849912762642\n","Training loss per 100 training steps: 0.025618850806783333\n","Training loss epoch: 0.025743406183798525\n","Training accuracy epoch: 0.9918761859582542\n","Validating model...\n","Validation Loss: 0.19024323974165372\n","Validation Accuracy: 0.957093253968254\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0036495777312666178\n","Training loss per 100 training steps: 0.01904047791624792\n","Training loss epoch: 0.01888901609973069\n","Training accuracy epoch: 0.9947916666666666\n","Validating model...\n","Validation Loss: 0.1821070924337369\n","Validation Accuracy: 0.9592427248677249\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0022350940853357315\n","Training loss per 100 training steps: 0.01262404280685875\n","Training loss epoch: 0.01252060919953282\n","Training accuracy epoch: 0.9960171568627451\n","Validating model...\n","Validation Loss: 0.2116178618629883\n","Validation Accuracy: 0.9592378618113911\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0005635249544866383\n","Training loss per 100 training steps: 0.017059977067228737\n","Training loss epoch: 0.01695147177487539\n","Training accuracy epoch: 0.9947916666666666\n","Validating model...\n","Validation Loss: 0.19640996968191043\n","Validation Accuracy: 0.96015697945845\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 9.997753466666662 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.146006720869789\n","Validation Accuracy: 0.9624001383242999\n","Validation duration: 2.080356150000004 minutes\n","F1-score (test): 87.2%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.88      0.80      0.84      1170\n","        test       0.92      0.87      0.89      2464\n","   treatment       0.84      0.89      0.86      1244\n","\n","   micro avg       0.89      0.86      0.87      4878\n","   macro avg       0.88      0.85      0.86      4878\n","weighted avg       0.89      0.86      0.87      4878\n","\n","!!!!!! Starting model number 7 !!!!!!\n","Points in X_train after augmentation: 6526\n","Points in y_train after augmentation: 6526\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0955326557159424\n","Training loss per 100 training steps: 0.25123735187151053\n","Training loss epoch: 0.249504285864532\n","Training accuracy epoch: 0.9217168722327641\n","Validating model...\n","Validation Loss: 0.15263031649531103\n","Validation Accuracy: 0.9528137643946467\n","Training epoch: 2\n","Training loss per 100 training steps: 0.13879041373729706\n","Training loss per 100 training steps: 0.07675879227808945\n","Training loss epoch: 0.07614613901002004\n","Training accuracy epoch: 0.9767156862745098\n","Validating model...\n","Validation Loss: 0.14553258249846598\n","Validation Accuracy: 0.9616839791472145\n","Training epoch: 3\n","Training loss per 100 training steps: 0.01068821456283331\n","Training loss per 100 training steps: 0.031082624830028945\n","Training loss epoch: 0.03111455693850111\n","Training accuracy epoch: 0.9911102545857052\n","Validating model...\n","Validation Loss: 0.17887569294429803\n","Validation Accuracy: 0.9595442343604108\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0033591855317354202\n","Training loss per 100 training steps: 0.021396673077574497\n","Training loss epoch: 0.021234602663396655\n","Training accuracy epoch: 0.9947916666666666\n","Validating model...\n","Validation Loss: 0.17208546064976676\n","Validation Accuracy: 0.9601618425147836\n","Training epoch: 5\n","Training loss per 100 training steps: 0.015089592896401882\n","Training loss per 100 training steps: 0.02038297844511263\n","Training loss epoch: 0.020372439978196853\n","Training accuracy epoch: 0.993714421252372\n","Validating model...\n","Validation Loss: 0.20183799516263545\n","Validation Accuracy: 0.9552550186741362\n","Training epoch: 6\n","Training loss per 100 training steps: 0.009443677961826324\n","Training loss per 100 training steps: 0.01840686855669419\n","Training loss epoch: 0.01824386734755107\n","Training accuracy epoch: 0.9952512254901961\n","Validating model...\n","Validation Loss: 0.18975005631435515\n","Validation Accuracy: 0.9604682150638033\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0031380567234009504\n","Training loss per 100 training steps: 0.013566796928943864\n","Training loss epoch: 0.01344568696610319\n","Training accuracy epoch: 0.9963235294117647\n","Validating model...\n","Validation Loss: 0.1901249535354402\n","Validation Accuracy: 0.9586299797696857\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 9.989777599999995 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1349391825545657\n","Validation Accuracy: 0.9610213061766034\n","Validation duration: 2.075448233333342 minutes\n","F1-score (test): 86.9%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.87      0.81      0.84      1170\n","        test       0.89      0.88      0.89      2464\n","   treatment       0.89      0.83      0.86      1244\n","\n","   micro avg       0.89      0.85      0.87      4878\n","   macro avg       0.89      0.84      0.86      4878\n","weighted avg       0.89      0.85      0.87      4878\n","\n","!!!!!! Starting model number 8 !!!!!!\n","Points in X_train after augmentation: 6526\n","Points in y_train after augmentation: 6526\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1023106575012207\n","Training loss per 100 training steps: 0.2725883689847323\n","Training loss epoch: 0.271432464613634\n","Training accuracy epoch: 0.9186333807716636\n","Validating model...\n","Validation Loss: 0.1405995374216753\n","Validation Accuracy: 0.9571078431372549\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06602204591035843\n","Training loss per 100 training steps: 0.07829760416125012\n","Training loss epoch: 0.07819371527133911\n","Training accuracy epoch: 0.9760979996837444\n","Validating model...\n","Validation Loss: 0.13352158709483988\n","Validation Accuracy: 0.9604584889511361\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0616203211247921\n","Training loss per 100 training steps: 0.03281061614905069\n","Training loss epoch: 0.03351205242135763\n","Training accuracy epoch: 0.988807518975332\n","Validating model...\n","Validation Loss: 0.16180043061510385\n","Validation Accuracy: 0.961085823218176\n","Training epoch: 4\n","Training loss per 100 training steps: 0.005488694179803133\n","Training loss per 100 training steps: 0.02029077176178695\n","Training loss epoch: 0.020138551494478723\n","Training accuracy epoch: 0.9944852941176471\n","Validating model...\n","Validation Loss: 0.1780489536353807\n","Validation Accuracy: 0.9613873327108621\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0016236689407378435\n","Training loss per 100 training steps: 0.014669012899296174\n","Training loss epoch: 0.014642904488331018\n","Training accuracy epoch: 0.9957107843137255\n","Validating model...\n","Validation Loss: 0.19271675892649034\n","Validation Accuracy: 0.9598506069094304\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0006072911783121526\n","Training loss per 100 training steps: 0.007756049875896147\n","Training loss epoch: 0.008741555965731522\n","Training accuracy epoch: 0.9973908918406073\n","Validating model...\n","Validation Loss: 0.243511204849746\n","Validation Accuracy: 0.9552647447868036\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0026218220591545105\n","Training loss per 100 training steps: 0.026480689831250948\n","Training loss epoch: 0.026267260625472237\n","Training accuracy epoch: 0.9921875\n","Validating model...\n","Validation Loss: 0.1960869776632856\n","Validation Accuracy: 0.9570981170245876\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 10.025813450000003 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13068692770536505\n","Validation Accuracy: 0.9591652199074074\n","Validation duration: 2.093727033333319 minutes\n","F1-score (test): 86.1%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.84      0.80      0.82      1170\n","        test       0.90      0.86      0.88      2464\n","   treatment       0.85      0.86      0.86      1244\n","\n","   micro avg       0.87      0.85      0.86      4878\n","   macro avg       0.86      0.84      0.85      4878\n","weighted avg       0.87      0.85      0.86      4878\n","\n","!!!!!! Starting model number 9 !!!!!!\n","Points in X_train after augmentation: 6526\n","Points in y_train after augmentation: 6526\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0642900466918945\n","Training loss per 100 training steps: 0.2596202460071533\n","Training loss epoch: 0.25807917459557456\n","Training accuracy epoch: 0.915431293485136\n","Validating model...\n","Validation Loss: 0.15116904917008736\n","Validation Accuracy: 0.9515785480859009\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07243241369724274\n","Training loss per 100 training steps: 0.07774305925474014\n","Training loss epoch: 0.0782087743921461\n","Training accuracy epoch: 0.9753271268184693\n","Validating model...\n","Validation Loss: 0.15332710913692912\n","Validation Accuracy: 0.9598603330220976\n","Training epoch: 3\n","Training loss per 100 training steps: 0.014017241075634956\n","Training loss per 100 training steps: 0.03315569349048235\n","Training loss epoch: 0.0333502707824878\n","Training accuracy epoch: 0.9895783918406073\n","Validating model...\n","Validation Loss: 0.20774333960577554\n","Validation Accuracy: 0.9527991752256458\n","Training epoch: 4\n","Training loss per 100 training steps: 0.1403602957725525\n","Training loss per 100 training steps: 0.022176430097292407\n","Training loss epoch: 0.02202345327446785\n","Training accuracy epoch: 0.9937193627450981\n","Validating model...\n","Validation Loss: 0.21771478056268512\n","Validation Accuracy: 0.9555613912231559\n","Training epoch: 5\n","Training loss per 100 training steps: 0.002096497919410467\n","Training loss per 100 training steps: 0.015706230837293892\n","Training loss epoch: 0.015598416485362594\n","Training accuracy epoch: 0.9954044117647058\n","Validating model...\n","Validation Loss: 0.19276754306081464\n","Validation Accuracy: 0.9592329987550576\n","Training epoch: 6\n","Training loss per 100 training steps: 0.003940054215490818\n","Training loss per 100 training steps: 0.01353924681540892\n","Training loss epoch: 0.013686765265518654\n","Training accuracy epoch: 0.9961654016445288\n","Validating model...\n","Validation Loss: 0.2506781386978486\n","Validation Accuracy: 0.9473039215686274\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 8.548980183333333 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14011120258537293\n","Validation Accuracy: 0.9548002413617886\n","Validation duration: 2.082720116666663 minutes\n","F1-score (test): 84.8%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.88      0.71      0.78      1170\n","        test       0.91      0.85      0.88      2464\n","   treatment       0.92      0.77      0.84      1244\n","\n","   micro avg       0.91      0.79      0.85      4878\n","   macro avg       0.91      0.78      0.83      4878\n","weighted avg       0.91      0.79      0.85      4878\n","\n","!!!!!! Starting model number 10 !!!!!!\n","Points in X_train after augmentation: 6526\n","Points in y_train after augmentation: 6526\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.073638439178467\n","Training loss per 100 training steps: 0.2754079880985883\n","Training loss epoch: 0.2745455725520265\n","Training accuracy epoch: 0.9146604206198609\n","Validating model...\n","Validation Loss: 0.14502547918727585\n","Validation Accuracy: 0.9540295284780578\n","Training epoch: 2\n","Training loss per 100 training steps: 0.048184338957071304\n","Training loss per 100 training steps: 0.06914006563198596\n","Training loss epoch: 0.06862663487246369\n","Training accuracy epoch: 0.9774816176470589\n","Validating model...\n","Validation Loss: 0.14152771848089554\n","Validation Accuracy: 0.9580172346716465\n","Training epoch: 3\n","Training loss per 100 training steps: 0.07994571328163147\n","Training loss per 100 training steps: 0.04120034442080351\n","Training loss epoch: 0.0426898498393997\n","Training accuracy epoch: 0.9891138915243517\n","Validating model...\n","Validation Loss: 0.200281081429007\n","Validation Accuracy: 0.9595490974167444\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0019734071101993322\n","Training loss per 100 training steps: 0.030522336809905154\n","Training loss epoch: 0.03036488411381987\n","Training accuracy epoch: 0.9918811274509803\n","Validating model...\n","Validation Loss: 0.1653110783994563\n","Validation Accuracy: 0.9561692732648615\n","Training epoch: 5\n","Training loss per 100 training steps: 0.004540801513940096\n","Training loss per 100 training steps: 0.01695710823624533\n","Training loss epoch: 0.016848824663183597\n","Training accuracy epoch: 0.9941789215686274\n","Validating model...\n","Validation Loss: 0.18629416871322868\n","Validation Accuracy: 0.9531152738873327\n","Training epoch: 6\n","Training loss per 100 training steps: 0.012129315175116062\n","Training loss per 100 training steps: 0.0195501451173078\n","Training loss epoch: 0.0193785334841403\n","Training accuracy epoch: 0.9938725490196079\n","Validating model...\n","Validation Loss: 0.1931989235077601\n","Validation Accuracy: 0.9616937052598817\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0024098572321236134\n","Training loss per 100 training steps: 0.012012380448465079\n","Training loss epoch: 0.011904228299481831\n","Training accuracy epoch: 0.9973958333333334\n","Validating model...\n","Validation Loss: 0.21928040512013433\n","Validation Accuracy: 0.958323607220666\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 9.993743983333342 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13286373920898228\n","Validation Accuracy: 0.9593010741305329\n","Validation duration: 2.076219416666663 minutes\n","F1-score (test): 86.3%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.79      0.84      0.82      1170\n","        test       0.91      0.87      0.89      2464\n","   treatment       0.88      0.85      0.86      1244\n","\n","   micro avg       0.87      0.86      0.86      4878\n","   macro avg       0.86      0.85      0.85      4878\n","weighted avg       0.87      0.86      0.86      4878\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"bM0wPLD5kaw4"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9283417,"status":"ok","timestamp":1657364839149,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"Jhz9BiIwGCsV","outputId":"8d0918e4-d3bf-4e42-ee4e-245c952592c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 25.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 8158\n","Points in y_train after augmentation: 8158\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.736918568611145\n","Training loss per 100 training steps: 0.339573764915366\n","Training loss per 100 training steps: 0.2664940763793107\n","Training loss epoch: 0.24376236354822622\n","Training accuracy epoch: 0.9251143790849673\n","Validating model...\n","Validation Loss: 0.1366872096037054\n","Validation Accuracy: 0.9580071948134092\n","Training epoch: 2\n","Training loss per 100 training steps: 0.251456618309021\n","Training loss per 100 training steps: 0.06398835773625881\n","Training loss per 100 training steps: 0.06568795112853601\n","Training loss epoch: 0.07484928441882206\n","Training accuracy epoch: 0.9764705882352941\n","Validating model...\n","Validation Loss: 0.15920512477739476\n","Validation Accuracy: 0.9546173308032891\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02995237335562706\n","Training loss per 100 training steps: 0.036911144484950247\n","Training loss per 100 training steps: 0.03303452339793662\n","Training loss epoch: 0.038380116211277814\n","Training accuracy epoch: 0.9873774509803922\n","Validating model...\n","Validation Loss: 0.16563143186024665\n","Validation Accuracy: 0.9577107052498419\n","Training epoch: 4\n","Training loss per 100 training steps: 0.009354477748274803\n","Training loss per 100 training steps: 0.024373617757452965\n","Training loss per 100 training steps: 0.019370945728634743\n","Training loss epoch: 0.023716418690552625\n","Training accuracy epoch: 0.9935049019607843\n","Validating model...\n","Validation Loss: 0.18277050391399968\n","Validation Accuracy: 0.9543406072106262\n","Training epoch: 5\n","Training loss per 100 training steps: 0.011268412694334984\n","Training loss per 100 training steps: 0.007263579105873048\n","Training loss per 100 training steps: 0.016322746720143007\n","Training loss epoch: 0.019296502215244496\n","Training accuracy epoch: 0.9949754901960784\n","Validating model...\n","Validation Loss: 0.22024757474291085\n","Validation Accuracy: 0.9561788425047438\n","Training epoch: 6\n","Training loss per 100 training steps: 0.001415024045854807\n","Training loss per 100 training steps: 0.02822262296247951\n","Training loss per 100 training steps: 0.03102894198057932\n","Training loss epoch: 0.028162641247663666\n","Training accuracy epoch: 0.9911764705882353\n","Validating model...\n","Validation Loss: 0.2500747115151242\n","Validation Accuracy: 0.9534214895635674\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 12.056935433333333 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14432545940750666\n","Validation Accuracy: 0.9567780671296297\n","Validation duration: 2.30253585 minutes\n","F1-score (test): 85.0%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.87      0.75      0.81      1170\n","        test       0.85      0.90      0.87      2464\n","   treatment       0.95      0.76      0.85      1244\n","\n","   micro avg       0.87      0.83      0.85      4878\n","   macro avg       0.89      0.81      0.84      4878\n","weighted avg       0.88      0.83      0.85      4878\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 8158\n","Points in y_train after augmentation: 8158\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8695051670074463\n","Training loss per 100 training steps: 0.3092555777713804\n","Training loss per 100 training steps: 0.2470643081475253\n","Training loss epoch: 0.22727257139688614\n","Training accuracy epoch: 0.9296486928104575\n","Validating model...\n","Validation Loss: 0.13285791773951666\n","Validation Accuracy: 0.9586298228969007\n","Training epoch: 2\n","Training loss per 100 training steps: 0.20169928669929504\n","Training loss per 100 training steps: 0.07632000278912042\n","Training loss per 100 training steps: 0.07097739987515506\n","Training loss epoch: 0.07242805197214087\n","Training accuracy epoch: 0.9779411764705882\n","Validating model...\n","Validation Loss: 0.16077295643980524\n","Validation Accuracy: 0.9580269607843137\n","Training epoch: 3\n","Training loss per 100 training steps: 0.016536647453904152\n","Training loss per 100 training steps: 0.039293750018079644\n","Training loss per 100 training steps: 0.04037021544868525\n","Training loss epoch: 0.04153755166860042\n","Training accuracy epoch: 0.9876225490196079\n","Validating model...\n","Validation Loss: 0.2014010954755541\n","Validation Accuracy: 0.9552696078431373\n","Training epoch: 4\n","Training loss per 100 training steps: 0.026783360168337822\n","Training loss per 100 training steps: 0.01799247151074728\n","Training loss per 100 training steps: 0.021572565589075797\n","Training loss epoch: 0.01971325506690168\n","Training accuracy epoch: 0.9944852941176471\n","Validating model...\n","Validation Loss: 0.24769909863750275\n","Validation Accuracy: 0.9546469797596459\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0006163371726870537\n","Training loss per 100 training steps: 0.018615912310352624\n","Training loss per 100 training steps: 0.022410666379082567\n","Training loss epoch: 0.02700615901232916\n","Training accuracy epoch: 0.991764705882353\n","Validating model...\n","Validation Loss: 0.24010565769704578\n","Validation Accuracy: 0.9540342346616066\n","Training epoch: 6\n","Training loss per 100 training steps: 0.004324621055275202\n","Training loss per 100 training steps: 0.02614554834187879\n","Training loss per 100 training steps: 0.03397125942097972\n","Training loss epoch: 0.03540228621728317\n","Training accuracy epoch: 0.9903186274509804\n","Validating model...\n","Validation Loss: 0.23893450072871786\n","Validation Accuracy: 0.9525122549019608\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 12.192276866666669 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14242165162566514\n","Validation Accuracy: 0.9559622556584363\n","Validation duration: 2.317926716666667 minutes\n","F1-score (test): 85.5%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.82      0.79      0.81      1170\n","        test       0.87      0.90      0.88      2464\n","   treatment       0.81      0.88      0.84      1244\n","\n","   micro avg       0.84      0.87      0.85      4878\n","   macro avg       0.83      0.86      0.84      4878\n","weighted avg       0.84      0.87      0.85      4878\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 8158\n","Points in y_train after augmentation: 8158\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.653628349304199\n","Training loss per 100 training steps: 0.35275452532390555\n","Training loss per 100 training steps: 0.2664195451588921\n","Training loss epoch: 0.24485666217903296\n","Training accuracy epoch: 0.9263398692810457\n","Validating model...\n","Validation Loss: 0.1532417217762593\n","Validation Accuracy: 0.9527988614800759\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07657840102910995\n","Training loss per 100 training steps: 0.07464807932633943\n","Training loss per 100 training steps: 0.07278985309354331\n","Training loss epoch: 0.07531918272120404\n","Training accuracy epoch: 0.9759722222222222\n","Validating model...\n","Validation Loss: 0.14820951448443034\n","Validation Accuracy: 0.9574142156862745\n","Training epoch: 3\n","Training loss per 100 training steps: 0.004701179452240467\n","Training loss per 100 training steps: 0.034308561387859135\n","Training loss per 100 training steps: 0.04026391130665882\n","Training loss epoch: 0.03954378030874638\n","Training accuracy epoch: 0.988218954248366\n","Validating model...\n","Validation Loss: 0.15606142470485293\n","Validation Accuracy: 0.9595390575585073\n","Training epoch: 4\n","Training loss per 100 training steps: 0.008097575977444649\n","Training loss per 100 training steps: 0.018061612886295996\n","Training loss per 100 training steps: 0.02151378129483826\n","Training loss epoch: 0.022331640841644806\n","Training accuracy epoch: 0.9936274509803922\n","Validating model...\n","Validation Loss: 0.1814102543758767\n","Validation Accuracy: 0.9573845667299178\n","Training epoch: 5\n","Training loss per 100 training steps: 0.003430191660299897\n","Training loss per 100 training steps: 0.04485659132824547\n","Training loss per 100 training steps: 0.039558381470040746\n","Training loss epoch: 0.03867160890607492\n","Training accuracy epoch: 0.9877450980392157\n","Validating model...\n","Validation Loss: 0.21783731121560743\n","Validation Accuracy: 0.9543504901960784\n","Training epoch: 6\n","Training loss per 100 training steps: 0.02164044789969921\n","Training loss per 100 training steps: 0.008334328653146789\n","Training loss per 100 training steps: 0.01290796648481321\n","Training loss epoch: 0.011386640464208505\n","Training accuracy epoch: 0.9970588235294118\n","Validating model...\n","Validation Loss: 0.2236976775556304\n","Validation Accuracy: 0.9595390575585073\n","Training epoch: 7\n","Training loss per 100 training steps: 0.00012525281636044383\n","Training loss per 100 training steps: 0.007908793582089964\n","Training loss per 100 training steps: 0.01786443869616901\n","Training loss epoch: 0.02291617868958936\n","Training accuracy epoch: 0.9933741830065359\n","Validating model...\n","Validation Loss: 0.21230661861815914\n","Validation Accuracy: 0.9552597248576851\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 14.23543845 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15715700939607039\n","Validation Accuracy: 0.9578792116769548\n","Validation duration: 2.320515933333339 minutes\n","F1-score (test): 85.9%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.88      0.75      0.81      1170\n","        test       0.85      0.91      0.88      2464\n","   treatment       0.83      0.89      0.86      1244\n","\n","   micro avg       0.85      0.86      0.86      4878\n","   macro avg       0.86      0.85      0.85      4878\n","weighted avg       0.86      0.86      0.86      4878\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 8158\n","Points in y_train after augmentation: 8158\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.339784622192383\n","Training loss per 100 training steps: 0.36374333982199136\n","Training loss per 100 training steps: 0.2812518405992149\n","Training loss epoch: 0.2582714498992644\n","Training accuracy epoch: 0.9208251633986928\n","Validating model...\n","Validation Loss: 0.1355902232667979\n","Validation Accuracy: 0.9546568627450981\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07817164063453674\n","Training loss per 100 training steps: 0.07107464784968386\n","Training loss per 100 training steps: 0.07822686667201939\n","Training loss epoch: 0.07734627517798513\n","Training accuracy epoch: 0.9764705882352941\n","Validating model...\n","Validation Loss: 0.14477008708990088\n","Validation Accuracy: 0.9589460784313726\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02944590337574482\n","Training loss per 100 training steps: 0.030072261289449058\n","Training loss per 100 training steps: 0.036960678793656734\n","Training loss epoch: 0.039259459603322194\n","Training accuracy epoch: 0.9876225490196079\n","Validating model...\n","Validation Loss: 0.14845258363536284\n","Validation Accuracy: 0.9583234503478811\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01180010475218296\n","Training loss per 100 training steps: 0.01671499763886297\n","Training loss per 100 training steps: 0.017969400282767927\n","Training loss epoch: 0.017374318136488928\n","Training accuracy epoch: 0.9948529411764706\n","Validating model...\n","Validation Loss: 0.1934812366251957\n","Validation Accuracy: 0.9595588235294118\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0007991554448381066\n","Training loss per 100 training steps: 0.011434228434532854\n","Training loss per 100 training steps: 0.017195157522775246\n","Training loss epoch: 0.02418530240224665\n","Training accuracy epoch: 0.9939869281045751\n","Validating model...\n","Validation Loss: 0.1696214309468975\n","Validation Accuracy: 0.9604779411764706\n","Training epoch: 6\n","Training loss per 100 training steps: 0.01384011935442686\n","Training loss per 100 training steps: 0.03402777742029693\n","Training loss per 100 training steps: 0.02999120671034209\n","Training loss epoch: 0.030393460932970687\n","Training accuracy epoch: 0.9906781045751634\n","Validating model...\n","Validation Loss: 0.2059030069934784\n","Validation Accuracy: 0.9592524509803921\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 12.28927866666667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13772054922258206\n","Validation Accuracy: 0.9550419560185185\n","Validation duration: 2.323567866666667 minutes\n","F1-score (test): 85.4%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.86      0.77      0.81      1170\n","        test       0.84      0.91      0.88      2464\n","   treatment       0.80      0.90      0.85      1244\n","\n","   micro avg       0.83      0.88      0.85      4878\n","   macro avg       0.83      0.86      0.84      4878\n","weighted avg       0.83      0.88      0.85      4878\n","\n","!!!!!! Starting model number 5 !!!!!!\n","Points in X_train after augmentation: 8158\n","Points in y_train after augmentation: 8158\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1764132976531982\n","Training loss per 100 training steps: 0.34284585670079337\n","Training loss per 100 training steps: 0.2614720472324621\n","Training loss epoch: 0.23855994090657023\n","Training accuracy epoch: 0.9268137254901961\n","Validating model...\n","Validation Loss: 0.15316169293980827\n","Validation Accuracy: 0.9512867647058824\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09662704914808273\n","Training loss per 100 training steps: 0.07757067846567693\n","Training loss per 100 training steps: 0.08011358208486356\n","Training loss epoch: 0.08331854109579295\n","Training accuracy epoch: 0.9735212418300654\n","Validating model...\n","Validation Loss: 0.18080571490595593\n","Validation Accuracy: 0.9429850569259962\n","Training epoch: 3\n","Training loss per 100 training steps: 0.11194121092557907\n","Training loss per 100 training steps: 0.03756187324490546\n","Training loss per 100 training steps: 0.038567194457117246\n","Training loss epoch: 0.038684545349393626\n","Training accuracy epoch: 0.9874918300653595\n","Validating model...\n","Validation Loss: 0.17413659381461055\n","Validation Accuracy: 0.9570880771663505\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01804937608540058\n","Training loss per 100 training steps: 0.023899235173663363\n","Training loss per 100 training steps: 0.020284004257288206\n","Training loss epoch: 0.024458859131418115\n","Training accuracy epoch: 0.993014705882353\n","Validating model...\n","Validation Loss: 0.1897005384123665\n","Validation Accuracy: 0.9540243516761544\n","Training epoch: 5\n","Training loss per 100 training steps: 0.02596135064959526\n","Training loss per 100 training steps: 0.016333067399365506\n","Training loss per 100 training steps: 0.020480579455004918\n","Training loss epoch: 0.0221670708868438\n","Training accuracy epoch: 0.9942320261437908\n","Validating model...\n","Validation Loss: 0.22761404829518642\n","Validation Accuracy: 0.9561788425047438\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00012082260946044698\n","Training loss per 100 training steps: 0.021199911735772667\n","Training loss per 100 training steps: 0.022120952734851686\n","Training loss epoch: 0.02412397227296834\n","Training accuracy epoch: 0.9927614379084967\n","Validating model...\n","Validation Loss: 0.19276788412917442\n","Validation Accuracy: 0.9580269607843137\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 12.398626866666662 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14905993734040143\n","Validation Accuracy: 0.9522207754629629\n","Validation duration: 2.3606036166666704 minutes\n","F1-score (test): 83.6%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.83      0.76      0.80      1170\n","        test       0.81      0.91      0.86      2464\n","   treatment       0.93      0.74      0.82      1244\n","\n","   micro avg       0.84      0.83      0.84      4878\n","   macro avg       0.86      0.80      0.83      4878\n","weighted avg       0.85      0.83      0.83      4878\n","\n","!!!!!! Starting model number 6 !!!!!!\n","Points in X_train after augmentation: 8158\n","Points in y_train after augmentation: 8158\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.285524845123291\n","Training loss per 100 training steps: 0.31278587885127207\n","Training loss per 100 training steps: 0.2415906393956115\n","Training loss epoch: 0.22559464386865205\n","Training accuracy epoch: 0.9284313725490196\n","Validating model...\n","Validation Loss: 0.15807109255818466\n","Validation Accuracy: 0.9525023719165086\n","Training epoch: 2\n","Training loss per 100 training steps: 0.012714083306491375\n","Training loss per 100 training steps: 0.0570652032510774\n","Training loss per 100 training steps: 0.06874793456445694\n","Training loss epoch: 0.06745501897279538\n","Training accuracy epoch: 0.9801470588235294\n","Validating model...\n","Validation Loss: 0.14198830868596868\n","Validation Accuracy: 0.961377292852625\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04243474826216698\n","Training loss per 100 training steps: 0.03607621935189305\n","Training loss per 100 training steps: 0.03886887132142675\n","Training loss epoch: 0.03471877308500766\n","Training accuracy epoch: 0.9897058823529412\n","Validating model...\n","Validation Loss: 0.1847246849761623\n","Validation Accuracy: 0.9629289215686274\n","Training epoch: 4\n","Training loss per 100 training steps: 0.026552775874733925\n","Training loss per 100 training steps: 0.01907719045460782\n","Training loss per 100 training steps: 0.03147896551053603\n","Training loss epoch: 0.029761287285923484\n","Training accuracy epoch: 0.9919035947712418\n","Validating model...\n","Validation Loss: 0.19241656533767146\n","Validation Accuracy: 0.9567619386464263\n","Training epoch: 5\n","Training loss per 100 training steps: 0.021651679649949074\n","Training loss per 100 training steps: 0.019010299278018616\n","Training loss per 100 training steps: 0.023144867484395818\n","Training loss epoch: 0.02584939039724322\n","Training accuracy epoch: 0.9923856209150327\n","Validating model...\n","Validation Loss: 0.16793137594347582\n","Validation Accuracy: 0.956791587602783\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0817364752292633\n","Training loss per 100 training steps: 0.028329182781295224\n","Training loss per 100 training steps: 0.02694266831049978\n","Training loss epoch: 0.025592604483359073\n","Training accuracy epoch: 0.9921568627450981\n","Validating model...\n","Validation Loss: 0.20273803761009213\n","Validation Accuracy: 0.955862586970272\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0005595157272182405\n","Training loss per 100 training steps: 0.017672784908301205\n","Training loss per 100 training steps: 0.017310475991566526\n","Training loss epoch: 0.01652123682870297\n","Training accuracy epoch: 0.9955882352941177\n","Validating model...\n","Validation Loss: 0.23615006718975173\n","Validation Accuracy: 0.9583135673624289\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 14.296562866666667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14928898298388016\n","Validation Accuracy: 0.9571759259259259\n","Validation duration: 2.3312771500000053 minutes\n","F1-score (test): 85.9%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.79      0.84      0.81      1170\n","        test       0.83      0.93      0.88      2464\n","   treatment       0.90      0.84      0.87      1244\n","\n","   micro avg       0.83      0.88      0.86      4878\n","   macro avg       0.84      0.87      0.85      4878\n","weighted avg       0.84      0.88      0.86      4878\n","\n","!!!!!! Starting model number 7 !!!!!!\n","Points in X_train after augmentation: 8158\n","Points in y_train after augmentation: 8158\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.373702049255371\n","Training loss per 100 training steps: 0.35054459561142\n","Training loss per 100 training steps: 0.25359700406804236\n","Training loss epoch: 0.23569586559509237\n","Training accuracy epoch: 0.926593137254902\n","Validating model...\n","Validation Loss: 0.14621799422756715\n","Validation Accuracy: 0.9571078431372549\n","Training epoch: 2\n","Training loss per 100 training steps: 0.027518074959516525\n","Training loss per 100 training steps: 0.07409765814790631\n","Training loss per 100 training steps: 0.08225118991251645\n","Training loss epoch: 0.08150542201383003\n","Training accuracy epoch: 0.9743872549019608\n","Validating model...\n","Validation Loss: 0.16934686677311273\n","Validation Accuracy: 0.9512669987349779\n","Training epoch: 3\n","Training loss per 100 training steps: 0.043134868144989014\n","Training loss per 100 training steps: 0.02742080018500622\n","Training loss per 100 training steps: 0.031192722454648558\n","Training loss epoch: 0.03366192043074133\n","Training accuracy epoch: 0.9911683006535947\n","Validating model...\n","Validation Loss: 0.19973344465331905\n","Validation Accuracy: 0.9564753320683113\n","Training epoch: 4\n","Training loss per 100 training steps: 0.002630527364090085\n","Training loss per 100 training steps: 0.027950390979721403\n","Training loss per 100 training steps: 0.027228742347629415\n","Training loss epoch: 0.02714554563908856\n","Training accuracy epoch: 0.9926470588235294\n","Validating model...\n","Validation Loss: 0.20271784227567397\n","Validation Accuracy: 0.9555463314358001\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0028374686371535063\n","Training loss per 100 training steps: 0.02063665987340512\n","Training loss per 100 training steps: 0.021332436739304912\n","Training loss epoch: 0.021759560271154853\n","Training accuracy epoch: 0.9928921568627451\n","Validating model...\n","Validation Loss: 0.2121877588700348\n","Validation Accuracy: 0.9564950980392157\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00311779766343534\n","Training loss per 100 training steps: 0.02774387156077324\n","Training loss per 100 training steps: 0.03462158524454745\n","Training loss epoch: 0.03487703404143937\n","Training accuracy epoch: 0.9903186274509804\n","Validating model...\n","Validation Loss: 0.19634140777092327\n","Validation Accuracy: 0.9570979601518027\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 12.102693799999997 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14724584897824874\n","Validation Accuracy: 0.9532134130658436\n","Validation duration: 2.3003695833333344 minutes\n","F1-score (test): 84.1%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.92      0.66      0.77      1170\n","        test       0.86      0.89      0.88      2464\n","   treatment       0.92      0.76      0.83      1244\n","\n","   micro avg       0.88      0.80      0.84      4878\n","   macro avg       0.90      0.77      0.82      4878\n","weighted avg       0.89      0.80      0.84      4878\n","\n","!!!!!! Starting model number 8 !!!!!!\n","Points in X_train after augmentation: 8158\n","Points in y_train after augmentation: 8158\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8823301792144775\n","Training loss per 100 training steps: 0.342401964313323\n","Training loss per 100 training steps: 0.2671233410877523\n","Training loss epoch: 0.24506514583732567\n","Training accuracy epoch: 0.9231535947712418\n","Validating model...\n","Validation Loss: 0.1385219337592157\n","Validation Accuracy: 0.9552399588867806\n","Training epoch: 2\n","Training loss per 100 training steps: 0.13042517006397247\n","Training loss per 100 training steps: 0.071161850922658\n","Training loss per 100 training steps: 0.07156388103192793\n","Training loss epoch: 0.07246085644754417\n","Training accuracy epoch: 0.9786764705882353\n","Validating model...\n","Validation Loss: 0.1422564953944518\n","Validation Accuracy: 0.9574142156862745\n","Training epoch: 3\n","Training loss per 100 training steps: 0.003635660046711564\n","Training loss per 100 training steps: 0.029281731158388908\n","Training loss per 100 training steps: 0.029890959710577755\n","Training loss epoch: 0.03482523386403188\n","Training accuracy epoch: 0.9896977124183006\n","Validating model...\n","Validation Loss: 0.1903563303936857\n","Validation Accuracy: 0.9540243516761544\n","Training epoch: 4\n","Training loss per 100 training steps: 0.04008887708187103\n","Training loss per 100 training steps: 0.027229510777627607\n","Training loss per 100 training steps: 0.03286498966635511\n","Training loss epoch: 0.03242570858861904\n","Training accuracy epoch: 0.9901960784313726\n","Validating model...\n","Validation Loss: 0.19625202645707474\n","Validation Accuracy: 0.9549533523086654\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0024547174107283354\n","Training loss per 100 training steps: 0.03070365220174599\n","Training loss per 100 training steps: 0.04093542597916867\n","Training loss epoch: 0.04435757761273314\n","Training accuracy epoch: 0.986266339869281\n","Validating model...\n","Validation Loss: 0.19340123303517626\n","Validation Accuracy: 0.9515832542694497\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0010146944550797343\n","Training loss per 100 training steps: 0.01955628086464701\n","Training loss per 100 training steps: 0.01842059596855511\n","Training loss epoch: 0.019062507828508102\n","Training accuracy epoch: 0.9944771241830065\n","Validating model...\n","Validation Loss: 0.2107831587200053\n","Validation Accuracy: 0.9577107052498419\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 12.211620399999992 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13317603820959684\n","Validation Accuracy: 0.9591089570473251\n","Validation duration: 2.3199377333333357 minutes\n","F1-score (test): 85.9%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.95      0.69      0.80      1170\n","        test       0.92      0.86      0.89      2464\n","   treatment       0.90      0.81      0.85      1244\n","\n","   micro avg       0.92      0.81      0.86      4878\n","   macro avg       0.92      0.79      0.85      4878\n","weighted avg       0.92      0.81      0.86      4878\n","\n","!!!!!! Starting model number 9 !!!!!!\n","Points in X_train after augmentation: 8158\n","Points in y_train after augmentation: 8158\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.2344274520874023\n","Training loss per 100 training steps: 0.34205329945624463\n","Training loss per 100 training steps: 0.2630266871636928\n","Training loss epoch: 0.24224701349203492\n","Training accuracy epoch: 0.923390522875817\n","Validating model...\n","Validation Loss: 0.13519883813226924\n","Validation Accuracy: 0.9583234503478811\n","Training epoch: 2\n","Training loss per 100 training steps: 0.021135905757546425\n","Training loss per 100 training steps: 0.07783723065150108\n","Training loss per 100 training steps: 0.07418246944411773\n","Training loss epoch: 0.07505480905300846\n","Training accuracy epoch: 0.9763480392156862\n","Validating model...\n","Validation Loss: 0.14491330883945064\n","Validation Accuracy: 0.960171568627451\n","Training epoch: 3\n","Training loss per 100 training steps: 0.012104254215955734\n","Training loss per 100 training steps: 0.034628501623560036\n","Training loss per 100 training steps: 0.03604582702220922\n","Training loss epoch: 0.03554149524231131\n","Training accuracy epoch: 0.9903104575163398\n","Validating model...\n","Validation Loss: 0.17062905054155955\n","Validation Accuracy: 0.9592228020240354\n","Training epoch: 4\n","Training loss per 100 training steps: 0.008330078795552254\n","Training loss per 100 training steps: 0.025330627443716114\n","Training loss per 100 training steps: 0.026717729291523024\n","Training loss epoch: 0.027112561619187722\n","Training accuracy epoch: 0.9915441176470589\n","Validating model...\n","Validation Loss: 0.20306436527992927\n","Validation Accuracy: 0.9564852150537635\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0003753322525881231\n","Training loss per 100 training steps: 0.026704315583701108\n","Training loss per 100 training steps: 0.03009025888047349\n","Training loss epoch: 0.03210093742033909\n","Training accuracy epoch: 0.9905637254901961\n","Validating model...\n","Validation Loss: 0.19721762251648733\n","Validation Accuracy: 0.9583135673624289\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0019879487808793783\n","Training loss per 100 training steps: 0.007440049465201648\n","Training loss per 100 training steps: 0.011792232462584935\n","Training loss epoch: 0.010307033365511326\n","Training accuracy epoch: 0.9971813725490196\n","Validating model...\n","Validation Loss: 0.2170073770634475\n","Validation Accuracy: 0.9604482922201139\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 12.231665866666678 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13925417491474137\n","Validation Accuracy: 0.9555443029835392\n","Validation duration: 2.3095254166666717 minutes\n","F1-score (test): 84.9%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.76      0.83      0.79      1170\n","        test       0.90      0.85      0.87      2464\n","   treatment       0.86      0.85      0.85      1244\n","\n","   micro avg       0.85      0.84      0.85      4878\n","   macro avg       0.84      0.84      0.84      4878\n","weighted avg       0.86      0.84      0.85      4878\n","\n","!!!!!! Starting model number 10 !!!!!!\n","Points in X_train after augmentation: 8158\n","Points in y_train after augmentation: 8158\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9401785135269165\n","Training loss per 100 training steps: 0.3102267360370053\n","Training loss per 100 training steps: 0.25066207092607495\n","Training loss epoch: 0.23116647583596847\n","Training accuracy epoch: 0.9281781045751634\n","Validating model...\n","Validation Loss: 0.19036447534374162\n","Validation Accuracy: 0.941166587602783\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05742259323596954\n","Training loss per 100 training steps: 0.07980426059952836\n","Training loss per 100 training steps: 0.07687751472515253\n","Training loss epoch: 0.08025711576509124\n","Training accuracy epoch: 0.9754820261437909\n","Validating model...\n","Validation Loss: 0.13393916167528824\n","Validation Accuracy: 0.955862586970272\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02013188973069191\n","Training loss per 100 training steps: 0.032320173962691816\n","Training loss per 100 training steps: 0.02968158033347471\n","Training loss epoch: 0.033334856683744446\n","Training accuracy epoch: 0.9898284313725491\n","Validating model...\n","Validation Loss: 0.1875556839148368\n","Validation Accuracy: 0.950950743200506\n","Training epoch: 4\n","Training loss per 100 training steps: 0.06033458560705185\n","Training loss per 100 training steps: 0.027608329388151626\n","Training loss per 100 training steps: 0.033416627137110896\n","Training loss epoch: 0.031199000960366582\n","Training accuracy epoch: 0.9908088235294118\n","Validating model...\n","Validation Loss: 0.2485314317865214\n","Validation Accuracy: 0.9500513915243517\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0016205488936975598\n","Training loss per 100 training steps: 0.022539868429280116\n","Training loss per 100 training steps: 0.03207258016116621\n","Training loss epoch: 0.03451482297192949\n","Training accuracy epoch: 0.990686274509804\n","Validating model...\n","Validation Loss: 0.1899110866155859\n","Validation Accuracy: 0.9525023719165086\n","Training epoch: 6\n","Training loss per 100 training steps: 0.004065395798534155\n","Training loss per 100 training steps: 0.0236813835433735\n","Training loss per 100 training steps: 0.02221376713721802\n","Training loss epoch: 0.022017166238248478\n","Training accuracy epoch: 0.9939950980392157\n","Validating model...\n","Validation Loss: 0.2087527630341641\n","Validation Accuracy: 0.9561689595192916\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0066813756711781025\n","Training loss per 100 training steps: 0.014370904600888601\n","Training loss per 100 training steps: 0.016033142644087253\n","Training loss epoch: 0.013479243388499918\n","Training accuracy epoch: 0.9962009803921569\n","Validating model...\n","Validation Loss: 0.2755901831963046\n","Validation Accuracy: 0.9561788425047438\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 14.398678599999979 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1333230498160076\n","Validation Accuracy: 0.9605195473251029\n","Validation duration: 2.3369028166666492 minutes\n","F1-score (test): 86.9%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.89      0.75      0.82      1170\n","        test       0.87      0.90      0.89      2464\n","   treatment       0.88      0.88      0.88      1244\n","\n","   micro avg       0.88      0.86      0.87      4878\n","   macro avg       0.88      0.84      0.86      4878\n","weighted avg       0.88      0.86      0.87      4878\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0.25\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"Jhz9BiIwGCsV"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10547654,"status":"ok","timestamp":1657375386800,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"jdO4m5O4Hlo3","outputId":"0bc52960-eeed-4176-f29a-c7a825f4bdbf"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 50.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 9789\n","Points in y_train after augmentation: 9789\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8825953006744385\n","Training loss per 100 training steps: 0.31210801057001153\n","Training loss per 100 training steps: 0.24675756885637692\n","Training loss per 100 training steps: 0.22051318635873224\n","Training loss epoch: 0.21925507941179806\n","Training accuracy epoch: 0.9319747295469912\n","Validating model...\n","Validation Loss: 0.13604410276200404\n","Validation Accuracy: 0.9577107052498419\n","Training epoch: 2\n","Training loss per 100 training steps: 0.03370976820588112\n","Training loss per 100 training steps: 0.06983543780406402\n","Training loss per 100 training steps: 0.07171541903415853\n","Training loss per 100 training steps: 0.07177768723901509\n","Training loss epoch: 0.07163617690968832\n","Training accuracy epoch: 0.978236984448952\n","Validating model...\n","Validation Loss: 0.14686671612948618\n","Validation Accuracy: 0.95739444971537\n","Training epoch: 3\n","Training loss per 100 training steps: 0.00791121181100607\n","Training loss per 100 training steps: 0.025902847092054638\n","Training loss per 100 training steps: 0.037638113916207534\n","Training loss per 100 training steps: 0.042336808697806295\n","Training loss epoch: 0.042051726910346525\n","Training accuracy epoch: 0.987234477124183\n","Validating model...\n","Validation Loss: 0.15877229660092032\n","Validation Accuracy: 0.9549533523086654\n","Training epoch: 4\n","Training loss per 100 training steps: 0.10701468586921692\n","Training loss per 100 training steps: 0.01972849648457371\n","Training loss per 100 training steps: 0.021278870598249722\n","Training loss per 100 training steps: 0.02666380542086397\n","Training loss epoch: 0.026478853785174936\n","Training accuracy epoch: 0.992534370069867\n","Validating model...\n","Validation Loss: 0.21553366721091866\n","Validation Accuracy: 0.9506542536369387\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0015412544598802924\n","Training loss per 100 training steps: 0.020266225050885857\n","Training loss per 100 training steps: 0.01662616954814638\n","Training loss per 100 training steps: 0.016365834122202265\n","Training loss epoch: 0.01620374067582447\n","Training accuracy epoch: 0.9952001633986928\n","Validating model...\n","Validation Loss: 0.2157227917635407\n","Validation Accuracy: 0.9552597248576851\n","Training epoch: 6\n","Training loss per 100 training steps: 0.247356578707695\n","Training loss per 100 training steps: 0.01050691145943653\n","Training loss per 100 training steps: 0.012905322866391539\n","Training loss per 100 training steps: 0.016920158490985306\n","Training loss epoch: 0.01670551779249103\n","Training accuracy epoch: 0.9950980392156863\n","Validating model...\n","Validation Loss: 0.23882472959025214\n","Validation Accuracy: 0.9540243516761544\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 14.367094516666688 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13948088153025578\n","Validation Accuracy: 0.9578952867798355\n","Validation duration: 2.3297828499999924 minutes\n","F1-score (test): 86.0%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.81      0.82      0.81      1170\n","        test       0.92      0.86      0.89      2464\n","   treatment       0.93      0.78      0.85      1244\n","\n","   micro avg       0.89      0.83      0.86      4878\n","   macro avg       0.88      0.82      0.85      4878\n","weighted avg       0.89      0.83      0.86      4878\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 9789\n","Points in y_train after augmentation: 9789\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.145984172821045\n","Training loss per 100 training steps: 0.31887107770336737\n","Training loss per 100 training steps: 0.2634711190038801\n","Training loss per 100 training steps: 0.22414872907968456\n","Training loss epoch: 0.22236347846151178\n","Training accuracy epoch: 0.9300449346405228\n","Validating model...\n","Validation Loss: 0.17741583838291905\n","Validation Accuracy: 0.9402474699557243\n","Training epoch: 2\n","Training loss per 100 training steps: 0.08129661530256271\n","Training loss per 100 training steps: 0.07147305684237934\n","Training loss per 100 training steps: 0.06948457229233797\n","Training loss per 100 training steps: 0.06803635599291218\n","Training loss epoch: 0.06838153190515156\n","Training accuracy epoch: 0.9792687908496732\n","Validating model...\n","Validation Loss: 0.13911444384732521\n","Validation Accuracy: 0.956791587602783\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03427371382713318\n","Training loss per 100 training steps: 0.031224081686370555\n","Training loss per 100 training steps: 0.03308249406145297\n","Training loss per 100 training steps: 0.0386741188645055\n","Training loss epoch: 0.03832512034540402\n","Training accuracy epoch: 0.9870302287581699\n","Validating model...\n","Validation Loss: 0.17480454732910455\n","Validation Accuracy: 0.956791587602783\n","Training epoch: 4\n","Training loss per 100 training steps: 0.10270493477582932\n","Training loss per 100 training steps: 0.018006075206034044\n","Training loss per 100 training steps: 0.02414193271042632\n","Training loss per 100 training steps: 0.02713465270176054\n","Training loss epoch: 0.027334297644747672\n","Training accuracy epoch: 0.9923406862745098\n","Validating model...\n","Validation Loss: 0.17521721011771837\n","Validation Accuracy: 0.9579874288425048\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0016667299205437303\n","Training loss per 100 training steps: 0.026156809573444437\n","Training loss per 100 training steps: 0.024847312391514366\n","Training loss per 100 training steps: 0.02294193474928604\n","Training loss epoch: 0.0230001707331527\n","Training accuracy epoch: 0.9939746732026143\n","Validating model...\n","Validation Loss: 0.20481846440145768\n","Validation Accuracy: 0.9546469797596459\n","Training epoch: 6\n","Training loss per 100 training steps: 0.002008706796914339\n","Training loss per 100 training steps: 0.02970124518505694\n","Training loss per 100 training steps: 0.022115015519194453\n","Training loss per 100 training steps: 0.0207966888489057\n","Training loss epoch: 0.02122265626768638\n","Training accuracy epoch: 0.9935661764705882\n","Validating model...\n","Validation Loss: 0.2331006452409829\n","Validation Accuracy: 0.9518995098039216\n","Training epoch: 7\n","Training loss per 100 training steps: 0.00035956635838374496\n","Training loss per 100 training steps: 0.020300540902062854\n","Training loss per 100 training steps: 0.01858595974443061\n","Training loss per 100 training steps: 0.020900309869763906\n","Training loss epoch: 0.02062792550110269\n","Training accuracy epoch: 0.9938725490196079\n","Validating model...\n","Validation Loss: 0.24698795844946575\n","Validation Accuracy: 0.9543406072106262\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 16.76089616666665 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14794332894099946\n","Validation Accuracy: 0.9564525462962963\n","Validation duration: 2.3201198666666643 minutes\n","F1-score (test): 85.8%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.74      0.88      0.81      1170\n","        test       0.90      0.87      0.88      2464\n","   treatment       0.83      0.90      0.86      1244\n","\n","   micro avg       0.84      0.88      0.86      4878\n","   macro avg       0.82      0.88      0.85      4878\n","weighted avg       0.85      0.88      0.86      4878\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 9789\n","Points in y_train after augmentation: 9789\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9636012315750122\n","Training loss per 100 training steps: 0.3445750507387784\n","Training loss per 100 training steps: 0.26155458216958527\n","Training loss per 100 training steps: 0.2276426112415436\n","Training loss epoch: 0.2286087549352422\n","Training accuracy epoch: 0.9289919990984898\n","Validating model...\n","Validation Loss: 0.1264237823357404\n","Validation Accuracy: 0.9613871758380772\n","Training epoch: 2\n","Training loss per 100 training steps: 0.11942697316408157\n","Training loss per 100 training steps: 0.07566347155065303\n","Training loss per 100 training steps: 0.0749375816319944\n","Training loss per 100 training steps: 0.07593920255587297\n","Training loss epoch: 0.07599919021367003\n","Training accuracy epoch: 0.9778390522875817\n","Validating model...\n","Validation Loss: 0.15085649572303703\n","Validation Accuracy: 0.9577107052498419\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02701777219772339\n","Training loss per 100 training steps: 0.03883547715596062\n","Training loss per 100 training steps: 0.04321279197807345\n","Training loss per 100 training steps: 0.04446850809020352\n","Training loss epoch: 0.0444228716804859\n","Training accuracy epoch: 0.9864984787018255\n","Validating model...\n","Validation Loss: 0.20208246063603105\n","Validation Accuracy: 0.948213156230234\n","Training epoch: 4\n","Training loss per 100 training steps: 0.12172073870897293\n","Training loss per 100 training steps: 0.031281639837099716\n","Training loss per 100 training steps: 0.02677104707989165\n","Training loss per 100 training steps: 0.028460367289282834\n","Training loss epoch: 0.028233715528686944\n","Training accuracy epoch: 0.9917279411764706\n","Validating model...\n","Validation Loss: 0.19516620486227146\n","Validation Accuracy: 0.9571078431372549\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0027641220949590206\n","Training loss per 100 training steps: 0.01974709310031745\n","Training loss per 100 training steps: 0.02555177946831563\n","Training loss per 100 training steps: 0.026969246775098685\n","Training loss epoch: 0.02657733229802141\n","Training accuracy epoch: 0.9909109477124183\n","Validating model...\n","Validation Loss: 0.23642714586058705\n","Validation Accuracy: 0.9521959993674889\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00297229434363544\n","Training loss per 100 training steps: 0.012507188680672805\n","Training loss per 100 training steps: 0.013662658967509221\n","Training loss per 100 training steps: 0.012629892183802295\n","Training loss epoch: 0.013361948297149425\n","Training accuracy epoch: 0.9962214052287581\n","Validating model...\n","Validation Loss: 0.2419045947025748\n","Validation Accuracy: 0.9589361954459203\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 14.588084166666643 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14249958969163276\n","Validation Accuracy: 0.9570473251028807\n","Validation duration: 2.370236883333352 minutes\n","F1-score (test): 85.8%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.85      0.81      0.83      1170\n","        test       0.82      0.92      0.87      2464\n","   treatment       0.93      0.81      0.87      1244\n","\n","   micro avg       0.85      0.87      0.86      4878\n","   macro avg       0.86      0.85      0.85      4878\n","weighted avg       0.85      0.87      0.86      4878\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 9789\n","Points in y_train after augmentation: 9789\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.99105703830719\n","Training loss per 100 training steps: 0.34206568877590765\n","Training loss per 100 training steps: 0.2636284606336658\n","Training loss per 100 training steps: 0.23374696864601088\n","Training loss epoch: 0.23228956870065112\n","Training accuracy epoch: 0.9235794173991435\n","Validating model...\n","Validation Loss: 0.14986449111179978\n","Validation Accuracy: 0.9503577640733712\n","Training epoch: 2\n","Training loss per 100 training steps: 0.053650662302970886\n","Training loss per 100 training steps: 0.06956553182767539\n","Training loss per 100 training steps: 0.06800664500078529\n","Training loss per 100 training steps: 0.07447908916843257\n","Training loss epoch: 0.07412494763349993\n","Training accuracy epoch: 0.9762860604011719\n","Validating model...\n","Validation Loss: 0.15457988383622803\n","Validation Accuracy: 0.9595390575585073\n","Training epoch: 3\n","Training loss per 100 training steps: 0.010819368064403534\n","Training loss per 100 training steps: 0.02954909504428137\n","Training loss per 100 training steps: 0.03444931991207205\n","Training loss per 100 training steps: 0.037939658597153474\n","Training loss epoch: 0.03772643629862513\n","Training accuracy epoch: 0.9886642156862745\n","Validating model...\n","Validation Loss: 0.17688471657411178\n","Validation Accuracy: 0.9524924889310563\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03146898001432419\n","Training loss per 100 training steps: 0.02536535070572823\n","Training loss per 100 training steps: 0.02768110465104877\n","Training loss per 100 training steps: 0.02792871490585389\n","Training loss epoch: 0.02772842981105783\n","Training accuracy epoch: 0.9923406862745098\n","Validating model...\n","Validation Loss: 0.21026998985411516\n","Validation Accuracy: 0.9546370967741936\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0011719586327672005\n","Training loss per 100 training steps: 0.01473078405741593\n","Training loss per 100 training steps: 0.020115068617893094\n","Training loss per 100 training steps: 0.019682304066958013\n","Training loss epoch: 0.01964497718226459\n","Training accuracy epoch: 0.9940662328149651\n","Validating model...\n","Validation Loss: 0.23679301226580077\n","Validation Accuracy: 0.9574043327008223\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0005505825974978507\n","Training loss per 100 training steps: 0.019295365430471157\n","Training loss per 100 training steps: 0.02490081915590479\n","Training loss per 100 training steps: 0.02564967552609347\n","Training loss epoch: 0.02551929468827914\n","Training accuracy epoch: 0.9912173202614379\n","Validating model...\n","Validation Loss: 0.24144124719425555\n","Validation Accuracy: 0.9494287634408602\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 14.404477000000012 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1420342757752493\n","Validation Accuracy: 0.9558015046296297\n","Validation duration: 2.334365200000017 minutes\n","F1-score (test): 85.2%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.81      0.80      0.81      1170\n","        test       0.87      0.89      0.88      2464\n","   treatment       0.93      0.76      0.84      1244\n","\n","   micro avg       0.87      0.83      0.85      4878\n","   macro avg       0.87      0.82      0.84      4878\n","weighted avg       0.87      0.83      0.85      4878\n","\n","!!!!!! Starting model number 5 !!!!!!\n","Points in X_train after augmentation: 9789\n","Points in y_train after augmentation: 9789\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7364704608917236\n","Training loss per 100 training steps: 0.3448811592810815\n","Training loss per 100 training steps: 0.2637133454737156\n","Training loss per 100 training steps: 0.2240514592468689\n","Training loss epoch: 0.2239450357361313\n","Training accuracy epoch: 0.9283792540004506\n","Validating model...\n","Validation Loss: 0.1487794073262051\n","Validation Accuracy: 0.9530953510436433\n","Training epoch: 2\n","Training loss per 100 training steps: 0.10906517505645752\n","Training loss per 100 training steps: 0.07347590042656232\n","Training loss per 100 training steps: 0.06533276950430811\n","Training loss per 100 training steps: 0.06629730373206379\n","Training loss epoch: 0.06719439215745071\n","Training accuracy epoch: 0.9789412891593419\n","Validating model...\n","Validation Loss: 0.16466160360997653\n","Validation Accuracy: 0.9546272137887414\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02786666713654995\n","Training loss per 100 training steps: 0.03210496189393158\n","Training loss per 100 training steps: 0.03462927156609868\n","Training loss per 100 training steps: 0.033381612662015565\n","Training loss epoch: 0.033856570759287496\n","Training accuracy epoch: 0.9899918300653595\n","Validating model...\n","Validation Loss: 0.20043066861199252\n","Validation Accuracy: 0.956791587602783\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0043380712158977985\n","Training loss per 100 training steps: 0.02274848776667766\n","Training loss per 100 training steps: 0.02541246967820511\n","Training loss per 100 training steps: 0.027644004357651502\n","Training loss epoch: 0.02833066083800148\n","Training accuracy epoch: 0.9921364379084967\n","Validating model...\n","Validation Loss: 0.1947181770445633\n","Validation Accuracy: 0.9537377450980392\n","Training epoch: 5\n","Training loss per 100 training steps: 0.004164098296314478\n","Training loss per 100 training steps: 0.022923303485933303\n","Training loss per 100 training steps: 0.021577996906024563\n","Training loss per 100 training steps: 0.02166852197451076\n","Training loss epoch: 0.02141326232835174\n","Training accuracy epoch: 0.9940767973856209\n","Validating model...\n","Validation Loss: 0.2006366348930397\n","Validation Accuracy: 0.956791587602783\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0007255612872540951\n","Training loss per 100 training steps: 0.01324871404682595\n","Training loss per 100 training steps: 0.014681608443071982\n","Training loss per 100 training steps: 0.013865424156308087\n","Training loss epoch: 0.013800221487769044\n","Training accuracy epoch: 0.9958023439260761\n","Validating model...\n","Validation Loss: 0.2641309162737504\n","Validation Accuracy: 0.9531151170145478\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 14.533653033333334 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15144623394708442\n","Validation Accuracy: 0.9500868055555556\n","Validation duration: 2.3497774499999955 minutes\n","F1-score (test): 84.3%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.66      0.86      0.75      1170\n","        test       0.88      0.89      0.88      2464\n","   treatment       0.88      0.86      0.87      1244\n","\n","   micro avg       0.82      0.87      0.84      4878\n","   macro avg       0.81      0.87      0.83      4878\n","weighted avg       0.83      0.87      0.85      4878\n","\n","!!!!!! Starting model number 6 !!!!!!\n","Points in X_train after augmentation: 9789\n","Points in y_train after augmentation: 9789\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9866142272949219\n","Training loss per 100 training steps: 0.3765468020545374\n","Training loss per 100 training steps: 0.27627330060251315\n","Training loss per 100 training steps: 0.24328866251357567\n","Training loss epoch: 0.24126506719762594\n","Training accuracy epoch: 0.9251007155735859\n","Validating model...\n","Validation Loss: 0.13969949825995548\n","Validation Accuracy: 0.9589361954459203\n","Training epoch: 2\n","Training loss per 100 training steps: 0.1108182817697525\n","Training loss per 100 training steps: 0.0752255737638599\n","Training loss per 100 training steps: 0.07162056289224038\n","Training loss per 100 training steps: 0.07338673554003498\n","Training loss epoch: 0.07303231052203664\n","Training accuracy epoch: 0.9781242956952896\n","Validating model...\n","Validation Loss: 0.1559068331102311\n","Validation Accuracy: 0.9546370967741936\n","Training epoch: 3\n","Training loss per 100 training steps: 0.005351424217224121\n","Training loss per 100 training steps: 0.02736911981736568\n","Training loss per 100 training steps: 0.03570278063349875\n","Training loss per 100 training steps: 0.04558868817352702\n","Training loss epoch: 0.04552495880921758\n","Training accuracy epoch: 0.9870302287581699\n","Validating model...\n","Validation Loss: 0.15568295146872782\n","Validation Accuracy: 0.9570979601518027\n","Training epoch: 4\n","Training loss per 100 training steps: 0.08744074404239655\n","Training loss per 100 training steps: 0.01228879018854419\n","Training loss per 100 training steps: 0.013704221210235715\n","Training loss per 100 training steps: 0.019448140218431994\n","Training loss epoch: 0.01944153513185858\n","Training accuracy epoch: 0.9939746732026143\n","Validating model...\n","Validation Loss: 0.2103034654214485\n","Validation Accuracy: 0.9475905281467426\n","Training epoch: 5\n","Training loss per 100 training steps: 0.004099398385733366\n","Training loss per 100 training steps: 0.024322909470428575\n","Training loss per 100 training steps: 0.03139247279976198\n","Training loss per 100 training steps: 0.03120192944264021\n","Training loss epoch: 0.030846772990889507\n","Training accuracy epoch: 0.9912173202614379\n","Validating model...\n","Validation Loss: 0.19419929504154282\n","Validation Accuracy: 0.9552597248576851\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0022890325635671616\n","Training loss per 100 training steps: 0.009600921901401667\n","Training loss per 100 training steps: 0.011519888935493947\n","Training loss per 100 training steps: 0.014747646789717607\n","Training loss epoch: 0.014659792881871208\n","Training accuracy epoch: 0.9954044117647058\n","Validating model...\n","Validation Loss: 0.21640100244001267\n","Validation Accuracy: 0.9555562144212524\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 14.478077166666662 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13611950764607172\n","Validation Accuracy: 0.9578028549382716\n","Validation duration: 2.337334949999998 minutes\n","F1-score (test): 86.0%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.82      0.81      0.82      1170\n","        test       0.88      0.88      0.88      2464\n","   treatment       0.86      0.86      0.86      1244\n","\n","   micro avg       0.86      0.86      0.86      4878\n","   macro avg       0.85      0.85      0.85      4878\n","weighted avg       0.86      0.86      0.86      4878\n","\n","!!!!!! Starting model number 7 !!!!!!\n","Points in X_train after augmentation: 9789\n","Points in y_train after augmentation: 9789\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.020595073699951\n","Training loss per 100 training steps: 0.32669531445175704\n","Training loss per 100 training steps: 0.26603116824370415\n","Training loss per 100 training steps: 0.2279033745759696\n","Training loss epoch: 0.22648936044729126\n","Training accuracy epoch: 0.9285940669371197\n","Validating model...\n","Validation Loss: 0.1504673621818131\n","Validation Accuracy: 0.9540441176470589\n","Training epoch: 2\n","Training loss per 100 training steps: 0.01014425978064537\n","Training loss per 100 training steps: 0.07563479109390611\n","Training loss per 100 training steps: 0.07118238645214217\n","Training loss per 100 training steps: 0.07232561238779937\n","Training loss epoch: 0.07221961322467275\n","Training accuracy epoch: 0.9769199346405228\n","Validating model...\n","Validation Loss: 0.1644770605409719\n","Validation Accuracy: 0.9543406072106262\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03075602650642395\n","Training loss per 100 training steps: 0.03524499849789767\n","Training loss per 100 training steps: 0.034908095667189665\n","Training loss per 100 training steps: 0.03573848332775033\n","Training loss epoch: 0.035355282868669534\n","Training accuracy epoch: 0.9902982026143791\n","Validating model...\n","Validation Loss: 0.1890499224211774\n","Validation Accuracy: 0.9570979601518027\n","Training epoch: 4\n","Training loss per 100 training steps: 0.021482711657881737\n","Training loss per 100 training steps: 0.03732479624922784\n","Training loss per 100 training steps: 0.03952917900713698\n","Training loss per 100 training steps: 0.03483223951146304\n","Training loss epoch: 0.03443121539620573\n","Training accuracy epoch: 0.9907066993464052\n","Validating model...\n","Validation Loss: 0.18537627067873438\n","Validation Accuracy: 0.953727862112587\n","Training epoch: 5\n","Training loss per 100 training steps: 0.00748030561953783\n","Training loss per 100 training steps: 0.013790897672332011\n","Training loss per 100 training steps: 0.024599510815083766\n","Training loss per 100 training steps: 0.023551465136235336\n","Training loss epoch: 0.02329909089861211\n","Training accuracy epoch: 0.9926470588235294\n","Validating model...\n","Validation Loss: 0.1908495817750044\n","Validation Accuracy: 0.9552498418722328\n","Training epoch: 6\n","Training loss per 100 training steps: 0.013953940011560917\n","Training loss per 100 training steps: 0.012823119415932721\n","Training loss per 100 training steps: 0.01169728278964341\n","Training loss per 100 training steps: 0.011308034196704089\n","Training loss epoch: 0.011355603482918334\n","Training accuracy epoch: 0.9964256535947712\n","Validating model...\n","Validation Loss: 0.2338466702103866\n","Validation Accuracy: 0.953727862112587\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 14.698901633333328 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.155774244845142\n","Validation Accuracy: 0.9505891525205762\n","Validation duration: 2.3844189500000237 minutes\n","F1-score (test): 84.3%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.71      0.87      0.78      1170\n","        test       0.84      0.90      0.87      2464\n","   treatment       0.89      0.83      0.86      1244\n","\n","   micro avg       0.81      0.88      0.84      4878\n","   macro avg       0.81      0.87      0.83      4878\n","weighted avg       0.82      0.88      0.84      4878\n","\n","!!!!!! Starting model number 8 !!!!!!\n","Points in X_train after augmentation: 9789\n","Points in y_train after augmentation: 9789\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.4921178817749023\n","Training loss per 100 training steps: 0.3566919401435569\n","Training loss per 100 training steps: 0.27081870078688386\n","Training loss per 100 training steps: 0.23976811994040428\n","Training loss epoch: 0.23816604462750499\n","Training accuracy epoch: 0.9256535947712419\n","Validating model...\n","Validation Loss: 0.14433873450273976\n","Validation Accuracy: 0.953727862112587\n","Training epoch: 2\n","Training loss per 100 training steps: 0.11009389907121658\n","Training loss per 100 training steps: 0.07720585341915709\n","Training loss per 100 training steps: 0.07660112666100523\n","Training loss per 100 training steps: 0.07593823947164036\n","Training loss epoch: 0.07530315201562142\n","Training accuracy epoch: 0.9756944444444444\n","Validating model...\n","Validation Loss: 0.15796641330234706\n","Validation Accuracy: 0.9512669987349779\n","Training epoch: 3\n","Training loss per 100 training steps: 0.012860763818025589\n","Training loss per 100 training steps: 0.0364420863184248\n","Training loss per 100 training steps: 0.04145979034900897\n","Training loss per 100 training steps: 0.04810983620168629\n","Training loss epoch: 0.047676180844504104\n","Training accuracy epoch: 0.9866217320261438\n","Validating model...\n","Validation Loss: 0.18540136488873565\n","Validation Accuracy: 0.9509606261859582\n","Training epoch: 4\n","Training loss per 100 training steps: 0.046156782656908035\n","Training loss per 100 training steps: 0.03473654175396216\n","Training loss per 100 training steps: 0.026923062196852806\n","Training loss per 100 training steps: 0.026394192528028344\n","Training loss epoch: 0.027101993967008204\n","Training accuracy epoch: 0.9918300653594772\n","Validating model...\n","Validation Loss: 0.21011533823512568\n","Validation Accuracy: 0.9561689595192916\n","Training epoch: 5\n","Training loss per 100 training steps: 0.002283678390085697\n","Training loss per 100 training steps: 0.014668970734041211\n","Training loss per 100 training steps: 0.018000076751372968\n","Training loss per 100 training steps: 0.02149459372669655\n","Training loss epoch: 0.021822991809992993\n","Training accuracy epoch: 0.9931576797385621\n","Validating model...\n","Validation Loss: 0.2035635193209529\n","Validation Accuracy: 0.957068311195446\n","Training epoch: 6\n","Training loss per 100 training steps: 0.003210535040125251\n","Training loss per 100 training steps: 0.026040391897953274\n","Training loss per 100 training steps: 0.02175328952323446\n","Training loss per 100 training steps: 0.0165773594323712\n","Training loss epoch: 0.01686000341844929\n","Training accuracy epoch: 0.9954959713770566\n","Validating model...\n","Validation Loss: 0.23846124246262537\n","Validation Accuracy: 0.9592425679949399\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 14.33071823333333 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14571946027852525\n","Validation Accuracy: 0.9553674768518519\n","Validation duration: 2.3182643166666823 minutes\n","F1-score (test): 85.1%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.91      0.69      0.79      1170\n","        test       0.84      0.91      0.87      2464\n","   treatment       0.89      0.83      0.86      1244\n","\n","   micro avg       0.87      0.84      0.85      4878\n","   macro avg       0.88      0.81      0.84      4878\n","weighted avg       0.87      0.84      0.85      4878\n","\n","!!!!!! Starting model number 9 !!!!!!\n","Points in X_train after augmentation: 9789\n","Points in y_train after augmentation: 9789\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.311314105987549\n","Training loss per 100 training steps: 0.3187786284465306\n","Training loss per 100 training steps: 0.2544786637157795\n","Training loss per 100 training steps: 0.22137449531076459\n","Training loss epoch: 0.21972330406101215\n","Training accuracy epoch: 0.930453431372549\n","Validating model...\n","Validation Loss: 0.15159008014654995\n","Validation Accuracy: 0.9518896268184693\n","Training epoch: 2\n","Training loss per 100 training steps: 0.1861923485994339\n","Training loss per 100 training steps: 0.07953848288680362\n","Training loss per 100 training steps: 0.07734417554630495\n","Training loss per 100 training steps: 0.08072085140591667\n","Training loss epoch: 0.08070077461242262\n","Training accuracy epoch: 0.9741520171286905\n","Validating model...\n","Validation Loss: 0.16091614577910116\n","Validation Accuracy: 0.9567817046173308\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04093551263213158\n","Training loss per 100 training steps: 0.026058679780839842\n","Training loss per 100 training steps: 0.03778767393205769\n","Training loss per 100 training steps: 0.039460241745274044\n","Training loss epoch: 0.039656794420177166\n","Training accuracy epoch: 0.9878472222222222\n","Validating model...\n","Validation Loss: 0.16486208687317283\n","Validation Accuracy: 0.9558724699557243\n","Training epoch: 4\n","Training loss per 100 training steps: 0.015797659754753113\n","Training loss per 100 training steps: 0.020689155706746207\n","Training loss per 100 training steps: 0.020281756610814623\n","Training loss per 100 training steps: 0.023836901904342147\n","Training loss epoch: 0.023890783932680886\n","Training accuracy epoch: 0.9927491830065359\n","Validating model...\n","Validation Loss: 0.20566855093741598\n","Validation Accuracy: 0.9567817046173308\n","Training epoch: 5\n","Training loss per 100 training steps: 0.006886889226734638\n","Training loss per 100 training steps: 0.019913499922886962\n","Training loss per 100 training steps: 0.02079693769410007\n","Training loss per 100 training steps: 0.026056357958366434\n","Training loss epoch: 0.0259249052904041\n","Training accuracy epoch: 0.9936683006535948\n","Validating model...\n","Validation Loss: 0.21047160449419536\n","Validation Accuracy: 0.9512669987349779\n","Training epoch: 6\n","Training loss per 100 training steps: 0.03744430094957352\n","Training loss per 100 training steps: 0.02096512541059626\n","Training loss per 100 training steps: 0.024640707998763566\n","Training loss per 100 training steps: 0.0251735524745098\n","Training loss epoch: 0.024908917684989124\n","Training accuracy epoch: 0.9921364379084967\n","Validating model...\n","Validation Loss: 0.20222235156403506\n","Validation Accuracy: 0.9595390575585073\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 14.339409416666664 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14697064804581547\n","Validation Accuracy: 0.9531611689814815\n","Validation duration: 2.3197249333333576 minutes\n","F1-score (test): 84.3%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.90      0.73      0.80      1170\n","        test       0.84      0.90      0.87      2464\n","   treatment       0.77      0.89      0.83      1244\n","\n","   micro avg       0.83      0.86      0.84      4878\n","   macro avg       0.83      0.84      0.83      4878\n","weighted avg       0.83      0.86      0.84      4878\n","\n","!!!!!! Starting model number 10 !!!!!!\n","Points in X_train after augmentation: 9789\n","Points in y_train after augmentation: 9789\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.2805886268615723\n","Training loss per 100 training steps: 0.34002591769146445\n","Training loss per 100 training steps: 0.26936163721763673\n","Training loss per 100 training steps: 0.23369684428954343\n","Training loss epoch: 0.23252769125917672\n","Training accuracy epoch: 0.9281855702050935\n","Validating model...\n","Validation Loss: 0.14091094557250686\n","Validation Accuracy: 0.9558724699557243\n","Training epoch: 2\n","Training loss per 100 training steps: 0.028607964515686035\n","Training loss per 100 training steps: 0.059907333979539866\n","Training loss per 100 training steps: 0.07192479292294521\n","Training loss per 100 training steps: 0.07455082553356848\n","Training loss epoch: 0.07409144595327781\n","Training accuracy epoch: 0.9750711347757494\n","Validating model...\n","Validation Loss: 0.1827630048101841\n","Validation Accuracy: 0.9469975490196079\n","Training epoch: 3\n","Training loss per 100 training steps: 0.11028843373060226\n","Training loss per 100 training steps: 0.0376582921944826\n","Training loss per 100 training steps: 0.03476495067449981\n","Training loss per 100 training steps: 0.033202271606363944\n","Training loss epoch: 0.0335431575783326\n","Training accuracy epoch: 0.9901855138607166\n","Validating model...\n","Validation Loss: 0.19970828213035038\n","Validation Accuracy: 0.9497549019607843\n","Training epoch: 4\n","Training loss per 100 training steps: 0.012830488383769989\n","Training loss per 100 training steps: 0.022047042403350547\n","Training loss per 100 training steps: 0.021553251775695746\n","Training loss per 100 training steps: 0.026215504731685525\n","Training loss epoch: 0.026164491931530053\n","Training accuracy epoch: 0.9923406862745098\n","Validating model...\n","Validation Loss: 0.19162270229357733\n","Validation Accuracy: 0.9561788425047438\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0019254572689533234\n","Training loss per 100 training steps: 0.013669040410532754\n","Training loss per 100 training steps: 0.016068465416004016\n","Training loss per 100 training steps: 0.021659521499010147\n","Training loss epoch: 0.021417536827238366\n","Training accuracy epoch: 0.9930555555555556\n","Validating model...\n","Validation Loss: 0.2499224466648907\n","Validation Accuracy: 0.9445268026565465\n","Training epoch: 6\n","Training loss per 100 training steps: 0.009539159946143627\n","Training loss per 100 training steps: 0.034949477523534174\n","Training loss per 100 training steps: 0.03320489145047379\n","Training loss per 100 training steps: 0.03388727701915369\n","Training loss epoch: 0.03476165517853813\n","Training accuracy epoch: 0.9897875816993464\n","Validating model...\n","Validation Loss: 0.17727065262927985\n","Validation Accuracy: 0.953727862112587\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 14.212642533333383 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14048205778063103\n","Validation Accuracy: 0.9556929976851852\n","Validation duration: 2.297312166666658 minutes\n","F1-score (test): 85.0%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.87      0.74      0.80      1170\n","        test       0.89      0.89      0.89      2464\n","   treatment       0.74      0.92      0.82      1244\n","\n","   micro avg       0.84      0.86      0.85      4878\n","   macro avg       0.83      0.85      0.84      4878\n","weighted avg       0.85      0.86      0.85      4878\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0.5\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"jdO4m5O4Hlo3"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12294558,"status":"ok","timestamp":1657387681725,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"oKNxFPucHn_R","outputId":"0a33eb7c-ac80-4fdf-88b0-b6faed7b0e35"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 75.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 11421\n","Points in y_train after augmentation: 11421\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0889768600463867\n","Training loss per 100 training steps: 0.34639736980494884\n","Training loss per 100 training steps: 0.26030772984194667\n","Training loss per 100 training steps: 0.2272254924608574\n","Training loss epoch: 0.2136375361490024\n","Training accuracy epoch: 0.9325980392156863\n","Validating model...\n","Validation Loss: 0.1523711759478365\n","Validation Accuracy: 0.9534214895635674\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04488595947623253\n","Training loss per 100 training steps: 0.06977649573882175\n","Training loss per 100 training steps: 0.06056759479068757\n","Training loss per 100 training steps: 0.05912503975395583\n","Training loss epoch: 0.06074675998398747\n","Training accuracy epoch: 0.9810833816285135\n","Validating model...\n","Validation Loss: 0.17419371248779855\n","Validation Accuracy: 0.9515634882985452\n","Training epoch: 3\n","Training loss per 100 training steps: 0.01278640702366829\n","Training loss per 100 training steps: 0.03682586771498277\n","Training loss per 100 training steps: 0.04047250999740107\n","Training loss per 100 training steps: 0.040826539966924445\n","Training loss epoch: 0.03977927464127008\n","Training accuracy epoch: 0.9884453781512605\n","Validating model...\n","Validation Loss: 0.21871599586459115\n","Validation Accuracy: 0.9448529411764706\n","Training epoch: 4\n","Training loss per 100 training steps: 0.024702146649360657\n","Training loss per 100 training steps: 0.03150093474305502\n","Training loss per 100 training steps: 0.025835981767158955\n","Training loss per 100 training steps: 0.02425936112208199\n","Training loss epoch: 0.024300397361262834\n","Training accuracy epoch: 0.9929971988795518\n","Validating model...\n","Validation Loss: 0.20875137320442316\n","Validation Accuracy: 0.954330724225174\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0010582052636891603\n","Training loss per 100 training steps: 0.0084240713236291\n","Training loss per 100 training steps: 0.016160278244289242\n","Training loss per 100 training steps: 0.01777595712115255\n","Training loss epoch: 0.01981978656506265\n","Training accuracy epoch: 0.9950980392156863\n","Validating model...\n","Validation Loss: 0.21010874129041993\n","Validation Accuracy: 0.9500513915243517\n","Training epoch: 6\n","Training loss per 100 training steps: 0.07991340011358261\n","Training loss per 100 training steps: 0.014096747755907513\n","Training loss per 100 training steps: 0.02162327800333831\n","Training loss per 100 training steps: 0.021283507336954433\n","Training loss epoch: 0.021324464038610512\n","Training accuracy epoch: 0.9936974789915967\n","Validating model...\n","Validation Loss: 0.2210885031639847\n","Validation Accuracy: 0.9494386464263125\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 16.719340433333308 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1492673735893159\n","Validation Accuracy: 0.9536112718621399\n","Validation duration: 2.36044476666666 minutes\n","F1-score (test): 84.3%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.84      0.74      0.78      1170\n","        test       0.85      0.89      0.87      2464\n","   treatment       0.90      0.79      0.84      1244\n","\n","   micro avg       0.86      0.83      0.84      4878\n","   macro avg       0.86      0.81      0.83      4878\n","weighted avg       0.86      0.83      0.84      4878\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 11421\n","Points in y_train after augmentation: 11421\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9807103872299194\n","Training loss per 100 training steps: 0.3199340377261143\n","Training loss per 100 training steps: 0.24968720525873833\n","Training loss per 100 training steps: 0.22256180717674798\n","Training loss epoch: 0.20598355321871006\n","Training accuracy epoch: 0.9331926736211725\n","Validating model...\n","Validation Loss: 0.18580882991298886\n","Validation Accuracy: 0.9485096457938014\n","Training epoch: 2\n","Training loss per 100 training steps: 0.2144353836774826\n","Training loss per 100 training steps: 0.06117264831226577\n","Training loss per 100 training steps: 0.06721988245288828\n","Training loss per 100 training steps: 0.06858392293948642\n","Training loss epoch: 0.06680643072557904\n","Training accuracy epoch: 0.9816085917125471\n","Validating model...\n","Validation Loss: 0.17336509656275204\n","Validation Accuracy: 0.9549533523086654\n","Training epoch: 3\n","Training loss per 100 training steps: 0.01096147857606411\n","Training loss per 100 training steps: 0.031342346457497096\n","Training loss per 100 training steps: 0.03984935737831231\n","Training loss per 100 training steps: 0.03545648374624142\n","Training loss epoch: 0.038832138743478524\n","Training accuracy epoch: 0.9887079831932774\n","Validating model...\n","Validation Loss: 0.18486492555844142\n","Validation Accuracy: 0.9577008222643897\n","Training epoch: 4\n","Training loss per 100 training steps: 0.008349363692104816\n","Training loss per 100 training steps: 0.022510084167404083\n","Training loss per 100 training steps: 0.029520311278745125\n","Training loss per 100 training steps: 0.030523970512366945\n","Training loss epoch: 0.02967508953812738\n","Training accuracy epoch: 0.9907212885154062\n","Validating model...\n","Validation Loss: 0.2125128250684379\n","Validation Accuracy: 0.9567817046173308\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0010564493713900447\n","Training loss per 100 training steps: 0.023395930228139374\n","Training loss per 100 training steps: 0.027025884357037774\n","Training loss per 100 training steps: 0.026424383595597425\n","Training loss epoch: 0.026108351642320046\n","Training accuracy epoch: 0.9915966386554622\n","Validating model...\n","Validation Loss: 0.22200874011739904\n","Validation Accuracy: 0.9506641366223909\n","Training epoch: 6\n","Training loss per 100 training steps: 0.02502530813217163\n","Training loss per 100 training steps: 0.022276218396745217\n","Training loss per 100 training steps: 0.017188713629049508\n","Training loss per 100 training steps: 0.013963476376230148\n","Training loss epoch: 0.01658107910302164\n","Training accuracy epoch: 0.9953515889114266\n","Validating model...\n","Validation Loss: 0.23681706427405338\n","Validation Accuracy: 0.9500415085388995\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0008035092032514513\n","Training loss per 100 training steps: 0.017081759195333338\n","Training loss per 100 training steps: 0.019976805203518393\n","Training loss per 100 training steps: 0.021506948296875657\n","Training loss epoch: 0.02140943712003122\n","Training accuracy epoch: 0.9947478991596639\n","Validating model...\n","Validation Loss: 0.26261680223051725\n","Validation Accuracy: 0.9476102941176471\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 19.733862083333346 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1605508138165735\n","Validation Accuracy: 0.9585503472222222\n","Validation duration: 2.3623177666666377 minutes\n","F1-score (test): 86.2%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.85      0.79      0.82      1170\n","        test       0.85      0.91      0.88      2464\n","   treatment       0.87      0.85      0.86      1244\n","\n","   micro avg       0.86      0.87      0.86      4878\n","   macro avg       0.86      0.85      0.85      4878\n","weighted avg       0.86      0.87      0.86      4878\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 11421\n","Points in y_train after augmentation: 11421\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.041181802749634\n","Training loss per 100 training steps: 0.3778532402276403\n","Training loss per 100 training steps: 0.2887384718589818\n","Training loss per 100 training steps: 0.2472104230815192\n","Training loss epoch: 0.23129808779085884\n","Training accuracy epoch: 0.9247108326089056\n","Validating model...\n","Validation Loss: 0.15860510254096166\n","Validation Accuracy: 0.9543406072106262\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04649684578180313\n","Training loss per 100 training steps: 0.06845068557667408\n","Training loss per 100 training steps: 0.06726937939352658\n","Training loss per 100 training steps: 0.06706266750255135\n","Training loss epoch: 0.06831742670463335\n","Training accuracy epoch: 0.9788165266106442\n","Validating model...\n","Validation Loss: 0.15393346244944076\n","Validation Accuracy: 0.9561788425047438\n","Training epoch: 3\n","Training loss per 100 training steps: 0.013756562024354935\n","Training loss per 100 training steps: 0.029771434357574227\n","Training loss per 100 training steps: 0.0364990600834216\n","Training loss per 100 training steps: 0.04209407826284553\n","Training loss epoch: 0.04547254668391526\n","Training accuracy epoch: 0.9865980875108664\n","Validating model...\n","Validation Loss: 0.15793883309964382\n","Validation Accuracy: 0.9576909392789374\n","Training epoch: 4\n","Training loss per 100 training steps: 0.06729830801486969\n","Training loss per 100 training steps: 0.028405545600102108\n","Training loss per 100 training steps: 0.02565234414124004\n","Training loss per 100 training steps: 0.02384478819055291\n","Training loss epoch: 0.022825729710386454\n","Training accuracy epoch: 0.9935224089635855\n","Validating model...\n","Validation Loss: 0.2567522066303497\n","Validation Accuracy: 0.9485294117647058\n","Training epoch: 5\n","Training loss per 100 training steps: 0.01096896268427372\n","Training loss per 100 training steps: 0.01412245300255536\n","Training loss per 100 training steps: 0.011917911939579525\n","Training loss per 100 training steps: 0.016008865235629027\n","Training loss epoch: 0.016135529484119657\n","Training accuracy epoch: 0.9958858543417367\n","Validating model...\n","Validation Loss: 0.20618440146733752\n","Validation Accuracy: 0.9574043327008223\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0025457297451794147\n","Training loss per 100 training steps: 0.021250729046970614\n","Training loss per 100 training steps: 0.019411502800205958\n","Training loss per 100 training steps: 0.01777935002523299\n","Training loss epoch: 0.01622254549184014\n","Training accuracy epoch: 0.9956232492997199\n","Validating model...\n","Validation Loss: 0.22763624689205067\n","Validation Accuracy: 0.9598454301075269\n","Training epoch: 7\n","Training loss per 100 training steps: 0.374364972114563\n","Training loss per 100 training steps: 0.0186164402225721\n","Training loss per 100 training steps: 0.019691858857720092\n","Training loss per 100 training steps: 0.020152939991245008\n","Training loss epoch: 0.018443760012504085\n","Training accuracy epoch: 0.9949139138413986\n","Validating model...\n","Validation Loss: 0.2644243938220647\n","Validation Accuracy: 0.948816018342821\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 19.388728699999955 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16120782806441034\n","Validation Accuracy: 0.9529803240740741\n","Validation duration: 2.332252883333361 minutes\n","F1-score (test): 84.1%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.77      0.82      0.79      1170\n","        test       0.90      0.85      0.88      2464\n","   treatment       0.77      0.89      0.82      1244\n","\n","   micro avg       0.83      0.85      0.84      4878\n","   macro avg       0.81      0.85      0.83      4878\n","weighted avg       0.84      0.85      0.84      4878\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 11421\n","Points in y_train after augmentation: 11421\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.6812547445297241\n","Training loss per 100 training steps: 0.3431489739271969\n","Training loss per 100 training steps: 0.2670269662338258\n","Training loss per 100 training steps: 0.23329393218497302\n","Training loss epoch: 0.22189902515001908\n","Training accuracy epoch: 0.9319762387713706\n","Validating model...\n","Validation Loss: 0.148896977524547\n","Validation Accuracy: 0.9503281151170145\n","Training epoch: 2\n","Training loss per 100 training steps: 0.11454275250434875\n","Training loss per 100 training steps: 0.08320541093172044\n","Training loss per 100 training steps: 0.07445144465578887\n","Training loss per 100 training steps: 0.07453111456834752\n","Training loss epoch: 0.07465469690789116\n","Training accuracy epoch: 0.9772318410122669\n","Validating model...\n","Validation Loss: 0.16239224995175996\n","Validation Accuracy: 0.9567817046173308\n","Training epoch: 3\n","Training loss per 100 training steps: 0.09255242347717285\n","Training loss per 100 training steps: 0.03334145809611361\n","Training loss per 100 training steps: 0.043519052083775475\n","Training loss per 100 training steps: 0.0377681926302314\n","Training loss epoch: 0.03559683834833415\n","Training accuracy epoch: 0.9898278276827972\n","Validating model...\n","Validation Loss: 0.18896058458074763\n","Validation Accuracy: 0.9586298228969007\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0325196199119091\n","Training loss per 100 training steps: 0.022919682219208422\n","Training loss per 100 training steps: 0.019594085656395484\n","Training loss per 100 training steps: 0.021271836994880302\n","Training loss epoch: 0.022289458320851774\n","Training accuracy epoch: 0.9930847338935574\n","Validating model...\n","Validation Loss: 0.21071874483388064\n","Validation Accuracy: 0.9531151170145478\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0015154961729422212\n","Training loss per 100 training steps: 0.026491340219520383\n","Training loss per 100 training steps: 0.030672879504235067\n","Training loss per 100 training steps: 0.02440113742077573\n","Training loss epoch: 0.02578052700573353\n","Training accuracy epoch: 0.9926470588235294\n","Validating model...\n","Validation Loss: 0.20443824423687057\n","Validation Accuracy: 0.956791587602783\n","Training epoch: 6\n","Training loss per 100 training steps: 0.20993220806121826\n","Training loss per 100 training steps: 0.01696944130504778\n","Training loss per 100 training steps: 0.023070959318815833\n","Training loss per 100 training steps: 0.019036137163761867\n","Training loss epoch: 0.020801011374439876\n","Training accuracy epoch: 0.9937850140056023\n","Validating model...\n","Validation Loss: 0.19111186214928133\n","Validation Accuracy: 0.9503676470588235\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 17.52625695 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15226936143234424\n","Validation Accuracy: 0.9503922325102881\n","Validation duration: 2.4581560999999663 minutes\n","F1-score (test): 84.1%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.69      0.86      0.77      1170\n","        test       0.86      0.89      0.87      2464\n","   treatment       0.87      0.85      0.86      1244\n","\n","   micro avg       0.81      0.87      0.84      4878\n","   macro avg       0.80      0.87      0.83      4878\n","weighted avg       0.82      0.87      0.84      4878\n","\n","!!!!!! Starting model number 5 !!!!!!\n","Points in X_train after augmentation: 11421\n","Points in y_train after augmentation: 11421\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0568695068359375\n","Training loss per 100 training steps: 0.3717464413678292\n","Training loss per 100 training steps: 0.28849168228383976\n","Training loss per 100 training steps: 0.25075899694498593\n","Training loss epoch: 0.23370236384288437\n","Training accuracy epoch: 0.9268116729450401\n","Validating model...\n","Validation Loss: 0.1344118302541913\n","Validation Accuracy: 0.9601518026565465\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07754463702440262\n","Training loss per 100 training steps: 0.06969578841489067\n","Training loss per 100 training steps: 0.07608776603505682\n","Training loss per 100 training steps: 0.07314071784985632\n","Training loss epoch: 0.07515055061147108\n","Training accuracy epoch: 0.9777479957500241\n","Validating model...\n","Validation Loss: 0.15491279143401804\n","Validation Accuracy: 0.9491223908918406\n","Training epoch: 3\n","Training loss per 100 training steps: 0.10361190140247345\n","Training loss per 100 training steps: 0.06594892239686803\n","Training loss per 100 training steps: 0.05388220133803164\n","Training loss per 100 training steps: 0.04802263010389162\n","Training loss epoch: 0.04335638707329543\n","Training accuracy epoch: 0.9876485076789336\n","Validating model...\n","Validation Loss: 0.21853578566650886\n","Validation Accuracy: 0.9570781941808982\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0006906022317707539\n","Training loss per 100 training steps: 0.02081617965342219\n","Training loss per 100 training steps: 0.0236231871199764\n","Training loss per 100 training steps: 0.026632243176698652\n","Training loss epoch: 0.026672192520190666\n","Training accuracy epoch: 0.9920343137254902\n","Validating model...\n","Validation Loss: 0.17166528152016575\n","Validation Accuracy: 0.9595291745730551\n","Training epoch: 5\n","Training loss per 100 training steps: 0.004201732575893402\n","Training loss per 100 training steps: 0.01654695779762904\n","Training loss per 100 training steps: 0.019115676805556554\n","Training loss per 100 training steps: 0.01981153238096361\n","Training loss epoch: 0.020316434892808172\n","Training accuracy epoch: 0.9941351540616247\n","Validating model...\n","Validation Loss: 0.18796466053554825\n","Validation Accuracy: 0.9534214895635674\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0014803193043917418\n","Training loss per 100 training steps: 0.010519168053097829\n","Training loss per 100 training steps: 0.01722142921800642\n","Training loss per 100 training steps: 0.016193531080722683\n","Training loss epoch: 0.016587708129116113\n","Training accuracy epoch: 0.9948354341736695\n","Validating model...\n","Validation Loss: 0.18161081087344108\n","Validation Accuracy: 0.9555562144212524\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 16.947069033333356 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13872778127336427\n","Validation Accuracy: 0.9554357960390947\n","Validation duration: 2.370999816666699 minutes\n","F1-score (test): 84.8%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.86      0.79      0.82      1170\n","        test       0.82      0.92      0.87      2464\n","   treatment       0.91      0.76      0.83      1244\n","\n","   micro avg       0.85      0.85      0.85      4878\n","   macro avg       0.86      0.82      0.84      4878\n","weighted avg       0.85      0.85      0.85      4878\n","\n","!!!!!! Starting model number 6 !!!!!!\n","Points in X_train after augmentation: 11421\n","Points in y_train after augmentation: 11421\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0460898876190186\n","Training loss per 100 training steps: 0.40323656111365497\n","Training loss per 100 training steps: 0.3005478861162541\n","Training loss per 100 training steps: 0.262750112248563\n","Training loss epoch: 0.2394641381398193\n","Training accuracy epoch: 0.9245176518883415\n","Validating model...\n","Validation Loss: 0.14952415574396796\n","Validation Accuracy: 0.9540441176470589\n","Training epoch: 2\n","Training loss per 100 training steps: 0.03205297142267227\n","Training loss per 100 training steps: 0.08645178828651251\n","Training loss per 100 training steps: 0.08163696065700303\n","Training loss per 100 training steps: 0.08075107325857003\n","Training loss epoch: 0.07485350502227076\n","Training accuracy epoch: 0.9754901960784313\n","Validating model...\n","Validation Loss: 0.17060590579286308\n","Validation Accuracy: 0.9604581752055661\n","Training epoch: 3\n","Training loss per 100 training steps: 0.061003874987363815\n","Training loss per 100 training steps: 0.026883799219066\n","Training loss per 100 training steps: 0.03275546170968043\n","Training loss per 100 training steps: 0.03588008023280205\n","Training loss epoch: 0.03720754117508294\n","Training accuracy epoch: 0.989670868347339\n","Validating model...\n","Validation Loss: 0.15544723217631234\n","Validation Accuracy: 0.9622964104996837\n","Training epoch: 4\n","Training loss per 100 training steps: 0.1507328301668167\n","Training loss per 100 training steps: 0.022170480398638726\n","Training loss per 100 training steps: 0.027131383522154197\n","Training loss per 100 training steps: 0.028663430873465498\n","Training loss epoch: 0.02863303946074508\n","Training accuracy epoch: 0.9913340336134454\n","Validating model...\n","Validation Loss: 0.21204527083546945\n","Validation Accuracy: 0.9583135673624289\n","Training epoch: 5\n","Training loss per 100 training steps: 0.001089011668227613\n","Training loss per 100 training steps: 0.01254327170721412\n","Training loss per 100 training steps: 0.01380903686993913\n","Training loss per 100 training steps: 0.013971125679860275\n","Training loss epoch: 0.013329655951471394\n","Training accuracy epoch: 0.9958858543417367\n","Validating model...\n","Validation Loss: 0.24124976932288\n","Validation Accuracy: 0.9531052340290955\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0006795697845518589\n","Training loss per 100 training steps: 0.010704364135139852\n","Training loss per 100 training steps: 0.024912500205804218\n","Training loss per 100 training steps: 0.03012720148227614\n","Training loss epoch: 0.03321021069095572\n","Training accuracy epoch: 0.9908963585434174\n","Validating model...\n","Validation Loss: 0.22814939966066924\n","Validation Accuracy: 0.9476102941176471\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 16.610551083333362 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16379152196572655\n","Validation Accuracy: 0.9501390496399177\n","Validation duration: 2.336167749999974 minutes\n","F1-score (test): 82.4%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.68      0.84      0.75      1170\n","        test       0.86      0.88      0.87      2464\n","   treatment       0.89      0.74      0.81      1244\n","\n","   micro avg       0.82      0.83      0.82      4878\n","   macro avg       0.81      0.82      0.81      4878\n","weighted avg       0.83      0.83      0.83      4878\n","\n","!!!!!! Starting model number 7 !!!!!!\n","Points in X_train after augmentation: 11421\n","Points in y_train after augmentation: 11421\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9066444635391235\n","Training loss per 100 training steps: 0.3326516531334065\n","Training loss per 100 training steps: 0.25325745162530916\n","Training loss per 100 training steps: 0.2198746095293904\n","Training loss epoch: 0.20657252884634278\n","Training accuracy epoch: 0.9358881483627934\n","Validating model...\n","Validation Loss: 0.13693073553982757\n","Validation Accuracy: 0.9598553130929791\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05493740737438202\n","Training loss per 100 training steps: 0.05775485767943711\n","Training loss per 100 training steps: 0.05900137537635112\n","Training loss per 100 training steps: 0.060535348847584235\n","Training loss epoch: 0.06346988340846918\n","Training accuracy epoch: 0.9807241862262146\n","Validating model...\n","Validation Loss: 0.15461806789401225\n","Validation Accuracy: 0.9580071948134092\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04965471848845482\n","Training loss per 100 training steps: 0.04454609783744384\n","Training loss per 100 training steps: 0.03998668651694237\n","Training loss per 100 training steps: 0.0362800522146598\n","Training loss epoch: 0.04064190378578912\n","Training accuracy epoch: 0.9883487877909785\n","Validating model...\n","Validation Loss: 0.17951155622836715\n","Validation Accuracy: 0.9579874288425048\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0008618194260634482\n","Training loss per 100 training steps: 0.01837152795287513\n","Training loss per 100 training steps: 0.02088247019978847\n","Training loss per 100 training steps: 0.02480590792210963\n","Training loss epoch: 0.025092769374688424\n","Training accuracy epoch: 0.9923753984352361\n","Validating model...\n","Validation Loss: 0.1979345125865246\n","Validation Accuracy: 0.9567619386464263\n","Training epoch: 5\n","Training loss per 100 training steps: 0.005184394307434559\n","Training loss per 100 training steps: 0.021978636416329973\n","Training loss per 100 training steps: 0.01844729608476778\n","Training loss per 100 training steps: 0.017193497658283312\n","Training loss epoch: 0.017283907527262502\n","Training accuracy epoch: 0.9951855742296919\n","Validating model...\n","Validation Loss: 0.23430064479893475\n","Validation Accuracy: 0.953125\n","Training epoch: 6\n","Training loss per 100 training steps: 0.046080462634563446\n","Training loss per 100 training steps: 0.012128520787936765\n","Training loss per 100 training steps: 0.015890046423770236\n","Training loss per 100 training steps: 0.017960681977404896\n","Training loss epoch: 0.01930801003037545\n","Training accuracy epoch: 0.9945728291316527\n","Validating model...\n","Validation Loss: 0.2037899889523853\n","Validation Accuracy: 0.9577205882352942\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 16.587344999999974 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13259560568904918\n","Validation Accuracy: 0.9584418402777778\n","Validation duration: 2.326042266666627 minutes\n","F1-score (test): 86.1%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.80      0.82      0.81      1170\n","        test       0.88      0.89      0.89      2464\n","   treatment       0.87      0.84      0.86      1244\n","\n","   micro avg       0.86      0.86      0.86      4878\n","   macro avg       0.85      0.85      0.85      4878\n","weighted avg       0.86      0.86      0.86      4878\n","\n","!!!!!! Starting model number 8 !!!!!!\n","Points in X_train after augmentation: 11421\n","Points in y_train after augmentation: 11421\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0577621459960938\n","Training loss per 100 training steps: 0.31985843205584746\n","Training loss per 100 training steps: 0.2430114846083507\n","Training loss per 100 training steps: 0.2154380763382759\n","Training loss epoch: 0.20359407819504916\n","Training accuracy epoch: 0.9355561189993238\n","Validating model...\n","Validation Loss: 0.13423183442129955\n","Validation Accuracy: 0.9555660974067046\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04586062952876091\n","Training loss per 100 training steps: 0.059702690349578265\n","Training loss per 100 training steps: 0.06190832096252785\n","Training loss per 100 training steps: 0.06423295340311258\n","Training loss epoch: 0.0681664527699427\n","Training accuracy epoch: 0.979954481792717\n","Validating model...\n","Validation Loss: 0.17483062881236786\n","Validation Accuracy: 0.9518896268184693\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0827040746808052\n","Training loss per 100 training steps: 0.0223776367565013\n","Training loss per 100 training steps: 0.02187391132274434\n","Training loss per 100 training steps: 0.02724108604284582\n","Training loss epoch: 0.028644637356421594\n","Training accuracy epoch: 0.9908963585434174\n","Validating model...\n","Validation Loss: 0.1702759103226366\n","Validation Accuracy: 0.9543406072106262\n","Training epoch: 4\n","Training loss per 100 training steps: 0.001506485161371529\n","Training loss per 100 training steps: 0.0221173768387047\n","Training loss per 100 training steps: 0.023986335339045515\n","Training loss per 100 training steps: 0.0257405358738153\n","Training loss epoch: 0.023296452137342907\n","Training accuracy epoch: 0.9926470588235294\n","Validating model...\n","Validation Loss: 0.24830159608687857\n","Validation Accuracy: 0.9497549019607843\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0005820402293466032\n","Training loss per 100 training steps: 0.019322742316638476\n","Training loss per 100 training steps: 0.02349427412897528\n","Training loss per 100 training steps: 0.022151047259040657\n","Training loss epoch: 0.022088129884029084\n","Training accuracy epoch: 0.9942226890756303\n","Validating model...\n","Validation Loss: 0.2145973253751507\n","Validation Accuracy: 0.9518896268184693\n","Training epoch: 6\n","Training loss per 100 training steps: 0.003163921879604459\n","Training loss per 100 training steps: 0.016161715834848767\n","Training loss per 100 training steps: 0.0174785410775108\n","Training loss per 100 training steps: 0.018701437886882083\n","Training loss epoch: 0.02027965332586866\n","Training accuracy epoch: 0.9943102240896359\n","Validating model...\n","Validation Loss: 0.24914384434141182\n","Validation Accuracy: 0.9460685483870968\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 16.46160150000002 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13795162345707435\n","Validation Accuracy: 0.9570111561213992\n","Validation duration: 2.3240377166666195 minutes\n","F1-score (test): 85.4%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.81      0.81      0.81      1170\n","        test       0.89      0.86      0.88      2464\n","   treatment       0.85      0.86      0.86      1244\n","\n","   micro avg       0.86      0.85      0.85      4878\n","   macro avg       0.85      0.84      0.85      4878\n","weighted avg       0.86      0.85      0.85      4878\n","\n","!!!!!! Starting model number 9 !!!!!!\n","Points in X_train after augmentation: 11421\n","Points in y_train after augmentation: 11421\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.6469615697860718\n","Training loss per 100 training steps: 0.3628171005535244\n","Training loss per 100 training steps: 0.27349295749778474\n","Training loss per 100 training steps: 0.23644201532377554\n","Training loss epoch: 0.22327866386204792\n","Training accuracy epoch: 0.9306632135612866\n","Validating model...\n","Validation Loss: 0.14617077691261382\n","Validation Accuracy: 0.9561887254901961\n","Training epoch: 2\n","Training loss per 100 training steps: 0.02886529080569744\n","Training loss per 100 training steps: 0.06068993030613897\n","Training loss per 100 training steps: 0.05896138787948392\n","Training loss per 100 training steps: 0.05792207977667983\n","Training loss epoch: 0.059372440461005434\n","Training accuracy epoch: 0.9829216169226311\n","Validating model...\n","Validation Loss: 0.16087112400918177\n","Validation Accuracy: 0.9555562144212524\n","Training epoch: 3\n","Training loss per 100 training steps: 0.011841315776109695\n","Training loss per 100 training steps: 0.029991237647222852\n","Training loss per 100 training steps: 0.03158425425198995\n","Training loss per 100 training steps: 0.04188320136677777\n","Training loss epoch: 0.04222475880113266\n","Training accuracy epoch: 0.9885329131652661\n","Validating model...\n","Validation Loss: 0.18753574870802991\n","Validation Accuracy: 0.9571078431372549\n","Training epoch: 4\n","Training loss per 100 training steps: 0.017575157806277275\n","Training loss per 100 training steps: 0.023744195114733597\n","Training loss per 100 training steps: 0.030400223415796714\n","Training loss per 100 training steps: 0.03273297291101294\n","Training loss epoch: 0.03751596699844451\n","Training accuracy epoch: 0.9879201680672269\n","Validating model...\n","Validation Loss: 0.19260070417258962\n","Validation Accuracy: 0.9509705091714105\n","Training epoch: 5\n","Training loss per 100 training steps: 0.009892365895211697\n","Training loss per 100 training steps: 0.017563892381742947\n","Training loss per 100 training steps: 0.023056879732004872\n","Training loss per 100 training steps: 0.024044817304608036\n","Training loss epoch: 0.024971727493239622\n","Training accuracy epoch: 0.992296918767507\n","Validating model...\n","Validation Loss: 0.178502382147902\n","Validation Accuracy: 0.9543406072106262\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00461381021887064\n","Training loss per 100 training steps: 0.013461488782598794\n","Training loss per 100 training steps: 0.01726063841589569\n","Training loss per 100 training steps: 0.015854519269095757\n","Training loss epoch: 0.01790618886167597\n","Training accuracy epoch: 0.9949229691876751\n","Validating model...\n","Validation Loss: 0.23113600830387726\n","Validation Accuracy: 0.9457424098671727\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 16.548104216666676 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14321076833908186\n","Validation Accuracy: 0.9548410172325104\n","Validation duration: 2.319400533333343 minutes\n","F1-score (test): 85.2%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.87      0.76      0.81      1170\n","        test       0.84      0.91      0.88      2464\n","   treatment       0.78      0.91      0.84      1244\n","\n","   micro avg       0.83      0.88      0.85      4878\n","   macro avg       0.83      0.86      0.84      4878\n","weighted avg       0.83      0.88      0.85      4878\n","\n","!!!!!! Starting model number 10 !!!!!!\n","Points in X_train after augmentation: 11421\n","Points in y_train after augmentation: 11421\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.3632872104644775\n","Training loss per 100 training steps: 0.3332275527317335\n","Training loss per 100 training steps: 0.258210479212341\n","Training loss per 100 training steps: 0.22566471293420096\n","Training loss epoch: 0.2129617006536208\n","Training accuracy epoch: 0.9328515889114266\n","Validating model...\n","Validation Loss: 0.15302667012849056\n","Validation Accuracy: 0.9555364484503479\n","Training epoch: 2\n","Training loss per 100 training steps: 0.022007368505001068\n","Training loss per 100 training steps: 0.05390167278283746\n","Training loss per 100 training steps: 0.059952472195270196\n","Training loss per 100 training steps: 0.06437333770876788\n","Training loss epoch: 0.06567609700663224\n","Training accuracy epoch: 0.9799454264464407\n","Validating model...\n","Validation Loss: 0.16111184541117765\n","Validation Accuracy: 0.9558527039848198\n","Training epoch: 3\n","Training loss per 100 training steps: 0.004961808677762747\n","Training loss per 100 training steps: 0.030627563399825208\n","Training loss per 100 training steps: 0.036903991064506196\n","Training loss per 100 training steps: 0.03550549071692889\n","Training loss epoch: 0.03879408034934931\n","Training accuracy epoch: 0.9878326330532213\n","Validating model...\n","Validation Loss: 0.1765726240963547\n","Validation Accuracy: 0.953727862112587\n","Training epoch: 4\n","Training loss per 100 training steps: 0.006148126441985369\n","Training loss per 100 training steps: 0.027773437468279705\n","Training loss per 100 training steps: 0.03221973352060672\n","Training loss per 100 training steps: 0.03433757288676557\n","Training loss epoch: 0.033638477172420155\n","Training accuracy epoch: 0.9903711484593838\n","Validating model...\n","Validation Loss: 0.19430561375909247\n","Validation Accuracy: 0.9567817046173308\n","Training epoch: 5\n","Training loss per 100 training steps: 0.15401066839694977\n","Training loss per 100 training steps: 0.025604257972866046\n","Training loss per 100 training steps: 0.024345652773453325\n","Training loss per 100 training steps: 0.023590997861769047\n","Training loss epoch: 0.022901768872410997\n","Training accuracy epoch: 0.992734593837535\n","Validating model...\n","Validation Loss: 0.2369213023683223\n","Validation Accuracy: 0.9476004111321948\n","Training epoch: 6\n","Training loss per 100 training steps: 0.005608572158962488\n","Training loss per 100 training steps: 0.02313282216079579\n","Training loss per 100 training steps: 0.017051388325138698\n","Training loss per 100 training steps: 0.01603109783844839\n","Training loss epoch: 0.017602607394556068\n","Training accuracy epoch: 0.9957107843137255\n","Validating model...\n","Validation Loss: 0.2189172432956505\n","Validation Accuracy: 0.9451296647691335\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 16.584718950000024 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15317848143900778\n","Validation Accuracy: 0.9505208333333334\n","Validation duration: 2.3505278833333554 minutes\n","F1-score (test): 83.2%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.84      0.80      0.82      1170\n","        test       0.89      0.86      0.87      2464\n","   treatment       0.96      0.62      0.75      1244\n","\n","   micro avg       0.89      0.78      0.83      4878\n","   macro avg       0.89      0.76      0.81      4878\n","weighted avg       0.89      0.78      0.83      4878\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0.75\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"oKNxFPucHn_R"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12959632,"status":"ok","timestamp":1657401499796,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"1tBh5gOBHpN1","outputId":"c1d514aa-77e9-4dfc-f92e-b14e8126cf5e"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 100% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 13052\n","Points in y_train after augmentation: 13052\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.208726644515991\n","Training loss per 100 training steps: 0.31575754712713827\n","Training loss per 100 training steps: 0.25127828622524123\n","Training loss per 100 training steps: 0.21619502728049986\n","Training loss per 100 training steps: 0.1978346660566003\n","Training loss epoch: 0.1960501570994144\n","Training accuracy epoch: 0.9390975140056023\n","Validating model...\n","Validation Loss: 0.14573905039943902\n","Validation Accuracy: 0.9558724699557243\n","Training epoch: 2\n","Training loss per 100 training steps: 0.008784808218479156\n","Training loss per 100 training steps: 0.059670857458126426\n","Training loss per 100 training steps: 0.05120057816123729\n","Training loss per 100 training steps: 0.05832969670650391\n","Training loss per 100 training steps: 0.059486789885935074\n","Training loss epoch: 0.05914636014081314\n","Training accuracy epoch: 0.9823069852941176\n","Validating model...\n","Validation Loss: 0.17549535634986801\n","Validation Accuracy: 0.9534214895635674\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0011887900764122605\n","Training loss per 100 training steps: 0.03587546688187545\n","Training loss per 100 training steps: 0.03178935059921385\n","Training loss per 100 training steps: 0.03787189530739731\n","Training loss per 100 training steps: 0.040765255187307725\n","Training loss epoch: 0.040680348641948444\n","Training accuracy epoch: 0.9870557598039216\n","Validating model...\n","Validation Loss: 0.16878443973038493\n","Validation Accuracy: 0.9549434693232132\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0189148411154747\n","Training loss per 100 training steps: 0.022193017528659785\n","Training loss per 100 training steps: 0.020690265292981153\n","Training loss per 100 training steps: 0.02676497862006745\n","Training loss per 100 training steps: 0.027591404964493593\n","Training loss epoch: 0.027680547910944476\n","Training accuracy epoch: 0.9916513480392157\n","Validating model...\n","Validation Loss: 0.25794538635961417\n","Validation Accuracy: 0.9402474699557243\n","Training epoch: 5\n","Training loss per 100 training steps: 0.008500294759869576\n","Training loss per 100 training steps: 0.03103833080895849\n","Training loss per 100 training steps: 0.024678069549677568\n","Training loss per 100 training steps: 0.027062796840091868\n","Training loss per 100 training steps: 0.02941280023723654\n","Training loss epoch: 0.029404096340858457\n","Training accuracy epoch: 0.9907322303921569\n","Validating model...\n","Validation Loss: 0.2045316156474976\n","Validation Accuracy: 0.9454656862745098\n","Training epoch: 6\n","Training loss per 100 training steps: 0.10099741071462631\n","Training loss per 100 training steps: 0.011316661607407236\n","Training loss per 100 training steps: 0.014464716573922886\n","Training loss per 100 training steps: 0.017383190408539324\n","Training loss per 100 training steps: 0.017080667936936963\n","Training loss epoch: 0.016861261765192394\n","Training accuracy epoch: 0.9947150735294118\n","Validating model...\n","Validation Loss: 0.2222537335914168\n","Validation Accuracy: 0.9540243516761544\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 19.165909133333297 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14499466431368124\n","Validation Accuracy: 0.9565047903806585\n","Validation duration: 2.395033933333252 minutes\n","F1-score (test): 85.5%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.75      0.86      0.80      1170\n","        test       0.92      0.86      0.89      2464\n","   treatment       0.82      0.90      0.86      1244\n","\n","   micro avg       0.84      0.87      0.86      4878\n","   macro avg       0.83      0.87      0.85      4878\n","weighted avg       0.85      0.87      0.86      4878\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 13052\n","Points in y_train after augmentation: 13052\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1212377548217773\n","Training loss per 100 training steps: 0.3482142837699687\n","Training loss per 100 training steps: 0.2697196881847447\n","Training loss per 100 training steps: 0.23010650983055514\n","Training loss per 100 training steps: 0.21186003170703116\n","Training loss epoch: 0.21070650814320235\n","Training accuracy epoch: 0.9329810049019608\n","Validating model...\n","Validation Loss: 0.14474212837533332\n","Validation Accuracy: 0.9531052340290955\n","Training epoch: 2\n","Training loss per 100 training steps: 0.15945740044116974\n","Training loss per 100 training steps: 0.07420625219508858\n","Training loss per 100 training steps: 0.06569997474767815\n","Training loss per 100 training steps: 0.07073269417780943\n","Training loss per 100 training steps: 0.06802036374255184\n","Training loss epoch: 0.06747923974377473\n","Training accuracy epoch: 0.978608630952381\n","Validating model...\n","Validation Loss: 0.17887457762160064\n","Validation Accuracy: 0.9567817046173308\n","Training epoch: 3\n","Training loss per 100 training steps: 0.009052879177033901\n","Training loss per 100 training steps: 0.027552917618408227\n","Training loss per 100 training steps: 0.02527151003625332\n","Training loss per 100 training steps: 0.02799523390620325\n","Training loss per 100 training steps: 0.028071277975258616\n","Training loss epoch: 0.027917963908097875\n","Training accuracy epoch: 0.9905024509803921\n","Validating model...\n","Validation Loss: 0.21913330763259986\n","Validation Accuracy: 0.9540342346616066\n","Training epoch: 4\n","Training loss per 100 training steps: 0.023014821112155914\n","Training loss per 100 training steps: 0.023108587679822035\n","Stopping epoch...\n","Training loss epoch: 0.023108587679822035\n","Training accuracy epoch: 0.9832920792079208\n","Validating model...\n","Validation Loss: 0.22239033173850747\n","Validation Accuracy: 0.953125\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0008241852046921849\n","Training loss per 100 training steps: 0.0252329740275071\n","Training loss per 100 training steps: 0.024100381150072563\n","Training loss per 100 training steps: 0.02436306151740123\n","Training loss per 100 training steps: 0.027798526852662812\n","Training loss epoch: 0.02788596908530784\n","Training accuracy epoch: 0.9911917892156863\n","Validating model...\n","Validation Loss: 0.20115074344115177\n","Validation Accuracy: 0.9497549019607843\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0027485282626003027\n","Training loss per 100 training steps: 0.02134885643216975\n","Training loss per 100 training steps: 0.015300888593791664\n","Training loss per 100 training steps: 0.015327790820365075\n","Training loss per 100 training steps: 0.0174384342976181\n","Training loss epoch: 0.01749846338009543\n","Training accuracy epoch: 0.9948573179271709\n","Validating model...\n","Validation Loss: 0.2675836290624883\n","Validation Accuracy: 0.9488061353573688\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 17.48243665000009 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13025148652862603\n","Validation Accuracy: 0.9574090149176955\n","Validation duration: 2.4489171333333313 minutes\n","F1-score (test): 86.0%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.82      0.78      0.80      1170\n","        test       0.88      0.90      0.89      2464\n","   treatment       0.82      0.89      0.86      1244\n","\n","   micro avg       0.85      0.87      0.86      4878\n","   macro avg       0.84      0.86      0.85      4878\n","weighted avg       0.85      0.87      0.86      4878\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 13052\n","Points in y_train after augmentation: 13052\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.303417682647705\n","Training loss per 100 training steps: 0.323919995697123\n","Training loss per 100 training steps: 0.26146535833472784\n","Training loss per 100 training steps: 0.22213931850148397\n","Training loss per 100 training steps: 0.20188387902685792\n","Training loss epoch: 0.20029933814429587\n","Training accuracy epoch: 0.9358040091036415\n","Validating model...\n","Validation Loss: 0.14704610391602138\n","Validation Accuracy: 0.9561788425047438\n","Training epoch: 2\n","Training loss per 100 training steps: 0.036352019757032394\n","Training loss per 100 training steps: 0.05306224226559706\n","Training loss per 100 training steps: 0.061128302422278\n","Training loss per 100 training steps: 0.05967075225666623\n","Training loss per 100 training steps: 0.062043179223137415\n","Training loss epoch: 0.06245324234637961\n","Training accuracy epoch: 0.9819240196078431\n","Validating model...\n","Validation Loss: 0.15633153946221093\n","Validation Accuracy: 0.9586298228969007\n","Training epoch: 3\n","Training loss per 100 training steps: 0.010356392711400986\n","Training loss per 100 training steps: 0.028739957634525578\n","Training loss per 100 training steps: 0.03142459466051431\n","Training loss per 100 training steps: 0.033477782704395574\n","Training loss per 100 training steps: 0.03530447968607536\n","Training loss epoch: 0.03518642411654582\n","Training accuracy epoch: 0.9895067401960784\n","Validating model...\n","Validation Loss: 0.18484328768681735\n","Validation Accuracy: 0.9564950980392157\n","Training epoch: 4\n","Training loss per 100 training steps: 0.002375729149207473\n","Training loss per 100 training steps: 0.01980939903310938\n","Training loss per 100 training steps: 0.03189622610152221\n","Training loss per 100 training steps: 0.03482703119175539\n","Training loss per 100 training steps: 0.03320771451742128\n","Training loss epoch: 0.03276972302565435\n","Training accuracy epoch: 0.9908854166666666\n","Validating model...\n","Validation Loss: 0.18898171321751422\n","Validation Accuracy: 0.9570979601518027\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0005478065577335656\n","Training loss per 100 training steps: 0.021632687166208715\n","Training loss per 100 training steps: 0.027453055778612147\n","Training loss per 100 training steps: 0.02622165339937019\n","Training loss per 100 training steps: 0.028545548759288785\n","Training loss epoch: 0.028403336203279884\n","Training accuracy epoch: 0.9908854166666666\n","Validating model...\n","Validation Loss: 0.20809881150889137\n","Validation Accuracy: 0.9549533523086654\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0017092073103412986\n","Training loss per 100 training steps: 0.016821257724532728\n","Training loss per 100 training steps: 0.01626790680259985\n","Training loss per 100 training steps: 0.013871659651693371\n","Training loss per 100 training steps: 0.01519168787495787\n","Training loss epoch: 0.01539080855735508\n","Training accuracy epoch: 0.9953934698879552\n","Validating model...\n","Validation Loss: 0.23971128220428534\n","Validation Accuracy: 0.949745018975332\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 18.998782949999924 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15170708907222702\n","Validation Accuracy: 0.9537760416666666\n","Validation duration: 2.3370613166667074 minutes\n","F1-score (test): 84.2%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.72      0.85      0.78      1170\n","        test       0.89      0.85      0.87      2464\n","   treatment       0.91      0.79      0.85      1244\n","\n","   micro avg       0.85      0.84      0.84      4878\n","   macro avg       0.84      0.83      0.83      4878\n","weighted avg       0.86      0.84      0.84      4878\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 13052\n","Points in y_train after augmentation: 13052\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.4284818172454834\n","Training loss per 100 training steps: 0.33854154655986496\n","Training loss per 100 training steps: 0.2619029062600871\n","Training loss per 100 training steps: 0.22948506620845624\n","Training loss per 100 training steps: 0.20852890701040142\n","Training loss epoch: 0.2072580705200523\n","Training accuracy epoch: 0.9342721463585434\n","Validating model...\n","Validation Loss: 0.16080623370248312\n","Validation Accuracy: 0.9482230392156863\n","Training epoch: 2\n","Training loss per 100 training steps: 0.036853522062301636\n","Training loss per 100 training steps: 0.06284487230638687\n","Training loss per 100 training steps: 0.055210249875533156\n","Training loss per 100 training steps: 0.06020416350117838\n","Training loss per 100 training steps: 0.06325562714635072\n","Training loss epoch: 0.06375257944027372\n","Training accuracy epoch: 0.9799873074229692\n","Validating model...\n","Validation Loss: 0.18975284948543297\n","Validation Accuracy: 0.9429850569259962\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03840271383523941\n","Training loss per 100 training steps: 0.02257153675038515\n","Training loss per 100 training steps: 0.02568027909192956\n","Training loss per 100 training steps: 0.02992215512190447\n","Training loss per 100 training steps: 0.02987342422707308\n","Training loss epoch: 0.029677147958222228\n","Training accuracy epoch: 0.9907212885154062\n","Validating model...\n","Validation Loss: 0.21075456444882815\n","Validation Accuracy: 0.9531151170145478\n","Training epoch: 4\n","Training loss per 100 training steps: 0.008584844879806042\n","Training loss per 100 training steps: 0.01742142643047598\n","Training loss per 100 training steps: 0.032522500471637086\n","Training loss per 100 training steps: 0.03309434039088545\n","Training loss per 100 training steps: 0.03099755232238055\n","Training loss epoch: 0.03179111051976375\n","Training accuracy epoch: 0.9901960784313726\n","Validating model...\n","Validation Loss: 0.20546957315544953\n","Validation Accuracy: 0.9583234503478811\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0013624678831547499\n","Training loss per 100 training steps: 0.0195029020461595\n","Training loss per 100 training steps: 0.021454042924477706\n","Training loss per 100 training steps: 0.017780869704728443\n","Training loss per 100 training steps: 0.01650035273328138\n","Training loss epoch: 0.0168947624588327\n","Training accuracy epoch: 0.9956232492997199\n","Validating model...\n","Validation Loss: 0.27166386970131107\n","Validation Accuracy: 0.9552696078431373\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0004979195655323565\n","Training loss per 100 training steps: 0.019296982920945317\n","Training loss per 100 training steps: 0.013771721192272738\n","Training loss per 100 training steps: 0.015575148954474002\n","Training loss per 100 training steps: 0.017470027642451796\n","Training loss epoch: 0.017209793865401713\n","Training accuracy epoch: 0.9947150735294118\n","Validating model...\n","Validation Loss: 0.2200322452271768\n","Validation Accuracy: 0.9546469797596459\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 18.56763601666668 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15356424898210982\n","Validation Accuracy: 0.9500868055555556\n","Validation duration: 2.3007954999999733 minutes\n","F1-score (test): 83.9%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.81      0.80      0.80      1170\n","        test       0.77      0.92      0.84      2464\n","   treatment       0.90      0.83      0.86      1244\n","\n","   micro avg       0.81      0.87      0.84      4878\n","   macro avg       0.83      0.85      0.84      4878\n","weighted avg       0.82      0.87      0.84      4878\n","\n","!!!!!! Starting model number 5 !!!!!!\n","Points in X_train after augmentation: 13052\n","Points in y_train after augmentation: 13052\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.173312187194824\n","Training loss per 100 training steps: 0.35083373798297185\n","Training loss per 100 training steps: 0.26735908983840573\n","Training loss per 100 training steps: 0.22856482119296379\n","Training loss per 100 training steps: 0.20458212218821012\n","Training loss epoch: 0.20256448560736745\n","Training accuracy epoch: 0.9329810049019608\n","Validating model...\n","Validation Loss: 0.1650100846491827\n","Validation Accuracy: 0.949745018975332\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04083754122257233\n","Training loss per 100 training steps: 0.056380710224528785\n","Training loss per 100 training steps: 0.061451574784601615\n","Training loss per 100 training steps: 0.05912745478323218\n","Training loss per 100 training steps: 0.056496714636918036\n","Training loss epoch: 0.05689355160718026\n","Training accuracy epoch: 0.9810486694677871\n","Validating model...\n","Validation Loss: 0.18887718823651656\n","Validation Accuracy: 0.9524924889310563\n","Training epoch: 3\n","Training loss per 100 training steps: 0.16410185396671295\n","Training loss per 100 training steps: 0.03556634898246773\n","Training loss per 100 training steps: 0.03416441104303008\n","Training loss per 100 training steps: 0.04015136330018742\n","Training loss per 100 training steps: 0.03784977766293846\n","Training loss epoch: 0.03792029098629285\n","Training accuracy epoch: 0.989342612044818\n","Validating model...\n","Validation Loss: 0.15898140784160134\n","Validation Accuracy: 0.9613970588235294\n","Training epoch: 4\n","Training loss per 100 training steps: 0.002251111203804612\n","Training loss per 100 training steps: 0.015994694240110012\n","Training loss per 100 training steps: 0.013001425877365223\n","Training loss per 100 training steps: 0.01968300581801036\n","Training loss per 100 training steps: 0.02375173360767468\n","Training loss epoch: 0.02410891423235572\n","Training accuracy epoch: 0.9927127100840336\n","Validating model...\n","Validation Loss: 0.20903663533824204\n","Validation Accuracy: 0.9515634882985452\n","Training epoch: 5\n","Training loss per 100 training steps: 0.3001707196235657\n","Training loss per 100 training steps: 0.023851505021096696\n","Training loss per 100 training steps: 0.028273591281010986\n","Training loss per 100 training steps: 0.025156999300903118\n","Training loss per 100 training steps: 0.02305764113938984\n","Training loss epoch: 0.02283705521917642\n","Training accuracy epoch: 0.9931066176470589\n","Validating model...\n","Validation Loss: 0.20092275774211385\n","Validation Accuracy: 0.9570781941808982\n","Training epoch: 6\n","Training loss per 100 training steps: 0.004118341486901045\n","Training loss per 100 training steps: 0.010644478353269463\n","Training loss per 100 training steps: 0.011977291056021598\n","Training loss per 100 training steps: 0.01336747881848782\n","Training loss per 100 training steps: 0.012765807250385147\n","Training loss epoch: 0.012755716072990931\n","Training accuracy epoch: 0.9957107843137255\n","Validating model...\n","Validation Loss: 0.22501635050481555\n","Validation Accuracy: 0.9601616856419988\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0009837178513407707\n","Training loss per 100 training steps: 0.027535722482924137\n","Training loss per 100 training steps: 0.02023496583982461\n","Training loss per 100 training steps: 0.01790440318943736\n","Training loss per 100 training steps: 0.017733787414919763\n","Training loss epoch: 0.017575660564605144\n","Training accuracy epoch: 0.9943321078431373\n","Validating model...\n","Validation Loss: 0.2860490369851451\n","Validation Accuracy: 0.9531151170145478\n","Training epoch: 8\n","Training loss per 100 training steps: 0.06211832910776138\n","Training loss per 100 training steps: 0.009610037490743384\n","Training loss per 100 training steps: 0.014941618329779053\n","Training loss per 100 training steps: 0.01289575920154343\n","Training loss per 100 training steps: 0.014299961147502418\n","Training loss epoch: 0.01436534390621305\n","Training accuracy epoch: 0.9959405637254902\n","Validating model...\n","Validation Loss: 0.2205060246716112\n","Validation Accuracy: 0.9552399588867806\n","Training epoch: 9\n","Patience limit reached\n","Training duration: 24.8815957666667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1552279287923705\n","Validation Accuracy: 0.9604833783436214\n","Validation duration: 2.3136782833333807 minutes\n","F1-score (test): 87.2%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.78      0.88      0.83      1170\n","        test       0.88      0.90      0.89      2464\n","   treatment       0.88      0.89      0.89      1244\n","\n","   micro avg       0.85      0.89      0.87      4878\n","   macro avg       0.85      0.89      0.87      4878\n","weighted avg       0.85      0.89      0.87      4878\n","\n","!!!!!! Starting model number 6 !!!!!!\n","Points in X_train after augmentation: 13052\n","Points in y_train after augmentation: 13052\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1960129737854004\n","Training loss per 100 training steps: 0.33154256936937276\n","Training loss per 100 training steps: 0.24882296508002044\n","Training loss per 100 training steps: 0.21427793274525292\n","Training loss per 100 training steps: 0.1995073094060575\n","Training loss epoch: 0.19732814852499822\n","Training accuracy epoch: 0.9371936274509803\n","Validating model...\n","Validation Loss: 0.16278755127032304\n","Validation Accuracy: 0.9543208412397217\n","Training epoch: 2\n","Training loss per 100 training steps: 0.03338158503174782\n","Training loss per 100 training steps: 0.062301147438696414\n","Training loss per 100 training steps: 0.05956364780506907\n","Training loss per 100 training steps: 0.061506884822705485\n","Training loss per 100 training steps: 0.061497660113981646\n","Training loss epoch: 0.06129100139985573\n","Training accuracy epoch: 0.9808517156862745\n","Validating model...\n","Validation Loss: 0.1712890892659369\n","Validation Accuracy: 0.9527889784946236\n","Training epoch: 3\n","Training loss per 100 training steps: 0.008971509523689747\n","Training loss per 100 training steps: 0.02985085784238625\n","Training loss per 100 training steps: 0.03251059937064388\n","Training loss per 100 training steps: 0.03685712163236791\n","Training loss per 100 training steps: 0.038167521342440065\n","Training loss epoch: 0.03771249452827261\n","Training accuracy epoch: 0.9875919117647058\n","Validating model...\n","Validation Loss: 0.1918160576457797\n","Validation Accuracy: 0.9506740196078431\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0020206968765705824\n","Training loss per 100 training steps: 0.02055904251006939\n","Training loss per 100 training steps: 0.02446429505428781\n","Training loss per 100 training steps: 0.02857631406718958\n","Training loss per 100 training steps: 0.029321081935125577\n","Training loss epoch: 0.029241144921280805\n","Training accuracy epoch: 0.9909620098039216\n","Validating model...\n","Validation Loss: 0.19799493117712771\n","Validation Accuracy: 0.9592524509803921\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0007501989020965993\n","Training loss per 100 training steps: 0.014257936778053005\n","Training loss per 100 training steps: 0.01653708339815343\n","Training loss per 100 training steps: 0.016066425648963455\n","Training loss per 100 training steps: 0.015901295788462177\n","Training loss epoch: 0.017198456411243374\n","Training accuracy epoch: 0.9955575980392157\n","Validating model...\n","Validation Loss: 0.2226299447856767\n","Validation Accuracy: 0.9528087444655281\n","Training epoch: 6\n","Training loss per 100 training steps: 0.003677760949358344\n","Training loss per 100 training steps: 0.018125397293963286\n","Training loss per 100 training steps: 0.01512749668360463\n","Training loss per 100 training steps: 0.01584348586101535\n","Training loss per 100 training steps: 0.01768468334199483\n","Training loss epoch: 0.017880248563290246\n","Training accuracy epoch: 0.9944087009803921\n","Validating model...\n","Validation Loss: 0.26515376514312355\n","Validation Accuracy: 0.9525023719165086\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 18.65193833333336 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14943307917699847\n","Validation Accuracy: 0.9542623135288066\n","Validation duration: 2.316564950000005 minutes\n","F1-score (test): 85.3%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.85      0.82      0.83      1170\n","        test       0.80      0.93      0.86      2464\n","   treatment       0.86      0.87      0.87      1244\n","\n","   micro avg       0.82      0.89      0.85      4878\n","   macro avg       0.83      0.87      0.85      4878\n","weighted avg       0.82      0.89      0.85      4878\n","\n","!!!!!! Starting model number 7 !!!!!!\n","Points in X_train after augmentation: 13052\n","Points in y_train after augmentation: 13052\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.096935987472534\n","Training loss per 100 training steps: 0.36322796241481703\n","Training loss per 100 training steps: 0.2848244589007464\n","Training loss per 100 training steps: 0.24590817908214968\n","Training loss per 100 training steps: 0.22735827956975732\n","Training loss epoch: 0.2264974074741807\n","Training accuracy epoch: 0.9299719887955182\n","Validating model...\n","Validation Loss: 0.164133504781799\n","Validation Accuracy: 0.9442204301075269\n","Training epoch: 2\n","Training loss per 100 training steps: 0.03470753878355026\n","Training loss per 100 training steps: 0.07263307734669214\n","Training loss per 100 training steps: 0.07231638415725855\n","Training loss per 100 training steps: 0.07674351096171823\n","Training loss per 100 training steps: 0.07553008296515357\n","Training loss epoch: 0.075747348459474\n","Training accuracy epoch: 0.9778645833333334\n","Validating model...\n","Validation Loss: 0.1712495566907284\n","Validation Accuracy: 0.9558724699557243\n","Training epoch: 3\n","Training loss per 100 training steps: 0.012259199284017086\n","Training loss per 100 training steps: 0.03340044659262726\n","Training loss per 100 training steps: 0.03398812641473649\n","Training loss per 100 training steps: 0.03872145215879764\n","Training loss per 100 training steps: 0.04177732561301833\n","Training loss epoch: 0.041568367823107535\n","Training accuracy epoch: 0.9879639355742297\n","Validating model...\n","Validation Loss: 0.1891554632491213\n","Validation Accuracy: 0.9527988614800759\n","Training epoch: 4\n","Training loss per 100 training steps: 0.008411220274865627\n","Training loss per 100 training steps: 0.02025962045956818\n","Training loss per 100 training steps: 0.028768086878771647\n","Training loss per 100 training steps: 0.027808435942047117\n","Training loss per 100 training steps: 0.02626216623685648\n","Training loss epoch: 0.02632165534326786\n","Training accuracy epoch: 0.9919577205882353\n","Validating model...\n","Validation Loss: 0.23374974129047568\n","Validation Accuracy: 0.9561887254901961\n","Training epoch: 5\n","Training loss per 100 training steps: 0.001125226030126214\n","Training loss per 100 training steps: 0.021872907287399698\n","Training loss per 100 training steps: 0.022496254301504856\n","Training loss per 100 training steps: 0.021597945052268683\n","Training loss per 100 training steps: 0.02491222603844323\n","Training loss epoch: 0.025030616231650163\n","Training accuracy epoch: 0.9922640931372549\n","Validating model...\n","Validation Loss: 0.19098647835141724\n","Validation Accuracy: 0.9552597248576851\n","Training epoch: 6\n","Training loss per 100 training steps: 0.009828480891883373\n","Training loss per 100 training steps: 0.02505932962158833\n","Training loss per 100 training steps: 0.025302401348248828\n","Training loss per 100 training steps: 0.024178279923593997\n","Training loss per 100 training steps: 0.0227788943589087\n","Training loss epoch: 0.022417415277998894\n","Training accuracy epoch: 0.9934895833333334\n","Validating model...\n","Validation Loss: 0.22556570134018364\n","Validation Accuracy: 0.9509705091714105\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 18.551840233333376 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.18147872954917452\n","Validation Accuracy: 0.9398509837962963\n","Validation duration: 2.297585999999986 minutes\n","F1-score (test): 81.2%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.66      0.86      0.75      1170\n","        test       0.77      0.94      0.84      2464\n","   treatment       0.88      0.75      0.81      1244\n","\n","   micro avg       0.76      0.87      0.81      4878\n","   macro avg       0.77      0.85      0.80      4878\n","weighted avg       0.77      0.87      0.81      4878\n","\n","!!!!!! Starting model number 8 !!!!!!\n","Points in X_train after augmentation: 13052\n","Points in y_train after augmentation: 13052\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1333119869232178\n","Training loss per 100 training steps: 0.34693637431258023\n","Training loss per 100 training steps: 0.2725313164534705\n","Training loss per 100 training steps: 0.2309158904744046\n","Training loss per 100 training steps: 0.2102614708762718\n","Training loss epoch: 0.20937504545744398\n","Training accuracy epoch: 0.9342721463585434\n","Validating model...\n","Validation Loss: 0.1637488730667232\n","Validation Accuracy: 0.9570979601518027\n","Training epoch: 2\n","Training loss per 100 training steps: 0.03475469723343849\n","Training loss per 100 training steps: 0.05378511615125186\n","Training loss per 100 training steps: 0.06017793367955074\n","Training loss per 100 training steps: 0.05957729690646338\n","Training loss per 100 training steps: 0.05961887926406731\n","Training loss epoch: 0.05902089176736042\n","Training accuracy epoch: 0.9820006127450981\n","Validating model...\n","Validation Loss: 0.14575051348519458\n","Validation Accuracy: 0.9586298228969007\n","Training epoch: 3\n","Training loss per 100 training steps: 0.004532163962721825\n","Training loss per 100 training steps: 0.022086169200258948\n","Training loss per 100 training steps: 0.026623657745507835\n","Training loss per 100 training steps: 0.026749249837162866\n","Training loss per 100 training steps: 0.030326807313552823\n","Training loss epoch: 0.030743949526225275\n","Training accuracy epoch: 0.9899662990196079\n","Validating model...\n","Validation Loss: 0.1794498471403951\n","Validation Accuracy: 0.9552696078431373\n","Training epoch: 4\n","Training loss per 100 training steps: 0.15361979603767395\n","Training loss per 100 training steps: 0.01796426799316605\n","Training loss per 100 training steps: 0.019431935599831335\n","Training loss per 100 training steps: 0.026335338457020314\n","Training loss per 100 training steps: 0.031414232467315124\n","Training loss epoch: 0.03125277175950389\n","Training accuracy epoch: 0.9915747549019608\n","Validating model...\n","Validation Loss: 0.18524620077782766\n","Validation Accuracy: 0.9577205882352942\n","Training epoch: 5\n","Training loss per 100 training steps: 0.03194667026400566\n","Training loss per 100 training steps: 0.020686060746631464\n","Training loss per 100 training steps: 0.023411332684498402\n","Training loss per 100 training steps: 0.02308984551343029\n","Training loss per 100 training steps: 0.022036551659036382\n","Training loss epoch: 0.02201885841168405\n","Training accuracy epoch: 0.9939491421568627\n","Validating model...\n","Validation Loss: 0.19150375829143312\n","Validation Accuracy: 0.9592524509803921\n","Training epoch: 6\n","Training loss per 100 training steps: 0.004683299921452999\n","Training loss per 100 training steps: 0.00633591332677164\n","Training loss per 100 training steps: 0.01649850290558974\n","Training loss per 100 training steps: 0.04218421611307669\n","Training loss per 100 training steps: 0.05156761440630271\n","Training loss epoch: 0.05094982968792322\n","Training accuracy epoch: 0.9839154411764706\n","Validating model...\n","Validation Loss: 0.22465885472375507\n","Validation Accuracy: 0.953401723592663\n","Training epoch: 7\n","Training loss per 100 training steps: 0.008352207951247692\n","Training loss per 100 training steps: 0.02746836829969157\n","Training loss per 100 training steps: 0.03067164291462349\n","Training loss per 100 training steps: 0.026091144666718892\n","Training loss per 100 training steps: 0.022585243580077876\n","Training loss epoch: 0.022367402859755185\n","Training accuracy epoch: 0.9927127100840336\n","Validating model...\n","Validation Loss: 0.21476117865106562\n","Validation Accuracy: 0.9574142156862745\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 21.49982046666664 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16673376157080014\n","Validation Accuracy: 0.9561270254629629\n","Validation duration: 2.274638283333237 minutes\n","F1-score (test): 85.5%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.72      0.86      0.78      1170\n","        test       0.89      0.89      0.89      2464\n","   treatment       0.90      0.84      0.87      1244\n","\n","   micro avg       0.84      0.87      0.86      4878\n","   macro avg       0.83      0.86      0.85      4878\n","weighted avg       0.85      0.87      0.86      4878\n","\n","!!!!!! Starting model number 9 !!!!!!\n","Points in X_train after augmentation: 13052\n","Points in y_train after augmentation: 13052\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0286312103271484\n","Training loss per 100 training steps: 0.3374291927655145\n","Training loss per 100 training steps: 0.26370806377659095\n","Training loss per 100 training steps: 0.22574944413604334\n","Training loss per 100 training steps: 0.20766281862127736\n","Training loss epoch: 0.2055802986290598\n","Training accuracy epoch: 0.9330575980392157\n","Validating model...\n","Validation Loss: 0.13747926309759564\n","Validation Accuracy: 0.9555660974067046\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09864968061447144\n","Training loss per 100 training steps: 0.06518178848817133\n","Training loss per 100 training steps: 0.06912955006732796\n","Training loss per 100 training steps: 0.0679719161483586\n","Training loss per 100 training steps: 0.06976333694843728\n","Training loss epoch: 0.07010792093990627\n","Training accuracy epoch: 0.9778645833333334\n","Validating model...\n","Validation Loss: 0.18015165966319138\n","Validation Accuracy: 0.9509705091714105\n","Training epoch: 3\n","Training loss per 100 training steps: 0.010199797339737415\n","Training loss per 100 training steps: 0.03504089156908011\n","Training loss per 100 training steps: 0.03141172179478494\n","Training loss per 100 training steps: 0.03302671737250318\n","Training loss per 100 training steps: 0.034339575071417335\n","Training loss epoch: 0.03384858134271709\n","Training accuracy epoch: 0.9904258578431373\n","Validating model...\n","Validation Loss: 0.21971517870220922\n","Validation Accuracy: 0.9555759803921569\n","Training epoch: 4\n","Training loss per 100 training steps: 0.006977609824389219\n","Training loss per 100 training steps: 0.020715790799021316\n","Training loss per 100 training steps: 0.018795610727601574\n","Training loss per 100 training steps: 0.024472822964725555\n","Training loss per 100 training steps: 0.026670867180229083\n","Training loss epoch: 0.026679722611244835\n","Training accuracy epoch: 0.9918045343137255\n","Validating model...\n","Validation Loss: 0.21499401309148536\n","Validation Accuracy: 0.9472841555977229\n","Training epoch: 5\n","Training loss per 100 training steps: 0.017927024513483047\n","Training loss per 100 training steps: 0.00931928499119407\n","Training loss per 100 training steps: 0.015091433191040081\n","Training loss per 100 training steps: 0.016183701734028777\n","Training loss per 100 training steps: 0.022045357528520326\n","Training loss epoch: 0.02249998389689769\n","Training accuracy epoch: 0.9937740721288516\n","Validating model...\n","Validation Loss: 0.23557427880244658\n","Validation Accuracy: 0.9417398007590133\n","Training epoch: 6\n","Training loss per 100 training steps: 0.005494636949151754\n","Training loss per 100 training steps: 0.013869419167196324\n","Training loss per 100 training steps: 0.015069953348100722\n","Training loss per 100 training steps: 0.016068497768980745\n","Training loss per 100 training steps: 0.018543089259910266\n","Training loss epoch: 0.01877152833007059\n","Training accuracy epoch: 0.9945618872549019\n","Validating model...\n","Validation Loss: 0.25932084013594947\n","Validation Accuracy: 0.9518995098039216\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 18.932185516666625 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13596559526114207\n","Validation Accuracy: 0.9569589120370371\n","Validation duration: 2.3356972500000364 minutes\n","F1-score (test): 85.7%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.82      0.82      0.82      1170\n","        test       0.88      0.88      0.88      2464\n","   treatment       0.80      0.90      0.85      1244\n","\n","   micro avg       0.84      0.87      0.86      4878\n","   macro avg       0.83      0.87      0.85      4878\n","weighted avg       0.84      0.87      0.86      4878\n","\n","!!!!!! Starting model number 10 !!!!!!\n","Points in X_train after augmentation: 13052\n","Points in y_train after augmentation: 13052\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0634303092956543\n","Training loss per 100 training steps: 0.3441353890823551\n","Training loss per 100 training steps: 0.26696947767904294\n","Training loss per 100 training steps: 0.23163625067935334\n","Training loss per 100 training steps: 0.20747877989763258\n","Training loss epoch: 0.20567908343703797\n","Training accuracy epoch: 0.9358915441176471\n","Validating model...\n","Validation Loss: 0.16312404567896224\n","Validation Accuracy: 0.9543406072106262\n","Training epoch: 2\n","Training loss per 100 training steps: 0.015135444700717926\n","Training loss per 100 training steps: 0.06443796856882106\n","Training loss per 100 training steps: 0.06168788945214332\n","Training loss per 100 training steps: 0.0673127895672852\n","Training loss per 100 training steps: 0.0654259897069425\n","Training loss epoch: 0.06609186905666765\n","Training accuracy epoch: 0.9799873074229692\n","Validating model...\n","Validation Loss: 0.18869006721697765\n","Validation Accuracy: 0.955862586970272\n","Training epoch: 3\n","Training loss per 100 training steps: 0.004420639481395483\n","Training loss per 100 training steps: 0.03493775143910494\n","Training loss per 100 training steps: 0.029852234772626607\n","Training loss per 100 training steps: 0.03529608861424889\n","Training loss per 100 training steps: 0.034520748091331495\n","Training loss epoch: 0.034422959357613636\n","Training accuracy epoch: 0.9904258578431373\n","Validating model...\n","Validation Loss: 0.18647654847739556\n","Validation Accuracy: 0.9540144686907022\n","Training epoch: 4\n","Training loss per 100 training steps: 0.004101726692169905\n","Training loss per 100 training steps: 0.015532618181781133\n","Training loss per 100 training steps: 0.01317537553458989\n","Training loss per 100 training steps: 0.018724724441966694\n","Training loss per 100 training steps: 0.024969392322461665\n","Training loss epoch: 0.026033949890060123\n","Training accuracy epoch: 0.9916294642857143\n","Validating model...\n","Validation Loss: 0.23533435805938116\n","Validation Accuracy: 0.9445366856419988\n","Training epoch: 5\n","Training loss per 100 training steps: 0.17751997709274292\n","Training loss per 100 training steps: 0.033557056617925386\n","Training loss per 100 training steps: 0.03487107396257268\n","Training loss per 100 training steps: 0.0323228000518572\n","Training loss per 100 training steps: 0.029080743502905043\n","Training loss epoch: 0.028963595605983203\n","Training accuracy epoch: 0.9920343137254902\n","Validating model...\n","Validation Loss: 0.19514800608186644\n","Validation Accuracy: 0.9583234503478811\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0038736164569854736\n","Training loss per 100 training steps: 0.01761234848786579\n","Training loss per 100 training steps: 0.01536465181098308\n","Training loss per 100 training steps: 0.01914854129079027\n","Training loss per 100 training steps: 0.018594694995983825\n","Training loss epoch: 0.018975465725174324\n","Training accuracy epoch: 0.9943321078431373\n","Validating model...\n","Validation Loss: 0.2159620318270754\n","Validation Accuracy: 0.9589361954459203\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 19.19537663333334 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1544559174714474\n","Validation Accuracy: 0.9547164351851852\n","Validation duration: 2.379647983333416 minutes\n","F1-score (test): 84.1%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.73      0.85      0.79      1170\n","        test       0.94      0.82      0.87      2464\n","   treatment       0.83      0.84      0.84      1244\n","\n","   micro avg       0.85      0.83      0.84      4878\n","   macro avg       0.83      0.84      0.83      4878\n","weighted avg       0.86      0.83      0.84      4878\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 1\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"1tBh5gOBHpN1"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["8a28bd70307b45d888888f97e267ac0b","369b6ac6fab34c0381587a2875504651","2f8aa33cd70142449a20a428b592c46a","36b1b0e4541b42ffb7461231dceea20b","72db0b3308ad49c88c7b5f67bc8a3bc0","6226d078bff74dfc9a30cec5d9d270ac","175de7028ba147478d5c8e5746616aa4","d5470b1c3a9d437887c7d2e67ff9fd58","2a5bc01e7de24916bd3031fdb0a5a8f1","5a6a90cc22f8469f87f86fe0e8291a45","a407e571b30341f79fcf6a2110f37d0e"]},"id":"Zjhn7-LqHri0","outputId":"8f4f212b-86c8-483d-e252-1b22fa159e6f","executionInfo":{"status":"ok","timestamp":1657574685854,"user_tz":240,"elapsed":3577786,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}}},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 200% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 19578\n","Points in y_train after augmentation: 19578\n","Device:  cuda\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8a28bd70307b45d888888f97e267ac0b","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/422M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1510531902313232\n","Training loss per 100 training steps: 0.3358585459023419\n","Training loss per 100 training steps: 0.2605309724918942\n","Training loss per 100 training steps: 0.23197141531669221\n","Training loss per 100 training steps: 0.21328314633440792\n","Training loss per 100 training steps: 0.19248070362620726\n","Training loss per 100 training steps: 0.17948518585206044\n","Training loss epoch: 0.17857119612916209\n","Training accuracy epoch: 0.9431050465057818\n","Validating model...\n","Validation Loss: 0.16203898712810055\n","Validation Accuracy: 0.9546370967741936\n","Training epoch: 2\n","Training loss per 100 training steps: 0.01285853236913681\n","Training loss per 100 training steps: 0.048857635306655475\n","Training loss per 100 training steps: 0.05485703568588201\n","Training loss per 100 training steps: 0.05227297214262088\n","Training loss per 100 training steps: 0.052482353621499236\n","Training loss per 100 training steps: 0.05143854049735697\n","Training loss per 100 training steps: 0.052351333986686545\n","Training loss epoch: 0.05237119191288537\n","Training accuracy epoch: 0.9844142785319255\n","Validating model...\n","Validation Loss: 0.17645426630869956\n","Validation Accuracy: 0.9604779411764706\n","Training epoch: 3\n","Training loss per 100 training steps: 0.004065289162099361\n","Training loss per 100 training steps: 0.03155511071200086\n","Training loss per 100 training steps: 0.030493135456012014\n","Training loss per 100 training steps: 0.03465592069783406\n","Training loss per 100 training steps: 0.03523308820087704\n","Training loss per 100 training steps: 0.032464414798494746\n","Training loss per 100 training steps: 0.03365348968224851\n","Training loss epoch: 0.03412564630959536\n","Training accuracy epoch: 0.9896854575163399\n","Validating model...\n","Validation Loss: 0.18691695005890877\n","Validation Accuracy: 0.9561887254901961\n","Training epoch: 4\n","Training loss per 100 training steps: 0.002884736517444253\n","Training loss per 100 training steps: 0.04104277330691613\n","Training loss per 100 training steps: 0.03583888054962342\n","Training loss per 100 training steps: 0.03134647093228284\n","Training loss per 100 training steps: 0.032911963560537175\n","Training loss per 100 training steps: 0.03149097035778989\n","Training loss per 100 training steps: 0.03082658334228132\n","Training loss epoch: 0.030589690866346168\n","Training accuracy epoch: 0.9908088235294118\n","Validating model...\n","Validation Loss: 0.2073043674556139\n","Validation Accuracy: 0.9586199399114484\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0033137944992631674\n","Training loss per 100 training steps: 0.008552656875373472\n","Training loss per 100 training steps: 0.012048959584726572\n","Training loss per 100 training steps: 0.017055236179059824\n","Training loss per 100 training steps: 0.01763754422042491\n","Training loss per 100 training steps: 0.01740172767635605\n","Training loss per 100 training steps: 0.01858143163486714\n","Training loss epoch: 0.019379020591508842\n","Training accuracy epoch: 0.9945638511814983\n","Validating model...\n","Validation Loss: 0.2164064087133453\n","Validation Accuracy: 0.9512867647058824\n","Training epoch: 6\n","Training loss per 100 training steps: 0.092875637114048\n","Training loss per 100 training steps: 0.016607214820900894\n","Training loss per 100 training steps: 0.017924328705305186\n","Training loss per 100 training steps: 0.020345073904276693\n","Training loss per 100 training steps: 0.02187842534195418\n","Training loss per 100 training steps: 0.02271325208679257\n","Training loss per 100 training steps: 0.022361989829372753\n","Training loss epoch: 0.02208198970913228\n","Training accuracy epoch: 0.9937704248366013\n","Validating model...\n","Validation Loss: 0.25471123433646214\n","Validation Accuracy: 0.9478870177103099\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 28.114945333333335 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14398041933802436\n","Validation Accuracy: 0.9565610532407407\n","Validation duration: 2.4151974000000034 minutes\n","F1-score (test): 85.4%\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.79      0.82      0.80      1170\n","        test       0.93      0.84      0.88      2464\n","   treatment       0.84      0.86      0.85      1244\n","\n","   micro avg       0.87      0.84      0.85      4878\n","   macro avg       0.85      0.84      0.84      4878\n","weighted avg       0.87      0.84      0.85      4878\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 19578\n","Points in y_train after augmentation: 19578\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.38842511177063\n","Training loss per 100 training steps: 0.36606718374803515\n","Training loss per 100 training steps: 0.2778516776340814\n","Training loss per 100 training steps: 0.24057211915024887\n","Training loss per 100 training steps: 0.2166036916975085\n","Training loss per 100 training steps: 0.19871917880301043\n","Training loss per 100 training steps: 0.18554309451973497\n","Training loss epoch: 0.18379030569461843\n","Training accuracy epoch: 0.9433092948717948\n","Validating model...\n","Validation Loss: 0.1504304603440687\n","Validation Accuracy: 0.9592524509803921\n","Training epoch: 2\n","Training loss per 100 training steps: 0.010151442140340805\n","Training loss per 100 training steps: 0.05268585377045455\n","Training loss per 100 training steps: 0.046736238210257006\n","Training loss per 100 training steps: 0.04757173403533271\n","Training loss per 100 training steps: 0.04631202316194415\n","Training loss per 100 training steps: 0.04651796248471439\n","Training loss per 100 training steps: 0.046677041535491216\n","Training loss epoch: 0.04710760689521242\n","Training accuracy epoch: 0.9851802099044746\n","Validating model...\n","Validation Loss: 0.19354157872936306\n","Validation Accuracy: 0.9463650379506642\n","Training epoch: 3\n","Training loss per 100 training steps: 0.013521791435778141\n","Training loss per 100 training steps: 0.025597315470084068\n","Training loss per 100 training steps: 0.0180680005433529\n","Training loss per 100 training steps: 0.027313651856610496\n","Training loss per 100 training steps: 0.031651371398747914\n","Training loss per 100 training steps: 0.032777812523907233\n","Training loss per 100 training steps: 0.032003623705418136\n","Training loss epoch: 0.03275137885584568\n","Training accuracy epoch: 0.9903492647058824\n","Validating model...\n","Validation Loss: 0.25928714675611964\n","Validation Accuracy: 0.940840449082859\n","Training epoch: 4\n","Training loss per 100 training steps: 0.010408266447484493\n","Training loss per 100 training steps: 0.018177897433950888\n","Training loss per 100 training steps: 0.02017660829295353\n","Training loss per 100 training steps: 0.02085230920032174\n","Training loss per 100 training steps: 0.02089710950057726\n","Training loss per 100 training steps: 0.021329866696201162\n","Training loss per 100 training steps: 0.022352980149774455\n","Training loss epoch: 0.022364124678573884\n","Training accuracy epoch: 0.9935661764705882\n","Validating model...\n","Validation Loss: 0.2341122828984939\n","Validation Accuracy: 0.9494386464263125\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0007748314528726041\n","Training loss per 100 training steps: 0.028494531310354773\n","Training loss per 100 training steps: 0.021103123968741647\n","Training loss per 100 training steps: 0.01946911430812094\n","Training loss per 100 training steps: 0.022899110108106503\n","Training loss per 100 training steps: 0.022138582212666184\n","Training loss per 100 training steps: 0.022095310953614253\n","Training loss epoch: 0.02190794520244821\n","Training accuracy epoch: 0.9939236111111112\n","Validating model...\n","Validation Loss: 0.2324683770375308\n","Validation Accuracy: 0.953125\n","Training epoch: 6\n","Training loss per 100 training steps: 0.001016120659187436\n","Training loss per 100 training steps: 0.016678612468240317\n","Training loss per 100 training steps: 0.017064829720114704\n","Training loss per 100 training steps: 0.01891252811422047\n","Training loss per 100 training steps: 0.01642534192987547\n","Training loss per 100 training steps: 0.015131505854557243\n","Training loss per 100 training steps: 0.016449267422407904\n","Training loss epoch: 0.01643748783027191\n","Training accuracy epoch: 0.9946895424836601\n","Validating model...\n","Validation Loss: 0.23128164799338408\n","Validation Accuracy: 0.9524924889310563\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 28.518611966666672 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1494222859476361\n","Validation Accuracy: 0.9566132973251029\n","Validation duration: 2.40568126666667 minutes\n","F1-score (test): 85.4%\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.73      0.86      0.79      1170\n","        test       0.88      0.90      0.89      2464\n","   treatment       0.93      0.77      0.85      1244\n","\n","   micro avg       0.85      0.86      0.85      4878\n","   macro avg       0.85      0.84      0.84      4878\n","weighted avg       0.86      0.86      0.85      4878\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 19578\n","Points in y_train after augmentation: 19578\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1710751056671143\n","Training loss per 100 training steps: 0.3591736523563614\n","Training loss per 100 training steps: 0.2818931359149034\n","Training loss per 100 training steps: 0.24702454902900017\n","Training loss per 100 training steps: 0.21843250764259822\n","Training loss per 100 training steps: 0.2028846567010548\n","Training loss per 100 training steps: 0.18563259755626954\n","Training loss epoch: 0.18407105731517626\n","Training accuracy epoch: 0.941062562845651\n","Validating model...\n","Validation Loss: 0.163013681315123\n","Validation Accuracy: 0.9561788425047438\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06074606254696846\n","Training loss per 100 training steps: 0.05537621909521963\n","Training loss per 100 training steps: 0.0565982680826851\n","Training loss per 100 training steps: 0.059279564437394544\n","Training loss per 100 training steps: 0.06194865232260382\n","Training loss per 100 training steps: 0.06159693425699712\n","Training loss per 100 training steps: 0.061910550418610495\n","Training loss epoch: 0.06110417253655089\n","Training accuracy epoch: 0.9811580882352942\n","Validating model...\n","Validation Loss: 0.19769691497112588\n","Validation Accuracy: 0.9494386464263125\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04544327035546303\n","Training loss per 100 training steps: 0.019544269106383114\n","Training loss per 100 training steps: 0.021584437853964834\n","Training loss per 100 training steps: 0.023448921248674134\n","Training loss per 100 training steps: 0.029321132767977463\n","Training loss per 100 training steps: 0.0309517243906099\n","Training loss per 100 training steps: 0.03199193193266337\n","Training loss epoch: 0.03197641002509425\n","Training accuracy epoch: 0.9901842948717948\n","Validating model...\n","Validation Loss: 0.2037666397047681\n","Validation Accuracy: 0.9528186274509803\n","Training epoch: 4\n","Training loss per 100 training steps: 0.12231790274381638\n","Training loss per 100 training steps: 0.02652196547749572\n","Training loss per 100 training steps: 0.02333912243287598\n","Training loss per 100 training steps: 0.02141350927943305\n","Training loss per 100 training steps: 0.02271281583281118\n","Training loss per 100 training steps: 0.022134772086589916\n","Training loss per 100 training steps: 0.02172366141733584\n","Training loss epoch: 0.021649930546189744\n","Training accuracy epoch: 0.993515114379085\n","Validating model...\n","Validation Loss: 0.22546298968589717\n","Validation Accuracy: 0.9546568627450981\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0012009451165795326\n","Training loss per 100 training steps: 0.029547589692811016\n","Training loss per 100 training steps: 0.03201025390690708\n","Training loss per 100 training steps: 0.028175986781346023\n","Training loss per 100 training steps: 0.026598557780485598\n","Training loss per 100 training steps: 0.02654957652459176\n","Training loss per 100 training steps: 0.024725595903825483\n","Training loss epoch: 0.02471946498697589\n","Training accuracy epoch: 0.9925959967320261\n","Validating model...\n","Validation Loss: 0.21721588051806584\n","Validation Accuracy: 0.9580170777988615\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0006603633519262075\n","Training loss per 100 training steps: 0.00655045824244706\n","Training loss per 100 training steps: 0.009556527831338275\n","Training loss per 100 training steps: 0.008012157154121194\n","Training loss per 100 training steps: 0.018143320419477093\n","Training loss per 100 training steps: 0.019006684104311434\n","Training loss per 100 training steps: 0.019304838535629545\n","Training loss epoch: 0.01987721655279612\n","Training accuracy epoch: 0.9934012066365008\n","Validating model...\n","Validation Loss: 0.2169289112030574\n","Validation Accuracy: 0.9540441176470589\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 27.94434163333332 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15122756918774233\n","Validation Accuracy: 0.9562717013888888\n","Validation duration: 2.3672197833333333 minutes\n","F1-score (test): 84.7%\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.78      0.84      0.81      1170\n","        test       0.95      0.79      0.86      2464\n","   treatment       0.87      0.85      0.86      1244\n","\n","   micro avg       0.88      0.81      0.85      4878\n","   macro avg       0.87      0.82      0.84      4878\n","weighted avg       0.89      0.81      0.85      4878\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 19578\n","Points in y_train after augmentation: 19578\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9636863470077515\n","Training loss per 100 training steps: 0.3407524687302585\n","Training loss per 100 training steps: 0.26497615738517016\n","Training loss per 100 training steps: 0.2258825839212492\n","Training loss per 100 training steps: 0.21062749654560947\n","Training loss per 100 training steps: 0.19229799396350994\n","Training loss per 100 training steps: 0.17795930153298226\n","Training loss epoch: 0.1767506949258116\n","Training accuracy epoch: 0.9448922197083962\n","Validating model...\n","Validation Loss: 0.1754126762332139\n","Validation Accuracy: 0.945149430740038\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0575856938958168\n","Training loss per 100 training steps: 0.055357952994100824\n","Training loss per 100 training steps: 0.06090959008095035\n","Training loss per 100 training steps: 0.057862845240578525\n","Training loss per 100 training steps: 0.05867763043194312\n","Training loss per 100 training steps: 0.055148935618511995\n","Training loss per 100 training steps: 0.05428802420907405\n","Training loss epoch: 0.05479589698903165\n","Training accuracy epoch: 0.9837622549019608\n","Validating model...\n","Validation Loss: 0.17065809937376603\n","Validation Accuracy: 0.9549533523086654\n","Training epoch: 3\n","Training loss per 100 training steps: 0.012818028219044209\n","Training loss per 100 training steps: 0.02255250455634115\n","Training loss per 100 training steps: 0.02679852922102413\n","Training loss per 100 training steps: 0.029366686558555906\n","Training loss per 100 training steps: 0.03142450945377826\n","Training loss per 100 training steps: 0.028656170871645535\n","Training loss per 100 training steps: 0.027536984483435202\n","Training loss epoch: 0.027981470164044356\n","Training accuracy epoch: 0.9923406862745098\n","Validating model...\n","Validation Loss: 0.17722570666142823\n","Validation Accuracy: 0.9552597248576851\n","Training epoch: 4\n","Training loss per 100 training steps: 0.004143349826335907\n","Training loss per 100 training steps: 0.013911950884912495\n","Training loss per 100 training steps: 0.020764503232797084\n","Training loss per 100 training steps: 0.02420974625345123\n","Training loss per 100 training steps: 0.023061329310147632\n","Training loss per 100 training steps: 0.02654270567668545\n","Training loss per 100 training steps: 0.026179697903570682\n","Training loss epoch: 0.026249207814877093\n","Training accuracy epoch: 0.9921875\n","Validating model...\n","Validation Loss: 0.35266855260809227\n","Validation Accuracy: 0.9276960784313726\n","Training epoch: 5\n","Training loss per 100 training steps: 0.12398121505975723\n","Training loss per 100 training steps: 0.030785456759679954\n","Training loss per 100 training steps: 0.024487728594289167\n","Training loss per 100 training steps: 0.022035044298485615\n","Training loss per 100 training steps: 0.024306339186432185\n","Training loss per 100 training steps: 0.02565613254456455\n","Training loss per 100 training steps: 0.024696356040273443\n","Training loss epoch: 0.025098489578809984\n","Training accuracy epoch: 0.9924820889894419\n","Validating model...\n","Validation Loss: 0.2487547942323099\n","Validation Accuracy: 0.9546469797596459\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0009774974314495921\n","Training loss per 100 training steps: 0.017750554223023907\n","Training loss per 100 training steps: 0.020231024206709233\n","Training loss per 100 training steps: 0.0198708583680202\n","Training loss per 100 training steps: 0.01953795452077758\n","Training loss per 100 training steps: 0.01935700448357129\n","Training loss per 100 training steps: 0.01790351630958493\n","Training loss epoch: 0.018210325018075534\n","Training accuracy epoch: 0.9950980392156863\n","Validating model...\n","Validation Loss: 0.22026196481630334\n","Validation Accuracy: 0.9570979601518027\n","Training epoch: 7\n","Training loss per 100 training steps: 0.00032254663528874516\n","Training loss per 100 training steps: 0.014687070964217777\n","Training loss per 100 training steps: 0.020588602589655305\n","Training loss per 100 training steps: 0.018209605151758394\n","Training loss per 100 training steps: 0.01771591436205707\n","Training loss per 100 training steps: 0.018115374750785108\n","Training loss per 100 training steps: 0.017386636265113636\n","Training loss epoch: 0.017446064922694775\n","Training accuracy epoch: 0.9950980392156863\n","Validating model...\n","Validation Loss: 0.3082752244928783\n","Validation Accuracy: 0.9451197817836813\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 32.5752924 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.17427632958835468\n","Validation Accuracy: 0.9536112718621399\n","Validation duration: 2.389450599999994 minutes\n","F1-score (test): 84.6%\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.81      0.83      0.82      1170\n","        test       0.89      0.85      0.87      2464\n","   treatment       0.78      0.88      0.83      1244\n","\n","   micro avg       0.84      0.85      0.85      4878\n","   macro avg       0.83      0.85      0.84      4878\n","weighted avg       0.84      0.85      0.85      4878\n","\n","!!!!!! Starting model number 5 !!!!!!\n","Points in X_train after augmentation: 19578\n","Points in y_train after augmentation: 19578\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1927597522735596\n","Training loss per 100 training steps: 0.3330889205162478\n","Training loss per 100 training steps: 0.2559579810618761\n","Training loss per 100 training steps: 0.22291195713156878\n","Training loss per 100 training steps: 0.20270258113230924\n","Training loss per 100 training steps: 0.18669165127089027\n","Training loss per 100 training steps: 0.17666760069153856\n","Training loss epoch: 0.17531531044012666\n","Training accuracy epoch: 0.9439338235294118\n","Validating model...\n","Validation Loss: 0.17927270859032504\n","Validation Accuracy: 0.9445268026565465\n","Training epoch: 2\n","Training loss per 100 training steps: 0.2966929078102112\n","Training loss per 100 training steps: 0.04952733038283774\n","Training loss per 100 training steps: 0.06181726754302465\n","Training loss per 100 training steps: 0.0621267868655709\n","Training loss per 100 training steps: 0.058330314018051756\n","Training loss per 100 training steps: 0.05662924442193964\n","Training loss per 100 training steps: 0.05758076169436639\n","Training loss epoch: 0.05740550138190194\n","Training accuracy epoch: 0.9820261437908496\n","Validating model...\n","Validation Loss: 0.18223517361569547\n","Validation Accuracy: 0.9530953510436433\n","Training epoch: 3\n","Training loss per 100 training steps: 0.004390146117657423\n","Training loss per 100 training steps: 0.037648809838021116\n","Training loss per 100 training steps: 0.0348994236248916\n","Training loss per 100 training steps: 0.03260578878824924\n","Training loss per 100 training steps: 0.03528839222539014\n","Training loss per 100 training steps: 0.034832918296843214\n","Training loss per 100 training steps: 0.033219635946210864\n","Training loss epoch: 0.032950645803865364\n","Training accuracy epoch: 0.9899407679738562\n","Validating model...\n","Validation Loss: 0.23691694917679165\n","Validation Accuracy: 0.9531151170145478\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0006171732675284147\n","Training loss per 100 training steps: 0.01715669801515195\n","Training loss per 100 training steps: 0.024336183664224756\n","Training loss per 100 training steps: 0.020735231038296876\n","Training loss per 100 training steps: 0.0215139030167716\n","Training loss per 100 training steps: 0.024173960997900222\n","Training loss per 100 training steps: 0.02438699900254829\n","Training loss epoch: 0.02437515997793573\n","Training accuracy epoch: 0.992686337355455\n","Validating model...\n","Validation Loss: 0.23788590585201175\n","Validation Accuracy: 0.9528087444655281\n","Training epoch: 5\n","Training loss per 100 training steps: 0.002664444502443075\n","Training loss per 100 training steps: 0.013823248486905958\n","Training loss per 100 training steps: 0.01553774495702932\n","Training loss per 100 training steps: 0.016526154493851173\n","Training loss per 100 training steps: 0.01823347242555739\n","Training loss per 100 training steps: 0.01808082871885525\n","Training loss per 100 training steps: 0.018930030832019287\n","Training loss epoch: 0.01867320639680686\n","Training accuracy epoch: 0.995046977124183\n","Validating model...\n","Validation Loss: 0.23525000173157976\n","Validation Accuracy: 0.9488259013282733\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00024100291193462908\n","Training loss per 100 training steps: 0.009561562357703224\n","Training loss per 100 training steps: 0.019861859972203563\n","Training loss per 100 training steps: 0.021767409365106703\n","Training loss per 100 training steps: 0.02498791537352401\n","Training loss per 100 training steps: 0.026802062239975877\n","Training loss per 100 training steps: 0.025621055930630326\n","Training loss epoch: 0.02553981520471698\n","Training accuracy epoch: 0.9927491830065359\n","Validating model...\n","Validation Loss: 0.23345428640359564\n","Validation Accuracy: 0.9512669987349779\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 27.97178210000002 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.17226687579817804\n","Validation Accuracy: 0.9438657407407407\n","Validation duration: 2.3965423666666537 minutes\n","F1-score (test): 82.6%\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.69      0.82      0.75      1170\n","        test       0.79      0.93      0.86      2464\n","   treatment       0.82      0.87      0.84      1244\n","\n","   micro avg       0.78      0.88      0.83      4878\n","   macro avg       0.77      0.87      0.82      4878\n","weighted avg       0.78      0.88      0.83      4878\n","\n","!!!!!! Starting model number 6 !!!!!!\n","Points in X_train after augmentation: 19578\n","Points in y_train after augmentation: 19578\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0390100479125977\n","Training loss per 100 training steps: 0.34487122267779735\n","Training loss per 100 training steps: 0.2636742016708302\n","Training loss per 100 training steps: 0.22739742417507294\n","Training loss per 100 training steps: 0.2074071951837574\n","Training loss per 100 training steps: 0.19130461540852978\n","Training loss per 100 training steps: 0.1796499818775372\n","Training loss epoch: 0.17752153748852578\n","Training accuracy epoch: 0.9442284125188537\n","Validating model...\n","Validation Loss: 0.1467183997270231\n","Validation Accuracy: 0.9580170777988615\n","Training epoch: 2\n","Training loss per 100 training steps: 0.005489998962730169\n","Training loss per 100 training steps: 0.05725217932468686\n","Training loss per 100 training steps: 0.05399297126678898\n","Training loss per 100 training steps: 0.05734771382325852\n","Training loss per 100 training steps: 0.05776375569092537\n","Training loss per 100 training steps: 0.054985715818852594\n","Training loss per 100 training steps: 0.05710289961789749\n","Training loss epoch: 0.057704102087311686\n","Training accuracy epoch: 0.9819240196078431\n","Validating model...\n","Validation Loss: 0.1492656275136944\n","Validation Accuracy: 0.9509705091714105\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03695826977491379\n","Training loss per 100 training steps: 0.02816491963694536\n","Training loss per 100 training steps: 0.026854588364920492\n","Training loss per 100 training steps: 0.029442624919359384\n","Training loss per 100 training steps: 0.02970304741786022\n","Training loss per 100 training steps: 0.031145769253383835\n","Training loss per 100 training steps: 0.032211327656949354\n","Training loss epoch: 0.03209870251694928\n","Training accuracy epoch: 0.9901450163398693\n","Validating model...\n","Validation Loss: 0.22529296881939267\n","Validation Accuracy: 0.9448232922201139\n","Training epoch: 4\n","Training loss per 100 training steps: 0.08080608397722244\n","Training loss per 100 training steps: 0.03137529781203496\n","Training loss per 100 training steps: 0.02654029742918274\n","Training loss per 100 training steps: 0.0263040853163229\n","Training loss per 100 training steps: 0.02756655885234993\n","Training loss per 100 training steps: 0.026797233913544594\n","Training loss per 100 training steps: 0.027010587978046216\n","Training loss epoch: 0.027614651179426956\n","Training accuracy epoch: 0.9917161576168929\n","Validating model...\n","Validation Loss: 0.22690636859710245\n","Validation Accuracy: 0.9537080961416825\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0072297826409339905\n","Training loss per 100 training steps: 0.01611202073371093\n","Training loss per 100 training steps: 0.015106708001182067\n","Training loss per 100 training steps: 0.01460380370022251\n","Training loss per 100 training steps: 0.013422244867763396\n","Training loss per 100 training steps: 0.015177000350856312\n","Training loss per 100 training steps: 0.017595645009886557\n","Training loss epoch: 0.017868485344176104\n","Training accuracy epoch: 0.9944735105580693\n","Validating model...\n","Validation Loss: 0.21221660143540552\n","Validation Accuracy: 0.9525122549019608\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0011364069068804383\n","Training loss per 100 training steps: 0.014193344299651517\n","Training loss per 100 training steps: 0.01435901822414555\n","Training loss per 100 training steps: 0.012083256545637508\n","Training loss per 100 training steps: 0.014984825331112573\n","Training loss per 100 training steps: 0.015313212067429525\n","Training loss per 100 training steps: 0.015831409296567688\n","Training loss epoch: 0.015894718123579912\n","Training accuracy epoch: 0.995812908496732\n","Validating model...\n","Validation Loss: 0.2307655509794131\n","Validation Accuracy: 0.9546370967741936\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 28.43029890000001 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14311702010389935\n","Validation Accuracy: 0.9569026491769548\n","Validation duration: 2.417047716666669 minutes\n","F1-score (test): 86.1%\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.75      0.84      0.79      1170\n","        test       0.89      0.89      0.89      2464\n","   treatment       0.88      0.86      0.87      1244\n","\n","   micro avg       0.85      0.87      0.86      4878\n","   macro avg       0.84      0.86      0.85      4878\n","weighted avg       0.86      0.87      0.86      4878\n","\n","!!!!!! Starting model number 7 !!!!!!\n","Points in X_train after augmentation: 19578\n","Points in y_train after augmentation: 19578\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.088629722595215\n","Training loss per 100 training steps: 0.33385080110171056\n","Training loss per 100 training steps: 0.25933975146721994\n","Training loss per 100 training steps: 0.22047428873079858\n","Training loss per 100 training steps: 0.19921237258867655\n","Training loss per 100 training steps: 0.18516909974225668\n","Training loss per 100 training steps: 0.17312914025644383\n","Training loss epoch: 0.171628868990666\n","Training accuracy epoch: 0.9444444444444444\n","Validating model...\n","Validation Loss: 0.17495979261401967\n","Validation Accuracy: 0.953125\n","Training epoch: 2\n","Training loss per 100 training steps: 0.08036481589078903\n","Training loss per 100 training steps: 0.053495705810071216\n","Training loss per 100 training steps: 0.04468511791514066\n","Training loss per 100 training steps: 0.04855425057888644\n","Training loss per 100 training steps: 0.05238733210289117\n","Training loss per 100 training steps: 0.05233258733880462\n","Training loss per 100 training steps: 0.05336016932563986\n","Training loss epoch: 0.05428262635541614\n","Training accuracy epoch: 0.9839547197083962\n","Validating model...\n","Validation Loss: 0.1971583295529069\n","Validation Accuracy: 0.9463551549652119\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0046560680493712425\n","Training loss per 100 training steps: 0.02412163947321622\n","Training loss per 100 training steps: 0.02277292766109044\n","Training loss per 100 training steps: 0.026475593137115463\n","Training loss per 100 training steps: 0.02580135331417003\n","Training loss per 100 training steps: 0.027375206624745844\n","Training loss per 100 training steps: 0.03211707066009561\n","Training loss epoch: 0.032801513063900736\n","Training accuracy epoch: 0.9904906674208145\n","Validating model...\n","Validation Loss: 0.22508199146021998\n","Validation Accuracy: 0.9436175679949399\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0086020827293396\n","Training loss per 100 training steps: 0.018663355479268173\n","Training loss per 100 training steps: 0.025749291406263277\n","Training loss per 100 training steps: 0.026733661971717882\n","Training loss per 100 training steps: 0.02693139641899749\n","Training loss per 100 training steps: 0.026986724045238004\n","Training loss per 100 training steps: 0.026187508435572767\n","Training loss epoch: 0.026194964009953442\n","Training accuracy epoch: 0.9914726307189542\n","Validating model...\n","Validation Loss: 0.23571804300545232\n","Validation Accuracy: 0.9503379981024668\n","Training epoch: 5\n","Training loss per 100 training steps: 0.006259398069232702\n","Training loss per 100 training steps: 0.008793283634419129\n","Training loss per 100 training steps: 0.010800492530529369\n","Training loss per 100 training steps: 0.01286074655060695\n","Training loss per 100 training steps: 0.013917363312162466\n","Training loss per 100 training steps: 0.017125746311830517\n","Training loss per 100 training steps: 0.018811265317469503\n","Training loss epoch: 0.01883756548713018\n","Training accuracy epoch: 0.9940767973856209\n","Validating model...\n","Validation Loss: 0.25565323592209277\n","Validation Accuracy: 0.9506542536369387\n","Training epoch: 6\n","Training loss per 100 training steps: 0.006586839910596609\n","Training loss per 100 training steps: 0.016389325391362872\n","Training loss per 100 training steps: 0.012904271711799517\n","Training loss per 100 training steps: 0.01683258880349055\n","Training loss per 100 training steps: 0.016725360102814682\n","Training loss per 100 training steps: 0.018512652885077616\n","Training loss per 100 training steps: 0.01777206348253061\n","Training loss epoch: 0.017669311343498147\n","Training accuracy epoch: 0.9946895424836601\n","Validating model...\n","Validation Loss: 0.2599885133856921\n","Validation Accuracy: 0.9528087444655281\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 28.522145849999983 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1592184995802031\n","Validation Accuracy: 0.956396283436214\n","Validation duration: 2.4396101666666556 minutes\n","F1-score (test): 85.7%\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.84      0.76      0.80      1170\n","        test       0.89      0.88      0.89      2464\n","   treatment       0.87      0.84      0.85      1244\n","\n","   micro avg       0.87      0.84      0.86      4878\n","   macro avg       0.87      0.83      0.85      4878\n","weighted avg       0.87      0.84      0.86      4878\n","\n","!!!!!! Starting model number 8 !!!!!!\n","Points in X_train after augmentation: 19578\n","Points in y_train after augmentation: 19578\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.148143768310547\n","Training loss per 100 training steps: 0.3290840697170484\n","Training loss per 100 training steps: 0.25543659053446344\n","Training loss per 100 training steps: 0.23474596075611529\n","Training loss per 100 training steps: 0.20693422208814197\n","Training loss per 100 training steps: 0.19085207226697334\n","Training loss per 100 training steps: 0.17730704372238906\n","Training loss epoch: 0.17611552254042703\n","Training accuracy epoch: 0.9434232026143791\n","Validating model...\n","Validation Loss: 0.16401625693976588\n","Validation Accuracy: 0.9521959993674889\n","Training epoch: 2\n","Training loss per 100 training steps: 0.03502234071493149\n","Training loss per 100 training steps: 0.05439278221168177\n","Training loss per 100 training steps: 0.053427882894493677\n","Training loss per 100 training steps: 0.05079870330219302\n","Training loss per 100 training steps: 0.05214951419070633\n","Training loss per 100 training steps: 0.051752904859443984\n","Training loss per 100 training steps: 0.0504956827311565\n","Training loss epoch: 0.050652018697101855\n","Training accuracy epoch: 0.984375\n","Validating model...\n","Validation Loss: 0.19797338707619072\n","Validation Accuracy: 0.9491223908918406\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0055364565923810005\n","Training loss per 100 training steps: 0.026107521806636107\n","Training loss per 100 training steps: 0.026505573795742324\n","Training loss per 100 training steps: 0.028328719758602676\n","Training loss per 100 training steps: 0.030411199320289434\n","Training loss per 100 training steps: 0.030300297692349317\n","Training loss per 100 training steps: 0.029323200251516413\n","Training loss epoch: 0.02914622114048993\n","Training accuracy epoch: 0.9916258169934641\n","Validating model...\n","Validation Loss: 0.2310529323685663\n","Validation Accuracy: 0.953727862112587\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0028837674763053656\n","Training loss per 100 training steps: 0.019098404878640944\n","Training loss per 100 training steps: 0.020951384766735668\n","Training loss per 100 training steps: 0.019469358770772768\n","Training loss per 100 training steps: 0.023600040919157884\n","Training loss per 100 training steps: 0.025616221338616938\n","Training loss per 100 training steps: 0.024982362670577737\n","Training loss epoch: 0.024705685943760186\n","Training accuracy epoch: 0.9924428104575164\n","Validating model...\n","Validation Loss: 0.22039848731661799\n","Validation Accuracy: 0.9497549019607843\n","Training epoch: 5\n","Training loss per 100 training steps: 0.001103512942790985\n","Training loss per 100 training steps: 0.013330539793933345\n","Training loss per 100 training steps: 0.011554804025912907\n","Training loss per 100 training steps: 0.015648426804533946\n","Training loss per 100 training steps: 0.016561013085739613\n","Training loss per 100 training steps: 0.018722836754727225\n","Training loss per 100 training steps: 0.020807038513277604\n","Training loss epoch: 0.02081519337552653\n","Training accuracy epoch: 0.994281045751634\n","Validating model...\n","Validation Loss: 0.22469073283105437\n","Validation Accuracy: 0.953125\n","Training epoch: 6\n","Training loss per 100 training steps: 0.005876390729099512\n","Training loss per 100 training steps: 0.013510680303760196\n","Training loss per 100 training steps: 0.017128212964139064\n","Training loss per 100 training steps: 0.017966433642493975\n","Training loss per 100 training steps: 0.017321874418426125\n","Training loss per 100 training steps: 0.017133428266267535\n","Training loss per 100 training steps: 0.017597445676080185\n","Training loss epoch: 0.017579454202396115\n","Training accuracy epoch: 0.9947406045751634\n","Validating model...\n","Validation Loss: 0.24586208955288918\n","Validation Accuracy: 0.9439041745730551\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 28.102320166666686 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16222135245186142\n","Validation Accuracy: 0.9499421296296297\n","Validation duration: 2.376379016666639 minutes\n","F1-score (test): 83.5%\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.82      0.80      0.81      1170\n","        test       0.91      0.83      0.87      2464\n","   treatment       0.71      0.92      0.80      1244\n","\n","   micro avg       0.82      0.85      0.83      4878\n","   macro avg       0.81      0.85      0.83      4878\n","weighted avg       0.84      0.85      0.84      4878\n","\n","!!!!!! Starting model number 9 !!!!!!\n","Points in X_train after augmentation: 19578\n","Points in y_train after augmentation: 19578\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.284885883331299\n","Training loss per 100 training steps: 0.3654275207531334\n","Training loss per 100 training steps: 0.28636684677846247\n","Training loss per 100 training steps: 0.24477854924295037\n","Training loss per 100 training steps: 0.21817461539412897\n","Training loss per 100 training steps: 0.20391705294117377\n","Training loss per 100 training steps: 0.1863697343505919\n","Training loss epoch: 0.18601732790314904\n","Training accuracy epoch: 0.9419424019607843\n","Validating model...\n","Validation Loss: 0.16640959523033863\n","Validation Accuracy: 0.9481933902593296\n","Training epoch: 2\n","Training loss per 100 training steps: 0.019158484414219856\n","Training loss per 100 training steps: 0.04959863629814532\n","Training loss per 100 training steps: 0.05178840689630994\n","Training loss per 100 training steps: 0.05044541291875511\n","Training loss per 100 training steps: 0.05445910605835377\n","Training loss per 100 training steps: 0.05488928692311257\n","Training loss per 100 training steps: 0.05588903751846259\n","Training loss epoch: 0.05581016851347693\n","Training accuracy epoch: 0.9829334778783309\n","Validating model...\n","Validation Loss: 0.18618487357561403\n","Validation Accuracy: 0.9500612745098039\n","Training epoch: 3\n","Training loss per 100 training steps: 0.003717350773513317\n","Training loss per 100 training steps: 0.02146036127474998\n","Training loss per 100 training steps: 0.03347646341188834\n","Training loss per 100 training steps: 0.034199232468188144\n","Training loss per 100 training steps: 0.03246586839958765\n","Training loss per 100 training steps: 0.03183320206207174\n","Training loss per 100 training steps: 0.03354290803168887\n","Training loss epoch: 0.03335685655486552\n","Training accuracy epoch: 0.9899918300653595\n","Validating model...\n","Validation Loss: 0.22896623154462992\n","Validation Accuracy: 0.9430048228969007\n","Training epoch: 4\n","Training loss per 100 training steps: 0.004349300637841225\n","Training loss per 100 training steps: 0.014553178107253009\n","Training loss per 100 training steps: 0.02619606342681554\n","Training loss per 100 training steps: 0.023121246379901473\n","Training loss per 100 training steps: 0.022669784056812123\n","Training loss per 100 training steps: 0.022781938314060272\n","Training loss per 100 training steps: 0.025732260269821644\n","Training loss epoch: 0.0260506194839157\n","Training accuracy epoch: 0.9921875\n","Validating model...\n","Validation Loss: 0.24301340469551802\n","Validation Accuracy: 0.9457720588235294\n","Training epoch: 5\n","Training loss per 100 training steps: 0.009695159271359444\n","Training loss per 100 training steps: 0.037148103802026905\n","Training loss per 100 training steps: 0.027428932041850693\n","Training loss per 100 training steps: 0.023817950224699576\n","Training loss per 100 training steps: 0.02184143971483121\n","Training loss per 100 training steps: 0.02374837233469089\n","Training loss per 100 training steps: 0.023563085369463194\n","Training loss epoch: 0.023250412555771736\n","Training accuracy epoch: 0.9936683006535948\n","Validating model...\n","Validation Loss: 0.21851197644633324\n","Validation Accuracy: 0.9543504901960784\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0015369739849120378\n","Training loss per 100 training steps: 0.016450130045275655\n","Training loss per 100 training steps: 0.021889618759950512\n","Training loss per 100 training steps: 0.019678250075508594\n","Training loss per 100 training steps: 0.018187304360294445\n","Training loss per 100 training steps: 0.019965468311009413\n","Training loss per 100 training steps: 0.018314652272413707\n","Training loss epoch: 0.018517096327378847\n","Training accuracy epoch: 0.9942299836601307\n","Validating model...\n","Validation Loss: 0.22217566736342667\n","Validation Accuracy: 0.9500612745098039\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 28.251046416666636 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.14624485163356574\n","Validation Accuracy: 0.9558015046296297\n","Validation duration: 2.405309116666649 minutes\n","F1-score (test): 85.8%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","     problem       0.89      0.74      0.81      1170\n","        test       0.84      0.91      0.87      2464\n","   treatment       0.87      0.88      0.88      1244\n","\n","   micro avg       0.86      0.86      0.86      4878\n","   macro avg       0.87      0.84      0.85      4878\n","weighted avg       0.86      0.86      0.86      4878\n","\n","!!!!!! Starting model number 10 !!!!!!\n","Points in X_train after augmentation: 19578\n","Points in y_train after augmentation: 19578\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8870939016342163\n","Training loss per 100 training steps: 0.3220922745911792\n","Training loss per 100 training steps: 0.25514980652531727\n","Training loss per 100 training steps: 0.22913031211661242\n","Training loss per 100 training steps: 0.21364325858150932\n","Training loss per 100 training steps: 0.19799164537444502\n","Training loss per 100 training steps: 0.1861794460797295\n","Training loss epoch: 0.18481943996781422\n","Training accuracy epoch: 0.9422252073906485\n","Validating model...\n","Validation Loss: 0.16165118136981904\n","Validation Accuracy: 0.9476004111321948\n","Training epoch: 2\n","Training loss per 100 training steps: 0.009411745704710484\n","Training loss per 100 training steps: 0.05023367020375289\n","Training loss per 100 training steps: 0.05424343228608889\n","Training loss per 100 training steps: 0.05913042381330025\n","Training loss per 100 training steps: 0.061665608055693356\n","Training loss per 100 training steps: 0.06023096146855314\n","Training loss per 100 training steps: 0.058471338053760015\n","Training loss epoch: 0.05919716640170496\n","Training accuracy epoch: 0.9819122360482655\n","Validating model...\n","Validation Loss: 0.17143626046234595\n","Validation Accuracy: 0.950950743200506\n","Training epoch: 3\n","Training loss per 100 training steps: 0.030089233070611954\n","Training loss per 100 training steps: 0.020961844012784392\n","Training loss per 100 training steps: 0.025163310831320004\n","Training loss per 100 training steps: 0.032484891135988146\n","Training loss per 100 training steps: 0.03263763170381613\n","Training loss per 100 training steps: 0.031799165234216\n","Training loss per 100 training steps: 0.033845145368933856\n","Training loss epoch: 0.03399921304843422\n","Training accuracy epoch: 0.9897365196078431\n","Validating model...\n","Validation Loss: 0.20753816982352302\n","Validation Accuracy: 0.948213156230234\n","Training epoch: 4\n","Training loss per 100 training steps: 0.00860762782394886\n","Training loss per 100 training steps: 0.02771864292825028\n","Training loss per 100 training steps: 0.026193292285037684\n","Training loss per 100 training steps: 0.02564984212603971\n","Training loss per 100 training steps: 0.024950553508701286\n","Training loss per 100 training steps: 0.025838010504847846\n","Training loss per 100 training steps: 0.027513521907660498\n","Training loss epoch: 0.027697686897286404\n","Training accuracy epoch: 0.9913705065359477\n","Validating model...\n","Validation Loss: 0.19994623523020624\n","Validation Accuracy: 0.9549533523086654\n","Training epoch: 5\n","Training loss per 100 training steps: 0.009312726557254791\n","Training loss per 100 training steps: 0.01120648259443397\n","Training loss per 100 training steps: 0.01618774304040754\n","Training loss per 100 training steps: 0.020139167446428848\n","Training loss per 100 training steps: 0.020578379555839924\n","Training loss per 100 training steps: 0.021304522390018902\n","Training loss per 100 training steps: 0.02330732770756057\n","Training loss epoch: 0.02409417602250994\n","Training accuracy epoch: 0.9927884615384616\n","Validating model...\n","Validation Loss: 0.23333732207424426\n","Validation Accuracy: 0.9405538425047438\n","Training epoch: 6\n","Training loss per 100 training steps: 0.007661358918994665\n","Training loss per 100 training steps: 0.024373121826164884\n","Training loss per 100 training steps: 0.018514854596743582\n","Training loss per 100 training steps: 0.015378532424792292\n","Training loss per 100 training steps: 0.019005845370664343\n","Training loss per 100 training steps: 0.01911591022943179\n","Training loss per 100 training steps: 0.01946450899858232\n","Training loss epoch: 0.0197270402376923\n","Training accuracy epoch: 0.9943321078431373\n","Validating model...\n","Validation Loss: 0.2521955898469862\n","Validation Accuracy: 0.9531052340290955\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 27.47750775000004 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.16171263312787265\n","Validation Accuracy: 0.9524377893518519\n","Validation duration: 2.334343599999981 minutes\n","F1-score (test): 84.9%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","     problem       0.75      0.88      0.81      1170\n","        test       0.81      0.91      0.86      2464\n","   treatment       0.88      0.85      0.87      1244\n","\n","   micro avg       0.81      0.89      0.85      4878\n","   macro avg       0.81      0.88      0.84      4878\n","weighted avg       0.81      0.89      0.85      4878\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 2\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"Zjhn7-LqHri0"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d89bc32d9d8b47fab10a8215dd8bacea","6fa9eae422f842b38be6c533616a1f9c","80518727ea4c4ceaa9975f8f883f1fdd","e098a89273d6492c88262989bfc18e27","42328398d1614a8b926b21209f76a8fe","8ac9807adede4e85a63f3b138f649f45","0917668f72944b08b83d5402dc5b5a60","806fdf45960a4b25ab38e6697fe400e5","a07e47c473894653917e6b5b49bcd52b","f09f40a2829f42108748ba129fef0304","cada9e4086eb498fb2a1f2f5b0e48ceb"]},"executionInfo":{"elapsed":37274287,"status":"ok","timestamp":1657475174748,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"TTDq-xbgHqXQ","outputId":"3ef5e262-f99a-4197-c533-4383f7bccbdc"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 500% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 39156\n","Points in y_train after augmentation: 39156\n","Device:  cuda\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d89bc32d9d8b47fab10a8215dd8bacea","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/422M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7654467821121216\n","Training loss per 100 training steps: 0.37039194150947696\n","Training loss per 100 training steps: 0.2847066987746057\n","Training loss per 100 training steps: 0.24836351054309067\n","Training loss per 100 training steps: 0.2188867276320768\n","Training loss per 100 training steps: 0.20428047873016572\n","Training loss per 100 training steps: 0.18956873974663682\n","Training loss per 100 training steps: 0.17705595018122924\n","Training loss per 100 training steps: 0.16459751487363677\n","Training loss per 100 training steps: 0.1582693789353528\n","Training loss per 100 training steps: 0.1515051042152844\n","Training loss per 100 training steps: 0.14463022077355878\n","Training loss per 100 training steps: 0.1388693767043178\n","Training loss epoch: 0.13740928532339608\n","Training accuracy epoch: 0.9568014705882353\n","Validating model...\n","Validation Loss: 0.18013583827425964\n","Validation Accuracy: 0.9473039215686274\n","Training epoch: 2\n","Training loss per 100 training steps: 0.007219108287245035\n","Training loss per 100 training steps: 0.041231218872402824\n","Training loss per 100 training steps: 0.03686799408389552\n","Training loss per 100 training steps: 0.03747453982574383\n","Training loss per 100 training steps: 0.03888608434475886\n","Training loss per 100 training steps: 0.03874968208981159\n","Training loss per 100 training steps: 0.040456899973540995\n","Training loss per 100 training steps: 0.04142829740985288\n","Training loss per 100 training steps: 0.04125270828823867\n","Training loss per 100 training steps: 0.041702095009453724\n","Training loss per 100 training steps: 0.04201752824902341\n","Training loss per 100 training steps: 0.04241269961247757\n","Training loss per 100 training steps: 0.041958130221953695\n","Training loss epoch: 0.04162867822231336\n","Training accuracy epoch: 0.9878727532679739\n","Validating model...\n","Validation Loss: 0.19714156915684797\n","Validation Accuracy: 0.9497549019607843\n","Training epoch: 3\n","Training loss per 100 training steps: 0.004059773404151201\n","Training loss per 100 training steps: 0.018220700925829277\n","Training loss per 100 training steps: 0.02347143151694839\n","Training loss per 100 training steps: 0.02183700996527272\n","Training loss per 100 training steps: 0.020903976873979217\n","Training loss per 100 training steps: 0.021407291971158912\n","Training loss per 100 training steps: 0.02205234582435633\n","Training loss per 100 training steps: 0.022574133006565224\n","Training loss per 100 training steps: 0.022695036354765687\n","Training loss per 100 training steps: 0.02448848203091017\n","Training loss per 100 training steps: 0.02405238408850251\n","Training loss per 100 training steps: 0.024390463665471186\n","Training loss per 100 training steps: 0.024587591379703712\n","Training loss epoch: 0.024629705937923956\n","Training accuracy epoch: 0.9925959967320261\n","Validating model...\n","Validation Loss: 0.22755069166647873\n","Validation Accuracy: 0.9500513915243517\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0010463778162375093\n","Training loss per 100 training steps: 0.012315495429263164\n","Training loss per 100 training steps: 0.01424412366448188\n","Training loss per 100 training steps: 0.01615283365663647\n","Training loss per 100 training steps: 0.015220998984636991\n","Training loss per 100 training steps: 0.01647170880426778\n","Training loss per 100 training steps: 0.016694515967849016\n","Training loss per 100 training steps: 0.017932578023105758\n","Training loss per 100 training steps: 0.018824361621999686\n","Training loss per 100 training steps: 0.020182414143068456\n","Training loss per 100 training steps: 0.0203117400968178\n","Training loss per 100 training steps: 0.021652626507624995\n","Training loss per 100 training steps: 0.021998400121260756\n","Training loss epoch: 0.022271087916082476\n","Training accuracy epoch: 0.9933874591503268\n","Validating model...\n","Validation Loss: 0.18106675865961805\n","Validation Accuracy: 0.9527988614800759\n","Training epoch: 5\n","Training loss per 100 training steps: 0.002765361685305834\n","Training loss per 100 training steps: 0.018376106989488127\n","Training loss per 100 training steps: 0.012762160225595008\n","Training loss per 100 training steps: 0.011490818278429306\n","Training loss per 100 training steps: 0.012821435170592753\n","Training loss per 100 training steps: 0.013559545114634794\n","Training loss per 100 training steps: 0.01471742689921389\n","Training loss per 100 training steps: 0.014700104469881735\n","Training loss per 100 training steps: 0.014210182163985658\n","Training loss per 100 training steps: 0.0156263421890289\n","Training loss per 100 training steps: 0.015860924864744386\n","Training loss per 100 training steps: 0.017074604464726736\n","Training loss per 100 training steps: 0.017169962658451485\n","Training loss epoch: 0.01737166982409428\n","Training accuracy epoch: 0.9952767565359477\n","Validating model...\n","Validation Loss: 0.23097989889542006\n","Validation Accuracy: 0.9515931372549019\n","Training epoch: 6\n","Training loss per 100 training steps: 0.005957313347607851\n","Training loss per 100 training steps: 0.018377318406030352\n","Training loss per 100 training steps: 0.01667356938715915\n","Training loss per 100 training steps: 0.018532910179592393\n","Training loss per 100 training steps: 0.01814015106800778\n","Training loss per 100 training steps: 0.01892583442926781\n","Training loss per 100 training steps: 0.01772370117958087\n","Training loss per 100 training steps: 0.018001146617302084\n","Training loss per 100 training steps: 0.017766830814283555\n","Training loss per 100 training steps: 0.018188362700845485\n","Training loss per 100 training steps: 0.018078882958370804\n","Training loss per 100 training steps: 0.017809420542310758\n","Training loss per 100 training steps: 0.018124814242326225\n","Training loss epoch: 0.018098884380325378\n","Training accuracy epoch: 0.9949193218954249\n","Validating model...\n","Validation Loss: 0.27787736321995765\n","Validation Accuracy: 0.9430048228969007\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 55.2739018 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.18137608751917636\n","Validation Accuracy: 0.9450392232510288\n","Validation duration: 2.4130737666666695 minutes\n","F1-score (test): 81.9%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.67      0.87      0.76      1170\n","        test       0.92      0.79      0.85      2464\n","   treatment       0.79      0.87      0.83      1244\n","\n","   micro avg       0.81      0.83      0.82      4878\n","   macro avg       0.79      0.85      0.81      4878\n","weighted avg       0.83      0.83      0.82      4878\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 39156\n","Points in y_train after augmentation: 39156\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9437692165374756\n","Training loss per 100 training steps: 0.34852043638872626\n","Training loss per 100 training steps: 0.2710668136880024\n","Training loss per 100 training steps: 0.23239248738843837\n","Training loss per 100 training steps: 0.20873732773117962\n","Training loss per 100 training steps: 0.1926841047925209\n","Training loss per 100 training steps: 0.17716610252534887\n","Training loss per 100 training steps: 0.1683491161591327\n","Training loss per 100 training steps: 0.15967712266770043\n","Training loss per 100 training steps: 0.15350127640347225\n","Training loss per 100 training steps: 0.14784812888774376\n","Training loss per 100 training steps: 0.14035825493223594\n","Training loss per 100 training steps: 0.13461011605683115\n","Training loss epoch: 0.13355504690359035\n","Training accuracy epoch: 0.9576439950980392\n","Validating model...\n","Validation Loss: 0.17556154321737624\n","Validation Accuracy: 0.9528087444655281\n","Training epoch: 2\n","Training loss per 100 training steps: 0.10097099840641022\n","Training loss per 100 training steps: 0.048593311364840866\n","Training loss per 100 training steps: 0.038617691127652884\n","Training loss per 100 training steps: 0.04370162840599993\n","Training loss per 100 training steps: 0.04249623040890756\n","Training loss per 100 training steps: 0.044862619110956105\n","Training loss per 100 training steps: 0.04453146081293248\n","Training loss per 100 training steps: 0.04599213383723344\n","Training loss per 100 training steps: 0.0456342841052731\n","Training loss per 100 training steps: 0.045766392446384835\n","Training loss per 100 training steps: 0.04597730697407694\n","Training loss per 100 training steps: 0.0465727339070838\n","Training loss per 100 training steps: 0.04618155669894858\n","Training loss epoch: 0.04585243189508903\n","Training accuracy epoch: 0.9866217320261438\n","Validating model...\n","Validation Loss: 0.21428607324481824\n","Validation Accuracy: 0.9506641366223909\n","Training epoch: 3\n","Training loss per 100 training steps: 0.016394367441534996\n","Training loss per 100 training steps: 0.03035370466422686\n","Training loss per 100 training steps: 0.028195682333739456\n","Training loss per 100 training steps: 0.02456104242023579\n","Training loss per 100 training steps: 0.02283220345379687\n","Training loss per 100 training steps: 0.022405760366055547\n","Training loss per 100 training steps: 0.025093115506139345\n","Training loss per 100 training steps: 0.026078764658569745\n","Training loss per 100 training steps: 0.025598385921733503\n","Training loss per 100 training steps: 0.027175892643599753\n","Training loss per 100 training steps: 0.026227116101032046\n","Training loss per 100 training steps: 0.026349032186866263\n","Training loss per 100 training steps: 0.026487109979231153\n","Training loss epoch: 0.026550725384332313\n","Training accuracy epoch: 0.9922640931372549\n","Validating model...\n","Validation Loss: 0.2420035403583646\n","Validation Accuracy: 0.9463452719797597\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0027490309439599514\n","Training loss per 100 training steps: 0.010809037453462693\n","Training loss per 100 training steps: 0.012628936665902953\n","Training loss per 100 training steps: 0.01749173752353233\n","Training loss per 100 training steps: 0.017541989190065582\n","Training loss per 100 training steps: 0.020794567182667537\n","Training loss per 100 training steps: 0.019606142045324515\n","Training loss per 100 training steps: 0.02021817588535491\n","Training loss per 100 training steps: 0.020524325235881966\n","Training loss per 100 training steps: 0.020439048636128162\n","Training loss per 100 training steps: 0.021123719201884935\n","Training loss per 100 training steps: 0.021051084774048944\n","Training loss per 100 training steps: 0.021128286316622124\n","Training loss epoch: 0.02155000326680012\n","Training accuracy epoch: 0.993515114379085\n","Validating model...\n","Validation Loss: 0.2275898343487985\n","Validation Accuracy: 0.9515733712839974\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0017718321178108454\n","Training loss per 100 training steps: 0.011223464229476688\n","Training loss per 100 training steps: 0.017185252567215138\n","Training loss per 100 training steps: 0.017697308491035582\n","Training loss per 100 training steps: 0.019376997446135167\n","Training loss per 100 training steps: 0.02044308662733531\n","Training loss per 100 training steps: 0.02201243530821701\n","Training loss per 100 training steps: 0.020982294184534487\n","Training loss per 100 training steps: 0.020743271508965537\n","Training loss per 100 training steps: 0.021157113538928237\n","Training loss per 100 training steps: 0.021533155698459115\n","Training loss per 100 training steps: 0.022079527066808748\n","Training loss per 100 training steps: 0.021524197851425172\n","Training loss epoch: 0.02119636529873698\n","Training accuracy epoch: 0.9936938316993464\n","Validating model...\n","Validation Loss: 0.2994689605848358\n","Validation Accuracy: 0.9463452719797597\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00025807326892390847\n","Training loss per 100 training steps: 0.006308494770510691\n","Training loss per 100 training steps: 0.008961844447239584\n","Training loss per 100 training steps: 0.010453413674304555\n","Training loss per 100 training steps: 0.010704126414951989\n","Training loss per 100 training steps: 0.013029768305853371\n","Training loss per 100 training steps: 0.013645129536235496\n","Training loss per 100 training steps: 0.013032869398859823\n","Training loss per 100 training steps: 0.013930303063987936\n","Training loss per 100 training steps: 0.01487594080594313\n","Training loss per 100 training steps: 0.014708477549276438\n","Training loss per 100 training steps: 0.015033492949828604\n","Training loss per 100 training steps: 0.014697063806214905\n","Training loss epoch: 0.014682652764061464\n","Training accuracy epoch: 0.9959405637254902\n","Validating model...\n","Validation Loss: 0.26624509872521696\n","Validation Accuracy: 0.948213156230234\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 54.63930066666667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16265197580923996\n","Validation Accuracy: 0.9508825231481481\n","Validation duration: 2.3825724333333254 minutes\n","F1-score (test): 83.1%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.76      0.84      0.79      1170\n","        test       0.89      0.80      0.84      2464\n","   treatment       0.87      0.82      0.85      1244\n","\n","   micro avg       0.85      0.81      0.83      4878\n","   macro avg       0.84      0.82      0.83      4878\n","weighted avg       0.86      0.81      0.83      4878\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 39156\n","Points in y_train after augmentation: 39156\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9085501432418823\n","Training loss per 100 training steps: 0.3507602187887867\n","Training loss per 100 training steps: 0.26956574484678125\n","Training loss per 100 training steps: 0.23099958531688466\n","Training loss per 100 training steps: 0.20740296557996227\n","Training loss per 100 training steps: 0.18897746410406754\n","Training loss per 100 training steps: 0.1760866454649041\n","Training loss per 100 training steps: 0.16524320535199682\n","Training loss per 100 training steps: 0.15638265938041138\n","Training loss per 100 training steps: 0.1482571305492097\n","Training loss per 100 training steps: 0.14415909655854575\n","Training loss per 100 training steps: 0.1390700926206969\n","Training loss per 100 training steps: 0.13343681704247531\n","Training loss epoch: 0.13199963012006016\n","Training accuracy epoch: 0.958843954248366\n","Validating model...\n","Validation Loss: 0.15323662612639716\n","Validation Accuracy: 0.9561788425047438\n","Training epoch: 2\n","Training loss per 100 training steps: 0.005634182598441839\n","Training loss per 100 training steps: 0.03591873979620695\n","Training loss per 100 training steps: 0.039229662127550156\n","Training loss per 100 training steps: 0.03809316310088074\n","Training loss per 100 training steps: 0.039747524000926376\n","Training loss per 100 training steps: 0.03952000589004115\n","Training loss per 100 training steps: 0.03980891742302781\n","Training loss per 100 training steps: 0.039005086078658435\n","Training loss per 100 training steps: 0.04112620589366725\n","Training loss per 100 training steps: 0.0406543962628154\n","Training loss per 100 training steps: 0.0411683191617791\n","Training loss per 100 training steps: 0.041670474901837784\n","Training loss per 100 training steps: 0.041336273577987165\n","Training loss epoch: 0.04133623909687456\n","Training accuracy epoch: 0.9877961601307189\n","Validating model...\n","Validation Loss: 0.17364151445080472\n","Validation Accuracy: 0.9530755850727388\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0016238716198131442\n","Training loss per 100 training steps: 0.034114787967110254\n","Training loss per 100 training steps: 0.027597699410210258\n","Training loss per 100 training steps: 0.024988936253864336\n","Training loss per 100 training steps: 0.026021497904806703\n","Training loss per 100 training steps: 0.02499529816243498\n","Training loss per 100 training steps: 0.02451178398988242\n","Training loss per 100 training steps: 0.02517079152240745\n","Training loss per 100 training steps: 0.024460814861098863\n","Training loss per 100 training steps: 0.025599405432463203\n","Training loss per 100 training steps: 0.026023848231189122\n","Training loss per 100 training steps: 0.02675982407589825\n","Training loss per 100 training steps: 0.026618926634108964\n","Training loss epoch: 0.02692227220082785\n","Training accuracy epoch: 0.9918147467320262\n","Validating model...\n","Validation Loss: 0.23400812206319624\n","Validation Accuracy: 0.9454656862745098\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0006604412337765098\n","Training loss per 100 training steps: 0.028422617695540983\n","Training loss per 100 training steps: 0.02692518663356331\n","Training loss per 100 training steps: 0.02613449665640235\n","Training loss per 100 training steps: 0.02819828030059899\n","Training loss per 100 training steps: 0.02625409810071413\n","Training loss per 100 training steps: 0.025164766584642343\n","Training loss per 100 training steps: 0.023024982033588375\n","Training loss per 100 training steps: 0.02288040671788331\n","Training loss per 100 training steps: 0.021473066248137274\n","Training loss per 100 training steps: 0.021601133695186035\n","Training loss per 100 training steps: 0.021817203044985356\n","Training loss per 100 training steps: 0.02237680910612599\n","Training loss epoch: 0.02241048361832452\n","Training accuracy epoch: 0.993515114379085\n","Validating model...\n","Validation Loss: 0.20681857113388605\n","Validation Accuracy: 0.9555463314358001\n","Training epoch: 5\n","Training loss per 100 training steps: 0.00032255452242679894\n","Training loss per 100 training steps: 0.015888495977459668\n","Training loss per 100 training steps: 0.013364649344749971\n","Training loss per 100 training steps: 0.01723722302676078\n","Training loss per 100 training steps: 0.01898524850664836\n","Training loss per 100 training steps: 0.01711967486156566\n","Training loss per 100 training steps: 0.018222085093302046\n","Training loss per 100 training steps: 0.018458744045824427\n","Training loss per 100 training steps: 0.017587921840172743\n","Training loss per 100 training steps: 0.01877272783450875\n","Training loss per 100 training steps: 0.018097281014380823\n","Training loss per 100 training steps: 0.017857028293264302\n","Training loss per 100 training steps: 0.01758654831442364\n","Training loss epoch: 0.017378582123976135\n","Training accuracy epoch: 0.9949448529411765\n","Validating model...\n","Validation Loss: 0.2630010358437657\n","Validation Accuracy: 0.949745018975332\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0002177053247578442\n","Training loss per 100 training steps: 0.015230570341337075\n","Training loss per 100 training steps: 0.014579387512386705\n","Training loss per 100 training steps: 0.012990835111946864\n","Training loss per 100 training steps: 0.012026755082031042\n","Training loss per 100 training steps: 0.011928825364785933\n","Training loss per 100 training steps: 0.012131779043081712\n","Training loss per 100 training steps: 0.011395758687973342\n","Training loss per 100 training steps: 0.012176937041220392\n","Training loss per 100 training steps: 0.012171934423506201\n","Training loss per 100 training steps: 0.012356783520993083\n","Training loss per 100 training steps: 0.012349720472936103\n","Training loss per 100 training steps: 0.01337991967791627\n","Training loss epoch: 0.013461530014685457\n","Training accuracy epoch: 0.9964767156862745\n","Validating model...\n","Validation Loss: 0.25125369492596683\n","Validation Accuracy: 0.946681293485136\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 54.566598116666654 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13952519470304078\n","Validation Accuracy: 0.9601779513888888\n","Validation duration: 2.3892581666666652 minutes\n","F1-score (test): 86.8%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.88      0.77      0.82      1170\n","        test       0.86      0.90      0.88      2464\n","   treatment       0.91      0.85      0.88      1244\n","\n","   micro avg       0.88      0.86      0.87      4878\n","   macro avg       0.88      0.84      0.86      4878\n","weighted avg       0.88      0.86      0.87      4878\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 39156\n","Points in y_train after augmentation: 39156\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.3120615482330322\n","Training loss per 100 training steps: 0.39591920029113786\n","Training loss per 100 training steps: 0.300621943186913\n","Training loss per 100 training steps: 0.25465174016242603\n","Training loss per 100 training steps: 0.22978660716510324\n","Training loss per 100 training steps: 0.20613996819695254\n","Training loss per 100 training steps: 0.18983239651550718\n","Training loss per 100 training steps: 0.17908252070335068\n","Training loss per 100 training steps: 0.1707623955804143\n","Training loss per 100 training steps: 0.16249887231912064\n","Training loss per 100 training steps: 0.15485153076730643\n","Training loss per 100 training steps: 0.1500119286995139\n","Training loss per 100 training steps: 0.14224731082456896\n","Training loss epoch: 0.14151436592110972\n","Training accuracy epoch: 0.9568525326797386\n","Validating model...\n","Validation Loss: 0.17265421097331188\n","Validation Accuracy: 0.9546469797596459\n","Training epoch: 2\n","Training loss per 100 training steps: 0.10922253876924515\n","Training loss per 100 training steps: 0.05067457229309337\n","Training loss per 100 training steps: 0.04799637209163024\n","Training loss per 100 training steps: 0.046055712638905524\n","Training loss per 100 training steps: 0.0445091408730236\n","Training loss per 100 training steps: 0.044549267215420955\n","Training loss per 100 training steps: 0.04269832568561787\n","Training loss per 100 training steps: 0.04405363091889081\n","Training loss per 100 training steps: 0.04331208494931957\n","Training loss per 100 training steps: 0.043340011388090564\n","Training loss per 100 training steps: 0.043572515306616814\n","Training loss per 100 training steps: 0.04347018679376285\n","Training loss per 100 training steps: 0.04326091648901341\n","Stopping epoch...\n","Training loss epoch: 0.04326091648901341\n","Training accuracy epoch: 0.9854548293089093\n","Validating model...\n","Validation Loss: 0.21134567464283535\n","Validation Accuracy: 0.9531052340290955\n","Training epoch: 3\n","Training loss per 100 training steps: 0.015338712371885777\n","Training loss per 100 training steps: 0.021777033211667976\n","Training loss per 100 training steps: 0.020152922544225273\n","Training loss per 100 training steps: 0.022257881236639326\n","Training loss per 100 training steps: 0.024712154312170182\n","Training loss per 100 training steps: 0.024071072602071548\n","Training loss per 100 training steps: 0.024473214585708104\n","Training loss per 100 training steps: 0.02510477958713142\n","Training loss per 100 training steps: 0.024969766440026818\n","Training loss per 100 training steps: 0.025535063635221046\n","Training loss per 100 training steps: 0.025859540934693864\n","Training loss per 100 training steps: 0.02584700295978651\n","Training loss per 100 training steps: 0.02717951136208597\n","Training loss epoch: 0.027357651775126845\n","Training accuracy epoch: 0.9921364379084967\n","Validating model...\n","Validation Loss: 0.23597363292298956\n","Validation Accuracy: 0.9386859582542695\n","Training epoch: 4\n","Training loss per 100 training steps: 0.013856389559805393\n","Training loss per 100 training steps: 0.012738795767452954\n","Training loss per 100 training steps: 0.01209734882170448\n","Training loss per 100 training steps: 0.013097530763209148\n","Training loss per 100 training steps: 0.015506523362983034\n","Training loss per 100 training steps: 0.015761950675318177\n","Training loss per 100 training steps: 0.01606237940369569\n","Training loss per 100 training steps: 0.017882161789808552\n","Training loss per 100 training steps: 0.01960263920259155\n","Training loss per 100 training steps: 0.01988334323055515\n","Training loss per 100 training steps: 0.019880815229078475\n","Training loss per 100 training steps: 0.02055918803093792\n","Training loss per 100 training steps: 0.020150081036844736\n","Training loss epoch: 0.020158896179732527\n","Training accuracy epoch: 0.9941278594771242\n","Validating model...\n","Validation Loss: 0.26080269275239426\n","Validation Accuracy: 0.9494485294117647\n","Training epoch: 5\n","Training loss per 100 training steps: 0.03995281830430031\n","Training loss per 100 training steps: 0.03136622041822895\n","Training loss per 100 training steps: 0.028579000982415947\n","Training loss per 100 training steps: 0.02562779885574795\n","Training loss per 100 training steps: 0.02424379367492524\n","Training loss per 100 training steps: 0.021075022531772764\n","Training loss per 100 training steps: 0.02463662435552268\n","Training loss per 100 training steps: 0.02472487415440152\n","Training loss per 100 training steps: 0.024793559680371655\n","Training loss per 100 training steps: 0.02394212498806353\n","Training loss per 100 training steps: 0.02341902695843237\n","Training loss per 100 training steps: 0.022576656003220837\n","Training loss per 100 training steps: 0.02228612114065059\n","Training loss epoch: 0.022293887163862987\n","Training accuracy epoch: 0.9938214869281046\n","Validating model...\n","Validation Loss: 0.253098423064312\n","Validation Accuracy: 0.9479067836812144\n","Training epoch: 6\n","Training loss per 100 training steps: 0.015176416374742985\n","Training loss per 100 training steps: 0.02056742395132568\n","Training loss per 100 training steps: 0.021249859162681014\n","Training loss per 100 training steps: 0.018305080889146372\n","Training loss per 100 training steps: 0.016555716586016185\n","Training loss per 100 training steps: 0.0181454325967295\n","Training loss per 100 training steps: 0.01899138837740404\n","Training loss per 100 training steps: 0.019782692111095117\n","Training loss per 100 training steps: 0.020258477585264202\n","Training loss per 100 training steps: 0.02047520097112606\n","Training loss per 100 training steps: 0.020065777032374665\n","Training loss per 100 training steps: 0.020209147597340715\n","Training loss per 100 training steps: 0.019922361620993614\n","Training loss epoch: 0.01990662463653922\n","Training accuracy epoch: 0.9944699754901961\n","Validating model...\n","Validation Loss: 0.23477195529695188\n","Validation Accuracy: 0.9469777830487034\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 53.97676318333333 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15736433402620337\n","Validation Accuracy: 0.953125\n","Validation duration: 2.3728157500000027 minutes\n","F1-score (test): 84.3%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.90      0.76      0.82      1170\n","        test       0.85      0.87      0.86      2464\n","   treatment       0.78      0.89      0.83      1244\n","\n","   micro avg       0.84      0.85      0.84      4878\n","   macro avg       0.84      0.84      0.84      4878\n","weighted avg       0.84      0.85      0.84      4878\n","\n","!!!!!! Starting model number 5 !!!!!!\n","Points in X_train after augmentation: 39156\n","Points in y_train after augmentation: 39156\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.315378427505493\n","Training loss per 100 training steps: 0.3562476382692262\n","Training loss per 100 training steps: 0.27839552972521353\n","Training loss per 100 training steps: 0.2400188626740066\n","Training loss per 100 training steps: 0.21327931542086537\n","Training loss per 100 training steps: 0.19883936681847894\n","Training loss per 100 training steps: 0.18649545288877176\n","Training loss per 100 training steps: 0.1756798284936739\n","Training loss per 100 training steps: 0.16576115456066756\n","Training loss per 100 training steps: 0.1588252785441969\n","Training loss per 100 training steps: 0.1521067150807302\n","Training loss per 100 training steps: 0.14721947840085467\n","Training loss per 100 training steps: 0.1409307991820027\n","Training loss epoch: 0.13964524811203743\n","Training accuracy epoch: 0.9565563725490196\n","Validating model...\n","Validation Loss: 0.18423464029397377\n","Validation Accuracy: 0.9497252530044276\n","Training epoch: 2\n","Training loss per 100 training steps: 0.011123267002403736\n","Training loss per 100 training steps: 0.03131618939160305\n","Training loss per 100 training steps: 0.03418386908710253\n","Training loss per 100 training steps: 0.033775484291109506\n","Training loss per 100 training steps: 0.037370678277348315\n","Training loss per 100 training steps: 0.03840674765193333\n","Training loss per 100 training steps: 0.03903855389091008\n","Training loss per 100 training steps: 0.04004120663939025\n","Training loss per 100 training steps: 0.040614772340141526\n","Training loss per 100 training steps: 0.040684516990330426\n","Training loss per 100 training steps: 0.0416777282312164\n","Training loss per 100 training steps: 0.04161817376071195\n","Training loss per 100 training steps: 0.04154254114638675\n","Training loss epoch: 0.041786748014714416\n","Training accuracy epoch: 0.9873621323529411\n","Validating model...\n","Validation Loss: 0.22292936275092265\n","Validation Accuracy: 0.9479067836812144\n","Training epoch: 3\n","Training loss per 100 training steps: 0.01153425220400095\n","Training loss per 100 training steps: 0.025210345402391084\n","Training loss per 100 training steps: 0.02791551933474711\n","Training loss per 100 training steps: 0.025311688435245755\n","Training loss per 100 training steps: 0.022841614867701948\n","Training loss per 100 training steps: 0.021523288496707923\n","Training loss per 100 training steps: 0.02374504504060162\n","Training loss per 100 training steps: 0.024379682506242974\n","Training loss per 100 training steps: 0.023528282243382596\n","Training loss per 100 training steps: 0.024231373052126713\n","Training loss per 100 training steps: 0.024699606288446706\n","Training loss per 100 training steps: 0.025275644875582457\n","Training loss per 100 training steps: 0.025912246436689705\n","Training loss epoch: 0.025687134778903414\n","Training accuracy epoch: 0.9918811274509803\n","Validating model...\n","Validation Loss: 0.25248168215073424\n","Validation Accuracy: 0.9497153700189753\n","Training epoch: 4\n","Training loss per 100 training steps: 0.00485357316210866\n","Training loss per 100 training steps: 0.014144636347998247\n","Training loss per 100 training steps: 0.017727544463751604\n","Training loss per 100 training steps: 0.02164726900031552\n","Training loss per 100 training steps: 0.023596447543168506\n","Training loss per 100 training steps: 0.02347665784629622\n","Training loss per 100 training steps: 0.0252778304753692\n","Training loss per 100 training steps: 0.02375694116562435\n","Training loss per 100 training steps: 0.02301114798957427\n","Training loss per 100 training steps: 0.02275712374702219\n","Training loss per 100 training steps: 0.021522706297688713\n","Training loss per 100 training steps: 0.021872557760491736\n","Training loss per 100 training steps: 0.022043036740294272\n","Training loss epoch: 0.022115032035858677\n","Training accuracy epoch: 0.9937448937908496\n","Validating model...\n","Validation Loss: 0.24059917751697404\n","Validation Accuracy: 0.949745018975332\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0005267448141239583\n","Training loss per 100 training steps: 0.02059829802198179\n","Training loss per 100 training steps: 0.03196756747873866\n","Training loss per 100 training steps: 0.02773303322288466\n","Training loss per 100 training steps: 0.026220545317684307\n","Training loss per 100 training steps: 0.02640584527951781\n","Training loss per 100 training steps: 0.025422841812881153\n","Training loss per 100 training steps: 0.02400323487309028\n","Training loss per 100 training steps: 0.02334219610110382\n","Training loss per 100 training steps: 0.022835934910523412\n","Training loss per 100 training steps: 0.022360261421235227\n","Training loss per 100 training steps: 0.021743645776651836\n","Training loss per 100 training steps: 0.02096859878239274\n","Training loss epoch: 0.02084567119601797\n","Training accuracy epoch: 0.9938980800653595\n","Validating model...\n","Validation Loss: 0.2821324064668671\n","Validation Accuracy: 0.946078431372549\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0007147481665015221\n","Training loss per 100 training steps: 0.01247214499636528\n","Training loss per 100 training steps: 0.009687719996369894\n","Training loss per 100 training steps: 0.015548292760521814\n","Training loss per 100 training steps: 0.016239390665576142\n","Training loss per 100 training steps: 0.016441442871614063\n","Training loss per 100 training steps: 0.01719451550340641\n","Training loss per 100 training steps: 0.017941192873647656\n","Training loss per 100 training steps: 0.017505326289815836\n","Training loss per 100 training steps: 0.0163638492140651\n","Training loss per 100 training steps: 0.016678755825459184\n","Training loss per 100 training steps: 0.017101560518426078\n","Training loss per 100 training steps: 0.017803656352170842\n","Training loss epoch: 0.017744107951122023\n","Training accuracy epoch: 0.9948171977124183\n","Validating model...\n","Validation Loss: 0.28648221293948223\n","Validation Accuracy: 0.9384092346616066\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 54.626474466666636 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.17548061394740622\n","Validation Accuracy: 0.9480251736111112\n","Validation duration: 2.3921252000000095 minutes\n","F1-score (test): 82.6%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.66      0.87      0.75      1170\n","        test       0.84      0.89      0.86      2464\n","   treatment       0.87      0.79      0.83      1244\n","\n","   micro avg       0.80      0.86      0.83      4878\n","   macro avg       0.79      0.85      0.81      4878\n","weighted avg       0.81      0.86      0.83      4878\n","\n","!!!!!! Starting model number 6 !!!!!!\n","Points in X_train after augmentation: 39156\n","Points in y_train after augmentation: 39156\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9794503450393677\n","Training loss per 100 training steps: 0.3544899402001854\n","Training loss per 100 training steps: 0.2710064463178391\n","Training loss per 100 training steps: 0.22948028542955354\n","Training loss per 100 training steps: 0.20571160593425433\n","Training loss per 100 training steps: 0.1917409302244807\n","Training loss per 100 training steps: 0.1816242868293808\n","Training loss per 100 training steps: 0.17070424680653878\n","Training loss per 100 training steps: 0.16183557761420314\n","Training loss per 100 training steps: 0.15297588905802548\n","Training loss per 100 training steps: 0.14539501235731267\n","Training loss per 100 training steps: 0.1390037659647558\n","Training loss per 100 training steps: 0.13346065797725365\n","Training loss epoch: 0.13242557440532313\n","Training accuracy epoch: 0.9584865196078431\n","Validating model...\n","Validation Loss: 0.16678123960189303\n","Validation Accuracy: 0.9555562144212524\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0067588528618216515\n","Training loss per 100 training steps: 0.027135763636624236\n","Training loss per 100 training steps: 0.035006867809422706\n","Training loss per 100 training steps: 0.036350886606065204\n","Training loss per 100 training steps: 0.040143232401419766\n","Training loss per 100 training steps: 0.04205757512177941\n","Training loss per 100 training steps: 0.03976610124970441\n","Training loss per 100 training steps: 0.04203565776850975\n","Training loss per 100 training steps: 0.04717246518216297\n","Training loss per 100 training steps: 0.04744663535115711\n","Training loss per 100 training steps: 0.04741578013418111\n","Training loss per 100 training steps: 0.04731978697436204\n","Training loss per 100 training steps: 0.04787576254399803\n","Training loss epoch: 0.04806979133408116\n","Training accuracy epoch: 0.9851154003267973\n","Validating model...\n","Validation Loss: 0.27256175021494866\n","Validation Accuracy: 0.9350490196078431\n","Training epoch: 3\n","Training loss per 100 training steps: 0.07845394313335419\n","Training loss per 100 training steps: 0.03277050377628166\n","Training loss per 100 training steps: 0.03284370738912179\n","Training loss per 100 training steps: 0.029074072733210506\n","Training loss per 100 training steps: 0.026641490400405636\n","Training loss per 100 training steps: 0.024610097441194207\n","Training loss per 100 training steps: 0.02206250493900022\n","Training loss per 100 training steps: 0.023876842296247692\n","Training loss per 100 training steps: 0.02338655603750241\n","Training loss per 100 training steps: 0.025657899874519247\n","Training loss per 100 training steps: 0.026683940914359276\n","Training loss per 100 training steps: 0.026769163650953273\n","Training loss per 100 training steps: 0.028678096751409112\n","Training loss epoch: 0.028699861020749524\n","Training accuracy epoch: 0.9916870915032681\n","Validating model...\n","Validation Loss: 0.20829580159510905\n","Validation Accuracy: 0.9521959993674889\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0014418507926166058\n","Training loss per 100 training steps: 0.013206607241864721\n","Training loss per 100 training steps: 0.01188158267583068\n","Training loss per 100 training steps: 0.013641750910255572\n","Training loss per 100 training steps: 0.013153853628558265\n","Training loss per 100 training steps: 0.015432781593127273\n","Training loss per 100 training steps: 0.016747130540665626\n","Training loss per 100 training steps: 0.01582369151830437\n","Training loss per 100 training steps: 0.01630324883582771\n","Training loss per 100 training steps: 0.01720770463474639\n","Training loss per 100 training steps: 0.018773999301320454\n","Training loss per 100 training steps: 0.02174980545021392\n","Training loss per 100 training steps: 0.022787926316967053\n","Training loss epoch: 0.022603630084810065\n","Training accuracy epoch: 0.9934895833333334\n","Validating model...\n","Validation Loss: 0.24952366342825139\n","Validation Accuracy: 0.9472940385831752\n","Training epoch: 5\n","Training loss per 100 training steps: 0.009820464998483658\n","Training loss per 100 training steps: 0.01946403104224067\n","Training loss per 100 training steps: 0.019965977387286175\n","Training loss per 100 training steps: 0.019980140458674484\n","Training loss per 100 training steps: 0.01803655904917914\n","Training loss per 100 training steps: 0.016988842999990175\n","Training loss per 100 training steps: 0.017464482066932036\n","Training loss per 100 training steps: 0.016775937658662712\n","Training loss per 100 training steps: 0.0159419473409176\n","Training loss per 100 training steps: 0.015862092533282617\n","Training loss per 100 training steps: 0.015614405866869277\n","Training loss per 100 training steps: 0.01536507636899232\n","Training loss per 100 training steps: 0.015109018920814891\n","Training loss epoch: 0.014963207994839524\n","Training accuracy epoch: 0.9956597222222222\n","Validating model...\n","Validation Loss: 0.26734671654626524\n","Validation Accuracy: 0.949745018975332\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0026956191286444664\n","Training loss per 100 training steps: 0.0069760544170679685\n","Training loss per 100 training steps: 0.007041329534385752\n","Training loss per 100 training steps: 0.010965454269380552\n","Training loss per 100 training steps: 0.014032145434144954\n","Training loss per 100 training steps: 0.014155675898024299\n","Training loss per 100 training steps: 0.013830485917947687\n","Training loss per 100 training steps: 0.014261629219036797\n","Training loss per 100 training steps: 0.013933306212942973\n","Training loss per 100 training steps: 0.016073945726747398\n","Training loss per 100 training steps: 0.015809002939272183\n","Training loss per 100 training steps: 0.016032927730470506\n","Training loss per 100 training steps: 0.01610462612234149\n","Training loss epoch: 0.016096281673985597\n","Training accuracy epoch: 0.9953533496732027\n","Validating model...\n","Validation Loss: 0.2811677198247601\n","Validation Accuracy: 0.9460487824161923\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 54.765290683333355 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1590590796939203\n","Validation Accuracy: 0.9532335069444444\n","Validation duration: 2.395933316666681 minutes\n","F1-score (test): 85.1%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.74      0.86      0.79      1170\n","        test       0.83      0.92      0.87      2464\n","   treatment       0.84      0.90      0.87      1244\n","\n","   micro avg       0.81      0.90      0.85      4878\n","   macro avg       0.80      0.89      0.84      4878\n","weighted avg       0.81      0.90      0.85      4878\n","\n","!!!!!! Starting model number 7 !!!!!!\n","Points in X_train after augmentation: 39156\n","Points in y_train after augmentation: 39156\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.113344430923462\n","Training loss per 100 training steps: 0.3370178398298155\n","Training loss per 100 training steps: 0.2687857081807816\n","Training loss per 100 training steps: 0.23345921729440705\n","Training loss per 100 training steps: 0.20828628370032048\n","Training loss per 100 training steps: 0.19174403639672\n","Training loss per 100 training steps: 0.178495100431668\n","Training loss per 100 training steps: 0.1689654349252454\n","Training loss per 100 training steps: 0.15858694959429562\n","Training loss per 100 training steps: 0.15303587948657432\n","Training loss per 100 training steps: 0.14603769590638085\n","Training loss per 100 training steps: 0.14067462835394076\n","Training loss per 100 training steps: 0.13444538417977547\n","Training loss epoch: 0.1335570728479545\n","Training accuracy epoch: 0.9589460784313726\n","Validating model...\n","Validation Loss: 0.16631400283407785\n","Validation Accuracy: 0.9524924889310563\n","Training epoch: 2\n","Training loss per 100 training steps: 0.003939910791814327\n","Training loss per 100 training steps: 0.034699050054336794\n","Training loss per 100 training steps: 0.04046613229635584\n","Training loss per 100 training steps: 0.04484559135299572\n","Training loss per 100 training steps: 0.04251919870881452\n","Training loss per 100 training steps: 0.04088951430484251\n","Training loss per 100 training steps: 0.03991156231393858\n","Training loss per 100 training steps: 0.03948258710874825\n","Training loss per 100 training steps: 0.04014569580891128\n","Training loss per 100 training steps: 0.040880470138207774\n","Training loss per 100 training steps: 0.04199451355119496\n","Training loss per 100 training steps: 0.04150754615846242\n","Training loss per 100 training steps: 0.0406983634708773\n","Training loss epoch: 0.04105293481288576\n","Training accuracy epoch: 0.9874642565359477\n","Validating model...\n","Validation Loss: 0.2234541061300072\n","Validation Accuracy: 0.9454162713472486\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0014848397113382816\n","Training loss per 100 training steps: 0.017089097497818787\n","Training loss per 100 training steps: 0.021245690158496505\n","Training loss per 100 training steps: 0.022156172180900265\n","Training loss per 100 training steps: 0.02435416019554459\n","Training loss per 100 training steps: 0.02437656112570602\n","Training loss per 100 training steps: 0.022083199684760538\n","Training loss per 100 training steps: 0.023742234743235616\n","Training loss per 100 training steps: 0.025212088168820933\n","Training loss per 100 training steps: 0.02449999547288735\n","Training loss per 100 training steps: 0.024145104023871582\n","Training loss per 100 training steps: 0.025912591754032727\n","Training loss per 100 training steps: 0.0261299131290024\n","Training loss epoch: 0.025962232082973394\n","Training accuracy epoch: 0.9921619689542484\n","Validating model...\n","Validation Loss: 0.21877538449788356\n","Validation Accuracy: 0.9518896268184693\n","Training epoch: 4\n","Training loss per 100 training steps: 0.007324341218918562\n","Training loss per 100 training steps: 0.010413228100630233\n","Training loss per 100 training steps: 0.015271144091231002\n","Training loss per 100 training steps: 0.01837786420448985\n","Training loss per 100 training steps: 0.016853185601326627\n","Training loss per 100 training steps: 0.01665710066696127\n","Training loss per 100 training steps: 0.016661521680918952\n","Training loss per 100 training steps: 0.017408982390212276\n","Training loss per 100 training steps: 0.017813492398055405\n","Training loss per 100 training steps: 0.018816200713163513\n","Training loss per 100 training steps: 0.018610457897854826\n","Training loss per 100 training steps: 0.018686603722013723\n","Training loss per 100 training steps: 0.01878782530126397\n","Training loss epoch: 0.018820054235666427\n","Training accuracy epoch: 0.9946231617647059\n","Validating model...\n","Validation Loss: 0.2772495353001789\n","Validation Accuracy: 0.9512669987349779\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0033407926093786955\n","Training loss per 100 training steps: 0.014803702602137599\n","Training loss per 100 training steps: 0.012243593532191845\n","Training loss per 100 training steps: 0.014130346830918815\n","Training loss per 100 training steps: 0.017955879501290354\n","Training loss per 100 training steps: 0.01942290537899426\n","Training loss per 100 training steps: 0.019755775665271813\n","Training loss per 100 training steps: 0.019788893791409752\n","Training loss per 100 training steps: 0.020208655406702986\n","Training loss per 100 training steps: 0.019892951769614555\n","Training loss per 100 training steps: 0.01956581253137017\n","Training loss per 100 training steps: 0.01939717256445164\n","Training loss per 100 training steps: 0.01926114588854281\n","Training loss epoch: 0.01904248623426599\n","Training accuracy epoch: 0.994000204248366\n","Validating model...\n","Validation Loss: 0.23912716747508966\n","Validation Accuracy: 0.9546568627450981\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0045548249036073685\n","Training loss per 100 training steps: 0.00480820652217625\n","Training loss per 100 training steps: 0.00606488043794076\n","Training loss per 100 training steps: 0.00525760423628514\n","Training loss per 100 training steps: 0.010784011245499428\n","Training loss per 100 training steps: 0.011232308385448838\n","Training loss per 100 training steps: 0.015964906957118555\n","Training loss per 100 training steps: 0.01645273047065251\n","Training loss per 100 training steps: 0.01653701358740359\n","Training loss per 100 training steps: 0.01642816027913202\n","Training loss per 100 training steps: 0.016698529529297755\n","Training loss per 100 training steps: 0.01615132515943697\n","Training loss per 100 training steps: 0.016285045592209904\n","Training loss epoch: 0.016244645643370793\n","Training accuracy epoch: 0.994970383986928\n","Validating model...\n","Validation Loss: 0.30997014059182987\n","Validation Accuracy: 0.94176944971537\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 54.77832498333337 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15754641041187117\n","Validation Accuracy: 0.9537559477880658\n","Validation duration: 2.403749633333306 minutes\n","F1-score (test): 84.5%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.72      0.85      0.78      1170\n","        test       0.89      0.87      0.88      2464\n","   treatment       0.88      0.82      0.85      1244\n","\n","   micro avg       0.84      0.85      0.84      4878\n","   macro avg       0.83      0.84      0.83      4878\n","weighted avg       0.84      0.85      0.85      4878\n","\n","!!!!!! Starting model number 8 !!!!!!\n","Points in X_train after augmentation: 39156\n","Points in y_train after augmentation: 39156\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.826410174369812\n","Training loss per 100 training steps: 0.34893360848326493\n","Training loss per 100 training steps: 0.2771517159834282\n","Training loss per 100 training steps: 0.23728014769471958\n","Training loss per 100 training steps: 0.21628905001428544\n","Training loss per 100 training steps: 0.19721166154034175\n","Training loss per 100 training steps: 0.18238832311570713\n","Training loss per 100 training steps: 0.17219910451251558\n","Training loss per 100 training steps: 0.16257319353638885\n","Training loss per 100 training steps: 0.1528897531003434\n","Training loss per 100 training steps: 0.1464227914054702\n","Training loss per 100 training steps: 0.13959873258855218\n","Training loss per 100 training steps: 0.13450653998892317\n","Training loss epoch: 0.13331002769843384\n","Training accuracy epoch: 0.9578482434640523\n","Validating model...\n","Validation Loss: 0.16606052438888297\n","Validation Accuracy: 0.9531151170145478\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06792259961366653\n","Training loss per 100 training steps: 0.03161328547348333\n","Training loss per 100 training steps: 0.03325473679755513\n","Training loss per 100 training steps: 0.03745005968757023\n","Training loss per 100 training steps: 0.03742082905679816\n","Training loss per 100 training steps: 0.036168362054078765\n","Training loss per 100 training steps: 0.03669802090294501\n","Training loss per 100 training steps: 0.03884018964403024\n","Training loss per 100 training steps: 0.03963459805917831\n","Training loss per 100 training steps: 0.04168125784750609\n","Training loss per 100 training steps: 0.04138845043712422\n","Training loss per 100 training steps: 0.04023163309658634\n","Training loss per 100 training steps: 0.04031412602504727\n","Training loss epoch: 0.04022869359635009\n","Training accuracy epoch: 0.9881791258169934\n","Validating model...\n","Validation Loss: 0.21637421318126715\n","Validation Accuracy: 0.9454162713472486\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0017592187505215406\n","Training loss per 100 training steps: 0.02809771413869907\n","Training loss per 100 training steps: 0.023181549068835718\n","Training loss per 100 training steps: 0.029489942823333257\n","Training loss per 100 training steps: 0.030152417969831296\n","Training loss per 100 training steps: 0.028386833937013776\n","Training loss per 100 training steps: 0.029210848062990322\n","Training loss per 100 training steps: 0.02898845629741341\n","Training loss per 100 training steps: 0.02871302116415045\n","Training loss per 100 training steps: 0.02854688850276174\n","Training loss per 100 training steps: 0.02896409870417729\n","Training loss per 100 training steps: 0.028731893462399197\n","Training loss per 100 training steps: 0.028801306674674117\n","Training loss epoch: 0.028658417007249394\n","Training accuracy epoch: 0.9916002859477124\n","Validating model...\n","Validation Loss: 0.22327631894871708\n","Validation Accuracy: 0.9574142156862745\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0009671546285971999\n","Training loss per 100 training steps: 0.024731943213656352\n","Training loss per 100 training steps: 0.014650516590770723\n","Training loss per 100 training steps: 0.018603140686434056\n","Training loss per 100 training steps: 0.02082906497827182\n","Training loss per 100 training steps: 0.023425851995177695\n","Training loss per 100 training steps: 0.022318824311174427\n","Training loss per 100 training steps: 0.023455657116562584\n","Training loss per 100 training steps: 0.023696380809201487\n","Training loss per 100 training steps: 0.02310570691532991\n","Training loss per 100 training steps: 0.02335399639670394\n","Training loss per 100 training steps: 0.022710539789884233\n","Training loss per 100 training steps: 0.02230417817502149\n","Training loss epoch: 0.022094178815808656\n","Training accuracy epoch: 0.9939491421568627\n","Validating model...\n","Validation Loss: 0.22995969946336403\n","Validation Accuracy: 0.9525122549019608\n","Training epoch: 5\n","Training loss per 100 training steps: 0.00047653590445406735\n","Training loss per 100 training steps: 0.022630376020610094\n","Training loss per 100 training steps: 0.026464683386417272\n","Training loss per 100 training steps: 0.024298374575960752\n","Training loss per 100 training steps: 0.022190200021826346\n","Training loss per 100 training steps: 0.022643038445786585\n","Training loss per 100 training steps: 0.022945582239253554\n","Training loss per 100 training steps: 0.02209173582924838\n","Training loss per 100 training steps: 0.021034832007239546\n","Training loss per 100 training steps: 0.02114240512164704\n","Training loss per 100 training steps: 0.02202659734430526\n","Training loss per 100 training steps: 0.022936694264553296\n","Training loss per 100 training steps: 0.02311424186577926\n","Training loss epoch: 0.023065096386346424\n","Training accuracy epoch: 0.9934640522875817\n","Validating model...\n","Validation Loss: 0.23685306974007023\n","Validation Accuracy: 0.9488357843137255\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0030445598531514406\n","Training loss per 100 training steps: 0.007981028916768955\n","Training loss per 100 training steps: 0.005468069910059048\n","Training loss per 100 training steps: 0.007842969979583812\n","Training loss per 100 training steps: 0.00890582303448053\n","Training loss per 100 training steps: 0.012130352456023648\n","Training loss per 100 training steps: 0.012920380288544428\n","Training loss per 100 training steps: 0.01468233731414222\n","Training loss per 100 training steps: 0.014906600466275358\n","Training loss per 100 training steps: 0.01692340558397503\n","Training loss per 100 training steps: 0.01772054165462055\n","Training loss per 100 training steps: 0.018520789621113424\n","Training loss per 100 training steps: 0.017918410372437275\n","Training loss epoch: 0.017939873525041894\n","Training accuracy epoch: 0.9945210375816994\n","Validating model...\n","Validation Loss: 0.29318177423577735\n","Validation Accuracy: 0.9445366856419988\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 54.70444451666669 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16382002023615147\n","Validation Accuracy: 0.9530526620370371\n","Validation duration: 2.387952283333349 minutes\n","F1-score (test): 84.9%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.78      0.84      0.81      1170\n","        test       0.82      0.92      0.86      2464\n","   treatment       0.87      0.85      0.86      1244\n","\n","   micro avg       0.82      0.88      0.85      4878\n","   macro avg       0.82      0.87      0.84      4878\n","weighted avg       0.82      0.88      0.85      4878\n","\n","!!!!!! Starting model number 9 !!!!!!\n","Points in X_train after augmentation: 39156\n","Points in y_train after augmentation: 39156\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.4162144660949707\n","Training loss per 100 training steps: 0.3802113490972188\n","Training loss per 100 training steps: 0.2875908404931574\n","Training loss per 100 training steps: 0.24444289033322833\n","Training loss per 100 training steps: 0.21448654160507377\n","Training loss per 100 training steps: 0.19897088711103517\n","Training loss per 100 training steps: 0.1818282050545484\n","Training loss per 100 training steps: 0.16802237700281025\n","Training loss per 100 training steps: 0.1614103171854953\n","Training loss per 100 training steps: 0.15387342856009775\n","Training loss per 100 training steps: 0.14937619981321076\n","Training loss per 100 training steps: 0.1428107984741933\n","Training loss per 100 training steps: 0.1376430065845869\n","Training loss epoch: 0.13650447982517483\n","Training accuracy epoch: 0.9574397467320261\n","Validating model...\n","Validation Loss: 0.17736187193305322\n","Validation Accuracy: 0.9491223908918406\n","Training epoch: 2\n","Training loss per 100 training steps: 0.007998143322765827\n","Training loss per 100 training steps: 0.03633166730316301\n","Training loss per 100 training steps: 0.03137582357013158\n","Training loss per 100 training steps: 0.03301107066370581\n","Training loss per 100 training steps: 0.03537556361244466\n","Training loss per 100 training steps: 0.03769446428581243\n","Training loss per 100 training steps: 0.0382009855614504\n","Training loss per 100 training steps: 0.03778061356862805\n","Training loss per 100 training steps: 0.03902318048742617\n","Training loss per 100 training steps: 0.04060638256574651\n","Training loss per 100 training steps: 0.04025808145711012\n","Training loss per 100 training steps: 0.0404560259885098\n","Training loss per 100 training steps: 0.04094959968561617\n","Training loss epoch: 0.0410129624286996\n","Training accuracy epoch: 0.9881280637254902\n","Validating model...\n","Validation Loss: 0.18433897798269183\n","Validation Accuracy: 0.9552597248576851\n","Training epoch: 3\n","Training loss per 100 training steps: 0.001255183364264667\n","Training loss per 100 training steps: 0.02616610376816704\n","Training loss per 100 training steps: 0.027527053743445624\n","Training loss per 100 training steps: 0.025860882821656064\n","Training loss per 100 training steps: 0.028320197455969375\n","Training loss per 100 training steps: 0.029443189819813233\n","Training loss per 100 training steps: 0.028710664855229114\n","Training loss per 100 training steps: 0.029830957856249316\n","Training loss per 100 training steps: 0.03214155581321456\n","Training loss per 100 training steps: 0.032309373921395455\n","Training loss per 100 training steps: 0.03294430124896081\n","Training loss per 100 training steps: 0.032569293404133046\n","Training loss per 100 training steps: 0.03304919927323256\n","Training loss epoch: 0.03270301491318522\n","Training accuracy epoch: 0.9904003267973857\n","Validating model...\n","Validation Loss: 0.20541868806364671\n","Validation Accuracy: 0.953727862112587\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0010545344557613134\n","Training loss per 100 training steps: 0.025179108460998568\n","Training loss per 100 training steps: 0.022133779130089536\n","Training loss per 100 training steps: 0.019802143128663827\n","Training loss per 100 training steps: 0.018401902612151248\n","Training loss per 100 training steps: 0.02250113525167512\n","Training loss per 100 training steps: 0.022154455553972125\n","Training loss per 100 training steps: 0.022349737323632102\n","Training loss per 100 training steps: 0.0226952747923295\n","Training loss per 100 training steps: 0.02300919950372174\n","Training loss per 100 training steps: 0.02317791729645334\n","Training loss per 100 training steps: 0.02281088346376629\n","Training loss per 100 training steps: 0.022840515774158358\n","Training loss epoch: 0.02274300517673706\n","Training accuracy epoch: 0.993234272875817\n","Validating model...\n","Validation Loss: 0.21968605864294302\n","Validation Accuracy: 0.9531151170145478\n","Training epoch: 5\n","Training loss per 100 training steps: 0.000522337039001286\n","Training loss per 100 training steps: 0.011581608687301563\n","Training loss per 100 training steps: 0.01846094757186154\n","Training loss per 100 training steps: 0.014999902670697519\n","Training loss per 100 training steps: 0.013129446571430092\n","Training loss per 100 training steps: 0.012899957674996626\n","Training loss per 100 training steps: 0.013504921398910326\n","Training loss per 100 training steps: 0.014506866768789766\n","Training loss per 100 training steps: 0.015267709392230402\n","Training loss per 100 training steps: 0.014803307677291815\n","Training loss per 100 training steps: 0.014336541205915642\n","Training loss per 100 training steps: 0.013923660518959876\n","Training loss per 100 training steps: 0.014681861401810324\n","Training loss epoch: 0.015107046902878115\n","Training accuracy epoch: 0.9954299428104575\n","Validating model...\n","Validation Loss: 0.23789552600247393\n","Validation Accuracy: 0.9481933902593296\n","Training epoch: 6\n","Training loss per 100 training steps: 0.06251177191734314\n","Training loss per 100 training steps: 0.014155297606116123\n","Training loss per 100 training steps: 0.015059735405423031\n","Training loss per 100 training steps: 0.013117115558587258\n","Training loss per 100 training steps: 0.015278107682608058\n","Training loss per 100 training steps: 0.014205499177805251\n","Training loss per 100 training steps: 0.013404931067540177\n","Training loss per 100 training steps: 0.01560015466966122\n","Training loss per 100 training steps: 0.01610854446304567\n","Training loss per 100 training steps: 0.016559788655019468\n","Training loss per 100 training steps: 0.01565163080046589\n","Training loss per 100 training steps: 0.016738883884338873\n","Training loss per 100 training steps: 0.016448463807280284\n","Training loss epoch: 0.01649707155139944\n","Training accuracy epoch: 0.9954044117647058\n","Validating model...\n","Validation Loss: 0.2678249801789278\n","Validation Accuracy: 0.9488061353573688\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 53.763670599999934 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1747289985835744\n","Validation Accuracy: 0.9499782986111112\n","Validation duration: 2.354794566666654 minutes\n","F1-score (test): 83.1%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.78      0.77      0.78      1170\n","        test       0.79      0.92      0.85      2464\n","   treatment       0.92      0.76      0.83      1244\n","\n","   micro avg       0.82      0.85      0.83      4878\n","   macro avg       0.83      0.82      0.82      4878\n","weighted avg       0.82      0.85      0.83      4878\n","\n","!!!!!! Starting model number 10 !!!!!!\n","Points in X_train after augmentation: 39156\n","Points in y_train after augmentation: 39156\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9615694284439087\n","Training loss per 100 training steps: 0.3537227793200181\n","Training loss per 100 training steps: 0.2696466114353481\n","Training loss per 100 training steps: 0.23206732532108493\n","Training loss per 100 training steps: 0.21047998119744837\n","Training loss per 100 training steps: 0.1912137787345752\n","Training loss per 100 training steps: 0.17678111253698323\n","Training loss per 100 training steps: 0.16719831026839452\n","Training loss per 100 training steps: 0.15907410806139116\n","Training loss per 100 training steps: 0.15317080280594694\n","Training loss per 100 training steps: 0.14748693787754252\n","Training loss per 100 training steps: 0.14086981983407046\n","Training loss per 100 training steps: 0.13660627750188986\n","Training loss epoch: 0.1358730194603589\n","Training accuracy epoch: 0.9570057189542484\n","Validating model...\n","Validation Loss: 0.17111573535401156\n","Validation Accuracy: 0.9485195287792536\n","Training epoch: 2\n","Training loss per 100 training steps: 0.006979703437536955\n","Training loss per 100 training steps: 0.03946188774010591\n","Training loss per 100 training steps: 0.04127624325091668\n","Training loss per 100 training steps: 0.04107197927232937\n","Training loss per 100 training steps: 0.04325912318435124\n","Training loss per 100 training steps: 0.041589127820981536\n","Training loss per 100 training steps: 0.04142080848776432\n","Training loss per 100 training steps: 0.0410434859344379\n","Training loss per 100 training steps: 0.03973766216559431\n","Training loss per 100 training steps: 0.03983915049609078\n","Training loss per 100 training steps: 0.0394795721620505\n","Training loss per 100 training steps: 0.03901864276377818\n","Training loss per 100 training steps: 0.03859808461342077\n","Training loss epoch: 0.03858669833222367\n","Training accuracy epoch: 0.9883833741830066\n","Validating model...\n","Validation Loss: 0.23134881579636724\n","Validation Accuracy: 0.9463848039215687\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0026231880765408278\n","Training loss per 100 training steps: 0.03228228978840358\n","Training loss per 100 training steps: 0.031072671170432158\n","Training loss per 100 training steps: 0.028145996300543062\n","Training loss per 100 training steps: 0.02737081733052799\n","Training loss per 100 training steps: 0.027148953563422885\n","Training loss per 100 training steps: 0.027247997745188744\n","Training loss per 100 training steps: 0.028650159331702212\n","Training loss per 100 training steps: 0.02974896788981234\n","Training loss per 100 training steps: 0.03069472738324466\n","Training loss per 100 training steps: 0.030678219012105483\n","Training loss per 100 training steps: 0.030014116370152884\n","Training loss per 100 training steps: 0.030741447041100135\n","Training loss epoch: 0.030888935361884317\n","Training accuracy epoch: 0.9910130718954249\n","Validating model...\n","Validation Loss: 0.1961842053889425\n","Validation Accuracy: 0.9518797438330171\n","Training epoch: 4\n","Training loss per 100 training steps: 0.061515554785728455\n","Training loss per 100 training steps: 0.01943253165100572\n","Training loss per 100 training steps: 0.0171006392763287\n","Training loss per 100 training steps: 0.016644087105976306\n","Training loss per 100 training steps: 0.014665809753889444\n","Training loss per 100 training steps: 0.015616443907411466\n","Training loss per 100 training steps: 0.017607337653916057\n","Training loss per 100 training steps: 0.01852488802268818\n","Training loss per 100 training steps: 0.02062235681957274\n","Training loss per 100 training steps: 0.020959761545141398\n","Training loss per 100 training steps: 0.020823434029976683\n","Training loss per 100 training steps: 0.021768239333819734\n","Training loss per 100 training steps: 0.021405283557379046\n","Training loss epoch: 0.021530907360250602\n","Training accuracy epoch: 0.9939746732026143\n","Validating model...\n","Validation Loss: 0.2513108832345632\n","Validation Accuracy: 0.9518995098039216\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0007863030768930912\n","Training loss per 100 training steps: 0.010382599357543237\n","Training loss per 100 training steps: 0.01971684013721701\n","Training loss per 100 training steps: 0.020401893334498628\n","Training loss per 100 training steps: 0.021380883952592727\n","Training loss per 100 training steps: 0.019383075079604024\n","Training loss per 100 training steps: 0.019875479376384408\n","Training loss per 100 training steps: 0.01965420209912003\n","Training loss per 100 training steps: 0.01918070037845723\n","Training loss per 100 training steps: 0.019807721518186053\n","Training loss per 100 training steps: 0.020187728617571878\n","Training loss per 100 training steps: 0.02093940217716287\n","Training loss per 100 training steps: 0.019534762723523908\n","Training loss epoch: 0.019520783010508608\n","Training accuracy epoch: 0.9939593545751635\n","Validating model...\n","Validation Loss: 0.27251332666634753\n","Validation Accuracy: 0.946681293485136\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0002842180838342756\n","Training loss per 100 training steps: 0.012935509927695304\n","Training loss per 100 training steps: 0.014291074269871687\n","Training loss per 100 training steps: 0.014102966396400683\n","Training loss per 100 training steps: 0.012685132006433952\n","Training loss per 100 training steps: 0.011956682840295734\n","Training loss per 100 training steps: 0.01349328362138205\n","Training loss per 100 training steps: 0.013309263801946173\n","Training loss per 100 training steps: 0.012738865807686774\n","Training loss per 100 training steps: 0.014069887644571373\n","Training loss per 100 training steps: 0.01513278022442561\n","Training loss per 100 training steps: 0.01617296349148217\n","Training loss per 100 training steps: 0.017153823160265706\n","Training loss epoch: 0.017612266402888103\n","Training accuracy epoch: 0.9948937908496732\n","Validating model...\n","Validation Loss: 0.2566014091129296\n","Validation Accuracy: 0.9494386464263125\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 53.82911188333334 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16820108931588712\n","Validation Accuracy: 0.9499059606481481\n","Validation duration: 2.359043566666757 minutes\n","F1-score (test): 83.8%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.69      0.86      0.77      1170\n","        test       0.87      0.87      0.87      2464\n","   treatment       0.84      0.85      0.85      1244\n","\n","   micro avg       0.81      0.87      0.84      4878\n","   macro avg       0.80      0.86      0.83      4878\n","weighted avg       0.82      0.87      0.84      4878\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 5\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"TTDq-xbgHqXQ"}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"bert_50_perc.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0917668f72944b08b83d5402dc5b5a60":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42328398d1614a8b926b21209f76a8fe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fa9eae422f842b38be6c533616a1f9c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ac9807adede4e85a63f3b138f649f45","placeholder":"","style":"IPY_MODEL_0917668f72944b08b83d5402dc5b5a60","value":"Downloading: 100%"}},"80518727ea4c4ceaa9975f8f883f1fdd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_806fdf45960a4b25ab38e6697fe400e5","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a07e47c473894653917e6b5b49bcd52b","value":442221694}},"806fdf45960a4b25ab38e6697fe400e5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ac9807adede4e85a63f3b138f649f45":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a07e47c473894653917e6b5b49bcd52b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cada9e4086eb498fb2a1f2f5b0e48ceb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d89bc32d9d8b47fab10a8215dd8bacea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6fa9eae422f842b38be6c533616a1f9c","IPY_MODEL_80518727ea4c4ceaa9975f8f883f1fdd","IPY_MODEL_e098a89273d6492c88262989bfc18e27"],"layout":"IPY_MODEL_42328398d1614a8b926b21209f76a8fe"}},"e098a89273d6492c88262989bfc18e27":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f09f40a2829f42108748ba129fef0304","placeholder":"","style":"IPY_MODEL_cada9e4086eb498fb2a1f2f5b0e48ceb","value":" 422M/422M [00:06&lt;00:00, 68.5MB/s]"}},"f09f40a2829f42108748ba129fef0304":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7921b2377e57436a827f369ae031347a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_94b7dd99132b4d1ab44e3b12d6a2d4d3","IPY_MODEL_8a2e1dccef6d4d71a481b873a33f0161","IPY_MODEL_d12aa2a13f874918b417325e7ed594ec"],"layout":"IPY_MODEL_ad80db927f7e48379eab04846d7d42b9"}},"94b7dd99132b4d1ab44e3b12d6a2d4d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69eeefd6fc774efa88a3dd3a687d688d","placeholder":"","style":"IPY_MODEL_c30986658b024283908ed62e95da3161","value":"Downloading: 100%"}},"8a2e1dccef6d4d71a481b873a33f0161":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d48f170a84404c2fa3da6b8acbae50c3","max":385,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2a68fa1180974efa89a9b26928f4273c","value":385}},"d12aa2a13f874918b417325e7ed594ec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43cc0bc690424ba2934143b11035fc52","placeholder":"","style":"IPY_MODEL_8aa4ec30614c48909388baed3439533a","value":" 385/385 [00:00&lt;00:00, 14.0kB/s]"}},"ad80db927f7e48379eab04846d7d42b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69eeefd6fc774efa88a3dd3a687d688d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c30986658b024283908ed62e95da3161":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d48f170a84404c2fa3da6b8acbae50c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a68fa1180974efa89a9b26928f4273c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"43cc0bc690424ba2934143b11035fc52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8aa4ec30614c48909388baed3439533a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e8e3788f303428fa68b3dac9fb9513e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0ecd11f19e854fc281e8091e0a7804a9","IPY_MODEL_f8005be957004e94a640a31f74f364af","IPY_MODEL_f609d3e5ca2b4731a8f952363f2e48ed"],"layout":"IPY_MODEL_8c947bd0452e48cabefa9bfef59a1f04"}},"0ecd11f19e854fc281e8091e0a7804a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af4f256bffc84ac08f222f23ce65c912","placeholder":"","style":"IPY_MODEL_5137196c40d94440907d12dc4f43b402","value":"Downloading: 100%"}},"f8005be957004e94a640a31f74f364af":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e53623b3ce34641af45879d4f018a69","max":227845,"min":0,"orientation":"horizontal","style":"IPY_MODEL_baabfddf89054bc3a88f668d66c34830","value":227845}},"f609d3e5ca2b4731a8f952363f2e48ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78bc3e23e00f456fa29c7fe4c179e6fa","placeholder":"","style":"IPY_MODEL_6aa58aec0ef64080961b47db1dd7a3e5","value":" 223k/223k [00:00&lt;00:00, 631kB/s]"}},"8c947bd0452e48cabefa9bfef59a1f04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af4f256bffc84ac08f222f23ce65c912":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5137196c40d94440907d12dc4f43b402":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e53623b3ce34641af45879d4f018a69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"baabfddf89054bc3a88f668d66c34830":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"78bc3e23e00f456fa29c7fe4c179e6fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6aa58aec0ef64080961b47db1dd7a3e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a28bd70307b45d888888f97e267ac0b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_369b6ac6fab34c0381587a2875504651","IPY_MODEL_2f8aa33cd70142449a20a428b592c46a","IPY_MODEL_36b1b0e4541b42ffb7461231dceea20b"],"layout":"IPY_MODEL_72db0b3308ad49c88c7b5f67bc8a3bc0"}},"369b6ac6fab34c0381587a2875504651":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6226d078bff74dfc9a30cec5d9d270ac","placeholder":"","style":"IPY_MODEL_175de7028ba147478d5c8e5746616aa4","value":"Downloading: 100%"}},"2f8aa33cd70142449a20a428b592c46a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5470b1c3a9d437887c7d2e67ff9fd58","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2a5bc01e7de24916bd3031fdb0a5a8f1","value":442221694}},"36b1b0e4541b42ffb7461231dceea20b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a6a90cc22f8469f87f86fe0e8291a45","placeholder":"","style":"IPY_MODEL_a407e571b30341f79fcf6a2110f37d0e","value":" 422M/422M [00:06&lt;00:00, 68.2MB/s]"}},"72db0b3308ad49c88c7b5f67bc8a3bc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6226d078bff74dfc9a30cec5d9d270ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"175de7028ba147478d5c8e5746616aa4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d5470b1c3a9d437887c7d2e67ff9fd58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a5bc01e7de24916bd3031fdb0a5a8f1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5a6a90cc22f8469f87f86fe0e8291a45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a407e571b30341f79fcf6a2110f37d0e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}