{"cells":[{"cell_type":"markdown","metadata":{"id":"FFh7WVoJH5dr"},"source":["Adapted from [ner_with_bilstm_and_crf](https://www.kaggle.com/nikkisharma536/ner-with-bilstm-and-crf/notebook)\n","Altigran Soares da Silva\n","IComp/UFAM - 15/03/2021\n"],"id":"FFh7WVoJH5dr"},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":83579,"status":"ok","timestamp":1668757042865,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"zvip_oC0j5-y","outputId":"aafde218-6b19-4c41-dedf-184cc87d1744"},"outputs":[{"output_type":"stream","name":"stdout","text":["Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 4.0 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n","\u001b[K     |████████████████████████████████| 5.5 MB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 101.3 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 32.0 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.0 tokenizers-0.13.2 transformers-4.24.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 1.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16182 sha256=f0f70fc23c76c37dee8033d5eabea003bbd9a07c9523e615722ceca34f9491bf\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n","[2158, 24943]\n","[5, 5]\n","[26193, 5489, 13041, 21644, 21084, 14996, 22881, 12397, 16282, 13698, 12383, 3573]\n","[1, 4, 4, 4, 4, 4, 5, 6, 3, 3, 3, 5]\n","[13337, 16888, 13823]\n","[5, 5, 5]\n","17077\n","2\n","B-treatment\n","lovenox\n","28388\n","7\n"]}],"source":["# Uncomment this cell if you want to load saved data\n","\n","# Re-import necessary libs\n","import pandas as pd\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","import pickle, math\n","from requests import get\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import random\n","import time\n","%tensorflow_version 2.x\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import torch\n","from torch import cuda\n","from torch.utils.data import Dataset, DataLoader\n","!pip install sentencepiece\n","!pip install transformers\n","from transformers import BertForTokenClassification, AutoTokenizer\n","import matplotlib.pyplot as plt\n","!pip install seqeval\n","from seqeval.metrics import f1_score, classification_report\n","\n","BACKUP_FOLDER_ID = '1YWR4Ip8w94RwFMyMtNpRa9M0FpiJtqd5'\n","notebook_filename = get('http://172.28.0.2:9000/api/sessions').json()[0]['name'].replace(\"_CWR\",\"\")\n","\n","X_train_filename = f'{notebook_filename}_X_train.csv'\n","y_train_filename = f'{notebook_filename}_y_train.csv'\n","X_dev_filename = f'{notebook_filename}_X_dev.csv'\n","y_dev_filename = f'{notebook_filename}_y_dev.csv'\n","X_test_filename = f'{notebook_filename}_X_test.csv'\n","y_test_filename = f'{notebook_filename}_y_test.csv'\n","\n","word2idx_filename = f'{notebook_filename}_word2idx.pkl'\n","idx2word_filename = f'{notebook_filename}_idx2word.pkl'\n","tag2idx_filename = f'{notebook_filename}_tag2idx.pkl'\n","idx2tag_filename = f'{notebook_filename}_idx2tag.pkl'\n","\n","others_filename = f'{notebook_filename}_others.pkl'\n","\n","# Re-get important variables\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","def get_backup_files_ids(folder_id):\n","  file_list = drive.ListFile({'q': \"'{}' in parents and trashed=false\".format(folder_id)}).GetList()\n","  return file_list\n","\n","def load_backup_dataset(file_id):\n","  downloaded = drive.CreateFile({'id':file_id})\n","  downloaded.GetContentFile(f\"{file_id}.csv\")\n","\n","  dataset = pd.read_csv(f\"{file_id}.csv\", encoding=\"latin1\")\n","  dataset = dataset.values.tolist()\n","  dataset = [ [ int(word) for word in sentence if str(word) != 'nan' ] for sentence in dataset]\n","  return dataset\n","\n","def load_backup_dict(file_id):\n","  downloaded = drive.CreateFile({'id':file_id})\n","  downloaded.GetContentFile(f\"{file_id}.pkl\")\n","\n","  dict_file = open(f\"{file_id}.pkl\", \"rb\")\n","  out_dict = pickle.load(dict_file)\n","  return out_dict\n","\n","backup_file_list = get_backup_files_ids(BACKUP_FOLDER_ID)\n","\n","X_train_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == X_train_filename][0]['id']\n","y_train_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == y_train_filename][0]['id']\n","X_dev_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == X_dev_filename][0]['id']\n","y_dev_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == y_dev_filename][0]['id']\n","X_test_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == X_test_filename][0]['id']\n","y_test_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == y_test_filename][0]['id']\n","\n","word2idx_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == word2idx_filename][0]['id']\n","idx2word_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == idx2word_filename][0]['id']\n","tag2idx_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == tag2idx_filename][0]['id']\n","idx2tag_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == idx2tag_filename][0]['id']\n","\n","others_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == others_filename][0]['id']\n","\n","X_train = load_backup_dataset(X_train_file_id)\n","y_train = load_backup_dataset(y_train_file_id)\n","X_dev = load_backup_dataset(X_dev_file_id)\n","y_dev = load_backup_dataset(y_dev_file_id)\n","X_test = load_backup_dataset(X_test_file_id)\n","y_test = load_backup_dataset(y_test_file_id)\n","\n","word2idx = load_backup_dict(word2idx_file_id)\n","idx2word = load_backup_dict(idx2word_file_id)\n","tag2idx = load_backup_dict(tag2idx_file_id)\n","idx2tag = load_backup_dict(idx2tag_file_id)\n","\n","others = load_backup_dict(others_file_id)\n","\n","n_words = others[\"n_words\"]\n","n_tags = others[\"n_tags\"]\n","\n","# Check some points after loading data to see if they match the ones before saving\n","print(X_train[0])\n","print(y_train[0])\n","print(X_dev[0])\n","print(y_dev[0])\n","print(X_test[0])\n","print(y_test[0])\n","print(word2idx['comprehension'])\n","print(tag2idx['B-treatment'])\n","print(idx2tag[2])\n","print(idx2word[100])\n","print(n_words)\n","print(n_tags)"],"id":"zvip_oC0j5-y"},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["c14bd1f6e6a241139e1c30bffcd08706","519ff5f8b70c428c8f4fe26e1c668e17","82f8f0b3a08b426f92f8ac2c7ef1fe0e","94a7eaca18c3402e85ec3fae8292aab8","7c21b9fa9709447db4d894974f653ea0","0b582f60ee82482e83d2d96abcc0dbad","94a108b46b25482dacd825de0facdcec","154be693d44e4554ab51af056cfe9ec0","dec98a245fee414887653962b04b84f2","de15af0f18eb4309ac4d08bde6d141ff","67484684b0c64833a86d3ec71f9c3678","ccbd71c87ef94c208f1a9ba0bb583215","c96244782d6f44b0bce56892331e23c8","1380567c51de4e59b23c5572adf26d91","cc6eec01b9384e3887081f7c52f1d1c1","981eb6ae1b56468db29871451dd47cf4","6f5a37cd2dfc49538e04f8a5f03369b4","fcf4bbe92c9b476587bf91dbeccedcf9","48420256cc4744949c91f5e6fd4ea996","ab3cda7bdce74876b49342e47ae8012a","7d7b3d16842240549a63851f795e7b29","1e9715af13494c2390b359e9a04b9598"]},"executionInfo":{"elapsed":8142,"status":"ok","timestamp":1668757050993,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"2wRVTj71hovp","outputId":"3245b23b-b56e-4739-c010-acea76cc9f57"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/385 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c14bd1f6e6a241139e1c30bffcd08706"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/228k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccbd71c87ef94c208f1a9ba0bb583215"}},"metadata":{}}],"source":["tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n","\n","from transformers import pipeline\n","from future.utils import iteritems\n","\n","# Augmentation function using entity replacement technique.\n","# It will generate a new dataset, with X% more points based on\n","# the original dataset. E.g.: if you set augmentation percentage as 0.5 and dataset has\n","# 1000 points, it will generate a dataset with 1500 points.\n","\n","def generate_sentences(dataset, labels, augmented_set_size_percentage):\n","    if augmented_set_size_percentage < 0:\n","        raise Exception(\"Invalid augmented set size percentage\")\n","\n","    unmasker = pipeline('fill-mask', model='allenai/scibert_scivocab_uncased')\n","    \n","    number_of_new_sentences = math.ceil(augmented_set_size_percentage * len(dataset))\n","\n","    valid_dataset_idxs = [i for i,labels in enumerate(labels) if tag2idx[\"O\"] in labels]\n","    valid_dataset_sents = [sent for i,sent in enumerate(dataset) if i in valid_dataset_idxs]\n","    valid_dataset_labels = [labels for i,labels in enumerate(labels) if i in valid_dataset_idxs]\n","\n","    random_idxs = np.random.choice(len(valid_dataset_sents), number_of_new_sentences, replace=True)\n","    base_labels = [valid_dataset_labels[i] for i in random_idxs]\n","\n","    if not all([tag2idx[\"O\"] in labels for labels in base_labels]):\n","        raise Exception(\"Sentence without 'O'-tagged token in the dataset!!!\")\n","\n","    base_sequences = [valid_dataset_sents[i] for i in random_idxs]\n","\n","    new_sequences = []\n","    new_labels = []\n","    \n","    for k, sequence in enumerate(base_sequences):\n","      sequence_str = [idx2word[word] for word in sequence]\n","\n","      # check max number of tokens bert support and truncate sentence before augmentation\n","      # augmented sentence will be shorter than original sentence if higher than bert limit\n","      encoding = tokenizer(sequence_str,\n","                             is_split_into_words=True, \n","                             return_offsets_mapping=True, \n","                             truncation=True, \n","                             max_length=512)\n","      \n","      max_n_of_tokens = len([mapping for mapping in encoding[\"offset_mapping\"] if mapping[0] == 0 and mapping[1] != 0])\n","\n","      truncated_sequence_str = sequence_str[:max_n_of_tokens]\n","      truncated_labels = base_labels[k][:max_n_of_tokens]\n","\n","      # print(len(sequence_str),len(truncated_sequence_str),len(base_labels[k]),len(truncated_labels))\n","\n","      replaceable_indices = [i for i,label in enumerate(truncated_labels) if label == tag2idx[\"O\"]]\n","      replace_percent = round(random.uniform(0.1, 1), 1)\n","      replace_qty = max(math.floor(replace_percent*len(replaceable_indices)), 1)\n","      replace_indices = random.sample(replaceable_indices, k=replace_qty)\n","      replace_indices.sort()\n","\n","      masked_text_list = [\"[MASK]\" if i in replace_indices else word for i,word in enumerate(truncated_sequence_str)]\n","      new_mask_sent = ' '.join(masked_text_list)\n","      augmented_text_list = unmasker(new_mask_sent)\n","\n","      augmented_sentence = truncated_sequence_str.copy()\n","      if len(replace_indices) == 1:\n","        augmented_text_list = [augmented_text_list]\n","\n","      for i,index in enumerate(replace_indices):\n","        available_words = [word[\"token_str\"] for word in augmented_text_list[i] if word[\"token_str\"] != truncated_sequence_str[index]]\n","        new_word = random.choice(available_words)\n","        if new_word != \"[UNK]\":\n","          augmented_sentence[index] = new_word\n","\n","      # print(\"Original text->\",len(sequence_str),sequence_str)\n","      # print(\"Augmented text->\",len(sequence_str),augmented_sentence)\n","\n","      new_sequences.append(augmented_sentence)\n","      new_labels.append(truncated_labels)\n","\n","    all_words = list(set([word for seq in new_sequences for word in seq]))\n","    updated_word2idx = word2idx.copy()\n","    updated_idx2word = idx2word.copy()\n","    for word in all_words:\n","      try:\n","        updated_word2idx[word]\n","      except:\n","        updated_word2idx[word] = len(updated_word2idx)\n","    updated_idx2word = {i: w for w, i in iteritems(updated_word2idx)}\n","\n","    new_sequences = [[updated_word2idx[word] for word in seq] for seq in new_sequences]\n","\n","    augmented_X_train = dataset + new_sequences\n","    augmented_y_train = labels + new_labels\n","\n","    print(f\"Points in X_train after augmentation: {len(augmented_X_train)}\")\n","    print(f\"Points in y_train after augmentation: {len(augmented_y_train)}\")\n","\n","    return augmented_X_train, augmented_y_train, updated_word2idx, updated_idx2word"],"id":"2wRVTj71hovp"},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2845,"status":"ok","timestamp":1668757053835,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"mYHzTnzZZfBg"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n","\n","class dataset(Dataset):\n","  def __init__(self, dataframe, tokenizer, max_len):\n","        self.len = len(dataframe)\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","  def __getitem__(self, index):\n","        # step 1: get the sentence and word labels\n","        sentence = self.data.sentence[index]\n","        word_labels = self.data.word_labels[index].split(\",\") \n","\n","        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n","        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n","        encoding = self.tokenizer(sentence,\n","                             is_split_into_words=True, \n","                             return_offsets_mapping=True, \n","                             padding='max_length', \n","                             truncation=True, \n","                             max_length=self.max_len)\n","        \n","        # step 3: create token labels only for first word pieces of each tokenized word\n","        labels = [tag2idx[label] for label in word_labels] \n","        # code based on https://huggingface.co/transformers/custom_datasets.html#tok-ner\n","        # create an empty array of -100 of length max_length\n","        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n","        \n","        # set only labels whose first offset position is 0 and the second is not 0\n","        i = 0\n","        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n","          if mapping[0] == 0 and mapping[1] != 0:\n","            # overwrite label\n","            encoded_labels[idx] = labels[i]\n","            i += 1\n","\n","        # step 4: turn everything into PyTorch tensors\n","        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n","        item['labels'] = torch.as_tensor(encoded_labels)\n","        \n","        return item\n","\n","  def __len__(self):\n","        return self.len"],"id":"mYHzTnzZZfBg"},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1668757053836,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"d8H1s-6b_-pM"},"outputs":[],"source":["# some configuration variables\n","LEARNING_RATE = 5e-05\n","MAX_GRAD_NORM = 10\n","TRAINING_STOP_LOSS_PERCENTAGE = 1\n","\n","# Model creation function\n","def create_model(maxlen, n_labels, training_set, testing_set, validation_set):\n","  device = 'cuda' if cuda.is_available() else 'cpu'\n","  print(\"Device: \", device)\n","\n","  model = BertForTokenClassification.from_pretrained('allenai/scibert_scivocab_uncased', num_labels=n_labels)\n","  model.to(device)\n","\n","  optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n","\n","  TRAIN_BATCH_SIZE = round(0.05*len(training_set))\n","  if TRAIN_BATCH_SIZE > 32:\n","    TRAIN_BATCH_SIZE = 32\n","  if TRAIN_BATCH_SIZE < 10:\n","    TRAIN_BATCH_SIZE = 10\n","\n","  VALID_BATCH_SIZE = round(0.1*len(validation_set))\n","  if VALID_BATCH_SIZE > 32:\n","    VALID_BATCH_SIZE = 32\n","  if VALID_BATCH_SIZE < 10:\n","    VALID_BATCH_SIZE = 10\n","\n","  train_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                  'shuffle': True,\n","                  'num_workers': 0\n","                  }\n","\n","  test_params = {'batch_size': VALID_BATCH_SIZE,\n","                  'shuffle': True,\n","                  'num_workers': 0\n","                  }\n","\n","  training_loader = DataLoader(training_set, **train_params)\n","  testing_loader = DataLoader(testing_set, **test_params)\n","  validation_loader = DataLoader(validation_set, **test_params)\n","\n","  return model, device, optimizer, training_loader, testing_loader, validation_loader"],"id":"d8H1s-6b_-pM"},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1668757053836,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"cjp-jXx4AmiV"},"outputs":[],"source":["# Model training function\n","def train(model, device, optimizer, training_loader, epoch, training_stop_loss_percentage):\n","    tr_loss, tr_accuracy = 0, 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","    tr_preds, tr_labels = [], []\n","    losses = []\n","    # put model in training mode\n","    model.train()\n","    \n","    for idx, batch in enumerate(training_loader):\n","        \n","        ids = batch['input_ids'].to(device, dtype = torch.long)\n","        mask = batch['attention_mask'].to(device, dtype = torch.long)\n","        labels = batch['labels'].to(device, dtype = torch.long)\n","\n","        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels, return_dict = False)\n","        tr_loss += loss.item()\n","\n","        nb_tr_steps += 1\n","        nb_tr_examples += labels.size(0)\n","        \n","        if idx % 100==0:\n","            loss_step = tr_loss/nb_tr_steps\n","            print(f\"Training loss per 100 training steps: {loss_step}\")\n","            losses.append(loss_step)\n","            last_5_losses = losses[-5:]\n","            loss_min = min(last_5_losses)\n","            loss_max = max(last_5_losses)\n","            if len(last_5_losses) > 1 and (loss_max - loss_min)/loss_max < training_stop_loss_percentage/100:\n","              print(\"Stopping epoch...\")\n","              break\n","           \n","        # compute training accuracy\n","        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","        \n","        # only compute accuracy at active labels\n","        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n","        \n","        labels = torch.masked_select(flattened_targets, active_accuracy)\n","        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","        \n","        tr_labels.extend(labels)\n","        tr_preds.extend(predictions)\n","\n","        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n","        tr_accuracy += tmp_tr_accuracy\n","    \n","        # gradient clipping\n","        torch.nn.utils.clip_grad_norm_(\n","            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n","        )\n","        \n","        # backward pass\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    epoch_loss = tr_loss / nb_tr_steps\n","    tr_accuracy = tr_accuracy / nb_tr_steps\n","    print(f\"Training loss epoch: {epoch_loss}\")\n","    print(f\"Training accuracy epoch: {tr_accuracy}\")"],"id":"cjp-jXx4AmiV"},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1668757053837,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"JvdztU6FA8Bd"},"outputs":[],"source":["# Model testing function\n","def test(model, device, testing_loader):\n","    print(\"Validating model...\")\n","    # put model in evaluation mode\n","    model.eval()\n","    \n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_examples, nb_eval_steps = 0, 0\n","    eval_preds, eval_labels = [], []\n","    \n","    with torch.no_grad():\n","        for idx, batch in enumerate(testing_loader):\n","            \n","            ids = batch['input_ids'].to(device, dtype = torch.long)\n","            mask = batch['attention_mask'].to(device, dtype = torch.long)\n","            labels = batch['labels'].to(device, dtype = torch.long)\n","            \n","            loss, eval_logits = model(input_ids=ids, attention_mask=mask, labels=labels, return_dict = False)\n","            \n","            eval_loss += loss.item()\n","\n","            nb_eval_steps += 1\n","            nb_eval_examples += labels.size(0)\n","        \n","            # compute evaluation accuracy\n","            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","            \n","            # only compute accuracy at active labels\n","            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","        \n","            labels = torch.masked_select(flattened_targets, active_accuracy)\n","            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","            \n","            eval_labels.extend(labels)\n","            eval_preds.extend(predictions)\n","            \n","            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n","            eval_accuracy += tmp_eval_accuracy\n","\n","    labels = [idx2tag[id.item()] for id in eval_labels]\n","    predictions = [idx2tag[id.item()] for id in eval_preds]\n","    \n","    eval_loss = eval_loss / nb_eval_steps\n","    eval_accuracy = eval_accuracy / nb_eval_steps\n","    print(f\"Validation Loss: {eval_loss}\")\n","    print(f\"Validation Accuracy: {eval_accuracy}\")\n","\n","    return labels, predictions, eval_loss"],"id":"JvdztU6FA8Bd"},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1668757053837,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"jMknjbDrh6Fk"},"outputs":[],"source":["def create_train_and_validate_model(augmented_percentage):\n","\n","  augmented_X_train, augmented_y_train, updated_word2idx, updated_idx2word = generate_sentences(X_train, y_train, augmented_percentage)\n","\n","  maxlen_X_train = max([len(s) for s in augmented_X_train])\n","  maxlen_X_test = max([len(s) for s in X_test])\n","  maxlen_X_dev = max([len(s) for s in X_dev])\n","  maxlen_y_train = max([len(s) for s in augmented_y_train])\n","  maxlen_y_test = max([len(s) for s in y_test])\n","  maxlen_y_dev = max([len(s) for s in y_dev])\n","\n","  maxlen = max([maxlen_X_train, maxlen_X_test, maxlen_X_dev, maxlen_y_train, maxlen_y_test, maxlen_y_dev])\n","\n","  if maxlen > 512:\n","    maxlen = 512\n","\n","  augmented_X_train_words = [[updated_idx2word[word] for word in sentence] for sentence in augmented_X_train]\n","  X_dev_words = [[updated_idx2word[word] for word in sentence] for sentence in X_dev]\n","  X_test_words = [[updated_idx2word[word] for word in sentence] for sentence in X_test]\n","  augmented_y_train_tags = [','.join([idx2tag[tag] for tag in sentence]) for sentence in augmented_y_train]\n","  y_dev_tags = [','.join([idx2tag[tag] for tag in sentence]) for sentence in y_dev]\n","  y_test_tags = [','.join([idx2tag[tag] for tag in sentence]) for sentence in y_test]\n","\n","  new_train_df = pd.DataFrame({\"sentence\": augmented_X_train_words, \"word_labels\": augmented_y_train_tags}).reset_index(drop=True)\n","  new_test_df = pd.DataFrame({\"sentence\": X_test_words, \"word_labels\": y_test_tags}).reset_index(drop=True)\n","  new_val_df = pd.DataFrame({\"sentence\": X_dev_words, \"word_labels\": y_dev_tags}).reset_index(drop=True)\n","\n","  training_set = dataset(new_train_df, tokenizer, maxlen)\n","  testing_set = dataset(new_test_df, tokenizer, maxlen)\n","  validation_set = dataset(new_val_df, tokenizer, maxlen)\n","\n","  model, device, optimizer, training_loader, testing_loader, val_loader = create_model(maxlen, len(tag2idx), training_set, testing_set, validation_set)\n","\n","  training_start_time = time.clock()\n","  min_val_loss = 0\n","  MAX_PATIENCE = 5\n","  patience = 0\n","\n","  for epoch in range(100):\n","    print(f\"Training epoch: {epoch + 1}\")\n","    if patience == MAX_PATIENCE:\n","      print(\"Patience limit reached\")\n","      break\n","    train(model, device, optimizer, training_loader, epoch, TRAINING_STOP_LOSS_PERCENTAGE)\n","    labels, predictions, val_loss = test(model, device, val_loader)\n","    if ((min_val_loss == 0) or (min_val_loss != 0 and val_loss < min_val_loss)):\n","      min_val_loss = val_loss\n","      torch.save(model.state_dict(), 'checkpoint.pt')\n","      patience = 0\n","    else:\n","      patience = patience + 1\n","  print(f\"Training duration: {(time.clock() - training_start_time)/60} minutes\")\n","\n","  checkpoint = torch.load('checkpoint.pt')\n","  model.load_state_dict(checkpoint)\n","\n","  validation_start_time = time.clock()\n","  labels, predictions, test_loss = test(model, device, testing_loader)\n","  labels = [labels]\n","  predictions = [predictions]\n","  print(f\"Validation duration: {(time.clock() - validation_start_time)/60} minutes\")\n","\n","  print(\"F1-score (test): {:.1%}\".format(f1_score(labels, predictions)))\n","  print(classification_report(labels, predictions))"],"id":"jMknjbDrh6Fk"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a108736ef51f4593a72b4d21bcb9a845"]},"id":"Jhz9BiIwGCsV","outputId":"ee7645d2-f8d0-4d0b-b7df-6d64d375da33"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 25.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a108736ef51f4593a72b4d21bcb9a845","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 13000\n","Points in y_train after augmentation: 13000\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.2238314151763916\n","Training loss per 100 training steps: 0.4126851186156273\n","Training loss per 100 training steps: 0.3051232147720916\n","Training loss per 100 training steps: 0.26108700796912276\n","Training loss per 100 training steps: 0.2340318113008045\n","Training loss epoch: 0.23232007152984419\n","Training accuracy epoch: 0.9274590941603876\n","Validating model...\n","Validation Loss: 0.15484844152997065\n","Validation Accuracy: 0.9483885828565461\n","Training epoch: 2\n","Training loss per 100 training steps: 0.057135146111249924\n","Training loss per 100 training steps: 0.0989330115515997\n","Training loss per 100 training steps: 0.1006701360294475\n","Training loss per 100 training steps: 0.09721373272688434\n","Training loss per 100 training steps: 0.09553270091063476\n","Training loss epoch: 0.0955285065011087\n","Training accuracy epoch: 0.9696096870981561\n","Validating model...\n","Validation Loss: 0.13611716641621155\n","Validation Accuracy: 0.9583552006765645\n","Training epoch: 3\n","Training loss per 100 training steps: 0.027541298419237137\n","Training loss per 100 training steps: 0.05509205487565977\n","Training loss per 100 training steps: 0.05459938426525216\n","Training loss per 100 training steps: 0.05468291909653582\n","Training loss per 100 training steps: 0.05846281230979206\n","Training loss epoch: 0.05853268600936238\n","Training accuracy epoch: 0.9818300597529024\n","Validating model...\n","Validation Loss: 0.1478169064775303\n","Validation Accuracy: 0.9587731854121109\n","Training epoch: 4\n","Training loss per 100 training steps: 0.037320055067539215\n","Training loss per 100 training steps: 0.03609623385611737\n","Training loss per 100 training steps: 0.03705970860035414\n","Training loss per 100 training steps: 0.037983177444028154\n","Training loss per 100 training steps: 0.039399815184479936\n","Training loss epoch: 0.039526463177338864\n","Training accuracy epoch: 0.9877140346324675\n","Validating model...\n","Validation Loss: 0.1482496171004393\n","Validation Accuracy: 0.9607525816414747\n","Training epoch: 5\n","Training loss per 100 training steps: 0.011045616120100021\n","Training loss per 100 training steps: 0.03104108662141653\n","Training loss per 100 training steps: 0.028990659463122043\n","Training loss per 100 training steps: 0.029348679478636067\n","Training loss per 100 training steps: 0.0307468815208494\n","Training loss epoch: 0.030866343947356288\n","Training accuracy epoch: 0.9904986573412982\n","Validating model...\n","Validation Loss: 0.16314553398058398\n","Validation Accuracy: 0.958348380483241\n","Training epoch: 6\n","Training loss per 100 training steps: 0.017459901049733162\n","Training loss per 100 training steps: 0.023985430885263084\n","Training loss per 100 training steps: 0.02599225318480969\n","Training loss per 100 training steps: 0.026258288256892085\n","Training loss per 100 training steps: 0.026338700565655817\n","Training loss epoch: 0.026280902320386372\n","Training accuracy epoch: 0.9914894400101746\n","Validating model...\n","Validation Loss: 0.18030217338305016\n","Validation Accuracy: 0.960877714328911\n","Training epoch: 7\n","Training loss per 100 training steps: 0.02397543378174305\n","Training loss per 100 training steps: 0.0161285798288974\n","Training loss per 100 training steps: 0.01703078145698751\n","Training loss per 100 training steps: 0.017959426207455536\n","Training loss per 100 training steps: 0.018733826103159216\n","Training loss epoch: 0.019253875385925257\n","Training accuracy epoch: 0.994227120366662\n","Validating model...\n","Validation Loss: 0.21467057301046014\n","Validation Accuracy: 0.9555072103600386\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 53.17625231666667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14640678401014562\n","Validation Accuracy: 0.9563133527798973\n","Validation duration: 5.923016233333328 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.1%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.87      0.84     12546\n","        test       0.86      0.88      0.87      9012\n","   treatment       0.84      0.84      0.84      9297\n","\n","   micro avg       0.84      0.86      0.85     30855\n","   macro avg       0.84      0.86      0.85     30855\n","weighted avg       0.84      0.86      0.85     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 13000\n","Points in y_train after augmentation: 13000\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0112955570220947\n","Training loss per 100 training steps: 0.39809269605591746\n","Training loss per 100 training steps: 0.3010473438163302\n","Training loss per 100 training steps: 0.2586716638500508\n","Training loss per 100 training steps: 0.23195524906688497\n","Training loss epoch: 0.23108917471085486\n","Training accuracy epoch: 0.9259851856543875\n","Validating model...\n","Validation Loss: 0.15180177768910086\n","Validation Accuracy: 0.9515131534895931\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09810871630907059\n","Training loss per 100 training steps: 0.09437131824543571\n","Training loss per 100 training steps: 0.0925971098262724\n","Training loss per 100 training steps: 0.09381598297296172\n","Training loss per 100 training steps: 0.09514910937228852\n","Training loss epoch: 0.09487168233228403\n","Training accuracy epoch: 0.9698873548540892\n","Validating model...\n","Validation Loss: 0.14344580277994082\n","Validation Accuracy: 0.9561305911526541\n","Training epoch: 3\n","Training loss per 100 training steps: 0.040486641228199005\n","Training loss per 100 training steps: 0.043813322721473355\n","Training loss per 100 training steps: 0.05177129136366\n","Training loss per 100 training steps: 0.054102449963314835\n","Training loss per 100 training steps: 0.05551811813335039\n","Training loss epoch: 0.0556423707781657\n","Training accuracy epoch: 0.9824829001088985\n","Validating model...\n","Validation Loss: 0.1464276145297018\n","Validation Accuracy: 0.9586287381817292\n","Training epoch: 4\n","Training loss per 100 training steps: 0.05143219232559204\n","Training loss per 100 training steps: 0.031533905422536306\n","Training loss per 100 training steps: 0.03645095704192879\n","Training loss per 100 training steps: 0.03766124541066785\n","Training loss per 100 training steps: 0.03971953989015869\n","Training loss epoch: 0.040187273300950774\n","Training accuracy epoch: 0.9871739845174845\n","Validating model...\n","Validation Loss: 0.1786358989049475\n","Validation Accuracy: 0.9541067258726569\n","Training epoch: 5\n","Training loss per 100 training steps: 0.05046738684177399\n","Training loss per 100 training steps: 0.028386603222495997\n","Training loss per 100 training steps: 0.030575102305188034\n","Training loss per 100 training steps: 0.02862736508265707\n","Training loss per 100 training steps: 0.031226785508323543\n","Training loss epoch: 0.031187701942593647\n","Training accuracy epoch: 0.9901201019166261\n","Validating model...\n","Validation Loss: 0.1999312819574367\n","Validation Accuracy: 0.9556099953582299\n","Training epoch: 6\n","Training loss per 100 training steps: 0.003595734713599086\n","Training loss per 100 training steps: 0.03320776656878614\n","Training loss per 100 training steps: 0.02887406092674578\n","Training loss per 100 training steps: 0.027077796063548345\n","Training loss per 100 training steps: 0.027218111612900227\n","Training loss epoch: 0.027287142962664684\n","Training accuracy epoch: 0.9915736546317797\n","Validating model...\n","Validation Loss: 0.2137795524949861\n","Validation Accuracy: 0.9522915002735197\n","Training epoch: 7\n","Training loss per 100 training steps: 0.07867095619440079\n","Training loss per 100 training steps: 0.02154743463829123\n","Training loss per 100 training steps: 0.02279291998662184\n","Training loss per 100 training steps: 0.02244023059029132\n","Training loss per 100 training steps: 0.022066835942707183\n","Training loss epoch: 0.0220196490175736\n","Training accuracy epoch: 0.9933174337822224\n","Validating model...\n","Validation Loss: 0.1981103118484864\n","Validation Accuracy: 0.957134779866281\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 53.49504111666667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16541734101526714\n","Validation Accuracy: 0.9516086724151696\n","Validation duration: 5.886596333333333 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.9%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.84      0.83     12546\n","        test       0.83      0.84      0.84      9012\n","   treatment       0.81      0.84      0.82      9297\n","\n","   micro avg       0.82      0.84      0.83     30855\n","   macro avg       0.82      0.84      0.83     30855\n","weighted avg       0.82      0.84      0.83     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 13000\n","Points in y_train after augmentation: 13000\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.2550418376922607\n","Training loss per 100 training steps: 0.4070722327226459\n","Training loss per 100 training steps: 0.29755068694551784\n","Training loss per 100 training steps: 0.25888583436608315\n","Training loss per 100 training steps: 0.23234836543513057\n","Training loss epoch: 0.23095108079895632\n","Training accuracy epoch: 0.92647275794152\n","Validating model...\n","Validation Loss: 0.15328402691460274\n","Validation Accuracy: 0.9511042709437483\n","Training epoch: 2\n","Training loss per 100 training steps: 0.12198527157306671\n","Training loss per 100 training steps: 0.09148733439569426\n","Training loss per 100 training steps: 0.08875592015405644\n","Training loss per 100 training steps: 0.0920729327086743\n","Training loss per 100 training steps: 0.0910360161331192\n","Training loss epoch: 0.09054901334171067\n","Training accuracy epoch: 0.9711050980044053\n","Validating model...\n","Validation Loss: 0.1369272378249118\n","Validation Accuracy: 0.9583530297236597\n","Training epoch: 3\n","Training loss per 100 training steps: 0.054979052394628525\n","Training loss per 100 training steps: 0.04519897184823409\n","Training loss per 100 training steps: 0.04995460149864504\n","Training loss per 100 training steps: 0.05398009788783335\n","Training loss per 100 training steps: 0.05735751108598531\n","Training loss epoch: 0.057500636111258434\n","Training accuracy epoch: 0.9818175950124782\n","Validating model...\n","Validation Loss: 0.15029658407408308\n","Validation Accuracy: 0.9591360465166109\n","Training epoch: 4\n","Training loss per 100 training steps: 0.008817213587462902\n","Training loss per 100 training steps: 0.037455172231881925\n","Training loss per 100 training steps: 0.03925410533713093\n","Training loss per 100 training steps: 0.043875128581525875\n","Training loss per 100 training steps: 0.04401124837086014\n","Training loss epoch: 0.04431714082516602\n","Training accuracy epoch: 0.9860710905358145\n","Validating model...\n","Validation Loss: 0.17069133540446108\n","Validation Accuracy: 0.9551107038364686\n","Training epoch: 5\n","Training loss per 100 training steps: 0.011133678257465363\n","Training loss per 100 training steps: 0.02818112184828387\n","Training loss per 100 training steps: 0.03237760981628254\n","Training loss per 100 training steps: 0.029942633845205992\n","Training loss per 100 training steps: 0.03027286454297816\n","Training loss epoch: 0.03015485742668271\n","Training accuracy epoch: 0.9902827327378417\n","Validating model...\n","Validation Loss: 0.1728386582274522\n","Validation Accuracy: 0.9594685047375783\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0032315165735781193\n","Training loss per 100 training steps: 0.02246937623171431\n","Training loss per 100 training steps: 0.02079500330366491\n","Training loss per 100 training steps: 0.02077958711726201\n","Training loss per 100 training steps: 0.022323935355368696\n","Training loss epoch: 0.022410925771784797\n","Training accuracy epoch: 0.9930189757563128\n","Validating model...\n","Validation Loss: 0.17242131843050193\n","Validation Accuracy: 0.9606953785449024\n","Training epoch: 7\n","Training loss per 100 training steps: 0.034456510096788406\n","Training loss per 100 training steps: 0.02231172078501175\n","Training loss per 100 training steps: 0.02326729773562309\n","Training loss per 100 training steps: 0.023098686730498415\n","Training loss per 100 training steps: 0.021191272939766696\n","Training loss epoch: 0.021762085215563838\n","Training accuracy epoch: 0.9935393926600654\n","Validating model...\n","Validation Loss: 0.19702495638184347\n","Validation Accuracy: 0.9601632609114273\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 53.49970576666668 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15972100141678108\n","Validation Accuracy: 0.9542722396894165\n","Validation duration: 5.835310349999994 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.1%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.88      0.85     12546\n","        test       0.83      0.84      0.84      9012\n","   treatment       0.79      0.88      0.83      9297\n","\n","   micro avg       0.82      0.87      0.84     30855\n","   macro avg       0.82      0.87      0.84     30855\n","weighted avg       0.82      0.87      0.84     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 13000\n","Points in y_train after augmentation: 13000\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.2570841312408447\n","Training loss per 100 training steps: 0.3873715096771127\n","Training loss per 100 training steps: 0.29464976191150016\n","Training loss per 100 training steps: 0.25375524674390637\n","Training loss per 100 training steps: 0.22767647563890922\n","Training loss epoch: 0.22647583643912683\n","Training accuracy epoch: 0.9278208795012824\n","Validating model...\n","Validation Loss: 0.14021938015985025\n","Validation Accuracy: 0.9538085968411589\n","Training epoch: 2\n","Training loss per 100 training steps: 0.08775196224451065\n","Training loss per 100 training steps: 0.09354505796760025\n","Training loss per 100 training steps: 0.09720691952353983\n","Training loss per 100 training steps: 0.09718721099445392\n","Training loss per 100 training steps: 0.09568521713935527\n","Training loss epoch: 0.09554439373039789\n","Training accuracy epoch: 0.9695641640696832\n","Validating model...\n","Validation Loss: 0.14444202080659277\n","Validation Accuracy: 0.9581720046090834\n","Training epoch: 3\n","Training loss per 100 training steps: 0.007334742229431868\n","Training loss per 100 training steps: 0.05080286931652244\n","Training loss per 100 training steps: 0.05468792104352247\n","Training loss per 100 training steps: 0.056018004956596416\n","Training loss per 100 training steps: 0.05807061405722377\n","Training loss epoch: 0.05830639129028603\n","Training accuracy epoch: 0.9817398342039085\n","Validating model...\n","Validation Loss: 0.15335747569364\n","Validation Accuracy: 0.9556986720975666\n","Training epoch: 4\n","Training loss per 100 training steps: 0.02063005417585373\n","Training loss per 100 training steps: 0.036268293320450305\n","Training loss per 100 training steps: 0.04113133900465249\n","Training loss per 100 training steps: 0.04051021127141641\n","Training loss per 100 training steps: 0.04182420242020391\n","Training loss epoch: 0.041716584274476665\n","Training accuracy epoch: 0.9873373890551749\n","Validating model...\n","Validation Loss: 0.17084054173538823\n","Validation Accuracy: 0.9556389232798987\n","Training epoch: 5\n","Training loss per 100 training steps: 0.03452485427260399\n","Training loss per 100 training steps: 0.028978013546473468\n","Training loss per 100 training steps: 0.027994379488084076\n","Training loss per 100 training steps: 0.026191629297479035\n","Training loss per 100 training steps: 0.027448948540816552\n","Training loss epoch: 0.027864136541615805\n","Training accuracy epoch: 0.9912778930111248\n","Validating model...\n","Validation Loss: 0.1817202013131086\n","Validation Accuracy: 0.958026432083219\n","Training epoch: 6\n","Training loss per 100 training steps: 0.025017162784934044\n","Training loss per 100 training steps: 0.02024858658280371\n","Training loss per 100 training steps: 0.021483886972491383\n","Training loss per 100 training steps: 0.022378330195533033\n","Training loss per 100 training steps: 0.02241715577900168\n","Training loss epoch: 0.022501810999868633\n","Training accuracy epoch: 0.9932622865434687\n","Validating model...\n","Validation Loss: 0.17625160951941432\n","Validation Accuracy: 0.9598045651779458\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 45.61035351666666 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15079982542105158\n","Validation Accuracy: 0.9521800724423944\n","Validation duration: 5.888058816666671 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.83      0.83     12546\n","        test       0.85      0.85      0.85      9012\n","   treatment       0.86      0.79      0.82      9297\n","\n","   micro avg       0.84      0.83      0.83     30855\n","   macro avg       0.84      0.82      0.83     30855\n","weighted avg       0.84      0.83      0.83     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 13000\n","Points in y_train after augmentation: 13000\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9382812976837158\n","Training loss per 100 training steps: 0.3989105229035462\n","Training loss per 100 training steps: 0.29792924466269527\n","Training loss per 100 training steps: 0.2572011615573568\n","Training loss per 100 training steps: 0.23072396348836713\n","Training loss epoch: 0.22911670624624014\n","Training accuracy epoch: 0.9271736281578185\n","Validating model...\n","Validation Loss: 0.13698828198596255\n","Validation Accuracy: 0.9557010441251446\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0653398409485817\n","Training loss per 100 training steps: 0.09441687756835825\n","Training loss per 100 training steps: 0.09256862305030597\n","Training loss per 100 training steps: 0.09425025329030927\n","Training loss per 100 training steps: 0.09502224712179709\n","Training loss epoch: 0.09536519053298294\n","Training accuracy epoch: 0.9700717638671601\n","Validating model...\n","Validation Loss: 0.13855198654648546\n","Validation Accuracy: 0.9564372265137188\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0474683940410614\n","Training loss per 100 training steps: 0.04566614578782332\n","Training loss per 100 training steps: 0.05226078371642463\n","Training loss per 100 training steps: 0.05172248359652007\n","Training loss per 100 training steps: 0.053636257976823094\n","Training loss epoch: 0.054094487257732\n","Training accuracy epoch: 0.9833764709447645\n","Validating model...\n","Validation Loss: 0.1588886504049425\n","Validation Accuracy: 0.9577121035195855\n","Training epoch: 4\n","Training loss per 100 training steps: 0.036486659198999405\n","Training loss per 100 training steps: 0.03986302020470842\n","Training loss per 100 training steps: 0.03808010727762527\n","Training loss per 100 training steps: 0.03611326994617281\n","Training loss per 100 training steps: 0.03731082743434398\n","Training loss epoch: 0.03775302126817177\n","Training accuracy epoch: 0.9883807501407075\n","Validating model...\n","Validation Loss: 0.14727768155613116\n","Validation Accuracy: 0.9608554351932943\n","Training epoch: 5\n","Training loss per 100 training steps: 0.012238636612892151\n","Training loss per 100 training steps: 0.024515574772630146\n","Training loss per 100 training steps: 0.0266805623724028\n","Training loss per 100 training steps: 0.027288795651889644\n","Training loss per 100 training steps: 0.02798464101480269\n","Training loss epoch: 0.027819164741740857\n","Training accuracy epoch: 0.9916380561047304\n","Validating model...\n","Validation Loss: 0.19199388406493448\n","Validation Accuracy: 0.957533766973391\n","Training epoch: 6\n","Training loss per 100 training steps: 0.008752933703362942\n","Training loss per 100 training steps: 0.017150298652520386\n","Training loss per 100 training steps: 0.02212747135483405\n","Training loss per 100 training steps: 0.02466132748114762\n","Training loss per 100 training steps: 0.025613432264558162\n","Training loss epoch: 0.02558646388841033\n","Training accuracy epoch: 0.9921258031391329\n","Validating model...\n","Validation Loss: 0.19798566731200976\n","Validation Accuracy: 0.9591568703133718\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 45.57234491666665 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14540142093082303\n","Validation Accuracy: 0.9541562498446218\n","Validation duration: 5.860470800000015 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.85      0.83     12546\n","        test       0.84      0.88      0.86      9012\n","   treatment       0.82      0.85      0.84      9297\n","\n","   micro avg       0.82      0.86      0.84     30855\n","   macro avg       0.83      0.86      0.84     30855\n","weighted avg       0.82      0.86      0.84     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 13000\n","Points in y_train after augmentation: 13000\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.977508544921875\n","Training loss per 100 training steps: 0.4235701709985733\n","Training loss per 100 training steps: 0.3117008919072388\n","Training loss per 100 training steps: 0.26579703743325117\n","Training loss per 100 training steps: 0.23969829296159031\n","Training loss epoch: 0.23801319756950148\n","Training accuracy epoch: 0.9243448636774111\n","Validating model...\n","Validation Loss: 0.154674365535959\n","Validation Accuracy: 0.9487662996718205\n","Training epoch: 2\n","Training loss per 100 training steps: 0.15307757258415222\n","Training loss per 100 training steps: 0.1039630370491212\n","Training loss per 100 training steps: 0.09707042122658212\n","Training loss per 100 training steps: 0.09785759560392544\n","Training loss per 100 training steps: 0.09767800562566802\n","Training loss epoch: 0.09766730145809838\n","Training accuracy epoch: 0.9687976774951089\n","Validating model...\n","Validation Loss: 0.1325299736934823\n","Validation Accuracy: 0.9592338737907374\n","Training epoch: 3\n","Training loss per 100 training steps: 0.022176522761583328\n","Training loss per 100 training steps: 0.052620136275850604\n","Training loss per 100 training steps: 0.054750103848657354\n","Training loss per 100 training steps: 0.05497951044676287\n","Training loss per 100 training steps: 0.056267597860635774\n","Training loss epoch: 0.05704802042388195\n","Training accuracy epoch: 0.9822485397319739\n","Validating model...\n","Validation Loss: 0.1345162112749629\n","Validation Accuracy: 0.9599693887943841\n","Training epoch: 4\n","Training loss per 100 training steps: 0.02263173647224903\n","Training loss per 100 training steps: 0.030172266289684\n","Training loss per 100 training steps: 0.03231401951863101\n","Training loss per 100 training steps: 0.037494513337682944\n","Training loss per 100 training steps: 0.03964119975250725\n","Training loss epoch: 0.039794381285150345\n","Training accuracy epoch: 0.987877288431762\n","Validating model...\n","Validation Loss: 0.1695672465040796\n","Validation Accuracy: 0.9547557781502757\n","Training epoch: 5\n","Training loss per 100 training steps: 0.04810414835810661\n","Training loss per 100 training steps: 0.028096735573115546\n","Training loss per 100 training steps: 0.027867316974405736\n","Training loss per 100 training steps: 0.028888844388716566\n","Training loss per 100 training steps: 0.030331869053705468\n","Training loss epoch: 0.031027205518666535\n","Training accuracy epoch: 0.9903612738419458\n","Validating model...\n","Validation Loss: 0.16920325437911435\n","Validation Accuracy: 0.9594500600948546\n","Training epoch: 6\n","Training loss per 100 training steps: 0.006603678222745657\n","Training loss per 100 training steps: 0.019010728568594794\n","Training loss per 100 training steps: 0.02064174187568883\n","Training loss per 100 training steps: 0.02044441732786831\n","Training loss per 100 training steps: 0.02212132496626913\n","Training loss epoch: 0.022146501274623837\n","Training accuracy epoch: 0.9932399197639775\n","Validating model...\n","Validation Loss: 0.1741867664137057\n","Validation Accuracy: 0.9615008290927128\n","Training epoch: 7\n","Training loss per 100 training steps: 0.009872627444565296\n","Training loss per 100 training steps: 0.016163869726928043\n","Training loss per 100 training steps: 0.01960445010938464\n","Training loss per 100 training steps: 0.02235562703881623\n","Training loss per 100 training steps: 0.025216624791620117\n","Training loss epoch: 0.025594752525032044\n","Training accuracy epoch: 0.9920855730871003\n","Validating model...\n","Validation Loss: 0.17657124113243122\n","Validation Accuracy: 0.9580470031117707\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 53.24467510000001 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.154334734605746\n","Validation Accuracy: 0.953580415878085\n","Validation duration: 5.842931033333298 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.85      0.84     12546\n","        test       0.83      0.83      0.83      9012\n","   treatment       0.82      0.86      0.84      9297\n","\n","   micro avg       0.83      0.84      0.84     30855\n","   macro avg       0.83      0.84      0.84     30855\n","weighted avg       0.83      0.84      0.84     30855\n","\n","!!!!!! Starting model number 7 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 13000\n","Points in y_train after augmentation: 13000\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8411486148834229\n","Training loss per 100 training steps: 0.39431020027340047\n","Training loss per 100 training steps: 0.30655956861391587\n","Training loss per 100 training steps: 0.2613056797125807\n","Training loss per 100 training steps: 0.23441195218566052\n","Training loss epoch: 0.23343370649826323\n","Training accuracy epoch: 0.9256547588458918\n","Validating model...\n","Validation Loss: 0.14196239690018164\n","Validation Accuracy: 0.9547437751498777\n","Training epoch: 2\n","Training loss per 100 training steps: 0.1284751147031784\n","Training loss per 100 training steps: 0.09304867393918115\n","Training loss per 100 training steps: 0.09243735305232863\n","Training loss per 100 training steps: 0.09505202067842664\n","Training loss per 100 training steps: 0.09401137187979428\n","Training loss epoch: 0.09421470167609595\n","Training accuracy epoch: 0.9695288453327194\n","Validating model...\n","Validation Loss: 0.13479796192282206\n","Validation Accuracy: 0.9603329603832259\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02759338542819023\n","Training loss per 100 training steps: 0.05087913241753779\n","Training loss per 100 training steps: 0.05417449238121658\n","Training loss per 100 training steps: 0.05370472059229333\n","Training loss per 100 training steps: 0.05758653867158323\n","Training loss epoch: 0.0580273128448727\n","Training accuracy epoch: 0.9819417308301845\n","Validating model...\n","Validation Loss: 0.1633378666668356\n","Validation Accuracy: 0.9559510490469031\n","Training epoch: 4\n","Training loss per 100 training steps: 0.04005833715200424\n","Training loss per 100 training steps: 0.03379317996839043\n","Training loss per 100 training steps: 0.035169502381995246\n","Training loss per 100 training steps: 0.04066595524407156\n","Training loss per 100 training steps: 0.04056084081193809\n","Training loss epoch: 0.040767884406510566\n","Training accuracy epoch: 0.987429953705019\n","Validating model...\n","Validation Loss: 0.17469019297655528\n","Validation Accuracy: 0.9576589903108872\n","Training epoch: 5\n","Training loss per 100 training steps: 0.004489022772759199\n","Training loss per 100 training steps: 0.033182846034166984\n","Training loss per 100 training steps: 0.03239878313123615\n","Training loss per 100 training steps: 0.034044066155321615\n","Training loss per 100 training steps: 0.03323725419002295\n","Training loss epoch: 0.03336096012547809\n","Training accuracy epoch: 0.9899030556348997\n","Validating model...\n","Validation Loss: 0.16868007531413784\n","Validation Accuracy: 0.9594171315804344\n","Training epoch: 6\n","Training loss per 100 training steps: 0.011980053968727589\n","Training loss per 100 training steps: 0.034100281305168526\n","Training loss per 100 training steps: 0.029470880737120463\n","Training loss per 100 training steps: 0.030063298004880497\n","Training loss per 100 training steps: 0.02983007288800362\n","Training loss epoch: 0.029851825332328566\n","Training accuracy epoch: 0.9907093038087224\n","Validating model...\n","Validation Loss: 0.1871885589215082\n","Validation Accuracy: 0.9578478639043381\n","Training epoch: 7\n","Training loss per 100 training steps: 0.029193038120865822\n","Training loss per 100 training steps: 0.01859136170818295\n","Training loss per 100 training steps: 0.02018708465574541\n","Training loss per 100 training steps: 0.02288763177042759\n","Training loss per 100 training steps: 0.022646288814236807\n","Training loss epoch: 0.022739414107660862\n","Training accuracy epoch: 0.9934384315850397\n","Validating model...\n","Validation Loss: 0.18795981132364892\n","Validation Accuracy: 0.9569022405723765\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 53.41289586666668 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15659238677579668\n","Validation Accuracy: 0.9548296376704369\n","Validation duration: 5.8461033999999925 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.3%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.86      0.84     12546\n","        test       0.85      0.85      0.85      9012\n","   treatment       0.82      0.86      0.84      9297\n","\n","   micro avg       0.83      0.86      0.84     30855\n","   macro avg       0.83      0.86      0.84     30855\n","weighted avg       0.83      0.86      0.84     30855\n","\n","!!!!!! Starting model number 8 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 13000\n","Points in y_train after augmentation: 13000\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.4597127437591553\n","Training loss per 100 training steps: 0.42333849755549197\n","Training loss per 100 training steps: 0.3074847842330363\n","Training loss per 100 training steps: 0.26334402668119666\n","Training loss per 100 training steps: 0.2335978651005877\n","Training loss epoch: 0.23159188197820427\n","Training accuracy epoch: 0.9270056845647662\n","Validating model...\n","Validation Loss: 0.13503532326937495\n","Validation Accuracy: 0.9558760965854374\n","Training epoch: 2\n","Training loss per 100 training steps: 0.11136886477470398\n","Training loss per 100 training steps: 0.0912574577412688\n","Training loss per 100 training steps: 0.0904900441826576\n","Training loss per 100 training steps: 0.09369978563012277\n","Training loss per 100 training steps: 0.09350492029062976\n","Training loss epoch: 0.09357357117134611\n","Training accuracy epoch: 0.9701226951064713\n","Validating model...\n","Validation Loss: 0.12504187785089016\n","Validation Accuracy: 0.9600595078007097\n","Training epoch: 3\n","Training loss per 100 training steps: 0.01754111424088478\n","Training loss per 100 training steps: 0.04881304857957334\n","Training loss per 100 training steps: 0.05432548938522959\n","Training loss per 100 training steps: 0.05641915972972678\n","Training loss per 100 training steps: 0.058062653664611004\n","Training loss epoch: 0.058156429505071786\n","Training accuracy epoch: 0.9813660610494838\n","Validating model...\n","Validation Loss: 0.15117766800058352\n","Validation Accuracy: 0.9621017383719679\n","Training epoch: 4\n","Training loss per 100 training steps: 0.05814455822110176\n","Training loss per 100 training steps: 0.035563555241811394\n","Training loss per 100 training steps: 0.03755176394936902\n","Training loss per 100 training steps: 0.037870125694237526\n","Training loss per 100 training steps: 0.036769257159613336\n","Training loss epoch: 0.03679294844474918\n","Training accuracy epoch: 0.9884390133340394\n","Validating model...\n","Validation Loss: 0.15516536524398372\n","Validation Accuracy: 0.9604143268360643\n","Training epoch: 5\n","Training loss per 100 training steps: 0.030247826129198074\n","Training loss per 100 training steps: 0.024257754118615152\n","Training loss per 100 training steps: 0.023276522312260035\n","Training loss per 100 training steps: 0.02467165975092734\n","Training loss per 100 training steps: 0.025131567743777568\n","Training loss epoch: 0.025202047319353972\n","Training accuracy epoch: 0.9922249797622632\n","Validating model...\n","Validation Loss: 0.19855267322295672\n","Validation Accuracy: 0.9576539377700456\n","Training epoch: 6\n","Training loss per 100 training steps: 0.011917719617486\n","Training loss per 100 training steps: 0.019689714317648016\n","Training loss per 100 training steps: 0.02213661800763009\n","Training loss per 100 training steps: 0.02438044888945915\n","Training loss per 100 training steps: 0.024344933122725104\n","Training loss epoch: 0.02507821719790866\n","Training accuracy epoch: 0.992174930499514\n","Validating model...\n","Validation Loss: 0.20861173113928988\n","Validation Accuracy: 0.9531122082259962\n","Training epoch: 7\n","Training loss per 100 training steps: 0.12100710719823837\n","Training loss per 100 training steps: 0.025066193480201362\n","Training loss per 100 training steps: 0.029067383056265574\n","Training loss per 100 training steps: 0.02666464654003205\n","Training loss per 100 training steps: 0.025855959415728425\n","Training loss epoch: 0.025616367988823857\n","Training accuracy epoch: 0.9922870740405313\n","Validating model...\n","Validation Loss: 0.21139339599516485\n","Validation Accuracy: 0.9546279839920127\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 53.44403953333337 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14859946798188267\n","Validation Accuracy: 0.955686386971192\n","Validation duration: 5.853588733333284 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.3%\n","              precision    recall  f1-score   support\n","\n","     problem       0.85      0.84      0.84     12546\n","        test       0.85      0.85      0.85      9012\n","   treatment       0.82      0.85      0.83      9297\n","\n","   micro avg       0.84      0.85      0.84     30855\n","   macro avg       0.84      0.85      0.84     30855\n","weighted avg       0.84      0.85      0.84     30855\n","\n","!!!!!! Starting model number 9 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 13000\n","Points in y_train after augmentation: 13000\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.230412244796753\n","Training loss per 100 training steps: 0.42328684946688094\n","Training loss per 100 training steps: 0.3143403207262357\n","Training loss per 100 training steps: 0.2648460761059162\n","Training loss per 100 training steps: 0.23912089611601056\n","Training loss epoch: 0.2378269468573739\n","Training accuracy epoch: 0.9234077158150711\n","Validating model...\n","Validation Loss: 0.13010220752133952\n","Validation Accuracy: 0.9565807934660261\n","Training epoch: 2\n","Training loss per 100 training steps: 0.08279342204332352\n","Training loss per 100 training steps: 0.10072778074974471\n","Training loss per 100 training steps: 0.099414742635146\n","Training loss per 100 training steps: 0.09944749241880453\n","Training loss per 100 training steps: 0.09933788237043487\n","Training loss epoch: 0.09893633722824202\n","Training accuracy epoch: 0.9685570076672071\n","Validating model...\n","Validation Loss: 0.13639669877464894\n","Validation Accuracy: 0.9574038769640777\n","Training epoch: 3\n","Training loss per 100 training steps: 0.024662241339683533\n","Training loss per 100 training steps: 0.05183850221870707\n","Training loss per 100 training steps: 0.05575799248158116\n","Training loss per 100 training steps: 0.05428783960819888\n","Training loss per 100 training steps: 0.056660564401491254\n","Training loss epoch: 0.05650847318584525\n","Training accuracy epoch: 0.9818822881312895\n","Validating model...\n","Validation Loss: 0.1534519816277089\n","Validation Accuracy: 0.9588321649579926\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0487186573445797\n","Training loss per 100 training steps: 0.029767642325564923\n","Training loss per 100 training steps: 0.036792036312729565\n","Training loss per 100 training steps: 0.03803456651644033\n","Training loss per 100 training steps: 0.038270300477766375\n","Training loss epoch: 0.03820181527765381\n","Training accuracy epoch: 0.9877576598643638\n","Validating model...\n","Validation Loss: 0.15889569824295385\n","Validation Accuracy: 0.9596514399445452\n","Training epoch: 5\n","Training loss per 100 training steps: 0.06737027317285538\n","Training loss per 100 training steps: 0.025986099515414546\n","Training loss per 100 training steps: 0.02804110199213028\n","Training loss per 100 training steps: 0.028923672288996585\n","Training loss per 100 training steps: 0.03273920240252281\n","Training loss epoch: 0.03287049108562437\n","Training accuracy epoch: 0.9903615494467952\n","Validating model...\n","Validation Loss: 0.17378981363076668\n","Validation Accuracy: 0.9558211544722036\n","Training epoch: 6\n","Training loss per 100 training steps: 0.025687428191304207\n","Training loss per 100 training steps: 0.029139454629834704\n","Training loss per 100 training steps: 0.027046548827280248\n","Training loss per 100 training steps: 0.02670017561153586\n","Training loss per 100 training steps: 0.027509408766209865\n","Training loss epoch: 0.027325727645203662\n","Training accuracy epoch: 0.9914575920511772\n","Validating model...\n","Validation Loss: 0.17478307042355565\n","Validation Accuracy: 0.9596412034059345\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 45.82343278333331 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14822087074733442\n","Validation Accuracy: 0.9528600879969388\n","Validation duration: 5.844619833333369 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.85      0.83     12546\n","        test       0.85      0.83      0.84      9012\n","   treatment       0.77      0.87      0.82      9297\n","\n","   micro avg       0.81      0.85      0.83     30855\n","   macro avg       0.81      0.85      0.83     30855\n","weighted avg       0.81      0.85      0.83     30855\n","\n","!!!!!! Starting model number 10 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 13000\n","Points in y_train after augmentation: 13000\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.059187173843384\n","Training loss per 100 training steps: 0.39909620524042905\n","Training loss per 100 training steps: 0.30300809902634784\n","Training loss per 100 training steps: 0.25864272288656315\n","Training loss per 100 training steps: 0.23020051191200935\n","Training loss epoch: 0.22915991943064135\n","Training accuracy epoch: 0.9269013035678113\n","Validating model...\n","Validation Loss: 0.13536044459354568\n","Validation Accuracy: 0.957350122374581\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09385625272989273\n","Training loss per 100 training steps: 0.08797331312025833\n","Training loss per 100 training steps: 0.0923100106733207\n","Training loss per 100 training steps: 0.0949701900250492\n","Training loss per 100 training steps: 0.09624444292927918\n","Training loss epoch: 0.0966064448065653\n","Training accuracy epoch: 0.9694450395882849\n","Validating model...\n","Validation Loss: 0.14050657723050614\n","Validation Accuracy: 0.9562581084236369\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02284182608127594\n","Training loss per 100 training steps: 0.056227770269765415\n","Training loss per 100 training steps: 0.056898087844604726\n","Training loss per 100 training steps: 0.05992051468469029\n","Training loss per 100 training steps: 0.06133422017111408\n","Training loss epoch: 0.061162755825769625\n","Training accuracy epoch: 0.9808300157393606\n","Validating model...\n","Validation Loss: 0.15808118601607812\n","Validation Accuracy: 0.9585223696551503\n","Training epoch: 4\n","Training loss per 100 training steps: 0.006768094841390848\n","Training loss per 100 training steps: 0.0393589240346694\n","Training loss per 100 training steps: 0.04015782275538317\n","Training loss per 100 training steps: 0.03993091900969091\n","Training loss per 100 training steps: 0.039360725535997225\n","Training loss epoch: 0.03923501939191289\n","Training accuracy epoch: 0.987662942269734\n","Validating model...\n","Validation Loss: 0.17533340698180647\n","Validation Accuracy: 0.9575548745469706\n","Training epoch: 5\n","Training loss per 100 training steps: 0.014549411833286285\n","Training loss per 100 training steps: 0.03654310708902407\n","Training loss per 100 training steps: 0.03636675395085407\n","Training loss per 100 training steps: 0.03424413250898478\n","Training loss per 100 training steps: 0.033541994274447574\n","Training loss epoch: 0.033679210056015346\n","Training accuracy epoch: 0.9894238058215459\n","Validating model...\n","Validation Loss: 0.16932922780707285\n","Validation Accuracy: 0.9591587681375555\n","Training epoch: 6\n","Training loss per 100 training steps: 0.058108139783144\n","Training loss per 100 training steps: 0.024087051783762133\n","Training loss per 100 training steps: 0.02244156907748116\n","Training loss per 100 training steps: 0.02547169308738158\n","Training loss per 100 training steps: 0.028543224477527333\n","Training loss epoch: 0.028411862111755667\n","Training accuracy epoch: 0.9913075714293149\n","Validating model...\n","Validation Loss: 0.1781481396310128\n","Validation Accuracy: 0.9589883087291504\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 45.77358655000001 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1405412553382727\n","Validation Accuracy: 0.9564305906762057\n","Validation duration: 5.846117133333367 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.85      0.84     12546\n","        test       0.86      0.87      0.87      9012\n","   treatment       0.81      0.87      0.84      9297\n","\n","   micro avg       0.83      0.86      0.85     30855\n","   macro avg       0.83      0.86      0.85     30855\n","weighted avg       0.83      0.86      0.85     30855\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0.25\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"Jhz9BiIwGCsV"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"jdO4m5O4Hlo3","outputId":"40b2e8fd-a19f-44d3-ae76-14e20f5fd810"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 50.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 15600\n","Points in y_train after augmentation: 15600\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1292853355407715\n","Training loss per 100 training steps: 0.39948544356197413\n","Training loss per 100 training steps: 0.3046537917570688\n","Training loss per 100 training steps: 0.26319790643909047\n","Training loss per 100 training steps: 0.23728957456859417\n","Training loss epoch: 0.21904744056328276\n","Training accuracy epoch: 0.9315449211055197\n","Validating model...\n","Validation Loss: 0.13768013153080041\n","Validation Accuracy: 0.955028007333299\n","Training epoch: 2\n","Training loss per 100 training steps: 0.12206325680017471\n","Training loss per 100 training steps: 0.08343403547596519\n","Training loss per 100 training steps: 0.08710945473140597\n","Training loss per 100 training steps: 0.08734091321482908\n","Training loss per 100 training steps: 0.091776261684436\n","Training loss epoch: 0.09213995330844868\n","Training accuracy epoch: 0.9710661344002037\n","Validating model...\n","Validation Loss: 0.1441198710787606\n","Validation Accuracy: 0.9565410597715229\n","Training epoch: 3\n","Training loss per 100 training steps: 0.05295513942837715\n","Training loss per 100 training steps: 0.04915975392473364\n","Training loss per 100 training steps: 0.051143653417441676\n","Training loss per 100 training steps: 0.051928048653286756\n","Training loss per 100 training steps: 0.052510048432317456\n","Training loss epoch: 0.05516451353791216\n","Training accuracy epoch: 0.9825461568823598\n","Validating model...\n","Validation Loss: 0.14622265497198353\n","Validation Accuracy: 0.9534106802992462\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03582223132252693\n","Training loss per 100 training steps: 0.028655634969380676\n","Training loss per 100 training steps: 0.029392148831405153\n","Training loss per 100 training steps: 0.03331744755646121\n","Training loss per 100 training steps: 0.034461686790031275\n","Training loss epoch: 0.03398816637192914\n","Training accuracy epoch: 0.9889734397567972\n","Validating model...\n","Validation Loss: 0.1779265125681247\n","Validation Accuracy: 0.9576042968255725\n","Training epoch: 5\n","Training loss per 100 training steps: 0.014769312925636768\n","Training loss per 100 training steps: 0.026744056238313343\n","Training loss per 100 training steps: 0.027593296959495812\n","Training loss per 100 training steps: 0.0291327514052948\n","Training loss per 100 training steps: 0.03056628757622093\n","Training loss epoch: 0.03043622400236629\n","Training accuracy epoch: 0.9903283300902417\n","Validating model...\n","Validation Loss: 0.17326583187156297\n","Validation Accuracy: 0.9581890446325206\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0025738405529409647\n","Training loss per 100 training steps: 0.01704791902292446\n","Training loss per 100 training steps: 0.01903025750464653\n","Training loss per 100 training steps: 0.01955457244716597\n","Training loss per 100 training steps: 0.019774897801056922\n","Training loss epoch: 0.020431548966520434\n","Training accuracy epoch: 0.993482048321539\n","Validating model...\n","Validation Loss: 0.18138391343126822\n","Validation Accuracy: 0.9590156418759906\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 54.26335266666671 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14608878104869896\n","Validation Accuracy: 0.9539999015329629\n","Validation duration: 5.849044333333343 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.3%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.86      0.83     12546\n","        test       0.85      0.87      0.86      9012\n","   treatment       0.83      0.85      0.84      9297\n","\n","   micro avg       0.83      0.86      0.84     30855\n","   macro avg       0.83      0.86      0.84     30855\n","weighted avg       0.83      0.86      0.84     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 15600\n","Points in y_train after augmentation: 15600\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9798208475112915\n","Training loss per 100 training steps: 0.42940197058833474\n","Training loss per 100 training steps: 0.31975572463588336\n","Training loss per 100 training steps: 0.2670054478799782\n","Training loss per 100 training steps: 0.2379407609564408\n","Training loss epoch: 0.22220570276506613\n","Training accuracy epoch: 0.9301068487026367\n","Validating model...\n","Validation Loss: 0.14404959451745858\n","Validation Accuracy: 0.9553639325905013\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07341080158948898\n","Training loss per 100 training steps: 0.0878877875828507\n","Training loss per 100 training steps: 0.0862827490486983\n","Training loss per 100 training steps: 0.08840245587992608\n","Training loss per 100 training steps: 0.08859308276957184\n","Training loss epoch: 0.08719468750174111\n","Training accuracy epoch: 0.9718698753911136\n","Validating model...\n","Validation Loss: 0.15273612779988485\n","Validation Accuracy: 0.9557294680786864\n","Training epoch: 3\n","Training loss per 100 training steps: 0.09123104065656662\n","Training loss per 100 training steps: 0.04510929269052231\n","Training loss per 100 training steps: 0.04951172220330704\n","Training loss per 100 training steps: 0.0503342821528869\n","Training loss per 100 training steps: 0.052312853280454874\n","Training loss epoch: 0.05242523804524547\n","Training accuracy epoch: 0.9832858592038747\n","Validating model...\n","Validation Loss: 0.16320084618380318\n","Validation Accuracy: 0.9571970484684106\n","Training epoch: 4\n","Training loss per 100 training steps: 0.047848641872406006\n","Training loss per 100 training steps: 0.029728784387248873\n","Training loss per 100 training steps: 0.031201608474389533\n","Training loss per 100 training steps: 0.034194372371581704\n","Training loss per 100 training steps: 0.035450521772936394\n","Training loss epoch: 0.03938993958319293\n","Training accuracy epoch: 0.987531887886415\n","Validating model...\n","Validation Loss: 0.17070068855007942\n","Validation Accuracy: 0.9583555980845835\n","Training epoch: 5\n","Training loss per 100 training steps: 0.030560847371816635\n","Training loss per 100 training steps: 0.03058665007869206\n","Stopping epoch...\n","Training loss epoch: 0.03058665007869206\n","Training accuracy epoch: 0.980536707960723\n","Validating model...\n","Validation Loss: 0.1973880093980145\n","Validation Accuracy: 0.9557255668005171\n","Training epoch: 6\n","Training loss per 100 training steps: 0.03404594957828522\n","Training loss per 100 training steps: 0.026231633432412353\n","Training loss per 100 training steps: 0.027413520140721653\n","Training loss per 100 training steps: 0.025283214514317035\n","Training loss per 100 training steps: 0.026046267858975826\n","Training loss epoch: 0.026497681046778587\n","Training accuracy epoch: 0.9918706570618975\n","Validating model...\n","Validation Loss: 0.18573334031774627\n","Validation Accuracy: 0.9586988649988566\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 47.508091849999985 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1609290445620125\n","Validation Accuracy: 0.9497056273064953\n","Validation duration: 5.855552416666614 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 81.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.82      0.82     12546\n","        test       0.86      0.82      0.84      9012\n","   treatment       0.73      0.84      0.78      9297\n","\n","   micro avg       0.80      0.83      0.81     30855\n","   macro avg       0.80      0.83      0.81     30855\n","weighted avg       0.81      0.83      0.81     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 15600\n","Points in y_train after augmentation: 15600\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8070671558380127\n","Training loss per 100 training steps: 0.40044921312001674\n","Training loss per 100 training steps: 0.29857946765511784\n","Training loss per 100 training steps: 0.2577745011107272\n","Training loss per 100 training steps: 0.23298702860004883\n","Training loss epoch: 0.2196625423174901\n","Training accuracy epoch: 0.9296777547177694\n","Validating model...\n","Validation Loss: 0.13647449829361655\n","Validation Accuracy: 0.9558042985665876\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05191592499613762\n","Training loss per 100 training steps: 0.09315817147530246\n","Training loss per 100 training steps: 0.0866448257757879\n","Training loss per 100 training steps: 0.08542828923060351\n","Training loss per 100 training steps: 0.08679133103904953\n","Training loss epoch: 0.08721791872884467\n","Training accuracy epoch: 0.9720013527043682\n","Validating model...\n","Validation Loss: 0.14041569797539866\n","Validation Accuracy: 0.9583644829865423\n","Training epoch: 3\n","Training loss per 100 training steps: 0.06579570472240448\n","Training loss per 100 training steps: 0.05659526198327836\n","Training loss per 100 training steps: 0.058016395465058476\n","Training loss per 100 training steps: 0.05855298409489079\n","Training loss per 100 training steps: 0.0580551231836208\n","Training loss epoch: 0.05822598258821584\n","Training accuracy epoch: 0.9820386655811342\n","Validating model...\n","Validation Loss: 0.14371468642025026\n","Validation Accuracy: 0.9578283426137947\n","Training epoch: 4\n","Training loss per 100 training steps: 0.05734908580780029\n","Training loss per 100 training steps: 0.03339322255970449\n","Training loss per 100 training steps: 0.033383596568618584\n","Training loss per 100 training steps: 0.035096610588813665\n","Training loss per 100 training steps: 0.035183556845000574\n","Training loss epoch: 0.035189362819884815\n","Training accuracy epoch: 0.9891150561809233\n","Validating model...\n","Validation Loss: 0.16853288112982334\n","Validation Accuracy: 0.957539983584708\n","Training epoch: 5\n","Training loss per 100 training steps: 0.005027676932513714\n","Training loss per 100 training steps: 0.02506486848596078\n","Training loss per 100 training steps: 0.023632290138311647\n","Training loss per 100 training steps: 0.024574518480656848\n","Training loss per 100 training steps: 0.025545884957281578\n","Training loss epoch: 0.025040051650320805\n","Training accuracy epoch: 0.9920453215503576\n","Validating model...\n","Validation Loss: 0.2075192279714559\n","Validation Accuracy: 0.9582320802566645\n","Training epoch: 6\n","Training loss per 100 training steps: 0.006181370001286268\n","Training loss per 100 training steps: 0.02159583745385972\n","Training loss per 100 training steps: 0.020083944976100446\n","Training loss per 100 training steps: 0.021911094355995635\n","Training loss per 100 training steps: 0.02261744797804005\n","Training loss epoch: 0.022553423504162864\n","Training accuracy epoch: 0.993309924940621\n","Validating model...\n","Validation Loss: 0.199060741352377\n","Validation Accuracy: 0.9584308694195265\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 54.333037650000065 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1468568061655215\n","Validation Accuracy: 0.9527286071599363\n","Validation duration: 5.858509400000063 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.85      0.83     12546\n","        test       0.79      0.89      0.84      9012\n","   treatment       0.79      0.87      0.83      9297\n","\n","   micro avg       0.80      0.87      0.83     30855\n","   macro avg       0.80      0.87      0.83     30855\n","weighted avg       0.80      0.87      0.83     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 15600\n","Points in y_train after augmentation: 15600\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.178138494491577\n","Training loss per 100 training steps: 0.41571889994758193\n","Training loss per 100 training steps: 0.30757838950969685\n","Training loss per 100 training steps: 0.2646948339980702\n","Training loss per 100 training steps: 0.23631886581418818\n","Training loss epoch: 0.22135144940073617\n","Training accuracy epoch: 0.9290933685454652\n","Validating model...\n","Validation Loss: 0.1448499064457107\n","Validation Accuracy: 0.9555815789567454\n","Training epoch: 2\n","Training loss per 100 training steps: 0.14134854078292847\n","Training loss per 100 training steps: 0.0982555686357883\n","Training loss per 100 training steps: 0.09109657429232823\n","Training loss per 100 training steps: 0.08954629476841205\n","Training loss per 100 training steps: 0.08896703525513708\n","Training loss epoch: 0.08958545695707874\n","Training accuracy epoch: 0.9715441996424672\n","Validating model...\n","Validation Loss: 0.1407250395504298\n","Validation Accuracy: 0.9587906924070646\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0340920016169548\n","Training loss per 100 training steps: 0.05070872540760896\n","Training loss per 100 training steps: 0.05345135956622697\n","Training loss per 100 training steps: 0.05571068153001888\n","Training loss per 100 training steps: 0.05561746552033801\n","Training loss epoch: 0.055517277504760223\n","Training accuracy epoch: 0.9822623559680108\n","Validating model...\n","Validation Loss: 0.14752273387336112\n","Validation Accuracy: 0.9573965841403608\n","Training epoch: 4\n","Training loss per 100 training steps: 0.049404654651880264\n","Training loss per 100 training steps: 0.033290805032310807\n","Training loss per 100 training steps: 0.03414843104714852\n","Training loss per 100 training steps: 0.036474674144926854\n","Training loss per 100 training steps: 0.03844830730205351\n","Training loss epoch: 0.03815443441367204\n","Training accuracy epoch: 0.9880104818523607\n","Validating model...\n","Validation Loss: 0.1607334501557536\n","Validation Accuracy: 0.9606050835958778\n","Training epoch: 5\n","Training loss per 100 training steps: 0.017328407615423203\n","Training loss per 100 training steps: 0.028669376401138483\n","Training loss per 100 training steps: 0.026795823037837497\n","Training loss per 100 training steps: 0.026712241746946253\n","Training loss per 100 training steps: 0.026544742690610638\n","Training loss epoch: 0.026725766444080184\n","Training accuracy epoch: 0.991704333151857\n","Validating model...\n","Validation Loss: 0.1878439680576421\n","Validation Accuracy: 0.9584363249287331\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0069278571754693985\n","Training loss per 100 training steps: 0.02051770741737789\n","Training loss per 100 training steps: 0.021967102073258096\n","Training loss per 100 training steps: 0.022270038833785987\n","Training loss per 100 training steps: 0.023749131565632537\n","Training loss epoch: 0.024718133609820173\n","Training accuracy epoch: 0.992399454729994\n","Validating model...\n","Validation Loss: 0.2124968861991709\n","Validation Accuracy: 0.9559976088258354\n","Training epoch: 7\n","Training loss per 100 training steps: 0.028184691444039345\n","Training loss per 100 training steps: 0.01623806665538543\n","Training loss per 100 training steps: 0.016598804100052874\n","Training loss per 100 training steps: 0.017770380468418716\n","Training loss per 100 training steps: 0.019307585757259427\n","Training loss epoch: 0.020159979231109782\n","Training accuracy epoch: 0.9937428561301771\n","Validating model...\n","Validation Loss: 0.18742841719226402\n","Validation Accuracy: 0.9570586517978957\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 63.43696131666669 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16153759042585822\n","Validation Accuracy: 0.9549937884992716\n","Validation duration: 5.860334083333388 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.85      0.84     12546\n","        test       0.85      0.88      0.86      9012\n","   treatment       0.82      0.85      0.84      9297\n","\n","   micro avg       0.83      0.86      0.85     30855\n","   macro avg       0.83      0.86      0.85     30855\n","weighted avg       0.83      0.86      0.85     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 15600\n","Points in y_train after augmentation: 15600\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9661195278167725\n","Training loss per 100 training steps: 0.41607447425917826\n","Training loss per 100 training steps: 0.3157184231118183\n","Training loss per 100 training steps: 0.2678470673949219\n","Training loss per 100 training steps: 0.2396773924665558\n","Training loss epoch: 0.22308562892168515\n","Training accuracy epoch: 0.9291466533124719\n","Validating model...\n","Validation Loss: 0.13720003094572525\n","Validation Accuracy: 0.9567732385554233\n","Training epoch: 2\n","Training loss per 100 training steps: 0.1373346447944641\n","Training loss per 100 training steps: 0.0797509543487046\n","Training loss per 100 training steps: 0.08660902007858255\n","Training loss per 100 training steps: 0.08798489940547666\n","Training loss per 100 training steps: 0.08757420157563137\n","Training loss epoch: 0.08731025789642981\n","Training accuracy epoch: 0.9717876771908349\n","Validating model...\n","Validation Loss: 0.15031669247750337\n","Validation Accuracy: 0.9561657820062586\n","Training epoch: 3\n","Training loss per 100 training steps: 0.009022052399814129\n","Training loss per 100 training steps: 0.047143336500751205\n","Training loss per 100 training steps: 0.050438317257114014\n","Training loss per 100 training steps: 0.052652625425833204\n","Training loss per 100 training steps: 0.053011144979385444\n","Training loss epoch: 0.05388993446020501\n","Training accuracy epoch: 0.9830399341727719\n","Validating model...\n","Validation Loss: 0.16155649385378731\n","Validation Accuracy: 0.9581660017090331\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03778611868619919\n","Training loss per 100 training steps: 0.03603281457977609\n","Training loss per 100 training steps: 0.035700983615170476\n","Training loss per 100 training steps: 0.035697784322388224\n","Training loss per 100 training steps: 0.03634033008900116\n","Training loss epoch: 0.036706245103307056\n","Training accuracy epoch: 0.9884905922565911\n","Validating model...\n","Validation Loss: 0.16725781030178843\n","Validation Accuracy: 0.9587808988932661\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0213908888399601\n","Training loss per 100 training steps: 0.024331359642253508\n","Training loss per 100 training steps: 0.023753546666590245\n","Training loss per 100 training steps: 0.02582537991565612\n","Training loss per 100 training steps: 0.02620907532930272\n","Training loss epoch: 0.027004124502008245\n","Training accuracy epoch: 0.9912953420614007\n","Validating model...\n","Validation Loss: 0.1895564172368545\n","Validation Accuracy: 0.9549746884319961\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00550649780780077\n","Training loss per 100 training steps: 0.02995302043924348\n","Training loss per 100 training steps: 0.02723432134660841\n","Training loss per 100 training steps: 0.027727799979347947\n","Training loss per 100 training steps: 0.02657800267521348\n","Training loss epoch: 0.027113717460630796\n","Training accuracy epoch: 0.9914739841903799\n","Validating model...\n","Validation Loss: 0.18597894324921072\n","Validation Accuracy: 0.9566916393055328\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 54.29805390000001 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15064534122615847\n","Validation Accuracy: 0.9542708939204059\n","Validation duration: 5.847202883333376 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.85      0.82      0.84     12546\n","        test       0.86      0.86      0.86      9012\n","   treatment       0.83      0.86      0.84      9297\n","\n","   micro avg       0.85      0.84      0.84     30855\n","   macro avg       0.85      0.84      0.85     30855\n","weighted avg       0.85      0.84      0.84     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 15600\n","Points in y_train after augmentation: 15600\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.01393723487854\n","Training loss per 100 training steps: 0.41727029200237575\n","Training loss per 100 training steps: 0.31277052042496145\n","Training loss per 100 training steps: 0.2672245497273844\n","Training loss per 100 training steps: 0.24155739090054706\n","Training loss epoch: 0.22203901672705276\n","Training accuracy epoch: 0.9303542961169036\n","Validating model...\n","Validation Loss: 0.13963487057329774\n","Validation Accuracy: 0.9547401590543123\n","Training epoch: 2\n","Training loss per 100 training steps: 0.1254035234451294\n","Training loss per 100 training steps: 0.08863653072921357\n","Training loss per 100 training steps: 0.08743197383562946\n","Training loss per 100 training steps: 0.08922339551169363\n","Training loss per 100 training steps: 0.08832480307747413\n","Training loss epoch: 0.08926826456970093\n","Training accuracy epoch: 0.971875073819423\n","Validating model...\n","Validation Loss: 0.15273699135362329\n","Validation Accuracy: 0.9563398156301574\n","Training epoch: 3\n","Training loss per 100 training steps: 0.01289375964552164\n","Training loss per 100 training steps: 0.04789361312505928\n","Training loss per 100 training steps: 0.05227911963465795\n","Training loss per 100 training steps: 0.05574395125762767\n","Training loss per 100 training steps: 0.05633918168789654\n","Training loss epoch: 0.05817142584204643\n","Training accuracy epoch: 0.9820017832498317\n","Validating model...\n","Validation Loss: 0.15981659421382785\n","Validation Accuracy: 0.954781940124651\n","Training epoch: 4\n","Training loss per 100 training steps: 0.06816117465496063\n","Training loss per 100 training steps: 0.04142392374169413\n","Training loss per 100 training steps: 0.037596522123826234\n","Training loss per 100 training steps: 0.036701655086513574\n","Training loss per 100 training steps: 0.03703795879860954\n","Training loss epoch: 0.036675242419196216\n","Training accuracy epoch: 0.9887082103484799\n","Validating model...\n","Validation Loss: 0.16239285040888693\n","Validation Accuracy: 0.960659130269268\n","Training epoch: 5\n","Training loss per 100 training steps: 0.008137259632349014\n","Training loss per 100 training steps: 0.025023806676508324\n","Training loss per 100 training steps: 0.027066922422257524\n","Training loss per 100 training steps: 0.027953147145214047\n","Training loss per 100 training steps: 0.02826476233031257\n","Training loss epoch: 0.030519945717552205\n","Training accuracy epoch: 0.9910713771669994\n","Validating model...\n","Validation Loss: 0.18340732459607836\n","Validation Accuracy: 0.9555829781762659\n","Training epoch: 6\n","Training loss per 100 training steps: 0.035834722220897675\n","Training loss per 100 training steps: 0.030704470060876395\n","Training loss per 100 training steps: 0.03290677815791571\n","Training loss per 100 training steps: 0.03186384333449221\n","Training loss per 100 training steps: 0.030819292110274836\n","Training loss epoch: 0.031081309826657192\n","Training accuracy epoch: 0.9904557539048304\n","Validating model...\n","Validation Loss: 0.1941774780317754\n","Validation Accuracy: 0.9567044625865934\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 54.357510466666646 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.149770739121811\n","Validation Accuracy: 0.9531625738538332\n","Validation duration: 5.8586268000000326 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.9%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.87      0.84     12546\n","        test       0.84      0.86      0.85      9012\n","   treatment       0.81      0.85      0.83      9297\n","\n","   micro avg       0.82      0.86      0.84     30855\n","   macro avg       0.82      0.86      0.84     30855\n","weighted avg       0.82      0.86      0.84     30855\n","\n","!!!!!! Starting model number 7 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 15600\n","Points in y_train after augmentation: 15600\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9923877716064453\n","Training loss per 100 training steps: 0.41333893118518417\n","Training loss per 100 training steps: 0.30550963731844033\n","Training loss per 100 training steps: 0.2573323004764576\n","Training loss per 100 training steps: 0.2333745898544194\n","Training loss epoch: 0.21964815052867423\n","Training accuracy epoch: 0.9305136917581336\n","Validating model...\n","Validation Loss: 0.1328175061370258\n","Validation Accuracy: 0.9576595542766806\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05757118761539459\n","Training loss per 100 training steps: 0.08067310816783568\n","Training loss per 100 training steps: 0.08178683184782293\n","Training loss per 100 training steps: 0.08346615899880215\n","Training loss per 100 training steps: 0.08389855729546072\n","Training loss epoch: 0.08350699481298597\n","Training accuracy epoch: 0.9734496032105615\n","Validating model...\n","Validation Loss: 0.1434107783262606\n","Validation Accuracy: 0.956838869088543\n","Training epoch: 3\n","Training loss per 100 training steps: 0.029102539643645287\n","Training loss per 100 training steps: 0.0452383585288051\n","Training loss per 100 training steps: 0.046472779101001754\n","Training loss per 100 training steps: 0.046944968891252714\n","Training loss per 100 training steps: 0.04731125796696826\n","Training loss epoch: 0.04754713024432603\n","Training accuracy epoch: 0.985023369213078\n","Validating model...\n","Validation Loss: 0.1609739460196201\n","Validation Accuracy: 0.9577448272419052\n","Training epoch: 4\n","Training loss per 100 training steps: 0.012444679625332355\n","Training loss per 100 training steps: 0.027926529762289015\n","Training loss per 100 training steps: 0.02724828939208418\n","Training loss per 100 training steps: 0.03371732560855853\n","Training loss per 100 training steps: 0.03595742521960837\n","Training loss epoch: 0.03699369978190201\n","Training accuracy epoch: 0.9883777497785335\n","Validating model...\n","Validation Loss: 0.17862270591030646\n","Validation Accuracy: 0.9567912724492261\n","Training epoch: 5\n","Training loss per 100 training steps: 0.011561350896954536\n","Training loss per 100 training steps: 0.027334898348325993\n","Training loss per 100 training steps: 0.028160162648853303\n","Training loss per 100 training steps: 0.028860786535229496\n","Training loss per 100 training steps: 0.02871673726801879\n","Training loss epoch: 0.028546779828487714\n","Training accuracy epoch: 0.9911622465566808\n","Validating model...\n","Validation Loss: 0.1883712022916063\n","Validation Accuracy: 0.9559426449595029\n","Training epoch: 6\n","Training loss per 100 training steps: 0.022442283108830452\n","Training loss per 100 training steps: 0.015302050821851976\n","Training loss per 100 training steps: 0.0183603684881248\n","Training loss per 100 training steps: 0.018752105023744407\n","Training loss per 100 training steps: 0.020299957734050734\n","Training loss epoch: 0.020977165173671444\n","Training accuracy epoch: 0.9935654997740976\n","Validating model...\n","Validation Loss: 0.1877046659733955\n","Validation Accuracy: 0.9583404893331081\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 54.386747633333286 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14879004224807163\n","Validation Accuracy: 0.9529202867768334\n","Validation duration: 5.860369166666593 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.84      0.83     12546\n","        test       0.83      0.86      0.85      9012\n","   treatment       0.81      0.85      0.83      9297\n","\n","   micro avg       0.82      0.85      0.84     30855\n","   macro avg       0.82      0.85      0.84     30855\n","weighted avg       0.82      0.85      0.84     30855\n","\n","!!!!!! Starting model number 8 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 15600\n","Points in y_train after augmentation: 15600\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1872756481170654\n","Training loss per 100 training steps: 0.4254398278080591\n","Training loss per 100 training steps: 0.31461800039926574\n","Training loss per 100 training steps: 0.2687663191750002\n","Training loss per 100 training steps: 0.24125314324611144\n","Training loss epoch: 0.22411499858726977\n","Training accuracy epoch: 0.9286354875402087\n","Validating model...\n","Validation Loss: 0.14291555139345008\n","Validation Accuracy: 0.9553367559491464\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04989546909928322\n","Training loss per 100 training steps: 0.08547981618212001\n","Training loss per 100 training steps: 0.08711280606093988\n","Training loss per 100 training steps: 0.08501052425747298\n","Training loss per 100 training steps: 0.08729736651862946\n","Training loss epoch: 0.08701441504946741\n","Training accuracy epoch: 0.9718524370921862\n","Validating model...\n","Validation Loss: 0.13789858001393157\n","Validation Accuracy: 0.9573471568804819\n","Training epoch: 3\n","Training loss per 100 training steps: 0.022878380492329597\n","Training loss per 100 training steps: 0.044485113703378355\n","Training loss per 100 training steps: 0.04702967291104779\n","Training loss per 100 training steps: 0.052062030338629633\n","Training loss per 100 training steps: 0.05245106733355327\n","Training loss epoch: 0.05237857199018271\n","Training accuracy epoch: 0.9829540953177025\n","Validating model...\n","Validation Loss: 0.159774026385956\n","Validation Accuracy: 0.9579788194406156\n","Training epoch: 4\n","Training loss per 100 training steps: 0.007317837327718735\n","Training loss per 100 training steps: 0.03402464612995708\n","Training loss per 100 training steps: 0.034541243057123465\n","Training loss per 100 training steps: 0.03451774559877937\n","Training loss per 100 training steps: 0.035319048449155545\n","Training loss epoch: 0.03579234518969553\n","Training accuracy epoch: 0.9887017692653519\n","Validating model...\n","Validation Loss: 0.21347951381043953\n","Validation Accuracy: 0.9507291019155539\n","Training epoch: 5\n","Training loss per 100 training steps: 0.010396929457783699\n","Training loss per 100 training steps: 0.028006288511125316\n","Training loss per 100 training steps: 0.02948455210191323\n","Training loss per 100 training steps: 0.029325218599729017\n","Training loss per 100 training steps: 0.029632454303713363\n","Training loss epoch: 0.02902163177123675\n","Training accuracy epoch: 0.9910020396733933\n","Validating model...\n","Validation Loss: 0.17089083035742597\n","Validation Accuracy: 0.9591855918525094\n","Training epoch: 6\n","Training loss per 100 training steps: 0.004985435400158167\n","Training loss per 100 training steps: 0.017899097677085106\n","Training loss per 100 training steps: 0.01953399188866357\n","Training loss per 100 training steps: 0.021153752582106722\n","Training loss per 100 training steps: 0.021046301954500773\n","Training loss epoch: 0.020529291862643375\n","Training accuracy epoch: 0.9933877312494687\n","Validating model...\n","Validation Loss: 0.20365707648845463\n","Validation Accuracy: 0.9571350487015211\n","Training epoch: 7\n","Training loss per 100 training steps: 0.003240370424464345\n","Training loss per 100 training steps: 0.016349293722651235\n","Training loss per 100 training steps: 0.016731992849862362\n","Training loss per 100 training steps: 0.019265087873696587\n","Training loss per 100 training steps: 0.019227967722088266\n","Training loss epoch: 0.019936257621204694\n","Training accuracy epoch: 0.9938877795314284\n","Validating model...\n","Validation Loss: 0.20909538345604942\n","Validation Accuracy: 0.9578452670593485\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 63.2609209333333 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15342210226312833\n","Validation Accuracy: 0.9545786584606014\n","Validation duration: 5.834860683333196 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.9%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.85      0.84     12546\n","        test       0.81      0.87      0.84      9012\n","   treatment       0.84      0.83      0.83      9297\n","\n","   micro avg       0.83      0.85      0.84     30855\n","   macro avg       0.83      0.85      0.84     30855\n","weighted avg       0.83      0.85      0.84     30855\n","\n","!!!!!! Starting model number 9 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 15600\n","Points in y_train after augmentation: 15600\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.391108989715576\n","Training loss per 100 training steps: 0.4326333900046821\n","Training loss per 100 training steps: 0.3254062600285556\n","Training loss per 100 training steps: 0.27240256638423943\n","Training loss per 100 training steps: 0.243562925221431\n","Training loss epoch: 0.22754310803167277\n","Training accuracy epoch: 0.9282002112919514\n","Validating model...\n","Validation Loss: 0.145574751249575\n","Validation Accuracy: 0.9540901565614989\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06168724223971367\n","Training loss per 100 training steps: 0.08296650607544596\n","Training loss per 100 training steps: 0.08654659961475365\n","Training loss per 100 training steps: 0.08512752725931497\n","Training loss per 100 training steps: 0.08689929221865914\n","Training loss epoch: 0.0878777863184891\n","Training accuracy epoch: 0.9723478281385738\n","Validating model...\n","Validation Loss: 0.1353093134481218\n","Validation Accuracy: 0.959179614322322\n","Training epoch: 3\n","Training loss per 100 training steps: 0.05250508710741997\n","Training loss per 100 training steps: 0.05505830857275736\n","Training loss per 100 training steps: 0.054444213441818656\n","Training loss per 100 training steps: 0.0520309077581991\n","Training loss per 100 training steps: 0.053865559466480466\n","Training loss epoch: 0.054891715234634084\n","Training accuracy epoch: 0.983015957750313\n","Validating model...\n","Validation Loss: 0.13917747611034806\n","Validation Accuracy: 0.9594153653296538\n","Training epoch: 4\n","Training loss per 100 training steps: 0.024533672258257866\n","Training loss per 100 training steps: 0.03192589919562313\n","Training loss per 100 training steps: 0.03562613286712758\n","Training loss per 100 training steps: 0.03711569067663157\n","Training loss per 100 training steps: 0.03808442327342556\n","Training loss epoch: 0.03769537610227059\n","Training accuracy epoch: 0.9881748854259589\n","Validating model...\n","Validation Loss: 0.15613022993330833\n","Validation Accuracy: 0.9606722338632365\n","Training epoch: 5\n","Training loss per 100 training steps: 0.023652657866477966\n","Training loss per 100 training steps: 0.02636737482032121\n","Training loss per 100 training steps: 0.02620995009436147\n","Training loss per 100 training steps: 0.02617500191036166\n","Training loss per 100 training steps: 0.02750591586687674\n","Training loss epoch: 0.027685554356497454\n","Training accuracy epoch: 0.9915088665727768\n","Validating model...\n","Validation Loss: 0.18086653760356175\n","Validation Accuracy: 0.958441932835335\n","Training epoch: 6\n","Training loss per 100 training steps: 0.009706025943160057\n","Training loss per 100 training steps: 0.019489083207433693\n","Training loss per 100 training steps: 0.020986767532072258\n","Training loss per 100 training steps: 0.022546368630593675\n","Training loss per 100 training steps: 0.024738775465481838\n","Training loss epoch: 0.02523268797753577\n","Training accuracy epoch: 0.9921038304723406\n","Validating model...\n","Validation Loss: 0.19515542008660056\n","Validation Accuracy: 0.9565404910379185\n","Training epoch: 7\n","Training loss per 100 training steps: 0.009905046783387661\n","Training loss per 100 training steps: 0.015907386140920923\n","Training loss per 100 training steps: 0.017530341796861932\n","Training loss per 100 training steps: 0.0193071436071985\n","Training loss per 100 training steps: 0.019519887173355573\n","Training loss epoch: 0.02114105608135836\n","Training accuracy epoch: 0.9935654777357399\n","Validating model...\n","Validation Loss: 0.19407423415112418\n","Validation Accuracy: 0.9560114481916321\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 63.40382431666658 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15302345133925513\n","Validation Accuracy: 0.9554326832828337\n","Validation duration: 5.8441845999999105 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.3%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.85      0.83     12546\n","        test       0.85      0.87      0.86      9012\n","   treatment       0.84      0.84      0.84      9297\n","\n","   micro avg       0.84      0.85      0.84     30855\n","   macro avg       0.84      0.85      0.84     30855\n","weighted avg       0.84      0.85      0.84     30855\n","\n","!!!!!! Starting model number 10 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 15600\n","Points in y_train after augmentation: 15600\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.3955514430999756\n","Training loss per 100 training steps: 0.4720284313258558\n","Training loss per 100 training steps: 0.3450486776025141\n","Training loss per 100 training steps: 0.29028805948026554\n","Training loss per 100 training steps: 0.257888525529321\n","Training loss epoch: 0.2385431762983198\n","Training accuracy epoch: 0.9253948886954865\n","Validating model...\n","Validation Loss: 0.13492288962974178\n","Validation Accuracy: 0.9548937042478653\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06557407975196838\n","Training loss per 100 training steps: 0.08755987190115865\n","Training loss per 100 training steps: 0.08343455859399702\n","Training loss per 100 training steps: 0.08858140686409319\n","Training loss per 100 training steps: 0.09129435822432698\n","Training loss epoch: 0.09150495657460672\n","Training accuracy epoch: 0.9706550002744364\n","Validating model...\n","Validation Loss: 0.14628091527076512\n","Validation Accuracy: 0.95640564639462\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0741523802280426\n","Training loss per 100 training steps: 0.05746391000650307\n","Training loss per 100 training steps: 0.05298355892671282\n","Training loss per 100 training steps: 0.053263929347659264\n","Training loss per 100 training steps: 0.05479910609049913\n","Training loss epoch: 0.05481858117139486\n","Training accuracy epoch: 0.9825113752586367\n","Validating model...\n","Validation Loss: 0.1466788873076439\n","Validation Accuracy: 0.9581622991921507\n","Training epoch: 4\n","Training loss per 100 training steps: 0.07173986732959747\n","Training loss per 100 training steps: 0.029430163803505757\n","Training loss per 100 training steps: 0.030576151214477452\n","Training loss per 100 training steps: 0.03385169227840379\n","Training loss per 100 training steps: 0.035120632030456525\n","Training loss epoch: 0.03595321422615031\n","Training accuracy epoch: 0.9886961330519147\n","Validating model...\n","Validation Loss: 0.17619883093692654\n","Validation Accuracy: 0.9567303618627796\n","Training epoch: 5\n","Training loss per 100 training steps: 0.006649537943303585\n","Training loss per 100 training steps: 0.029262239920288913\n","Training loss per 100 training steps: 0.027531980820097474\n","Training loss per 100 training steps: 0.027737445814111132\n","Training loss per 100 training steps: 0.027805700565182008\n","Training loss epoch: 0.029383028314695084\n","Training accuracy epoch: 0.9905270641822408\n","Validating model...\n","Validation Loss: 0.1982734225835506\n","Validation Accuracy: 0.9546609737917617\n","Training epoch: 6\n","Training loss per 100 training steps: 0.010686946101486683\n","Training loss per 100 training steps: 0.02262949744253281\n","Training loss per 100 training steps: 0.02352366438459846\n","Training loss per 100 training steps: 0.02385282490102333\n","Training loss per 100 training steps: 0.022192636934141547\n","Training loss epoch: 0.022606159845695327\n","Training accuracy epoch: 0.9928697478272795\n","Validating model...\n","Validation Loss: 0.19790103828969907\n","Validation Accuracy: 0.9577076124964303\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 54.29894208333329 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14837838808954176\n","Validation Accuracy: 0.9532707627405761\n","Validation duration: 5.8490078666667005 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.1%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.85      0.83     12546\n","        test       0.84      0.87      0.86      9012\n","   treatment       0.85      0.82      0.84      9297\n","\n","   micro avg       0.83      0.85      0.84     30855\n","   macro avg       0.84      0.85      0.84     30855\n","weighted avg       0.83      0.85      0.84     30855\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0.5\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"jdO4m5O4Hlo3"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"oKNxFPucHn_R","outputId":"924ab4f7-cb17-4f6d-ae72-1f5ea74e4fca"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 75.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 18200\n","Points in y_train after augmentation: 18200\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0803842544555664\n","Training loss per 100 training steps: 0.40735184120954854\n","Training loss per 100 training steps: 0.3133521379152341\n","Training loss per 100 training steps: 0.26596689792318995\n","Training loss per 100 training steps: 0.24067850130380242\n","Training loss per 100 training steps: 0.22053516566931844\n","Training loss epoch: 0.21118233196424266\n","Training accuracy epoch: 0.9329254510204361\n","Validating model...\n","Validation Loss: 0.1372640004212206\n","Validation Accuracy: 0.9568106872040469\n","Training epoch: 2\n","Training loss per 100 training steps: 0.12300866842269897\n","Training loss per 100 training steps: 0.08260406446781489\n","Training loss per 100 training steps: 0.0842057351597506\n","Training loss per 100 training steps: 0.08703800163346272\n","Training loss per 100 training steps: 0.08734983446870807\n","Training loss per 100 training steps: 0.08707137375014151\n","Training loss epoch: 0.085770035066817\n","Training accuracy epoch: 0.9722605741238147\n","Validating model...\n","Validation Loss: 0.1489335314261836\n","Validation Accuracy: 0.957988346792688\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03255032002925873\n","Training loss per 100 training steps: 0.05538034818070655\n","Training loss per 100 training steps: 0.05053336607681504\n","Training loss per 100 training steps: 0.05127037521235125\n","Training loss per 100 training steps: 0.05316526019258281\n","Training loss per 100 training steps: 0.05290562904276281\n","Training loss epoch: 0.05232044772624721\n","Training accuracy epoch: 0.9832914817352418\n","Validating model...\n","Validation Loss: 0.16214527903342402\n","Validation Accuracy: 0.9566449586331303\n","Training epoch: 4\n","Training loss per 100 training steps: 0.04539045691490173\n","Training loss per 100 training steps: 0.03618779440299783\n","Training loss per 100 training steps: 0.03620680121922708\n","Training loss per 100 training steps: 0.03437078560789911\n","Training loss per 100 training steps: 0.034928816554869326\n","Training loss per 100 training steps: 0.03557157730639535\n","Training loss epoch: 0.03561908669897841\n","Training accuracy epoch: 0.9884877636227482\n","Validating model...\n","Validation Loss: 0.1743369074175497\n","Validation Accuracy: 0.9578686616144326\n","Training epoch: 5\n","Training loss per 100 training steps: 0.04954944923520088\n","Training loss per 100 training steps: 0.02284781978059892\n","Training loss per 100 training steps: 0.024904438636186927\n","Training loss per 100 training steps: 0.026500801161315254\n","Training loss per 100 training steps: 0.02678310223175747\n","Training loss per 100 training steps: 0.02701932388964758\n","Training loss epoch: 0.027830846319408836\n","Training accuracy epoch: 0.9913032649331122\n","Validating model...\n","Validation Loss: 0.20130015099300191\n","Validation Accuracy: 0.9532398803176576\n","Training epoch: 6\n","Training loss per 100 training steps: 0.03014305792748928\n","Training loss per 100 training steps: 0.019095010102247026\n","Training loss per 100 training steps: 0.01931540486900905\n","Training loss per 100 training steps: 0.01970035679548657\n","Training loss per 100 training steps: 0.02035932070163411\n","Training loss per 100 training steps: 0.02073096959436212\n","Training loss epoch: 0.021830742177635313\n","Training accuracy epoch: 0.9931928272775019\n","Validating model...\n","Validation Loss: 0.19073770187988684\n","Validation Accuracy: 0.9565097833546007\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 62.83526295000023 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1517927662320694\n","Validation Accuracy: 0.9545807985299627\n","Validation duration: 5.831106733333339 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.85      0.84     12546\n","        test       0.84      0.86      0.85      9012\n","   treatment       0.84      0.83      0.83      9297\n","\n","   micro avg       0.83      0.85      0.84     30855\n","   macro avg       0.84      0.85      0.84     30855\n","weighted avg       0.83      0.85      0.84     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 18200\n","Points in y_train after augmentation: 18200\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.211308240890503\n","Training loss per 100 training steps: 0.43898581742945286\n","Training loss per 100 training steps: 0.3233830732529733\n","Training loss per 100 training steps: 0.27314867664660725\n","Training loss per 100 training steps: 0.24600675405279507\n","Training loss per 100 training steps: 0.22536591534500947\n","Training loss epoch: 0.2153637244976625\n","Training accuracy epoch: 0.9310562239746571\n","Validating model...\n","Validation Loss: 0.1359908079801055\n","Validation Accuracy: 0.9564159095876646\n","Training epoch: 2\n","Training loss per 100 training steps: 0.043572429567575455\n","Training loss per 100 training steps: 0.08601421024650335\n","Training loss per 100 training steps: 0.0886076652579269\n","Training loss per 100 training steps: 0.08812642740116662\n","Training loss per 100 training steps: 0.08652524549300385\n","Training loss per 100 training steps: 0.08499207190645044\n","Training loss epoch: 0.08471473443333341\n","Training accuracy epoch: 0.9725243045893196\n","Validating model...\n","Validation Loss: 0.14206246620455346\n","Validation Accuracy: 0.9583325301180529\n","Training epoch: 3\n","Training loss per 100 training steps: 0.018779747188091278\n","Training loss per 100 training steps: 0.04131912827805275\n","Training loss per 100 training steps: 0.0483827379518258\n","Training loss per 100 training steps: 0.049024451021228814\n","Training loss per 100 training steps: 0.0501330709653881\n","Training loss per 100 training steps: 0.05007484054356486\n","Training loss epoch: 0.04960590905488611\n","Training accuracy epoch: 0.9842766467612359\n","Validating model...\n","Validation Loss: 0.1508283145096782\n","Validation Accuracy: 0.9594187604482306\n","Training epoch: 4\n","Training loss per 100 training steps: 0.023440072312951088\n","Training loss per 100 training steps: 0.02838091894472479\n","Training loss per 100 training steps: 0.031183998138106322\n","Training loss per 100 training steps: 0.03222038647031529\n","Training loss per 100 training steps: 0.03302942308512495\n","Training loss per 100 training steps: 0.03278626999822436\n","Training loss epoch: 0.03265442196234753\n","Training accuracy epoch: 0.9897840201269646\n","Validating model...\n","Validation Loss: 0.17811308356074543\n","Validation Accuracy: 0.9585793464125448\n","Training epoch: 5\n","Training loss per 100 training steps: 0.007822500541806221\n","Training loss per 100 training steps: 0.020588344225825946\n","Training loss per 100 training steps: 0.021221308430902364\n","Training loss per 100 training steps: 0.024562735487227375\n","Training loss per 100 training steps: 0.026440616195412943\n","Training loss per 100 training steps: 0.029014399158303623\n","Training loss epoch: 0.029821058907521552\n","Training accuracy epoch: 0.9905924693362301\n","Validating model...\n","Validation Loss: 0.18912571241667905\n","Validation Accuracy: 0.9575453430088985\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0020303844939917326\n","Training loss per 100 training steps: 0.02284868362954458\n","Training loss per 100 training steps: 0.022560295008878174\n","Training loss per 100 training steps: 0.021407216157689937\n","Training loss per 100 training steps: 0.02090800234230997\n","Training loss per 100 training steps: 0.021484548802498706\n","Training loss epoch: 0.020880183999046932\n","Training accuracy epoch: 0.9935256333056242\n","Validating model...\n","Validation Loss: 0.2012762835297685\n","Validation Accuracy: 0.9579081168965897\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 62.85520138333329 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14650368781682724\n","Validation Accuracy: 0.9536942573243105\n","Validation duration: 5.83325308333345 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.3%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.85      0.83     12546\n","        test       0.81      0.86      0.83      9012\n","   treatment       0.84      0.85      0.84      9297\n","\n","   micro avg       0.81      0.85      0.83     30855\n","   macro avg       0.82      0.85      0.83     30855\n","weighted avg       0.81      0.85      0.83     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 18200\n","Points in y_train after augmentation: 18200\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.935884952545166\n","Training loss per 100 training steps: 0.4008642967679713\n","Training loss per 100 training steps: 0.3077275010187234\n","Training loss per 100 training steps: 0.26253562083969084\n","Training loss per 100 training steps: 0.23699119839436394\n","Training loss per 100 training steps: 0.21661305016356552\n","Training loss epoch: 0.2068837791393218\n","Training accuracy epoch: 0.9343187863907935\n","Validating model...\n","Validation Loss: 0.1298917480925848\n","Validation Accuracy: 0.9599236176933958\n","Training epoch: 2\n","Training loss per 100 training steps: 0.043658021837472916\n","Training loss per 100 training steps: 0.08524916960977681\n","Training loss per 100 training steps: 0.08542360981639048\n","Training loss per 100 training steps: 0.0870342559902078\n","Training loss per 100 training steps: 0.08436987342596278\n","Training loss per 100 training steps: 0.08531600347498874\n","Training loss epoch: 0.08317553238396538\n","Training accuracy epoch: 0.9734375714814067\n","Validating model...\n","Validation Loss: 0.15210304365723165\n","Validation Accuracy: 0.9555170961446481\n","Training epoch: 3\n","Training loss per 100 training steps: 0.034598350524902344\n","Training loss per 100 training steps: 0.04468195979935256\n","Training loss per 100 training steps: 0.045266189811686376\n","Training loss per 100 training steps: 0.04491201135487701\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0.75\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"oKNxFPucHn_R"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["6981b764289b43f6acb468c4f4c3dea3","917716071c224608b0a0d7b8736ddd27","1d287171f668406a95dde65b6bd3786d","012c4068d2fb4d13a80c319c8eca7abf","5e2b12ed936e4ab58995bf8fee0a6874","bb57f5d36b0a4432896a315ef62b623d","940a9dfaa6e44252a8cad1c5bb50bd02","f54a40f09f284b3eac191eb91fed516c","52693de900eb4455a53d547dede3bf7f","144f517c165f4b598a170bc7ff072a6b","af4d72de98be4b569445fce8520a8b9f"]},"executionInfo":{"elapsed":37600332,"status":"ok","timestamp":1667748635372,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"VSbPfhy9UBxD","outputId":"8abdb03e-6788-4b82-9cbe-116a06ac3579"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 75.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6981b764289b43f6acb468c4f4c3dea3","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 18200\n","Points in y_train after augmentation: 18200\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0288989543914795\n","Training loss per 100 training steps: 0.41459682701837897\n","Training loss per 100 training steps: 0.31379418063964415\n","Training loss per 100 training steps: 0.2655372920374934\n","Training loss per 100 training steps: 0.23689858357136387\n","Training loss per 100 training steps: 0.21806870354060642\n","Training loss epoch: 0.2082033528240892\n","Training accuracy epoch: 0.9338117478567968\n","Validating model...\n","Validation Loss: 0.14255203234104366\n","Validation Accuracy: 0.9533053118053322\n","Training epoch: 2\n","Training loss per 100 training steps: 0.10732899606227875\n","Training loss per 100 training steps: 0.0867826996998179\n","Training loss per 100 training steps: 0.08105338838841043\n","Training loss per 100 training steps: 0.08177939621094256\n","Training loss per 100 training steps: 0.08341757929941959\n","Training loss per 100 training steps: 0.08184419308943365\n","Training loss epoch: 0.0825293908396536\n","Training accuracy epoch: 0.9733520554792111\n","Validating model...\n","Validation Loss: 0.14484373204313317\n","Validation Accuracy: 0.9543490436548077\n","Training epoch: 3\n","Training loss per 100 training steps: 0.05319169908761978\n","Training loss per 100 training steps: 0.05079168835101594\n","Training loss per 100 training steps: 0.04604073620832233\n","Training loss per 100 training steps: 0.047976031453902536\n","Training loss per 100 training steps: 0.04908428980534585\n","Training loss per 100 training steps: 0.05080967984290537\n","Training loss epoch: 0.050089297560821096\n","Training accuracy epoch: 0.9842911580926946\n","Validating model...\n","Validation Loss: 0.14810403327566463\n","Validation Accuracy: 0.9585865957213002\n","Training epoch: 4\n","Training loss per 100 training steps: 0.034294527024030685\n","Training loss per 100 training steps: 0.036186453240859034\n","Training loss per 100 training steps: 0.03787896399553031\n","Training loss per 100 training steps: 0.03828432898043324\n","Training loss per 100 training steps: 0.03929807934468784\n","Training loss per 100 training steps: 0.03992882758535132\n","Training loss epoch: 0.03964138692097578\n","Training accuracy epoch: 0.9874144901167571\n","Validating model...\n","Validation Loss: 0.17555526629477353\n","Validation Accuracy: 0.95570471391783\n","Training epoch: 5\n","Training loss per 100 training steps: 0.04877646267414093\n","Training loss per 100 training steps: 0.01843824989213101\n","Training loss per 100 training steps: 0.02011468190356941\n","Training loss per 100 training steps: 0.022131389542250735\n","Training loss per 100 training steps: 0.022191601525527654\n","Training loss per 100 training steps: 0.023569680502900328\n","Training loss epoch: 0.02426903892201265\n","Training accuracy epoch: 0.9922983843336042\n","Validating model...\n","Validation Loss: 0.18340513932627517\n","Validation Accuracy: 0.9567145580770222\n","Training epoch: 6\n","Training loss per 100 training steps: 0.052187662571668625\n","Training loss per 100 training steps: 0.02443054197056422\n","Training loss per 100 training steps: 0.027286080488893413\n","Training loss per 100 training steps: 0.025598680208444108\n","Training loss per 100 training steps: 0.026421983919017587\n","Training loss per 100 training steps: 0.025459856755913935\n","Training loss epoch: 0.025010601988482505\n","Training accuracy epoch: 0.9922908843656552\n","Validating model...\n","Validation Loss: 0.19996743923198287\n","Validation Accuracy: 0.9580769868295717\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 66.13686671666667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1563348774776656\n","Validation Accuracy: 0.9520297972900441\n","Validation duration: 6.2684093 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.85      0.84     12546\n","        test       0.83      0.83      0.83      9012\n","   treatment       0.83      0.82      0.82      9297\n","\n","   micro avg       0.83      0.83      0.83     30855\n","   macro avg       0.83      0.83      0.83     30855\n","weighted avg       0.83      0.83      0.83     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 18200\n","Points in y_train after augmentation: 18200\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.202709197998047\n","Training loss per 100 training steps: 0.4038707719433426\n","Training loss per 100 training steps: 0.2930937571015524\n","Training loss per 100 training steps: 0.250999659807282\n","Training loss per 100 training steps: 0.2281044227839854\n","Training loss per 100 training steps: 0.2116218510859027\n","Training loss epoch: 0.20261262787378317\n","Training accuracy epoch: 0.9352924141402906\n","Validating model...\n","Validation Loss: 0.14347779129135918\n","Validation Accuracy: 0.9549898587011983\n","Training epoch: 2\n","Training loss per 100 training steps: 0.10149563103914261\n","Training loss per 100 training steps: 0.07411294202735223\n","Training loss per 100 training steps: 0.07899478125612978\n","Training loss per 100 training steps: 0.08073796723904304\n","Training loss per 100 training steps: 0.08204924455493168\n","Training loss per 100 training steps: 0.0833528533934833\n","Training loss epoch: 0.08364090725111731\n","Training accuracy epoch: 0.9738715618939819\n","Validating model...\n","Validation Loss: 0.1541688277253083\n","Validation Accuracy: 0.9537797204920239\n","Training epoch: 3\n","Training loss per 100 training steps: 0.1306297779083252\n","Training loss per 100 training steps: 0.0473015698751822\n","Training loss per 100 training steps: 0.048783148530018125\n","Training loss per 100 training steps: 0.05060325902221458\n","Training loss per 100 training steps: 0.050428932508281864\n","Training loss per 100 training steps: 0.0504822011622498\n","Training loss epoch: 0.05070599338190339\n","Training accuracy epoch: 0.9839065585678767\n","Validating model...\n","Validation Loss: 0.17968537108730767\n","Validation Accuracy: 0.9541065827624089\n","Training epoch: 4\n","Training loss per 100 training steps: 0.05725140497088432\n","Training loss per 100 training steps: 0.035583952220507184\n","Training loss per 100 training steps: 0.03193299669948457\n","Training loss per 100 training steps: 0.031254081963638825\n","Training loss per 100 training steps: 0.03388682203982815\n","Training loss per 100 training steps: 0.035453931217968554\n","Training loss epoch: 0.0355830408067251\n","Training accuracy epoch: 0.9889680216402646\n","Validating model...\n","Validation Loss: 0.17560498781695769\n","Validation Accuracy: 0.9562451637272986\n","Training epoch: 5\n","Training loss per 100 training steps: 0.017743228003382683\n","Training loss per 100 training steps: 0.023345789447943174\n","Training loss per 100 training steps: 0.02371012811104197\n","Training loss per 100 training steps: 0.02265966111760079\n","Training loss per 100 training steps: 0.025767645932457634\n","Training loss per 100 training steps: 0.025592957880996733\n","Training loss epoch: 0.02524779577789049\n","Training accuracy epoch: 0.9922588695078033\n","Validating model...\n","Validation Loss: 0.2036340937211916\n","Validation Accuracy: 0.955527149550041\n","Training epoch: 6\n","Training loss per 100 training steps: 0.05866503715515137\n","Training loss per 100 training steps: 0.01502598125987806\n","Training loss per 100 training steps: 0.016081005956315023\n","Training loss per 100 training steps: 0.016374920806584516\n","Training loss per 100 training steps: 0.016767318005745584\n","Training loss per 100 training steps: 0.01741578562955229\n","Training loss epoch: 0.019431197774487666\n","Training accuracy epoch: 0.9941029199833153\n","Validating model...\n","Validation Loss: 0.18329640129556904\n","Validation Accuracy: 0.9552087727483406\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 66.2063999 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15518207839879863\n","Validation Accuracy: 0.9530395459270627\n","Validation duration: 6.246643049999997 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.83      0.83     12546\n","        test       0.83      0.86      0.85      9012\n","   treatment       0.82      0.84      0.83      9297\n","\n","   micro avg       0.82      0.84      0.83     30855\n","   macro avg       0.82      0.85      0.83     30855\n","weighted avg       0.82      0.84      0.83     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 18200\n","Points in y_train after augmentation: 18200\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.138659954071045\n","Training loss per 100 training steps: 0.4296981490189486\n","Training loss per 100 training steps: 0.3181067869734408\n","Training loss per 100 training steps: 0.27191461867767314\n","Training loss per 100 training steps: 0.24196675897313472\n","Training loss per 100 training steps: 0.2208462179212751\n","Training loss epoch: 0.21058357584246012\n","Training accuracy epoch: 0.9332315299215269\n","Validating model...\n","Validation Loss: 0.13713605068140217\n","Validation Accuracy: 0.9563013038187714\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06440737098455429\n","Training loss per 100 training steps: 0.08209100463381498\n","Training loss per 100 training steps: 0.08521705232004621\n","Training loss per 100 training steps: 0.0825491370385717\n","Training loss per 100 training steps: 0.0829770915893062\n","Training loss per 100 training steps: 0.08128083924653227\n","Training loss epoch: 0.08246430281962158\n","Training accuracy epoch: 0.9739944372910551\n","Validating model...\n","Validation Loss: 0.14601509380093836\n","Validation Accuracy: 0.955573065694584\n","Training epoch: 3\n","Training loss per 100 training steps: 0.01805419661104679\n","Training loss per 100 training steps: 0.042631623007836614\n","Training loss per 100 training steps: 0.04346507392703226\n","Training loss per 100 training steps: 0.04560415754620716\n","Training loss per 100 training steps: 0.04597278068566746\n","Training loss per 100 training steps: 0.046233641694740445\n","Training loss epoch: 0.04643406439081541\n","Training accuracy epoch: 0.9854087976328991\n","Validating model...\n","Validation Loss: 0.18144599520057053\n","Validation Accuracy: 0.9544364416902226\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03954433649778366\n","Training loss per 100 training steps: 0.027018109584310192\n","Training loss per 100 training steps: 0.029232965394812845\n","Training loss per 100 training steps: 0.03113016768465394\n","Training loss per 100 training steps: 0.03210947065506168\n","Training loss per 100 training steps: 0.034016315135389136\n","Training loss epoch: 0.03490629062520566\n","Training accuracy epoch: 0.9894865433577771\n","Validating model...\n","Validation Loss: 0.17982277426530013\n","Validation Accuracy: 0.9561089960965586\n","Training epoch: 5\n","Training loss per 100 training steps: 0.011472531594336033\n","Training loss per 100 training steps: 0.02423668112940072\n","Training loss per 100 training steps: 0.02435652340967347\n","Training loss per 100 training steps: 0.024480269448885823\n","Training loss per 100 training steps: 0.02599182914584838\n","Training loss per 100 training steps: 0.026553510586933757\n","Training loss epoch: 0.02697651342755619\n","Training accuracy epoch: 0.9918866970237317\n","Validating model...\n","Validation Loss: 0.17593240165816887\n","Validation Accuracy: 0.9571498712645414\n","Training epoch: 6\n","Training loss per 100 training steps: 0.05944602191448212\n","Training loss per 100 training steps: 0.022083442533702247\n","Training loss per 100 training steps: 0.021417151899100165\n","Training loss per 100 training steps: 0.021421185110431114\n","Training loss per 100 training steps: 0.022318762578877233\n","Training loss per 100 training steps: 0.02411865072309536\n","Training loss epoch: 0.02482053032707544\n","Training accuracy epoch: 0.9925429150618301\n","Validating model...\n","Validation Loss: 0.1800783144479448\n","Validation Accuracy: 0.95888988294115\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 66.23934746666667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15872831557040895\n","Validation Accuracy: 0.9501154803630167\n","Validation duration: 6.2197122333333335 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.81      0.82     12546\n","        test       0.85      0.84      0.85      9012\n","   treatment       0.76      0.85      0.81      9297\n","\n","   micro avg       0.81      0.83      0.82     30855\n","   macro avg       0.81      0.84      0.82     30855\n","weighted avg       0.81      0.83      0.82     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 18200\n","Points in y_train after augmentation: 18200\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.031343936920166\n","Training loss per 100 training steps: 0.4247271417833791\n","Training loss per 100 training steps: 0.3169607477105079\n","Training loss per 100 training steps: 0.26710493777231914\n","Training loss per 100 training steps: 0.23825728743711017\n","Training loss per 100 training steps: 0.21944019428181077\n","Training loss epoch: 0.20909702961180876\n","Training accuracy epoch: 0.9330504588296112\n","Validating model...\n","Validation Loss: 0.14579327264195913\n","Validation Accuracy: 0.9552516564152558\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04191756621003151\n","Training loss per 100 training steps: 0.08250002422840289\n","Training loss per 100 training steps: 0.08353036759764104\n","Training loss per 100 training steps: 0.08416260509098883\n","Training loss per 100 training steps: 0.08396794776573889\n","Training loss per 100 training steps: 0.08346300675792102\n","Training loss epoch: 0.08474365990569648\n","Training accuracy epoch: 0.9730180915523449\n","Validating model...\n","Validation Loss: 0.1580475273650962\n","Validation Accuracy: 0.9535758925748071\n","Training epoch: 3\n","Training loss per 100 training steps: 0.029383460059762\n","Training loss per 100 training steps: 0.04434675221229986\n","Training loss per 100 training steps: 0.04554221819882369\n","Training loss per 100 training steps: 0.04792108142785604\n","Training loss per 100 training steps: 0.04656306429048466\n","Training loss per 100 training steps: 0.04859871859058083\n","Training loss epoch: 0.048291188192525994\n","Training accuracy epoch: 0.9848182378207609\n","Validating model...\n","Validation Loss: 0.15919673878264118\n","Validation Accuracy: 0.9592662626141573\n","Training epoch: 4\n","Training loss per 100 training steps: 0.030252745375037193\n","Training loss per 100 training steps: 0.02986398283484401\n","Training loss per 100 training steps: 0.031254505635521825\n","Training loss per 100 training steps: 0.03179830941758382\n","Training loss per 100 training steps: 0.03223777074306423\n","Training loss per 100 training steps: 0.03316502784473632\n","Training loss epoch: 0.03420146167612191\n","Training accuracy epoch: 0.9895342417461647\n","Validating model...\n","Validation Loss: 0.17626032579158032\n","Validation Accuracy: 0.9552054699847797\n","Training epoch: 5\n","Training loss per 100 training steps: 0.012924004346132278\n","Training loss per 100 training steps: 0.02938011875791051\n","Training loss per 100 training steps: 0.028871051690295635\n","Training loss per 100 training steps: 0.02658452830111849\n","Training loss per 100 training steps: 0.02793893158613493\n","Training loss per 100 training steps: 0.027103325456172646\n","Training loss epoch: 0.027199301199033292\n","Training accuracy epoch: 0.9916919640289612\n","Validating model...\n","Validation Loss: 0.18151621143756944\n","Validation Accuracy: 0.9583822284373479\n","Training epoch: 6\n","Training loss per 100 training steps: 0.008611577562987804\n","Training loss per 100 training steps: 0.018185490732528453\n","Training loss per 100 training steps: 0.01911205028917001\n","Training loss per 100 training steps: 0.01959562573896758\n","Training loss per 100 training steps: 0.019931291248893222\n","Training loss per 100 training steps: 0.021018732342396877\n","Training loss epoch: 0.021714044258739924\n","Training accuracy epoch: 0.9935284018144043\n","Validating model...\n","Validation Loss: 0.19745463965001045\n","Validation Accuracy: 0.9545128437615005\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 66.22517106666668 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15389976183090498\n","Validation Accuracy: 0.9548776211795461\n","Validation duration: 6.252144850000028 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.86      0.83     12546\n","        test       0.84      0.85      0.84      9012\n","   treatment       0.84      0.83      0.84      9297\n","\n","   micro avg       0.83      0.85      0.84     30855\n","   macro avg       0.83      0.85      0.84     30855\n","weighted avg       0.83      0.85      0.84     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 18200\n","Points in y_train after augmentation: 18200\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.17392897605896\n","Training loss per 100 training steps: 0.4206849820543044\n","Training loss per 100 training steps: 0.31142913503804015\n","Training loss per 100 training steps: 0.26478146745566516\n","Training loss per 100 training steps: 0.23680502349078805\n","Training loss per 100 training steps: 0.21956726511616906\n","Training loss epoch: 0.20948144947039538\n","Training accuracy epoch: 0.9337105965620303\n","Validating model...\n","Validation Loss: 0.14577827215581746\n","Validation Accuracy: 0.9538976874561047\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07702302187681198\n","Training loss per 100 training steps: 0.08531664378277146\n","Training loss per 100 training steps: 0.08612635962442676\n","Training loss per 100 training steps: 0.08592806259894192\n","Training loss per 100 training steps: 0.08628279141886648\n","Training loss per 100 training steps: 0.08382589342871945\n","Training loss epoch: 0.08347039402303776\n","Training accuracy epoch: 0.9731343169103776\n","Validating model...\n","Validation Loss: 0.14672043078953956\n","Validation Accuracy: 0.9575141096746715\n","Training epoch: 3\n","Training loss per 100 training steps: 0.020508766174316406\n","Training loss per 100 training steps: 0.05008046297670001\n","Training loss per 100 training steps: 0.04637868814077692\n","Training loss per 100 training steps: 0.0485306593567826\n","Training loss per 100 training steps: 0.04938437359551539\n","Training loss per 100 training steps: 0.05101734092143065\n","Training loss epoch: 0.05189349326208522\n","Training accuracy epoch: 0.9838349774828468\n","Validating model...\n","Validation Loss: 0.15626371043504445\n","Validation Accuracy: 0.9577538356689757\n","Training epoch: 4\n","Training loss per 100 training steps: 0.030833033844828606\n","Training loss per 100 training steps: 0.035074963332338276\n","Training loss per 100 training steps: 0.03615770163883302\n","Training loss per 100 training steps: 0.037751571366182866\n","Training loss per 100 training steps: 0.03789536273565627\n","Training loss per 100 training steps: 0.038213131074447876\n","Training loss epoch: 0.03982576366652275\n","Training accuracy epoch: 0.9876796923543205\n","Validating model...\n","Validation Loss: 0.1611323831965784\n","Validation Accuracy: 0.958306990320855\n","Training epoch: 5\n","Training loss per 100 training steps: 0.04165652021765709\n","Training loss per 100 training steps: 0.02221277844170016\n","Training loss per 100 training steps: 0.022323662028833298\n","Training loss per 100 training steps: 0.02300524370987711\n","Training loss per 100 training steps: 0.023728559254389953\n","Training loss per 100 training steps: 0.02442299053928036\n","Training loss epoch: 0.024921160791992407\n","Training accuracy epoch: 0.9922379652173542\n","Validating model...\n","Validation Loss: 0.1972653553881622\n","Validation Accuracy: 0.9565803082541846\n","Training epoch: 6\n","Training loss per 100 training steps: 0.021527599543333054\n","Training loss per 100 training steps: 0.02079632767075027\n","Training loss per 100 training steps: 0.020042958391936896\n","Training loss per 100 training steps: 0.022613493392848877\n","Training loss per 100 training steps: 0.02257407210872362\n","Training loss per 100 training steps: 0.02356297593434135\n","Training loss epoch: 0.023885042930896737\n","Training accuracy epoch: 0.9930568315030197\n","Validating model...\n","Validation Loss: 0.21025677689339045\n","Validation Accuracy: 0.9511568375258103\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 66.21083155000002 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1507923898774337\n","Validation Accuracy: 0.9522930296492026\n","Validation duration: 6.235849166666655 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.87      0.83     12546\n","        test       0.85      0.86      0.85      9012\n","   treatment       0.83      0.83      0.83      9297\n","\n","   micro avg       0.82      0.85      0.84     30855\n","   macro avg       0.82      0.85      0.84     30855\n","weighted avg       0.82      0.85      0.84     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 18200\n","Points in y_train after augmentation: 18200\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.2329015731811523\n","Training loss per 100 training steps: 0.4331364828613725\n","Training loss per 100 training steps: 0.32558604874717656\n","Training loss per 100 training steps: 0.2763084731624768\n","Training loss per 100 training steps: 0.2460388906690248\n","Training loss per 100 training steps: 0.22472229467597074\n","Training loss epoch: 0.21425381753927583\n","Training accuracy epoch: 0.9322237454389432\n","Validating model...\n","Validation Loss: 0.1485692702185411\n","Validation Accuracy: 0.9515588290292145\n","Training epoch: 2\n","Training loss per 100 training steps: 0.27372491359710693\n","Training loss per 100 training steps: 0.08799454748704291\n","Training loss per 100 training steps: 0.09178219010024818\n","Training loss per 100 training steps: 0.0905106382543512\n","Training loss per 100 training steps: 0.08942449439614268\n","Training loss per 100 training steps: 0.08905481551764552\n","Training loss epoch: 0.08755580043037191\n","Training accuracy epoch: 0.9722091695388947\n","Validating model...\n","Validation Loss: 0.15560383018251364\n","Validation Accuracy: 0.9529616091910483\n","Training epoch: 3\n","Training loss per 100 training steps: 0.016107406467199326\n","Training loss per 100 training steps: 0.04942522452461837\n","Training loss per 100 training steps: 0.04823375464560677\n","Training loss per 100 training steps: 0.05161709059339227\n","Training loss per 100 training steps: 0.05171840910119309\n","Training loss per 100 training steps: 0.05197550224125415\n","Training loss epoch: 0.052059479396600404\n","Training accuracy epoch: 0.9828953399081214\n","Validating model...\n","Validation Loss: 0.1643560174550232\n","Validation Accuracy: 0.9569025972792182\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01875637099146843\n","Training loss per 100 training steps: 0.03149422026806428\n","Training loss per 100 training steps: 0.03098521437160022\n","Training loss per 100 training steps: 0.030193609979152183\n","Training loss per 100 training steps: 0.03151726996307807\n","Training loss per 100 training steps: 0.03263855585340455\n","Training loss epoch: 0.03214682348261576\n","Training accuracy epoch: 0.9901459464267404\n","Validating model...\n","Validation Loss: 0.18227117602689216\n","Validation Accuracy: 0.9574448604490133\n","Training epoch: 5\n","Training loss per 100 training steps: 0.010707534849643707\n","Training loss per 100 training steps: 0.021075815273596362\n","Training loss per 100 training steps: 0.023933483840230464\n","Training loss per 100 training steps: 0.02280483297861345\n","Training loss per 100 training steps: 0.024096869930922242\n","Training loss per 100 training steps: 0.025799717591004724\n","Training loss epoch: 0.025854747061927023\n","Training accuracy epoch: 0.9916445496694093\n","Validating model...\n","Validation Loss: 0.19698933325707912\n","Validation Accuracy: 0.9571441674349798\n","Training epoch: 6\n","Training loss per 100 training steps: 0.01033953856676817\n","Training loss per 100 training steps: 0.015900916786458674\n","Training loss per 100 training steps: 0.020463714470788003\n","Training loss per 100 training steps: 0.02159610671413586\n","Training loss per 100 training steps: 0.022658096336088424\n","Training loss per 100 training steps: 0.02415745710524658\n","Training loss epoch: 0.024788847520066874\n","Training accuracy epoch: 0.9923708193068648\n","Validating model...\n","Validation Loss: 0.18831663423931444\n","Validation Accuracy: 0.9563980081467759\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 66.22517916666669 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15493384366143598\n","Validation Accuracy: 0.9514850877737255\n","Validation duration: 6.226840566666639 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.76      0.88      0.82     12546\n","        test       0.87      0.86      0.87      9012\n","   treatment       0.80      0.83      0.82      9297\n","\n","   micro avg       0.80      0.86      0.83     30855\n","   macro avg       0.81      0.86      0.83     30855\n","weighted avg       0.80      0.86      0.83     30855\n","\n","!!!!!! Starting model number 7 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 18200\n","Points in y_train after augmentation: 18200\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9473460912704468\n","Training loss per 100 training steps: 0.39038565046716445\n","Training loss per 100 training steps: 0.2914405125031127\n","Training loss per 100 training steps: 0.2564463636828617\n","Training loss per 100 training steps: 0.229469695386298\n","Training loss per 100 training steps: 0.20937074831651595\n","Training loss epoch: 0.20092107479334506\n","Training accuracy epoch: 0.9358020081622314\n","Validating model...\n","Validation Loss: 0.13984699668241785\n","Validation Accuracy: 0.9539630880832924\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04483925178647041\n","Training loss per 100 training steps: 0.07683618320613214\n","Training loss per 100 training steps: 0.08131269253883047\n","Training loss per 100 training steps: 0.08265194057972725\n","Training loss per 100 training steps: 0.08130993687564\n","Training loss per 100 training steps: 0.08036252800858544\n","Training loss epoch: 0.08032857848950031\n","Training accuracy epoch: 0.9747700167736946\n","Validating model...\n","Validation Loss: 0.1586522049718089\n","Validation Accuracy: 0.9537028190213007\n","Training epoch: 3\n","Training loss per 100 training steps: 0.08455359935760498\n","Training loss per 100 training steps: 0.04529982239542769\n","Training loss per 100 training steps: 0.04474976112306192\n","Training loss per 100 training steps: 0.04381673201258013\n","Training loss per 100 training steps: 0.043984875198223736\n","Training loss per 100 training steps: 0.045696755744072566\n","Training loss epoch: 0.046408982792998515\n","Training accuracy epoch: 0.9856482696676879\n","Validating model...\n","Validation Loss: 0.16313303070892762\n","Validation Accuracy: 0.9567632489038252\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0183784831315279\n","Training loss per 100 training steps: 0.026049150691118718\n","Training loss per 100 training steps: 0.0286245252381065\n","Training loss per 100 training steps: 0.028302703919879275\n","Training loss per 100 training steps: 0.02907901761665513\n","Training loss per 100 training steps: 0.029413061351478174\n","Training loss epoch: 0.030161467157607088\n","Training accuracy epoch: 0.9907757766045991\n","Validating model...\n","Validation Loss: 0.21951367957638457\n","Validation Accuracy: 0.9474589336631877\n","Training epoch: 5\n","Training loss per 100 training steps: 0.037260375916957855\n","Training loss per 100 training steps: 0.021293614700547244\n","Training loss per 100 training steps: 0.02327575150237822\n","Training loss per 100 training steps: 0.025030298884865205\n","Training loss per 100 training steps: 0.02577866559808707\n","Training loss per 100 training steps: 0.027321843166199854\n","Training loss epoch: 0.027342850423208477\n","Training accuracy epoch: 0.9912849424194162\n","Validating model...\n","Validation Loss: 0.20072799630753405\n","Validation Accuracy: 0.9519164552649929\n","Training epoch: 6\n","Training loss per 100 training steps: 0.021227285265922546\n","Training loss per 100 training steps: 0.017840888790929193\n","Training loss per 100 training steps: 0.019515116560326156\n","Training loss per 100 training steps: 0.020045334904878538\n","Training loss per 100 training steps: 0.019759288120682717\n","Training loss per 100 training steps: 0.0203227400303374\n","Training loss epoch: 0.0207646542786488\n","Training accuracy epoch: 0.9935204081913638\n","Validating model...\n","Validation Loss: 0.19631066357160543\n","Validation Accuracy: 0.9561649122860318\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 66.21417653333326 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1509828526910429\n","Validation Accuracy: 0.9525478921554869\n","Validation duration: 6.245221016666619 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.86      0.83     12546\n","        test       0.82      0.89      0.85      9012\n","   treatment       0.81      0.85      0.83      9297\n","\n","   micro avg       0.81      0.87      0.84     30855\n","   macro avg       0.81      0.87      0.84     30855\n","weighted avg       0.81      0.87      0.84     30855\n","\n","!!!!!! Starting model number 8 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 18200\n","Points in y_train after augmentation: 18200\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.2371044158935547\n","Training loss per 100 training steps: 0.42260233482511916\n","Training loss per 100 training steps: 0.31179594637742686\n","Training loss per 100 training steps: 0.2681754031079354\n","Training loss per 100 training steps: 0.23973137196014052\n","Training loss per 100 training steps: 0.21983013937097348\n","Training loss epoch: 0.2096814205820929\n","Training accuracy epoch: 0.9342998471430993\n","Validating model...\n","Validation Loss: 0.14535796780187588\n","Validation Accuracy: 0.9544147489889199\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07348215579986572\n","Training loss per 100 training steps: 0.08890040061150742\n","Training loss per 100 training steps: 0.0875006606153662\n","Training loss per 100 training steps: 0.08562455752066203\n","Training loss per 100 training steps: 0.08653844716933154\n","Training loss per 100 training steps: 0.08431720417253152\n","Training loss epoch: 0.08479368880142332\n","Training accuracy epoch: 0.9727093508051678\n","Validating model...\n","Validation Loss: 0.1446358934407691\n","Validation Accuracy: 0.9589268657612282\n","Training epoch: 3\n","Training loss per 100 training steps: 0.049795981496572495\n","Training loss per 100 training steps: 0.045692004544642006\n","Training loss per 100 training steps: 0.04881789691894505\n","Training loss per 100 training steps: 0.051545497571486375\n","Training loss per 100 training steps: 0.052202446685820594\n","Training loss per 100 training steps: 0.05165740467251061\n","Training loss epoch: 0.050601898887324\n","Training accuracy epoch: 0.9839481886170286\n","Validating model...\n","Validation Loss: 0.1573043745615846\n","Validation Accuracy: 0.9561727167514432\n","Training epoch: 4\n","Training loss per 100 training steps: 0.04213520139455795\n","Training loss per 100 training steps: 0.030345494556932313\n","Training loss per 100 training steps: 0.03266561285775637\n","Training loss per 100 training steps: 0.033934779771900674\n","Training loss per 100 training steps: 0.034524746293473775\n","Training loss per 100 training steps: 0.033718213999221945\n","Training loss epoch: 0.033450687957824465\n","Training accuracy epoch: 0.9891594598547759\n","Validating model...\n","Validation Loss: 0.17912852285163744\n","Validation Accuracy: 0.955951080208559\n","Training epoch: 5\n","Training loss per 100 training steps: 0.013506065122783184\n","Training loss per 100 training steps: 0.021381274128498714\n","Training loss per 100 training steps: 0.02257382479005155\n","Training loss per 100 training steps: 0.022839343196177156\n","Training loss per 100 training steps: 0.023031803125229913\n","Training loss per 100 training steps: 0.023498306901472064\n","Training loss epoch: 0.023462297113858627\n","Training accuracy epoch: 0.992600407553912\n","Validating model...\n","Validation Loss: 0.19372309787900416\n","Validation Accuracy: 0.9588156753514153\n","Training epoch: 6\n","Training loss per 100 training steps: 0.03004862181842327\n","Training loss per 100 training steps: 0.01964129770859283\n","Training loss per 100 training steps: 0.018841741224623457\n","Training loss per 100 training steps: 0.02002555527356902\n","Training loss per 100 training steps: 0.021247497635941134\n","Training loss per 100 training steps: 0.021999085883186116\n","Training loss epoch: 0.022356884686197752\n","Training accuracy epoch: 0.993124583422084\n","Validating model...\n","Validation Loss: 0.20779826535613505\n","Validation Accuracy: 0.9534938597852388\n","Training epoch: 7\n","Training loss per 100 training steps: 0.08351822942495346\n","Training loss per 100 training steps: 0.01694291242799436\n","Training loss per 100 training steps: 0.016618041078379348\n","Training loss per 100 training steps: 0.016791546969648227\n","Training loss per 100 training steps: 0.016835872314918548\n","Training loss per 100 training steps: 0.01679643062183851\n","Training loss epoch: 0.017104139874322234\n","Training accuracy epoch: 0.9946675900754974\n","Validating model...\n","Validation Loss: 0.23299179199550832\n","Validation Accuracy: 0.9550515712066096\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 77.2789881833333 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1557368966384308\n","Validation Accuracy: 0.9543440021285471\n","Validation duration: 6.256640600000052 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.88      0.83     12546\n","        test       0.81      0.87      0.84      9012\n","   treatment       0.84      0.86      0.85      9297\n","\n","   micro avg       0.81      0.87      0.84     30855\n","   macro avg       0.81      0.87      0.84     30855\n","weighted avg       0.81      0.87      0.84     30855\n","\n"]}],"source":["number_of_training_models = 8\n","target_augmented_percentage = 0.75\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"VSbPfhy9UBxD"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1tBh5gOBHpN1","outputId":"bcfbd06a-664a-4ef0-a7e4-f3076c5885a4"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 100% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 20800\n","Points in y_train after augmentation: 20800\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8724300861358643\n","Training loss per 100 training steps: 0.38981538369218904\n","Training loss per 100 training steps: 0.3014069466448542\n","Training loss per 100 training steps: 0.25725740381204015\n","Training loss per 100 training steps: 0.23353623868224033\n","Training loss per 100 training steps: 0.21886626451077337\n","Training loss per 100 training steps: 0.20760182515654507\n","Training loss epoch: 0.2007929659462892\n","Training accuracy epoch: 0.9360116837437429\n","Validating model...\n","Validation Loss: 0.13642642540591104\n","Validation Accuracy: 0.9557886867420652\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07904757559299469\n","Training loss per 100 training steps: 0.07845459524357673\n","Stopping epoch...\n","Training loss epoch: 0.07845459524357673\n","Training accuracy epoch: 0.9655788835551391\n","Validating model...\n","Validation Loss: 0.1609847475351258\n","Validation Accuracy: 0.9540920291423517\n","Training epoch: 3\n","Training loss per 100 training steps: 0.046496227383613586\n","Training loss per 100 training steps: 0.07122146842613963\n","Training loss per 100 training steps: 0.07230698153728721\n","Training loss per 100 training steps: 0.07468261112431157\n","Training loss per 100 training steps: 0.07516831054614666\n","Training loss per 100 training steps: 0.07508636200930663\n","Training loss per 100 training steps: 0.0763330067277029\n","Training loss epoch: 0.07640599622606085\n","Training accuracy epoch: 0.9754309386922936\n","Validating model...\n","Validation Loss: 0.1551472158836467\n","Validation Accuracy: 0.9547913441976484\n","Training epoch: 4\n","Training loss per 100 training steps: 0.07423924654722214\n","Training loss per 100 training steps: 0.04352072399284801\n","Training loss per 100 training steps: 0.043397919866789265\n","Training loss per 100 training steps: 0.04448136445243171\n","Training loss per 100 training steps: 0.04640771040606993\n","Training loss per 100 training steps: 0.04599252200365706\n","Training loss per 100 training steps: 0.04628644715227534\n","Training loss epoch: 0.046009895837006085\n","Training accuracy epoch: 0.9858580441426517\n","Validating model...\n","Validation Loss: 0.16420895507099567\n","Validation Accuracy: 0.9560365219593119\n","Training epoch: 5\n","Training loss per 100 training steps: 0.010202108882367611\n","Training loss per 100 training steps: 0.025388930758834808\n","Training loss per 100 training steps: 0.029181705388432806\n","Training loss per 100 training steps: 0.02848959073715958\n","Training loss per 100 training steps: 0.028978944521082652\n","Training loss per 100 training steps: 0.02932705817116283\n","Training loss per 100 training steps: 0.030299184644093487\n","Training loss epoch: 0.030213008232217713\n","Training accuracy epoch: 0.9902845216987269\n","Validating model...\n","Validation Loss: 0.1799483582522575\n","Validation Accuracy: 0.9567911522437126\n","Training epoch: 6\n","Training loss per 100 training steps: 0.002298959530889988\n","Training loss per 100 training steps: 0.02348092005249242\n","Training loss per 100 training steps: 0.022519068979248127\n","Training loss per 100 training steps: 0.024088214196619016\n","Training loss per 100 training steps: 0.024607342883434722\n","Training loss per 100 training steps: 0.024006038761633576\n","Training loss per 100 training steps: 0.024413863490912877\n","Training loss epoch: 0.02462432549487298\n","Training accuracy epoch: 0.9921802914268391\n","Validating model...\n","Validation Loss: 0.23118704741264318\n","Validation Accuracy: 0.9543208738103905\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 65.13048668333322 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1533307065471524\n","Validation Accuracy: 0.9522375890741339\n","Validation duration: 6.249960899999981 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.86      0.83     12546\n","        test       0.84      0.85      0.85      9012\n","   treatment       0.80      0.86      0.83      9297\n","\n","   micro avg       0.81      0.86      0.84     30855\n","   macro avg       0.81      0.86      0.84     30855\n","weighted avg       0.81      0.86      0.84     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 20800\n","Points in y_train after augmentation: 20800\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9175240993499756\n","Training loss per 100 training steps: 0.3722370578215854\n","Training loss per 100 training steps: 0.2859572281699572\n","Training loss per 100 training steps: 0.24956590156272004\n","Training loss per 100 training steps: 0.2262457561240232\n","Training loss per 100 training steps: 0.21047720433530692\n","Training loss per 100 training steps: 0.19754587469340462\n","Training loss epoch: 0.19200358254118607\n","Training accuracy epoch: 0.9382369657496328\n","Validating model...\n","Validation Loss: 0.14232094319803373\n","Validation Accuracy: 0.9541623468295308\n","Training epoch: 2\n","Training loss per 100 training steps: 0.10579757392406464\n","Training loss per 100 training steps: 0.07609652499161144\n","Training loss per 100 training steps: 0.07298903585647915\n","Training loss per 100 training steps: 0.0758302550410165\n","Training loss per 100 training steps: 0.07431716683257994\n","Training loss per 100 training steps: 0.0743222460857111\n","Training loss per 100 training steps: 0.07550453189481515\n","Training loss epoch: 0.07504682632306447\n","Training accuracy epoch: 0.9760475304035356\n","Validating model...\n","Validation Loss: 0.15674538165330887\n","Validation Accuracy: 0.9569125886804021\n","Training epoch: 3\n","Training loss per 100 training steps: 0.13198205828666687\n","Training loss per 100 training steps: 0.046120331419797815\n","Training loss per 100 training steps: 0.04515829420097135\n","Training loss per 100 training steps: 0.0443444238059792\n","Training loss per 100 training steps: 0.046741926173988424\n","Training loss per 100 training steps: 0.04644805167851869\n","Training loss per 100 training steps: 0.045615117007497694\n","Training loss epoch: 0.04565304966500172\n","Training accuracy epoch: 0.9856878703001147\n","Validating model...\n","Validation Loss: 0.17515638017688284\n","Validation Accuracy: 0.9539990857548114\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03812221437692642\n","Training loss per 100 training steps: 0.02600180453593188\n","Training loss per 100 training steps: 0.02766454138501144\n","Training loss per 100 training steps: 0.02762836370805891\n","Training loss per 100 training steps: 0.02918433405991941\n","Training loss per 100 training steps: 0.02979657641775114\n","Training loss per 100 training steps: 0.030459346665288732\n","Training loss epoch: 0.030355509772377377\n","Training accuracy epoch: 0.9906620987782625\n","Validating model...\n","Validation Loss: 0.21210089572569257\n","Validation Accuracy: 0.9497097568468174\n","Training epoch: 5\n","Training loss per 100 training steps: 0.00975923240184784\n","Training loss per 100 training steps: 0.026523050726483584\n","Training loss per 100 training steps: 0.022928205730546432\n","Training loss per 100 training steps: 0.026379339990246286\n","Training loss per 100 training steps: 0.027058994849247304\n","Training loss per 100 training steps: 0.027695413481838214\n","Training loss per 100 training steps: 0.028210764168567968\n","Training loss epoch: 0.02849464635669182\n","Training accuracy epoch: 0.9909698046065691\n","Validating model...\n","Validation Loss: 0.18201115548417166\n","Validation Accuracy: 0.9556398912158564\n","Training epoch: 6\n","Training loss per 100 training steps: 0.027019690722227097\n","Training loss per 100 training steps: 0.015079902853853631\n","Training loss per 100 training steps: 0.01829615349890618\n","Training loss per 100 training steps: 0.01925489315925556\n","Training loss per 100 training steps: 0.019493809071755006\n","Training loss per 100 training steps: 0.019459330352620888\n","Training loss per 100 training steps: 0.019323374635769292\n","Training loss epoch: 0.0192279170666678\n","Training accuracy epoch: 0.9942320028921813\n","Validating model...\n","Validation Loss: 0.20933583315897297\n","Validation Accuracy: 0.9554903759300918\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 75.31566385000005 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15507716304812305\n","Validation Accuracy: 0.9516158325228948\n","Validation duration: 6.248271483333277 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.3%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.87      0.83     12546\n","        test       0.81      0.89      0.85      9012\n","   treatment       0.80      0.86      0.83      9297\n","\n","   micro avg       0.80      0.87      0.83     30855\n","   macro avg       0.80      0.87      0.83     30855\n","weighted avg       0.80      0.87      0.83     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 20800\n","Points in y_train after augmentation: 20800\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.3127052783966064\n","Training loss per 100 training steps: 0.435139603101381\n","Training loss per 100 training steps: 0.3226464587583471\n","Training loss per 100 training steps: 0.27421846547693113\n","Training loss per 100 training steps: 0.24472786331934823\n","Training loss per 100 training steps: 0.22533501208780293\n","Training loss per 100 training steps: 0.20914097644153135\n","Training loss epoch: 0.20316578222008852\n","Training accuracy epoch: 0.9355244482583117\n","Validating model...\n","Validation Loss: 0.14057576518457432\n","Validation Accuracy: 0.9552090801088351\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04713987931609154\n","Training loss per 100 training steps: 0.06904476969548971\n","Training loss per 100 training steps: 0.07378171534458203\n","Training loss per 100 training steps: 0.08074960526871028\n","Training loss per 100 training steps: 0.08215595744178628\n","Training loss per 100 training steps: 0.08164116014129744\n","Training loss per 100 training steps: 0.08155836134578741\n","Training loss epoch: 0.08107715810864018\n","Training accuracy epoch: 0.9741060290733073\n","Validating model...\n","Validation Loss: 0.14655272517498438\n","Validation Accuracy: 0.9577616525250678\n","Training epoch: 3\n","Training loss per 100 training steps: 0.034404218196868896\n","Training loss per 100 training steps: 0.04494400540975356\n","Training loss per 100 training steps: 0.043423855108491595\n","Training loss per 100 training steps: 0.04710720143237606\n","Training loss per 100 training steps: 0.049237808315408534\n","Training loss per 100 training steps: 0.04835312071761968\n","Training loss per 100 training steps: 0.04775777923759885\n","Training loss epoch: 0.04767936402251228\n","Training accuracy epoch: 0.9848219133691843\n","Validating model...\n","Validation Loss: 0.17699952861415102\n","Validation Accuracy: 0.9570670539111177\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03458500653505325\n","Training loss per 100 training steps: 0.03215096614756944\n","Training loss per 100 training steps: 0.030812667558822244\n","Training loss per 100 training steps: 0.030699834039208923\n","Training loss per 100 training steps: 0.031501431893406345\n","Training loss per 100 training steps: 0.03272601556634259\n","Training loss per 100 training steps: 0.03216558250853522\n","Training loss epoch: 0.03306963050146945\n","Training accuracy epoch: 0.9896148446046639\n","Validating model...\n","Validation Loss: 0.19229737932902652\n","Validation Accuracy: 0.9569220979709973\n","Training epoch: 5\n","Training loss per 100 training steps: 0.006773203145712614\n","Training loss per 100 training steps: 0.02324353695482864\n","Training loss per 100 training steps: 0.02343119949042167\n","Training loss per 100 training steps: 0.02728558569045063\n","Training loss per 100 training steps: 0.027198894357568865\n","Training loss per 100 training steps: 0.026430067580245332\n","Training loss per 100 training steps: 0.02639286989547985\n","Training loss epoch: 0.026247791199532983\n","Training accuracy epoch: 0.9920537735674564\n","Validating model...\n","Validation Loss: 0.20055061436028448\n","Validation Accuracy: 0.9545024126618019\n","Training epoch: 6\n","Training loss per 100 training steps: 0.03372608870267868\n","Training loss per 100 training steps: 0.01764205221944295\n","Training loss per 100 training steps: 0.0169585437354034\n","Training loss per 100 training steps: 0.01702064499057879\n","Training loss per 100 training steps: 0.017702715809310685\n","Training loss per 100 training steps: 0.018375916171357958\n","Training loss per 100 training steps: 0.018455758945553093\n","Training loss epoch: 0.018113922520827216\n","Training accuracy epoch: 0.994668017488468\n","Validating model...\n","Validation Loss: 0.21108458967661703\n","Validation Accuracy: 0.9569406720015616\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 75.28997301666665 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15078887585938597\n","Validation Accuracy: 0.9535836121381661\n","Validation duration: 6.235230716666653 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.86      0.83     12546\n","        test       0.83      0.88      0.85      9012\n","   treatment       0.83      0.84      0.84      9297\n","\n","   micro avg       0.82      0.86      0.84     30855\n","   macro avg       0.82      0.86      0.84     30855\n","weighted avg       0.82      0.86      0.84     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 20800\n","Points in y_train after augmentation: 20800\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.163616418838501\n","Training loss per 100 training steps: 0.4107136730805482\n","Training loss per 100 training steps: 0.3107435507190168\n","Training loss per 100 training steps: 0.266544612638182\n","Training loss per 100 training steps: 0.2371431677102894\n","Training loss per 100 training steps: 0.21936761682291706\n","Training loss per 100 training steps: 0.20417939236824603\n","Training loss epoch: 0.19884481446101115\n","Training accuracy epoch: 0.9362236473470326\n","Validating model...\n","Validation Loss: 0.14354571956512216\n","Validation Accuracy: 0.9554029000181424\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05532322824001312\n","Training loss per 100 training steps: 0.08560352375970619\n","Training loss per 100 training steps: 0.08317812323681455\n","Training loss per 100 training steps: 0.08298775089589068\n","Training loss per 100 training steps: 0.08171070411689858\n","Training loss per 100 training steps: 0.08164481546714931\n","Training loss per 100 training steps: 0.08160193816924502\n","Training loss epoch: 0.08127923950982782\n","Training accuracy epoch: 0.9743312825052074\n","Validating model...\n","Validation Loss: 0.15020513500679622\n","Validation Accuracy: 0.9560292942329351\n","Training epoch: 3\n","Training loss per 100 training steps: 0.031153328716754913\n","Training loss per 100 training steps: 0.049757061415527125\n","Training loss per 100 training steps: 0.048976490989939045\n","Training loss per 100 training steps: 0.05007050469969446\n","Training loss per 100 training steps: 0.05012367354320395\n","Training loss per 100 training steps: 0.05034852475615705\n","Training loss per 100 training steps: 0.05014603167343048\n","Training loss epoch: 0.050803207477483035\n","Training accuracy epoch: 0.983632720485779\n","Validating model...\n","Validation Loss: 0.17526874289690675\n","Validation Accuracy: 0.9538321508278174\n","Training epoch: 4\n","Training loss per 100 training steps: 0.017505232244729996\n","Training loss per 100 training steps: 0.034824220929294825\n","Training loss per 100 training steps: 0.03161346308182721\n","Training loss per 100 training steps: 0.03165142256472619\n","Training loss per 100 training steps: 0.031629263331063855\n","Training loss per 100 training steps: 0.031447073242101005\n","Training loss per 100 training steps: 0.032438643759785966\n","Training loss epoch: 0.033179369531213664\n","Training accuracy epoch: 0.9894230266353872\n","Validating model...\n","Validation Loss: 0.17437443376047077\n","Validation Accuracy: 0.9572789633049068\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0016358353896066546\n","Training loss per 100 training steps: 0.021522562420641135\n","Training loss per 100 training steps: 0.02626483737484121\n","Training loss per 100 training steps: 0.0267885961156784\n","Training loss per 100 training steps: 0.026746835538123424\n","Training loss per 100 training steps: 0.0269143466727098\n","Training loss per 100 training steps: 0.028098531338555145\n","Training loss epoch: 0.028094552768251072\n","Training accuracy epoch: 0.9913060185153614\n","Validating model...\n","Validation Loss: 0.16857286834750662\n","Validation Accuracy: 0.959609913875144\n","Training epoch: 6\n","Training loss per 100 training steps: 0.07118953764438629\n","Training loss per 100 training steps: 0.019376272911385696\n","Training loss per 100 training steps: 0.022349348168678822\n","Training loss per 100 training steps: 0.020983611856025652\n","Training loss per 100 training steps: 0.021571218466213172\n","Training loss per 100 training steps: 0.02138800098339538\n","Training loss per 100 training steps: 0.021524374109434086\n","Training loss epoch: 0.021425995933285986\n","Training accuracy epoch: 0.9935029297608692\n","Validating model...\n","Validation Loss: 0.20068953994226146\n","Validation Accuracy: 0.9569077237062895\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 75.33583263333324 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15437014512200323\n","Validation Accuracy: 0.9516784044911878\n","Validation duration: 6.243253049999961 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.3%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.86      0.82     12546\n","        test       0.84      0.88      0.86      9012\n","   treatment       0.77      0.88      0.82      9297\n","\n","   micro avg       0.80      0.87      0.83     30855\n","   macro avg       0.80      0.87      0.84     30855\n","weighted avg       0.80      0.87      0.83     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 20800\n","Points in y_train after augmentation: 20800\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0356457233428955\n","Training loss per 100 training steps: 0.4003607120991933\n","Training loss per 100 training steps: 0.30304309425514137\n","Training loss per 100 training steps: 0.26141927110346846\n","Training loss per 100 training steps: 0.23580320918017492\n","Training loss per 100 training steps: 0.2180529252111079\n","Training loss per 100 training steps: 0.20383190726876854\n","Training loss epoch: 0.19695591119619515\n","Training accuracy epoch: 0.936762320463585\n","Validating model...\n","Validation Loss: 0.1412541637947033\n","Validation Accuracy: 0.9545286525887031\n","Training epoch: 2\n","Training loss per 100 training steps: 0.028778359293937683\n","Training loss per 100 training steps: 0.08527312461876928\n","Training loss per 100 training steps: 0.08750963848158347\n","Training loss per 100 training steps: 0.08506048328097773\n","Training loss per 100 training steps: 0.08189255802978081\n","Training loss per 100 training steps: 0.08105326914590989\n","Training loss per 100 training steps: 0.08009715750348598\n","Training loss epoch: 0.08005441808499969\n","Training accuracy epoch: 0.9740848041406797\n","Validating model...\n","Validation Loss: 0.15711120929714148\n","Validation Accuracy: 0.9537405663875077\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02736898511648178\n","Training loss per 100 training steps: 0.04629810278460678\n","Training loss per 100 training steps: 0.04212085650515608\n","Training loss per 100 training steps: 0.04496735398366775\n","Training loss per 100 training steps: 0.04486252754018584\n","Training loss per 100 training steps: 0.046193850349389505\n","Training loss per 100 training steps: 0.04642450406499666\n","Training loss epoch: 0.04664665050589695\n","Training accuracy epoch: 0.9851238940543824\n","Validating model...\n","Validation Loss: 0.1572150932745887\n","Validation Accuracy: 0.9591691905026677\n","Training epoch: 4\n","Training loss per 100 training steps: 0.019837114959955215\n","Training loss per 100 training steps: 0.0266619589603921\n","Training loss per 100 training steps: 0.026437131018465877\n","Training loss per 100 training steps: 0.026469713179054253\n","Training loss per 100 training steps: 0.030418990216475733\n","Training loss per 100 training steps: 0.03135275936494033\n","Training loss per 100 training steps: 0.031125570523836178\n","Training loss epoch: 0.0309071591646912\n","Training accuracy epoch: 0.9904913220501672\n","Validating model...\n","Validation Loss: 0.17924046910718663\n","Validation Accuracy: 0.9571666795086012\n","Training epoch: 5\n","Training loss per 100 training steps: 0.014269448816776276\n","Training loss per 100 training steps: 0.020822669707911808\n","Training loss per 100 training steps: 0.02240238046222621\n","Training loss per 100 training steps: 0.023023635174528358\n","Training loss per 100 training steps: 0.022191775109772188\n","Training loss per 100 training steps: 0.023060318392082425\n","Training loss per 100 training steps: 0.023548598419843914\n","Training loss epoch: 0.023915730268121337\n","Training accuracy epoch: 0.9926712119940545\n","Validating model...\n","Validation Loss: 0.20425233685157515\n","Validation Accuracy: 0.9562090346002834\n","Training epoch: 6\n","Training loss per 100 training steps: 0.02420932799577713\n","Training loss per 100 training steps: 0.019357405474990385\n","Training loss per 100 training steps: 0.021800889165038754\n","Training loss per 100 training steps: 0.02079457041855431\n","Training loss per 100 training steps: 0.020812280098977325\n","Training loss per 100 training steps: 0.020286307772881762\n","Training loss per 100 training steps: 0.021157537642967097\n","Training loss epoch: 0.022707126616106296\n","Training accuracy epoch: 0.9929689083955869\n","Validating model...\n","Validation Loss: 0.2112494157990078\n","Validation Accuracy: 0.9494365256617683\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 75.24475738333349 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15756163555542352\n","Validation Accuracy: 0.951733061553641\n","Validation duration: 6.240375633333315 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.8%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.87      0.83     12546\n","        test       0.86      0.86      0.86      9012\n","   treatment       0.82      0.85      0.83      9297\n","\n","   micro avg       0.82      0.86      0.84     30855\n","   macro avg       0.82      0.86      0.84     30855\n","weighted avg       0.82      0.86      0.84     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 20800\n","Points in y_train after augmentation: 20800\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.236896276473999\n","Training loss per 100 training steps: 0.43068172494963847\n","Training loss per 100 training steps: 0.31112817048433405\n","Training loss per 100 training steps: 0.26504714023383746\n","Training loss per 100 training steps: 0.23821953418397546\n","Training loss per 100 training steps: 0.21844775465032654\n","Training loss per 100 training steps: 0.2043172111967191\n","Training loss epoch: 0.19880880436358545\n","Training accuracy epoch: 0.9357253850618377\n","Validating model...\n","Validation Loss: 0.16038789034083292\n","Validation Accuracy: 0.9475269199562864\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07021497935056686\n","Training loss per 100 training steps: 0.07772571550184253\n","Training loss per 100 training steps: 0.07450204782317675\n","Training loss per 100 training steps: 0.0727259954716082\n","Training loss per 100 training steps: 0.07443746215108772\n","Training loss per 100 training steps: 0.07506470133117335\n","Training loss per 100 training steps: 0.07365675677720476\n","Training loss epoch: 0.07348812984660841\n","Training accuracy epoch: 0.9760086147575161\n","Validating model...\n","Validation Loss: 0.15994320323618202\n","Validation Accuracy: 0.9553412258508328\n","Training epoch: 3\n","Training loss per 100 training steps: 0.01008552499115467\n","Training loss per 100 training steps: 0.04423065895980021\n","Training loss per 100 training steps: 0.04538818984871628\n","Training loss per 100 training steps: 0.04710715723555053\n","Training loss per 100 training steps: 0.04640107537780022\n","Training loss per 100 training steps: 0.04650910184653606\n","Training loss per 100 training steps: 0.04764385791665901\n","Training loss epoch: 0.04730477838705365\n","Training accuracy epoch: 0.9846774116316181\n","Validating model...\n","Validation Loss: 0.1724778125062585\n","Validation Accuracy: 0.9574975217975774\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0074421316385269165\n","Training loss per 100 training steps: 0.026365591819388884\n","Training loss per 100 training steps: 0.02599060660823531\n","Training loss per 100 training steps: 0.03020907214848925\n","Training loss per 100 training steps: 0.02833218736564764\n","Training loss per 100 training steps: 0.027969413036118055\n","Training loss per 100 training steps: 0.028768123436088484\n","Training loss epoch: 0.029123368624490328\n","Training accuracy epoch: 0.9907573555647222\n","Validating model...\n","Validation Loss: 0.20043521217227755\n","Validation Accuracy: 0.957911177802808\n","Training epoch: 5\n","Training loss per 100 training steps: 0.011592552065849304\n","Training loss per 100 training steps: 0.02384588313934458\n","Training loss per 100 training steps: 0.022878322268741216\n","Training loss per 100 training steps: 0.022647068951823484\n","Training loss per 100 training steps: 0.022912940362359784\n","Training loss per 100 training steps: 0.024301522851332802\n","Training loss per 100 training steps: 0.024523196387898485\n","Training loss epoch: 0.024851127512296303\n","Training accuracy epoch: 0.9926621580156292\n","Validating model...\n","Validation Loss: 0.1954024410383268\n","Validation Accuracy: 0.9584835119049686\n","Training epoch: 6\n","Training loss per 100 training steps: 0.021292591467499733\n","Training loss per 100 training steps: 0.016371823306711816\n","Training loss per 100 training steps: 0.01893231952452884\n","Training loss per 100 training steps: 0.018501689940291857\n","Training loss per 100 training steps: 0.0175986682775226\n","Training loss per 100 training steps: 0.01875090864189564\n","Training loss per 100 training steps: 0.019490236402125084\n","Training loss epoch: 0.01942111522066765\n","Training accuracy epoch: 0.9940825179497179\n","Validating model...\n","Validation Loss: 0.21967118194737992\n","Validation Accuracy: 0.9571403667110082\n","Training epoch: 7\n","Training loss per 100 training steps: 0.04570716619491577\n","Training loss per 100 training steps: 0.014960297118840131\n","Training loss per 100 training steps: 0.015765224564985594\n","Training loss per 100 training steps: 0.018680262307458916\n","Training loss per 100 training steps: 0.02052058464795394\n","Training loss per 100 training steps: 0.020208681155417435\n","Training loss per 100 training steps: 0.02127488556863936\n","Training loss epoch: 0.0214981276648737\n","Training accuracy epoch: 0.993492898184083\n","Validating model...\n","Validation Loss: 0.2583416396292386\n","Validation Accuracy: 0.9508195753836884\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 87.78884621666681 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.17895716768624778\n","Validation Accuracy: 0.9522200280514184\n","Validation duration: 6.226561883333246 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.85      0.84      0.85     12546\n","        test       0.78      0.90      0.84      9012\n","   treatment       0.81      0.84      0.83      9297\n","\n","   micro avg       0.82      0.86      0.84     30855\n","   macro avg       0.82      0.86      0.84     30855\n","weighted avg       0.82      0.86      0.84     30855\n","\n","!!!!!! Starting model number 7 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 20800\n","Points in y_train after augmentation: 20800\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9635703563690186\n","Training loss per 100 training steps: 0.3871344516035354\n","Training loss per 100 training steps: 0.29713379387831806\n","Training loss per 100 training steps: 0.2550130605796643\n","Training loss per 100 training steps: 0.23087216958292106\n","Training loss per 100 training steps: 0.21268462561472448\n","Training loss per 100 training steps: 0.19774835819251427\n","Training loss epoch: 0.19193085925223735\n","Training accuracy epoch: 0.9381313578156675\n","Validating model...\n","Validation Loss: 0.15029209818352351\n","Validation Accuracy: 0.9524983089630706\n","Training epoch: 2\n","Training loss per 100 training steps: 0.12936630845069885\n","Training loss per 100 training steps: 0.07626791740998183\n","Training loss per 100 training steps: 0.07414494667999187\n","Training loss per 100 training steps: 0.07528701483386498\n","Training loss per 100 training steps: 0.0761730221478719\n","Training loss per 100 training steps: 0.07547417864344731\n","Training loss per 100 training steps: 0.07489500198042184\n","Training loss epoch: 0.0748182597111624\n","Training accuracy epoch: 0.9758408719776018\n","Validating model...\n","Validation Loss: 0.1541930657460705\n","Validation Accuracy: 0.9538165142596956\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0521242581307888\n","Training loss per 100 training steps: 0.041166294748793436\n","Training loss per 100 training steps: 0.04021555641712389\n","Training loss per 100 training steps: 0.040882442841164\n","Training loss per 100 training steps: 0.0434109266670862\n","Training loss per 100 training steps: 0.04362292614339771\n","Training loss per 100 training steps: 0.044085252473747574\n","Training loss epoch: 0.04399213924538344\n","Training accuracy epoch: 0.9860441784567783\n","Validating model...\n","Validation Loss: 0.17580864652265588\n","Validation Accuracy: 0.9539486286098436\n","Training epoch: 4\n","Training loss per 100 training steps: 0.08742529898881912\n","Training loss per 100 training steps: 0.03314902683567846\n","Training loss per 100 training steps: 0.029010617167837177\n","Training loss per 100 training steps: 0.02940124493793111\n","Training loss per 100 training steps: 0.02982991188967791\n","Training loss per 100 training steps: 0.030516361785883423\n","Training loss per 100 training steps: 0.030477184219829763\n","Training loss epoch: 0.030898654045572935\n","Training accuracy epoch: 0.9903584371653096\n","Validating model...\n","Validation Loss: 0.17355259505475495\n","Validation Accuracy: 0.9562506544180874\n","Training epoch: 5\n","Training loss per 100 training steps: 0.029733343049883842\n","Training loss per 100 training steps: 0.01956710282316671\n","Training loss per 100 training steps: 0.020491339931778832\n","Training loss per 100 training steps: 0.021419652932024934\n","Training loss per 100 training steps: 0.02185796253006334\n","Training loss per 100 training steps: 0.023467975493753793\n","Training loss per 100 training steps: 0.02390254710011801\n","Training loss epoch: 0.024297712264636246\n","Training accuracy epoch: 0.992540274597993\n","Validating model...\n","Validation Loss: 0.17767397631504028\n","Validation Accuracy: 0.9563425036576546\n","Training epoch: 6\n","Training loss per 100 training steps: 0.010971893556416035\n","Training loss per 100 training steps: 0.015319465387538813\n","Training loss per 100 training steps: 0.015575518795122294\n","Training loss per 100 training steps: 0.01666009610853749\n","Training loss per 100 training steps: 0.017393177430066478\n","Training loss per 100 training steps: 0.01763874653098499\n","Training loss per 100 training steps: 0.0207897554765364\n","Training loss epoch: 0.02091516247198272\n","Training accuracy epoch: 0.9936040602681752\n","Validating model...\n","Validation Loss: 0.238652586114484\n","Validation Accuracy: 0.9500309057008961\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 75.17009181666654 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16827245912281796\n","Validation Accuracy: 0.9484011466922152\n","Validation duration: 6.224739966666675 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.77      0.87      0.82     12546\n","        test       0.79      0.87      0.83      9012\n","   treatment       0.78      0.87      0.83      9297\n","\n","   micro avg       0.78      0.87      0.82     30855\n","   macro avg       0.78      0.87      0.82     30855\n","weighted avg       0.78      0.87      0.82     30855\n","\n","!!!!!! Starting model number 8 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 20800\n","Points in y_train after augmentation: 20800\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1771786212921143\n","Training loss per 100 training steps: 0.4176862763591332\n","Training loss per 100 training steps: 0.31183817131973024\n","Training loss per 100 training steps: 0.264231561475814\n","Training loss per 100 training steps: 0.2366508888614891\n","Training loss per 100 training steps: 0.2183405942991822\n","Training loss per 100 training steps: 0.2050307290737026\n","Training loss epoch: 0.19889571262093692\n","Training accuracy epoch: 0.9369525558461371\n","Validating model...\n","Validation Loss: 0.13903220588123644\n","Validation Accuracy: 0.9554689898272327\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06682898104190826\n","Training loss per 100 training steps: 0.0777517642254139\n","Training loss per 100 training steps: 0.07937171694530702\n","Training loss per 100 training steps: 0.07823046368463243\n","Training loss per 100 training steps: 0.07913637112366254\n","Training loss per 100 training steps: 0.08014779104693177\n","Training loss per 100 training steps: 0.08048573334913657\n","Training loss epoch: 0.07974860542453825\n","Training accuracy epoch: 0.9743779718465285\n","Validating model...\n","Validation Loss: 0.16374574824200047\n","Validation Accuracy: 0.9550164760021577\n","Training epoch: 3\n","Training loss per 100 training steps: 0.047427088022232056\n","Training loss per 100 training steps: 0.04138694546360633\n","Training loss per 100 training steps: 0.04261127767380123\n","Training loss per 100 training steps: 0.04646040998365222\n","Training loss per 100 training steps: 0.047355463205746136\n","Training loss per 100 training steps: 0.0486549176828761\n","Training loss per 100 training steps: 0.04917824520193313\n","Training loss epoch: 0.04890872179458921\n","Training accuracy epoch: 0.984515860029311\n","Validating model...\n","Validation Loss: 0.1663935583133202\n","Validation Accuracy: 0.9580771798211558\n","Training epoch: 4\n","Training loss per 100 training steps: 0.015643665567040443\n","Training loss per 100 training steps: 0.029087951558983267\n","Training loss per 100 training steps: 0.029686321319076257\n","Training loss per 100 training steps: 0.029904282552057078\n","Training loss per 100 training steps: 0.029961157288806432\n","Training loss per 100 training steps: 0.031156280861996455\n","Training loss per 100 training steps: 0.031937331491198\n","Training loss epoch: 0.03256111436810058\n","Training accuracy epoch: 0.9897800728371835\n","Validating model...\n","Validation Loss: 0.19391053167546723\n","Validation Accuracy: 0.9517379730973542\n","Training epoch: 5\n","Training loss per 100 training steps: 0.03531678393483162\n","Training loss per 100 training steps: 0.02218343398250215\n","Training loss per 100 training steps: 0.022318355416802604\n","Training loss per 100 training steps: 0.022263378615180136\n","Training loss per 100 training steps: 0.022653164107908734\n","Training loss per 100 training steps: 0.023044230971887833\n","Training loss per 100 training steps: 0.023785891874593384\n","Training loss epoch: 0.02414826196090032\n","Training accuracy epoch: 0.9923381480500495\n","Validating model...\n","Validation Loss: 0.20788787368249584\n","Validation Accuracy: 0.9552171295570772\n","Training epoch: 6\n","Training loss per 100 training steps: 0.014641630463302135\n","Training loss per 100 training steps: 0.01643070845062485\n","Training loss per 100 training steps: 0.01739846824972997\n","Training loss per 100 training steps: 0.019083555247688795\n","Training loss per 100 training steps: 0.021563598081821393\n","Training loss per 100 training steps: 0.021789103612455236\n","Training loss per 100 training steps: 0.021142890075506012\n","Training loss epoch: 0.02155965826680096\n","Training accuracy epoch: 0.9933331275882565\n","Validating model...\n","Validation Loss: 0.19726571305231613\n","Validation Accuracy: 0.9563403238418497\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 75.19042628333337 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.149001309663786\n","Validation Accuracy: 0.9537711399808472\n","Validation duration: 6.219274549999924 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.84      0.83     12546\n","        test       0.83      0.85      0.84      9012\n","   treatment       0.83      0.84      0.84      9297\n","\n","   micro avg       0.83      0.84      0.83     30855\n","   macro avg       0.83      0.84      0.83     30855\n","weighted avg       0.83      0.84      0.83     30855\n","\n","!!!!!! Starting model number 9 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 20800\n","Points in y_train after augmentation: 20800\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.848410964012146\n","Training loss per 100 training steps: 0.4083116392392923\n","Training loss per 100 training steps: 0.3099983740431159\n","Training loss per 100 training steps: 0.2653621782817912\n","Training loss per 100 training steps: 0.23658640553566285\n","Training loss per 100 training steps: 0.21830693902280515\n","Training loss per 100 training steps: 0.2031655747957912\n","Training loss epoch: 0.19793784608061496\n","Training accuracy epoch: 0.9365377429591543\n","Validating model...\n","Validation Loss: 0.14321437874784718\n","Validation Accuracy: 0.9532106139360452\n","Training epoch: 2\n","Training loss per 100 training steps: 0.10479331016540527\n","Training loss per 100 training steps: 0.08582498913280445\n","Training loss per 100 training steps: 0.085586166342915\n","Training loss per 100 training steps: 0.08215512873982374\n","Training loss per 100 training steps: 0.08034909824536476\n","Training loss per 100 training steps: 0.07867026032169838\n","Training loss per 100 training steps: 0.07925789818917703\n","Training loss epoch: 0.07964402716750135\n","Training accuracy epoch: 0.9743981429489479\n","Validating model...\n","Validation Loss: 0.17469316716124486\n","Validation Accuracy: 0.9540925906126655\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03557680919766426\n","Training loss per 100 training steps: 0.04427228181503049\n","Training loss per 100 training steps: 0.047729795107696746\n","Training loss per 100 training steps: 0.04825990612385021\n","Training loss per 100 training steps: 0.04812659975112256\n","Training loss per 100 training steps: 0.04874352346004327\n","Training loss per 100 training steps: 0.04906759810337205\n","Training loss epoch: 0.049341788871321256\n","Training accuracy epoch: 0.9845980460551371\n","Validating model...\n","Validation Loss: 0.15597548362399852\n","Validation Accuracy: 0.9568115693580531\n","Training epoch: 4\n","Training loss per 100 training steps: 0.04401616007089615\n","Training loss per 100 training steps: 0.02829967987364029\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 1\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"1tBh5gOBHpN1"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a487f8fb973d443c91acf5f3c0265cea","e7c9ccf8d1724d63b614dad271a6d834","25126a1181e8488196d1adcf2f0d8c7e","36de6fda26164e3f83c25228ff6c057e","6a8990ef69b24d1cba0de912a4532a24","0f3b864852674078a9a2184450bf39e1","9d4543bccc8345948e8970a0afede7fa","2ded5e8e703842739d64463fe428a5f2","8164f9f4d15e4e38b76e34fda07bc471","ca07ef2a9f3548958eac4fca0c7dcfa4","66c00ae1102a4e2db81c977b11746511"]},"executionInfo":{"elapsed":10492880,"status":"ok","timestamp":1667808281539,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"bm9GsmqkfOMB","outputId":"85690f56-ae04-49fe-b73d-81af70329de1"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 100% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a487f8fb973d443c91acf5f3c0265cea","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 20800\n","Points in y_train after augmentation: 20800\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1870486736297607\n","Training loss per 100 training steps: 0.4118020328702313\n","Training loss per 100 training steps: 0.308949012809725\n","Training loss per 100 training steps: 0.2644651251600628\n","Training loss per 100 training steps: 0.23751083969549644\n","Training loss per 100 training steps: 0.2177821584863815\n","Training loss per 100 training steps: 0.20352539267955028\n","Training loss epoch: 0.19836090638373907\n","Training accuracy epoch: 0.9367168342858299\n","Validating model...\n","Validation Loss: 0.14039524705088757\n","Validation Accuracy: 0.9537642560274039\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09523492306470871\n","Training loss per 100 training steps: 0.07974448106666603\n","Training loss per 100 training steps: 0.0820942211395769\n","Training loss per 100 training steps: 0.08028969588222298\n","Training loss per 100 training steps: 0.0782422299410897\n","Training loss per 100 training steps: 0.07652712660375054\n","Training loss per 100 training steps: 0.07762748631532497\n","Training loss epoch: 0.07885766665522868\n","Training accuracy epoch: 0.974680891326994\n","Validating model...\n","Validation Loss: 0.15444831912974258\n","Validation Accuracy: 0.9539391608359429\n","Training epoch: 3\n","Training loss per 100 training steps: 0.06276858597993851\n","Training loss per 100 training steps: 0.04804426724423129\n","Training loss per 100 training steps: 0.04708799649382112\n","Training loss per 100 training steps: 0.04654343277711013\n","Training loss per 100 training steps: 0.04541516141324975\n","Training loss per 100 training steps: 0.04641919059050595\n","Training loss per 100 training steps: 0.045917054529793055\n","Training loss epoch: 0.0460906938635386\n","Training accuracy epoch: 0.9855190046630862\n","Validating model...\n","Validation Loss: 0.16707743810755865\n","Validation Accuracy: 0.9537263787462766\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0166977196931839\n","Training loss per 100 training steps: 0.0263124963171817\n","Training loss per 100 training steps: 0.026773811353889492\n","Training loss per 100 training steps: 0.028203818308146195\n","Training loss per 100 training steps: 0.028756742543039233\n","Training loss per 100 training steps: 0.030487326926276637\n","Training loss per 100 training steps: 0.030983220213077367\n","Training loss epoch: 0.03162029882875056\n","Training accuracy epoch: 0.9901771427076645\n","Validating model...\n","Validation Loss: 0.16795791535601987\n","Validation Accuracy: 0.9560771548715729\n","Training epoch: 5\n","Training loss per 100 training steps: 0.05365314707159996\n","Training loss per 100 training steps: 0.02073439702133436\n","Training loss per 100 training steps: 0.021490507095412753\n","Training loss per 100 training steps: 0.022271342843189292\n","Training loss per 100 training steps: 0.022632905629293952\n","Training loss per 100 training steps: 0.024357113263968513\n","Training loss per 100 training steps: 0.0255369329237156\n","Training loss epoch: 0.025720284928370696\n","Training accuracy epoch: 0.9917860794634485\n","Validating model...\n","Validation Loss: 0.2190351996135402\n","Validation Accuracy: 0.9536765175888529\n","Training epoch: 6\n","Training loss per 100 training steps: 0.006307388190180063\n","Training loss per 100 training steps: 0.02084611508174624\n","Training loss per 100 training steps: 0.020688863893083543\n","Training loss per 100 training steps: 0.020874783223064807\n","Training loss per 100 training steps: 0.021391939206055813\n","Training loss per 100 training steps: 0.02158538240334298\n","Training loss per 100 training steps: 0.02085632053296858\n","Training loss epoch: 0.02079344099503942\n","Training accuracy epoch: 0.993424222992479\n","Validating model...\n","Validation Loss: 0.21324223180168442\n","Validation Accuracy: 0.9561359938341937\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 73.95320086666668 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14707522691632793\n","Validation Accuracy: 0.9529995849794886\n","Validation duration: 6.182302816666667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.84      0.83     12546\n","        test       0.85      0.88      0.86      9012\n","   treatment       0.84      0.84      0.84      9297\n","\n","   micro avg       0.83      0.85      0.84     30855\n","   macro avg       0.83      0.85      0.84     30855\n","weighted avg       0.83      0.85      0.84     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 20800\n","Points in y_train after augmentation: 20800\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1497974395751953\n","Training loss per 100 training steps: 0.42084306301456864\n","Training loss per 100 training steps: 0.30764745494619533\n","Training loss per 100 training steps: 0.26340931668828094\n","Training loss per 100 training steps: 0.23375794867476324\n","Training loss per 100 training steps: 0.219380724543107\n","Training loss per 100 training steps: 0.2049098999089191\n","Training loss epoch: 0.1991304972423957\n","Training accuracy epoch: 0.9363428988031562\n","Validating model...\n","Validation Loss: 0.13248891477751268\n","Validation Accuracy: 0.9578660809744294\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07829730957746506\n","Training loss per 100 training steps: 0.0802365524952512\n","Training loss per 100 training steps: 0.07984320585388895\n","Training loss per 100 training steps: 0.08056676950293323\n","Training loss per 100 training steps: 0.07976853915785168\n","Training loss per 100 training steps: 0.07936637228663393\n","Training loss per 100 training steps: 0.07884020445257822\n","Training loss epoch: 0.0793323829325919\n","Training accuracy epoch: 0.9747545665875696\n","Validating model...\n","Validation Loss: 0.13842782455605346\n","Validation Accuracy: 0.9591298855790628\n","Training epoch: 3\n","Training loss per 100 training steps: 0.1482020914554596\n","Training loss per 100 training steps: 0.04098858522933604\n","Training loss per 100 training steps: 0.043710817791410346\n","Training loss per 100 training steps: 0.048493234651082774\n","Training loss per 100 training steps: 0.049977590175498826\n","Training loss per 100 training steps: 0.04906718074780946\n","Training loss per 100 training steps: 0.04873962739959806\n","Training loss epoch: 0.048739151860085816\n","Training accuracy epoch: 0.9848970779902961\n","Validating model...\n","Validation Loss: 0.1562127491894674\n","Validation Accuracy: 0.9550317173059485\n","Training epoch: 4\n","Training loss per 100 training steps: 0.005807914771139622\n","Training loss per 100 training steps: 0.025808933320095633\n","Training loss per 100 training steps: 0.029366552649038053\n","Training loss per 100 training steps: 0.034190126646780394\n","Training loss per 100 training steps: 0.03548487387493048\n","Training loss per 100 training steps: 0.03619487526149911\n","Training loss per 100 training steps: 0.0362464705487549\n","Training loss epoch: 0.03665189208212093\n","Training accuracy epoch: 0.9887461171539484\n","Validating model...\n","Validation Loss: 0.16147610548786917\n","Validation Accuracy: 0.9590462003898502\n","Training epoch: 5\n","Training loss per 100 training steps: 0.003641778137534857\n","Training loss per 100 training steps: 0.021095155792467592\n","Training loss per 100 training steps: 0.024977059071693588\n","Training loss per 100 training steps: 0.0252175049338431\n","Training loss per 100 training steps: 0.0262082135313518\n","Training loss per 100 training steps: 0.02680576490094242\n","Training loss per 100 training steps: 0.026866226612796352\n","Training loss epoch: 0.027113949409327827\n","Training accuracy epoch: 0.9918027801431881\n","Validating model...\n","Validation Loss: 0.177855327610507\n","Validation Accuracy: 0.9573598381926046\n","Training epoch: 6\n","Training loss per 100 training steps: 0.010394635610282421\n","Training loss per 100 training steps: 0.016565422787985735\n","Training loss per 100 training steps: 0.015211225236940953\n","Training loss per 100 training steps: 0.01734088410759125\n","Training loss per 100 training steps: 0.01665687879370096\n","Training loss per 100 training steps: 0.01703158926032623\n","Training loss per 100 training steps: 0.01721665219684866\n","Training loss epoch: 0.01742487602576148\n","Training accuracy epoch: 0.9945468097524818\n","Validating model...\n","Validation Loss: 0.2148666131709303\n","Validation Accuracy: 0.9548633348182811\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 73.87292223333334 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15098339350488796\n","Validation Accuracy: 0.9531835865061526\n","Validation duration: 6.186120400000012 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.84      0.82      0.83     12546\n","        test       0.82      0.87      0.85      9012\n","   treatment       0.80      0.86      0.83      9297\n","\n","   micro avg       0.82      0.85      0.84     30855\n","   macro avg       0.82      0.85      0.84     30855\n","weighted avg       0.82      0.85      0.84     30855\n","\n"]}],"source":["number_of_training_models = 2\n","target_augmented_percentage = 1\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"bm9GsmqkfOMB"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zjhn7-LqHri0","outputId":"3ff5a1e0-f30b-4469-aea6-59e90b83455b"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 200% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 31200\n","Points in y_train after augmentation: 31200\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.20814847946167\n","Training loss per 100 training steps: 0.4042518164704342\n","Training loss per 100 training steps: 0.2971440925823515\n","Training loss per 100 training steps: 0.25963859755137436\n","Training loss per 100 training steps: 0.23042209378613202\n","Training loss per 100 training steps: 0.212245285890238\n","Training loss per 100 training steps: 0.19968291313795003\n","Training loss per 100 training steps: 0.1882923442562152\n","Training loss per 100 training steps: 0.17802513555650332\n","Training loss per 100 training steps: 0.16970963059582403\n","Training loss epoch: 0.1644329590484118\n","Training accuracy epoch: 0.9474070599233759\n","Validating model...\n","Validation Loss: 0.13404438006026403\n","Validation Accuracy: 0.9589990830794825\n","Training epoch: 2\n","Training loss per 100 training steps: 0.016699442639946938\n","Training loss per 100 training steps: 0.06484672381994452\n","Training loss per 100 training steps: 0.06421246968293146\n","Training loss per 100 training steps: 0.06806048976282196\n","Training loss per 100 training steps: 0.07040639108330235\n","Training loss per 100 training steps: 0.07006570642735965\n","Training loss per 100 training steps: 0.07008625461120227\n","Training loss per 100 training steps: 0.06871933304039116\n","Training loss per 100 training steps: 0.06682815532852313\n","Training loss per 100 training steps: 0.06571427433049672\n","Training loss epoch: 0.06420949992843163\n","Training accuracy epoch: 0.9794088383095256\n","Validating model...\n","Validation Loss: 0.15758145378007518\n","Validation Accuracy: 0.9565415259942488\n","Training epoch: 3\n","Training loss per 100 training steps: 0.11904981732368469\n","Training loss per 100 training steps: 0.030454667001538496\n","Training loss per 100 training steps: 0.032517307916359595\n","Training loss per 100 training steps: 0.03273088964045766\n","Training loss per 100 training steps: 0.03456159902590227\n","Training loss per 100 training steps: 0.034266730740261146\n","Training loss per 100 training steps: 0.035167526284437284\n","Training loss per 100 training steps: 0.035076329824694046\n","Training loss per 100 training steps: 0.03460321592029821\n","Training loss per 100 training steps: 0.03459805212361938\n","Training loss epoch: 0.03498097505110005\n","Training accuracy epoch: 0.9888555286674171\n","Validating model...\n","Validation Loss: 0.17395678646378704\n","Validation Accuracy: 0.9571728854950101\n","Training epoch: 4\n","Training loss per 100 training steps: 0.00860744807869196\n","Training loss per 100 training steps: 0.024275869815748665\n","Training loss per 100 training steps: 0.024493270115208677\n","Training loss per 100 training steps: 0.025299747804399468\n","Training loss per 100 training steps: 0.026979325676250953\n","Training loss per 100 training steps: 0.027462490864038586\n","Training loss per 100 training steps: 0.02762694867791146\n","Training loss per 100 training steps: 0.028521194898944544\n","Training loss per 100 training steps: 0.028675251821760603\n","Training loss per 100 training steps: 0.02829682436326186\n","Training loss epoch: 0.028020191094718684\n","Training accuracy epoch: 0.9910316112058931\n","Validating model...\n","Validation Loss: 0.20940521078837382\n","Validation Accuracy: 0.9571513042882932\n","Training epoch: 5\n","Training loss per 100 training steps: 0.00629595760256052\n","Training loss per 100 training steps: 0.016684716588720717\n","Training loss per 100 training steps: 0.01857216287414724\n","Training loss per 100 training steps: 0.019071794504282744\n","Training loss per 100 training steps: 0.019895653384232527\n","Training loss per 100 training steps: 0.020007543622268857\n","Training loss per 100 training steps: 0.019973870511023412\n","Training loss per 100 training steps: 0.020271443083902923\n","Training loss per 100 training steps: 0.021087638351798277\n","Training loss per 100 training steps: 0.02166308943882789\n","Training loss epoch: 0.021713301800191404\n","Training accuracy epoch: 0.9933118129407599\n","Validating model...\n","Validation Loss: 0.20832882451449897\n","Validation Accuracy: 0.9562983149604082\n","Training epoch: 6\n","Training loss per 100 training steps: 0.03904817998409271\n","Training loss per 100 training steps: 0.015289334312892786\n","Training loss per 100 training steps: 0.01722716338412989\n","Training loss per 100 training steps: 0.01764635548204032\n","Training loss per 100 training steps: 0.019443585665764734\n","Training loss per 100 training steps: 0.01925464064070347\n","Training loss per 100 training steps: 0.01919996694632815\n","Training loss per 100 training steps: 0.01897701253147481\n","Training loss per 100 training steps: 0.018989365300821716\n","Training loss per 100 training steps: 0.01901889867748813\n","Training loss epoch: 0.01917667045425146\n","Training accuracy epoch: 0.9941773288812438\n","Validating model...\n","Validation Loss: 0.22670448440816496\n","Validation Accuracy: 0.952273208218701\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 109.26575106666665 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15517124969779547\n","Validation Accuracy: 0.9530345678658383\n","Validation duration: 6.140914249999999 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.85      0.83     12546\n","        test       0.83      0.85      0.84      9012\n","   treatment       0.83      0.84      0.84      9297\n","\n","   micro avg       0.82      0.85      0.84     30855\n","   macro avg       0.82      0.85      0.84     30855\n","weighted avg       0.82      0.85      0.84     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 31200\n","Points in y_train after augmentation: 31200\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.01599383354187\n","Training loss per 100 training steps: 0.4439203634415523\n","Training loss per 100 training steps: 0.33257853050730124\n","Training loss per 100 training steps: 0.2816128109850955\n","Training loss per 100 training steps: 0.2506664851750073\n","Training loss per 100 training steps: 0.22879065435654866\n","Training loss per 100 training steps: 0.21388239817641141\n","Training loss per 100 training steps: 0.20047022610870902\n","Training loss per 100 training steps: 0.19077765854882464\n","Training loss per 100 training steps: 0.1813423341382026\n","Training loss epoch: 0.17561778248025056\n","Training accuracy epoch: 0.9439497869067531\n","Validating model...\n","Validation Loss: 0.14803006981390637\n","Validation Accuracy: 0.9557891283575437\n","Training epoch: 2\n","Training loss per 100 training steps: 0.08550723642110825\n","Training loss per 100 training steps: 0.07108375339741164\n","Training loss per 100 training steps: 0.07073335453117294\n","Training loss per 100 training steps: 0.06950213339804762\n","Training loss per 100 training steps: 0.06891641534511883\n","Training loss per 100 training steps: 0.06964685807298282\n","Training loss per 100 training steps: 0.06853596642675396\n","Training loss per 100 training steps: 0.06777294758393744\n","Training loss per 100 training steps: 0.06738983904163862\n","Training loss per 100 training steps: 0.06732213880337536\n","Training loss epoch: 0.06702924786374355\n","Training accuracy epoch: 0.9782321491019015\n","Validating model...\n","Validation Loss: 0.16027517750399647\n","Validation Accuracy: 0.955327334329463\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03783871605992317\n","Training loss per 100 training steps: 0.03598965699830563\n","Training loss per 100 training steps: 0.03586183019000944\n","Training loss per 100 training steps: 0.035714981686076355\n","Training loss per 100 training steps: 0.036922391838489325\n","Training loss per 100 training steps: 0.03701018067374231\n","Training loss per 100 training steps: 0.03712679643397794\n","Training loss per 100 training steps: 0.037946390039214434\n","Training loss per 100 training steps: 0.03774740175604495\n","Training loss per 100 training steps: 0.03789687188991865\n","Training loss epoch: 0.03794027296026261\n","Training accuracy epoch: 0.9881119691417879\n","Validating model...\n","Validation Loss: 0.19201183633564353\n","Validation Accuracy: 0.9514817799939733\n","Training epoch: 4\n","Training loss per 100 training steps: 0.010366459377110004\n","Training loss per 100 training steps: 0.020421610478920365\n","Training loss per 100 training steps: 0.025118733792153385\n","Training loss per 100 training steps: 0.026471882449784795\n","Training loss per 100 training steps: 0.025427686079855814\n","Training loss per 100 training steps: 0.025970618426660354\n","Training loss per 100 training steps: 0.025580211466712143\n","Training loss per 100 training steps: 0.025637182457815624\n","Training loss per 100 training steps: 0.025877368026520572\n","Training loss per 100 training steps: 0.026379886596966492\n","Training loss epoch: 0.026415623858606872\n","Training accuracy epoch: 0.9918575015218517\n","Validating model...\n","Validation Loss: 0.2006274879480676\n","Validation Accuracy: 0.9532184427902514\n","Training epoch: 5\n","Training loss per 100 training steps: 0.05036015808582306\n","Training loss per 100 training steps: 0.023673038013362426\n","Training loss per 100 training steps: 0.02252911567857109\n","Training loss per 100 training steps: 0.023052553118336514\n","Training loss per 100 training steps: 0.023981673196202\n","Training loss per 100 training steps: 0.025410753562804794\n","Training loss per 100 training steps: 0.025384805182470768\n","Training loss per 100 training steps: 0.025094295098258983\n","Training loss per 100 training steps: 0.024342374568171427\n","Training loss per 100 training steps: 0.0237034619551981\n","Training loss epoch: 0.023562919872406964\n","Training accuracy epoch: 0.9925759247833171\n","Validating model...\n","Validation Loss: 0.22076879825152748\n","Validation Accuracy: 0.9516763854574724\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0006335919024422765\n","Training loss per 100 training steps: 0.011401927111887068\n","Training loss per 100 training steps: 0.01447955957458665\n","Training loss per 100 training steps: 0.014170411206662742\n","Training loss per 100 training steps: 0.014204566116285676\n","Training loss per 100 training steps: 0.01464942770636224\n","Training loss per 100 training steps: 0.015304676790240557\n","Training loss per 100 training steps: 0.015152560303493545\n","Training loss per 100 training steps: 0.015248934106810308\n","Training loss per 100 training steps: 0.015985298866490583\n","Training loss epoch: 0.0164456943263455\n","Training accuracy epoch: 0.9948928415323653\n","Validating model...\n","Validation Loss: 0.25058084167540073\n","Validation Accuracy: 0.9486952773851035\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 109.47155031666668 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15859000761540504\n","Validation Accuracy: 0.9528430657277556\n","Validation duration: 6.13800258333334 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.87      0.84     12546\n","        test       0.84      0.88      0.86      9012\n","   treatment       0.84      0.82      0.83      9297\n","\n","   micro avg       0.83      0.86      0.84     30855\n","   macro avg       0.83      0.86      0.84     30855\n","weighted avg       0.83      0.86      0.84     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 31200\n","Points in y_train after augmentation: 31200\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.255430221557617\n","Training loss per 100 training steps: 0.45721227048647284\n","Training loss per 100 training steps: 0.3245348991520369\n","Training loss per 100 training steps: 0.275129034038497\n","Training loss per 100 training steps: 0.24517276673171287\n","Training loss per 100 training steps: 0.2235484194352539\n","Training loss per 100 training steps: 0.20871420026432952\n","Training loss per 100 training steps: 0.19593473861044466\n","Training loss per 100 training steps: 0.18542581156463583\n","Training loss per 100 training steps: 0.17658321681607114\n","Training loss epoch: 0.17137767164561993\n","Training accuracy epoch: 0.9452326692058581\n","Validating model...\n","Validation Loss: 0.14816625072778045\n","Validation Accuracy: 0.9554207350845142\n","Training epoch: 2\n","Training loss per 100 training steps: 0.03628677874803543\n","Training loss per 100 training steps: 0.07198051335566705\n","Training loss per 100 training steps: 0.06768945164848768\n","Training loss per 100 training steps: 0.06681572563599708\n","Training loss per 100 training steps: 0.06657936064958424\n","Training loss per 100 training steps: 0.06649450431884585\n","Training loss per 100 training steps: 0.06446586718810676\n","Training loss per 100 training steps: 0.06540995159222295\n","Training loss per 100 training steps: 0.06512215061487628\n","Training loss per 100 training steps: 0.06512929645928241\n","Training loss epoch: 0.06532475072412919\n","Training accuracy epoch: 0.9790452280394552\n","Validating model...\n","Validation Loss: 0.1695458328036906\n","Validation Accuracy: 0.9540146792432008\n","Training epoch: 3\n","Training loss per 100 training steps: 0.07752801477909088\n","Training loss per 100 training steps: 0.035107733446662084\n","Training loss per 100 training steps: 0.03485654098496063\n","Training loss per 100 training steps: 0.03687211810812305\n","Training loss per 100 training steps: 0.03556760087170339\n","Training loss per 100 training steps: 0.0365150671256167\n","Training loss per 100 training steps: 0.037262536641504744\n","Training loss per 100 training steps: 0.0367256243807528\n","Training loss per 100 training steps: 0.036744117278131316\n","Training loss per 100 training steps: 0.03719959236173937\n","Training loss epoch: 0.037515276327776986\n","Training accuracy epoch: 0.988051947332873\n","Validating model...\n","Validation Loss: 0.19433982017171847\n","Validation Accuracy: 0.9519944809193027\n","Training epoch: 4\n","Training loss per 100 training steps: 0.08929014950990677\n","Training loss per 100 training steps: 0.02767295627117083\n","Training loss per 100 training steps: 0.024829235968390824\n","Training loss per 100 training steps: 0.02554239632745128\n","Training loss per 100 training steps: 0.02559324325787535\n","Training loss per 100 training steps: 0.02503311714102159\n","Training loss per 100 training steps: 0.025132191144205018\n","Training loss per 100 training steps: 0.025060859076946457\n","Training loss per 100 training steps: 0.02499169654123655\n","Training loss per 100 training steps: 0.02543573677970084\n","Training loss epoch: 0.025770557811424042\n","Training accuracy epoch: 0.9921236687442656\n","Validating model...\n","Validation Loss: 0.20415688078705366\n","Validation Accuracy: 0.9534680368011695\n","Training epoch: 5\n","Training loss per 100 training steps: 0.09141958504915237\n","Training loss per 100 training steps: 0.01897262118521635\n","Training loss per 100 training steps: 0.020456439010979637\n","Training loss per 100 training steps: 0.022510623475428412\n","Training loss per 100 training steps: 0.022682162130047145\n","Training loss per 100 training steps: 0.022913811304522847\n","Training loss per 100 training steps: 0.02192445590302965\n","Training loss per 100 training steps: 0.022137498000710434\n","Training loss per 100 training steps: 0.02251214504446288\n","Training loss per 100 training steps: 0.02195144112855785\n","Training loss epoch: 0.021695301096158054\n","Training accuracy epoch: 0.9931773181123332\n","Validating model...\n","Validation Loss: 0.21871341757669852\n","Validation Accuracy: 0.9554144231050409\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0127349141985178\n","Training loss per 100 training steps: 0.01525706285437901\n","Training loss per 100 training steps: 0.01527705099691396\n","Training loss per 100 training steps: 0.015632308937475376\n","Training loss per 100 training steps: 0.015834217678007675\n","Training loss per 100 training steps: 0.015943642961629992\n","Training loss per 100 training steps: 0.01582929888138154\n","Training loss per 100 training steps: 0.015717624830890488\n","Training loss per 100 training steps: 0.01604657804254226\n","Training loss per 100 training steps: 0.01653775686769489\n","Training loss epoch: 0.01723567382629531\n","Training accuracy epoch: 0.9948280795019483\n","Validating model...\n","Validation Loss: 0.2515887495178681\n","Validation Accuracy: 0.946971932100774\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 109.34789920000003 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16329951949969487\n","Validation Accuracy: 0.9519175030204747\n","Validation duration: 6.121476966666645 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.76      0.85      0.80     12546\n","        test       0.85      0.86      0.85      9012\n","   treatment       0.81      0.86      0.83      9297\n","\n","   micro avg       0.80      0.85      0.83     30855\n","   macro avg       0.81      0.85      0.83     30855\n","weighted avg       0.80      0.85      0.83     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 31200\n","Points in y_train after augmentation: 31200\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.3039796352386475\n","Training loss per 100 training steps: 0.4527672403814769\n","Training loss per 100 training steps: 0.3294651899023436\n","Training loss per 100 training steps: 0.27819344155069603\n","Training loss per 100 training steps: 0.24706034640087154\n","Training loss per 100 training steps: 0.22520967024172137\n","Training loss per 100 training steps: 0.20993659264112075\n","Training loss per 100 training steps: 0.19843423546699757\n","Training loss per 100 training steps: 0.1892207268574339\n","Training loss per 100 training steps: 0.1809783762943136\n","Training loss epoch: 0.17431249545743832\n","Training accuracy epoch: 0.94491446966738\n","Validating model...\n","Validation Loss: 0.13887366771020673\n","Validation Accuracy: 0.9570778647821272\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07457706332206726\n","Training loss per 100 training steps: 0.06505908592982163\n","Training loss per 100 training steps: 0.06408343701831885\n","Training loss per 100 training steps: 0.06363920616202576\n","Training loss per 100 training steps: 0.06285685708658059\n","Training loss per 100 training steps: 0.06289562175492802\n","Training loss per 100 training steps: 0.0633552777154771\n","Training loss per 100 training steps: 0.06352895173840703\n","Training loss per 100 training steps: 0.06302957751494036\n","Training loss per 100 training steps: 0.061336777440699174\n","Training loss epoch: 0.060678331770767\n","Training accuracy epoch: 0.9808524062246674\n","Validating model...\n","Validation Loss: 0.18837390723940614\n","Validation Accuracy: 0.9543792135304395\n","Training epoch: 3\n","Training loss per 100 training steps: 0.018185622990131378\n","Training loss per 100 training steps: 0.03513877492600886\n","Training loss per 100 training steps: 0.035532938260863074\n","Training loss per 100 training steps: 0.03640813863700089\n","Training loss per 100 training steps: 0.03671535764858034\n","Training loss per 100 training steps: 0.03872144941339072\n","Training loss per 100 training steps: 0.03922406331358629\n","Training loss per 100 training steps: 0.03948326412450187\n","Training loss per 100 training steps: 0.0390936210559688\n","Training loss per 100 training steps: 0.0386908511893739\n","Training loss epoch: 0.03816846344512529\n","Training accuracy epoch: 0.9881087937288486\n","Validating model...\n","Validation Loss: 0.23765436062807\n","Validation Accuracy: 0.9492829558753574\n","Training epoch: 4\n","Training loss per 100 training steps: 0.015849994495511055\n","Training loss per 100 training steps: 0.03299794722081042\n","Training loss per 100 training steps: 0.030179201632237702\n","Training loss per 100 training steps: 0.027731684336680114\n","Training loss per 100 training steps: 0.026780260873127012\n","Training loss per 100 training steps: 0.026331866162126426\n","Training loss per 100 training steps: 0.0261841916902217\n","Training loss per 100 training steps: 0.026315773798241817\n","Training loss per 100 training steps: 0.026377042873498614\n","Training loss per 100 training steps: 0.026723773758517335\n","Training loss epoch: 0.026888044064816756\n","Training accuracy epoch: 0.9918197938358141\n","Validating model...\n","Validation Loss: 0.2069115871926407\n","Validation Accuracy: 0.9535141413338722\n","Training epoch: 5\n","Training loss per 100 training steps: 0.05951044708490372\n","Training loss per 100 training steps: 0.018940445924371406\n","Training loss per 100 training steps: 0.01756131301161402\n","Training loss per 100 training steps: 0.01822336769718491\n","Training loss per 100 training steps: 0.018611053230724022\n","Training loss per 100 training steps: 0.0189545229180742\n","Training loss per 100 training steps: 0.018591059654150716\n","Training loss per 100 training steps: 0.01933764655765122\n","Training loss per 100 training steps: 0.022471397781535896\n","Training loss per 100 training steps: 0.022795750079978853\n","Training loss epoch: 0.023309369439390513\n","Training accuracy epoch: 0.9926689494410081\n","Validating model...\n","Validation Loss: 0.22039074892202368\n","Validation Accuracy: 0.9527480824677549\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0026996517553925514\n","Training loss per 100 training steps: 0.017219970391205704\n","Training loss per 100 training steps: 0.017529170656407633\n","Training loss per 100 training steps: 0.015553369985578545\n","Training loss per 100 training steps: 0.015327322814207723\n","Training loss per 100 training steps: 0.014939522461318773\n","Training loss per 100 training steps: 0.015215969648312533\n","Training loss per 100 training steps: 0.015410038423330885\n","Training loss per 100 training steps: 0.015395979706531381\n","Training loss per 100 training steps: 0.016377733034213807\n","Training loss epoch: 0.016486504171192885\n","Training accuracy epoch: 0.9948230727216261\n","Validating model...\n","Validation Loss: 0.22527255160226065\n","Validation Accuracy: 0.9571170100119347\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 109.31877316666663 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15163092665413083\n","Validation Accuracy: 0.9532186869242965\n","Validation duration: 6.134082100000039 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.83      0.82     12546\n","        test       0.81      0.88      0.84      9012\n","   treatment       0.82      0.85      0.83      9297\n","\n","   micro avg       0.81      0.85      0.83     30855\n","   macro avg       0.81      0.85      0.83     30855\n","weighted avg       0.81      0.85      0.83     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 31200\n","Points in y_train after augmentation: 31200\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9344379901885986\n","Training loss per 100 training steps: 0.4084471430961448\n","Training loss per 100 training steps: 0.3092131482353851\n","Training loss per 100 training steps: 0.2635769142438209\n","Training loss per 100 training steps: 0.23721350630062477\n","Training loss per 100 training steps: 0.21771389074222056\n","Training loss per 100 training steps: 0.20442661085784336\n","Training loss per 100 training steps: 0.19117289840558627\n","Training loss per 100 training steps: 0.18147297563512674\n","Training loss per 100 training steps: 0.17363195170076784\n","Training loss epoch: 0.1680043799067155\n","Training accuracy epoch: 0.94586909049427\n","Validating model...\n","Validation Loss: 0.1590278608990567\n","Validation Accuracy: 0.9559602539093524\n","Training epoch: 2\n","Training loss per 100 training steps: 0.14763982594013214\n","Training loss per 100 training steps: 0.0639829162950858\n","Training loss per 100 training steps: 0.06408368711318098\n","Training loss per 100 training steps: 0.06429938070377045\n","Training loss per 100 training steps: 0.06438690697323726\n","Training loss per 100 training steps: 0.06273338388272388\n","Training loss per 100 training steps: 0.06275090207802922\n","Training loss per 100 training steps: 0.06210652174037508\n","Training loss per 100 training steps: 0.0619436116824008\n","Training loss per 100 training steps: 0.061677893065536324\n","Training loss epoch: 0.061552861157613686\n","Training accuracy epoch: 0.9803489405610512\n","Validating model...\n","Validation Loss: 0.1689057754860683\n","Validation Accuracy: 0.9544420628282275\n","Training epoch: 3\n","Training loss per 100 training steps: 0.042994916439056396\n","Training loss per 100 training steps: 0.03651833387165524\n","Training loss per 100 training steps: 0.03568877343236659\n","Training loss per 100 training steps: 0.036580032061018126\n","Training loss per 100 training steps: 0.03876062389927686\n","Training loss per 100 training steps: 0.03927479903380983\n","Training loss per 100 training steps: 0.03920200089815564\n","Training loss per 100 training steps: 0.039945144469673066\n","Training loss per 100 training steps: 0.03969750652228076\n","Training loss per 100 training steps: 0.03930223937100885\n","Training loss epoch: 0.039104077097338936\n","Training accuracy epoch: 0.9876057584635465\n","Validating model...\n","Validation Loss: 0.18927685483419276\n","Validation Accuracy: 0.9556805864518461\n","Training epoch: 4\n","Training loss per 100 training steps: 0.011130986735224724\n","Training loss per 100 training steps: 0.020679246464808756\n","Training loss per 100 training steps: 0.021075542544742202\n","Training loss per 100 training steps: 0.022127203512209717\n","Training loss per 100 training steps: 0.02395886839152618\n","Training loss per 100 training steps: 0.024717558340769923\n","Training loss per 100 training steps: 0.024878838082687146\n","Training loss per 100 training steps: 0.025045458968734096\n","Training loss per 100 training steps: 0.02551291833024765\n","Training loss per 100 training steps: 0.02577428449140128\n","Training loss epoch: 0.026699381785061305\n","Training accuracy epoch: 0.9917342755567002\n","Validating model...\n","Validation Loss: 0.20450070539078155\n","Validation Accuracy: 0.9517836273863943\n","Training epoch: 5\n","Training loss per 100 training steps: 0.006392014212906361\n","Training loss per 100 training steps: 0.021143157837340738\n","Training loss per 100 training steps: 0.019998070175194213\n","Training loss per 100 training steps: 0.0178172329512844\n","Training loss per 100 training steps: 0.0177561621477205\n","Training loss per 100 training steps: 0.018200175257510283\n","Training loss per 100 training steps: 0.018375507489946236\n","Training loss per 100 training steps: 0.01828628830163648\n","Training loss per 100 training steps: 0.019089221310137322\n","Training loss per 100 training steps: 0.01933652656548217\n","Training loss epoch: 0.019707295928442947\n","Training accuracy epoch: 0.9937178395523533\n","Validating model...\n","Validation Loss: 0.2153761244149177\n","Validation Accuracy: 0.9545099123150358\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0054190801456570625\n","Training loss per 100 training steps: 0.017234971600706864\n","Training loss per 100 training steps: 0.01678317650067805\n","Training loss per 100 training steps: 0.01868833357186298\n","Training loss per 100 training steps: 0.01980838304691242\n","Training loss per 100 training steps: 0.019653845962242476\n","Training loss per 100 training steps: 0.020597272870658094\n","Training loss per 100 training steps: 0.021396467916758137\n","Training loss per 100 training steps: 0.0210494332481103\n","Training loss per 100 training steps: 0.02089464205849402\n","Training loss epoch: 0.02076946108873623\n","Training accuracy epoch: 0.9935865406743849\n","Validating model...\n","Validation Loss: 0.21445587057281623\n","Validation Accuracy: 0.9571903144432194\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 109.23973659999999 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.17331719626801917\n","Validation Accuracy: 0.9508889633468841\n","Validation duration: 6.1330075500000625 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.3%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.85      0.82     12546\n","        test       0.83      0.82      0.83      9012\n","   treatment       0.81      0.84      0.82      9297\n","\n","   micro avg       0.81      0.84      0.82     30855\n","   macro avg       0.81      0.84      0.82     30855\n","weighted avg       0.81      0.84      0.82     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 31200\n","Points in y_train after augmentation: 31200\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7926626205444336\n","Training loss per 100 training steps: 0.40937801280824265\n","Training loss per 100 training steps: 0.30899851824810254\n","Training loss per 100 training steps: 0.2626065770999538\n","Training loss per 100 training steps: 0.23762924807085806\n","Training loss per 100 training steps: 0.22047109012222457\n","Training loss per 100 training steps: 0.2067524981274333\n","Training loss per 100 training steps: 0.1947726729205051\n","Training loss per 100 training steps: 0.1843976733529389\n","Training loss per 100 training steps: 0.17581304717606366\n","Training loss epoch: 0.1693494484057793\n","Training accuracy epoch: 0.945428431780297\n","Validating model...\n","Validation Loss: 0.16426129099707326\n","Validation Accuracy: 0.9519889429148821\n","Training epoch: 2\n","Training loss per 100 training steps: 0.23174776136875153\n","Training loss per 100 training steps: 0.07603335329838613\n","Training loss per 100 training steps: 0.07150485058922079\n","Training loss per 100 training steps: 0.06751872194107882\n","Training loss per 100 training steps: 0.06556922446313938\n","Training loss per 100 training steps: 0.06531916562274485\n","Training loss per 100 training steps: 0.06534517959640447\n","Training loss per 100 training steps: 0.06584511562642481\n","Training loss per 100 training steps: 0.06478879443973247\n","Training loss per 100 training steps: 0.06407829203677015\n","Training loss epoch: 0.06369111213116692\n","Training accuracy epoch: 0.9798648317278014\n","Validating model...\n","Validation Loss: 0.19299828379668973\n","Validation Accuracy: 0.9498815618420092\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0567220002412796\n","Training loss per 100 training steps: 0.0449525749836449\n","Training loss per 100 training steps: 0.04089872440235198\n","Training loss per 100 training steps: 0.039610491362415824\n","Training loss per 100 training steps: 0.0411225903815267\n","Training loss per 100 training steps: 0.041589376031460165\n","Training loss per 100 training steps: 0.041325089333814485\n","Training loss per 100 training steps: 0.04101452455934291\n","Training loss per 100 training steps: 0.041325630975617436\n","Training loss per 100 training steps: 0.04097291266573562\n","Training loss epoch: 0.041069364379852626\n","Training accuracy epoch: 0.9868619493122415\n","Validating model...\n","Validation Loss: 0.187718685764771\n","Validation Accuracy: 0.9529909547360822\n","Training epoch: 4\n","Training loss per 100 training steps: 0.010758224874734879\n","Training loss per 100 training steps: 0.025151858705621543\n","Training loss per 100 training steps: 0.02405452888125359\n","Training loss per 100 training steps: 0.024366457523094284\n","Training loss per 100 training steps: 0.02416789415016645\n","Training loss per 100 training steps: 0.023891029706454375\n","Training loss per 100 training steps: 0.023503213740142213\n","Training loss per 100 training steps: 0.023410823681679408\n","Training loss per 100 training steps: 0.024176543793096306\n","Training loss per 100 training steps: 0.024644345782666707\n","Training loss epoch: 0.024716336116469347\n","Training accuracy epoch: 0.9922353782596559\n","Validating model...\n","Validation Loss: 0.20779536529020828\n","Validation Accuracy: 0.9522197185049774\n","Training epoch: 5\n","Training loss per 100 training steps: 0.008812055923044682\n","Training loss per 100 training steps: 0.014983043026197518\n","Training loss per 100 training steps: 0.01587069074771557\n","Training loss per 100 training steps: 0.018988081985625106\n","Training loss per 100 training steps: 0.021054754423719606\n","Training loss per 100 training steps: 0.02141436264223276\n","Training loss per 100 training steps: 0.021524564419333016\n","Training loss per 100 training steps: 0.021503920713954402\n","Training loss per 100 training steps: 0.02165186138146065\n","Training loss per 100 training steps: 0.02129012303571315\n","Training loss epoch: 0.021505641856302434\n","Training accuracy epoch: 0.993426927908231\n","Validating model...\n","Validation Loss: 0.2498466819282863\n","Validation Accuracy: 0.9488110363969084\n","Training epoch: 6\n","Training loss per 100 training steps: 0.013075021095573902\n","Training loss per 100 training steps: 0.013641513435119339\n","Training loss per 100 training steps: 0.014680931272230746\n","Training loss per 100 training steps: 0.01672329993197614\n","Training loss per 100 training steps: 0.01860515794852061\n","Training loss per 100 training steps: 0.01792336615972907\n","Training loss per 100 training steps: 0.017482413206220033\n","Training loss per 100 training steps: 0.01870686952031341\n","Training loss per 100 training steps: 0.019137019217252665\n","Training loss per 100 training steps: 0.019579510058910243\n","Training loss epoch: 0.01976651272739475\n","Training accuracy epoch: 0.9939962132594737\n","Validating model...\n","Validation Loss: 0.230432685271099\n","Validation Accuracy: 0.9504038887994963\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 109.24110314999999 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.17912296778349965\n","Validation Accuracy: 0.9474983301841952\n","Validation duration: 6.124279533333417 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.76      0.86      0.81     12546\n","        test       0.82      0.88      0.85      9012\n","   treatment       0.80      0.85      0.82      9297\n","\n","   micro avg       0.79      0.86      0.82     30855\n","   macro avg       0.79      0.86      0.83     30855\n","weighted avg       0.79      0.86      0.82     30855\n","\n","!!!!!! Starting model number 7 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 31200\n","Points in y_train after augmentation: 31200\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9123456478118896\n","Training loss per 100 training steps: 0.41323147301036534\n","Training loss per 100 training steps: 0.31056674777423565\n","Training loss per 100 training steps: 0.26662257395412436\n","Training loss per 100 training steps: 0.24290562536279459\n","Training loss per 100 training steps: 0.22248060399380154\n","Training loss per 100 training steps: 0.2099138712247031\n","Training loss per 100 training steps: 0.1983068235425781\n","Training loss per 100 training steps: 0.18685139725670757\n","Training loss per 100 training steps: 0.1771742258495863\n","Training loss epoch: 0.17200896450246755\n","Training accuracy epoch: 0.9448512437390372\n","Validating model...\n","Validation Loss: 0.16422216403116655\n","Validation Accuracy: 0.9533270775281875\n","Training epoch: 2\n","Training loss per 100 training steps: 0.029491756111383438\n","Training loss per 100 training steps: 0.07704888861441966\n","Training loss per 100 training steps: 0.07462720117480749\n","Training loss per 100 training steps: 0.073130213870571\n","Training loss per 100 training steps: 0.07353394093372838\n","Training loss per 100 training steps: 0.07248528655562661\n","Training loss per 100 training steps: 0.07176381816697026\n","Training loss per 100 training steps: 0.0716572962442251\n","Training loss per 100 training steps: 0.07048105081245676\n","Training loss per 100 training steps: 0.07011285398856268\n","Training loss epoch: 0.06942370704399088\n","Training accuracy epoch: 0.9778505266882945\n","Validating model...\n","Validation Loss: 0.18779636329257643\n","Validation Accuracy: 0.9497307884819\n","Training epoch: 3\n","Training loss per 100 training steps: 0.05770362168550491\n","Training loss per 100 training steps: 0.038483424252821224\n","Training loss per 100 training steps: 0.037581811467908434\n","Training loss per 100 training steps: 0.03903017669028148\n","Training loss per 100 training steps: 0.039241558849518916\n","Training loss per 100 training steps: 0.038918868860252157\n","Training loss per 100 training steps: 0.03889868696399975\n","Training loss per 100 training steps: 0.03944970536066987\n","Training loss per 100 training steps: 0.03892925429709033\n","Training loss per 100 training steps: 0.03851839175140826\n","Training loss epoch: 0.03841003789303776\n","Training accuracy epoch: 0.9876647427659704\n","Validating model...\n","Validation Loss: 0.1959179166535085\n","Validation Accuracy: 0.9553610124725695\n","Training epoch: 4\n","Training loss per 100 training steps: 0.008715123869478703\n","Training loss per 100 training steps: 0.03297534620499994\n","Training loss per 100 training steps: 0.030850794692222603\n","Training loss per 100 training steps: 0.028842473540693348\n","Training loss per 100 training steps: 0.02712452709599354\n","Training loss per 100 training steps: 0.026312154964515996\n","Training loss per 100 training steps: 0.02647193760561529\n","Training loss per 100 training steps: 0.027327014500681795\n","Training loss per 100 training steps: 0.026904378220329664\n","Training loss per 100 training steps: 0.027357787867805423\n","Training loss epoch: 0.028188404098439677\n","Training accuracy epoch: 0.9912791386656293\n","Validating model...\n","Validation Loss: 0.22185820595107295\n","Validation Accuracy: 0.9511571520960901\n","Training epoch: 5\n","Training loss per 100 training steps: 0.01994769275188446\n","Training loss per 100 training steps: 0.026976299000728766\n","Training loss per 100 training steps: 0.03100795813011404\n","Training loss per 100 training steps: 0.029607897319991847\n","Training loss per 100 training steps: 0.027233921161689042\n","Training loss per 100 training steps: 0.025798436404022754\n","Training loss per 100 training steps: 0.02594608672683014\n","Training loss per 100 training steps: 0.02635109349564628\n","Training loss per 100 training steps: 0.02599801702446539\n","Training loss per 100 training steps: 0.026698368155899054\n","Training loss epoch: 0.026674678644243006\n","Training accuracy epoch: 0.9918511951765961\n","Validating model...\n","Validation Loss: 0.217457955666854\n","Validation Accuracy: 0.9538356942254383\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00843052938580513\n","Training loss per 100 training steps: 0.01802902320073687\n","Training loss per 100 training steps: 0.018404142564627114\n","Training loss per 100 training steps: 0.01861027101732781\n","Training loss per 100 training steps: 0.018652911650488952\n","Training loss per 100 training steps: 0.018395797529073336\n","Training loss per 100 training steps: 0.01837616036891102\n","Training loss per 100 training steps: 0.01813809291044278\n","Training loss per 100 training steps: 0.01805076829648865\n","Training loss per 100 training steps: 0.018544925444897165\n","Training loss epoch: 0.019362220383899956\n","Training accuracy epoch: 0.9942923438169197\n","Validating model...\n","Validation Loss: 0.21792466890719997\n","Validation Accuracy: 0.9516716741707145\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 109.25675700000016 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1824292140911523\n","Validation Accuracy: 0.947406595289703\n","Validation duration: 6.134990850000031 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.82      0.81     12546\n","        test       0.79      0.85      0.82      9012\n","   treatment       0.80      0.86      0.83      9297\n","\n","   micro avg       0.80      0.84      0.82     30855\n","   macro avg       0.80      0.84      0.82     30855\n","weighted avg       0.80      0.84      0.82     30855\n","\n","!!!!!! Starting model number 8 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 31200\n","Points in y_train after augmentation: 31200\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.6290842294692993\n","Training loss per 100 training steps: 0.43154319272478026\n","Training loss per 100 training steps: 0.32211155696443067\n","Training loss per 100 training steps: 0.28027853292979277\n","Training loss per 100 training steps: 0.24787061154712317\n","Training loss per 100 training steps: 0.22472868732245502\n","Training loss per 100 training steps: 0.20930462874496936\n","Training loss per 100 training steps: 0.19709620126569577\n","Training loss per 100 training steps: 0.18542143043953827\n","Training loss per 100 training steps: 0.17592158193775473\n","Training loss epoch: 0.17038932331479512\n","Training accuracy epoch: 0.9455605080229784\n","Validating model...\n","Validation Loss: 0.14773308480908345\n","Validation Accuracy: 0.9541637258962086\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05305444821715355\n","Training loss per 100 training steps: 0.06775873847822152\n","Training loss per 100 training steps: 0.07066112743292134\n","Training loss per 100 training steps: 0.0659314374071221\n","Training loss per 100 training steps: 0.06617706145004293\n","Training loss per 100 training steps: 0.06559128655183934\n","Training loss per 100 training steps: 0.06481605869239063\n","Training loss per 100 training steps: 0.06454551019460048\n","Training loss per 100 training steps: 0.06347972613767477\n","Training loss per 100 training steps: 0.0645840502696548\n","Training loss epoch: 0.06388146332632273\n","Training accuracy epoch: 0.9793625594142769\n","Validating model...\n","Validation Loss: 0.1591347474483894\n","Validation Accuracy: 0.9557561621048088\n","Training epoch: 3\n","Training loss per 100 training steps: 0.05758870765566826\n","Training loss per 100 training steps: 0.0377956737930158\n","Training loss per 100 training steps: 0.03895752396856189\n","Training loss per 100 training steps: 0.03739351766923461\n","Training loss per 100 training steps: 0.03710559467805963\n","Training loss per 100 training steps: 0.036571423439011576\n","Training loss per 100 training steps: 0.036328223484340505\n","Training loss per 100 training steps: 0.03606752518693333\n","Training loss per 100 training steps: 0.0364260296494271\n","Training loss per 100 training steps: 0.03632154426000987\n","Training loss epoch: 0.03641176404718023\n","Training accuracy epoch: 0.9884670427269685\n","Validating model...\n","Validation Loss: 0.18929953481276313\n","Validation Accuracy: 0.9542774372233959\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01674109883606434\n","Training loss per 100 training steps: 0.02053178970051911\n","Training loss per 100 training steps: 0.02419990142378771\n","Training loss per 100 training steps: 0.022932744159732954\n","Training loss per 100 training steps: 0.0242780151992091\n","Training loss per 100 training steps: 0.023822954326645916\n","Training loss per 100 training steps: 0.0245737415832737\n","Training loss per 100 training steps: 0.02520836170368526\n","Training loss per 100 training steps: 0.025248901775009703\n","Training loss per 100 training steps: 0.025553170734560107\n","Training loss epoch: 0.025455922836927363\n","Training accuracy epoch: 0.9921127367311371\n","Validating model...\n","Validation Loss: 0.20512454506832284\n","Validation Accuracy: 0.9552395379087143\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0021510962396860123\n","Training loss per 100 training steps: 0.020945876587809314\n","Training loss per 100 training steps: 0.017038675827849934\n","Training loss per 100 training steps: 0.016961036750851848\n","Training loss per 100 training steps: 0.016976901250943643\n","Training loss per 100 training steps: 0.01888065704178463\n","Training loss per 100 training steps: 0.01893451910240486\n","Training loss per 100 training steps: 0.018887184179997796\n","Training loss per 100 training steps: 0.019199414117251304\n","Training loss per 100 training steps: 0.019325030171679337\n","Training loss epoch: 0.019440769309727237\n","Training accuracy epoch: 0.9940319478815104\n","Validating model...\n","Validation Loss: 0.24049618922464258\n","Validation Accuracy: 0.9536710979619769\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00501520000398159\n","Training loss per 100 training steps: 0.014065686451377218\n","Training loss per 100 training steps: 0.014513554169671304\n","Training loss per 100 training steps: 0.015194041343124281\n","Training loss per 100 training steps: 0.018234128956950067\n","Training loss per 100 training steps: 0.019883116582657644\n","Training loss per 100 training steps: 0.020008522421629097\n","Training loss per 100 training steps: 0.01920823480117835\n","Training loss per 100 training steps: 0.01954939618640429\n","Training loss per 100 training steps: 0.01961786704878018\n","Training loss epoch: 0.01955374054115218\n","Training accuracy epoch: 0.9939384927046667\n","Validating model...\n","Validation Loss: 0.2102294642139565\n","Validation Accuracy: 0.9565312866447482\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 109.2206670833332 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16134066067213468\n","Validation Accuracy: 0.9519194526497471\n","Validation duration: 6.130237450000035 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.83      0.82     12546\n","        test       0.81      0.88      0.85      9012\n","   treatment       0.83      0.85      0.84      9297\n","\n","   micro avg       0.82      0.85      0.83     30855\n","   macro avg       0.82      0.85      0.84     30855\n","weighted avg       0.82      0.85      0.83     30855\n","\n","!!!!!! Starting model number 9 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 31200\n","Points in y_train after augmentation: 31200\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9909809827804565\n","Training loss per 100 training steps: 0.455729132979223\n","Training loss per 100 training steps: 0.33004781894793556\n","Training loss per 100 training steps: 0.2808114918214934\n","Training loss per 100 training steps: 0.24732185016732264\n","Training loss per 100 training steps: 0.22617625339540418\n","Training loss per 100 training steps: 0.21081927507347156\n","Training loss per 100 training steps: 0.19789065594403618\n","Training loss per 100 training steps: 0.18829192379524423\n","Training loss per 100 training steps: 0.1801839185554067\n","Training loss epoch: 0.17377725943540914\n","Training accuracy epoch: 0.9442694823183722\n","Validating model...\n","Validation Loss: 0.14643035732306442\n","Validation Accuracy: 0.9540010683416699\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04928053915500641\n","Training loss per 100 training steps: 0.06598485336814186\n","Training loss per 100 training steps: 0.06781012346198903\n","Training loss per 100 training steps: 0.07067493224931119\n","Training loss per 100 training steps: 0.07183666345187256\n","Training loss per 100 training steps: 0.07411955621376068\n","Training loss per 100 training steps: 0.07298687208109161\n","Training loss per 100 training steps: 0.07206360283726228\n","Training loss per 100 training steps: 0.07188232435313485\n","Training loss per 100 training steps: 0.0702512770411574\n","Training loss epoch: 0.0688000222782676\n","Training accuracy epoch: 0.9778119716195208\n","Validating model...\n","Validation Loss: 0.1685083955526352\n","Validation Accuracy: 0.9559158105445252\n","Training epoch: 3\n","Training loss per 100 training steps: 0.044315654784440994\n","Training loss per 100 training steps: 0.03500854146510068\n","Training loss per 100 training steps: 0.03602300112052306\n","Training loss per 100 training steps: 0.036982959903702387\n","Training loss per 100 training steps: 0.03776789103469758\n","Training loss per 100 training steps: 0.039311466315210965\n","Training loss per 100 training steps: 0.03975718144401784\n","Training loss per 100 training steps: 0.040042662249410395\n","Training loss per 100 training steps: 0.04001354251769645\n","Training loss per 100 training steps: 0.03963807899350885\n","Training loss epoch: 0.040419740219576616\n","Training accuracy epoch: 0.9872858271846758\n","Validating model...\n","Validation Loss: 0.16867425058085422\n","Validation Accuracy: 0.9529020670198912\n","Training epoch: 4\n","Training loss per 100 training steps: 0.007506958208978176\n","Training loss per 100 training steps: 0.02664698981726081\n","Training loss per 100 training steps: 0.024872765085191942\n","Training loss per 100 training steps: 0.025003486863674713\n","Training loss per 100 training steps: 0.025370105789240423\n","Training loss per 100 training steps: 0.027955389433371242\n","Training loss per 100 training steps: 0.028438241901681968\n","Training loss per 100 training steps: 0.028429393840557794\n","Training loss per 100 training steps: 0.029497495543713986\n","Training loss per 100 training steps: 0.029619888576175542\n","Training loss epoch: 0.029380989805675852\n","Training accuracy epoch: 0.9907528229429539\n","Validating model...\n","Validation Loss: 0.1900767737564135\n","Validation Accuracy: 0.9568680148543596\n","Training epoch: 5\n","Training loss per 100 training steps: 0.006343455985188484\n","Training loss per 100 training steps: 0.01917022439803338\n","Training loss per 100 training steps: 0.018445038484566988\n","Training loss per 100 training steps: 0.024391598949414613\n","Training loss per 100 training steps: 0.02255635412437191\n","Training loss per 100 training steps: 0.021719176595251702\n","Training loss per 100 training steps: 0.02237760776856499\n","Training loss per 100 training steps: 0.02299381152958544\n","Training loss per 100 training steps: 0.022969805730707924\n","Training loss per 100 training steps: 0.022607036732777034\n","Training loss epoch: 0.022298726093095654\n","Training accuracy epoch: 0.9929226827182205\n","Validating model...\n","Validation Loss: 0.2207546296299665\n","Validation Accuracy: 0.954592961149905\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0013980395160615444\n","Training loss per 100 training steps: 0.013072906232595738\n","Training loss per 100 training steps: 0.013381368371736795\n","Training loss per 100 training steps: 0.013293596200004492\n","Training loss per 100 training steps: 0.014044168876557196\n","Training loss per 100 training steps: 0.01382725588374812\n","Training loss per 100 training steps: 0.01478472428283803\n","Training loss per 100 training steps: 0.015592842820967706\n","Training loss per 100 training steps: 0.01596883166301327\n","Training loss per 100 training steps: 0.016756900936887382\n","Training loss epoch: 0.01698828486382412\n","Training accuracy epoch: 0.994733065824582\n","Validating model...\n","Validation Loss: 0.2242999230209109\n","Validation Accuracy: 0.952192069042262\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 109.14284151666652 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16095005934066312\n","Validation Accuracy: 0.9529923973821519\n","Validation duration: 6.135707283333371 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.85      0.83     12546\n","        test       0.85      0.86      0.85      9012\n","   treatment       0.84      0.82      0.83      9297\n","\n","   micro avg       0.83      0.84      0.84     30855\n","   macro avg       0.84      0.84      0.84     30855\n","weighted avg       0.83      0.84      0.84     30855\n","\n","!!!!!! Starting model number 10 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 31200\n","Points in y_train after augmentation: 31200\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.266653060913086\n","Training loss per 100 training steps: 0.4333202676607831\n","Training loss per 100 training steps: 0.32166689426744755\n","Training loss per 100 training steps: 0.27194816704554814\n","Training loss per 100 training steps: 0.24220202801902396\n","Training loss per 100 training steps: 0.22354103518861854\n","Training loss per 100 training steps: 0.21062800227765135\n","Training loss per 100 training steps: 0.19690639210782532\n","Training loss per 100 training steps: 0.18719540246891395\n","Training loss per 100 training steps: 0.17913982640749276\n","Training loss epoch: 0.173078011077566\n","Training accuracy epoch: 0.9441146829446676\n","Validating model...\n","Validation Loss: 0.14508521491540716\n","Validation Accuracy: 0.9563928491574324\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06260711699724197\n","Training loss per 100 training steps: 0.07328938943619775\n","Training loss per 100 training steps: 0.06805175129991414\n","Training loss per 100 training steps: 0.06796459850555045\n","Training loss per 100 training steps: 0.06674342918061092\n","Training loss per 100 training steps: 0.06562266863572101\n","Training loss per 100 training steps: 0.06635183296336819\n","Training loss per 100 training steps: 0.06703438021716915\n","Training loss per 100 training steps: 0.0669156280750253\n","Training loss per 100 training steps: 0.06666768324710264\n","Training loss epoch: 0.06702523234109276\n","Training accuracy epoch: 0.9786504924177808\n","Validating model...\n","Validation Loss: 0.16074959029044425\n","Validation Accuracy: 0.9565589614342899\n","Training epoch: 3\n","Training loss per 100 training steps: 0.10244949907064438\n","Training loss per 100 training steps: 0.0316417035750473\n","Training loss per 100 training steps: 0.03680549199004838\n","Training loss per 100 training steps: 0.03642941101499063\n","Training loss per 100 training steps: 0.03813740825762466\n","Training loss per 100 training steps: 0.03915146846317699\n","Training loss per 100 training steps: 0.039522497573233645\n","Training loss per 100 training steps: 0.03950487507873224\n","Training loss per 100 training steps: 0.040012369806571316\n","Training loss per 100 training steps: 0.04025654534441827\n","Training loss epoch: 0.0399785984110517\n","Training accuracy epoch: 0.9871798122677125\n","Validating model...\n","Validation Loss: 0.18538084011766817\n","Validation Accuracy: 0.9547102967102388\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03103248029947281\n","Training loss per 100 training steps: 0.022581684730467524\n","Training loss per 100 training steps: 0.02288853052357184\n","Training loss per 100 training steps: 0.024253380453551306\n","Training loss per 100 training steps: 0.02538561152074802\n","Training loss per 100 training steps: 0.026596059913035045\n","Training loss per 100 training steps: 0.02745398427026591\n","Training loss per 100 training steps: 0.027484507476658523\n","Training loss per 100 training steps: 0.027779320662448207\n","Training loss per 100 training steps: 0.028268258999924606\n","Training loss epoch: 0.028458085673956725\n","Training accuracy epoch: 0.9911185528044348\n","Validating model...\n","Validation Loss: 0.21721570242147942\n","Validation Accuracy: 0.9521866404011318\n","Training epoch: 5\n","Training loss per 100 training steps: 0.007486744783818722\n","Training loss per 100 training steps: 0.01864461639278227\n","Training loss per 100 training steps: 0.018796320054483187\n","Training loss per 100 training steps: 0.018179183705954307\n","Training loss per 100 training steps: 0.019534019562891893\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 2\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"Zjhn7-LqHri0"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["c3cb5bc506084541acd5f4844b5209b7","3bcd6b75235d43a390b64a26303d4f4d","4b4306c3de574a77854ca31efd0084a0","158c9ebd0fd44b0fa1c6bf8b24b835d2","e79cb1e88a6044c5847250da8d6001de","454c11066f324cb8a57c8efea20b1cf5","27320f94ab354b4a965e64f022534c86","0bbc252e28fd457fab8b0aaa44b49cc4","7fb68a2aa2e64257879bbc049b18ce17","e266d74215ed41368b7f88a4c0eef24b","b1701d9b189c41ec827f2a12782825ea"]},"executionInfo":{"elapsed":7451878,"status":"ok","timestamp":1667898533055,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"fAbAcoasBHIb","outputId":"0fcd0a52-6411-4097-ba8d-faa353638760"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 200% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c3cb5bc506084541acd5f4844b5209b7","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 31200\n","Points in y_train after augmentation: 31200\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1261544227600098\n","Training loss per 100 training steps: 0.44551036381485437\n","Training loss per 100 training steps: 0.32922619377350926\n","Training loss per 100 training steps: 0.28081401109546916\n","Training loss per 100 training steps: 0.25195988460892155\n","Training loss per 100 training steps: 0.23028029155677665\n","Training loss per 100 training steps: 0.21370357789483524\n","Training loss per 100 training steps: 0.20122604691071408\n","Training loss per 100 training steps: 0.1908741547934218\n","Training loss per 100 training steps: 0.1810736194207487\n","Training loss epoch: 0.1757974060987815\n","Training accuracy epoch: 0.9436325271626983\n","Validating model...\n","Validation Loss: 0.1513457153621432\n","Validation Accuracy: 0.9540244444409476\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06284678727388382\n","Training loss per 100 training steps: 0.06812075665681669\n","Training loss per 100 training steps: 0.06782813860446363\n","Training loss per 100 training steps: 0.06586854495386596\n","Training loss per 100 training steps: 0.06681450648335485\n","Training loss per 100 training steps: 0.06723500155432971\n","Training loss per 100 training steps: 0.06685350736457477\n","Training loss per 100 training steps: 0.06772121093162839\n","Training loss per 100 training steps: 0.06712152757978394\n","Training loss per 100 training steps: 0.06601630304485237\n","Training loss epoch: 0.06565819981221396\n","Training accuracy epoch: 0.9787119098523392\n","Validating model...\n","Validation Loss: 0.16575272161174903\n","Validation Accuracy: 0.9578079579718951\n","Training epoch: 3\n","Training loss per 100 training steps: 0.05514654144644737\n","Training loss per 100 training steps: 0.029106071617657152\n","Training loss per 100 training steps: 0.032357567447511046\n","Training loss per 100 training steps: 0.033302095946871314\n","Training loss per 100 training steps: 0.034853039917877485\n","Training loss per 100 training steps: 0.03785289616599129\n","Training loss per 100 training steps: 0.040373733754931466\n","Training loss per 100 training steps: 0.04049163753500264\n","Training loss per 100 training steps: 0.03995618055058357\n","Training loss per 100 training steps: 0.03999913379898322\n","Training loss epoch: 0.0397313277129657\n","Training accuracy epoch: 0.9872968212026729\n","Validating model...\n","Validation Loss: 0.18301672074193884\n","Validation Accuracy: 0.956113066787247\n","Training epoch: 4\n","Training loss per 100 training steps: 0.011128266341984272\n","Training loss per 100 training steps: 0.020542548844904297\n","Training loss per 100 training steps: 0.021607502375784984\n","Training loss per 100 training steps: 0.022953137579804096\n","Training loss per 100 training steps: 0.0249740519303076\n","Training loss per 100 training steps: 0.02563582869021672\n","Training loss per 100 training steps: 0.02648838417652604\n","Training loss per 100 training steps: 0.02648237962312279\n","Training loss per 100 training steps: 0.025878840515310975\n","Training loss per 100 training steps: 0.026428106285892136\n","Training loss epoch: 0.026484257732159816\n","Training accuracy epoch: 0.9916543499315704\n","Validating model...\n","Validation Loss: 0.18723691548765092\n","Validation Accuracy: 0.9571544577386948\n","Training epoch: 5\n","Training loss per 100 training steps: 0.009956542402505875\n","Training loss per 100 training steps: 0.016761964453859163\n","Training loss per 100 training steps: 0.019511872279024522\n","Training loss per 100 training steps: 0.018963558871053048\n","Training loss per 100 training steps: 0.02000378924517769\n","Training loss per 100 training steps: 0.02009074801152494\n","Training loss per 100 training steps: 0.020174637230476536\n","Training loss per 100 training steps: 0.02029739362684234\n","Training loss per 100 training steps: 0.019962910522567864\n","Training loss per 100 training steps: 0.019794586976911548\n","Training loss epoch: 0.020180689567425407\n","Training accuracy epoch: 0.9936959549099298\n","Validating model...\n","Validation Loss: 0.21767284201046863\n","Validation Accuracy: 0.9541579850998517\n","Training epoch: 6\n","Training loss per 100 training steps: 0.011902834288775921\n","Training loss per 100 training steps: 0.012928863504952244\n","Training loss per 100 training steps: 0.013211424041722451\n","Training loss per 100 training steps: 0.01388584130654031\n","Training loss per 100 training steps: 0.017895801130164313\n","Training loss per 100 training steps: 0.019477891503366644\n","Training loss per 100 training steps: 0.0192883958727797\n","Training loss per 100 training steps: 0.019997494570251965\n","Training loss per 100 training steps: 0.020491785522563134\n","Training loss per 100 training steps: 0.02086227458421571\n","Training loss epoch: 0.021023517912373137\n","Training accuracy epoch: 0.9936826566157044\n","Validating model...\n","Validation Loss: 0.22939544489195982\n","Validation Accuracy: 0.9523392902580762\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 103.65052276666667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.17273518226230172\n","Validation Accuracy: 0.9493350256766592\n","Validation duration: 5.6796122666666635 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 81.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.83      0.81     12546\n","        test       0.78      0.84      0.81      9012\n","   treatment       0.82      0.84      0.83      9297\n","\n","   micro avg       0.80      0.83      0.82     30855\n","   macro avg       0.80      0.83      0.82     30855\n","weighted avg       0.80      0.83      0.82     30855\n","\n"]}],"source":["number_of_training_models = 1\n","target_augmented_percentage = 2\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"fAbAcoasBHIb"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TTDq-xbgHqXQ","outputId":"e1ae45f2-6fff-489b-e8d8-949796bb3fc4"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 500% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 62400\n","Points in y_train after augmentation: 62400\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.6540045738220215\n","Training loss per 100 training steps: 0.4065857616686585\n","Training loss per 100 training steps: 0.30610338053596553\n","Training loss per 100 training steps: 0.2658394600490597\n","Training loss per 100 training steps: 0.23768314207321092\n","Training loss per 100 training steps: 0.21955906752192095\n","Training loss per 100 training steps: 0.20419033363263142\n","Training loss per 100 training steps: 0.192145916602751\n","Training loss per 100 training steps: 0.18177064262172404\n","Training loss per 100 training steps: 0.1732605036707816\n","Training loss per 100 training steps: 0.16600010614213231\n","Training loss per 100 training steps: 0.15962059623295344\n","Training loss per 100 training steps: 0.15480177133164982\n","Training loss per 100 training steps: 0.14942943503425887\n","Training loss per 100 training steps: 0.14495510601509712\n","Training loss per 100 training steps: 0.14071279245960483\n","Training loss per 100 training steps: 0.1366277556001982\n","Training loss per 100 training steps: 0.13285188097287756\n","Training loss per 100 training steps: 0.12980524358856205\n","Training loss per 100 training steps: 0.12697014441201243\n","Training loss epoch: 0.12582657121312923\n","Training accuracy epoch: 0.9592702921737281\n","Validating model...\n","Validation Loss: 0.16137577907799125\n","Validation Accuracy: 0.9539744180617392\n","Training epoch: 2\n","Training loss per 100 training steps: 0.040315669029951096\n","Training loss per 100 training steps: 0.05135934690179506\n","Training loss per 100 training steps: 0.04887291466335381\n","Training loss per 100 training steps: 0.04805336919678158\n","Training loss per 100 training steps: 0.04780170090491895\n","Training loss per 100 training steps: 0.047196676870975306\n","Training loss per 100 training steps: 0.046171166261149796\n","Training loss per 100 training steps: 0.04711774960273183\n","Training loss per 100 training steps: 0.04698110603815765\n","Training loss per 100 training steps: 0.046778411871146876\n","Training loss per 100 training steps: 0.04606811803431584\n","Training loss per 100 training steps: 0.045965707769108216\n","Training loss per 100 training steps: 0.045976211888782315\n","Training loss per 100 training steps: 0.045290562795077115\n","Training loss per 100 training steps: 0.04470937717493243\n","Training loss per 100 training steps: 0.04467052308349888\n","Training loss per 100 training steps: 0.04418028866690988\n","Training loss per 100 training steps: 0.04442017126973797\n","Training loss per 100 training steps: 0.04413017819808545\n","Training loss per 100 training steps: 0.043529172236090534\n","Training loss epoch: 0.04330383585198806\n","Training accuracy epoch: 0.9859152147828238\n","Validating model...\n","Validation Loss: 0.22199565530210347\n","Validation Accuracy: 0.9462919448561347\n","Training epoch: 3\n","Training loss per 100 training steps: 0.013501420617103577\n","Training loss per 100 training steps: 0.024863932478831768\n","Training loss per 100 training steps: 0.02530904301727163\n","Training loss per 100 training steps: 0.023506881644410945\n","Training loss per 100 training steps: 0.024207076582096126\n","Training loss per 100 training steps: 0.02410807569711999\n","Training loss per 100 training steps: 0.024377217020617858\n","Training loss per 100 training steps: 0.02458545059621993\n","Training loss per 100 training steps: 0.02464435020268089\n","Training loss per 100 training steps: 0.024495023172428847\n","Training loss per 100 training steps: 0.02454160149859313\n","Training loss per 100 training steps: 0.02423502961092237\n","Training loss per 100 training steps: 0.02433832971739554\n","Training loss per 100 training steps: 0.024010128989102725\n","Training loss per 100 training steps: 0.024214620657658555\n","Training loss per 100 training steps: 0.024335110350864858\n","Training loss per 100 training steps: 0.0246494177945834\n","Training loss per 100 training steps: 0.02486106655513553\n","Training loss per 100 training steps: 0.025037074451673354\n","Training loss per 100 training steps: 0.024992583414878592\n","Training loss epoch: 0.02525830737719587\n","Training accuracy epoch: 0.9920997596585861\n","Validating model...\n","Validation Loss: 0.22359578032651312\n","Validation Accuracy: 0.9483148004432506\n","Training epoch: 4\n","Training loss per 100 training steps: 0.006155576091259718\n","Training loss per 100 training steps: 0.02530374612179723\n","Training loss per 100 training steps: 0.02270515581687903\n","Training loss per 100 training steps: 0.021707601182354597\n","Training loss per 100 training steps: 0.021847349818867916\n","Training loss per 100 training steps: 0.022057809419892802\n","Training loss per 100 training steps: 0.020965838136954136\n","Training loss per 100 training steps: 0.021273222641312595\n","Training loss per 100 training steps: 0.020894694296501\n","Training loss per 100 training steps: 0.020696063627628197\n","Training loss per 100 training steps: 0.02035808803439331\n","Training loss per 100 training steps: 0.020329482202832316\n","Training loss per 100 training steps: 0.020034445907047144\n","Training loss per 100 training steps: 0.02006266347984173\n","Training loss per 100 training steps: 0.02000032863852448\n","Training loss per 100 training steps: 0.019845728876953277\n","Training loss per 100 training steps: 0.019762520380458868\n","Training loss per 100 training steps: 0.019664988532116724\n","Training loss per 100 training steps: 0.019679346809472083\n","Training loss per 100 training steps: 0.01968728670646807\n","Stopping epoch...\n","Training loss epoch: 0.01968728670646807\n","Training accuracy epoch: 0.9933065809014804\n","Validating model...\n","Validation Loss: 0.26384704516499075\n","Validation Accuracy: 0.9476454685807303\n","Training epoch: 5\n","Training loss per 100 training steps: 0.013689044862985611\n","Training loss per 100 training steps: 0.011960687412013586\n","Training loss per 100 training steps: 0.010536012414377183\n","Training loss per 100 training steps: 0.011404977245909931\n","Training loss per 100 training steps: 0.012162138046168414\n","Training loss per 100 training steps: 0.011714404887515593\n","Training loss per 100 training steps: 0.01160471765182102\n","Training loss per 100 training steps: 0.011421496179931333\n","Training loss per 100 training steps: 0.011887044947348492\n","Training loss per 100 training steps: 0.012598380615759526\n","Training loss per 100 training steps: 0.013280376231974245\n","Training loss per 100 training steps: 0.013846510116711511\n","Training loss per 100 training steps: 0.013972171108090287\n","Training loss per 100 training steps: 0.014184593886271588\n","Training loss per 100 training steps: 0.014411213591072123\n","Training loss per 100 training steps: 0.01443884587182175\n","Training loss per 100 training steps: 0.014400131158398518\n","Training loss per 100 training steps: 0.014306650870116367\n","Training loss per 100 training steps: 0.01442119801297863\n","Stopping epoch...\n","Training loss epoch: 0.01442119801297863\n","Training accuracy epoch: 0.9949139784024382\n","Validating model...\n","Validation Loss: 0.26205461356159926\n","Validation Accuracy: 0.9479917511907516\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0011313649592921138\n","Training loss per 100 training steps: 0.011329133205039721\n","Training loss per 100 training steps: 0.01036474395636585\n","Training loss per 100 training steps: 0.01086857421242437\n","Training loss per 100 training steps: 0.012119668672915706\n","Training loss per 100 training steps: 0.012939623096481917\n","Training loss per 100 training steps: 0.012996711461433285\n","Training loss per 100 training steps: 0.013570730960002891\n","Training loss per 100 training steps: 0.013595915539124771\n","Training loss per 100 training steps: 0.013828232987287954\n","Training loss per 100 training steps: 0.0138766247552406\n","Training loss per 100 training steps: 0.013423182669289298\n","Training loss per 100 training steps: 0.013901013834477087\n","Training loss per 100 training steps: 0.013728880932849265\n","Training loss per 100 training steps: 0.013539215630791775\n","Training loss per 100 training steps: 0.013532547087352837\n","Training loss per 100 training steps: 0.013685432883815506\n","Training loss per 100 training steps: 0.013739998639213359\n","Training loss per 100 training steps: 0.01380435462871486\n","Training loss per 100 training steps: 0.01388843500509368\n","Training loss epoch: 0.013856016766594854\n","Training accuracy epoch: 0.9957371742286123\n","Validating model...\n","Validation Loss: 0.30508594103641323\n","Validation Accuracy: 0.9432224435603969\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 201.3503502 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1802756631320032\n","Validation Accuracy: 0.950664966587224\n","Validation duration: 5.66544529999998 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 81.9%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.82      0.81     12546\n","        test       0.83      0.86      0.85      9012\n","   treatment       0.79      0.82      0.81      9297\n","\n","   micro avg       0.81      0.83      0.82     30855\n","   macro avg       0.81      0.83      0.82     30855\n","weighted avg       0.81      0.83      0.82     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 62400\n","Points in y_train after augmentation: 62400\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0041513442993164\n","Training loss per 100 training steps: 0.4063350582624426\n","Training loss per 100 training steps: 0.30779593315587117\n","Training loss per 100 training steps: 0.2594040986088621\n","Training loss per 100 training steps: 0.23316101416332316\n","Training loss per 100 training steps: 0.2147116498415639\n","Training loss per 100 training steps: 0.20130838079071184\n","Training loss per 100 training steps: 0.19036751855085052\n","Training loss per 100 training steps: 0.18082821879596375\n","Training loss per 100 training steps: 0.17263149704316944\n","Training loss per 100 training steps: 0.1654274810875927\n","Training loss per 100 training steps: 0.15868875462913734\n","Training loss per 100 training steps: 0.15369200862581212\n","Training loss per 100 training steps: 0.148893263261854\n","Training loss per 100 training steps: 0.1439246382719859\n","Training loss per 100 training steps: 0.13947392292730237\n","Training loss per 100 training steps: 0.13549120312057514\n","Training loss per 100 training steps: 0.1316862430361629\n","Training loss per 100 training steps: 0.12786822404111553\n","Training loss per 100 training steps: 0.12447917807395563\n","Training loss epoch: 0.1228008779957413\n","Training accuracy epoch: 0.9601585313706654\n","Validating model...\n","Validation Loss: 0.17653544150389633\n","Validation Accuracy: 0.9537781447338597\n","Training epoch: 2\n","Training loss per 100 training steps: 0.026393599808216095\n","Training loss per 100 training steps: 0.049405610778986815\n","Training loss per 100 training steps: 0.046458796398779055\n","Training loss per 100 training steps: 0.04657540317049306\n","Training loss per 100 training steps: 0.04863485683248079\n","Training loss per 100 training steps: 0.04825915059236486\n","Training loss per 100 training steps: 0.04721317494934279\n","Training loss per 100 training steps: 0.04671155261613173\n","Training loss per 100 training steps: 0.04572723587433088\n","Training loss per 100 training steps: 0.045075555770791295\n","Training loss per 100 training steps: 0.04411694468229313\n","Training loss per 100 training steps: 0.043862053355879636\n","Training loss per 100 training steps: 0.04392044605145605\n","Training loss per 100 training steps: 0.043311037150316145\n","Training loss per 100 training steps: 0.042489922239174596\n","Training loss per 100 training steps: 0.04278523958648625\n","Training loss per 100 training steps: 0.04257285505298206\n","Training loss per 100 training steps: 0.04208151029525812\n","Training loss per 100 training steps: 0.041863694502483395\n","Training loss per 100 training steps: 0.041837996572720526\n","Training loss epoch: 0.041772329956890106\n","Training accuracy epoch: 0.9866163502295641\n","Validating model...\n","Validation Loss: 0.20551026506083353\n","Validation Accuracy: 0.9497632054805367\n","Training epoch: 3\n","Training loss per 100 training steps: 0.07668261975049973\n","Training loss per 100 training steps: 0.025837265688114532\n","Training loss per 100 training steps: 0.02475079903969847\n","Training loss per 100 training steps: 0.023829085875358248\n","Training loss per 100 training steps: 0.024144189361136804\n","Training loss per 100 training steps: 0.023303724461032484\n","Training loss per 100 training steps: 0.02349660884644743\n","Training loss per 100 training steps: 0.02427607939825041\n","Training loss per 100 training steps: 0.024613772214450796\n","Training loss per 100 training steps: 0.024350328653633232\n","Training loss per 100 training steps: 0.024917115787877798\n","Training loss per 100 training steps: 0.025080496208343846\n","Training loss per 100 training steps: 0.02521942293150839\n","Training loss per 100 training steps: 0.02528613057464639\n","Training loss per 100 training steps: 0.025180211999678955\n","Training loss per 100 training steps: 0.02591318192668098\n","Training loss per 100 training steps: 0.026117725365505502\n","Training loss per 100 training steps: 0.026484098652819022\n","Training loss per 100 training steps: 0.02669385964346161\n","Training loss per 100 training steps: 0.02676704226170462\n","Training loss epoch: 0.02680000669352758\n","Training accuracy epoch: 0.9916422972718932\n","Validating model...\n","Validation Loss: 0.26467753845182335\n","Validation Accuracy: 0.9446795918249776\n","Training epoch: 4\n","Training loss per 100 training steps: 0.048175420612096786\n","Training loss per 100 training steps: 0.022950958348188253\n","Training loss per 100 training steps: 0.021712042155863243\n","Training loss per 100 training steps: 0.021579482699388582\n","Training loss per 100 training steps: 0.021797149386396285\n","Training loss per 100 training steps: 0.021347803743709502\n","Training loss per 100 training steps: 0.021003949721676983\n","Training loss per 100 training steps: 0.02030525299606376\n","Training loss per 100 training steps: 0.01989331417929959\n","Training loss per 100 training steps: 0.019587245831010475\n","Training loss per 100 training steps: 0.019989768797446825\n","Training loss per 100 training steps: 0.020044464921139114\n","Training loss per 100 training steps: 0.019718264747915253\n","Training loss per 100 training steps: 0.019752874051260624\n","Training loss per 100 training steps: 0.019844180279936365\n","Training loss per 100 training steps: 0.019942276779531056\n","Training loss per 100 training steps: 0.019670429763732174\n","Training loss per 100 training steps: 0.01980641771834122\n","Training loss per 100 training steps: 0.019801783262533387\n","Training loss per 100 training steps: 0.019526270989268978\n","Training loss epoch: 0.019593589445292495\n","Training accuracy epoch: 0.9938834149984295\n","Validating model...\n","Validation Loss: 0.27550152089301644\n","Validation Accuracy: 0.9466095047786985\n","Training epoch: 5\n","Training loss per 100 training steps: 0.23778477311134338\n","Training loss per 100 training steps: 0.019254748972875095\n","Training loss per 100 training steps: 0.01680749188601827\n","Training loss per 100 training steps: 0.015629934175524\n","Training loss per 100 training steps: 0.014336559109208627\n","Training loss per 100 training steps: 0.014457881477171836\n","Training loss per 100 training steps: 0.015309031897526856\n","Training loss per 100 training steps: 0.01518508181542297\n","Training loss per 100 training steps: 0.015162643393615439\n","Training loss per 100 training steps: 0.015051899424460913\n","Training loss per 100 training steps: 0.015818844085135803\n","Training loss per 100 training steps: 0.015571638904823321\n","Training loss per 100 training steps: 0.015959211292354912\n","Training loss per 100 training steps: 0.016607947223127653\n","Training loss per 100 training steps: 0.016339445288972694\n","Training loss per 100 training steps: 0.01610752333176912\n","Training loss per 100 training steps: 0.016091099190775848\n","Training loss per 100 training steps: 0.01617131137850583\n","Training loss per 100 training steps: 0.016158490226846314\n","Training loss per 100 training steps: 0.016239242930431164\n","Stopping epoch...\n","Training loss epoch: 0.016239242930431164\n","Training accuracy epoch: 0.9945327372095044\n","Validating model...\n","Validation Loss: 0.25137902409225316\n","Validation Accuracy: 0.9517716794495551\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00766019755974412\n","Training loss per 100 training steps: 0.009585915307403717\n","Training loss per 100 training steps: 0.009442900601121138\n","Training loss per 100 training steps: 0.008992529214053118\n","Training loss per 100 training steps: 0.009186302314657878\n","Training loss per 100 training steps: 0.00878215633170538\n","Training loss per 100 training steps: 0.00946944846803909\n","Training loss per 100 training steps: 0.010547510381827375\n","Training loss per 100 training steps: 0.010845101730645571\n","Training loss per 100 training steps: 0.010573005691538543\n","Training loss per 100 training steps: 0.011016621830311817\n","Training loss per 100 training steps: 0.011124979299081293\n","Training loss per 100 training steps: 0.011315034716705587\n","Training loss per 100 training steps: 0.011461785936519718\n","Training loss per 100 training steps: 0.011647217482803965\n","Training loss per 100 training steps: 0.011680852096170037\n","Training loss per 100 training steps: 0.012266106041172519\n","Training loss per 100 training steps: 0.012411918668631098\n","Training loss per 100 training steps: 0.012699651923629497\n","Training loss per 100 training steps: 0.012771881052897251\n","Training loss epoch: 0.01280628819153674\n","Training accuracy epoch: 0.9961528791105512\n","Validating model...\n","Validation Loss: 0.31052420464912794\n","Validation Accuracy: 0.945413553474216\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 203.5021023999999 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.2024784281233291\n","Validation Accuracy: 0.9486332418645854\n","Validation duration: 5.671484266666569 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.9%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.81      0.81     12546\n","        test       0.84      0.88      0.86      9012\n","   treatment       0.84      0.81      0.82      9297\n","\n","   micro avg       0.83      0.83      0.83     30855\n","   macro avg       0.83      0.83      0.83     30855\n","weighted avg       0.83      0.83      0.83     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 62400\n","Points in y_train after augmentation: 62400\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0838260650634766\n","Training loss per 100 training steps: 0.41825438445747487\n","Training loss per 100 training steps: 0.3154777241361082\n","Training loss per 100 training steps: 0.2679014778216416\n","Training loss per 100 training steps: 0.24309317875384095\n","Training loss per 100 training steps: 0.221858055763943\n","Training loss per 100 training steps: 0.20624696559113095\n","Training loss per 100 training steps: 0.19440933655729561\n","Training loss per 100 training steps: 0.18573025929114867\n","Training loss per 100 training steps: 0.17746007205147324\n","Training loss per 100 training steps: 0.17003604825902413\n","Training loss per 100 training steps: 0.16366572863676945\n","Training loss per 100 training steps: 0.15764854309753168\n","Training loss per 100 training steps: 0.1527583322571526\n","Training loss per 100 training steps: 0.14834306025937424\n","Training loss per 100 training steps: 0.14361136300125713\n","Training loss per 100 training steps: 0.13977320619197395\n","Training loss per 100 training steps: 0.13608731855109973\n","Training loss per 100 training steps: 0.13254463318363038\n","Training loss per 100 training steps: 0.12974115045371806\n","Training loss epoch: 0.12792164713239823\n","Training accuracy epoch: 0.9585037192962194\n","Validating model...\n","Validation Loss: 0.17618426922466848\n","Validation Accuracy: 0.9520046617311219\n","Training epoch: 2\n","Training loss per 100 training steps: 0.035322826355695724\n","Training loss per 100 training steps: 0.04134434860402552\n","Training loss per 100 training steps: 0.043839802852002396\n","Training loss per 100 training steps: 0.04407781212702022\n","Training loss per 100 training steps: 0.04413872363540504\n","Training loss per 100 training steps: 0.04501921255020666\n","Training loss per 100 training steps: 0.045742659244962194\n","Training loss per 100 training steps: 0.04737407043702454\n","Training loss per 100 training steps: 0.04756861131146466\n","Training loss per 100 training steps: 0.04709220476904377\n","Training loss per 100 training steps: 0.0470208727717902\n","Training loss per 100 training steps: 0.04742007920214844\n","Training loss per 100 training steps: 0.04683371585581318\n","Training loss per 100 training steps: 0.0464952247268123\n","Training loss per 100 training steps: 0.04613995282138983\n","Training loss per 100 training steps: 0.046282057994747064\n","Training loss per 100 training steps: 0.045727213586085495\n","Training loss per 100 training steps: 0.04529002337726923\n","Training loss per 100 training steps: 0.04507221531805255\n","Training loss per 100 training steps: 0.04480663473578978\n","Training loss epoch: 0.0445787309246878\n","Training accuracy epoch: 0.9857669779917421\n","Validating model...\n","Validation Loss: 0.22865094515410336\n","Validation Accuracy: 0.9456307976820075\n","Training epoch: 3\n","Training loss per 100 training steps: 0.001893224660307169\n","Training loss per 100 training steps: 0.01899816268146739\n","Training loss per 100 training steps: 0.022579242702369665\n","Training loss per 100 training steps: 0.025210487988523742\n","Training loss per 100 training steps: 0.024911030843050366\n","Training loss per 100 training steps: 0.02422109470789148\n","Training loss per 100 training steps: 0.023866850788435416\n","Training loss per 100 training steps: 0.024295125712146357\n","Training loss per 100 training steps: 0.024329773156343264\n","Training loss per 100 training steps: 0.024346507013698917\n","Training loss per 100 training steps: 0.024638837421211514\n","Training loss per 100 training steps: 0.024661446693031917\n","Training loss per 100 training steps: 0.024371594502621614\n","Training loss per 100 training steps: 0.025093630087335696\n","Training loss per 100 training steps: 0.02560077227241919\n","Training loss per 100 training steps: 0.025981223184167394\n","Training loss per 100 training steps: 0.0262769903238836\n","Training loss per 100 training steps: 0.02642120101591375\n","Training loss per 100 training steps: 0.026316513258880826\n","Training loss per 100 training steps: 0.026487023301998487\n","Training loss epoch: 0.02668282827634054\n","Training accuracy epoch: 0.9917261466632289\n","Validating model...\n","Validation Loss: 0.24195347397358385\n","Validation Accuracy: 0.9426943007101245\n","Training epoch: 4\n","Training loss per 100 training steps: 0.05269287899136543\n","Training loss per 100 training steps: 0.028272483971587724\n","Training loss per 100 training steps: 0.02314772062636078\n","Training loss per 100 training steps: 0.02141884948007849\n","Training loss per 100 training steps: 0.0205759702186783\n","Training loss per 100 training steps: 0.020228927528639945\n","Training loss per 100 training steps: 0.020440754419837313\n","Training loss per 100 training steps: 0.020308364896107392\n","Training loss per 100 training steps: 0.02084172697334211\n","Training loss per 100 training steps: 0.020649577300502278\n","Training loss per 100 training steps: 0.02101779740836288\n","Training loss per 100 training steps: 0.02073521197885702\n","Training loss per 100 training steps: 0.020773866175448828\n","Training loss per 100 training steps: 0.020939605620411045\n","Training loss per 100 training steps: 0.020679123572592883\n","Training loss per 100 training steps: 0.020570216123186092\n","Training loss per 100 training steps: 0.020271976784397083\n","Training loss per 100 training steps: 0.020499926562594722\n","Training loss per 100 training steps: 0.020735595753326053\n","Training loss per 100 training steps: 0.020690093244596076\n","Training loss epoch: 0.020561060911292235\n","Training accuracy epoch: 0.9935965263522551\n","Validating model...\n","Validation Loss: 0.2940392554677152\n","Validation Accuracy: 0.9406688657536487\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0198651235550642\n","Training loss per 100 training steps: 0.019865301971630386\n","Stopping epoch...\n","Training loss epoch: 0.019865301971630386\n","Training accuracy epoch: 0.9835388071999106\n","Validating model...\n","Validation Loss: 0.29110427312069126\n","Validation Accuracy: 0.9432405329299477\n","Training epoch: 6\n","Training loss per 100 training steps: 0.005310628097504377\n","Training loss per 100 training steps: 0.016032187300411487\n","Training loss per 100 training steps: 0.017273753453729515\n","Training loss per 100 training steps: 0.01697068352931399\n","Training loss per 100 training steps: 0.015544250013583696\n","Training loss per 100 training steps: 0.016155314266074267\n","Training loss per 100 training steps: 0.016296307484709584\n","Training loss per 100 training steps: 0.015862039654768442\n","Training loss per 100 training steps: 0.015723075176341826\n","Training loss per 100 training steps: 0.015434723218961605\n","Training loss per 100 training steps: 0.015308366860927116\n","Training loss per 100 training steps: 0.015372250805037742\n","Training loss per 100 training steps: 0.01565010768970995\n","Training loss per 100 training steps: 0.015507494832380467\n","Training loss per 100 training steps: 0.016154946146978613\n","Training loss per 100 training steps: 0.01606429612811135\n","Training loss per 100 training steps: 0.016235578241128343\n","Training loss per 100 training steps: 0.016570057613214752\n","Training loss per 100 training steps: 0.016749578053524707\n","Training loss per 100 training steps: 0.016790297560888377\n","Training loss epoch: 0.016953017246366168\n","Training accuracy epoch: 0.9948652254433316\n","Validating model...\n","Validation Loss: 0.2582093459832204\n","Validation Accuracy: 0.9491315377563003\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 172.3935911833334 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.20052604824821982\n","Validation Accuracy: 0.9476394455849132\n","Validation duration: 5.666264166666709 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.80      0.81     12546\n","        test       0.85      0.85      0.85      9012\n","   treatment       0.77      0.85      0.81      9297\n","\n","   micro avg       0.81      0.83      0.82     30855\n","   macro avg       0.81      0.84      0.82     30855\n","weighted avg       0.81      0.83      0.82     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 62400\n","Points in y_train after augmentation: 62400\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.96686851978302\n","Training loss per 100 training steps: 0.4299387171274365\n","Training loss per 100 training steps: 0.31795149756159946\n","Training loss per 100 training steps: 0.27079779355232897\n","Training loss per 100 training steps: 0.24185124041507963\n","Training loss per 100 training steps: 0.2200481244539489\n","Training loss per 100 training steps: 0.20482140738895155\n","Training loss per 100 training steps: 0.1917728428328981\n","Training loss per 100 training steps: 0.182217578448997\n","Training loss per 100 training steps: 0.17311136923021286\n","Training loss per 100 training steps: 0.166241491533961\n","Training loss per 100 training steps: 0.1599582754719248\n","Training loss per 100 training steps: 0.15375983818774605\n","Training loss per 100 training steps: 0.14907371254600613\n","Training loss per 100 training steps: 0.14495577348055827\n","Training loss per 100 training steps: 0.14019004208098435\n","Training loss per 100 training steps: 0.13632484139271922\n","Training loss per 100 training steps: 0.1325551458592825\n","Training loss per 100 training steps: 0.1294156175278963\n","Training loss per 100 training steps: 0.126025842698433\n","Training loss epoch: 0.12450372238738988\n","Training accuracy epoch: 0.9595922970456591\n","Validating model...\n","Validation Loss: 0.17969751295137715\n","Validation Accuracy: 0.9539709914389883\n","Training epoch: 2\n","Training loss per 100 training steps: 0.040903568267822266\n","Training loss per 100 training steps: 0.04494453080939037\n","Training loss per 100 training steps: 0.047241683361301225\n","Training loss per 100 training steps: 0.04613452728070393\n","Training loss per 100 training steps: 0.045713299854038436\n","Training loss per 100 training steps: 0.0450326437781195\n","Training loss per 100 training steps: 0.04544054160782519\n","Training loss per 100 training steps: 0.04582404051894075\n","Training loss per 100 training steps: 0.04529603849137237\n","Training loss per 100 training steps: 0.045023698996200526\n","Training loss per 100 training steps: 0.04471504742341985\n","Training loss per 100 training steps: 0.04482511276424483\n","Training loss per 100 training steps: 0.044935329200651075\n","Training loss per 100 training steps: 0.04417428744448239\n","Training loss per 100 training steps: 0.0435266578364765\n","Training loss per 100 training steps: 0.042922857161881225\n","Training loss per 100 training steps: 0.04288690533803986\n","Training loss per 100 training steps: 0.04278294505601555\n","Training loss per 100 training steps: 0.04251681800396737\n","Training loss per 100 training steps: 0.0423596821288612\n","Training loss epoch: 0.04215856837801253\n","Training accuracy epoch: 0.9863226005971384\n","Validating model...\n","Validation Loss: 0.2036524639743102\n","Validation Accuracy: 0.9505895200547206\n","Training epoch: 3\n","Training loss per 100 training steps: 0.008954925462603569\n","Training loss per 100 training steps: 0.028141395525435115\n","Training loss per 100 training steps: 0.028549411882002333\n","Training loss per 100 training steps: 0.026994470767197246\n","Training loss per 100 training steps: 0.026352461473464716\n","Training loss per 100 training steps: 0.02574495144363608\n","Training loss per 100 training steps: 0.025764035520948834\n","Training loss per 100 training steps: 0.025909571024837017\n","Training loss per 100 training steps: 0.026314242878628224\n","Training loss per 100 training steps: 0.025984546016593186\n","Training loss per 100 training steps: 0.025476471431003036\n","Training loss per 100 training steps: 0.025467049514083486\n","Training loss per 100 training steps: 0.025548677008878595\n","Training loss per 100 training steps: 0.025761490947984626\n","Training loss per 100 training steps: 0.025822028263994184\n","Training loss per 100 training steps: 0.026055993541783846\n","Training loss per 100 training steps: 0.026083483922388056\n","Training loss per 100 training steps: 0.026013623229122564\n","Training loss per 100 training steps: 0.026138781405067996\n","Training loss per 100 training steps: 0.02620926986424951\n","Stopping epoch...\n","Training loss epoch: 0.02620926986424951\n","Training accuracy epoch: 0.9912115157499363\n","Validating model...\n","Validation Loss: 0.2481975768535555\n","Validation Accuracy: 0.9501006284762024\n","Training epoch: 4\n","Training loss per 100 training steps: 0.016370104625821114\n","Training loss per 100 training steps: 0.022286139021161944\n","Training loss per 100 training steps: 0.019665638198010364\n","Training loss per 100 training steps: 0.018235912049719846\n","Training loss per 100 training steps: 0.01902421530637486\n","Training loss per 100 training steps: 0.018284394995875457\n","Training loss per 100 training steps: 0.018295972974127942\n","Training loss per 100 training steps: 0.018772963969038266\n","Training loss per 100 training steps: 0.018929994666539645\n","Training loss per 100 training steps: 0.018961065863962023\n","Training loss per 100 training steps: 0.018595643292666626\n","Training loss per 100 training steps: 0.019174960661368853\n","Training loss per 100 training steps: 0.01942552837684613\n","Training loss per 100 training steps: 0.019446298848786788\n","Training loss per 100 training steps: 0.019289406076047722\n","Training loss per 100 training steps: 0.019204477836960537\n","Training loss per 100 training steps: 0.019125544323922158\n","Training loss per 100 training steps: 0.01905212501372399\n","Training loss per 100 training steps: 0.019157399757718564\n","Training loss per 100 training steps: 0.019317763577359776\n","Training loss epoch: 0.019619408190856353\n","Training accuracy epoch: 0.9937494899229617\n","Validating model...\n","Validation Loss: 0.28704176280744276\n","Validation Accuracy: 0.9416680118705976\n","Training epoch: 5\n","Training loss per 100 training steps: 0.022747935727238655\n","Training loss per 100 training steps: 0.020209975183323615\n","Training loss per 100 training steps: 0.016083478508575066\n","Training loss per 100 training steps: 0.017218830298510165\n","Training loss per 100 training steps: 0.018034402667306725\n","Training loss per 100 training steps: 0.017880466989959088\n","Training loss per 100 training steps: 0.01768614172216074\n","Training loss per 100 training steps: 0.017284040579927048\n","Training loss per 100 training steps: 0.016942893687508346\n","Training loss per 100 training steps: 0.016779591809980444\n","Training loss per 100 training steps: 0.016333210292262035\n","Training loss per 100 training steps: 0.01604250131167415\n","Training loss per 100 training steps: 0.01558830420708167\n","Training loss per 100 training steps: 0.015455124650483319\n","Training loss per 100 training steps: 0.015324437008847164\n","Training loss per 100 training steps: 0.015259676067628817\n","Training loss per 100 training steps: 0.015153437270592013\n","Training loss per 100 training steps: 0.015124403077896248\n","Training loss per 100 training steps: 0.015519436246548135\n","Training loss per 100 training steps: 0.015532542161950252\n","Training loss epoch: 0.015501998786475712\n","Training accuracy epoch: 0.9952176502289645\n","Validating model...\n","Validation Loss: 0.2523609895694566\n","Validation Accuracy: 0.9508539206275766\n","Training epoch: 6\n","Training loss per 100 training steps: 0.006808096542954445\n","Training loss per 100 training steps: 0.010727770449040403\n","Training loss per 100 training steps: 0.0121037685784363\n","Training loss per 100 training steps: 0.012851512427379894\n","Training loss per 100 training steps: 0.012336338499788557\n","Training loss per 100 training steps: 0.012492171047962254\n","Training loss per 100 training steps: 0.01235301200104428\n","Training loss per 100 training steps: 0.012138189149515793\n","Training loss per 100 training steps: 0.012486860649134835\n","Training loss per 100 training steps: 0.012577732471384436\n","Training loss per 100 training steps: 0.01308421738574909\n","Training loss per 100 training steps: 0.013847316429095632\n","Training loss per 100 training steps: 0.014168040267728152\n","Training loss per 100 training steps: 0.014392412747301646\n","Training loss per 100 training steps: 0.014692285668838527\n","Training loss per 100 training steps: 0.014601764101423786\n","Training loss per 100 training steps: 0.01443722933437697\n","Training loss per 100 training steps: 0.014357912929172968\n","Training loss per 100 training steps: 0.014273715348997844\n","Training loss per 100 training steps: 0.014229931558230595\n","Training loss epoch: 0.014159967353431663\n","Training accuracy epoch: 0.9956762460220699\n","Validating model...\n","Validation Loss: 0.2778867533938451\n","Validation Accuracy: 0.9469491025246357\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 203.31442601666666 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1997948742570804\n","Validation Accuracy: 0.9494424033834018\n","Validation duration: 5.672426149999955 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.82      0.81     12546\n","        test       0.84      0.84      0.84      9012\n","   treatment       0.80      0.82      0.81      9297\n","\n","   micro avg       0.81      0.83      0.82     30855\n","   macro avg       0.82      0.83      0.82     30855\n","weighted avg       0.82      0.83      0.82     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 62400\n","Points in y_train after augmentation: 62400\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9993983507156372\n","Training loss per 100 training steps: 0.4366023466728701\n","Training loss per 100 training steps: 0.319473397153527\n","Training loss per 100 training steps: 0.2739449853071343\n","Training loss per 100 training steps: 0.24466745251617825\n","Training loss per 100 training steps: 0.2260557073363644\n","Training loss per 100 training steps: 0.20981503191238235\n","Training loss per 100 training steps: 0.19938180380940607\n","Training loss per 100 training steps: 0.18818665532332457\n","Training loss per 100 training steps: 0.1799136157810159\n","Training loss per 100 training steps: 0.17226308843606597\n","Training loss per 100 training steps: 0.16520494575545422\n","Training loss per 100 training steps: 0.1601880842573215\n","Training loss per 100 training steps: 0.1558057280095562\n","Training loss per 100 training steps: 0.1503048932507533\n","Training loss per 100 training steps: 0.145551517436704\n","Training loss per 100 training steps: 0.14158314139408285\n","Training loss per 100 training steps: 0.13803721865395993\n","Training loss per 100 training steps: 0.13470095464171658\n","Training loss per 100 training steps: 0.13119516023133404\n","Training loss epoch: 0.12970432085558198\n","Training accuracy epoch: 0.9582396378059845\n","Validating model...\n","Validation Loss: 0.17067401764261259\n","Validation Accuracy: 0.9505983878344527\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06107253208756447\n","Training loss per 100 training steps: 0.05653930171900014\n","Training loss per 100 training steps: 0.055871737761821465\n","Training loss per 100 training steps: 0.05494149092219745\n","Training loss per 100 training steps: 0.054770760522676896\n","Training loss per 100 training steps: 0.053260935278062874\n","Training loss per 100 training steps: 0.05447109795784494\n","Training loss per 100 training steps: 0.05351055471609199\n","Training loss per 100 training steps: 0.05223135461858689\n","Training loss per 100 training steps: 0.05133667861015332\n","Training loss per 100 training steps: 0.05097121670358367\n","Training loss per 100 training steps: 0.04980238850971178\n","Training loss per 100 training steps: 0.048772698238633144\n","Training loss per 100 training steps: 0.04882294003623355\n","Training loss per 100 training steps: 0.04862051698838565\n","Training loss per 100 training steps: 0.04835359772529545\n","Training loss per 100 training steps: 0.0480104792446624\n","Training loss per 100 training steps: 0.04760981246609753\n","Training loss per 100 training steps: 0.04713526176621487\n","Training loss per 100 training steps: 0.04650225739102803\n","Training loss epoch: 0.0462247159720685\n","Training accuracy epoch: 0.9850945526869529\n","Validating model...\n","Validation Loss: 0.2057088056651803\n","Validation Accuracy: 0.9516544929713088\n","Training epoch: 3\n","Training loss per 100 training steps: 0.013147776946425438\n","Training loss per 100 training steps: 0.021275489506920302\n","Training loss per 100 training steps: 0.020637573127284998\n","Training loss per 100 training steps: 0.021577351155344312\n","Training loss per 100 training steps: 0.022296133972855372\n","Training loss per 100 training steps: 0.0228111324432174\n","Training loss per 100 training steps: 0.02323227752497522\n","Training loss per 100 training steps: 0.023602223261252855\n","Training loss per 100 training steps: 0.024432405226715095\n","Training loss per 100 training steps: 0.024553424655356457\n","Training loss per 100 training steps: 0.024885826120427536\n","Training loss per 100 training steps: 0.025614201687052203\n","Training loss per 100 training steps: 0.02618574750451503\n","Training loss per 100 training steps: 0.026741012426463318\n","Training loss per 100 training steps: 0.026940826410783335\n","Training loss per 100 training steps: 0.026788258246598463\n","Training loss per 100 training steps: 0.026720402778000068\n","Training loss per 100 training steps: 0.02673575641338394\n","Stopping epoch...\n","Training loss epoch: 0.02673575641338394\n","Training accuracy epoch: 0.9910832617447907\n","Validating model...\n","Validation Loss: 0.21343046349364442\n","Validation Accuracy: 0.9547735742386801\n","Training epoch: 4\n","Training loss per 100 training steps: 0.018899662420153618\n","Training loss per 100 training steps: 0.024023547104679712\n","Training loss per 100 training steps: 0.023449867512029942\n","Training loss per 100 training steps: 0.022997572862209003\n","Training loss per 100 training steps: 0.02477934584660256\n","Training loss per 100 training steps: 0.024604877439827588\n","Training loss per 100 training steps: 0.023901767786995147\n","Training loss per 100 training steps: 0.023399042849762422\n","Training loss per 100 training steps: 0.023069246061385777\n","Training loss per 100 training steps: 0.022719696650013315\n","Training loss per 100 training steps: 0.022815827514567354\n","Training loss per 100 training steps: 0.023118574633425884\n","Training loss per 100 training steps: 0.022675547824944173\n","Training loss per 100 training steps: 0.02251526449879826\n","Training loss per 100 training steps: 0.02266837963561024\n","Training loss per 100 training steps: 0.02235985406481169\n","Training loss per 100 training steps: 0.022415288421478084\n","Training loss per 100 training steps: 0.022123426963905884\n","Training loss per 100 training steps: 0.02195419409042245\n","Training loss per 100 training steps: 0.021913037599316225\n","Training loss epoch: 0.021874730576020785\n","Training accuracy epoch: 0.9932213652539177\n","Validating model...\n","Validation Loss: 0.26620494216293483\n","Validation Accuracy: 0.9490875562332757\n","Training epoch: 5\n","Training loss per 100 training steps: 0.023054540157318115\n","Training loss per 100 training steps: 0.020806182788495935\n","Training loss per 100 training steps: 0.01677345775128041\n","Training loss per 100 training steps: 0.016297050750778797\n","Training loss per 100 training steps: 0.015790444375201596\n","Training loss per 100 training steps: 0.01578443633760056\n","Training loss per 100 training steps: 0.016695362773275286\n","Training loss per 100 training steps: 0.016440012701405094\n","Training loss per 100 training steps: 0.016875425151481844\n","Training loss per 100 training steps: 0.017001792082455027\n","Training loss per 100 training steps: 0.016913416790024664\n","Training loss per 100 training steps: 0.017070966058039146\n","Training loss per 100 training steps: 0.017360997032644584\n","Training loss per 100 training steps: 0.01776798150741866\n","Training loss per 100 training steps: 0.018091909947992403\n","Training loss per 100 training steps: 0.018540650523381077\n","Training loss per 100 training steps: 0.018366691389967944\n","Training loss per 100 training steps: 0.01868119437699146\n","Training loss per 100 training steps: 0.018461879102352502\n","Training loss per 100 training steps: 0.018345671581188418\n","Training loss epoch: 0.018238066019153055\n","Training accuracy epoch: 0.994452922434492\n","Validating model...\n","Validation Loss: 0.27358486188890097\n","Validation Accuracy: 0.9445717913728523\n","Training epoch: 6\n","Training loss per 100 training steps: 0.005225500091910362\n","Training loss per 100 training steps: 0.013783685693870031\n","Training loss per 100 training steps: 0.014862034196614414\n","Training loss per 100 training steps: 0.014193414163435778\n","Training loss per 100 training steps: 0.013676797312736903\n","Training loss per 100 training steps: 0.01300507905849924\n","Training loss per 100 training steps: 0.013433060253916669\n","Training loss per 100 training steps: 0.013310563737258665\n","Training loss per 100 training steps: 0.013519977686426616\n","Training loss per 100 training steps: 0.0135544229570132\n","Training loss per 100 training steps: 0.013412147260000153\n","Training loss per 100 training steps: 0.013457842680020173\n","Training loss per 100 training steps: 0.013946256215912294\n","Training loss per 100 training steps: 0.014144019829337488\n","Training loss per 100 training steps: 0.014296498354689732\n","Training loss per 100 training steps: 0.014305741901938052\n","Training loss per 100 training steps: 0.014327421331573697\n","Training loss per 100 training steps: 0.014375934281189603\n","Training loss per 100 training steps: 0.014449927193752729\n","Training loss per 100 training steps: 0.014752637813668644\n","Training loss epoch: 0.014769885432294521\n","Training accuracy epoch: 0.9955108892983185\n","Validating model...\n","Validation Loss: 0.25743150759439964\n","Validation Accuracy: 0.9516857827843219\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 200.04576705000025 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.17744636612500203\n","Validation Accuracy: 0.9485775594997018\n","Validation duration: 5.689846583333322 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 81.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.77      0.84      0.80     12546\n","        test       0.80      0.87      0.83      9012\n","   treatment       0.79      0.85      0.82      9297\n","\n","   micro avg       0.78      0.85      0.82     30855\n","   macro avg       0.78      0.85      0.82     30855\n","weighted avg       0.78      0.85      0.82     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 62400\n","Points in y_train after augmentation: 62400\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.142627239227295\n","Training loss per 100 training steps: 0.43150881604097857\n","Training loss per 100 training steps: 0.32648647954659676\n","Training loss per 100 training steps: 0.2779046672325198\n","Training loss per 100 training steps: 0.24789427911068435\n","Training loss per 100 training steps: 0.22740002602576734\n","Training loss per 100 training steps: 0.21138140439565686\n","Training loss per 100 training steps: 0.19894112040755071\n","Training loss per 100 training steps: 0.1889224106029662\n","Training loss per 100 training steps: 0.1796021866203843\n","Training loss per 100 training steps: 0.1723759556458993\n","Training loss per 100 training steps: 0.16572039906818634\n","Training loss per 100 training steps: 0.1596284825153196\n","Training loss per 100 training steps: 0.15420769365915282\n","Training loss per 100 training steps: 0.1497000653767356\n","Training loss per 100 training steps: 0.14549062411231967\n","Training loss per 100 training steps: 0.140871887548427\n","Training loss per 100 training steps: 0.1371395369533938\n","Training loss per 100 training steps: 0.13317340764443059\n","Training loss per 100 training steps: 0.13015579926521212\n","Training loss epoch: 0.12857809798123362\n","Training accuracy epoch: 0.9584585514100934\n","Validating model...\n","Validation Loss: 0.1656151411014718\n","Validation Accuracy: 0.9545074890598051\n","Training epoch: 2\n","Training loss per 100 training steps: 0.03962201625108719\n","Training loss per 100 training steps: 0.04006289173895032\n","Training loss per 100 training steps: 0.04219286901695626\n","Training loss per 100 training steps: 0.04111733836465302\n","Training loss per 100 training steps: 0.040906995141813694\n","Training loss per 100 training steps: 0.04105528775266113\n","Training loss per 100 training steps: 0.04318003159925999\n","Training loss per 100 training steps: 0.044424910195631516\n","Training loss per 100 training steps: 0.044990432660005866\n","Training loss per 100 training steps: 0.04507582483127854\n","Training loss per 100 training steps: 0.044968740476135326\n","Training loss per 100 training steps: 0.04498555854835855\n","Training loss per 100 training steps: 0.04486915213482409\n","Stopping epoch...\n","Training loss epoch: 0.04486915213482409\n","Training accuracy epoch: 0.9846793616130113\n","Validating model...\n","Validation Loss: 0.19972266322727522\n","Validation Accuracy: 0.9474390670525682\n","Training epoch: 3\n","Training loss per 100 training steps: 0.003899624804034829\n","Training loss per 100 training steps: 0.033522647886195835\n","Training loss per 100 training steps: 0.03809765049149815\n","Training loss per 100 training steps: 0.037805817482924935\n","Training loss per 100 training steps: 0.036519540274083766\n","Training loss per 100 training steps: 0.03591987124073529\n","Training loss per 100 training steps: 0.03581870507763485\n","Training loss per 100 training steps: 0.0348797272219882\n","Training loss per 100 training steps: 0.03505549639272742\n","Training loss per 100 training steps: 0.03413462488174017\n","Training loss per 100 training steps: 0.033778655410211134\n","Training loss per 100 training steps: 0.03350586664302953\n","Training loss per 100 training steps: 0.03328690222048857\n","Training loss per 100 training steps: 0.03290962201502349\n","Training loss per 100 training steps: 0.03296639321858514\n","Training loss per 100 training steps: 0.032745298110649766\n","Training loss per 100 training steps: 0.03267961535570814\n","Training loss per 100 training steps: 0.0328834880757168\n","Stopping epoch...\n","Training loss epoch: 0.0328834880757168\n","Training accuracy epoch: 0.989040337758233\n","Validating model...\n","Validation Loss: 0.20381503184507418\n","Validation Accuracy: 0.9524378490135077\n","Training epoch: 4\n","Training loss per 100 training steps: 0.003856400027871132\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 5\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"TTDq-xbgHqXQ"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["612e19f520624ff7b75a03cd253ee5d3","4fb48adf8965427880956abe04443787","f3bc6f71c8b54232a866bfcd5b67f725","e9837d75cf974774ac2a0d5d26cff367","39fd495fad9347c2a9570da55f67fa0a","9be7a6e499c245ddb3a0b0e473a6c370","4bb5f022255e48febe8d94d957a66fee","03ab7b2d918c42339fea1562ed0addcd","ee068c469a9741e7b5dc3a3844364260","1321c8f130f0460f91285205f89cc2d2","5cad95f611574e5aaa6f177310bdc30e"]},"id":"bruL9R0SPw1r","outputId":"189ff2d4-a1a8-44f0-a133-7f26097bb7c1"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 500% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"612e19f520624ff7b75a03cd253ee5d3","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 62400\n","Points in y_train after augmentation: 62400\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.2178738117218018\n","Training loss per 100 training steps: 0.42619473206819875\n","Training loss per 100 training steps: 0.3227185345259472\n","Training loss per 100 training steps: 0.2704928892098392\n","Training loss per 100 training steps: 0.24300449167812554\n","Training loss per 100 training steps: 0.2238825046254727\n","Training loss per 100 training steps: 0.20987569625968247\n","Training loss per 100 training steps: 0.1975510546302532\n","Training loss per 100 training steps: 0.18899710506396125\n","Training loss per 100 training steps: 0.1793388319589388\n","Training loss per 100 training steps: 0.17181890333009944\n","Training loss per 100 training steps: 0.1647792032595849\n","Training loss per 100 training steps: 0.15873012319672464\n","Training loss per 100 training steps: 0.1530170440043879\n","Training loss per 100 training steps: 0.14832838395441603\n","Training loss per 100 training steps: 0.14419442194909216\n","Training loss per 100 training steps: 0.1399987491317731\n","Training loss per 100 training steps: 0.1364167465008182\n","Training loss per 100 training steps: 0.13269262903523546\n","Training loss per 100 training steps: 0.12948728611042185\n","Training loss epoch: 0.12788137531027388\n","Training accuracy epoch: 0.9587669553433938\n","Validating model...\n","Validation Loss: 0.1866659794680097\n","Validation Accuracy: 0.9493697428835388\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04475181922316551\n","Training loss per 100 training steps: 0.04537301404991805\n","Training loss per 100 training steps: 0.046699881549016456\n","Training loss per 100 training steps: 0.047690798974042124\n","Training loss per 100 training steps: 0.04724902290377088\n","Training loss per 100 training steps: 0.047212638792316027\n","Training loss per 100 training steps: 0.048360445050479296\n","Training loss per 100 training steps: 0.04849321507389116\n","Training loss per 100 training steps: 0.0480993631430733\n","Training loss per 100 training steps: 0.04703888495335899\n","Training loss per 100 training steps: 0.046636097745357694\n","Training loss per 100 training steps: 0.04593566979821281\n","Training loss per 100 training steps: 0.0452642525132547\n","Training loss per 100 training steps: 0.04545715901099409\n","Training loss per 100 training steps: 0.04529942520914053\n","Training loss per 100 training steps: 0.04523027781304034\n","Training loss per 100 training steps: 0.04517027685319252\n","Stopping epoch...\n","Training loss epoch: 0.04517027685319252\n","Training accuracy epoch: 0.9848222942616635\n","Validating model...\n","Validation Loss: 0.20435996738250378\n","Validation Accuracy: 0.9475106525587341\n","Training epoch: 3\n","Training loss per 100 training steps: 0.010877360589802265\n","Training loss per 100 training steps: 0.03475459146838967\n","Training loss per 100 training steps: 0.03402148266855757\n","Training loss per 100 training steps: 0.03269865896020617\n","Training loss per 100 training steps: 0.03307519281663911\n","Training loss per 100 training steps: 0.03158902868018774\n","Training loss per 100 training steps: 0.030476985603668565\n","Training loss per 100 training steps: 0.029754127410324172\n","Training loss per 100 training steps: 0.029505267710809812\n","Training loss per 100 training steps: 0.029066166317658387\n","Training loss per 100 training steps: 0.029152603759432676\n","Training loss per 100 training steps: 0.02935152755707433\n","Training loss per 100 training steps: 0.028687666718304066\n","Training loss per 100 training steps: 0.02847838891083289\n","Training loss per 100 training steps: 0.02854145288974782\n","Training loss per 100 training steps: 0.028363964571854874\n","Training loss per 100 training steps: 0.02866700527543693\n","Training loss per 100 training steps: 0.028523616951394517\n","Training loss per 100 training steps: 0.02860592939302833\n","Training loss per 100 training steps: 0.02861790733867159\n","Training loss epoch: 0.028534796109202152\n","Training accuracy epoch: 0.990925357174313\n","Validating model...\n","Validation Loss: 0.24951049454461832\n","Validation Accuracy: 0.9453160410504184\n","Training epoch: 4\n","Training loss per 100 training steps: 0.025314250960946083\n","Training loss per 100 training steps: 0.02020200536964406\n","Training loss per 100 training steps: 0.021016740368155585\n","Training loss per 100 training steps: 0.01930944029159807\n","Training loss per 100 training steps: 0.01986556077269173\n","Training loss per 100 training steps: 0.01950312291523869\n","Training loss per 100 training steps: 0.0193749364646006\n","Training loss per 100 training steps: 0.01987616477827123\n","Training loss per 100 training steps: 0.0200875834560431\n","Training loss per 100 training steps: 0.020666422329498838\n","Training loss per 100 training steps: 0.020520862935502388\n","Training loss per 100 training steps: 0.020577177010935695\n","Training loss per 100 training steps: 0.02088589233566416\n","Training loss per 100 training steps: 0.021165904319367487\n","Training loss per 100 training steps: 0.02126642686987863\n","Training loss per 100 training steps: 0.021470106298799318\n","Training loss per 100 training steps: 0.021796556499763843\n","Training loss per 100 training steps: 0.021678008493153062\n","Training loss per 100 training steps: 0.02138707155901445\n","Training loss per 100 training steps: 0.021232315539414855\n","Training loss epoch: 0.02111419487584872\n","Training accuracy epoch: 0.9932569838267357\n","Validating model...\n","Validation Loss: 0.24906240848751812\n","Validation Accuracy: 0.9510552652020403\n","Training epoch: 5\n","Training loss per 100 training steps: 0.014181587845087051\n","Training loss per 100 training steps: 0.012674862132200253\n","Training loss per 100 training steps: 0.012249367190548102\n","Training loss per 100 training steps: 0.012897323315577934\n","Training loss per 100 training steps: 0.012694348880520063\n","Training loss per 100 training steps: 0.012503418931784015\n","Training loss per 100 training steps: 0.01278629455218183\n","Training loss per 100 training steps: 0.013203112586338628\n","Training loss per 100 training steps: 0.014122982804578311\n","Training loss per 100 training steps: 0.01482772369223407\n","Training loss per 100 training steps: 0.014752249815646646\n","Training loss per 100 training steps: 0.015195113596415273\n","Training loss per 100 training steps: 0.015707535066435983\n","Training loss per 100 training steps: 0.01619514722982314\n","Training loss per 100 training steps: 0.01616060646645709\n","Training loss per 100 training steps: 0.015917938498951227\n","Training loss per 100 training steps: 0.016006048430947106\n","Training loss per 100 training steps: 0.016104184680815863\n","Training loss per 100 training steps: 0.01596476479778586\n","Training loss per 100 training steps: 0.015878317757239094\n","Training loss epoch: 0.01585746624317462\n","Training accuracy epoch: 0.9951812843952371\n","Validating model...\n","Validation Loss: 0.3147017376666719\n","Validation Accuracy: 0.9473091668818462\n","Training epoch: 6\n","Training loss per 100 training steps: 0.001510175527073443\n","Training loss per 100 training steps: 0.012437165866370802\n","Training loss per 100 training steps: 0.013201670235530264\n","Training loss per 100 training steps: 0.012898969732610156\n","Training loss per 100 training steps: 0.012645050802876583\n","Training loss per 100 training steps: 0.01179511602147145\n","Training loss per 100 training steps: 0.011846632912061363\n","Training loss per 100 training steps: 0.011806799988944905\n","Training loss per 100 training steps: 0.011913965042629924\n","Training loss per 100 training steps: 0.011884487259380528\n","Stopping epoch...\n","Training loss epoch: 0.011884487259380528\n","Training accuracy epoch: 0.995106314948665\n","Validating model...\n","Validation Loss: 0.2913433854504452\n","Validation Accuracy: 0.9481093159269516\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 176.25597065 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.20905834418091992\n","Validation Accuracy: 0.9445756755878739\n","Validation duration: 5.479530683333299 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 80.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.80      0.80     12546\n","        test       0.82      0.81      0.82      9012\n","   treatment       0.79      0.81      0.80      9297\n","\n","   micro avg       0.81      0.80      0.80     30855\n","   macro avg       0.81      0.80      0.81     30855\n","weighted avg       0.81      0.80      0.80     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["number_of_training_models = 5\n","target_augmented_percentage = 5\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"bruL9R0SPw1r"},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["ba1fd6c808764271a0048f5510268fc1","a48236395e6046b9b87442d5e236b797","777c741666804d7fb08fc169c06e2033","4e8f2a96c5eb4781883deabf56a8d990","10949ad33e5344dcbf141283eb36bfb9","450e3283cb394a2597d9d03e35b6949f","e9e10e00b3e14a25ae14c5a19588147d","044c0ff22d674519872d9485193aa1b5","d55ebf1c6a2745d184ce91144f3ba132","10e4f22c3b1945a6b6022d960272db1d","4a91a55a0d9e43d19dc65e53fb994968"]},"id":"wNIuddr_B3Ll","executionInfo":{"status":"ok","timestamp":1668816007091,"user_tz":240,"elapsed":58953270,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"}},"outputId":"d19014c2-699a-46ce-f145-ba2424de2d24"},"outputs":[{"output_type":"stream","name":"stdout","text":["!!!!!! Augmented Percentage 500% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba1fd6c808764271a0048f5510268fc1"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 62400\n","Points in y_train after augmentation: 62400\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.069730281829834\n","Training loss per 100 training steps: 0.45080326018061967\n","Training loss per 100 training steps: 0.33681555177590145\n","Training loss per 100 training steps: 0.28530806632235994\n","Training loss per 100 training steps: 0.2593571662048152\n","Training loss per 100 training steps: 0.2360449576687194\n","Training loss per 100 training steps: 0.21905239548428782\n","Training loss per 100 training steps: 0.2062770021725951\n","Training loss per 100 training steps: 0.19523978526105223\n","Training loss per 100 training steps: 0.18464235998855513\n","Training loss per 100 training steps: 0.17733064134392168\n","Training loss per 100 training steps: 0.17085216274243067\n","Training loss per 100 training steps: 0.16467811199731747\n","Training loss per 100 training steps: 0.15864160902680777\n","Training loss per 100 training steps: 0.1541542450376892\n","Training loss per 100 training steps: 0.14933421569556832\n","Training loss per 100 training steps: 0.14491368913447145\n","Training loss per 100 training steps: 0.1407827528337042\n","Training loss per 100 training steps: 0.13712118261817974\n","Training loss per 100 training steps: 0.13347969949612887\n","Training loss epoch: 0.13201328645412547\n","Training accuracy epoch: 0.9574028343382628\n","Validating model...\n","Validation Loss: 0.170805439328799\n","Validation Accuracy: 0.9541912256400172\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06812486797571182\n","Training loss per 100 training steps: 0.05390442680973228\n","Training loss per 100 training steps: 0.048826444460848224\n","Training loss per 100 training steps: 0.04850872519713799\n","Training loss per 100 training steps: 0.04803049226902295\n","Training loss per 100 training steps: 0.04792654808302096\n","Training loss per 100 training steps: 0.047886964861929615\n","Training loss per 100 training steps: 0.04764350002914529\n","Training loss per 100 training steps: 0.04853257593133727\n","Training loss per 100 training steps: 0.047484897700635575\n","Training loss per 100 training steps: 0.04836595344187861\n","Training loss per 100 training steps: 0.0492776465527358\n","Training loss per 100 training steps: 0.04935391848425316\n","Training loss per 100 training steps: 0.048733563441747396\n","Training loss per 100 training steps: 0.048743859584743074\n","Training loss per 100 training steps: 0.049002500977658785\n","Training loss per 100 training steps: 0.04862530687230544\n","Training loss per 100 training steps: 0.04843451778378682\n","Training loss per 100 training steps: 0.04814047924346854\n","Training loss per 100 training steps: 0.04786492555011759\n","Training loss epoch: 0.04766898239592616\n","Training accuracy epoch: 0.9848215103306497\n","Validating model...\n","Validation Loss: 0.22655726435848259\n","Validation Accuracy: 0.9498805897035025\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02680552750825882\n","Training loss per 100 training steps: 0.021937015420286962\n","Training loss per 100 training steps: 0.02439745736658221\n","Training loss per 100 training steps: 0.025776752669316255\n","Training loss per 100 training steps: 0.025277958187376826\n","Training loss per 100 training steps: 0.02580283280901663\n","Training loss per 100 training steps: 0.026237528302595205\n","Training loss per 100 training steps: 0.026656424142945074\n","Training loss per 100 training steps: 0.02894236604446492\n","Training loss per 100 training steps: 0.029557997959569825\n","Training loss per 100 training steps: 0.02970881407711093\n","Training loss per 100 training steps: 0.02901348267317319\n","Training loss per 100 training steps: 0.028974027944213828\n","Training loss per 100 training steps: 0.028954917755225625\n","Training loss per 100 training steps: 0.029166710049812705\n","Training loss per 100 training steps: 0.02891601445100616\n","Stopping epoch...\n","Training loss epoch: 0.02891601445100616\n","Training accuracy epoch: 0.99042809392178\n","Validating model...\n","Validation Loss: 0.22766888488761403\n","Validation Accuracy: 0.9471774321814662\n","Training epoch: 4\n","Training loss per 100 training steps: 0.010265537537634373\n","Training loss per 100 training steps: 0.020739428274561697\n","Training loss per 100 training steps: 0.019219183286713362\n","Training loss per 100 training steps: 0.01916156982876549\n","Training loss per 100 training steps: 0.01852412840348269\n","Training loss per 100 training steps: 0.01855051597147416\n","Training loss per 100 training steps: 0.018373688731581583\n","Training loss per 100 training steps: 0.018863105723182984\n","Training loss per 100 training steps: 0.019346315121694123\n","Training loss per 100 training steps: 0.019788684495630416\n","Training loss per 100 training steps: 0.02024033351483956\n","Training loss per 100 training steps: 0.020132584354245347\n","Training loss per 100 training steps: 0.020107769576357105\n","Training loss per 100 training steps: 0.020303263553724426\n","Training loss per 100 training steps: 0.02059456634409257\n","Training loss per 100 training steps: 0.020812223038413864\n","Training loss per 100 training steps: 0.02114213769417416\n","Training loss per 100 training steps: 0.02173500721099423\n","Training loss per 100 training steps: 0.022214842717534166\n","Training loss per 100 training steps: 0.02261903599036702\n","Training loss epoch: 0.022760212877720523\n","Training accuracy epoch: 0.9929760899182225\n","Validating model...\n","Validation Loss: 0.2608780716243502\n","Validation Accuracy: 0.9489558673287675\n","Training epoch: 5\n","Training loss per 100 training steps: 0.01613476499915123\n","Training loss per 100 training steps: 0.017040642187584856\n","Training loss per 100 training steps: 0.01868464690065521\n","Training loss per 100 training steps: 0.018937673574805483\n","Training loss per 100 training steps: 0.018538348443522826\n","Training loss per 100 training steps: 0.017890972356816675\n","Training loss per 100 training steps: 0.017378414673176742\n","Training loss per 100 training steps: 0.016847712880214038\n","Training loss per 100 training steps: 0.016724050769557103\n","Training loss per 100 training steps: 0.016890405143538\n","Training loss per 100 training steps: 0.016963273241259316\n","Training loss per 100 training steps: 0.017039400374373678\n","Training loss per 100 training steps: 0.01745358599438743\n","Training loss per 100 training steps: 0.017437062066131243\n","Training loss per 100 training steps: 0.01748025640010615\n","Training loss per 100 training steps: 0.017839792048552232\n","Training loss per 100 training steps: 0.01804732893071013\n","Training loss per 100 training steps: 0.01840373232305668\n","Training loss per 100 training steps: 0.01839111827625526\n","Training loss per 100 training steps: 0.018508409756807873\n","Training loss epoch: 0.018538498678647628\n","Training accuracy epoch: 0.9943793320802876\n","Validating model...\n","Validation Loss: 0.24056193455086125\n","Validation Accuracy: 0.9480152130812413\n","Training epoch: 6\n","Training loss per 100 training steps: 0.01261723693460226\n","Training loss per 100 training steps: 0.01369668370214208\n","Training loss per 100 training steps: 0.013220364829659721\n","Training loss per 100 training steps: 0.013097547302548572\n","Training loss per 100 training steps: 0.012734479747205726\n","Training loss per 100 training steps: 0.01275914206471389\n","Training loss per 100 training steps: 0.013311940243538583\n","Training loss per 100 training steps: 0.013161267763313927\n","Training loss per 100 training steps: 0.013133766298495076\n","Training loss per 100 training steps: 0.013281319642811084\n","Training loss per 100 training steps: 0.01357415909008993\n","Training loss per 100 training steps: 0.013471476330301749\n","Training loss per 100 training steps: 0.013651385026463198\n","Training loss per 100 training steps: 0.01356126914419331\n","Training loss per 100 training steps: 0.013591532493997326\n","Training loss per 100 training steps: 0.013533866297451935\n","Training loss per 100 training steps: 0.013550131499174974\n","Stopping epoch...\n","Training loss epoch: 0.013550131499174974\n","Training accuracy epoch: 0.9952522514809947\n","Validating model...\n","Validation Loss: 0.3045735415313151\n","Validation Accuracy: 0.9449474253458038\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 197.06370578333332 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.1874607754202939\n","Validation Accuracy: 0.9477934418363619\n","Validation duration: 5.957267449999987 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 81.9%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.85      0.82     12546\n","        test       0.78      0.84      0.81      9012\n","   treatment       0.81      0.83      0.82      9297\n","\n","   micro avg       0.80      0.84      0.82     30855\n","   macro avg       0.80      0.84      0.82     30855\n","weighted avg       0.80      0.84      0.82     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 62400\n","Points in y_train after augmentation: 62400\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.3256914615631104\n","Training loss per 100 training steps: 0.4629080289661294\n","Training loss per 100 training steps: 0.33330521460122137\n","Training loss per 100 training steps: 0.28230132027668414\n","Training loss per 100 training steps: 0.25032887878151905\n","Training loss per 100 training steps: 0.22972037098900286\n","Training loss per 100 training steps: 0.21363886354333053\n","Training loss per 100 training steps: 0.20066003707342497\n","Training loss per 100 training steps: 0.1892426022550512\n","Training loss per 100 training steps: 0.18052374131638518\n","Training loss per 100 training steps: 0.17326085099375452\n","Training loss per 100 training steps: 0.16632711412308976\n","Training loss per 100 training steps: 0.1597166543223156\n","Training loss per 100 training steps: 0.15372013613627472\n","Training loss per 100 training steps: 0.1481365109418255\n","Training loss per 100 training steps: 0.143428811310188\n","Training loss per 100 training steps: 0.13951000590912815\n","Training loss per 100 training steps: 0.136060991738953\n","Training loss per 100 training steps: 0.1327773574605245\n","Training loss per 100 training steps: 0.12927898085886305\n","Training loss epoch: 0.12759896580702984\n","Training accuracy epoch: 0.9587849983863229\n","Validating model...\n","Validation Loss: 0.1847468697792524\n","Validation Accuracy: 0.9504772073594346\n","Training epoch: 2\n","Training loss per 100 training steps: 0.03282836824655533\n","Training loss per 100 training steps: 0.04400230204631196\n","Training loss per 100 training steps: 0.043703584978125286\n","Training loss per 100 training steps: 0.04399190822993699\n","Training loss per 100 training steps: 0.04583964977956881\n","Training loss per 100 training steps: 0.04635439492843882\n","Training loss per 100 training steps: 0.046998020582297774\n","Training loss per 100 training steps: 0.04725404782552862\n","Training loss per 100 training steps: 0.047322998469818696\n","Training loss per 100 training steps: 0.04747405887832586\n","Training loss per 100 training steps: 0.047370603614413254\n","Training loss per 100 training steps: 0.047354023518094916\n","Stopping epoch...\n","Training loss epoch: 0.047354023518094916\n","Training accuracy epoch: 0.983849728912789\n","Validating model...\n","Validation Loss: 0.1718049333854155\n","Validation Accuracy: 0.9529741803184301\n","Training epoch: 3\n","Training loss per 100 training steps: 0.008590053766965866\n","Training loss per 100 training steps: 0.03750724940892715\n","Training loss per 100 training steps: 0.03693927104343934\n","Training loss per 100 training steps: 0.0355458623332055\n","Training loss per 100 training steps: 0.03500587610699738\n","Training loss per 100 training steps: 0.03607495084308281\n","Training loss per 100 training steps: 0.036904315414998105\n","Training loss per 100 training steps: 0.0368207833379608\n","Training loss per 100 training steps: 0.03615997786012789\n","Training loss per 100 training steps: 0.03705185753826701\n","Training loss per 100 training steps: 0.036504463162636024\n","Training loss per 100 training steps: 0.036040351741023526\n","Training loss per 100 training steps: 0.03538794483713027\n","Training loss per 100 training steps: 0.03526384943727902\n","Training loss per 100 training steps: 0.03528286643559944\n","Training loss per 100 training steps: 0.03569256091686766\n","Training loss per 100 training steps: 0.03554639149915897\n","Training loss per 100 training steps: 0.035610320734838545\n","Training loss per 100 training steps: 0.035584697809945824\n","Training loss per 100 training steps: 0.03543639987020526\n","Stopping epoch...\n","Training loss epoch: 0.03543639987020526\n","Training accuracy epoch: 0.988255111238692\n","Validating model...\n","Validation Loss: 0.21497564397558763\n","Validation Accuracy: 0.9500300897961207\n","Training epoch: 4\n","Training loss per 100 training steps: 0.013762060552835464\n","Training loss per 100 training steps: 0.02350346050294356\n","Training loss per 100 training steps: 0.021471694851727386\n","Training loss per 100 training steps: 0.022179764395144977\n","Training loss per 100 training steps: 0.022652802887567762\n","Training loss per 100 training steps: 0.02259200002148584\n","Training loss per 100 training steps: 0.022047049062696136\n","Training loss per 100 training steps: 0.02206869042714654\n","Training loss per 100 training steps: 0.02241958611269543\n","Training loss per 100 training steps: 0.022150344557343847\n","Training loss per 100 training steps: 0.022599880563348277\n","Training loss per 100 training steps: 0.022779654727768252\n","Training loss per 100 training steps: 0.023271305851605747\n","Training loss per 100 training steps: 0.023132041672992376\n","Training loss per 100 training steps: 0.023270502960172114\n","Training loss per 100 training steps: 0.023050519462597608\n","Training loss per 100 training steps: 0.023239913528113523\n","Stopping epoch...\n","Training loss epoch: 0.023239913528113523\n","Training accuracy epoch: 0.9919535523188173\n","Validating model...\n","Validation Loss: 0.22451004492385046\n","Validation Accuracy: 0.9478352256585559\n","Training epoch: 5\n","Training loss per 100 training steps: 0.012125683017075062\n","Training loss per 100 training steps: 0.015412635508219315\n","Training loss per 100 training steps: 0.01658675441922694\n","Training loss per 100 training steps: 0.01654162354561565\n","Training loss per 100 training steps: 0.017273553527201852\n","Training loss per 100 training steps: 0.017788147332356823\n","Training loss per 100 training steps: 0.017961258670515047\n","Training loss per 100 training steps: 0.01761721516527586\n","Training loss per 100 training steps: 0.01803945916169701\n","Training loss per 100 training steps: 0.0180546417498375\n","Training loss per 100 training steps: 0.01822150184597995\n","Training loss per 100 training steps: 0.018184967127249665\n","Training loss per 100 training steps: 0.019183146185096242\n","Training loss per 100 training steps: 0.01960574774803353\n","Training loss per 100 training steps: 0.01982787636137447\n","Training loss per 100 training steps: 0.01991535935382316\n","Training loss per 100 training steps: 0.01986171021539954\n","Training loss per 100 training steps: 0.01981195427466341\n","Training loss per 100 training steps: 0.01967368112965373\n","Training loss per 100 training steps: 0.01965187074916194\n","Training loss epoch: 0.019561937425557212\n","Training accuracy epoch: 0.9940192431269792\n","Validating model...\n","Validation Loss: 0.23875028141109006\n","Validation Accuracy: 0.9522949776129951\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0013393801636993885\n","Training loss per 100 training steps: 0.015186025619871066\n","Training loss per 100 training steps: 0.015155947190044513\n","Training loss per 100 training steps: 0.014763149484857433\n","Training loss per 100 training steps: 0.014743551045936066\n","Training loss per 100 training steps: 0.015121210466230571\n","Training loss per 100 training steps: 0.01485519422366483\n","Training loss per 100 training steps: 0.014634252070646418\n","Training loss per 100 training steps: 0.014214569876041262\n","Training loss per 100 training steps: 0.013970318605337621\n","Training loss per 100 training steps: 0.014019108102887754\n","Training loss per 100 training steps: 0.014177820843540925\n","Training loss per 100 training steps: 0.014099085690612327\n","Training loss per 100 training steps: 0.014277575045716584\n","Training loss per 100 training steps: 0.014640538689014727\n","Training loss per 100 training steps: 0.01459350647087149\n","Training loss per 100 training steps: 0.014304149895733753\n","Training loss per 100 training steps: 0.014524761304290578\n","Training loss per 100 training steps: 0.014506758204500035\n","Training loss per 100 training steps: 0.014835435893292111\n","Training loss epoch: 0.014820230175055958\n","Training accuracy epoch: 0.9955014690634402\n","Validating model...\n","Validation Loss: 0.2733274735026545\n","Validation Accuracy: 0.948014052244161\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0028414048720151186\n","Training loss per 100 training steps: 0.013167536383815164\n","Training loss per 100 training steps: 0.012853996695131665\n","Training loss per 100 training steps: 0.01278335421986799\n","Training loss per 100 training steps: 0.013131413080674675\n","Training loss per 100 training steps: 0.012994247476100697\n","Training loss per 100 training steps: 0.012757709110848189\n","Training loss per 100 training steps: 0.01310535798327331\n","Training loss per 100 training steps: 0.013392134666107577\n","Training loss per 100 training steps: 0.013038899239215206\n","Training loss per 100 training steps: 0.01283024059553104\n","Training loss per 100 training steps: 0.012567332820969166\n","Training loss per 100 training steps: 0.012668712626538587\n","Training loss per 100 training steps: 0.012583867176685542\n","Training loss per 100 training steps: 0.012523942453823126\n","Training loss per 100 training steps: 0.01288741736990886\n","Training loss per 100 training steps: 0.013215983069139264\n","Training loss per 100 training steps: 0.013307249018002145\n","Training loss per 100 training steps: 0.013314930622007358\n","Training loss per 100 training steps: 0.013371292706792694\n","Training loss epoch: 0.01360102312610998\n","Training accuracy epoch: 0.9958694820727813\n","Validating model...\n","Validation Loss: 0.2976930330616313\n","Validation Accuracy: 0.9407252450397046\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 224.43696705000002 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.20174993310313397\n","Validation Accuracy: 0.946873812224666\n","Validation duration: 5.958056500000021 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 82.1%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.83      0.81     12546\n","        test       0.84      0.86      0.85      9012\n","   treatment       0.79      0.82      0.80      9297\n","\n","   micro avg       0.81      0.83      0.82     30855\n","   macro avg       0.81      0.83      0.82     30855\n","weighted avg       0.81      0.83      0.82     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 62400\n","Points in y_train after augmentation: 62400\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8349448442459106\n","Training loss per 100 training steps: 0.4053218808062006\n","Training loss per 100 training steps: 0.3038856862344552\n","Training loss per 100 training steps: 0.264371586202387\n","Training loss per 100 training steps: 0.24125796329796761\n","Training loss per 100 training steps: 0.22329501504312732\n","Training loss per 100 training steps: 0.20615429630791288\n","Training loss per 100 training steps: 0.19306316040190583\n","Training loss per 100 training steps: 0.1835230742621883\n","Training loss per 100 training steps: 0.17535644080841317\n","Training loss per 100 training steps: 0.1678358565729398\n","Training loss per 100 training steps: 0.16110511186898946\n","Training loss per 100 training steps: 0.1554160461319823\n","Training loss per 100 training steps: 0.15031610901462492\n","Training loss per 100 training steps: 0.14562990977764556\n","Training loss per 100 training steps: 0.14115864007257864\n","Training loss per 100 training steps: 0.1366206946492493\n","Training loss per 100 training steps: 0.13357456882255944\n","Training loss per 100 training steps: 0.1307158178129109\n","Training loss per 100 training steps: 0.12761657211345584\n","Training loss epoch: 0.12610976588148146\n","Training accuracy epoch: 0.9588457519137379\n","Validating model...\n","Validation Loss: 0.16390472994028749\n","Validation Accuracy: 0.9533205224825259\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04717198759317398\n","Training loss per 100 training steps: 0.051542648981039475\n","Training loss per 100 training steps: 0.05210358849193771\n","Training loss per 100 training steps: 0.050178061443631634\n","Training loss per 100 training steps: 0.04990257289576486\n","Training loss per 100 training steps: 0.049468134622834996\n","Training loss per 100 training steps: 0.048863812732493225\n","Training loss per 100 training steps: 0.04694702679068169\n","Training loss per 100 training steps: 0.04576836517935249\n","Training loss per 100 training steps: 0.04532851330619657\n","Training loss per 100 training steps: 0.044763635871903996\n","Training loss per 100 training steps: 0.04427212262382354\n","Training loss per 100 training steps: 0.04372957114364446\n","Training loss per 100 training steps: 0.04361504433425337\n","Training loss per 100 training steps: 0.04349979416295743\n","Training loss per 100 training steps: 0.04343475388045945\n","Training loss per 100 training steps: 0.043235896666418486\n","Training loss per 100 training steps: 0.04271899462433347\n","Training loss per 100 training steps: 0.04226787812733244\n","Training loss per 100 training steps: 0.04215314891936452\n","Training loss epoch: 0.04219836401454627\n","Training accuracy epoch: 0.9864828345573962\n","Validating model...\n","Validation Loss: 0.19406013957575544\n","Validation Accuracy: 0.954053691263038\n","Training epoch: 3\n","Training loss per 100 training steps: 0.010601670481264591\n","Training loss per 100 training steps: 0.024099427510495527\n","Training loss per 100 training steps: 0.02842781220363518\n","Training loss per 100 training steps: 0.027146013860089514\n","Training loss per 100 training steps: 0.02741683577666375\n","Training loss per 100 training steps: 0.02667341828464759\n","Training loss per 100 training steps: 0.02734182022940817\n","Training loss per 100 training steps: 0.02763643283813796\n","Training loss per 100 training steps: 0.02713066361809368\n","Training loss per 100 training steps: 0.02651707259748187\n","Training loss per 100 training steps: 0.026566931329675476\n","Training loss per 100 training steps: 0.02613637937901315\n","Training loss per 100 training steps: 0.02553835898470273\n","Training loss per 100 training steps: 0.025535481783463338\n","Training loss per 100 training steps: 0.025431847250568337\n","Training loss per 100 training steps: 0.025250381609855554\n","Training loss per 100 training steps: 0.025265150582057184\n","Training loss per 100 training steps: 0.02554441316968716\n","Training loss per 100 training steps: 0.025914802897549848\n","Training loss per 100 training steps: 0.026169801989706455\n","Training loss epoch: 0.026389984647050883\n","Training accuracy epoch: 0.9916529816187333\n","Validating model...\n","Validation Loss: 0.212669297956027\n","Validation Accuracy: 0.9515437410260087\n","Training epoch: 4\n","Training loss per 100 training steps: 0.003975795116275549\n","Training loss per 100 training steps: 0.016172200112861794\n","Training loss per 100 training steps: 0.020916917074335024\n","Training loss per 100 training steps: 0.020759993494237676\n","Training loss per 100 training steps: 0.01939846462241497\n","Training loss per 100 training steps: 0.019678960791431152\n","Training loss per 100 training steps: 0.019464292316236524\n","Training loss per 100 training steps: 0.019626365201986167\n","Training loss per 100 training steps: 0.019574000041966168\n","Training loss per 100 training steps: 0.01883067777514076\n","Training loss per 100 training steps: 0.01875014500850072\n","Training loss per 100 training steps: 0.018555868811763486\n","Training loss per 100 training steps: 0.018502948665162656\n","Training loss per 100 training steps: 0.01861277553967385\n","Training loss per 100 training steps: 0.018657333222858515\n","Training loss per 100 training steps: 0.0187207616561877\n","Training loss per 100 training steps: 0.018819551541088823\n","Training loss per 100 training steps: 0.018685917568615207\n","Training loss per 100 training steps: 0.019106177967798656\n","Training loss per 100 training steps: 0.019241053566259103\n","Training loss epoch: 0.019339474349279698\n","Training accuracy epoch: 0.9940058229682853\n","Validating model...\n","Validation Loss: 0.28464992732632083\n","Validation Accuracy: 0.9443374988012683\n","Training epoch: 5\n","Training loss per 100 training steps: 0.005111311562359333\n","Training loss per 100 training steps: 0.017784400958346554\n","Training loss per 100 training steps: 0.015558083330000756\n","Training loss per 100 training steps: 0.015367506992225024\n","Training loss per 100 training steps: 0.015319015668906002\n","Training loss per 100 training steps: 0.015482028928039755\n","Training loss per 100 training steps: 0.015375891102426771\n","Training loss per 100 training steps: 0.015773579218861952\n","Training loss per 100 training steps: 0.015375233975873641\n","Training loss per 100 training steps: 0.015180121682403137\n","Training loss per 100 training steps: 0.014698433837153019\n","Training loss per 100 training steps: 0.014787684021415917\n","Training loss per 100 training steps: 0.014791471639991801\n","Training loss per 100 training steps: 0.014691021701358678\n","Training loss per 100 training steps: 0.014640501823518833\n","Training loss per 100 training steps: 0.014660204407402785\n","Training loss per 100 training steps: 0.014755058773561104\n","Training loss per 100 training steps: 0.015076399653846344\n","Training loss per 100 training steps: 0.015188910258470245\n","Training loss per 100 training steps: 0.015091780204279556\n","Training loss epoch: 0.015286549090830168\n","Training accuracy epoch: 0.9952966891540411\n","Validating model...\n","Validation Loss: 0.2656918102270597\n","Validation Accuracy: 0.9480494845252214\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0014021758688613772\n","Training loss per 100 training steps: 0.01566603975566473\n","Training loss per 100 training steps: 0.015425856957566549\n","Training loss per 100 training steps: 0.0165637788531816\n","Training loss per 100 training steps: 0.01675521215250335\n","Training loss per 100 training steps: 0.016946851724095106\n","Training loss per 100 training steps: 0.016728682532215402\n","Training loss per 100 training steps: 0.01648588038707111\n","Training loss per 100 training steps: 0.01616021456250243\n","Training loss per 100 training steps: 0.015976928285581237\n","Training loss per 100 training steps: 0.015553878834693238\n","Training loss per 100 training steps: 0.015145297013411382\n","Training loss per 100 training steps: 0.01505871139855266\n","Training loss per 100 training steps: 0.014771283121128046\n","Training loss per 100 training steps: 0.015220717818872704\n","Training loss per 100 training steps: 0.015137283243658905\n","Training loss per 100 training steps: 0.015164328475376526\n","Training loss per 100 training steps: 0.014975034009495453\n","Training loss per 100 training steps: 0.01492225171197489\n","Training loss per 100 training steps: 0.014661944310309996\n","Training loss epoch: 0.014574553593463348\n","Training accuracy epoch: 0.9955441255319869\n","Validating model...\n","Validation Loss: 0.26634114438837225\n","Validation Accuracy: 0.9481509726579256\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 211.2080136833333 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.17957923265337875\n","Validation Accuracy: 0.9502986922742231\n","Validation duration: 5.946246000000004 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 82.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.82      0.82     12546\n","        test       0.80      0.84      0.82      9012\n","   treatment       0.83      0.85      0.84      9297\n","\n","   micro avg       0.82      0.83      0.82     30855\n","   macro avg       0.82      0.83      0.82     30855\n","weighted avg       0.82      0.83      0.82     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 62400\n","Points in y_train after augmentation: 62400\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.6831668615341187\n","Training loss per 100 training steps: 0.4024146487659747\n","Training loss per 100 training steps: 0.3059606422758221\n","Training loss per 100 training steps: 0.26273118390197375\n","Training loss per 100 training steps: 0.23383344143183155\n","Training loss per 100 training steps: 0.21523979853489203\n","Training loss per 100 training steps: 0.2005177251436746\n","Training loss per 100 training steps: 0.19129845961535114\n","Training loss per 100 training steps: 0.18200633851357836\n","Training loss per 100 training steps: 0.17439696496015583\n","Training loss per 100 training steps: 0.1677028640442259\n","Training loss per 100 training steps: 0.1608596888982389\n","Training loss per 100 training steps: 0.15444167068601897\n","Training loss per 100 training steps: 0.14940612416694385\n","Training loss per 100 training steps: 0.14370725473733373\n","Training loss per 100 training steps: 0.13913992329126473\n","Training loss per 100 training steps: 0.13562060796541117\n","Training loss per 100 training steps: 0.1320242789578895\n","Training loss per 100 training steps: 0.12871338421999085\n","Training loss per 100 training steps: 0.12582284774727284\n","Training loss epoch: 0.12471213775758559\n","Training accuracy epoch: 0.9597799789186336\n","Validating model...\n","Validation Loss: 0.14279009638862175\n","Validation Accuracy: 0.9559525647080599\n","Training epoch: 2\n","Training loss per 100 training steps: 0.017375651746988297\n","Training loss per 100 training steps: 0.05219448714673814\n","Training loss per 100 training steps: 0.05064446459621636\n","Training loss per 100 training steps: 0.047466677996450636\n","Training loss per 100 training steps: 0.049007630598687214\n","Training loss per 100 training steps: 0.04747276233617001\n","Training loss per 100 training steps: 0.04647317737846104\n","Training loss per 100 training steps: 0.04609086809526417\n","Training loss per 100 training steps: 0.04505156061874258\n","Training loss per 100 training steps: 0.04457789635144641\n","Training loss per 100 training steps: 0.044431296896750475\n","Training loss per 100 training steps: 0.04437816347751333\n","Training loss per 100 training steps: 0.043794135783789684\n","Training loss per 100 training steps: 0.043846570450807566\n","Training loss per 100 training steps: 0.04378662096792839\n","Training loss per 100 training steps: 0.043469971847418895\n","Training loss per 100 training steps: 0.04319707959400854\n","Training loss per 100 training steps: 0.043017919968607245\n","Training loss per 100 training steps: 0.043405884504331166\n","Training loss per 100 training steps: 0.04321095338726915\n","Training loss epoch: 0.043060279693156005\n","Training accuracy epoch: 0.9863581582670023\n","Validating model...\n","Validation Loss: 0.20510360088150997\n","Validation Accuracy: 0.9510422374111573\n","Training epoch: 3\n","Training loss per 100 training steps: 0.008121096529066563\n","Training loss per 100 training steps: 0.021769197226621875\n","Training loss per 100 training steps: 0.023499611837833435\n","Training loss per 100 training steps: 0.025128603112099513\n","Training loss per 100 training steps: 0.024578908976124473\n","Training loss per 100 training steps: 0.024603903273277602\n","Training loss per 100 training steps: 0.024700600168177277\n","Training loss per 100 training steps: 0.02415376238947729\n","Training loss per 100 training steps: 0.024619819812453963\n","Training loss per 100 training steps: 0.024518540085135203\n","Training loss per 100 training steps: 0.025054513908025773\n","Training loss per 100 training steps: 0.025098288614263962\n","Training loss per 100 training steps: 0.0253001596181724\n","Training loss per 100 training steps: 0.02618976917340106\n","Training loss per 100 training steps: 0.026232331816281866\n","Training loss per 100 training steps: 0.0261765748908778\n","Training loss per 100 training steps: 0.026466526954724505\n","Training loss per 100 training steps: 0.026784928591658024\n","Training loss per 100 training steps: 0.026806721229288212\n","Training loss per 100 training steps: 0.026798730659218253\n","Training loss epoch: 0.026696722163663558\n","Training accuracy epoch: 0.9916062439665034\n","Validating model...\n","Validation Loss: 0.22575848239969898\n","Validation Accuracy: 0.9526405459514273\n","Training epoch: 4\n","Training loss per 100 training steps: 0.008269328624010086\n","Training loss per 100 training steps: 0.00965821333194963\n","Training loss per 100 training steps: 0.014822649587911846\n","Training loss per 100 training steps: 0.016462160976939335\n","Training loss per 100 training steps: 0.017716143305815217\n","Training loss per 100 training steps: 0.017739430903419926\n","Training loss per 100 training steps: 0.018235962960064047\n","Training loss per 100 training steps: 0.019491929929991107\n","Training loss per 100 training steps: 0.019290294934871645\n","Training loss per 100 training steps: 0.019481984115907038\n","Training loss per 100 training steps: 0.019356001536401414\n","Training loss per 100 training steps: 0.019086281666678074\n","Training loss per 100 training steps: 0.01938160058738296\n","Training loss per 100 training steps: 0.01928917139472059\n","Training loss per 100 training steps: 0.019241337611930455\n","Training loss per 100 training steps: 0.019410035611318145\n","Training loss per 100 training steps: 0.019353012994431606\n","Stopping epoch...\n","Training loss epoch: 0.019353012994431606\n","Training accuracy epoch: 0.9932471100889333\n","Validating model...\n","Validation Loss: 0.25950479855785125\n","Validation Accuracy: 0.9470664931136152\n","Training epoch: 5\n","Training loss per 100 training steps: 0.007201754488050938\n","Training loss per 100 training steps: 0.015786845087175174\n","Training loss per 100 training steps: 0.01650183587520388\n","Training loss per 100 training steps: 0.017208737946591925\n","Training loss per 100 training steps: 0.01703263958030615\n","Training loss per 100 training steps: 0.016626931263740125\n","Training loss per 100 training steps: 0.01621821576554794\n","Training loss per 100 training steps: 0.016407940999845397\n","Training loss per 100 training steps: 0.0165130481617236\n","Training loss per 100 training steps: 0.0165730599384489\n","Training loss per 100 training steps: 0.016376006524887406\n","Training loss per 100 training steps: 0.01644478311957984\n","Training loss per 100 training steps: 0.01669642899603826\n","Training loss per 100 training steps: 0.01653844007068494\n","Training loss per 100 training steps: 0.016362992781455806\n","Training loss per 100 training steps: 0.016486849642092617\n","Training loss per 100 training steps: 0.016370255110430446\n","Training loss per 100 training steps: 0.016569247863063196\n","Training loss per 100 training steps: 0.01670936144183542\n","Training loss per 100 training steps: 0.016493725648026085\n","Training loss epoch: 0.016438727011353387\n","Training accuracy epoch: 0.9948013201747272\n","Validating model...\n","Validation Loss: 0.2485089479195704\n","Validation Accuracy: 0.9486784349181258\n","Training epoch: 6\n","Training loss per 100 training steps: 0.011695772409439087\n","Training loss per 100 training steps: 0.009724533702027846\n","Training loss per 100 training steps: 0.009322329437063627\n","Training loss per 100 training steps: 0.00981426898191259\n","Training loss per 100 training steps: 0.009620054886110842\n","Training loss per 100 training steps: 0.009953425679459959\n","Training loss per 100 training steps: 0.010840617833576148\n","Training loss per 100 training steps: 0.011203298241331159\n","Training loss per 100 training steps: 0.011995183004920352\n","Training loss per 100 training steps: 0.012465910252397384\n","Training loss per 100 training steps: 0.01307648031490987\n","Training loss per 100 training steps: 0.01325646766328892\n","Training loss per 100 training steps: 0.013067072290198921\n","Training loss per 100 training steps: 0.013125659585845847\n","Training loss per 100 training steps: 0.013063221475923202\n","Training loss per 100 training steps: 0.01331058595499415\n","Training loss per 100 training steps: 0.013511199721379591\n","Training loss per 100 training steps: 0.013481396438694846\n","Training loss per 100 training steps: 0.013332609395146008\n","Training loss per 100 training steps: 0.013551805494939539\n","Training loss epoch: 0.013457463421994664\n","Training accuracy epoch: 0.9956403916995369\n","Validating model...\n","Validation Loss: 0.29962366718992395\n","Validation Accuracy: 0.9457781746578058\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 204.89027645 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.17122295378767713\n","Validation Accuracy: 0.9486531305294497\n","Validation duration: 5.948879933333471 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 82.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.81      0.81     12546\n","        test       0.84      0.85      0.85      9012\n","   treatment       0.80      0.85      0.83      9297\n","\n","   micro avg       0.82      0.83      0.82     30855\n","   macro avg       0.82      0.83      0.83     30855\n","weighted avg       0.82      0.83      0.82     30855\n","\n"]}],"source":["number_of_training_models = 4\n","target_augmented_percentage = 5\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"wNIuddr_B3Ll"}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"012c4068d2fb4d13a80c319c8eca7abf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_144f517c165f4b598a170bc7ff072a6b","placeholder":"​","style":"IPY_MODEL_af4d72de98be4b569445fce8520a8b9f","value":" 442M/442M [00:20&lt;00:00, 19.4MB/s]"}},"03ab7b2d918c42339fea1562ed0addcd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bbc252e28fd457fab8b0aaa44b49cc4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f3b864852674078a9a2184450bf39e1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1321c8f130f0460f91285205f89cc2d2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"144f517c165f4b598a170bc7ff072a6b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"158c9ebd0fd44b0fa1c6bf8b24b835d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e266d74215ed41368b7f88a4c0eef24b","placeholder":"​","style":"IPY_MODEL_b1701d9b189c41ec827f2a12782825ea","value":" 442M/442M [00:07&lt;00:00, 58.9MB/s]"}},"1d287171f668406a95dde65b6bd3786d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f54a40f09f284b3eac191eb91fed516c","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_52693de900eb4455a53d547dede3bf7f","value":442221694}},"25126a1181e8488196d1adcf2f0d8c7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ded5e8e703842739d64463fe428a5f2","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8164f9f4d15e4e38b76e34fda07bc471","value":442221694}},"27320f94ab354b4a965e64f022534c86":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ded5e8e703842739d64463fe428a5f2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36de6fda26164e3f83c25228ff6c057e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca07ef2a9f3548958eac4fca0c7dcfa4","placeholder":"​","style":"IPY_MODEL_66c00ae1102a4e2db81c977b11746511","value":" 442M/442M [00:06&lt;00:00, 64.8MB/s]"}},"39fd495fad9347c2a9570da55f67fa0a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bcd6b75235d43a390b64a26303d4f4d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_454c11066f324cb8a57c8efea20b1cf5","placeholder":"​","style":"IPY_MODEL_27320f94ab354b4a965e64f022534c86","value":"Downloading: 100%"}},"454c11066f324cb8a57c8efea20b1cf5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b4306c3de574a77854ca31efd0084a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0bbc252e28fd457fab8b0aaa44b49cc4","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7fb68a2aa2e64257879bbc049b18ce17","value":442221694}},"4bb5f022255e48febe8d94d957a66fee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4fb48adf8965427880956abe04443787":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9be7a6e499c245ddb3a0b0e473a6c370","placeholder":"​","style":"IPY_MODEL_4bb5f022255e48febe8d94d957a66fee","value":"Downloading: 100%"}},"52693de900eb4455a53d547dede3bf7f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5cad95f611574e5aaa6f177310bdc30e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5e2b12ed936e4ab58995bf8fee0a6874":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"612e19f520624ff7b75a03cd253ee5d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4fb48adf8965427880956abe04443787","IPY_MODEL_f3bc6f71c8b54232a866bfcd5b67f725","IPY_MODEL_e9837d75cf974774ac2a0d5d26cff367"],"layout":"IPY_MODEL_39fd495fad9347c2a9570da55f67fa0a"}},"66c00ae1102a4e2db81c977b11746511":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6981b764289b43f6acb468c4f4c3dea3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_917716071c224608b0a0d7b8736ddd27","IPY_MODEL_1d287171f668406a95dde65b6bd3786d","IPY_MODEL_012c4068d2fb4d13a80c319c8eca7abf"],"layout":"IPY_MODEL_5e2b12ed936e4ab58995bf8fee0a6874"}},"6a8990ef69b24d1cba0de912a4532a24":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7fb68a2aa2e64257879bbc049b18ce17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8164f9f4d15e4e38b76e34fda07bc471":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"917716071c224608b0a0d7b8736ddd27":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb57f5d36b0a4432896a315ef62b623d","placeholder":"​","style":"IPY_MODEL_940a9dfaa6e44252a8cad1c5bb50bd02","value":"Downloading: 100%"}},"940a9dfaa6e44252a8cad1c5bb50bd02":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9be7a6e499c245ddb3a0b0e473a6c370":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d4543bccc8345948e8970a0afede7fa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a487f8fb973d443c91acf5f3c0265cea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e7c9ccf8d1724d63b614dad271a6d834","IPY_MODEL_25126a1181e8488196d1adcf2f0d8c7e","IPY_MODEL_36de6fda26164e3f83c25228ff6c057e"],"layout":"IPY_MODEL_6a8990ef69b24d1cba0de912a4532a24"}},"af4d72de98be4b569445fce8520a8b9f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1701d9b189c41ec827f2a12782825ea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb57f5d36b0a4432896a315ef62b623d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3cb5bc506084541acd5f4844b5209b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3bcd6b75235d43a390b64a26303d4f4d","IPY_MODEL_4b4306c3de574a77854ca31efd0084a0","IPY_MODEL_158c9ebd0fd44b0fa1c6bf8b24b835d2"],"layout":"IPY_MODEL_e79cb1e88a6044c5847250da8d6001de"}},"ca07ef2a9f3548958eac4fca0c7dcfa4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e266d74215ed41368b7f88a4c0eef24b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e79cb1e88a6044c5847250da8d6001de":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7c9ccf8d1724d63b614dad271a6d834":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f3b864852674078a9a2184450bf39e1","placeholder":"​","style":"IPY_MODEL_9d4543bccc8345948e8970a0afede7fa","value":"Downloading: 100%"}},"e9837d75cf974774ac2a0d5d26cff367":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1321c8f130f0460f91285205f89cc2d2","placeholder":"​","style":"IPY_MODEL_5cad95f611574e5aaa6f177310bdc30e","value":" 442M/442M [00:06&lt;00:00, 64.4MB/s]"}},"ee068c469a9741e7b5dc3a3844364260":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f3bc6f71c8b54232a866bfcd5b67f725":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_03ab7b2d918c42339fea1562ed0addcd","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ee068c469a9741e7b5dc3a3844364260","value":442221694}},"f54a40f09f284b3eac191eb91fed516c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c14bd1f6e6a241139e1c30bffcd08706":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_519ff5f8b70c428c8f4fe26e1c668e17","IPY_MODEL_82f8f0b3a08b426f92f8ac2c7ef1fe0e","IPY_MODEL_94a7eaca18c3402e85ec3fae8292aab8"],"layout":"IPY_MODEL_7c21b9fa9709447db4d894974f653ea0"}},"519ff5f8b70c428c8f4fe26e1c668e17":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b582f60ee82482e83d2d96abcc0dbad","placeholder":"​","style":"IPY_MODEL_94a108b46b25482dacd825de0facdcec","value":"Downloading: 100%"}},"82f8f0b3a08b426f92f8ac2c7ef1fe0e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_154be693d44e4554ab51af056cfe9ec0","max":385,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dec98a245fee414887653962b04b84f2","value":385}},"94a7eaca18c3402e85ec3fae8292aab8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de15af0f18eb4309ac4d08bde6d141ff","placeholder":"​","style":"IPY_MODEL_67484684b0c64833a86d3ec71f9c3678","value":" 385/385 [00:00&lt;00:00, 14.5kB/s]"}},"7c21b9fa9709447db4d894974f653ea0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b582f60ee82482e83d2d96abcc0dbad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94a108b46b25482dacd825de0facdcec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"154be693d44e4554ab51af056cfe9ec0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dec98a245fee414887653962b04b84f2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"de15af0f18eb4309ac4d08bde6d141ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67484684b0c64833a86d3ec71f9c3678":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ccbd71c87ef94c208f1a9ba0bb583215":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c96244782d6f44b0bce56892331e23c8","IPY_MODEL_1380567c51de4e59b23c5572adf26d91","IPY_MODEL_cc6eec01b9384e3887081f7c52f1d1c1"],"layout":"IPY_MODEL_981eb6ae1b56468db29871451dd47cf4"}},"c96244782d6f44b0bce56892331e23c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f5a37cd2dfc49538e04f8a5f03369b4","placeholder":"​","style":"IPY_MODEL_fcf4bbe92c9b476587bf91dbeccedcf9","value":"Downloading: 100%"}},"1380567c51de4e59b23c5572adf26d91":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_48420256cc4744949c91f5e6fd4ea996","max":227845,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ab3cda7bdce74876b49342e47ae8012a","value":227845}},"cc6eec01b9384e3887081f7c52f1d1c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d7b3d16842240549a63851f795e7b29","placeholder":"​","style":"IPY_MODEL_1e9715af13494c2390b359e9a04b9598","value":" 228k/228k [00:00&lt;00:00, 326kB/s]"}},"981eb6ae1b56468db29871451dd47cf4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f5a37cd2dfc49538e04f8a5f03369b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcf4bbe92c9b476587bf91dbeccedcf9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48420256cc4744949c91f5e6fd4ea996":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab3cda7bdce74876b49342e47ae8012a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7d7b3d16842240549a63851f795e7b29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e9715af13494c2390b359e9a04b9598":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba1fd6c808764271a0048f5510268fc1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a48236395e6046b9b87442d5e236b797","IPY_MODEL_777c741666804d7fb08fc169c06e2033","IPY_MODEL_4e8f2a96c5eb4781883deabf56a8d990"],"layout":"IPY_MODEL_10949ad33e5344dcbf141283eb36bfb9"}},"a48236395e6046b9b87442d5e236b797":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_450e3283cb394a2597d9d03e35b6949f","placeholder":"​","style":"IPY_MODEL_e9e10e00b3e14a25ae14c5a19588147d","value":"Downloading: 100%"}},"777c741666804d7fb08fc169c06e2033":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_044c0ff22d674519872d9485193aa1b5","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d55ebf1c6a2745d184ce91144f3ba132","value":442221694}},"4e8f2a96c5eb4781883deabf56a8d990":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_10e4f22c3b1945a6b6022d960272db1d","placeholder":"​","style":"IPY_MODEL_4a91a55a0d9e43d19dc65e53fb994968","value":" 442M/442M [00:07&lt;00:00, 55.4MB/s]"}},"10949ad33e5344dcbf141283eb36bfb9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"450e3283cb394a2597d9d03e35b6949f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9e10e00b3e14a25ae14c5a19588147d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"044c0ff22d674519872d9485193aa1b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d55ebf1c6a2745d184ce91144f3ba132":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"10e4f22c3b1945a6b6022d960272db1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a91a55a0d9e43d19dc65e53fb994968":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}