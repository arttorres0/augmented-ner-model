{"cells":[{"cell_type":"markdown","metadata":{"id":"FFh7WVoJH5dr"},"source":["Adapted from [ner_with_bilstm_and_crf](https://www.kaggle.com/nikkisharma536/ner-with-bilstm-and-crf/notebook)\n","Altigran Soares da Silva\n","IComp/UFAM - 15/03/2021\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12049,"status":"ok","timestamp":1656964160524,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"instant-coupon","outputId":"44c2a5c2-055b-4715-881f-c31eeb6946f0"},"outputs":[{"name":"stdout","output_type":"stream","text":["TensorFlow 1.x selected.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n","Requirement already satisfied: tokenizers!=0.11.3,\u003c0.13,\u003e=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.1.0-\u003etransformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003etransformers) (3.0.9)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers) (3.8.0)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2.10)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (1.24.3)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2022.6.15)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (1.2.2)\n","Requirement already satisfied: numpy\u003e=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n","Requirement already satisfied: scikit-learn\u003e=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n","Requirement already satisfied: threadpoolctl\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn\u003e=0.21.3-\u003eseqeval) (3.1.0)\n","Requirement already satisfied: scipy\u003e=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn\u003e=0.21.3-\u003eseqeval) (1.4.1)\n","Requirement already satisfied: joblib\u003e=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn\u003e=0.21.3-\u003eseqeval) (1.1.0)\n"]}],"source":["# For this to work, use:\n","# Keras 2.3.1\n","# TensorFlow 1.15.2\n","# Also remember to use GPU in your colab notebook\n","%tensorflow_version 1.x\n","\n","# Code to read csv file into Colaboratory:\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","from math import nan\n","from future.utils import iteritems\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import math\n","import random\n","import json\n","import pickle\n","import time\n","from requests import get\n","\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import torch\n","from torch import cuda\n","from torch.utils.data import Dataset, DataLoader\n","\n","!pip install sentencepiece\n","!pip install transformers\n","from transformers import BertForTokenClassification, AutoTokenizer\n","\n","!pip install seqeval\n","from seqeval.metrics import f1_score, classification_report"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mmt06ncv89hH"},"outputs":[],"source":["# Code to read csv file from google drive into Colaboratory:\n","DATA_TRAINING_FILE_ID = '1Y2gfhNgbGX7pA0FkA2vbOxdoSmNJVHIK'\n","DATA_TRAINING_FILENAME = 'ner_training_dataset.csv'\n","DATA_DEV_FILE_ID = '1AGW9cRPwBmeJqOo3WXPPcNckrX4jMcIn'\n","DATA_DEV_FILENAME = 'ner_validation_dataset.csv'\n","DATA_TEST_FILE_ID = '1L-fnx31bK0nZAl9_DDfo7-25H7PYU0l8'\n","DATA_TEST_FILENAME = 'ner_test_dataset.csv'\n","BACKUP_FOLDER_ID = '1YWR4Ip8w94RwFMyMtNpRa9M0FpiJtqd5'\n","\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","downloaded_training = drive.CreateFile({'id': DATA_TRAINING_FILE_ID})\n","downloaded_training.GetContentFile(DATA_TRAINING_FILENAME)\n","downloaded_dev = drive.CreateFile({'id': DATA_DEV_FILE_ID})\n","downloaded_dev.GetContentFile(DATA_DEV_FILENAME)\n","downloaded_test = drive.CreateFile({'id': DATA_TEST_FILE_ID})\n","downloaded_test.GetContentFile(DATA_TEST_FILENAME)\n","\n","# Read the csv file in a dataframe called \"data\"\n","training_data = pd.read_csv(DATA_TRAINING_FILENAME, encoding=\"latin1\")\n","dev_data = pd.read_csv(DATA_DEV_FILENAME, encoding=\"latin1\")\n","test_data = pd.read_csv(DATA_TEST_FILENAME, encoding=\"latin1\")\n","# Fill NaN values using the specified method\n","# Ffill propagate last valid observation/value forward to next valid \n","training_data = training_data.fillna(method=\"ffill\")\n","dev_data = dev_data.fillna(method=\"ffill\")\n","test_data = test_data.fillna(method=\"ffill\")\n","\n","notebook_filename = get('http://172.28.0.2:9000/api/sessions').json()[0]['name']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":588},"executionInfo":{"elapsed":525,"status":"ok","timestamp":1656964165476,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"adverse-doctor","outputId":"d6593d54-416b-40e5-f3c7-67df577968df"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of training sentences:  13052\n","Number of dev sentences:  3263\n","Number of test sentences:  27625\n","Number of words in the training dataset:  13860\n","Number of words in the dev dataset:  6360\n","Number of words in the test dataset:  21696\n","Tags in the training dataset: ['I-problem', 'I-treatment', 'B-problem', 'O', 'B-treatment', 'B-test', 'I-test']\n","Number of Labels in the training dataset:  7\n","Tags in the dev dataset: ['I-problem', 'I-treatment', 'B-problem', 'O', 'B-treatment', 'B-test', 'I-test']\n","Number of Labels in the dev dataset:  7\n","Tags in the test dataset: ['I-problem', 'I-treatment', 'B-problem', 'O', 'B-treatment', 'B-test', 'I-test']\n","Number of Labels in the test dataset:  7\n","What the training dataset looks like:\n"]},{"data":{"text/html":["\n","  \u003cdiv id=\"df-8810510f-44d3-4f86-9d16-864bb1d43024\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eSentence #\u003c/th\u003e\n","      \u003cth\u003eWord\u003c/th\u003e\n","      \u003cth\u003eTag\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003eSentence: 10707\u003c/td\u003e\n","      \u003ctd\u003eShe\u003c/td\u003e\n","      \u003ctd\u003eO\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003eSentence: 10707\u003c/td\u003e\n","      \u003ctd\u003ehad\u003c/td\u003e\n","      \u003ctd\u003eO\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003eSentence: 10707\u003c/td\u003e\n","      \u003ctd\u003enormal\u003c/td\u003e\n","      \u003ctd\u003eO\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003eSentence: 10707\u003c/td\u003e\n","      \u003ctd\u003ecomprehension\u003c/td\u003e\n","      \u003ctd\u003eO\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003eSentence: 10707\u003c/td\u003e\n","      \u003ctd\u003e.\u003c/td\u003e\n","      \u003ctd\u003eO\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e5\u003c/th\u003e\n","      \u003ctd\u003eSentence: 7349\u003c/td\u003e\n","      \u003ctd\u003eScott\u003c/td\u003e\n","      \u003ctd\u003eO\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e6\u003c/th\u003e\n","      \u003ctd\u003eSentence: 7349\u003c/td\u003e\n","      \u003ctd\u003eRobert\u003c/td\u003e\n","      \u003ctd\u003eO\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e7\u003c/th\u003e\n","      \u003ctd\u003eSentence: 7349\u003c/td\u003e\n","      \u003ctd\u003eNP\u003c/td\u003e\n","      \u003ctd\u003eO\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e8\u003c/th\u003e\n","      \u003ctd\u003eSentence: 7349\u003c/td\u003e\n","      \u003ctd\u003e80-AUM\u003c/td\u003e\n","      \u003ctd\u003eO\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e9\u003c/th\u003e\n","      \u003ctd\u003eSentence: 7349\u003c/td\u003e\n","      \u003ctd\u003e2017-06-29\u003c/td\u003e\n","      \u003ctd\u003eO\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8810510f-44d3-4f86-9d16-864bb1d43024')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-8810510f-44d3-4f86-9d16-864bb1d43024 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8810510f-44d3-4f86-9d16-864bb1d43024');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["        Sentence #           Word Tag\n","0  Sentence: 10707            She   O\n","1  Sentence: 10707            had   O\n","2  Sentence: 10707         normal   O\n","3  Sentence: 10707  comprehension   O\n","4  Sentence: 10707              .   O\n","5   Sentence: 7349          Scott   O\n","6   Sentence: 7349         Robert   O\n","7   Sentence: 7349             NP   O\n","8   Sentence: 7349         80-AUM   O\n","9   Sentence: 7349     2017-06-29   O"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Explore the input dataset\n","print(\"Number of training sentences: \", len(training_data.groupby(['Sentence #'])))\n","print(\"Number of dev sentences: \", len(dev_data.groupby(['Sentence #'])))\n","print(\"Number of test sentences: \", len(test_data.groupby(['Sentence #'])))\n","\n","training_words = list(set(training_data[\"Word\"].values))\n","n_training_words = len(training_words)\n","print(\"Number of words in the training dataset: \", n_training_words)\n","dev_words = list(set(dev_data[\"Word\"].values))\n","n_dev_words = len(dev_words)\n","print(\"Number of words in the dev dataset: \", n_dev_words)\n","test_words = list(set(test_data[\"Word\"].values))\n","n_test_words = len(test_words)\n","print(\"Number of words in the test dataset: \", n_test_words)\n","\n","training_tags = list(set(training_data[\"Tag\"].values))\n","print(\"Tags in the training dataset:\", training_tags)\n","n_training_tags = len(training_tags)\n","print(\"Number of Labels in the training dataset: \", n_training_tags)\n","dev_tags = list(set(dev_data[\"Tag\"].values))\n","print(\"Tags in the dev dataset:\", dev_tags)\n","n_dev_tags = len(dev_tags)\n","print(\"Number of Labels in the dev dataset: \", n_dev_tags)\n","test_tags = list(set(test_data[\"Tag\"].values))\n","print(\"Tags in the test dataset:\", test_tags)\n","n_test_tags = len(test_tags)\n","print(\"Number of Labels in the test dataset: \", n_test_tags)\n","\n","print(\"What the training dataset looks like:\")\n","# Show the first 10 rows\n","training_data.head(n=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2909,"status":"ok","timestamp":1656964168382,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"painful-karaoke","outputId":"eebb9831-5e16-460f-a07a-23c72fd2b662"},"outputs":[{"data":{"text/plain":["[('Last', 'O'),\n"," ('menstrual', 'O'),\n"," ('period', 'O'),\n"," ('2009-02-21', 'O'),\n"," ('.', 'O')]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# SentenceGetter re-organize \"data\" as an arry of sentences\n","# Each sentence is a list of pairs \u003cword,tag\u003e \n","class SentenceGetter(object):\n","    \n","    def __init__(self, dataset):\n","        self.n_sent = 1\n","        self.dataset = dataset\n","        self.empty = False\n","        agg_func = lambda s: [(w, t) for w,t in zip(s[\"Word\"].values.tolist(),\n","                                                        s[\"Tag\"].values.tolist())]\n","        self.grouped = self.dataset.groupby(\"Sentence #\").apply(agg_func)\n","        self.sentences = [s for s in self.grouped]\n","    \n","    def get_next(self):\n","        try:\n","            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n","            self.n_sent += 1\n","            return s\n","        except:\n","            return None\n","\n","training_getter = SentenceGetter(training_data)\n","training_sentences = training_getter.sentences\n","dev_getter = SentenceGetter(dev_data)\n","dev_sentences = dev_getter.sentences\n","test_getter = SentenceGetter(test_data)\n","test_sentences = test_getter.sentences\n","\n","# Example: training sentence #200 \n","training_sentences[200]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1656964168382,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"round-providence","outputId":"1c2c903d-9121-4e2b-802a-ae630346630e"},"outputs":[{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["# Explore set of sentences\n","# Plot sentences by length\n","plt.hist([len(s) for s in training_sentences], bins=50)\n","plt.title('Token per training sentence')\n","plt.xlabel('Len (number of token)')\n","plt.ylabel('# samples')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"elapsed":3229,"status":"ok","timestamp":1656964171607,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"urxTzspTyPq5","outputId":"741f0f2d-89f8-4c06-825a-1f83815d7258"},"outputs":[{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["# Explore set of sentences\n","# Plot sentences by length\n","plt.hist([len(s) for s in dev_sentences], bins=50)\n","plt.title('Token per dev sentence')\n","plt.xlabel('Len (number of token)')\n","plt.ylabel('# samples')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1656964171607,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"JJ91V_51yPw9","outputId":"f42962dc-66a5-4884-8996-8bd6941762fe"},"outputs":[{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["# Explore set of sentences\n","# Plot sentences by length\n","plt.hist([len(s) for s in test_sentences], bins=50)\n","plt.title('Token per test sentence')\n","plt.xlabel('Len (number of token)')\n","plt.ylabel('# samples')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1656964171608,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"juvenile-scene","outputId":"7a0fa7aa-fcb2-469a-ac55-74a39af53883"},"outputs":[{"name":"stdout","output_type":"stream","text":["5478\n","endothelialitis\n","4\n","B-treatment\n"]}],"source":["# Keras (and most other ML packages) expect all the ids to be numeric, \n","# this is an optimisation to save memory. \n","# We will create the following dictionaries:\n","# word2idx: assign a numeric index to each word in the dataset\n","# idx2word: inverted version of word2idx\n","# tag2idx: assign a numeric index to each tag in the dataset\n","# idx2tag: inverted version of tag2idx\n","\n","# Group training, dev and test data in order to create word-index dicts and to\n","# convert data to numeric indeces later\n","data = pd.concat([training_data, dev_data, test_data])\n","\n","# words \u003c= list of all words in the input dataset\n","words = list(set(data[\"Word\"].values))\n","n_words = len(words)\n","\n","# tags \u003c= list of all tags in the input dataset\n","tags = []\n","for tag in set(data[\"Tag\"].values):\n","    if tag is nan or isinstance(tag, float):\n","        tags.append('unk')\n","    else:\n","        tags.append(tag)\n","n_tags = len(tags)\n","\n","# Dictionaries\n","word2idx = {w: i for i, w in enumerate(words)}\n","idx2word = {i: w for w, i in iteritems(word2idx)}\n","tag2idx = {t: i for i, t in enumerate(tags)}\n","idx2tag = {v: k for k, v in iteritems(tag2idx)}\n","\n","# Index number for the word 'comprehension'\n","print(word2idx['comprehension'])\n","# Word of index 10\n","print(idx2word[10])\n","# Index number for the tag 'B-treatment'\n","print(tag2idx['B-treatment'])\n","# Tag of index 4\n","print(idx2tag[4])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"delayed-dryer"},"outputs":[],"source":["# Convert train, dev and test data to numeric values\n","X_train = [[word2idx[w[0]] for w in s] for s in training_sentences]\n","y_train = [[tag2idx[w[1]] for w in s] for s in training_sentences]\n","\n","X_dev = [[word2idx[w[0]] for w in s] for s in dev_sentences]\n","y_dev = [[tag2idx[w[1]] for w in s] for s in dev_sentences]\n","\n","X_test = [[word2idx[w[0]] for w in s] for s in test_sentences]\n","y_test = [[tag2idx[w[1]] for w in s] for s in test_sentences]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1656964172098,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"Ttsyh05Rhovo","outputId":"0029d109-3d3b-41a3-c9d3-75bf8e58271f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Points in X_train before removal: 13052\n","Points in y_train before removal: 13052\n","Points in X_train before removal: 13052\n","Points in y_train before removal: 13052\n"]}],"source":["# Use this function to randomly remove some points from training dataset\n","# Use removal percentage in decimal value. E.g.: if you set as 0.5, it will\n","# remove 50% of the dataset\n","\n","def random_remove_data_points(dataset, labels, removal_percentage):\n","    if removal_percentage \u003c 0 or removal_percentage \u003e 1:\n","        raise Exception(\"Invalid removal percentage\")\n","    \n","    if removal_percentage == 1:\n","        raise Exception(\"You can't remove the entire dataset\")\n","    \n","    number_of_points_remaining = round(len(dataset)*(1-removal_percentage))\n","\n","    try_again = True\n","\n","    while try_again:\n","      random_idxs = np.random.choice(len(dataset), number_of_points_remaining, replace=False)\n","      cut_dataset_sentences = [dataset[i] for i in random_idxs]\n","      cut_dataset_labels = [labels[i] for i in random_idxs]\n","      cut_tags = list(set([idx2tag[j] for sub in cut_dataset_labels for j in sub]))\n","\n","      if all(i in cut_tags for i in tags if i[:2] == \"B-\"):\n","        try_again = False\n","\n","    return cut_dataset_sentences, cut_dataset_labels \n","\n","print(f\"Points in X_train before removal: {len(X_train)}\")\n","print(f\"Points in y_train before removal: {len(y_train)}\")\n","# X_train, y_train = random_remove_data_points(X_train, y_train, 0.95)\n","print(f\"Points in X_train before removal: {len(X_train)}\")\n","print(f\"Points in y_train before removal: {len(y_train)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0SN-NYLpgsFa"},"outputs":[],"source":["# Aux functions to save data and dicts, if data consistency is important\n","# and there is desire to not random split again\n","\n","def save_backup_dataset(dataset, filename):\n","  dataset_df = pd.DataFrame(dataset)\n","  dataset_df.to_csv(filename, index=False)\n","  gfile = drive.CreateFile({'parents': [{'id': BACKUP_FOLDER_ID}]})\n","  gfile.SetContentFile(filename)\n","  gfile.Upload()\n","\n","def save_backup_dict(dict, filename):\n","  dict_file = open(filename, \"wb\")\n","  pickle.dump(dict, dict_file)\n","  dict_file.close()\n","  gfile = drive.CreateFile({'parents': [{'id': BACKUP_FOLDER_ID}]})\n","  gfile.SetContentFile(filename)\n","  gfile.Upload()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20948,"status":"ok","timestamp":1656964193042,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"MzRQfI30tuI2","outputId":"fe4925ca-9d5a-49f1-b8a8-c3e82babe9e6"},"outputs":[{"name":"stdout","output_type":"stream","text":["[4832, 12984]\n","[3, 3]\n","[23017, 18574, 22015, 27127, 20996, 2135, 3941, 9890, 4844, 13999, 2908, 1274, 3212, 11436]\n","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n","[25428, 25738, 13092]\n","[3, 3, 3]\n","5478\n","4\n","B-problem\n","methylene\n","28388\n","7\n"]}],"source":["# Uncomment this cell if you want to save data for further use\n","\n","# Check some points before saving\n","print(X_train[0])\n","print(y_train[0])\n","print(X_dev[0])\n","print(y_dev[0])\n","print(X_test[0])\n","print(y_test[0])\n","print(word2idx['comprehension'])\n","print(tag2idx['B-treatment'])\n","print(idx2tag[2])\n","print(idx2word[100])\n","print(n_words)\n","print(n_tags)\n","\n","X_train_filename = f'{notebook_filename}_X_train.csv'\n","y_train_filename = f'{notebook_filename}_y_train.csv'\n","X_dev_filename = f'{notebook_filename}_X_dev.csv'\n","y_dev_filename = f'{notebook_filename}_y_dev.csv'\n","X_test_filename = f'{notebook_filename}_X_test.csv'\n","y_test_filename = f'{notebook_filename}_y_test.csv'\n","\n","word2idx_filename = f'{notebook_filename}_word2idx.pkl'\n","idx2word_filename = f'{notebook_filename}_idx2word.pkl'\n","tag2idx_filename = f'{notebook_filename}_tag2idx.pkl'\n","idx2tag_filename = f'{notebook_filename}_idx2tag.pkl'\n","\n","others_filename = f'{notebook_filename}_others.pkl'\n","\n","save_backup_dataset(X_train, X_train_filename)\n","save_backup_dataset(y_train, y_train_filename)\n","save_backup_dataset(X_dev, X_dev_filename)\n","save_backup_dataset(y_dev, y_dev_filename)\n","save_backup_dataset(X_test, X_test_filename)\n","save_backup_dataset(y_test, y_test_filename)\n","\n","save_backup_dict(word2idx, word2idx_filename)\n","save_backup_dict(idx2word, idx2word_filename)\n","save_backup_dict(tag2idx, tag2idx_filename)\n","save_backup_dict(idx2tag, idx2tag_filename)\n","\n","save_backup_dict({\"n_words\":n_words, \"n_tags\":n_tags}, others_filename)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":67267,"status":"ok","timestamp":1657662046244,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"zvip_oC0j5-y","outputId":"6ed55094-5314-4870-8843-bbdf95b79755"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING: Tensorflow 1 is deprecated, and support will be removed on August 1, 2022.\n","After that, `%tensorflow_version 1.x` will throw an error.\n","\n","Your notebook should be updated to use Tensorflow 2.\n","See the guide at https://www.tensorflow.org/guide/migrate#migrate-from-tensorflow-1x-to-tensorflow-2.\n","\n","TensorFlow 1.x selected.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 14.0 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 14.9 MB/s \n","\u001b[?25hCollecting huggingface-hub\u003c1.0,\u003e=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 13.8 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Collecting pyyaml\u003e=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 83.9 MB/s \n","\u001b[?25hRequirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Collecting tokenizers!=0.11.3,\u003c0.13,\u003e=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 82.2 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.1.0-\u003etransformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003etransformers) (3.0.9)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers) (3.8.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2022.6.15)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2.10)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (1.24.3)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.1\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["yaml"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy\u003e=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n","Requirement already satisfied: scikit-learn\u003e=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n","Requirement already satisfied: scipy\u003e=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn\u003e=0.21.3-\u003eseqeval) (1.5.4)\n","Requirement already satisfied: threadpoolctl\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn\u003e=0.21.3-\u003eseqeval) (3.1.0)\n","Requirement already satisfied: joblib\u003e=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn\u003e=0.21.3-\u003eseqeval) (1.1.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=38e537f292b885137700c07ca8e3a0fa4d4c84c4e44558d5daf60da02c930bb0\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n","[4832, 12984]\n","[3, 3]\n","[23017, 18574, 22015, 27127, 20996, 2135, 3941, 9890, 4844, 13999, 2908, 1274, 3212, 11436]\n","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n","[25428, 25738, 13092]\n","[3, 3, 3]\n","5478\n","4\n","B-problem\n","methylene\n","28388\n","7\n"]}],"source":["# Uncomment this cell if you want to load saved data\n","\n","# Re-import necessary libs\n","import pandas as pd\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","import pickle, math\n","from requests import get\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import random\n","import time\n","%tensorflow_version 1.x\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import torch\n","from torch import cuda\n","from torch.utils.data import Dataset, DataLoader\n","!pip install sentencepiece\n","!pip install transformers\n","from transformers import BertForTokenClassification, AutoTokenizer\n","import matplotlib.pyplot as plt\n","!pip install seqeval\n","from seqeval.metrics import f1_score, classification_report\n","\n","BACKUP_FOLDER_ID = '1YWR4Ip8w94RwFMyMtNpRa9M0FpiJtqd5'\n","notebook_filename = get('http://172.28.0.2:9000/api/sessions').json()[0]['name']\n","\n","X_train_filename = f'{notebook_filename}_X_train.csv'\n","y_train_filename = f'{notebook_filename}_y_train.csv'\n","X_dev_filename = f'{notebook_filename}_X_dev.csv'\n","y_dev_filename = f'{notebook_filename}_y_dev.csv'\n","X_test_filename = f'{notebook_filename}_X_test.csv'\n","y_test_filename = f'{notebook_filename}_y_test.csv'\n","\n","word2idx_filename = f'{notebook_filename}_word2idx.pkl'\n","idx2word_filename = f'{notebook_filename}_idx2word.pkl'\n","tag2idx_filename = f'{notebook_filename}_tag2idx.pkl'\n","idx2tag_filename = f'{notebook_filename}_idx2tag.pkl'\n","\n","others_filename = f'{notebook_filename}_others.pkl'\n","\n","# Re-get important variables\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","def get_backup_files_ids(folder_id):\n","  file_list = drive.ListFile({'q': \"'{}' in parents and trashed=false\".format(folder_id)}).GetList()\n","  return file_list\n","\n","def load_backup_dataset(file_id):\n","  downloaded = drive.CreateFile({'id':file_id})\n","  downloaded.GetContentFile(f\"{file_id}.csv\")\n","\n","  dataset = pd.read_csv(f\"{file_id}.csv\", encoding=\"latin1\")\n","  dataset = dataset.fillna(method=\"ffill\")\n","  dataset = dataset.values.tolist()\n","  dataset = [ [ int(word) for word in sentence if str(word) != 'nan' ] for sentence in dataset]\n","  return dataset\n","\n","def load_backup_dict(file_id):\n","  downloaded = drive.CreateFile({'id':file_id})\n","  downloaded.GetContentFile(f\"{file_id}.pkl\")\n","\n","  dict_file = open(f\"{file_id}.pkl\", \"rb\")\n","  out_dict = pickle.load(dict_file)\n","  return out_dict\n","\n","backup_file_list = get_backup_files_ids(BACKUP_FOLDER_ID)\n","\n","X_train_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == X_train_filename][0]['id']\n","y_train_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == y_train_filename][0]['id']\n","X_dev_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == X_dev_filename][0]['id']\n","y_dev_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == y_dev_filename][0]['id']\n","X_test_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == X_test_filename][0]['id']\n","y_test_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == y_test_filename][0]['id']\n","\n","word2idx_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == word2idx_filename][0]['id']\n","idx2word_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == idx2word_filename][0]['id']\n","tag2idx_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == tag2idx_filename][0]['id']\n","idx2tag_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == idx2tag_filename][0]['id']\n","\n","others_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == others_filename][0]['id']\n","\n","X_train = load_backup_dataset(X_train_file_id)\n","y_train = load_backup_dataset(y_train_file_id)\n","X_dev = load_backup_dataset(X_dev_file_id)\n","y_dev = load_backup_dataset(y_dev_file_id)\n","X_test = load_backup_dataset(X_test_file_id)\n","y_test = load_backup_dataset(y_test_file_id)\n","\n","word2idx = load_backup_dict(word2idx_file_id)\n","idx2word = load_backup_dict(idx2word_file_id)\n","tag2idx = load_backup_dict(tag2idx_file_id)\n","idx2tag = load_backup_dict(idx2tag_file_id)\n","\n","others = load_backup_dict(others_file_id)\n","\n","n_words = others[\"n_words\"]\n","n_tags = others[\"n_tags\"]\n","\n","# Check some points after loading data to see if they match the ones before saving\n","print(X_train[0])\n","print(y_train[0])\n","print(X_dev[0])\n","print(y_dev[0])\n","print(X_test[0])\n","print(y_test[0])\n","print(word2idx['comprehension'])\n","print(tag2idx['B-treatment'])\n","print(idx2tag[2])\n","print(idx2word[100])\n","print(n_words)\n","print(n_tags)"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6480,"status":"ok","timestamp":1657662052710,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"ux5-6tyMhovp"},"outputs":[],"source":["# Aux function to help in augmentation. Generates a dict where entities\n","# are the keys, and words are the values.\n","\n","def create_entities_dict(dataset, labels, decoded_word=False):\n","    entities_dict = {}\n","    \n","    for i, sentence in enumerate(dataset):\n","        for k, word in enumerate(sentence):\n","            tag = idx2tag[labels[i][k]]\n","            if tag[:2] == \"B-\":\n","                if decoded_word:\n","                    word_list = [idx2word[word]]\n","                else:\n","                    word_list = [word]\n","                j = k + 1\n","                if j \u003c len(labels[i]):\n","                    while idx2tag[labels[i][j]][:2] == \"I-\":\n","                        if decoded_word:\n","                            word_list.append(idx2word[dataset[i][j]])\n","                        else:\n","                            word_list.append(dataset[i][j])\n","                        j = j+1\n","                        if j == len(labels[i]):\n","                            break\n","                        \n","                if entities_dict.get(tag):\n","                    if word_list not in entities_dict[tag]:\n","                        entities_dict[tag].append(word_list)\n","                else:\n","                    entities_dict[tag] = [word_list]\n","                    \n","    return entities_dict\n","\n","entities_dict = create_entities_dict(X_train, y_train)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1657662065134,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"2wRVTj71hovp"},"outputs":[],"source":["# Augmentation function using entity replacement technique.\n","# It will generate a new dataset, with X% more points based on\n","# the original dataset. E.g.: if you set augmentation percentage as 0.5 and dataset has\n","# 1000 points, it will generate a dataset with 1500 points.\n","\n","def generate_sentences(dataset, labels, entities_dict, augmented_set_size_percentage):\n","    if augmented_set_size_percentage \u003c 0:\n","        raise Exception(\"Invalid augmented set size percentage\")\n","\n","    number_of_new_sentences = math.ceil(augmented_set_size_percentage * len(dataset))\n","    random_idxs = np.random.choice(len(dataset), number_of_new_sentences, replace=True)\n","    \n","    base_sequences = [dataset[i] for i in random_idxs]\n","    base_labels = [labels[i] for i in random_idxs]\n","\n","    new_sequences = []\n","    new_labels = []\n","    \n","    for k, sequence in enumerate(base_sequences):\n","        new_sequence = []\n","        new_label = []\n","\n","        for i, word in enumerate(sequence):\n","            tag = idx2tag[base_labels[k][i]]\n","            if tag == \"O\":\n","                new_sequence.append(word)\n","                new_label.append(base_labels[k][i])\n","            elif tag[:2] == \"B-\":\n","                same_entities_type_tmp = entities_dict[tag]\n","                same_entities_type = np.array(same_entities_type_tmp, dtype=object)\n","                random_entity_idx = np.random.choice(len(same_entities_type), 1)[0]\n","                random_entity = same_entities_type[random_entity_idx]\n","                random_number_of_tokens = random.randint(1, len(random_entity))\n","                random_entity_tokens = np.random.choice(random_entity, random_number_of_tokens, replace = False).tolist()\n","                entity = tag[2:]\n","                decoded_token_labels = [f\"I-{entity}\" for token in random_entity_tokens]\n","                decoded_token_labels[0] = tag\n","                encoded_token_labels = [tag2idx[label] for label in decoded_token_labels]\n","                new_sequence = new_sequence + random_entity_tokens\n","                new_label = new_label + encoded_token_labels\n","\n","        new_sequences.append(new_sequence)\n","        new_labels.append(new_label)\n","\n","    augmented_X_train = dataset + new_sequences\n","    augmented_y_train = labels + new_labels\n","\n","    print(f\"Points in X_train after augmentation: {len(augmented_X_train)}\")\n","    print(f\"Points in y_train after augmentation: {len(augmented_y_train)}\")\n","\n","    return augmented_X_train, augmented_y_train"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"elapsed":12425,"status":"ok","timestamp":1657662065133,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"mYHzTnzZZfBg","outputId":"56bd12b6-2338-40d2-ab25-4314383ff1a0"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"836046a4d4aa4d0b81ed1af91176ad53","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/385 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f6c82d5ab1664ebb81a6a49b66cd0d13","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/223k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n","\n","class dataset(Dataset):\n","  def __init__(self, dataframe, tokenizer, max_len):\n","        self.len = len(dataframe)\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","  def __getitem__(self, index):\n","        # step 1: get the sentence and word labels\n","        sentence = self.data.sentence[index]\n","        word_labels = self.data.word_labels[index].split(\",\") \n","\n","        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n","        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n","        encoding = self.tokenizer(sentence,\n","                             return_offsets_mapping=True, \n","                             padding='max_length', \n","                             truncation=True, \n","                             max_length=self.max_len)\n","        \n","        # step 3: create token labels only for first word pieces of each tokenized word\n","        labels = [tag2idx[label] for label in word_labels] \n","        # code based on https://huggingface.co/transformers/custom_datasets.html#tok-ner\n","        # create an empty array of -100 of length max_length\n","        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n","        \n","        # set only labels whose first offset position is 0 and the second is not 0\n","        i = 0\n","        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n","          if mapping[0] == 0 and mapping[1] != 0:\n","            # overwrite label\n","            encoded_labels[idx] = labels[i]\n","            i += 1\n","\n","        # step 4: turn everything into PyTorch tensors\n","        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n","        item['labels'] = torch.as_tensor(encoded_labels)\n","        \n","        return item\n","\n","  def __len__(self):\n","        return self.len"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1657662065135,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"d8H1s-6b_-pM"},"outputs":[],"source":["# some configuration variables\n","LEARNING_RATE = 5e-05\n","MAX_GRAD_NORM = 10\n","TRAINING_STOP_LOSS_PERCENTAGE = 1\n","\n","# Model creation function\n","def create_model(maxlen, n_labels, training_set, testing_set, validation_set):\n","  device = 'cuda' if cuda.is_available() else 'cpu'\n","  print(\"Device: \", device)\n","\n","  model = BertForTokenClassification.from_pretrained('allenai/scibert_scivocab_uncased', num_labels=n_labels)\n","  model.to(device)\n","\n","  optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n","\n","  TRAIN_BATCH_SIZE = round(0.05*len(training_set))\n","  if TRAIN_BATCH_SIZE \u003e 32:\n","    TRAIN_BATCH_SIZE = 32\n","  if TRAIN_BATCH_SIZE \u003c 10:\n","    TRAIN_BATCH_SIZE = 10\n","\n","  VALID_BATCH_SIZE = round(0.1*len(validation_set))\n","  if VALID_BATCH_SIZE \u003e 32:\n","    VALID_BATCH_SIZE = 32\n","  if VALID_BATCH_SIZE \u003c 10:\n","    VALID_BATCH_SIZE = 10\n","\n","  train_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                  'shuffle': True,\n","                  'num_workers': 0\n","                  }\n","\n","  test_params = {'batch_size': VALID_BATCH_SIZE,\n","                  'shuffle': True,\n","                  'num_workers': 0\n","                  }\n","\n","  training_loader = DataLoader(training_set, **train_params)\n","  testing_loader = DataLoader(testing_set, **test_params)\n","  validation_loader = DataLoader(validation_set, **test_params)\n","\n","  return model, device, optimizer, training_loader, testing_loader, validation_loader"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1657662065135,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"cjp-jXx4AmiV"},"outputs":[],"source":["# Model training function\n","def train(model, device, optimizer, training_loader, epoch, training_stop_loss_percentage):\n","    tr_loss, tr_accuracy = 0, 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","    tr_preds, tr_labels = [], []\n","    losses = []\n","    # put model in training mode\n","    model.train()\n","    \n","    for idx, batch in enumerate(training_loader):\n","        \n","        ids = batch['input_ids'].to(device, dtype = torch.long)\n","        mask = batch['attention_mask'].to(device, dtype = torch.long)\n","        labels = batch['labels'].to(device, dtype = torch.long)\n","\n","        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels, return_dict = False)\n","        tr_loss += loss.item()\n","\n","        nb_tr_steps += 1\n","        nb_tr_examples += labels.size(0)\n","        \n","        if idx % 100==0:\n","            loss_step = tr_loss/nb_tr_steps\n","            print(f\"Training loss per 100 training steps: {loss_step}\")\n","            losses.append(loss_step)\n","            last_5_losses = losses[-5:]\n","            loss_min = min(last_5_losses)\n","            loss_max = max(last_5_losses)\n","            if len(last_5_losses) \u003e 1 and (loss_max - loss_min)/loss_max \u003c training_stop_loss_percentage/100:\n","              print(\"Stopping epoch...\")\n","              break\n","           \n","        # compute training accuracy\n","        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","        \n","        # only compute accuracy at active labels\n","        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n","        \n","        labels = torch.masked_select(flattened_targets, active_accuracy)\n","        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","        \n","        tr_labels.extend(labels)\n","        tr_preds.extend(predictions)\n","\n","        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n","        tr_accuracy += tmp_tr_accuracy\n","    \n","        # gradient clipping\n","        torch.nn.utils.clip_grad_norm_(\n","            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n","        )\n","        \n","        # backward pass\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    epoch_loss = tr_loss / nb_tr_steps\n","    tr_accuracy = tr_accuracy / nb_tr_steps\n","    print(f\"Training loss epoch: {epoch_loss}\")\n","    print(f\"Training accuracy epoch: {tr_accuracy}\")"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1657662065135,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"JvdztU6FA8Bd"},"outputs":[],"source":["# Model testing function\n","def test(model, device, testing_loader):\n","    print(\"Validating model...\")\n","    # put model in evaluation mode\n","    model.eval()\n","    \n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_examples, nb_eval_steps = 0, 0\n","    eval_preds, eval_labels = [], []\n","    \n","    with torch.no_grad():\n","        for idx, batch in enumerate(testing_loader):\n","            \n","            ids = batch['input_ids'].to(device, dtype = torch.long)\n","            mask = batch['attention_mask'].to(device, dtype = torch.long)\n","            labels = batch['labels'].to(device, dtype = torch.long)\n","            \n","            loss, eval_logits = model(input_ids=ids, attention_mask=mask, labels=labels, return_dict = False)\n","            \n","            eval_loss += loss.item()\n","\n","            nb_eval_steps += 1\n","            nb_eval_examples += labels.size(0)\n","        \n","            # compute evaluation accuracy\n","            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","            \n","            # only compute accuracy at active labels\n","            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","        \n","            labels = torch.masked_select(flattened_targets, active_accuracy)\n","            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","            \n","            eval_labels.extend(labels)\n","            eval_preds.extend(predictions)\n","            \n","            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n","            eval_accuracy += tmp_eval_accuracy\n","\n","    labels = [idx2tag[id.item()] for id in eval_labels]\n","    predictions = [idx2tag[id.item()] for id in eval_preds]\n","    \n","    eval_loss = eval_loss / nb_eval_steps\n","    eval_accuracy = eval_accuracy / nb_eval_steps\n","    print(f\"Validation Loss: {eval_loss}\")\n","    print(f\"Validation Accuracy: {eval_accuracy}\")\n","\n","    return labels, predictions, eval_loss"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1657662065136,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"jMknjbDrh6Fk"},"outputs":[],"source":["def create_train_and_validate_model(augmented_percentage):\n","\n","  augmented_X_train, augmented_y_train = generate_sentences(X_train, y_train, entities_dict, augmented_percentage)\n","\n","  maxlen_X_train = max([len(s) for s in augmented_X_train])\n","  maxlen_X_test = max([len(s) for s in X_test])\n","  maxlen_X_dev = max([len(s) for s in X_dev])\n","  maxlen_y_train = max([len(s) for s in augmented_y_train])\n","  maxlen_y_test = max([len(s) for s in y_test])\n","  maxlen_y_dev = max([len(s) for s in y_dev])\n","\n","  maxlen = max([maxlen_X_train, maxlen_X_test, maxlen_X_dev, maxlen_y_train, maxlen_y_test, maxlen_y_dev])\n","\n","  augmented_X_train_words = [' '.join([idx2word[word] for word in sentence]) for sentence in augmented_X_train]\n","  X_dev_words = [' '.join([idx2word[word] for word in sentence]) for sentence in X_dev]\n","  X_test_words = [' '.join([idx2word[word] for word in sentence]) for sentence in X_test]\n","  augmented_y_train_tags = [','.join([idx2tag[tag] for tag in sentence]) for sentence in augmented_y_train]\n","  y_dev_tags = [','.join([idx2tag[tag] for tag in sentence]) for sentence in y_dev]\n","  y_test_tags = [','.join([idx2tag[tag] for tag in sentence]) for sentence in y_test]\n","\n","  new_train_df = pd.DataFrame({\"sentence\": augmented_X_train_words, \"word_labels\": augmented_y_train_tags}).reset_index(drop=True)\n","  new_test_df = pd.DataFrame({\"sentence\": X_test_words, \"word_labels\": y_test_tags}).reset_index(drop=True)\n","  new_val_df = pd.DataFrame({\"sentence\": X_dev_words, \"word_labels\": y_dev_tags}).reset_index(drop=True)\n","\n","  training_set = dataset(new_train_df, tokenizer, maxlen)\n","  testing_set = dataset(new_test_df, tokenizer, maxlen)\n","  validation_set = dataset(new_val_df, tokenizer, maxlen)\n","\n","  model, device, optimizer, training_loader, testing_loader, val_loader = create_model(maxlen, len(tag2idx), training_set, testing_set, validation_set)\n","\n","  training_start_time = time.clock()\n","  min_val_loss = 0\n","  MAX_PATIENCE = 5\n","  patience = 0\n","\n","  for epoch in range(100):\n","    print(f\"Training epoch: {epoch + 1}\")\n","    if patience == MAX_PATIENCE:\n","      print(\"Patience limit reached\")\n","      break\n","    train(model, device, optimizer, training_loader, epoch, TRAINING_STOP_LOSS_PERCENTAGE)\n","    labels, predictions, val_loss = test(model, device, val_loader)\n","    if ((min_val_loss == 0) or (min_val_loss != 0 and val_loss \u003c min_val_loss)):\n","      min_val_loss = val_loss\n","      torch.save(model.state_dict(), 'checkpoint.pt')\n","      patience = 0\n","    else:\n","      patience = patience + 1\n","  print(f\"Training duration: {(time.clock() - training_start_time)/60} minutes\")\n","\n","  checkpoint = torch.load('checkpoint.pt')\n","  model.load_state_dict(checkpoint)\n","\n","  validation_start_time = time.clock()\n","  labels, predictions, test_loss = test(model, device, testing_loader)\n","  labels = [labels]\n","  predictions = [predictions]\n","  print(f\"Validation duration: {(time.clock() - validation_start_time)/60} minutes\")\n","\n","  print(\"F1-score (test): {:.1%}\".format(f1_score(labels, predictions)))\n","  print(classification_report(labels, predictions))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"bM0wPLD5kaw4","outputId":"ba82faec-0ab0-44a8-e295-ae4df1932ad6"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 13052\n","Points in y_train after augmentation: 13052\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0781595706939697\n","Training loss per 100 training steps: 0.2552810138884452\n","Training loss per 100 training steps: 0.1890862781684197\n","Training loss epoch: 0.18859667692552595\n","Training accuracy epoch: 0.9424734477124183\n","Validating model...\n","Validation Loss: 0.14019957619408766\n","Validation Accuracy: 0.9583284702769996\n","Training epoch: 2\n","Training loss per 100 training steps: 0.038125477731227875\n","Training loss per 100 training steps: 0.05920941470246209\n","Training loss per 100 training steps: 0.062007471995511605\n","Training loss epoch: 0.061573719092206484\n","Training accuracy epoch: 0.9806219362745098\n","Validating model...\n","Validation Loss: 0.1317456836319145\n","Validation Accuracy: 0.9669117647058824\n","Training epoch: 3\n","Training loss per 100 training steps: 0.006866083480417728\n","Training loss per 100 training steps: 0.022042413325150414\n","Training loss per 100 training steps: 0.03004852764364054\n","Training loss epoch: 0.030162356113649758\n","Training accuracy epoch: 0.9904258578431373\n","Validating model...\n","Validation Loss: 0.1425244557287763\n","Validation Accuracy: 0.9641544117647058\n","Training epoch: 4\n","Training loss per 100 training steps: 0.004681430757045746\n","Training loss per 100 training steps: 0.019918576339928266\n","Training loss per 100 training steps: 0.022400069990790732\n","Training loss epoch: 0.02214068332863926\n","Training accuracy epoch: 0.9934895833333334\n","Validating model...\n","Validation Loss: 0.1453467176578866\n","Validation Accuracy: 0.9662844304388422\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0626349225640297\n","Training loss per 100 training steps: 0.01965680890537955\n","Training loss per 100 training steps: 0.02391912566398882\n","Training loss epoch: 0.02415821981326992\n","Training accuracy epoch: 0.9925653594771241\n","Validating model...\n","Validation Loss: 0.15822667024993137\n","Validation Accuracy: 0.9641495487083722\n","Training epoch: 6\n","Training loss per 100 training steps: 0.05687839165329933\n","Training loss per 100 training steps: 0.015534139096236669\n","Training loss per 100 training steps: 0.01643443704436218\n","Training loss epoch: 0.016372567904838042\n","Training accuracy epoch: 0.9946384803921569\n","Validating model...\n","Validation Loss: 0.18950542004427454\n","Validation Accuracy: 0.9672035480859009\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0007560561061836779\n","Training loss per 100 training steps: 0.01754603068785751\n","Training loss per 100 training steps: 0.01695635227213697\n","Training loss epoch: 0.01687582910951688\n","Training accuracy epoch: 0.9950980392156863\n","Validating model...\n","Validation Loss: 0.1676274644229196\n","Validation Accuracy: 0.9626030967942732\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 30.939493266666666 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.12294746641526688\n","Validation Accuracy: 0.9646584942411924\n","Validation duration: 3.141701066666667 minutes\n","F1-score (test): 88.0%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.89      0.79      0.84      1170\n","        test       0.91      0.89      0.90      2464\n","   treatment       0.89      0.87      0.88      1244\n","\n","   micro avg       0.90      0.86      0.88      4878\n","   macro avg       0.89      0.85      0.87      4878\n","weighted avg       0.90      0.86      0.88      4878\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 13052\n","Points in y_train after augmentation: 13052\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9248090982437134\n","Training loss per 100 training steps: 0.25388769178402304\n","Training loss per 100 training steps: 0.1849010479520654\n","Training loss epoch: 0.18327843387812084\n","Training accuracy epoch: 0.9430095996732025\n","Validating model...\n","Validation Loss: 0.11193133123657283\n","Validation Accuracy: 0.9659877840024899\n","Training epoch: 2\n","Training loss per 100 training steps: 0.08231265842914581\n","Training loss per 100 training steps: 0.06381825154813209\n","Training loss per 100 training steps: 0.06492247748702987\n","Training loss epoch: 0.06484450506932084\n","Training accuracy epoch: 0.980764910130719\n","Validating model...\n","Validation Loss: 0.11756611076713193\n","Validation Accuracy: 0.9681226657329598\n","Training epoch: 3\n","Training loss per 100 training steps: 0.038508739322423935\n","Training loss per 100 training steps: 0.033493561845383435\n","Training loss per 100 training steps: 0.034829429119121076\n","Training loss epoch: 0.03502200203765111\n","Training accuracy epoch: 0.9888174019607843\n","Validating model...\n","Validation Loss: 0.13816703258849242\n","Validation Accuracy: 0.9647477046374106\n","Training epoch: 4\n","Training loss per 100 training steps: 0.012990506365895271\n","Training loss per 100 training steps: 0.018221469829435285\n","Training loss per 100 training steps: 0.018507758903187416\n","Training loss epoch: 0.018321441350089313\n","Training accuracy epoch: 0.9943321078431373\n","Validating model...\n","Validation Loss: 0.15475560714235054\n","Validation Accuracy: 0.9647622938064114\n","Training epoch: 5\n","Training loss per 100 training steps: 0.09717869758605957\n","Training loss per 100 training steps: 0.01918720802531974\n","Training loss per 100 training steps: 0.022867680268665654\n","Training loss epoch: 0.02280560301191073\n","Training accuracy epoch: 0.9935661764705882\n","Validating model...\n","Validation Loss: 0.175233871865488\n","Validation Accuracy: 0.961990351696234\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0034656033385545015\n","Training loss per 100 training steps: 0.016376261657569557\n","Training loss per 100 training steps: 0.016992813109742263\n","Training loss epoch: 0.016768105042751367\n","Training accuracy epoch: 0.9944852941176471\n","Validating model...\n","Validation Loss: 0.18032967078604498\n","Validation Accuracy: 0.9641495487083722\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 26.469010883333333 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.11377215241534738\n","Validation Accuracy: 0.9652054398148148\n","Validation duration: 3.1276215166666663 minutes\n","F1-score (test): 88.8%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.86      0.83      0.85      1170\n","        test       0.92      0.89      0.91      2464\n","   treatment       0.90      0.89      0.89      1244\n","\n","   micro avg       0.90      0.88      0.89      4878\n","   macro avg       0.89      0.87      0.88      4878\n","weighted avg       0.90      0.88      0.89      4878\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 13052\n","Points in y_train after augmentation: 13052\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8241209983825684\n","Training loss per 100 training steps: 0.24916934188787299\n","Training loss per 100 training steps: 0.189006945294379\n","Training loss epoch: 0.1879348807475146\n","Training accuracy epoch: 0.9418555964052288\n","Validating model...\n","Validation Loss: 0.11192243305199287\n","Validation Accuracy: 0.9665810768751945\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0331537164747715\n","Training loss per 100 training steps: 0.06771219465051695\n","Training loss per 100 training steps: 0.06294406379517446\n","Training loss epoch: 0.06288454674216279\n","Training accuracy epoch: 0.9810814950980392\n","Validating model...\n","Validation Loss: 0.11617823909310733\n","Validation Accuracy: 0.9644559212573918\n","Training epoch: 3\n","Training loss per 100 training steps: 0.030434560030698776\n","Training loss per 100 training steps: 0.03007246787189552\n","Training loss per 100 training steps: 0.033189206580464634\n","Training loss epoch: 0.03336643342866891\n","Training accuracy epoch: 0.9901143790849672\n","Validating model...\n","Validation Loss: 0.13685246271665627\n","Validation Accuracy: 0.9675147836912543\n","Training epoch: 4\n","Training loss per 100 training steps: 0.019647615030407906\n","Training loss per 100 training steps: 0.025407137474596112\n","Training loss per 100 training steps: 0.02532820387315399\n","Training loss epoch: 0.025567786826999794\n","Training accuracy epoch: 0.9925704656862745\n","Validating model...\n","Validation Loss: 0.15569191675532756\n","Validation Accuracy: 0.9665908029878617\n","Training epoch: 5\n","Training loss per 100 training steps: 0.012211146764457226\n","Training loss per 100 training steps: 0.014420016827511296\n","Training loss per 100 training steps: 0.018345994304848803\n","Training loss epoch: 0.018453042489615174\n","Training accuracy epoch: 0.9952512254901961\n","Validating model...\n","Validation Loss: 0.1737561139435617\n","Validation Accuracy: 0.9656765483971367\n","Training epoch: 6\n","Training loss per 100 training steps: 0.009633257985115051\n","Training loss per 100 training steps: 0.017378823437767178\n","Training loss per 100 training steps: 0.01747056764964042\n","Training loss epoch: 0.018160269256993926\n","Training accuracy epoch: 0.9944801879084967\n","Validating model...\n","Validation Loss: 0.16097452766923964\n","Validation Accuracy: 0.965370175848117\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 26.43221645000001 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.12925107824547147\n","Validation Accuracy: 0.9583086325654924\n","Validation duration: 3.1156703666666696 minutes\n","F1-score (test): 86.6%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.75      0.86      0.80      1170\n","        test       0.89      0.91      0.90      2464\n","   treatment       0.87      0.85      0.86      1244\n","\n","   micro avg       0.85      0.88      0.87      4878\n","   macro avg       0.84      0.87      0.85      4878\n","weighted avg       0.85      0.88      0.87      4878\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 13052\n","Points in y_train after augmentation: 13052\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1781368255615234\n","Training loss per 100 training steps: 0.27315833537590384\n","Training loss per 100 training steps: 0.20046962443646507\n","Training loss epoch: 0.19917684988867418\n","Training accuracy epoch: 0.9392514297385621\n","Validating model...\n","Validation Loss: 0.11229375976265646\n","Validation Accuracy: 0.9647622938064114\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05641184002161026\n","Training loss per 100 training steps: 0.04955612917403036\n","Training loss per 100 training steps: 0.0599439272955894\n","Training loss epoch: 0.06030610200204868\n","Training accuracy epoch: 0.9806168300653594\n","Validating model...\n","Validation Loss: 0.1367837778183029\n","Validation Accuracy: 0.9619952147525677\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0098974434658885\n","Training loss per 100 training steps: 0.03358783543404966\n","Training loss per 100 training steps: 0.03465201849562686\n","Training loss epoch: 0.03462823083642505\n","Training accuracy epoch: 0.9885876225490197\n","Validating model...\n","Validation Loss: 0.14209129176942595\n","Validation Accuracy: 0.9696545284780578\n","Training epoch: 4\n","Training loss per 100 training steps: 0.001658912398852408\n","Training loss per 100 training steps: 0.020153680422094346\n","Training loss per 100 training steps: 0.023206697963120238\n","Training loss epoch: 0.02292423173040494\n","Training accuracy epoch: 0.9937193627450981\n","Validating model...\n","Validation Loss: 0.19299100180540016\n","Validation Accuracy: 0.9632304310613133\n","Training epoch: 5\n","Training loss per 100 training steps: 0.01207667775452137\n","Training loss per 100 training steps: 0.020509320004649535\n","Training loss per 100 training steps: 0.019430301891783467\n","Training loss epoch: 0.019295585917550886\n","Training accuracy epoch: 0.994173815359477\n","Validating model...\n","Validation Loss: 0.14675172738383943\n","Validation Accuracy: 0.9656765483971367\n","Training epoch: 6\n","Training loss per 100 training steps: 0.005580509081482887\n","Training loss per 100 training steps: 0.014045527410903244\n","Training loss per 100 training steps: 0.013451643569182966\n","Training loss epoch: 0.013281279207149055\n","Training accuracy epoch: 0.9965533088235294\n","Validating model...\n","Validation Loss: 0.18254921914651243\n","Validation Accuracy: 0.9653653127917833\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 26.442198383333334 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.11477671001166864\n","Validation Accuracy: 0.9637657379177959\n","Validation duration: 3.1286547666666746 minutes\n","F1-score (test): 88.1%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.86      0.81      0.84      1170\n","        test       0.91      0.89      0.90      2464\n","   treatment       0.91      0.86      0.89      1244\n","\n","   micro avg       0.90      0.87      0.88      4878\n","   macro avg       0.89      0.85      0.87      4878\n","weighted avg       0.90      0.87      0.88      4878\n","\n","!!!!!! Starting model number 5 !!!!!!\n","Points in X_train after augmentation: 13052\n","Points in y_train after augmentation: 13052\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.269788980484009\n","Training loss per 100 training steps: 0.2649988017902516\n","Training loss per 100 training steps: 0.1969844100728112\n","Training loss epoch: 0.19458322860665767\n","Training accuracy epoch: 0.940640318627451\n","Validating model...\n","Validation Loss: 0.13906756689881578\n","Validation Accuracy: 0.9607697245564892\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04377707093954086\n","Training loss per 100 training steps: 0.05832735905285445\n","Training loss per 100 training steps: 0.05936472321424948\n","Training loss epoch: 0.059843189828326086\n","Training accuracy epoch: 0.9816125408496731\n","Validating model...\n","Validation Loss: 0.12861414974117102\n","Validation Accuracy: 0.9647428415810768\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02916412428021431\n","Training loss per 100 training steps: 0.03587840686755089\n","Training loss per 100 training steps: 0.03973085510275739\n","Training loss epoch: 0.03992787399899909\n","Training accuracy epoch: 0.9872089460784313\n","Validating model...\n","Validation Loss: 0.13209833418402603\n","Validation Accuracy: 0.9641398225957049\n","Training epoch: 4\n","Training loss per 100 training steps: 0.023261625319719315\n","Training loss per 100 training steps: 0.02129954536154977\n","Training loss per 100 training steps: 0.020887857637210606\n","Training loss epoch: 0.020898683901132066\n","Training accuracy epoch: 0.9927951388888888\n","Validating model...\n","Validation Loss: 0.14404825816460537\n","Validation Accuracy: 0.9696642545907251\n","Training epoch: 5\n","Training loss per 100 training steps: 0.004993820562958717\n","Training loss per 100 training steps: 0.011959524271378091\n","Training loss per 100 training steps: 0.015162795069117784\n","Training loss epoch: 0.015153936989829126\n","Training accuracy epoch: 0.9950980392156863\n","Validating model...\n","Validation Loss: 0.15646613469374748\n","Validation Accuracy: 0.9678211562402739\n","Training epoch: 6\n","Training loss per 100 training steps: 0.005886232480406761\n","Training loss per 100 training steps: 0.009823380066669721\n","Training loss per 100 training steps: 0.014758932447151873\n","Training loss epoch: 0.014824321062156278\n","Training accuracy epoch: 0.9963184232026143\n","Validating model...\n","Validation Loss: 0.17598253336059405\n","Validation Accuracy: 0.96015697945845\n","Training epoch: 7\n","Training loss per 100 training steps: 0.03663215413689613\n","Training loss per 100 training steps: 0.018257061692529893\n","Training loss per 100 training steps: 0.02300696177586197\n","Training loss epoch: 0.02282564155750294\n","Training accuracy epoch: 0.9924172794117647\n","Validating model...\n","Validation Loss: 0.1679323157478197\n","Validation Accuracy: 0.9638334500466853\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 30.885914616666664 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13814806977461558\n","Validation Accuracy: 0.9620022795280037\n","Validation duration: 3.132342550000006 minutes\n","F1-score (test): 87.3%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.92      0.76      0.83      1170\n","        test       0.90      0.89      0.90      2464\n","   treatment       0.88      0.84      0.86      1244\n","\n","   micro avg       0.90      0.85      0.87      4878\n","   macro avg       0.90      0.83      0.86      4878\n","weighted avg       0.90      0.85      0.87      4878\n","\n","!!!!!! Starting model number 6 !!!!!!\n","Points in X_train after augmentation: 13052\n","Points in y_train after augmentation: 13052\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8198978900909424\n","Training loss per 100 training steps: 0.2332687338463741\n","Training loss per 100 training steps: 0.18064933924458512\n","Training loss epoch: 0.17960453396845683\n","Training accuracy epoch: 0.9443933823529411\n","Validating model...\n","Validation Loss: 0.12151175437896859\n","Validation Accuracy: 0.9632207049486461\n","Training epoch: 2\n","Training loss per 100 training steps: 0.10497169196605682\n","Training loss per 100 training steps: 0.06335032760340831\n","Training loss per 100 training steps: 0.0675105614383793\n","Training loss epoch: 0.067873403324983\n","Training accuracy epoch: 0.9786815767973855\n","Validating model...\n","Validation Loss: 0.12266765715663924\n","Validation Accuracy: 0.9653750389044506\n","Training epoch: 3\n","Training loss per 100 training steps: 0.027580296620726585\n","Training loss per 100 training steps: 0.038679259875328234\n","Training loss per 100 training steps: 0.03929883727238546\n","Training loss epoch: 0.03887695640521854\n","Training accuracy epoch: 0.9880514705882353\n","Validating model...\n","Validation Loss: 0.14446138869057976\n","Validation Accuracy: 0.965068666355431\n","Training epoch: 4\n","Training loss per 100 training steps: 0.07327639311552048\n","Training loss per 100 training steps: 0.020626459697187686\n","Training loss per 100 training steps: 0.023174491454383814\n","Training loss epoch: 0.023229068473287328\n","Training accuracy epoch: 0.992953431372549\n","Validating model...\n","Validation Loss: 0.15422475417418516\n","Validation Accuracy: 0.9644510582010583\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0016274091321974993\n","Training loss per 100 training steps: 0.01723542215941142\n","Training loss per 100 training steps: 0.02045031873345959\n","Training loss epoch: 0.020622453440891524\n","Training accuracy epoch: 0.993484477124183\n","Validating model...\n","Validation Loss: 0.155165148583953\n","Validation Accuracy: 0.9678260192966075\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00224058935418725\n","Training loss per 100 training steps: 0.01064625504111991\n","Training loss per 100 training steps: 0.013968891059905661\n","Training loss epoch: 0.014292311643087077\n","Training accuracy epoch: 0.9957873774509803\n","Validating model...\n","Validation Loss: 0.20169029960536636\n","Validation Accuracy: 0.9632207049486461\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 26.436303549999987 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13185242270723124\n","Validation Accuracy: 0.9573885289634146\n","Validation duration: 3.1089586000000056 minutes\n","F1-score (test): 86.1%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.81      0.82      0.81      1170\n","        test       0.86      0.92      0.89      2464\n","   treatment       0.88      0.82      0.85      1244\n","\n","   micro avg       0.85      0.87      0.86      4878\n","   macro avg       0.85      0.85      0.85      4878\n","weighted avg       0.85      0.87      0.86      4878\n","\n","!!!!!! Starting model number 7 !!!!!!\n","Points in X_train after augmentation: 13052\n","Points in y_train after augmentation: 13052\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0379276275634766\n","Training loss per 100 training steps: 0.2477019771490947\n","Training loss per 100 training steps: 0.18788854243113332\n","Training loss epoch: 0.18679873133078218\n","Training accuracy epoch: 0.9404003267973856\n","Validating model...\n","Validation Loss: 0.11464990313877077\n","Validation Accuracy: 0.965370175848117\n","Training epoch: 2\n","Training loss per 100 training steps: 0.1661747843027115\n","Training loss per 100 training steps: 0.06487190076564946\n","Training loss per 100 training steps: 0.06571634263912243\n","Training loss epoch: 0.06520513912626341\n","Training accuracy epoch: 0.9795496323529411\n","Validating model...\n","Validation Loss: 0.12788786865113413\n","Validation Accuracy: 0.9672084111422347\n","Training epoch: 3\n","Training loss per 100 training steps: 0.002742563374340534\n","Training loss per 100 training steps: 0.02819154455584686\n","Training loss per 100 training steps: 0.03552218198785512\n","Training loss epoch: 0.035384836713966056\n","Training accuracy epoch: 0.990344158496732\n","Validating model...\n","Validation Loss: 0.16112326370899147\n","Validation Accuracy: 0.9647574307500778\n","Training epoch: 4\n","Training loss per 100 training steps: 0.002029554918408394\n","Training loss per 100 training steps: 0.023298245852370517\n","Training loss per 100 training steps: 0.024676871655708112\n","Training loss epoch: 0.02445731243214515\n","Training accuracy epoch: 0.9923406862745098\n","Validating model...\n","Validation Loss: 0.1636752458471878\n","Validation Accuracy: 0.9666005291005291\n","Training epoch: 5\n","Training loss per 100 training steps: 0.008520380593836308\n","Training loss per 100 training steps: 0.018023106264063424\n","Training loss per 100 training steps: 0.01813861472397204\n","Training loss epoch: 0.017985397954237436\n","Training accuracy epoch: 0.9947099673202614\n","Validating model...\n","Validation Loss: 0.1649735806322675\n","Validation Accuracy: 0.9659829209461562\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0020196011755615473\n","Training loss per 100 training steps: 0.012244682653581189\n","Training loss per 100 training steps: 0.016439900598291826\n","Training loss epoch: 0.0163679794689718\n","Training accuracy epoch: 0.9949448529411765\n","Validating model...\n","Validation Loss: 0.16094777092118473\n","Validation Accuracy: 0.9653750389044506\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 26.415695483333334 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.12383100183473693\n","Validation Accuracy: 0.9616202997967479\n","Validation duration: 3.1094885666666716 minutes\n","F1-score (test): 87.1%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.81      0.83      0.82      1170\n","        test       0.87      0.92      0.90      2464\n","   treatment       0.88      0.84      0.86      1244\n","\n","   micro avg       0.86      0.88      0.87      4878\n","   macro avg       0.86      0.87      0.86      4878\n","weighted avg       0.86      0.88      0.87      4878\n","\n","!!!!!! Starting model number 8 !!!!!!\n","Points in X_train after augmentation: 13052\n","Points in y_train after augmentation: 13052\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8816300630569458\n","Training loss per 100 training steps: 0.2534109447704683\n","Training loss per 100 training steps: 0.18860512471465923\n","Training loss epoch: 0.1876998274203609\n","Training accuracy epoch: 0.9422436683006535\n","Validating model...\n","Validation Loss: 0.1154734382551967\n","Validation Accuracy: 0.9672035480859009\n","Training epoch: 2\n","Training loss per 100 training steps: 0.03506205230951309\n","Training loss per 100 training steps: 0.05792135964286062\n","Training loss per 100 training steps: 0.06337394839412167\n","Training loss epoch: 0.06316338168393236\n","Training accuracy epoch: 0.98046875\n","Validating model...\n","Validation Loss: 0.11878642335753231\n","Validation Accuracy: 0.9668874494242141\n","Training epoch: 3\n","Training loss per 100 training steps: 0.020961914211511612\n","Training loss per 100 training steps: 0.034034662262195405\n","Training loss per 100 training steps: 0.03651259827140292\n","Training loss epoch: 0.036369310231998055\n","Training accuracy epoch: 0.9880514705882353\n","Validating model...\n","Validation Loss: 0.153547481250237\n","Validation Accuracy: 0.9629143323996264\n","Training epoch: 4\n","Training loss per 100 training steps: 0.08098147809505463\n","Training loss per 100 training steps: 0.028318666798837187\n","Training loss per 100 training steps: 0.029583100795361274\n","Training loss epoch: 0.029538556377006257\n","Training accuracy epoch: 0.9908803104575162\n","Validating model...\n","Validation Loss: 0.15803313010609618\n","Validation Accuracy: 0.9672084111422347\n","Training epoch: 5\n","Training loss per 100 training steps: 0.001643071649596095\n","Training loss per 100 training steps: 0.021298864589529204\n","Training loss per 100 training steps: 0.019843375170574436\n","Training loss epoch: 0.019877888631348397\n","Training accuracy epoch: 0.9937908496732025\n","Validating model...\n","Validation Loss: 0.1508129405955711\n","Validation Accuracy: 0.9681372549019608\n","Training epoch: 6\n","Training loss per 100 training steps: 0.008910587057471275\n","Training loss per 100 training steps: 0.01474649609916032\n","Training loss per 100 training steps: 0.017258882246458607\n","Training loss epoch: 0.017075576316867725\n","Training accuracy epoch: 0.9947150735294118\n","Validating model...\n","Validation Loss: 0.15376751952320702\n","Validation Accuracy: 0.9641495487083722\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 26.428321233333342 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.11112553681057223\n","Validation Accuracy: 0.9641000804539296\n","Validation duration: 3.1201107833333177 minutes\n","F1-score (test): 88.3%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.85      0.84      0.85      1170\n","        test       0.88      0.93      0.90      2464\n","   treatment       0.87      0.88      0.88      1244\n","\n","   micro avg       0.87      0.90      0.88      4878\n","   macro avg       0.87      0.88      0.88      4878\n","weighted avg       0.87      0.90      0.88      4878\n","\n","!!!!!! Starting model number 9 !!!!!!\n","Points in X_train after augmentation: 13052\n","Points in y_train after augmentation: 13052\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0138192176818848\n","Training loss per 100 training steps: 0.23847434089731168\n","Training loss per 100 training steps: 0.1881646238665898\n","Training loss epoch: 0.1864433483923694\n","Training accuracy epoch: 0.9404769199346406\n","Validating model...\n","Validation Loss: 0.12282262287814827\n","Validation Accuracy: 0.9616937052598817\n","Training epoch: 2\n","Training loss per 100 training steps: 0.041795335710048676\n","Training loss per 100 training steps: 0.05521446973371255\n","Training loss per 100 training steps: 0.056689582870513275\n","Training loss epoch: 0.057129870829692876\n","Training accuracy epoch: 0.9829963235294118\n","Validating model...\n","Validation Loss: 0.1386415301182983\n","Validation Accuracy: 0.9632158418923125\n","Training epoch: 3\n","Training loss per 100 training steps: 0.020751971751451492\n","Training loss per 100 training steps: 0.02797004921214268\n","Training loss per 100 training steps: 0.028692622067851583\n","Training loss epoch: 0.028833414655060088\n","Training accuracy epoch: 0.991421568627451\n","Validating model...\n","Validation Loss: 0.14965929519202487\n","Validation Accuracy: 0.9656814114534702\n","Training epoch: 4\n","Training loss per 100 training steps: 0.014759285375475883\n","Training loss per 100 training steps: 0.028229836925476936\n","Training loss per 100 training steps: 0.026687689104108188\n","Training loss epoch: 0.026383840279795193\n","Training accuracy epoch: 0.9924172794117647\n","Validating model...\n","Validation Loss: 0.1643957124187556\n","Validation Accuracy: 0.9650589402427637\n","Training epoch: 5\n","Training loss per 100 training steps: 0.006544291507452726\n","Training loss per 100 training steps: 0.016288452070566024\n","Training loss per 100 training steps: 0.022851128397574322\n","Training loss epoch: 0.022589738694174837\n","Training accuracy epoch: 0.9925704656862745\n","Validating model...\n","Validation Loss: 0.20556541952058016\n","Validation Accuracy: 0.9620000778089013\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0007736642146483064\n","Training loss per 100 training steps: 0.017925246077529756\n","Training loss per 100 training steps: 0.022280033230978477\n","Training loss epoch: 0.022122145952558712\n","Training accuracy epoch: 0.9939491421568627\n","Validating model...\n","Validation Loss: 0.14725993630275422\n","Validation Accuracy: 0.9629143323996264\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 26.446700216666674 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1286041359611166\n","Validation Accuracy: 0.9616520579268292\n","Validation duration: 3.1273641666666965 minutes\n","F1-score (test): 87.2%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.89      0.72      0.80      1170\n","        test       0.91      0.90      0.90      2464\n","   treatment       0.90      0.85      0.87      1244\n","\n","   micro avg       0.90      0.84      0.87      4878\n","   macro avg       0.90      0.82      0.86      4878\n","weighted avg       0.90      0.84      0.87      4878\n","\n","!!!!!! Starting model number 10 !!!!!!\n","Points in X_train after augmentation: 13052\n","Points in y_train after augmentation: 13052\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.2506027221679688\n","Training loss per 100 training steps: 0.2616910417518108\n","Training loss per 100 training steps: 0.1994642653868566\n","Training loss epoch: 0.198258398685093\n","Training accuracy epoch: 0.9390880310457517\n","Validating model...\n","Validation Loss: 0.1312133394473908\n","Validation Accuracy: 0.9586348428260192\n","Training epoch: 2\n","Training loss per 100 training steps: 0.08393687009811401\n","Training loss per 100 training steps: 0.07019348769439476\n","Training loss per 100 training steps: 0.06481260194012256\n","Training loss epoch: 0.06503797285304423\n","Training accuracy epoch: 0.9798457924836601\n","Validating model...\n","Validation Loss: 0.15571429144919796\n","Validation Accuracy: 0.9598554699657641\n","Training epoch: 3\n","Training loss per 100 training steps: 0.006212370004504919\n","Training loss per 100 training steps: 0.029795292751070592\n","Training loss per 100 training steps: 0.03676978620035639\n","Training loss epoch: 0.0373882545727789\n","Training accuracy epoch: 0.9886488970588235\n","Validating model...\n","Validation Loss: 0.13659439962722508\n","Validation Accuracy: 0.9626128229069405\n","Training epoch: 4\n","Training loss per 100 training steps: 0.013730649836361408\n","Training loss per 100 training steps: 0.02503071796946633\n","Training loss per 100 training steps: 0.026054160162662873\n","Training loss epoch: 0.02575933081314753\n","Training accuracy epoch: 0.9921875\n","Validating model...\n","Validation Loss: 0.14776508516047662\n","Validation Accuracy: 0.9656716853408029\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0017870463198050857\n","Training loss per 100 training steps: 0.015165640926737762\n","Training loss per 100 training steps: 0.023428410429371965\n","Training loss epoch: 0.023466201575430723\n","Training accuracy epoch: 0.9931832107843137\n","Validating model...\n","Validation Loss: 0.16261721712847552\n","Validation Accuracy: 0.9580075085589792\n","Training epoch: 6\n","Training loss per 100 training steps: 0.07321587204933167\n","Training loss per 100 training steps: 0.02630764530570532\n","Training loss per 100 training steps: 0.024444406220384768\n","Training loss epoch: 0.024260437089348368\n","Training accuracy epoch: 0.9926470588235294\n","Validating model...\n","Validation Loss: 0.16841117550582424\n","Validation Accuracy: 0.9641446856520386\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 26.429091149999962 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1285074712337788\n","Validation Accuracy: 0.9595269097222222\n","Validation duration: 3.121723633333325 minutes\n","F1-score (test): 86.3%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.90      0.69      0.78      1170\n","        test       0.89      0.90      0.90      2464\n","   treatment       0.93      0.81      0.86      1244\n","\n","   micro avg       0.90      0.83      0.86      4878\n","   macro avg       0.91      0.80      0.85      4878\n","weighted avg       0.90      0.83      0.86      4878\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16952213,"status":"ok","timestamp":1657342003997,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"Jhz9BiIwGCsV","outputId":"5455180b-f051-4f57-cab6-fc225533befa"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 25.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 16315\n","Points in y_train after augmentation: 16315\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.2924094200134277\n","Training loss per 100 training steps: 0.3138682125136256\n","Training loss per 100 training steps: 0.2534567310581382\n","Training loss per 100 training steps: 0.2208836678588806\n","Training loss per 100 training steps: 0.20094006046411253\n","Training loss per 100 training steps: 0.1835792119035724\n","Training loss epoch: 0.18283454001488567\n","Training accuracy epoch: 0.9432484567901235\n","Validating model...\n","Validation Loss: 0.11713603120890684\n","Validation Accuracy: 0.9632254111321948\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0683823749423027\n","Training loss per 100 training steps: 0.06546523831704042\n","Training loss per 100 training steps: 0.06097425724552314\n","Training loss per 100 training steps: 0.06341087416590244\n","Training loss per 100 training steps: 0.06531076995987431\n","Training loss per 100 training steps: 0.06715681552159658\n","Training loss epoch: 0.067418620761315\n","Training accuracy epoch: 0.9786151960784314\n","Validating model...\n","Validation Loss: 0.1455121906251674\n","Validation Accuracy: 0.9598553130929791\n","Training epoch: 3\n","Training loss per 100 training steps: 0.01795295625925064\n","Training loss per 100 training steps: 0.03184091854358719\n","Training loss per 100 training steps: 0.038786419121715335\n","Training loss per 100 training steps: 0.03516238114761384\n","Training loss per 100 training steps: 0.036065978878813486\n","Training loss per 100 training steps: 0.03753440357002749\n","Training loss epoch: 0.037450628422654925\n","Training accuracy epoch: 0.9885303195352215\n","Validating model...\n","Validation Loss: 0.15366271459360553\n","Validation Accuracy: 0.9607645477545858\n","Training epoch: 4\n","Training loss per 100 training steps: 0.07089877873659134\n","Training loss per 100 training steps: 0.01624589677111103\n","Training loss per 100 training steps: 0.022483535771433666\n","Training loss per 100 training steps: 0.02374991353621909\n","Training loss per 100 training steps: 0.026525498411937225\n","Training loss per 100 training steps: 0.028086150865652134\n","Training loss epoch: 0.027940871971904747\n","Training accuracy epoch: 0.9909313725490196\n","Validating model...\n","Validation Loss: 0.14855301649910033\n","Validation Accuracy: 0.9622964104996837\n","Training epoch: 5\n","Training loss per 100 training steps: 0.002299422863870859\n","Training loss per 100 training steps: 0.009699090896865888\n","Training loss per 100 training steps: 0.019812541917318002\n","Training loss per 100 training steps: 0.019481445557526407\n","Training loss per 100 training steps: 0.02053354390203881\n","Training loss per 100 training steps: 0.022194980269638606\n","Training loss epoch: 0.022344196838150986\n","Training accuracy epoch: 0.9928808097313\n","Validating model...\n","Validation Loss: 0.1795496381736502\n","Validation Accuracy: 0.9638480392156863\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0027118739672005177\n","Training loss per 100 training steps: 0.025003270045243258\n","Training loss per 100 training steps: 0.025893930097594765\n","Training loss per 100 training steps: 0.025574964731355412\n","Training loss per 100 training steps: 0.028931265791452505\n","Training loss per 100 training steps: 0.02983267861549132\n","Training loss epoch: 0.02982847803473751\n","Training accuracy epoch: 0.9907475490196078\n","Validating model...\n","Validation Loss: 0.18343793821644366\n","Validation Accuracy: 0.9616836654016445\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 23.4761243 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.11933018616939618\n","Validation Accuracy: 0.9630513760288066\n","Validation duration: 2.3693179999999985 minutes\n","F1-score (test): 87.1%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.93      0.77      0.84      1170\n","        test       0.87      0.90      0.88      2464\n","   treatment       0.92      0.83      0.87      1244\n","\n","   micro avg       0.89      0.85      0.87      4878\n","   macro avg       0.91      0.83      0.87      4878\n","weighted avg       0.90      0.85      0.87      4878\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 16315\n","Points in y_train after augmentation: 16315\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.115877389907837\n","Training loss per 100 training steps: 0.31188313087614455\n","Training loss per 100 training steps: 0.24300933228017976\n","Training loss per 100 training steps: 0.20995734891687146\n","Training loss per 100 training steps: 0.18929640238145437\n","Training loss per 100 training steps: 0.17896008972838864\n","Training loss epoch: 0.17807915935922852\n","Training accuracy epoch: 0.9459944625998548\n","Validating model...\n","Validation Loss: 0.14364747956221668\n","Validation Accuracy: 0.9576909392789374\n","Training epoch: 2\n","Training loss per 100 training steps: 0.03317492827773094\n","Training loss per 100 training steps: 0.07939732756401126\n","Training loss per 100 training steps: 0.0712942771604331\n","Training loss per 100 training steps: 0.07033360894480133\n","Training loss per 100 training steps: 0.07097456545570163\n","Training loss per 100 training steps: 0.06933246808035481\n","Training loss epoch: 0.06919802347901186\n","Training accuracy epoch: 0.9762754175744373\n","Validating model...\n","Validation Loss: 0.12132359825202502\n","Validation Accuracy: 0.9656763915243517\n","Training epoch: 3\n","Training loss per 100 training steps: 0.035841282457113266\n","Training loss per 100 training steps: 0.03348015880155709\n","Training loss per 100 training steps: 0.029430467897038026\n","Training loss per 100 training steps: 0.0353958464816075\n","Training loss per 100 training steps: 0.03768017260246548\n","Training loss per 100 training steps: 0.03989230338633925\n","Training loss epoch: 0.04033394417087502\n","Training accuracy epoch: 0.9866308097313\n","Validating model...\n","Validation Loss: 0.1557113495449919\n","Validation Accuracy: 0.9598553130929791\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0037588898558169603\n","Training loss per 100 training steps: 0.01995102600393342\n","Training loss per 100 training steps: 0.019971050243142444\n","Training loss per 100 training steps: 0.021031591372736157\n","Training loss per 100 training steps: 0.024857474145528274\n","Training loss per 100 training steps: 0.02679513868417576\n","Training loss epoch: 0.027639127851865602\n","Training accuracy epoch: 0.9918504901960784\n","Validating model...\n","Validation Loss: 0.1458778746803314\n","Validation Accuracy: 0.965043880455408\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0030438012909144163\n","Training loss per 100 training steps: 0.01729157522965066\n","Training loss per 100 training steps: 0.01754141756582024\n","Training loss per 100 training steps: 0.017859281181340204\n","Training loss per 100 training steps: 0.019906283514052332\n","Training loss per 100 training steps: 0.023041748068823007\n","Training loss epoch: 0.022973760094407457\n","Training accuracy epoch: 0.9936773783587509\n","Validating model...\n","Validation Loss: 0.18347397004653626\n","Validation Accuracy: 0.9577205882352942\n","Training epoch: 6\n","Training loss per 100 training steps: 0.156505286693573\n","Training loss per 100 training steps: 0.023215606079481792\n","Training loss per 100 training steps: 0.030280609570188213\n","Training loss per 100 training steps: 0.03033165066409972\n","Training loss per 100 training steps: 0.02971692344303994\n","Training loss per 100 training steps: 0.028957954855402698\n","Training loss epoch: 0.028764946019652474\n","Training accuracy epoch: 0.9911651234567902\n","Validating model...\n","Validation Loss: 0.177426799410622\n","Validation Accuracy: 0.9629190385831752\n","Training epoch: 7\n","Training loss per 100 training steps: 0.002049395116046071\n","Training loss per 100 training steps: 0.007941974707046929\n","Training loss per 100 training steps: 0.006513834845092824\n","Training loss per 100 training steps: 0.01012377826615598\n","Training loss per 100 training steps: 0.012746411212600223\n","Training loss per 100 training steps: 0.014139262773599053\n","Training loss epoch: 0.014513399415348734\n","Training accuracy epoch: 0.995147966594045\n","Validating model...\n","Validation Loss: 0.19092897696592606\n","Validation Accuracy: 0.9629190385831752\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 27.622540849999996 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.12007111260276428\n","Validation Accuracy: 0.9640480324074074\n","Validation duration: 2.379821883333337 minutes\n","F1-score (test): 87.9%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.86      0.81      0.83      1170\n","        test       0.89      0.91      0.90      2464\n","   treatment       0.92      0.84      0.88      1244\n","\n","   micro avg       0.89      0.87      0.88      4878\n","   macro avg       0.89      0.85      0.87      4878\n","weighted avg       0.89      0.87      0.88      4878\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 16315\n","Points in y_train after augmentation: 16315\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1815690994262695\n","Training loss per 100 training steps: 0.29469347652969974\n","Training loss per 100 training steps: 0.23676198766339773\n","Training loss per 100 training steps: 0.2095627960473596\n","Training loss per 100 training steps: 0.1915978841121283\n","Training loss per 100 training steps: 0.17663903971260297\n","Training loss epoch: 0.1751695019941704\n","Training accuracy epoch: 0.9456994371822803\n","Validating model...\n","Validation Loss: 0.13278593352137535\n","Validation Accuracy: 0.9613970588235294\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04259519651532173\n","Training loss per 100 training steps: 0.07235129881364358\n","Training loss per 100 training steps: 0.07032285917397421\n","Training loss per 100 training steps: 0.06225040361309962\n","Training loss per 100 training steps: 0.06369374401721072\n","Training loss per 100 training steps: 0.06492611618820363\n","Training loss epoch: 0.06499875381534152\n","Training accuracy epoch: 0.9802582607116921\n","Validating model...\n","Validation Loss: 0.13339126293145703\n","Validation Accuracy: 0.9641346457938014\n","Training epoch: 3\n","Training loss per 100 training steps: 0.014301221817731857\n","Training loss per 100 training steps: 0.033450719244584516\n","Training loss per 100 training steps: 0.03583980861944679\n","Training loss per 100 training steps: 0.035375897384494655\n","Training loss per 100 training steps: 0.03642732549128947\n","Training loss per 100 training steps: 0.04128160282198949\n","Training loss epoch: 0.0417353142032345\n","Training accuracy epoch: 0.9874273783587509\n","Validating model...\n","Validation Loss: 0.1497079510339901\n","Validation Accuracy: 0.9616935483870968\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03502140939235687\n","Training loss per 100 training steps: 0.024694371595921104\n","Training loss per 100 training steps: 0.023270770948379073\n","Training loss per 100 training steps: 0.03079539786939559\n","Training loss per 100 training steps: 0.032188745890729516\n","Training loss per 100 training steps: 0.03339559291232658\n","Training loss epoch: 0.033522795658848505\n","Training accuracy epoch: 0.9893995098039216\n","Validating model...\n","Validation Loss: 0.14950590079145817\n","Validation Accuracy: 0.9635317836812144\n","Training epoch: 5\n","Training loss per 100 training steps: 0.1456049680709839\n","Training loss per 100 training steps: 0.021136529065638614\n","Training loss per 100 training steps: 0.01841302075022507\n","Training loss per 100 training steps: 0.020391772315911702\n","Training loss per 100 training steps: 0.021298706853626403\n","Training loss per 100 training steps: 0.021510729304281995\n","Training loss epoch: 0.021484652341870754\n","Training accuracy epoch: 0.9938112745098039\n","Validating model...\n","Validation Loss: 0.16637260395566722\n","Validation Accuracy: 0.9647473908918406\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0028081329073756933\n","Training loss per 100 training steps: 0.021847854403543775\n","Training loss per 100 training steps: 0.016349787702734712\n","Training loss per 100 training steps: 0.015190833471806824\n","Training loss per 100 training steps: 0.01743764040660599\n","Training loss per 100 training steps: 0.019212316684419358\n","Training loss epoch: 0.019481927572725873\n","Training accuracy epoch: 0.9938612018881627\n","Validating model...\n","Validation Loss: 0.17508322164854584\n","Validation Accuracy: 0.9696592346616066\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 23.64833258333334 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13470082015986987\n","Validation Accuracy: 0.9581163194444444\n","Validation duration: 2.374123350000006 minutes\n","F1-score (test): 86.3%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.79      0.87      0.83      1170\n","        test       0.87      0.90      0.88      2464\n","   treatment       0.84      0.86      0.85      1244\n","\n","   micro avg       0.84      0.88      0.86      4878\n","   macro avg       0.84      0.88      0.86      4878\n","weighted avg       0.84      0.88      0.86      4878\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 16315\n","Points in y_train after augmentation: 16315\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8894838094711304\n","Training loss per 100 training steps: 0.30473930539913696\n","Training loss per 100 training steps: 0.24123965480842105\n","Training loss per 100 training steps: 0.21411779704209777\n","Training loss per 100 training steps: 0.1945798544868121\n","Training loss per 100 training steps: 0.1806733614956577\n","Training loss epoch: 0.18015257015860842\n","Training accuracy epoch: 0.9431758351488744\n","Validating model...\n","Validation Loss: 0.13796930967410112\n","Validation Accuracy: 0.9546370967741936\n","Training epoch: 2\n","Training loss per 100 training steps: 0.020217837765812874\n","Training loss per 100 training steps: 0.05558556904278622\n","Training loss per 100 training steps: 0.06931064137609777\n","Training loss per 100 training steps: 0.07175811092783867\n","Training loss per 100 training steps: 0.07340664700244988\n","Training loss per 100 training steps: 0.0722637438352876\n","Training loss epoch: 0.07278665207490763\n","Training accuracy epoch: 0.9764705882352941\n","Validating model...\n","Validation Loss: 0.16613060062723783\n","Validation Accuracy: 0.9561887254901961\n","Training epoch: 3\n","Training loss per 100 training steps: 0.010233421809971333\n","Training loss per 100 training steps: 0.043344901033820084\n","Training loss per 100 training steps: 0.03835191524648965\n","Training loss per 100 training steps: 0.04183221529994045\n","Training loss per 100 training steps: 0.038860827425516276\n","Training loss per 100 training steps: 0.04048550564744845\n","Training loss epoch: 0.04098191167411677\n","Training accuracy epoch: 0.9873161764705882\n","Validating model...\n","Validation Loss: 0.1420898665605551\n","Validation Accuracy: 0.9592326850094877\n","Training epoch: 4\n","Training loss per 100 training steps: 0.006327753886580467\n","Training loss per 100 training steps: 0.02568412613928189\n","Training loss per 100 training steps: 0.02718021989575893\n","Training loss per 100 training steps: 0.02650592243898369\n","Training loss per 100 training steps: 0.02532936419046657\n","Training loss per 100 training steps: 0.02843041010495501\n","Training loss epoch: 0.02883689605180681\n","Training accuracy epoch: 0.991360294117647\n","Validating model...\n","Validation Loss: 0.15764350406072267\n","Validation Accuracy: 0.962306293485136\n","Training epoch: 5\n","Training loss per 100 training steps: 0.01617640070617199\n","Training loss per 100 training steps: 0.01448175200249073\n","Training loss per 100 training steps: 0.011772520285602474\n","Training loss per 100 training steps: 0.01747971139162697\n","Training loss per 100 training steps: 0.021120173401660006\n","Training loss per 100 training steps: 0.02353363938776831\n","Training loss epoch: 0.02340846087600392\n","Training accuracy epoch: 0.9928308823529411\n","Validating model...\n","Validation Loss: 0.19554035569993122\n","Validation Accuracy: 0.9574043327008223\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0020536580123007298\n","Training loss per 100 training steps: 0.025496654415913478\n","Training loss per 100 training steps: 0.03025051724601222\n","Training loss per 100 training steps: 0.03560915938670402\n","Training loss per 100 training steps: 0.033370053672695944\n","Training loss per 100 training steps: 0.031964675483751356\n","Training loss epoch: 0.03161276705696033\n","Training accuracy epoch: 0.9910539215686275\n","Validating model...\n","Validation Loss: 0.1539116985958946\n","Validation Accuracy: 0.9635416666666666\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 23.37257983333334 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13963224142315556\n","Validation Accuracy: 0.9556568287037037\n","Validation duration: 2.3498492000000017 minutes\n","F1-score (test): 85.7%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.74      0.86      0.80      1170\n","        test       0.91      0.87      0.89      2464\n","   treatment       0.82      0.89      0.86      1244\n","\n","   micro avg       0.84      0.87      0.86      4878\n","   macro avg       0.83      0.87      0.85      4878\n","weighted avg       0.85      0.87      0.86      4878\n","\n","!!!!!! Starting model number 5 !!!!!!\n","Points in X_train after augmentation: 16315\n","Points in y_train after augmentation: 16315\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.5657355785369873\n","Training loss per 100 training steps: 0.2731055679297683\n","Training loss per 100 training steps: 0.22766586175809303\n","Training loss per 100 training steps: 0.19752370424110727\n","Training loss per 100 training steps: 0.18273527272268572\n","Training loss per 100 training steps: 0.16812056667002256\n","Training loss epoch: 0.16682366359723258\n","Training accuracy epoch: 0.9471200980392157\n","Validating model...\n","Validation Loss: 0.12828715598694615\n","Validation Accuracy: 0.9595390575585073\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09058472514152527\n","Training loss per 100 training steps: 0.06231675077561695\n","Training loss per 100 training steps: 0.06618480149318293\n","Training loss per 100 training steps: 0.06650624114422876\n","Training loss per 100 training steps: 0.06950184126893184\n","Training loss per 100 training steps: 0.07119443199035903\n","Training loss epoch: 0.07075844031493819\n","Training accuracy epoch: 0.9781749273783588\n","Validating model...\n","Validation Loss: 0.13955703667848937\n","Validation Accuracy: 0.9644607843137255\n","Training epoch: 3\n","Training loss per 100 training steps: 0.025372005999088287\n","Training loss per 100 training steps: 0.021769594459040642\n","Training loss per 100 training steps: 0.025814473980126106\n","Training loss per 100 training steps: 0.03120877094397807\n","Training loss per 100 training steps: 0.03577990851623698\n","Training loss per 100 training steps: 0.039002327950838155\n","Training loss epoch: 0.039495855197938176\n","Training accuracy epoch: 0.9873774509803922\n","Validating model...\n","Validation Loss: 0.1396669135600164\n","Validation Accuracy: 0.9641544117647058\n","Training epoch: 4\n","Training loss per 100 training steps: 0.005068971775472164\n","Training loss per 100 training steps: 0.034701074181945235\n","Training loss per 100 training steps: 0.03882273952725728\n","Training loss per 100 training steps: 0.039240256182971625\n","Training loss per 100 training steps: 0.03913145900468523\n","Training loss per 100 training steps: 0.04032668263543148\n","Training loss epoch: 0.04072950862144924\n","Training accuracy epoch: 0.9864469862018882\n","Validating model...\n","Validation Loss: 0.1513695610646049\n","Validation Accuracy: 0.9669018817204301\n","Training epoch: 5\n","Training loss per 100 training steps: 0.009545004926621914\n","Training loss per 100 training steps: 0.03111006558476832\n","Training loss per 100 training steps: 0.02656679768635097\n","Training loss per 100 training steps: 0.027353773543743055\n","Training loss per 100 training steps: 0.024298402459152796\n","Training loss per 100 training steps: 0.02527972845424944\n","Training loss epoch: 0.025276912984197993\n","Training accuracy epoch: 0.9917892156862745\n","Validating model...\n","Validation Loss: 0.19674711895155875\n","Validation Accuracy: 0.9604680581910183\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00821856502443552\n","Training loss per 100 training steps: 0.008941524647237355\n","Training loss per 100 training steps: 0.01422860968391184\n","Training loss per 100 training steps: 0.017104906414730624\n","Training loss per 100 training steps: 0.01951947375670995\n","Training loss per 100 training steps: 0.02242975245526631\n","Training loss epoch: 0.022714529477126037\n","Training accuracy epoch: 0.9933823529411765\n","Validating model...\n","Validation Loss: 0.18167147400113298\n","Validation Accuracy: 0.9497549019607843\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 24.370079183333353 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.12641110941465875\n","Validation Accuracy: 0.9595992476851852\n","Validation duration: 2.446351250000013 minutes\n","F1-score (test): 86.4%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.87      0.79      0.83      1170\n","        test       0.89      0.89      0.89      2464\n","   treatment       0.85      0.86      0.85      1244\n","\n","   micro avg       0.87      0.86      0.86      4878\n","   macro avg       0.87      0.84      0.86      4878\n","weighted avg       0.87      0.86      0.86      4878\n","\n","!!!!!! Starting model number 6 !!!!!!\n","Points in X_train after augmentation: 16315\n","Points in y_train after augmentation: 16315\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.3875792026519775\n","Training loss per 100 training steps: 0.3236506820130761\n","Training loss per 100 training steps: 0.24731881598436936\n","Training loss per 100 training steps: 0.21167166316201075\n","Training loss per 100 training steps: 0.18947034835248738\n","Training loss per 100 training steps: 0.1745326833041039\n","Training loss epoch: 0.1730798760191629\n","Training accuracy epoch: 0.9461896332607117\n","Validating model...\n","Validation Loss: 0.13041659862296107\n","Validation Accuracy: 0.9601616856419988\n","Training epoch: 2\n","Training loss per 100 training steps: 0.3031088411808014\n","Training loss per 100 training steps: 0.05330545620849854\n","Training loss per 100 training steps: 0.06185506384608924\n","Training loss per 100 training steps: 0.06127488682397712\n","Training loss per 100 training steps: 0.06356799379316277\n","Training loss per 100 training steps: 0.06453930006962931\n","Training loss epoch: 0.0647846226343045\n","Training accuracy epoch: 0.9797680646332607\n","Validating model...\n","Validation Loss: 0.13351133768675008\n","Validation Accuracy: 0.9629091555977229\n","Training epoch: 3\n","Training loss per 100 training steps: 0.16978156566619873\n","Training loss per 100 training steps: 0.029571673466874712\n","Training loss per 100 training steps: 0.029418581263254865\n","Training loss per 100 training steps: 0.03341396432514983\n","Training loss per 100 training steps: 0.03460216915162055\n","Training loss per 100 training steps: 0.0383711529484027\n","Training loss epoch: 0.03963518281057523\n","Training accuracy epoch: 0.9879901960784314\n","Validating model...\n","Validation Loss: 0.21003161455440683\n","Validation Accuracy: 0.949418880455408\n","Training epoch: 4\n","Training loss per 100 training steps: 0.08817317336797714\n","Training loss per 100 training steps: 0.03834334447274519\n","Training loss per 100 training steps: 0.029949731465118628\n","Training loss per 100 training steps: 0.028383967112378523\n","Training loss per 100 training steps: 0.02938632157740376\n","Training loss per 100 training steps: 0.03328175506830595\n","Training loss epoch: 0.03361787858724996\n","Training accuracy epoch: 0.9905024509803921\n","Validating model...\n","Validation Loss: 0.14893664992825292\n","Validation Accuracy: 0.9638480392156863\n","Training epoch: 5\n","Training loss per 100 training steps: 0.16040299832820892\n","Training loss per 100 training steps: 0.022302436435452228\n","Training loss per 100 training steps: 0.02512822822146106\n","Training loss per 100 training steps: 0.02793798510564771\n","Training loss per 100 training steps: 0.028976059255295866\n","Training loss per 100 training steps: 0.028094986062812917\n","Training loss epoch: 0.028084276669759156\n","Training accuracy epoch: 0.9908700980392157\n","Validating model...\n","Validation Loss: 0.17574655215296434\n","Validation Accuracy: 0.9613871758380772\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0003894094261340797\n","Training loss per 100 training steps: 0.01703650718263816\n","Training loss per 100 training steps: 0.015899015214515443\n","Training loss per 100 training steps: 0.016832542198341172\n","Training loss per 100 training steps: 0.017497549047558614\n","Training loss per 100 training steps: 0.01893887230109246\n","Training loss epoch: 0.018689372355612587\n","Training accuracy epoch: 0.9943627450980392\n","Validating model...\n","Validation Loss: 0.16848909217058497\n","Validation Accuracy: 0.9669117647058824\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 24.00754073333334 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14461137312173378\n","Validation Accuracy: 0.9543346514917695\n","Validation duration: 2.4284966666666454 minutes\n","F1-score (test): 85.4%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.78      0.82      0.80      1170\n","        test       0.82      0.93      0.87      2464\n","   treatment       0.85      0.88      0.87      1244\n","\n","   micro avg       0.82      0.89      0.85      4878\n","   macro avg       0.82      0.88      0.85      4878\n","weighted avg       0.82      0.89      0.85      4878\n","\n","!!!!!! Starting model number 7 !!!!!!\n","Points in X_train after augmentation: 16315\n","Points in y_train after augmentation: 16315\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9739079475402832\n","Training loss per 100 training steps: 0.30049212310131235\n","Training loss per 100 training steps: 0.23580283845835065\n","Training loss per 100 training steps: 0.20491078476177102\n","Training loss per 100 training steps: 0.18863095127817178\n","Training loss per 100 training steps: 0.17823282703329732\n","Training loss epoch: 0.17802011154537253\n","Training accuracy epoch: 0.9449028685548294\n","Validating model...\n","Validation Loss: 0.13547183163281457\n","Validation Accuracy: 0.9586397058823529\n","Training epoch: 2\n","Training loss per 100 training steps: 0.020523319020867348\n","Training loss per 100 training steps: 0.06385420789909872\n","Training loss per 100 training steps: 0.06627059987438055\n","Training loss per 100 training steps: 0.0682697510257815\n","Training loss per 100 training steps: 0.06662206314568016\n","Training loss per 100 training steps: 0.0660154496186214\n","Training loss epoch: 0.06615336388920197\n","Training accuracy epoch: 0.9787990196078431\n","Validating model...\n","Validation Loss: 0.13180789942099877\n","Validation Accuracy: 0.9622865275142315\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0065596136264503\n","Training loss per 100 training steps: 0.03871899898945455\n","Training loss per 100 training steps: 0.04112308302086857\n","Training loss per 100 training steps: 0.04212364093742822\n","Training loss per 100 training steps: 0.043099292419183685\n","Training loss per 100 training steps: 0.04444588613532578\n","Training loss epoch: 0.04428726163271623\n","Training accuracy epoch: 0.9860906862745098\n","Validating model...\n","Validation Loss: 0.15226519307194109\n","Validation Accuracy: 0.9644311353573688\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0033456538803875446\n","Training loss per 100 training steps: 0.019395638043452793\n","Training loss per 100 training steps: 0.026621473756930396\n","Training loss per 100 training steps: 0.029566058247490163\n","Training loss per 100 training steps: 0.030045176273489956\n","Training loss per 100 training steps: 0.03225508790297997\n","Training loss epoch: 0.03215986612947959\n","Training accuracy epoch: 0.9896446078431372\n","Validating model...\n","Validation Loss: 0.17439889716522028\n","Validation Accuracy: 0.9613871758380772\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0013171631144359708\n","Training loss per 100 training steps: 0.024723166546560732\n","Training loss per 100 training steps: 0.0249649936029808\n","Training loss per 100 training steps: 0.02846610260478753\n","Training loss per 100 training steps: 0.027013660683736444\n","Training loss per 100 training steps: 0.028966833475623753\n","Training loss epoch: 0.028627422436935984\n","Training accuracy epoch: 0.9909313725490196\n","Validating model...\n","Validation Loss: 0.1760673699512457\n","Validation Accuracy: 0.9659926470588235\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00020744261564686894\n","Training loss per 100 training steps: 0.027212929328538173\n","Training loss per 100 training steps: 0.025264780100018588\n","Training loss per 100 training steps: 0.02097938209448197\n","Training loss per 100 training steps: 0.01917623053212314\n","Training loss per 100 training steps: 0.02011994696060461\n","Training loss epoch: 0.02001311467975029\n","Training accuracy epoch: 0.9934436274509804\n","Validating model...\n","Validation Loss: 0.15454344198851863\n","Validation Accuracy: 0.9678308823529411\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0022232457995414734\n","Training loss per 100 training steps: 0.012729010995538527\n","Training loss per 100 training steps: 0.016187083489474126\n","Training loss per 100 training steps: 0.016261023572945628\n","Training loss per 100 training steps: 0.018038302878412286\n","Training loss per 100 training steps: 0.01794846271127653\n","Training loss epoch: 0.017890616590082967\n","Training accuracy epoch: 0.9946078431372549\n","Validating model...\n","Validation Loss: 0.23793881633059308\n","Validation Accuracy: 0.9570979601518027\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 27.66318021666666 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1381906340625897\n","Validation Accuracy: 0.9594184027777778\n","Validation duration: 2.381036083333311 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 86.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.85      0.78      0.81      1170\n","        test       0.90      0.88      0.89      2464\n","   treatment       0.87      0.86      0.86      1244\n","\n","   micro avg       0.88      0.85      0.86      4878\n","   macro avg       0.87      0.84      0.86      4878\n","weighted avg       0.88      0.85      0.86      4878\n","\n","!!!!!! Starting model number 8 !!!!!!\n","Points in X_train after augmentation: 16315\n","Points in y_train after augmentation: 16315\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1446170806884766\n","Training loss per 100 training steps: 0.3009696126094844\n","Training loss per 100 training steps: 0.23325511654236572\n","Training loss per 100 training steps: 0.2095942688406603\n","Training loss per 100 training steps: 0.1885080834655579\n","Training loss per 100 training steps: 0.1791296112620664\n","Training loss epoch: 0.17701430409124083\n","Training accuracy epoch: 0.9434935548293392\n","Validating model...\n","Validation Loss: 0.1346442141825808\n","Validation Accuracy: 0.9583234503478811\n","Training epoch: 2\n","Training loss per 100 training steps: 0.1066461130976677\n","Training loss per 100 training steps: 0.07280944594836766\n","Training loss per 100 training steps: 0.06859273636894328\n","Training loss per 100 training steps: 0.06647503108638601\n","Training loss per 100 training steps: 0.06593530207606464\n","Training loss per 100 training steps: 0.06488459807645879\n","Training loss epoch: 0.06473972740007893\n","Training accuracy epoch: 0.9797067901234568\n","Validating model...\n","Validation Loss: 0.13884901027332114\n","Validation Accuracy: 0.9669117647058824\n","Training epoch: 3\n","Training loss per 100 training steps: 0.008516178466379642\n","Training loss per 100 training steps: 0.037945594270321736\n","Training loss per 100 training steps: 0.0394404210487325\n","Training loss per 100 training steps: 0.039813139789159166\n","Training loss per 100 training steps: 0.04598585851757585\n","Training loss per 100 training steps: 0.04623760620899826\n","Training loss epoch: 0.046124734847085076\n","Training accuracy epoch: 0.9850490196078432\n","Validating model...\n","Validation Loss: 0.147962961635808\n","Validation Accuracy: 0.9635416666666666\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0013030979316681623\n","Training loss per 100 training steps: 0.02270175178381407\n","Training loss per 100 training steps: 0.02589056259798713\n","Training loss per 100 training steps: 0.02417662706642073\n","Training loss per 100 training steps: 0.025910335135683325\n","Training loss per 100 training steps: 0.0278033588257964\n","Training loss epoch: 0.027597267083782594\n","Training accuracy epoch: 0.9907362018881627\n","Validating model...\n","Validation Loss: 0.13985594875503368\n","Validation Accuracy: 0.9638282732447818\n","Training epoch: 5\n","Training loss per 100 training steps: 0.00419462937861681\n","Training loss per 100 training steps: 0.025301285712786094\n","Training loss per 100 training steps: 0.025661568236360628\n","Training loss per 100 training steps: 0.02854095975050596\n","Training loss per 100 training steps: 0.02663142631622815\n","Training loss per 100 training steps: 0.028468884340773926\n","Training loss epoch: 0.028527355155885885\n","Training accuracy epoch: 0.9918504901960784\n","Validating model...\n","Validation Loss: 0.17168130027187312\n","Validation Accuracy: 0.9589263124604681\n","Training epoch: 6\n","Training loss per 100 training steps: 0.12831977009773254\n","Training loss per 100 training steps: 0.023430589913842406\n","Training loss per 100 training steps: 0.02127793201361783\n","Training loss per 100 training steps: 0.0200888206899952\n","Training loss per 100 training steps: 0.02080454820460185\n","Training loss per 100 training steps: 0.020943951151626995\n","Training loss epoch: 0.021186897801132597\n","Training accuracy epoch: 0.993688725490196\n","Validating model...\n","Validation Loss: 0.19601746753238225\n","Validation Accuracy: 0.9592524509803921\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 23.747181783333325 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.12988218164065513\n","Validation Accuracy: 0.9622034143518519\n","Validation duration: 2.3882093500000035 minutes\n","F1-score (test): 87.3%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.88      0.79      0.83      1170\n","        test       0.91      0.88      0.89      2464\n","   treatment       0.93      0.81      0.87      1244\n","\n","   micro avg       0.91      0.84      0.87      4878\n","   macro avg       0.91      0.83      0.86      4878\n","weighted avg       0.91      0.84      0.87      4878\n","\n","!!!!!! Starting model number 9 !!!!!!\n","Points in X_train after augmentation: 16315\n","Points in y_train after augmentation: 16315\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9652644395828247\n","Training loss per 100 training steps: 0.3102308059535404\n","Training loss per 100 training steps: 0.23425531248325732\n","Training loss per 100 training steps: 0.20288934367879036\n","Training loss per 100 training steps: 0.18921018064955708\n","Training loss per 100 training steps: 0.18049763362137172\n","Training loss epoch: 0.1799237438304094\n","Training accuracy epoch: 0.9425744371822804\n","Validating model...\n","Validation Loss: 0.1736996497310625\n","Validation Accuracy: 0.9491223908918406\n","Training epoch: 2\n","Training loss per 100 training steps: 0.025148622691631317\n","Training loss per 100 training steps: 0.06843284904809281\n","Training loss per 100 training steps: 0.06557060188708817\n","Training loss per 100 training steps: 0.06391325146323411\n","Training loss per 100 training steps: 0.06770522407275809\n","Training loss per 100 training steps: 0.06654137560606055\n","Training loss epoch: 0.06698767098109694\n","Training accuracy epoch: 0.9777460058097314\n","Validating model...\n","Validation Loss: 0.13013290639911942\n","Validation Accuracy: 0.9669018817204301\n","Training epoch: 3\n","Training loss per 100 training steps: 0.007136337459087372\n","Training loss per 100 training steps: 0.02639259666833787\n","Training loss per 100 training steps: 0.03277122554142232\n","Training loss per 100 training steps: 0.03182555179431125\n","Training loss per 100 training steps: 0.03133840512593469\n","Training loss per 100 training steps: 0.029478825972542845\n","Training loss epoch: 0.02957518581060154\n","Training accuracy epoch: 0.9907475490196078\n","Validating model...\n","Validation Loss: 0.18872502477504038\n","Validation Accuracy: 0.9641445287792536\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0002711295965127647\n","Training loss per 100 training steps: 0.0253073903217642\n","Training loss per 100 training steps: 0.023863714357096104\n","Training loss per 100 training steps: 0.023729169265604175\n","Training loss per 100 training steps: 0.028608361152594415\n","Training loss per 100 training steps: 0.028999534571475253\n","Training loss epoch: 0.028631700842051227\n","Training accuracy epoch: 0.9908700980392157\n","Validating model...\n","Validation Loss: 0.192188430041093\n","Validation Accuracy: 0.9632155281467426\n","Training epoch: 5\n","Training loss per 100 training steps: 0.06218408793210983\n","Training loss per 100 training steps: 0.03449790714346656\n","Training loss per 100 training steps: 0.03333592916629161\n","Training loss per 100 training steps: 0.031051817693050637\n","Training loss per 100 training steps: 0.03300399880978497\n","Training loss per 100 training steps: 0.030570489516100214\n","Training loss epoch: 0.03077077040872217\n","Training accuracy epoch: 0.9901733841684822\n","Validating model...\n","Validation Loss: 0.18323002531456845\n","Validation Accuracy: 0.9626126660341556\n","Training epoch: 6\n","Training loss per 100 training steps: 0.013961962424218655\n","Training loss per 100 training steps: 0.023965469891168545\n","Training loss per 100 training steps: 0.029556418393462878\n","Training loss per 100 training steps: 0.030999014799896377\n","Training loss per 100 training steps: 0.03044934259064451\n","Training loss per 100 training steps: 0.029890356088744848\n","Training loss epoch: 0.029594926446303613\n","Training accuracy epoch: 0.991360294117647\n","Validating model...\n","Validation Loss: 0.18362565670452335\n","Validation Accuracy: 0.960774430740038\n","Training epoch: 7\n","Training loss per 100 training steps: 0.008223321288824081\n","Training loss per 100 training steps: 0.00882930037770697\n","Training loss per 100 training steps: 0.013003114597372066\n","Training loss per 100 training steps: 0.012368657210442637\n","Training loss per 100 training steps: 0.013759278772649078\n","Training loss per 100 training steps: 0.015502927123138843\n","Training loss epoch: 0.015948189841611903\n","Training accuracy epoch: 0.9955269607843137\n","Validating model...\n","Validation Loss: 0.17682825564977475\n","Validation Accuracy: 0.9604779411764706\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 27.76943420000001 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13432674703660638\n","Validation Accuracy: 0.9604311342592593\n","Validation duration: 2.3864261166666743 minutes\n","F1-score (test): 87.1%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.78      0.88      0.83      1170\n","        test       0.86      0.93      0.89      2464\n","   treatment       0.88      0.86      0.87      1244\n","\n","   micro avg       0.85      0.90      0.87      4878\n","   macro avg       0.84      0.89      0.86      4878\n","weighted avg       0.85      0.90      0.87      4878\n","\n","!!!!!! Starting model number 10 !!!!!!\n","Points in X_train after augmentation: 16315\n","Points in y_train after augmentation: 16315\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8893333673477173\n","Training loss per 100 training steps: 0.31272578954991725\n","Training loss per 100 training steps: 0.22967390122068165\n","Training loss per 100 training steps: 0.20184311670161462\n","Training loss per 100 training steps: 0.18475336592616584\n","Training loss per 100 training steps: 0.17431096527948528\n","Training loss epoch: 0.17286744296879453\n","Training accuracy epoch: 0.9457607116920843\n","Validating model...\n","Validation Loss: 0.118102089049952\n","Validation Accuracy: 0.9632155281467426\n","Training epoch: 2\n","Training loss per 100 training steps: 0.20499765872955322\n","Training loss per 100 training steps: 0.06896702144848238\n","Training loss per 100 training steps: 0.06673147437215982\n","Training loss per 100 training steps: 0.0695688184431949\n","Training loss per 100 training steps: 0.06721830906513661\n","Training loss per 100 training steps: 0.06825916114669413\n","Training loss epoch: 0.06819154717571413\n","Training accuracy epoch: 0.9790441176470588\n","Validating model...\n","Validation Loss: 0.12974810138728252\n","Validation Accuracy: 0.9650735294117647\n","Training epoch: 3\n","Training loss per 100 training steps: 0.011274415999650955\n","Training loss per 100 training steps: 0.033539662949076975\n","Training loss per 100 training steps: 0.028679235900760356\n","Training loss per 100 training steps: 0.034498253900656764\n","Training loss per 100 training steps: 0.038075967457846846\n","Training loss per 100 training steps: 0.040343595392041895\n","Training loss epoch: 0.04040112953493828\n","Training accuracy epoch: 0.9881127450980393\n","Validating model...\n","Validation Loss: 0.16290036809297426\n","Validation Accuracy: 0.9616935483870968\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0048902458511292934\n","Training loss per 100 training steps: 0.034203153440733394\n","Training loss per 100 training steps: 0.02934877183641636\n","Training loss per 100 training steps: 0.03321701061493791\n","Training loss per 100 training steps: 0.03360357754328172\n","Training loss per 100 training steps: 0.031229385113989108\n","Training loss epoch: 0.031155263672653567\n","Training accuracy epoch: 0.9909313725490196\n","Validating model...\n","Validation Loss: 0.18564337315026433\n","Validation Accuracy: 0.9613871758380772\n","Training epoch: 5\n","Training loss per 100 training steps: 0.006674124859273434\n","Training loss per 100 training steps: 0.026202533599842193\n","Training loss per 100 training steps: 0.027212487381907003\n","Training loss per 100 training steps: 0.02462542801290465\n","Training loss per 100 training steps: 0.0252616123065776\n","Training loss per 100 training steps: 0.025487910903731297\n","Training loss epoch: 0.025865586276503403\n","Training accuracy epoch: 0.9926969862018882\n","Validating model...\n","Validation Loss: 0.16733495692959896\n","Validation Accuracy: 0.9598454301075269\n","Training epoch: 6\n","Training loss per 100 training steps: 0.004742247052490711\n","Training loss per 100 training steps: 0.02149461579234178\n","Training loss per 100 training steps: 0.02064261807405201\n","Training loss per 100 training steps: 0.02620435403896348\n","Training loss per 100 training steps: 0.027209692873914077\n","Training loss per 100 training steps: 0.026637498138526696\n","Training loss epoch: 0.026408144704727615\n","Training accuracy epoch: 0.9922067901234568\n","Validating model...\n","Validation Loss: 0.1929729515666658\n","Validation Accuracy: 0.9613871758380772\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 23.683592149999974 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13417415029026517\n","Validation Accuracy: 0.9565771283436214\n","Validation duration: 2.3807950333333188 minutes\n","F1-score (test): 85.6%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.73      0.88      0.80      1170\n","        test       0.86      0.92      0.89      2464\n","   treatment       0.92      0.79      0.85      1244\n","\n","   micro avg       0.83      0.88      0.86      4878\n","   macro avg       0.83      0.87      0.85      4878\n","weighted avg       0.84      0.88      0.86      4878\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0.25\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":19925267,"status":"ok","timestamp":1657375611415,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"jdO4m5O4Hlo3","outputId":"ed944090-8f70-4dda-8116-f6971378c8dc"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 50.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 19578\n","Points in y_train after augmentation: 19578\n","Device:  cuda\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"276c19cb8e774d37a90c777410668893","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/422M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.215693235397339\n","Training loss per 100 training steps: 0.33854773668295673\n","Training loss per 100 training steps: 0.2578450901924971\n","Training loss per 100 training steps: 0.22356894816522582\n","Training loss per 100 training steps: 0.19951856219583652\n","Training loss per 100 training steps: 0.18602415255202118\n","Training loss per 100 training steps: 0.17435905911236035\n","Training loss epoch: 0.17280895941741642\n","Training accuracy epoch: 0.9468954248366013\n","Validating model...\n","Validation Loss: 0.12406462126904551\n","Validation Accuracy: 0.9641247628083491\n","Training epoch: 2\n","Training loss per 100 training steps: 0.11528557538986206\n","Training loss per 100 training steps: 0.06030313705214032\n","Training loss per 100 training steps: 0.057082550907716044\n","Training loss per 100 training steps: 0.059304212810598514\n","Training loss per 100 training steps: 0.06101039660882038\n","Training loss per 100 training steps: 0.06495579291542178\n","Training loss per 100 training steps: 0.0640058641234016\n","Training loss epoch: 0.06377689294411278\n","Training accuracy epoch: 0.9800857843137255\n","Validating model...\n","Validation Loss: 0.1468345036019124\n","Validation Accuracy: 0.9607843137254902\n","Training epoch: 3\n","Training loss per 100 training steps: 0.06865132600069046\n","Training loss per 100 training steps: 0.02640149741702123\n","Training loss per 100 training steps: 0.03435807159000808\n","Training loss per 100 training steps: 0.03668629988670996\n","Training loss per 100 training steps: 0.03709102517664212\n","Training loss per 100 training steps: 0.03867996113231692\n","Training loss per 100 training steps: 0.0412792068260711\n","Training loss epoch: 0.04127650475281662\n","Training accuracy epoch: 0.9868770424836601\n","Validating model...\n","Validation Loss: 0.16834333521432662\n","Validation Accuracy: 0.9570979601518027\n","Training epoch: 4\n","Training loss per 100 training steps: 0.14183104038238525\n","Training loss per 100 training steps: 0.03170945804141402\n","Training loss per 100 training steps: 0.025685406473377807\n","Training loss per 100 training steps: 0.023814830372780656\n","Training loss per 100 training steps: 0.02636831657758663\n","Training loss per 100 training steps: 0.024757599343542016\n","Training loss per 100 training steps: 0.02432761058149729\n","Training loss epoch: 0.02594043576591146\n","Training accuracy epoch: 0.9924820889894419\n","Validating model...\n","Validation Loss: 0.1799310585666521\n","Validation Accuracy: 0.9537377450980392\n","Training epoch: 5\n","Training loss per 100 training steps: 0.1051141545176506\n","Training loss per 100 training steps: 0.030686489421076667\n","Training loss per 100 training steps: 0.030293745911446752\n","Training loss per 100 training steps: 0.025954102680341967\n","Training loss per 100 training steps: 0.026406720077428513\n","Training loss per 100 training steps: 0.02756355512798824\n","Training loss per 100 training steps: 0.030291394542060295\n","Training loss epoch: 0.03032414545530961\n","Training accuracy epoch: 0.9909620098039216\n","Validating model...\n","Validation Loss: 0.15668563093926174\n","Validation Accuracy: 0.9629190385831752\n","Training epoch: 6\n","Training loss per 100 training steps: 0.2065952718257904\n","Training loss per 100 training steps: 0.029373177210224036\n","Training loss per 100 training steps: 0.02569935762147368\n","Training loss per 100 training steps: 0.02425271816485162\n","Training loss per 100 training steps: 0.023436540646154545\n","Training loss per 100 training steps: 0.02307220963919684\n","Training loss per 100 training steps: 0.02205735311282976\n","Training loss epoch: 0.022308575549853236\n","Training accuracy epoch: 0.9942182001005531\n","Validating model...\n","Validation Loss: 0.18029205163104195\n","Validation Accuracy: 0.9583135673624289\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 27.18893281666667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1363584208221356\n","Validation Accuracy: 0.9585503472222222\n","Validation duration: 2.302219516666666 minutes\n","F1-score (test): 86.3%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.87      0.78      0.82      1170\n","        test       0.83      0.94      0.88      2464\n","   treatment       0.86      0.88      0.87      1244\n","\n","   micro avg       0.84      0.88      0.86      4878\n","   macro avg       0.85      0.86      0.86      4878\n","weighted avg       0.85      0.88      0.86      4878\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 19578\n","Points in y_train after augmentation: 19578\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1021580696105957\n","Training loss per 100 training steps: 0.31424090085495815\n","Training loss per 100 training steps: 0.24158938893056775\n","Training loss per 100 training steps: 0.21400906517173462\n","Training loss per 100 training steps: 0.19346850622965586\n","Training loss per 100 training steps: 0.18036608955081174\n","Training loss per 100 training steps: 0.17119626495088397\n","Training loss epoch: 0.17039687653053917\n","Training accuracy epoch: 0.9472017973856209\n","Validating model...\n","Validation Loss: 0.13151117954768388\n","Validation Accuracy: 0.9586100569259962\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0953969731926918\n","Training loss per 100 training steps: 0.06547182546651895\n","Training loss per 100 training steps: 0.06636990976765456\n","Training loss per 100 training steps: 0.0681034375354957\n","Training loss per 100 training steps: 0.07068378194130753\n","Training loss per 100 training steps: 0.06945287797784994\n","Training loss per 100 training steps: 0.06942360968593998\n","Training loss epoch: 0.06882761795457233\n","Training accuracy epoch: 0.9798304738562091\n","Validating model...\n","Validation Loss: 0.14389770375290775\n","Validation Accuracy: 0.9629091555977229\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0025285091251134872\n","Training loss per 100 training steps: 0.023734695675188103\n","Training loss per 100 training steps: 0.029022110686046695\n","Training loss per 100 training steps: 0.029815027394921416\n","Training loss per 100 training steps: 0.03186047321375334\n","Training loss per 100 training steps: 0.03443208321360378\n","Training loss per 100 training steps: 0.0353804898467465\n","Training loss epoch: 0.03534419006343514\n","Training accuracy epoch: 0.9897875816993464\n","Validating model...\n","Validation Loss: 0.15162999731461135\n","Validation Accuracy: 0.9626225490196079\n","Training epoch: 4\n","Training loss per 100 training steps: 0.08698232471942902\n","Training loss per 100 training steps: 0.022923627525100042\n","Training loss per 100 training steps: 0.027416639224874015\n","Training loss per 100 training steps: 0.024285044383212762\n","Training loss per 100 training steps: 0.02434786463680284\n","Training loss per 100 training steps: 0.026280876301865565\n","Training loss per 100 training steps: 0.028415027997836052\n","Training loss epoch: 0.028909558985129608\n","Training accuracy epoch: 0.9912173202614379\n","Validating model...\n","Validation Loss: 0.14272376390313274\n","Validation Accuracy: 0.9641544117647058\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0008881028043106198\n","Training loss per 100 training steps: 0.016817366701175025\n","Training loss per 100 training steps: 0.016166442863015336\n","Training loss per 100 training steps: 0.018682713534261805\n","Training loss per 100 training steps: 0.018007945357492377\n","Training loss per 100 training steps: 0.02230578922298193\n","Training loss per 100 training steps: 0.023693690137825706\n","Training loss epoch: 0.02398263334403738\n","Training accuracy epoch: 0.9928002450980392\n","Validating model...\n","Validation Loss: 0.17730487829562752\n","Validation Accuracy: 0.9592326850094877\n","Training epoch: 6\n","Training loss per 100 training steps: 0.007153166923671961\n","Training loss per 100 training steps: 0.018063776274580546\n","Training loss per 100 training steps: 0.023403004924912964\n","Training loss per 100 training steps: 0.021730086686147843\n","Training loss per 100 training steps: 0.021015898220853195\n","Training loss per 100 training steps: 0.021020210311965815\n","Training loss per 100 training steps: 0.021928981525978244\n","Training loss epoch: 0.021840512159494858\n","Training accuracy epoch: 0.9936683006535948\n","Validating model...\n","Validation Loss: 0.21043444884194554\n","Validation Accuracy: 0.9586298228969007\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 27.9688075 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1370229489451352\n","Validation Accuracy: 0.9549334490740741\n","Validation duration: 2.3665780499999984 minutes\n","F1-score (test): 85.5%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.79      0.83      0.81      1170\n","        test       0.87      0.89      0.88      2464\n","   treatment       0.79      0.91      0.85      1244\n","\n","   micro avg       0.83      0.88      0.86      4878\n","   macro avg       0.82      0.88      0.85      4878\n","weighted avg       0.83      0.88      0.86      4878\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 19578\n","Points in y_train after augmentation: 19578\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.138986825942993\n","Training loss per 100 training steps: 0.31600445774522157\n","Training loss per 100 training steps: 0.2499908751330862\n","Training loss per 100 training steps: 0.21980982249683123\n","Training loss per 100 training steps: 0.1982617317954371\n","Training loss per 100 training steps: 0.1855288374752639\n","Training loss per 100 training steps: 0.17715460684819895\n","Training loss epoch: 0.17588157608368574\n","Training accuracy epoch: 0.9453125\n","Validating model...\n","Validation Loss: 0.13552949189747154\n","Validation Accuracy: 0.9613970588235294\n","Training epoch: 2\n","Training loss per 100 training steps: 0.01155929546803236\n","Training loss per 100 training steps: 0.07415569768780565\n","Training loss per 100 training steps: 0.06450449143430978\n","Training loss per 100 training steps: 0.06354209327040723\n","Training loss per 100 training steps: 0.06535922218752245\n","Training loss per 100 training steps: 0.0672879690450092\n","Training loss per 100 training steps: 0.0664930563334247\n","Training loss epoch: 0.06630812730996648\n","Training accuracy epoch: 0.9800347222222222\n","Validating model...\n","Validation Loss: 0.12712092751947543\n","Validation Accuracy: 0.9650735294117647\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0014945692382752895\n","Training loss per 100 training steps: 0.023142120908106686\n","Training loss per 100 training steps: 0.028728176355165017\n","Training loss per 100 training steps: 0.03005381180549758\n","Training loss per 100 training steps: 0.029000193882644167\n","Training loss per 100 training steps: 0.03115393115826111\n","Training loss per 100 training steps: 0.034636300068504385\n","Training loss epoch: 0.03440835304872903\n","Training accuracy epoch: 0.9886131535947712\n","Validating model...\n","Validation Loss: 0.15712455545287288\n","Validation Accuracy: 0.9635416666666666\n","Training epoch: 4\n","Training loss per 100 training steps: 0.1926926076412201\n","Training loss per 100 training steps: 0.031773731963118855\n","Training loss per 100 training steps: 0.027748454616124747\n","Training loss per 100 training steps: 0.03180671222504086\n","Training loss per 100 training steps: 0.03120452364162888\n","Training loss per 100 training steps: 0.029048878769802736\n","Training loss per 100 training steps: 0.029934012186493664\n","Training loss epoch: 0.029460162327559613\n","Training accuracy epoch: 0.9918300653594772\n","Validating model...\n","Validation Loss: 0.17803280421061324\n","Validation Accuracy: 0.9607843137254902\n","Training epoch: 5\n","Training loss per 100 training steps: 0.12119884043931961\n","Training loss per 100 training steps: 0.01962591665174517\n","Training loss per 100 training steps: 0.02098049695672472\n","Training loss per 100 training steps: 0.021773818822933805\n","Training loss per 100 training steps: 0.02398629857046777\n","Training loss per 100 training steps: 0.025159064478092425\n","Training loss per 100 training steps: 0.025096454489456077\n","Training loss epoch: 0.025717416295972524\n","Training accuracy epoch: 0.9922385620915033\n","Validating model...\n","Validation Loss: 0.20577902307987267\n","Validation Accuracy: 0.9558823529411765\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0014730494003742933\n","Training loss per 100 training steps: 0.01772876338077142\n","Training loss per 100 training steps: 0.015717203584493866\n","Training loss per 100 training steps: 0.014305147339531492\n","Training loss per 100 training steps: 0.016320287764851615\n","Training loss per 100 training steps: 0.0162914620607312\n","Training loss per 100 training steps: 0.016583628674321917\n","Training loss epoch: 0.016572417883211753\n","Training accuracy epoch: 0.9948937908496732\n","Validating model...\n","Validation Loss: 0.1774934445041735\n","Validation Accuracy: 0.9641445287792536\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0003001125587616116\n","Training loss per 100 training steps: 0.00594805340946244\n","Training loss per 100 training steps: 0.00900479822194572\n","Training loss per 100 training steps: 0.0079419452569794\n","Training loss per 100 training steps: 0.009726581856226775\n","Training loss per 100 training steps: 0.012429678160967347\n","Training loss per 100 training steps: 0.013829701122738822\n","Training loss epoch: 0.013835799018731146\n","Training accuracy epoch: 0.9962724673202614\n","Validating model...\n","Validation Loss: 0.2183370733347307\n","Validation Accuracy: 0.9592228020240354\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 33.447407516666665 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13137523281060298\n","Validation Accuracy: 0.9606119791666666\n","Validation duration: 2.4129356499999934 minutes\n","F1-score (test): 87.0%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.80      0.85      0.83      1170\n","        test       0.89      0.90      0.90      2464\n","   treatment       0.88      0.85      0.86      1244\n","\n","   micro avg       0.86      0.88      0.87      4878\n","   macro avg       0.86      0.87      0.86      4878\n","weighted avg       0.86      0.88      0.87      4878\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 19578\n","Points in y_train after augmentation: 19578\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.714329719543457\n","Training loss per 100 training steps: 0.32860280479313714\n","Training loss per 100 training steps: 0.26148133809256613\n","Training loss per 100 training steps: 0.2220541653888566\n","Training loss per 100 training steps: 0.2084464742418871\n","Training loss per 100 training steps: 0.19401804714495252\n","Training loss per 100 training steps: 0.182681573822958\n","Training loss epoch: 0.1801344507192779\n","Training accuracy epoch: 0.9442912581699346\n","Validating model...\n","Validation Loss: 0.13573999776660153\n","Validation Accuracy: 0.9589460784313726\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0034535396844148636\n","Training loss per 100 training steps: 0.055933376423793264\n","Training loss per 100 training steps: 0.05876594845701324\n","Training loss per 100 training steps: 0.05851148433659993\n","Training loss per 100 training steps: 0.06217544058023109\n","Training loss per 100 training steps: 0.06505745135878813\n","Training loss per 100 training steps: 0.06666554868875611\n","Training loss epoch: 0.06660494477698485\n","Training accuracy epoch: 0.9793198529411765\n","Validating model...\n","Validation Loss: 0.1448962424594142\n","Validation Accuracy: 0.9623161764705882\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04384360462427139\n","Training loss per 100 training steps: 0.039008337890240594\n","Training loss per 100 training steps: 0.04507396261112774\n","Training loss per 100 training steps: 0.04429306327968687\n","Training loss per 100 training steps: 0.04723391129648048\n","Training loss per 100 training steps: 0.04649269208532782\n","Training loss per 100 training steps: 0.04535587147337705\n","Training loss epoch: 0.04581816412555662\n","Training accuracy epoch: 0.9868141968325792\n","Validating model...\n","Validation Loss: 0.14253181570401305\n","Validation Accuracy: 0.960774430740038\n","Training epoch: 4\n","Training loss per 100 training steps: 0.04724320396780968\n","Training loss per 100 training steps: 0.02293302041033541\n","Training loss per 100 training steps: 0.023618347111125638\n","Training loss per 100 training steps: 0.023620534868271977\n","Training loss per 100 training steps: 0.026633793390926468\n","Training loss per 100 training steps: 0.02647464025607997\n","Training loss per 100 training steps: 0.02856782181993783\n","Training loss epoch: 0.029305611242188463\n","Training accuracy epoch: 0.9907066993464052\n","Validating model...\n","Validation Loss: 0.17148095029566035\n","Validation Accuracy: 0.9567718216318786\n","Training epoch: 5\n","Training loss per 100 training steps: 0.003023987403139472\n","Training loss per 100 training steps: 0.01735890950975331\n","Training loss per 100 training steps: 0.029098598389458885\n","Training loss per 100 training steps: 0.02773404337115357\n","Training loss per 100 training steps: 0.02867332217827883\n","Training loss per 100 training steps: 0.026496800280163556\n","Training loss per 100 training steps: 0.026169867309393594\n","Training loss epoch: 0.026730981187784043\n","Training accuracy epoch: 0.9918300653594772\n","Validating model...\n","Validation Loss: 0.20409548901735952\n","Validation Accuracy: 0.9607447817836813\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0008422531536780298\n","Training loss per 100 training steps: 0.03359712804160496\n","Training loss per 100 training steps: 0.022295368100566888\n","Training loss per 100 training steps: 0.026060335082901207\n","Training loss per 100 training steps: 0.029067788737342098\n","Training loss per 100 training steps: 0.028023266562824407\n","Training loss per 100 training steps: 0.02569503799956288\n","Training loss epoch: 0.025411533672679093\n","Training accuracy epoch: 0.9917279411764706\n","Validating model...\n","Validation Loss: 0.19958769606598128\n","Validation Accuracy: 0.962306293485136\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 27.992983483333333 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13196563194260644\n","Validation Accuracy: 0.9597800925925926\n","Validation duration: 2.361848216666658 minutes\n","F1-score (test): 86.8%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.84      0.81      0.83      1170\n","        test       0.93      0.85      0.89      2464\n","   treatment       0.85      0.89      0.87      1244\n","\n","   micro avg       0.89      0.85      0.87      4878\n","   macro avg       0.87      0.85      0.86      4878\n","weighted avg       0.89      0.85      0.87      4878\n","\n","!!!!!! Starting model number 5 !!!!!!\n","Points in X_train after augmentation: 19578\n","Points in y_train after augmentation: 19578\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.766218662261963\n","Training loss per 100 training steps: 0.3692619699320876\n","Training loss per 100 training steps: 0.2783614891808276\n","Training loss per 100 training steps: 0.23995621304996187\n","Training loss per 100 training steps: 0.21143058920046895\n","Training loss per 100 training steps: 0.1920653424214594\n","Training loss per 100 training steps: 0.18047685427172808\n","Training loss epoch: 0.17864956643456728\n","Training accuracy epoch: 0.9434232026143791\n","Validating model...\n","Validation Loss: 0.12979672274406195\n","Validation Accuracy: 0.9601616856419988\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06047741323709488\n","Training loss per 100 training steps: 0.06242850962058079\n","Training loss per 100 training steps: 0.061215589116026294\n","Training loss per 100 training steps: 0.06278943184893145\n","Training loss per 100 training steps: 0.060587005907474574\n","Training loss per 100 training steps: 0.06283004416286213\n","Training loss per 100 training steps: 0.06339882978828183\n","Training loss epoch: 0.06389386170485523\n","Training accuracy epoch: 0.9808006535947712\n","Validating model...\n","Validation Loss: 0.16921889062402495\n","Validation Accuracy: 0.9543406072106262\n","Training epoch: 3\n","Training loss per 100 training steps: 0.009280923753976822\n","Training loss per 100 training steps: 0.052622152547730075\n","Training loss per 100 training steps: 0.046697092345633094\n","Training loss per 100 training steps: 0.04184078681340713\n","Training loss per 100 training steps: 0.0421111753024335\n","Training loss per 100 training steps: 0.04216268133084399\n","Training loss per 100 training steps: 0.04240702936433456\n","Training loss epoch: 0.04303389180932796\n","Training accuracy epoch: 0.9865196078431373\n","Validating model...\n","Validation Loss: 0.17157675984815476\n","Validation Accuracy: 0.9561788425047438\n","Training epoch: 4\n","Training loss per 100 training steps: 0.008324939757585526\n","Training loss per 100 training steps: 0.0186283603161608\n","Training loss per 100 training steps: 0.018741615585081015\n","Training loss per 100 training steps: 0.02315749273914109\n","Training loss per 100 training steps: 0.022225523027894784\n","Training loss per 100 training steps: 0.022343675233092587\n","Training loss per 100 training steps: 0.02275487613088367\n","Training loss epoch: 0.022681443696771025\n","Training accuracy epoch: 0.9933501445449975\n","Validating model...\n","Validation Loss: 0.18377016532102453\n","Validation Accuracy: 0.9653601359898798\n","Training epoch: 5\n","Training loss per 100 training steps: 0.009337522089481354\n","Training loss per 100 training steps: 0.028629065720199624\n","Training loss per 100 training steps: 0.028310662067862487\n","Training loss per 100 training steps: 0.026381834469305542\n","Training loss per 100 training steps: 0.027867295956342165\n","Training loss per 100 training steps: 0.025861272523106455\n","Training loss per 100 training steps: 0.024855068560289496\n","Training loss epoch: 0.02464089395881256\n","Training accuracy epoch: 0.9921875\n","Validating model...\n","Validation Loss: 0.19996629230644983\n","Validation Accuracy: 0.9632352941176471\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0005778262275271118\n","Training loss per 100 training steps: 0.024141519192270797\n","Training loss per 100 training steps: 0.024521987955390002\n","Training loss per 100 training steps: 0.023066492447004178\n","Training loss per 100 training steps: 0.02573755931590673\n","Training loss per 100 training steps: 0.027745762909652187\n","Training loss per 100 training steps: 0.028610357414829753\n","Training loss epoch: 0.028291210305753958\n","Training accuracy epoch: 0.9923406862745098\n","Validating model...\n","Validation Loss: 0.1928102553961342\n","Validation Accuracy: 0.9589263124604681\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 27.202396899999986 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13302521578966495\n","Validation Accuracy: 0.9585463284465021\n","Validation duration: 2.2947045166666613 minutes\n","F1-score (test): 86.4%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.79      0.83      0.81      1170\n","        test       0.88      0.90      0.89      2464\n","   treatment       0.85      0.89      0.86      1244\n","\n","   micro avg       0.85      0.88      0.86      4878\n","   macro avg       0.84      0.87      0.85      4878\n","weighted avg       0.85      0.88      0.86      4878\n","\n","!!!!!! Starting model number 6 !!!!!!\n","Points in X_train after augmentation: 19578\n","Points in y_train after augmentation: 19578\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7848294973373413\n","Training loss per 100 training steps: 0.3251564999175544\n","Training loss per 100 training steps: 0.2420284821100496\n","Training loss per 100 training steps: 0.2203468538053408\n","Training loss per 100 training steps: 0.20089445794767646\n","Training loss per 100 training steps: 0.18366594315913623\n","Training loss per 100 training steps: 0.17431293638460277\n","Training loss epoch: 0.17335563805791263\n","Training accuracy epoch: 0.944420877325289\n","Validating model...\n","Validation Loss: 0.13063662745487675\n","Validation Accuracy: 0.9619999209361164\n","Training epoch: 2\n","Training loss per 100 training steps: 0.032038211822509766\n","Training loss per 100 training steps: 0.05505060264840722\n","Training loss per 100 training steps: 0.06027059188397573\n","Training loss per 100 training steps: 0.06247927246041336\n","Training loss per 100 training steps: 0.06258197772540756\n","Training loss per 100 training steps: 0.06092392572642354\n","Training loss per 100 training steps: 0.06334450395143251\n","Training loss epoch: 0.06308069963596329\n","Training accuracy epoch: 0.9806474673202614\n","Validating model...\n","Validation Loss: 0.14628375511771688\n","Validation Accuracy: 0.9552597248576851\n","Training epoch: 3\n","Training loss per 100 training steps: 0.01744919829070568\n","Training loss per 100 training steps: 0.04118617530796898\n","Training loss per 100 training steps: 0.033577031968364174\n","Training loss per 100 training steps: 0.033356112070351475\n","Training loss per 100 training steps: 0.033258760553866534\n","Training loss per 100 training steps: 0.03476552165292544\n","Training loss per 100 training steps: 0.035022795445442345\n","Training loss epoch: 0.03512051150704602\n","Training accuracy epoch: 0.9879493464052288\n","Validating model...\n","Validation Loss: 0.18412248648810953\n","Validation Accuracy: 0.9561689595192916\n","Training epoch: 4\n","Training loss per 100 training steps: 0.027965325862169266\n","Training loss per 100 training steps: 0.038697372249438255\n","Training loss per 100 training steps: 0.028375913863665708\n","Training loss per 100 training steps: 0.027708072525840115\n","Training loss per 100 training steps: 0.030427871814598283\n","Training loss per 100 training steps: 0.03255809368494226\n","Training loss per 100 training steps: 0.0316284577733519\n","Training loss epoch: 0.03186205787321395\n","Training accuracy epoch: 0.989826860231272\n","Validating model...\n","Validation Loss: 0.19589611567932355\n","Validation Accuracy: 0.9598651960784313\n","Training epoch: 5\n","Training loss per 100 training steps: 0.003945712931454182\n","Training loss per 100 training steps: 0.024544939781149553\n","Training loss per 100 training steps: 0.03204008295309072\n","Training loss per 100 training steps: 0.0276833463265279\n","Training loss per 100 training steps: 0.030905505034090147\n","Training loss per 100 training steps: 0.03193072639540499\n","Training loss per 100 training steps: 0.03375734134254506\n","Training loss epoch: 0.034611412891916465\n","Training accuracy epoch: 0.9893673014077425\n","Validating model...\n","Validation Loss: 0.16520847530588142\n","Validation Accuracy: 0.9564852150537635\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00795720610767603\n","Training loss per 100 training steps: 0.015936892796630537\n","Training loss per 100 training steps: 0.015607033489953693\n","Training loss per 100 training steps: 0.01992732464523245\n","Training loss per 100 training steps: 0.021973028932931772\n","Training loss per 100 training steps: 0.024749041213191575\n","Training loss per 100 training steps: 0.024877427943893856\n","Training loss epoch: 0.024818824281633733\n","Training accuracy epoch: 0.9925331510809452\n","Validating model...\n","Validation Loss: 0.17816213310089\n","Validation Accuracy: 0.9616935483870968\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 27.524036816666648 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13017405768348705\n","Validation Accuracy: 0.9602141203703703\n","Validation duration: 2.333089933333334 minutes\n","F1-score (test): 86.4%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.88      0.77      0.82      1170\n","        test       0.90      0.88      0.89      2464\n","   treatment       0.88      0.84      0.86      1244\n","\n","   micro avg       0.89      0.84      0.86      4878\n","   macro avg       0.88      0.83      0.85      4878\n","weighted avg       0.89      0.84      0.86      4878\n","\n","!!!!!! Starting model number 7 !!!!!!\n","Points in X_train after augmentation: 19578\n","Points in y_train after augmentation: 19578\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9771021604537964\n","Training loss per 100 training steps: 0.339236267611827\n","Training loss per 100 training steps: 0.25510324884335794\n","Training loss per 100 training steps: 0.2154160585390571\n","Training loss per 100 training steps: 0.20304695606937728\n","Training loss per 100 training steps: 0.19252742166926493\n","Training loss per 100 training steps: 0.1786672171288962\n","Training loss epoch: 0.17826600419509597\n","Training accuracy epoch: 0.9442284125188537\n","Validating model...\n","Validation Loss: 0.1304368625815008\n","Validation Accuracy: 0.9583333333333334\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07515816390514374\n","Training loss per 100 training steps: 0.06927498080998216\n","Training loss per 100 training steps: 0.06625723950124685\n","Training loss per 100 training steps: 0.06428429612153491\n","Training loss per 100 training steps: 0.061662190294176564\n","Training loss per 100 training steps: 0.06386375482363288\n","Training loss per 100 training steps: 0.064370141964725\n","Training loss epoch: 0.0646127498974214\n","Training accuracy epoch: 0.9799325980392157\n","Validating model...\n","Validation Loss: 0.14451586810515865\n","Validation Accuracy: 0.962306293485136\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02941850945353508\n","Training loss per 100 training steps: 0.04246490135141141\n","Training loss per 100 training steps: 0.040662788596891555\n","Training loss per 100 training steps: 0.03695221571290426\n","Training loss per 100 training steps: 0.038663251163058236\n","Training loss per 100 training steps: 0.04062090196171329\n","Training loss per 100 training steps: 0.04146958754735746\n","Training loss epoch: 0.04133846094885847\n","Training accuracy epoch: 0.9876940359477124\n","Validating model...\n","Validation Loss: 0.1523202128534881\n","Validation Accuracy: 0.9622964104996837\n","Training epoch: 4\n","Training loss per 100 training steps: 0.04302486032247543\n","Training loss per 100 training steps: 0.02572071180064554\n","Training loss per 100 training steps: 0.025219289409587467\n","Training loss per 100 training steps: 0.028402633821865177\n","Training loss per 100 training steps: 0.02871762029605278\n","Training loss per 100 training steps: 0.030645040055383006\n","Training loss per 100 training steps: 0.03223448761271723\n","Training loss epoch: 0.0320483875918452\n","Training accuracy epoch: 0.9901960784313726\n","Validating model...\n","Validation Loss: 0.16022759057951214\n","Validation Accuracy: 0.9604680581910183\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0056191799230873585\n","Training loss per 100 training steps: 0.030729688914368242\n","Training loss per 100 training steps: 0.03481072339429682\n","Training loss per 100 training steps: 0.03719437615853113\n","Training loss per 100 training steps: 0.03692327234243737\n","Training loss per 100 training steps: 0.036430313672959624\n","Training loss per 100 training steps: 0.03418454189940562\n","Training loss epoch: 0.0342196996243491\n","Training accuracy epoch: 0.9895833333333334\n","Validating model...\n","Validation Loss: 0.1600445316951521\n","Validation Accuracy: 0.9620098039215687\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0013040502090007067\n","Training loss per 100 training steps: 0.01224536689933122\n","Training loss per 100 training steps: 0.01287349342445719\n","Training loss per 100 training steps: 0.01360958290904311\n","Training loss per 100 training steps: 0.014345851811746418\n","Training loss per 100 training steps: 0.016679696966685423\n","Training loss per 100 training steps: 0.019910007676642062\n","Training loss epoch: 0.020253428827297932\n","Training accuracy epoch: 0.9939236111111112\n","Validating model...\n","Validation Loss: 0.16025815799823215\n","Validation Accuracy: 0.9580071948134092\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 27.389467666666647 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13988507199812578\n","Validation Accuracy: 0.9545717592592593\n","Validation duration: 2.3260820333333263 minutes\n","F1-score (test): 85.8%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.69      0.89      0.78      1170\n","        test       0.87      0.92      0.90      2464\n","   treatment       0.84      0.89      0.87      1244\n","\n","   micro avg       0.81      0.91      0.86      4878\n","   macro avg       0.80      0.90      0.85      4878\n","weighted avg       0.82      0.91      0.86      4878\n","\n","!!!!!! Starting model number 8 !!!!!!\n","Points in X_train after augmentation: 19578\n","Points in y_train after augmentation: 19578\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.2110466957092285\n","Training loss per 100 training steps: 0.336679190065306\n","Training loss per 100 training steps: 0.25706832380548345\n","Training loss per 100 training steps: 0.22275217034640502\n","Training loss per 100 training steps: 0.20442892502566004\n","Training loss per 100 training steps: 0.18792261552816616\n","Training loss per 100 training steps: 0.17607351795564127\n","Training loss epoch: 0.1764015889760058\n","Training accuracy epoch: 0.9433210784313726\n","Validating model...\n","Validation Loss: 0.12707375352928305\n","Validation Accuracy: 0.9613871758380772\n","Training epoch: 2\n","Training loss per 100 training steps: 0.008650621399283409\n","Training loss per 100 training steps: 0.05609989594748834\n","Training loss per 100 training steps: 0.058595754810555636\n","Training loss per 100 training steps: 0.05677800112155628\n","Training loss per 100 training steps: 0.059858101253900585\n","Training loss per 100 training steps: 0.061167132752941\n","Training loss per 100 training steps: 0.06248029738086618\n","Training loss epoch: 0.06295777842808771\n","Training accuracy epoch: 0.9810323969331322\n","Validating model...\n","Validation Loss: 0.12321802806657027\n","Validation Accuracy: 0.9687203510436433\n","Training epoch: 3\n","Training loss per 100 training steps: 0.004094994161278009\n","Training loss per 100 training steps: 0.0280863129485417\n","Training loss per 100 training steps: 0.03389795229999599\n","Training loss per 100 training steps: 0.03435917331075584\n","Training loss per 100 training steps: 0.040004508354061837\n","Training loss per 100 training steps: 0.04040744141860263\n","Training loss per 100 training steps: 0.04089981880144157\n","Training loss epoch: 0.0408118178277981\n","Training accuracy epoch: 0.9870302287581699\n","Validating model...\n","Validation Loss: 0.13331554978218513\n","Validation Accuracy: 0.9647375079063883\n","Training epoch: 4\n","Training loss per 100 training steps: 0.005406347569078207\n","Training loss per 100 training steps: 0.028498630783414598\n","Training loss per 100 training steps: 0.03123940500159706\n","Training loss per 100 training steps: 0.03666542211324719\n","Training loss per 100 training steps: 0.03494693196407389\n","Training loss per 100 training steps: 0.03589889933484116\n","Training loss per 100 training steps: 0.03434499962883537\n","Training loss epoch: 0.034033627916358375\n","Training accuracy epoch: 0.9892258986928104\n","Validating model...\n","Validation Loss: 0.19234147977355556\n","Validation Accuracy: 0.9576909392789374\n","Training epoch: 5\n","Training loss per 100 training steps: 0.035466268658638\n","Training loss per 100 training steps: 0.013261270863643737\n","Training loss per 100 training steps: 0.01576462179146254\n","Training loss per 100 training steps: 0.017651014664438375\n","Training loss per 100 training steps: 0.020373433779454365\n","Training loss per 100 training steps: 0.02046593712588357\n","Training loss per 100 training steps: 0.022632239812234174\n","Training loss epoch: 0.022321419350821825\n","Training accuracy epoch: 0.9924938725490197\n","Validating model...\n","Validation Loss: 0.1935441473288651\n","Validation Accuracy: 0.9598553130929791\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0009429851197637618\n","Training loss per 100 training steps: 0.010996316455660208\n","Training loss per 100 training steps: 0.015274690651540142\n","Training loss per 100 training steps: 0.017467758545511445\n","Training loss per 100 training steps: 0.024541568030006494\n","Training loss per 100 training steps: 0.025202443003329748\n","Training loss per 100 training steps: 0.025703036967644522\n","Training loss epoch: 0.026189462609526423\n","Training accuracy epoch: 0.9926981209150327\n","Validating model...\n","Validation Loss: 0.1981752393031082\n","Validation Accuracy: 0.9506740196078431\n","Training epoch: 7\n","Training loss per 100 training steps: 0.004382360726594925\n","Training loss per 100 training steps: 0.010896314497423903\n","Training loss per 100 training steps: 0.01063467566424848\n","Training loss per 100 training steps: 0.011243058123658787\n","Training loss per 100 training steps: 0.011097676294241835\n","Training loss per 100 training steps: 0.011869611033906116\n","Training loss per 100 training steps: 0.015407814304407552\n","Training loss epoch: 0.0154412606244103\n","Training accuracy epoch: 0.995046977124183\n","Validating model...\n","Validation Loss: 0.18320076903781976\n","Validation Accuracy: 0.9650636464263125\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 32.02522926666667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.11887754522875318\n","Validation Accuracy: 0.9656394675925926\n","Validation duration: 2.3331774999999957 minutes\n","F1-score (test): 88.7%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.82      0.86      0.84      1170\n","        test       0.91      0.91      0.91      2464\n","   treatment       0.86      0.91      0.89      1244\n","\n","   micro avg       0.87      0.90      0.89      4878\n","   macro avg       0.86      0.89      0.88      4878\n","weighted avg       0.88      0.90      0.89      4878\n","\n","!!!!!! Starting model number 9 !!!!!!\n","Points in X_train after augmentation: 19578\n","Points in y_train after augmentation: 19578\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.2786970138549805\n","Training loss per 100 training steps: 0.33782750633683534\n","Training loss per 100 training steps: 0.2563454323860617\n","Training loss per 100 training steps: 0.21672894085673894\n","Training loss per 100 training steps: 0.19494556214665051\n","Training loss per 100 training steps: 0.18089539896391943\n","Training loss per 100 training steps: 0.17129917200437797\n","Training loss epoch: 0.17070648551072462\n","Training accuracy epoch: 0.9459252450980392\n","Validating model...\n","Validation Loss: 0.12616661375425026\n","Validation Accuracy: 0.960774430740038\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05266966298222542\n","Training loss per 100 training steps: 0.05530639399836614\n","Training loss per 100 training steps: 0.05555415708387493\n","Training loss per 100 training steps: 0.05933592239102005\n","Training loss per 100 training steps: 0.0600116776898033\n","Training loss per 100 training steps: 0.06356012568400825\n","Training loss per 100 training steps: 0.06282254545704366\n","Training loss epoch: 0.06262536169088931\n","Training accuracy epoch: 0.9800857843137255\n","Validating model...\n","Validation Loss: 0.12914029099092836\n","Validation Accuracy: 0.9610808032890575\n","Training epoch: 3\n","Training loss per 100 training steps: 0.007012808695435524\n","Training loss per 100 training steps: 0.02308594337941175\n","Training loss per 100 training steps: 0.028806901098586926\n","Training loss per 100 training steps: 0.03108226172395895\n","Training loss per 100 training steps: 0.034831040963647246\n","Training loss per 100 training steps: 0.03578150141065217\n","Training loss per 100 training steps: 0.03584140224901211\n","Training loss epoch: 0.035741780087299675\n","Training accuracy epoch: 0.9894301470588235\n","Validating model...\n","Validation Loss: 0.14656326311124562\n","Validation Accuracy: 0.960774430740038\n","Training epoch: 4\n","Training loss per 100 training steps: 0.016733819618821144\n","Training loss per 100 training steps: 0.025246592216645505\n","Training loss per 100 training steps: 0.024196742618553785\n","Training loss per 100 training steps: 0.02433874879441954\n","Training loss per 100 training steps: 0.024841909578413774\n","Training loss per 100 training steps: 0.024387421220941365\n","Training loss per 100 training steps: 0.028502711586702804\n","Training loss epoch: 0.029175901378205714\n","Training accuracy epoch: 0.9915119092508798\n","Validating model...\n","Validation Loss: 0.18187329382863918\n","Validation Accuracy: 0.9543406072106262\n","Training epoch: 5\n","Training loss per 100 training steps: 0.010859069414436817\n","Training loss per 100 training steps: 0.025086376825831647\n","Training loss per 100 training steps: 0.02815406097765822\n","Training loss per 100 training steps: 0.0316812883890613\n","Training loss per 100 training steps: 0.029119571294717404\n","Training loss per 100 training steps: 0.027966114273376134\n","Training loss per 100 training steps: 0.02597223755572504\n","Training loss epoch: 0.025964092212591057\n","Training accuracy epoch: 0.9926470588235294\n","Validating model...\n","Validation Loss: 0.19056149140498532\n","Validation Accuracy: 0.9613970588235294\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0005819100770168006\n","Training loss per 100 training steps: 0.021187499806683715\n","Training loss per 100 training steps: 0.016570150049748503\n","Training loss per 100 training steps: 0.013231472546620328\n","Training loss per 100 training steps: 0.013631148476465989\n","Training loss per 100 training steps: 0.016352457166378113\n","Training loss per 100 training steps: 0.019422860670081372\n","Training loss epoch: 0.019620464827585834\n","Training accuracy epoch: 0.9936172385620915\n","Validating model...\n","Validation Loss: 0.21503690322067853\n","Validation Accuracy: 0.9525122549019608\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 27.540328283333352 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1374033397776118\n","Validation Accuracy: 0.9569589120370371\n","Validation duration: 2.3353436999999757 minutes\n","F1-score (test): 86.0%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.72      0.88      0.79      1170\n","        test       0.90      0.89      0.89      2464\n","   treatment       0.87      0.86      0.86      1244\n","\n","   micro avg       0.84      0.88      0.86      4878\n","   macro avg       0.83      0.88      0.85      4878\n","weighted avg       0.85      0.88      0.86      4878\n","\n","!!!!!! Starting model number 10 !!!!!!\n","Points in X_train after augmentation: 19578\n","Points in y_train after augmentation: 19578\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.061351776123047\n","Training loss per 100 training steps: 0.34375979603812246\n","Training loss per 100 training steps: 0.26189787511653567\n","Training loss per 100 training steps: 0.22607085178683564\n","Training loss per 100 training steps: 0.2054092588061072\n","Training loss per 100 training steps: 0.19081618990228622\n","Training loss per 100 training steps: 0.17989157895346833\n","Training loss epoch: 0.17886114825633068\n","Training accuracy epoch: 0.9435253267973857\n","Validating model...\n","Validation Loss: 0.1336696700389296\n","Validation Accuracy: 0.960171568627451\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09964501857757568\n","Training loss per 100 training steps: 0.06609237486367474\n","Training loss per 100 training steps: 0.059380450581932503\n","Training loss per 100 training steps: 0.06359277434834276\n","Training loss per 100 training steps: 0.06629844948427607\n","Training loss per 100 training steps: 0.06544575320501922\n","Training loss per 100 training steps: 0.06633496503756318\n","Training loss epoch: 0.06705175985101294\n","Training accuracy epoch: 0.9795751633986928\n","Validating model...\n","Validation Loss: 0.12877731921845206\n","Validation Accuracy: 0.9669018817204301\n","Training epoch: 3\n","Training loss per 100 training steps: 0.010377109050750732\n","Training loss per 100 training steps: 0.02837387733576395\n","Training loss per 100 training steps: 0.02628850695733282\n","Training loss per 100 training steps: 0.02629161437293066\n","Training loss per 100 training steps: 0.026692923458517783\n","Training loss per 100 training steps: 0.031473005369761976\n","Training loss per 100 training steps: 0.03402787925595706\n","Training loss epoch: 0.03488832297015881\n","Training accuracy epoch: 0.9890216503267973\n","Validating model...\n","Validation Loss: 0.13964565137661444\n","Validation Accuracy: 0.9620098039215687\n","Training epoch: 4\n","Training loss per 100 training steps: 0.053442757576704025\n","Training loss per 100 training steps: 0.018233709254285947\n","Training loss per 100 training steps: 0.02631232401211885\n","Training loss per 100 training steps: 0.031102110480636734\n","Training loss per 100 training steps: 0.03179667340764286\n","Training loss per 100 training steps: 0.030048819676603\n","Training loss per 100 training steps: 0.029613537108080117\n","Training loss epoch: 0.02950902551755361\n","Training accuracy epoch: 0.991064133986928\n","Validating model...\n","Validation Loss: 0.1676651690938218\n","Validation Accuracy: 0.9632352941176471\n","Training epoch: 5\n","Training loss per 100 training steps: 0.009834116324782372\n","Training loss per 100 training steps: 0.018747682523819167\n","Training loss per 100 training steps: 0.021229615845534757\n","Training loss per 100 training steps: 0.02218652361814119\n","Training loss per 100 training steps: 0.021189445681046803\n","Training loss per 100 training steps: 0.02023243814397291\n","Training loss per 100 training steps: 0.022233437002266907\n","Training loss epoch: 0.02316865923875727\n","Training accuracy epoch: 0.9930555555555556\n","Validating model...\n","Validation Loss: 0.16107467300025746\n","Validation Accuracy: 0.962306293485136\n","Training epoch: 6\n","Training loss per 100 training steps: 0.010723978281021118\n","Training loss per 100 training steps: 0.022070374745399562\n","Training loss per 100 training steps: 0.0178498190554584\n","Training loss per 100 training steps: 0.01987618127446374\n","Training loss per 100 training steps: 0.020738490783734864\n","Training loss per 100 training steps: 0.02104390793672378\n","Training loss per 100 training steps: 0.022156329642810446\n","Training loss epoch: 0.022249855048179525\n","Training accuracy epoch: 0.993310866013072\n","Validating model...\n","Validation Loss: 0.18236638891924967\n","Validation Accuracy: 0.9604779411764706\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0005326218670234084\n","Training loss per 100 training steps: 0.00985358094145016\n","Training loss per 100 training steps: 0.01645270174642734\n","Training loss per 100 training steps: 0.017556037889452973\n","Training loss per 100 training steps: 0.022710626973586064\n","Training loss per 100 training steps: 0.021472288244898257\n","Training loss per 100 training steps: 0.024154472794040812\n","Training loss epoch: 0.024451597490327662\n","Training accuracy epoch: 0.9926470588235294\n","Validating model...\n","Validation Loss: 0.16331058434454962\n","Validation Accuracy: 0.9629091555977229\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 31.878216933333352 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13596522129052943\n","Validation Accuracy: 0.9612268518518519\n","Validation duration: 2.3159771833333553 minutes\n","F1-score (test): 86.8%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.91      0.77      0.84      1170\n","        test       0.87      0.92      0.90      2464\n","   treatment       0.90      0.79      0.84      1244\n","\n","   micro avg       0.89      0.85      0.87      4878\n","   macro avg       0.89      0.83      0.86      4878\n","weighted avg       0.89      0.85      0.87      4878\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0.5\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23020943,"status":"ok","timestamp":1657398632850,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"oKNxFPucHn_R","outputId":"f1a7517f-0ca3-444e-9737-cd61c7bdfb45"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 75.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 22841\n","Points in y_train after augmentation: 22841\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8548579216003418\n","Training loss per 100 training steps: 0.30175390238366506\n","Training loss per 100 training steps: 0.24581879491347874\n","Training loss per 100 training steps: 0.22282888415730573\n","Training loss per 100 training steps: 0.19865630129282538\n","Training loss per 100 training steps: 0.18948991535911838\n","Training loss per 100 training steps: 0.17601398439859403\n","Training loss per 100 training steps: 0.16775765923448385\n","Training loss epoch: 0.16675329995758997\n","Training accuracy epoch: 0.9473354341736695\n","Validating model...\n","Validation Loss: 0.1409384084765014\n","Validation Accuracy: 0.9555660974067046\n","Training epoch: 2\n","Training loss per 100 training steps: 0.010771045461297035\n","Training loss per 100 training steps: 0.04964567152183909\n","Training loss per 100 training steps: 0.0614307002970643\n","Training loss per 100 training steps: 0.05962338825290175\n","Training loss per 100 training steps: 0.058322162846709484\n","Training loss per 100 training steps: 0.058828750788141225\n","Training loss per 100 training steps: 0.05973002563630496\n","Training loss per 100 training steps: 0.061806279844066364\n","Training loss epoch: 0.06153332601146152\n","Training accuracy epoch: 0.9802608543417367\n","Validating model...\n","Validation Loss: 0.14919080172879987\n","Validation Accuracy: 0.9589164294750159\n","Training epoch: 3\n","Training loss per 100 training steps: 0.008409637026488781\n","Training loss per 100 training steps: 0.035316102251083135\n","Training loss per 100 training steps: 0.03244301512494535\n","Training loss per 100 training steps: 0.030775899947984485\n","Training loss per 100 training steps: 0.03281653922851293\n","Training loss per 100 training steps: 0.033399195169463956\n","Training loss per 100 training steps: 0.03527229274253124\n","Training loss per 100 training steps: 0.03641175043733642\n","Training loss epoch: 0.03606957363162688\n","Training accuracy epoch: 0.9894520308123249\n","Validating model...\n","Validation Loss: 0.17022014666587232\n","Validation Accuracy: 0.9635317836812144\n","Training epoch: 4\n","Training loss per 100 training steps: 0.002275892999023199\n","Training loss per 100 training steps: 0.014940122956188746\n","Training loss per 100 training steps: 0.02560894945894127\n","Training loss per 100 training steps: 0.02887240397127769\n","Training loss per 100 training steps: 0.029097782667773308\n","Training loss per 100 training steps: 0.030230542614069877\n","Training loss per 100 training steps: 0.029833584712042872\n","Training loss per 100 training steps: 0.031350801520607735\n","Training loss epoch: 0.031720872757880894\n","Training accuracy epoch: 0.9906337535014006\n","Validating model...\n","Validation Loss: 0.17425664546032088\n","Validation Accuracy: 0.9580269607843137\n","Training epoch: 5\n","Training loss per 100 training steps: 0.00359911285340786\n","Training loss per 100 training steps: 0.02613358001171676\n","Training loss per 100 training steps: 0.01991171226619548\n","Training loss per 100 training steps: 0.024322282666502135\n","Training loss per 100 training steps: 0.023917816974021764\n","Training loss per 100 training steps: 0.024763788616235002\n","Training loss per 100 training steps: 0.026211620418736172\n","Training loss per 100 training steps: 0.027385463532708144\n","Training loss epoch: 0.027347319545154607\n","Training accuracy epoch: 0.9913655462184875\n","Validating model...\n","Validation Loss: 0.18148941236237684\n","Validation Accuracy: 0.9619900379506642\n","Training epoch: 6\n","Training loss per 100 training steps: 0.007276361808180809\n","Training loss per 100 training steps: 0.010139079258554168\n","Training loss per 100 training steps: 0.013986461209482224\n","Training loss per 100 training steps: 0.015585691351311064\n","Training loss per 100 training steps: 0.017446323649105273\n","Training loss per 100 training steps: 0.018379931276307573\n","Training loss per 100 training steps: 0.02001540801468638\n","Training loss per 100 training steps: 0.021287720243261112\n","Training loss epoch: 0.02159321040571307\n","Training accuracy epoch: 0.9933035714285714\n","Validating model...\n","Validation Loss: 0.16434539996051029\n","Validation Accuracy: 0.9607546647691335\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 31.86190793333329 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15147371575181345\n","Validation Accuracy: 0.9524337705761318\n","Validation duration: 2.334039999999974 minutes\n","F1-score (test): 83.0%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.82      0.77      0.79      1170\n","        test       0.78      0.94      0.85      2464\n","   treatment       0.93      0.73      0.81      1244\n","\n","   micro avg       0.81      0.85      0.83      4878\n","   macro avg       0.84      0.81      0.82      4878\n","weighted avg       0.83      0.85      0.83      4878\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 22841\n","Points in y_train after augmentation: 22841\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7219456434249878\n","Training loss per 100 training steps: 0.29604064186315726\n","Training loss per 100 training steps: 0.2364483243178817\n","Training loss per 100 training steps: 0.20948692676193542\n","Training loss per 100 training steps: 0.1929618220653227\n","Training loss per 100 training steps: 0.18264453644267545\n","Training loss per 100 training steps: 0.17414457498260846\n","Training loss per 100 training steps: 0.16778565309051632\n","Training loss epoch: 0.1668791053627542\n","Training accuracy epoch: 0.9477608543417366\n","Validating model...\n","Validation Loss: 0.13595132705956406\n","Validation Accuracy: 0.9577205882352942\n","Training epoch: 2\n","Training loss per 100 training steps: 0.17267946898937225\n","Training loss per 100 training steps: 0.05460841726917442\n","Training loss per 100 training steps: 0.0612688239980072\n","Training loss per 100 training steps: 0.06178355028878347\n","Training loss per 100 training steps: 0.05993360131145792\n","Training loss per 100 training steps: 0.06248684078624599\n","Training loss per 100 training steps: 0.061339784151593225\n","Training loss per 100 training steps: 0.062856866355262\n","Training loss epoch: 0.0626144771680532\n","Training accuracy epoch: 0.9806985294117647\n","Validating model...\n","Validation Loss: 0.1430867515577405\n","Validation Accuracy: 0.9604779411764706\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03990069404244423\n","Training loss per 100 training steps: 0.02425317019270272\n","Training loss per 100 training steps: 0.028265129445255062\n","Training loss per 100 training steps: 0.028619257178996067\n","Training loss per 100 training steps: 0.031975413583064605\n","Training loss per 100 training steps: 0.03403157970013874\n","Training loss per 100 training steps: 0.03564979919875908\n","Training loss per 100 training steps: 0.037521145971058156\n","Training loss epoch: 0.0377913905389663\n","Training accuracy epoch: 0.9882703081232493\n","Validating model...\n","Validation Loss: 0.17577321754138478\n","Validation Accuracy: 0.9515733712839974\n","Training epoch: 4\n","Training loss per 100 training steps: 0.030047589913010597\n","Training loss per 100 training steps: 0.03284183012017298\n","Training loss per 100 training steps: 0.025650600268533313\n","Training loss per 100 training steps: 0.024320173482853452\n","Training loss per 100 training steps: 0.023759352002082977\n","Training loss per 100 training steps: 0.0258802725384702\n","Training loss per 100 training steps: 0.02641679597529912\n","Training loss per 100 training steps: 0.028282110082034916\n","Training loss epoch: 0.02833662416384616\n","Training accuracy epoch: 0.9905217086834733\n","Validating model...\n","Validation Loss: 0.17962923286169968\n","Validation Accuracy: 0.9601419196710943\n","Training epoch: 5\n","Training loss per 100 training steps: 0.167282372713089\n","Training loss per 100 training steps: 0.026687039008783636\n","Training loss per 100 training steps: 0.025344315967991696\n","Training loss per 100 training steps: 0.023460985324964347\n","Training loss per 100 training steps: 0.023281628585102947\n","Training loss per 100 training steps: 0.023011824317223498\n","Training loss per 100 training steps: 0.02436765793491288\n","Training loss per 100 training steps: 0.02673661063826967\n","Training loss epoch: 0.026915437474849122\n","Training accuracy epoch: 0.9921971288515407\n","Validating model...\n","Validation Loss: 0.19043339852143226\n","Validation Accuracy: 0.9626225490196079\n","Training epoch: 6\n","Training loss per 100 training steps: 0.05936921760439873\n","Training loss per 100 training steps: 0.025618277955800295\n","Training loss per 100 training steps: 0.025527401734824033\n","Training loss per 100 training steps: 0.023158429110698493\n","Training loss per 100 training steps: 0.02485576501771392\n","Training loss per 100 training steps: 0.023592468644110087\n","Training loss per 100 training steps: 0.021443220708851567\n","Training loss per 100 training steps: 0.022517629171919552\n","Training loss epoch: 0.02232043579653885\n","Training accuracy epoch: 0.9934348739495799\n","Validating model...\n","Validation Loss: 0.21739993695433335\n","Validation Accuracy: 0.9546469797596459\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 32.76323944999998 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13885638842556444\n","Validation Accuracy: 0.955833654835391\n","Validation duration: 2.391054500000003 minutes\n","F1-score (test): 85.7%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.86      0.77      0.81      1170\n","        test       0.88      0.87      0.88      2464\n","   treatment       0.89      0.81      0.85      1244\n","\n","   micro avg       0.88      0.83      0.86      4878\n","   macro avg       0.88      0.82      0.85      4878\n","weighted avg       0.88      0.83      0.86      4878\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 22841\n","Points in y_train after augmentation: 22841\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1000144481658936\n","Training loss per 100 training steps: 0.3512491757179251\n","Training loss per 100 training steps: 0.2564692381695284\n","Training loss per 100 training steps: 0.22436479210816448\n","Training loss per 100 training steps: 0.2056590696852515\n","Training loss per 100 training steps: 0.1898274070168743\n","Training loss per 100 training steps: 0.17641538112736563\n","Training loss per 100 training steps: 0.16912830367198775\n","Training loss epoch: 0.1677805458427686\n","Training accuracy epoch: 0.9469852941176471\n","Validating model...\n","Validation Loss: 0.1145134240653658\n","Validation Accuracy: 0.9647572738772928\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05057530477643013\n","Training loss per 100 training steps: 0.0552849344313283\n","Training loss per 100 training steps: 0.05559957534594888\n","Training loss per 100 training steps: 0.05549171264844164\n","Training loss per 100 training steps: 0.05927390569981833\n","Training loss per 100 training steps: 0.059535288330592295\n","Training loss per 100 training steps: 0.06052214870476916\n","Training loss per 100 training steps: 0.059886576552438904\n","Training loss epoch: 0.05998316352069443\n","Training accuracy epoch: 0.9813988095238095\n","Validating model...\n","Validation Loss: 0.14398002221737533\n","Validation Accuracy: 0.9613871758380772\n","Training epoch: 3\n","Training loss per 100 training steps: 0.013826234266161919\n","Training loss per 100 training steps: 0.04552513226004557\n","Training loss per 100 training steps: 0.03724521852332394\n","Training loss per 100 training steps: 0.0353118850293792\n","Training loss per 100 training steps: 0.034691608816828284\n","Training loss per 100 training steps: 0.03491241157305508\n","Training loss per 100 training steps: 0.03494689811479487\n","Training loss per 100 training steps: 0.0380334351113182\n","Training loss epoch: 0.03848541656909566\n","Training accuracy epoch: 0.9880077030812325\n","Validating model...\n","Validation Loss: 0.15328452364409195\n","Validation Accuracy: 0.9626027830487034\n","Training epoch: 4\n","Training loss per 100 training steps: 0.11185551434755325\n","Training loss per 100 training steps: 0.016442672212638128\n","Training loss per 100 training steps: 0.021720582880085538\n","Training loss per 100 training steps: 0.023156485135861955\n","Training loss per 100 training steps: 0.027637044695620262\n","Training loss per 100 training steps: 0.027403554281338578\n","Training loss per 100 training steps: 0.02720850585334095\n","Training loss per 100 training steps: 0.028243090776033593\n","Training loss epoch: 0.02877902317479046\n","Training accuracy epoch: 0.9915091036414566\n","Validating model...\n","Validation Loss: 0.1653495817079994\n","Validation Accuracy: 0.9610808032890575\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0848027840256691\n","Training loss per 100 training steps: 0.011870419031981895\n","Training loss per 100 training steps: 0.014088379653487517\n","Training loss per 100 training steps: 0.01954352572268112\n","Training loss per 100 training steps: 0.01926638619879033\n","Training loss per 100 training steps: 0.02005934593185946\n","Training loss per 100 training steps: 0.020561296481265496\n","Training loss per 100 training steps: 0.022369505968942112\n","Training loss epoch: 0.022564931962945133\n","Training accuracy epoch: 0.9926908263305322\n","Validating model...\n","Validation Loss: 0.18616473762941657\n","Validation Accuracy: 0.9546568627450981\n","Training epoch: 6\n","Training loss per 100 training steps: 0.011226827278733253\n","Training loss per 100 training steps: 0.026364553088695734\n","Training loss per 100 training steps: 0.02082529358840339\n","Training loss per 100 training steps: 0.022960900856499898\n","Training loss per 100 training steps: 0.021217735958467945\n","Training loss per 100 training steps: 0.020167337878253554\n","Training loss per 100 training steps: 0.020919123007700904\n","Training loss per 100 training steps: 0.020906138581799384\n","Training loss epoch: 0.020838596127512838\n","Training accuracy epoch: 0.9933473389355743\n","Validating model...\n","Validation Loss: 0.1949021091367125\n","Validation Accuracy: 0.9583333333333334\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 32.27004683333332 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.12920233278338047\n","Validation Accuracy: 0.9601940264917695\n","Validation duration: 2.3669506666667077 minutes\n","F1-score (test): 87.0%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.84      0.85      0.84      1170\n","        test       0.85      0.93      0.89      2464\n","   treatment       0.87      0.86      0.86      1244\n","\n","   micro avg       0.85      0.89      0.87      4878\n","   macro avg       0.85      0.88      0.86      4878\n","weighted avg       0.85      0.89      0.87      4878\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 22841\n","Points in y_train after augmentation: 22841\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9487454891204834\n","Training loss per 100 training steps: 0.32452898640370015\n","Training loss per 100 training steps: 0.25443488104611783\n","Training loss per 100 training steps: 0.22144796180405787\n","Training loss per 100 training steps: 0.2047423580429166\n","Training loss per 100 training steps: 0.18823084165202733\n","Training loss per 100 training steps: 0.1772885086214768\n","Training loss per 100 training steps: 0.1698098841904478\n","Training loss epoch: 0.1679800788628026\n","Training accuracy epoch: 0.9474352240896359\n","Validating model...\n","Validation Loss: 0.13817688146852614\n","Validation Accuracy: 0.9628992726122707\n","Training epoch: 2\n","Training loss per 100 training steps: 0.012570465914905071\n","Training loss per 100 training steps: 0.06507697964137844\n","Training loss per 100 training steps: 0.06312332088324654\n","Training loss per 100 training steps: 0.06309251387895973\n","Training loss per 100 training steps: 0.06354300688909822\n","Training loss per 100 training steps: 0.06455078289996063\n","Training loss per 100 training steps: 0.06289633187244936\n","Training loss per 100 training steps: 0.06409937182593142\n","Training loss epoch: 0.06452759527492061\n","Training accuracy epoch: 0.9803046218487395\n","Validating model...\n","Validation Loss: 0.13311381600158034\n","Validation Accuracy: 0.9589460784313726\n","Training epoch: 3\n","Training loss per 100 training steps: 0.008548536337912083\n","Training loss per 100 training steps: 0.0309341663044029\n","Training loss per 100 training steps: 0.03051136277699426\n","Training loss per 100 training steps: 0.029136243626124155\n","Training loss per 100 training steps: 0.031141845732007033\n","Training loss per 100 training steps: 0.03311428485044135\n","Training loss per 100 training steps: 0.034865241480224955\n","Training loss per 100 training steps: 0.03521756586975275\n","Training loss epoch: 0.03613028733782224\n","Training accuracy epoch: 0.9891771708683474\n","Validating model...\n","Validation Loss: 0.1561788203880675\n","Validation Accuracy: 0.9632352941176471\n","Training epoch: 4\n","Training loss per 100 training steps: 0.04362039268016815\n","Training loss per 100 training steps: 0.03286548123215464\n","Training loss per 100 training steps: 0.023403553743337035\n","Training loss per 100 training steps: 0.0359164348026456\n","Training loss per 100 training steps: 0.035890179129320014\n","Training loss per 100 training steps: 0.03662314195306846\n","Training loss per 100 training steps: 0.035407989675252924\n","Training loss per 100 training steps: 0.03525658880972643\n","Training loss epoch: 0.03604098250934967\n","Training accuracy epoch: 0.9888392857142857\n","Validating model...\n","Validation Loss: 0.1572922665452329\n","Validation Accuracy: 0.9653403700189753\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0012163850478827953\n","Training loss per 100 training steps: 0.01591731483920127\n","Training loss per 100 training steps: 0.01551064231949314\n","Training loss per 100 training steps: 0.016350803735408394\n","Training loss per 100 training steps: 0.015631804757055064\n","Training loss per 100 training steps: 0.01688345242823226\n","Training loss per 100 training steps: 0.018960923572538108\n","Training loss per 100 training steps: 0.020720554325651886\n","Training loss epoch: 0.021113872542342756\n","Training accuracy epoch: 0.994266456582633\n","Validating model...\n","Validation Loss: 0.18526732402867363\n","Validation Accuracy: 0.962306293485136\n","Training epoch: 6\n","Training loss per 100 training steps: 0.000857429055031389\n","Training loss per 100 training steps: 0.02530470388678668\n","Training loss per 100 training steps: 0.020510917891886096\n","Training loss per 100 training steps: 0.021629092619594642\n","Training loss per 100 training steps: 0.023184083056975238\n","Training loss per 100 training steps: 0.026318492874188977\n","Training loss per 100 training steps: 0.024803587522093492\n","Training loss per 100 training steps: 0.02393160299086208\n","Training loss epoch: 0.023939915384327846\n","Training accuracy epoch: 0.9929971988795518\n","Validating model...\n","Validation Loss: 0.21014582853361694\n","Validation Accuracy: 0.9619999209361164\n","Training epoch: 7\n","Training loss per 100 training steps: 0.002438603201881051\n","Training loss per 100 training steps: 0.013240682006851622\n","Training loss per 100 training steps: 0.01720541156422977\n","Training loss per 100 training steps: 0.017340822131854505\n","Training loss per 100 training steps: 0.017144697589096914\n","Training loss per 100 training steps: 0.018658133609743326\n","Training loss per 100 training steps: 0.01809173614639861\n","Training loss per 100 training steps: 0.017196251427284863\n","Training loss epoch: 0.01737618506552023\n","Training accuracy epoch: 0.9949229691876751\n","Validating model...\n","Validation Loss: 0.26098342016313625\n","Validation Accuracy: 0.9500019765970905\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 37.265453183333314 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14206225127862934\n","Validation Accuracy: 0.9576461226851852\n","Validation duration: 2.342673183333318 minutes\n","F1-score (test): 86.1%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.78      0.86      0.82      1170\n","        test       0.89      0.88      0.89      2464\n","   treatment       0.84      0.86      0.85      1244\n","\n","   micro avg       0.85      0.87      0.86      4878\n","   macro avg       0.84      0.87      0.85      4878\n","weighted avg       0.85      0.87      0.86      4878\n","\n","!!!!!! Starting model number 5 !!!!!!\n","Points in X_train after augmentation: 22841\n","Points in y_train after augmentation: 22841\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.802546501159668\n","Training loss per 100 training steps: 0.32534663475090914\n","Training loss per 100 training steps: 0.25332040399943123\n","Training loss per 100 training steps: 0.2198704315095744\n","Training loss per 100 training steps: 0.20172019230847496\n","Training loss per 100 training steps: 0.19016264000268068\n","Training loss per 100 training steps: 0.18023468782666593\n","Training loss per 100 training steps: 0.17127531927979728\n","Training loss epoch: 0.16918866589981071\n","Training accuracy epoch: 0.9469100140056023\n","Validating model...\n","Validation Loss: 0.11888783837682293\n","Validation Accuracy: 0.9662891366223909\n","Training epoch: 2\n","Training loss per 100 training steps: 0.018996383994817734\n","Training loss per 100 training steps: 0.057909842711956344\n","Training loss per 100 training steps: 0.056243861274242364\n","Training loss per 100 training steps: 0.05591490327618843\n","Training loss per 100 training steps: 0.057692281099993206\n","Training loss per 100 training steps: 0.0575931737593983\n","Training loss per 100 training steps: 0.06023286738779284\n","Training loss per 100 training steps: 0.0635827809338725\n","Training loss epoch: 0.06335748501297436\n","Training accuracy epoch: 0.9803046218487395\n","Validating model...\n","Validation Loss: 0.1524721981943859\n","Validation Accuracy: 0.9580170777988615\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03169909492135048\n","Training loss per 100 training steps: 0.031067330849536758\n","Training loss per 100 training steps: 0.02502760648019658\n","Training loss per 100 training steps: 0.023847860902968632\n","Training loss per 100 training steps: 0.026396437478571098\n","Training loss per 100 training steps: 0.029160198345087922\n","Training loss per 100 training steps: 0.032256633610547536\n","Training loss per 100 training steps: 0.03373532939246243\n","Training loss epoch: 0.034088574253275064\n","Training accuracy epoch: 0.9894520308123249\n","Validating model...\n","Validation Loss: 0.1646545286787966\n","Validation Accuracy: 0.9573845667299178\n","Training epoch: 4\n","Training loss per 100 training steps: 0.019203491508960724\n","Training loss per 100 training steps: 0.020029238230257186\n","Training loss per 100 training steps: 0.026896453403392275\n","Training loss per 100 training steps: 0.023506808298262086\n","Training loss per 100 training steps: 0.028174418842601717\n","Training loss per 100 training steps: 0.028721391711746085\n","Training loss per 100 training steps: 0.030390108892387677\n","Training loss per 100 training steps: 0.03161010896087808\n","Training loss epoch: 0.03140803788865167\n","Training accuracy epoch: 0.9905899859943977\n","Validating model...\n","Validation Loss: 0.16892344974478998\n","Validation Accuracy: 0.9592524509803921\n","Training epoch: 5\n","Training loss per 100 training steps: 0.07899126410484314\n","Training loss per 100 training steps: 0.018366436934355638\n","Training loss per 100 training steps: 0.019892166148429848\n","Training loss per 100 training steps: 0.019407026286285673\n","Training loss per 100 training steps: 0.019516750692049948\n","Training loss per 100 training steps: 0.022951310453884176\n","Training loss per 100 training steps: 0.022319385140316644\n","Training loss per 100 training steps: 0.022781230454560975\n","Training loss epoch: 0.022965740881314377\n","Training accuracy epoch: 0.9930287114845939\n","Validating model...\n","Validation Loss: 0.182025405391423\n","Validation Accuracy: 0.960774430740038\n","Training epoch: 6\n","Training loss per 100 training steps: 0.003217499004676938\n","Training loss per 100 training steps: 0.015375433760547624\n","Training loss per 100 training steps: 0.013127312516076583\n","Training loss per 100 training steps: 0.011860961785932161\n","Training loss per 100 training steps: 0.016712293703590363\n","Training loss per 100 training steps: 0.01778455693610505\n","Training loss per 100 training steps: 0.01748532253172161\n","Training loss per 100 training steps: 0.018432055255879345\n","Training loss epoch: 0.01852916970452467\n","Training accuracy epoch: 0.9946918767507004\n","Validating model...\n","Validation Loss: 0.2011233730804901\n","Validation Accuracy: 0.961377292852625\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 32.479496283333354 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.12487693740237134\n","Validation Accuracy: 0.9622395833333334\n","Validation duration: 2.3804307833333342 minutes\n","F1-score (test): 87.4%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.83      0.84      0.83      1170\n","        test       0.92      0.87      0.89      2464\n","   treatment       0.92      0.84      0.88      1244\n","\n","   micro avg       0.89      0.85      0.87      4878\n","   macro avg       0.89      0.85      0.87      4878\n","weighted avg       0.90      0.85      0.87      4878\n","\n","!!!!!! Starting model number 6 !!!!!!\n","Points in X_train after augmentation: 22841\n","Points in y_train after augmentation: 22841\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9318859577178955\n","Training loss per 100 training steps: 0.31199733732212886\n","Training loss per 100 training steps: 0.2544278303874814\n","Training loss per 100 training steps: 0.21530194352520166\n","Training loss per 100 training steps: 0.1993358925500527\n","Training loss per 100 training steps: 0.19028064095324088\n","Training loss per 100 training steps: 0.17953533475781588\n","Training loss per 100 training steps: 0.17020054587419445\n","Training loss epoch: 0.1689361211131601\n","Training accuracy epoch: 0.9472163865546218\n","Validating model...\n","Validation Loss: 0.12953517897803263\n","Validation Accuracy: 0.964441018342821\n","Training epoch: 2\n","Training loss per 100 training steps: 0.004651399329304695\n","Training loss per 100 training steps: 0.049131558741221555\n","Training loss per 100 training steps: 0.05209060769646304\n","Training loss per 100 training steps: 0.05501845386884859\n","Training loss per 100 training steps: 0.0572574008279422\n","Training loss per 100 training steps: 0.06279121511969009\n","Training loss per 100 training steps: 0.062250802317051566\n","Training loss per 100 training steps: 0.060542869856235665\n","Training loss epoch: 0.061079393888051496\n","Training accuracy epoch: 0.9805234593837535\n","Validating model...\n","Validation Loss: 0.14886385828083126\n","Validation Accuracy: 0.9616836654016445\n","Training epoch: 3\n","Training loss per 100 training steps: 0.004533838480710983\n","Training loss per 100 training steps: 0.030538645526278985\n","Training loss per 100 training steps: 0.028134933956064728\n","Training loss per 100 training steps: 0.03287512023650509\n","Training loss per 100 training steps: 0.034594072258268875\n","Training loss per 100 training steps: 0.03507829691171172\n","Training loss per 100 training steps: 0.03493616103593488\n","Training loss per 100 training steps: 0.035400460136862676\n","Training loss epoch: 0.03563399495799401\n","Training accuracy epoch: 0.9891018907563025\n","Validating model...\n","Validation Loss: 0.15712956336952344\n","Validation Accuracy: 0.9632155281467426\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0034701344557106495\n","Training loss per 100 training steps: 0.023717671386248636\n","Training loss per 100 training steps: 0.023514313961333473\n","Training loss per 100 training steps: 0.026476377496997473\n","Training loss per 100 training steps: 0.028170787452546208\n","Training loss per 100 training steps: 0.030936015729436665\n","Training loss per 100 training steps: 0.0319569148200019\n","Training loss per 100 training steps: 0.03145754673580434\n","Training loss epoch: 0.031261414144953995\n","Training accuracy epoch: 0.990358893557423\n","Validating model...\n","Validation Loss: 0.18417855994273707\n","Validation Accuracy: 0.9589361954459203\n","Training epoch: 5\n","Training loss per 100 training steps: 0.002039993414655328\n","Training loss per 100 training steps: 0.02204956645336196\n","Training loss per 100 training steps: 0.02242090145837798\n","Training loss per 100 training steps: 0.020260237013469403\n","Training loss per 100 training steps: 0.021925316504295682\n","Training loss per 100 training steps: 0.024498691693707712\n","Training loss per 100 training steps: 0.024087152818253514\n","Training loss per 100 training steps: 0.02336620572508019\n","Training loss epoch: 0.024095019317054024\n","Training accuracy epoch: 0.9922531512605042\n","Validating model...\n","Validation Loss: 0.1948082710799759\n","Validation Accuracy: 0.9589263124604681\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0009057072456926107\n","Training loss per 100 training steps: 0.02052508853808147\n","Training loss per 100 training steps: 0.02370771116939656\n","Training loss per 100 training steps: 0.021691328425822273\n","Training loss per 100 training steps: 0.020426777262169377\n","Training loss per 100 training steps: 0.018886808508267825\n","Training loss per 100 training steps: 0.020001808521316986\n","Training loss per 100 training steps: 0.021610312496541387\n","Training loss epoch: 0.022168860486887525\n","Training accuracy epoch: 0.9935661764705882\n","Validating model...\n","Validation Loss: 0.1807773334999094\n","Validation Accuracy: 0.9564852150537635\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 32.50880308333332 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.12893858813724904\n","Validation Accuracy: 0.9617332175925926\n","Validation duration: 2.3789439333333577 minutes\n","F1-score (test): 87.3%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.85      0.83      0.84      1170\n","        test       0.84      0.93      0.88      2464\n","   treatment       0.92      0.85      0.88      1244\n","\n","   micro avg       0.86      0.88      0.87      4878\n","   macro avg       0.87      0.87      0.87      4878\n","weighted avg       0.86      0.88      0.87      4878\n","\n","!!!!!! Starting model number 7 !!!!!!\n","Points in X_train after augmentation: 22841\n","Points in y_train after augmentation: 22841\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7660869359970093\n","Training loss per 100 training steps: 0.30289684007368467\n","Training loss per 100 training steps: 0.238079092173434\n","Training loss per 100 training steps: 0.20488813162264585\n","Training loss per 100 training steps: 0.18762836512468495\n","Training loss per 100 training steps: 0.17799352375770028\n","Training loss per 100 training steps: 0.16800710454446802\n","Training loss per 100 training steps: 0.1584842742159006\n","Training loss epoch: 0.15726785323418238\n","Training accuracy epoch: 0.9516369047619048\n","Validating model...\n","Validation Loss: 0.12651621210891023\n","Validation Accuracy: 0.9619900379506642\n","Training epoch: 2\n","Training loss per 100 training steps: 0.03662734851241112\n","Training loss per 100 training steps: 0.048918619144495835\n","Training loss per 100 training steps: 0.05169996371306247\n","Training loss per 100 training steps: 0.05128701168643868\n","Training loss per 100 training steps: 0.0509363497513639\n","Training loss per 100 training steps: 0.0521989569890298\n","Training loss per 100 training steps: 0.05328558651568095\n","Training loss per 100 training steps: 0.052439655995606904\n","Training loss epoch: 0.05325329155295615\n","Training accuracy epoch: 0.9845063025210085\n","Validating model...\n","Validation Loss: 0.14691265042318835\n","Validation Accuracy: 0.9592425679949399\n","Training epoch: 3\n","Training loss per 100 training steps: 0.016439110040664673\n","Training loss per 100 training steps: 0.029008318673551893\n","Training loss per 100 training steps: 0.031843169895522015\n","Training loss per 100 training steps: 0.03291203482467155\n","Training loss per 100 training steps: 0.033577504059029255\n","Training loss per 100 training steps: 0.03408727650185573\n","Training loss per 100 training steps: 0.03521498361105191\n","Training loss per 100 training steps: 0.03603171920944397\n","Training loss epoch: 0.036307596766345235\n","Training accuracy epoch: 0.9885206582633054\n","Validating model...\n","Validation Loss: 0.16767191713762597\n","Validation Accuracy: 0.9564852150537635\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0039633275009691715\n","Training loss per 100 training steps: 0.017363845240174893\n","Training loss per 100 training steps: 0.024068712689352005\n","Training loss per 100 training steps: 0.022739210617001418\n","Training loss per 100 training steps: 0.025242424493308928\n","Training loss per 100 training steps: 0.02349642576266846\n","Training loss per 100 training steps: 0.024307906341749848\n","Training loss per 100 training steps: 0.02577328848929547\n","Training loss epoch: 0.02686603868583019\n","Training accuracy epoch: 0.9923844537815126\n","Validating model...\n","Validation Loss: 0.1779288238207764\n","Validation Accuracy: 0.9561788425047438\n","Training epoch: 5\n","Training loss per 100 training steps: 0.06463835388422012\n","Training loss per 100 training steps: 0.022169829227230833\n","Training loss per 100 training steps: 0.025345042299112046\n","Training loss per 100 training steps: 0.02356680431225309\n","Training loss per 100 training steps: 0.022728523274621184\n","Training loss per 100 training steps: 0.02400861469388706\n","Training loss per 100 training steps: 0.024084624965907037\n","Training loss per 100 training steps: 0.022566612466483726\n","Training loss epoch: 0.022418120195418213\n","Training accuracy epoch: 0.992953431372549\n","Validating model...\n","Validation Loss: 0.19373860009306787\n","Validation Accuracy: 0.957997311827957\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0010046912357211113\n","Training loss per 100 training steps: 0.028958636444663666\n","Training loss per 100 training steps: 0.023331374424742535\n","Training loss per 100 training steps: 0.019462452757797295\n","Training loss per 100 training steps: 0.02316619445827611\n","Training loss per 100 training steps: 0.023683411763117047\n","Training loss per 100 training steps: 0.022903818433018426\n","Training loss per 100 training steps: 0.023439666597230246\n","Training loss epoch: 0.02331756898210562\n","Training accuracy epoch: 0.9926470588235294\n","Validating model...\n","Validation Loss: 0.19725807203070087\n","Validation Accuracy: 0.960774430740038\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 31.91625314999995 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.12339993748470011\n","Validation Accuracy: 0.9611906828703703\n","Validation duration: 2.338643016666659 minutes\n","F1-score (test): 87.2%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.84      0.84      0.84      1170\n","        test       0.85      0.93      0.89      2464\n","   treatment       0.89      0.85      0.87      1244\n","\n","   micro avg       0.86      0.89      0.87      4878\n","   macro avg       0.86      0.87      0.87      4878\n","weighted avg       0.86      0.89      0.87      4878\n","\n","!!!!!! Starting model number 8 !!!!!!\n","Points in X_train after augmentation: 22841\n","Points in y_train after augmentation: 22841\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8965543508529663\n","Training loss per 100 training steps: 0.3282024495967544\n","Training loss per 100 training steps: 0.2618264760822058\n","Training loss per 100 training steps: 0.2250606667906343\n","Training loss per 100 training steps: 0.19932927286247734\n","Training loss per 100 training steps: 0.18700097540315397\n","Training loss per 100 training steps: 0.17443485900305658\n","Training loss per 100 training steps: 0.16286613487043336\n","Training loss epoch: 0.1615546484903696\n","Training accuracy epoch: 0.949655112044818\n","Validating model...\n","Validation Loss: 0.13904246203966586\n","Validation Accuracy: 0.9580170777988615\n","Training epoch: 2\n","Training loss per 100 training steps: 0.008709254674613476\n","Training loss per 100 training steps: 0.05941906544416774\n","Training loss per 100 training steps: 0.05038402000857999\n","Training loss per 100 training steps: 0.060059441288544846\n","Training loss per 100 training steps: 0.059736706258844065\n","Training loss per 100 training steps: 0.058987527845906995\n","Training loss per 100 training steps: 0.059157265485427074\n","Training loss per 100 training steps: 0.06100153844051605\n","Training loss epoch: 0.06047357014655618\n","Training accuracy epoch: 0.9821306022408964\n","Validating model...\n","Validation Loss: 0.14109976114659553\n","Validation Accuracy: 0.9622964104996837\n","Training epoch: 3\n","Training loss per 100 training steps: 0.002677265787497163\n","Training loss per 100 training steps: 0.02626386560824709\n","Training loss per 100 training steps: 0.02333604189392355\n","Training loss per 100 training steps: 0.032241746306185766\n","Training loss per 100 training steps: 0.03538325727781388\n","Training loss per 100 training steps: 0.03580127681683128\n","Training loss per 100 training steps: 0.03688848871538592\n","Training loss per 100 training steps: 0.037724876754748476\n","Training loss epoch: 0.03759217376629\n","Training accuracy epoch: 0.9886204481792717\n","Validating model...\n","Validation Loss: 0.20226204699600417\n","Validation Accuracy: 0.9540342346616066\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03722662478685379\n","Training loss per 100 training steps: 0.025869344328852868\n","Training loss per 100 training steps: 0.029329996960890937\n","Training loss per 100 training steps: 0.027045622115340385\n","Training loss per 100 training steps: 0.026196223304053492\n","Training loss per 100 training steps: 0.028861734363609556\n","Training loss per 100 training steps: 0.027688678066993808\n","Training loss per 100 training steps: 0.028760105493152895\n","Training loss epoch: 0.028993413026614755\n","Training accuracy epoch: 0.9906775210084033\n","Validating model...\n","Validation Loss: 0.17594665430335546\n","Validation Accuracy: 0.9616836654016445\n","Training epoch: 5\n","Training loss per 100 training steps: 0.038890086114406586\n","Training loss per 100 training steps: 0.023022615781289037\n","Training loss per 100 training steps: 0.03159089387129223\n","Training loss per 100 training steps: 0.030087901600342602\n","Training loss per 100 training steps: 0.03068783539657985\n","Training loss per 100 training steps: 0.03220364475150373\n","Training loss per 100 training steps: 0.03317226496175088\n","Training loss per 100 training steps: 0.03384613649650263\n","Training loss epoch: 0.034200323446010074\n","Training accuracy epoch: 0.9899649859943979\n","Validating model...\n","Validation Loss: 0.17416750704618536\n","Validation Accuracy: 0.9589263124604681\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0030691453721374273\n","Training loss per 100 training steps: 0.017003601602518396\n","Training loss per 100 training steps: 0.011820407670028323\n","Training loss per 100 training steps: 0.011464621017763795\n","Training loss per 100 training steps: 0.01240225137185472\n","Training loss per 100 training steps: 0.012048694756303885\n","Training loss per 100 training steps: 0.0127658638725575\n","Training loss per 100 training steps: 0.013863298138480676\n","Training loss epoch: 0.013962480636548018\n","Training accuracy epoch: 0.995579481792717\n","Validating model...\n","Validation Loss: 0.18803977197482405\n","Validation Accuracy: 0.9641544117647058\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 31.769542666666652 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1425687257128798\n","Validation Accuracy: 0.9555121527777778\n","Validation duration: 2.33370693333333 minutes\n","F1-score (test): 85.1%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.88      0.72      0.79      1170\n","        test       0.86      0.91      0.88      2464\n","   treatment       0.83      0.85      0.84      1244\n","\n","   micro avg       0.86      0.85      0.85      4878\n","   macro avg       0.86      0.82      0.84      4878\n","weighted avg       0.86      0.85      0.85      4878\n","\n","!!!!!! Starting model number 9 !!!!!!\n","Points in X_train after augmentation: 22841\n","Points in y_train after augmentation: 22841\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0597147941589355\n","Training loss per 100 training steps: 0.32868146350478183\n","Training loss per 100 training steps: 0.2510642179413073\n","Training loss per 100 training steps: 0.2176132320992624\n","Training loss per 100 training steps: 0.20197362523233317\n","Training loss per 100 training steps: 0.1873632670257486\n","Training loss per 100 training steps: 0.17549827395738435\n","Training loss per 100 training steps: 0.1664762646105996\n","Training loss epoch: 0.16584586877641933\n","Training accuracy epoch: 0.9478483893557422\n","Validating model...\n","Validation Loss: 0.137494993234035\n","Validation Accuracy: 0.9558527039848198\n","Training epoch: 2\n","Training loss per 100 training steps: 0.03533096984028816\n","Training loss per 100 training steps: 0.05908025260369229\n","Training loss per 100 training steps: 0.0574051628019012\n","Training loss per 100 training steps: 0.05780238997225226\n","Training loss per 100 training steps: 0.05870905202265336\n","Training loss per 100 training steps: 0.06050337713301003\n","Training loss per 100 training steps: 0.05992939140486489\n","Training loss per 100 training steps: 0.059865831327143015\n","Training loss epoch: 0.059926857544172485\n","Training accuracy epoch: 0.9817051820728291\n","Validating model...\n","Validation Loss: 0.13214115882703267\n","Validation Accuracy: 0.9604680581910183\n","Training epoch: 3\n","Training loss per 100 training steps: 0.01068221963942051\n","Training loss per 100 training steps: 0.03361333302385865\n","Training loss per 100 training steps: 0.03324604954655092\n","Training loss per 100 training steps: 0.03188120130471966\n","Training loss per 100 training steps: 0.03224325575894836\n","Training loss per 100 training steps: 0.034363691423979666\n","Training loss per 100 training steps: 0.03577571545586923\n","Training loss per 100 training steps: 0.034580545568300314\n","Training loss epoch: 0.03503172709984041\n","Training accuracy epoch: 0.9891894257703081\n","Validating model...\n","Validation Loss: 0.1537892745425993\n","Validation Accuracy: 0.9607843137254902\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0015813802601769567\n","Training loss per 100 training steps: 0.01678102891310118\n","Training loss per 100 training steps: 0.022418601143781143\n","Training loss per 100 training steps: 0.027713622187792775\n","Training loss per 100 training steps: 0.030447811536576413\n","Training loss per 100 training steps: 0.03009181472544241\n","Training loss per 100 training steps: 0.030054289517700367\n","Training loss per 100 training steps: 0.028922104972022165\n","Training loss epoch: 0.028533770495597927\n","Training accuracy epoch: 0.9915966386554622\n","Validating model...\n","Validation Loss: 0.18519219704937903\n","Validation Accuracy: 0.9641544117647058\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0004431613488122821\n","Training loss per 100 training steps: 0.026312853785411518\n","Training loss per 100 training steps: 0.027614491830686507\n","Training loss per 100 training steps: 0.024531427978109057\n","Training loss per 100 training steps: 0.02822314747008977\n","Training loss per 100 training steps: 0.028100644810929915\n","Training loss per 100 training steps: 0.028067420888454854\n","Training loss per 100 training steps: 0.028157814516710483\n","Training loss epoch: 0.028103896481860874\n","Training accuracy epoch: 0.9913340336134454\n","Validating model...\n","Validation Loss: 0.1783275425892926\n","Validation Accuracy: 0.9577008222643897\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0006992098060436547\n","Training loss per 100 training steps: 0.016154710516923725\n","Training loss per 100 training steps: 0.016187043503453593\n","Training loss per 100 training steps: 0.021523230496972474\n","Training loss per 100 training steps: 0.02025154031242463\n","Training loss per 100 training steps: 0.02128342868321463\n","Training loss per 100 training steps: 0.02139842395356478\n","Training loss per 100 training steps: 0.022542874000419096\n","Training loss epoch: 0.02253066020690129\n","Training accuracy epoch: 0.9933473389355743\n","Validating model...\n","Validation Loss: 0.21878125116642216\n","Validation Accuracy: 0.9540243516761544\n","Training epoch: 7\n","Training loss per 100 training steps: 0.054351478815078735\n","Training loss per 100 training steps: 0.017518913162132208\n","Training loss per 100 training steps: 0.01706179324617153\n","Training loss per 100 training steps: 0.015600620885041196\n","Training loss per 100 training steps: 0.014540421209729043\n","Training loss per 100 training steps: 0.014837253971066361\n","Training loss per 100 training steps: 0.014734040297191189\n","Training loss per 100 training steps: 0.01542981366560947\n","Training loss epoch: 0.015975748368094043\n","Training accuracy epoch: 0.9958420868347339\n","Validating model...\n","Validation Loss: 0.2348282680724486\n","Validation Accuracy: 0.9568014705882353\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 37.895714166666586 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14573007412777603\n","Validation Accuracy: 0.9562516075102881\n","Validation duration: 2.378177266666656 minutes\n","F1-score (test): 86.5%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.71      0.89      0.79      1170\n","        test       0.88      0.92      0.90      2464\n","   treatment       0.84      0.89      0.87      1244\n","\n","   micro avg       0.83      0.91      0.86      4878\n","   macro avg       0.81      0.90      0.85      4878\n","weighted avg       0.83      0.91      0.87      4878\n","\n","!!!!!! Starting model number 10 !!!!!!\n","Points in X_train after augmentation: 22841\n","Points in y_train after augmentation: 22841\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.4261229038238525\n","Training loss per 100 training steps: 0.35702568506545357\n","Training loss per 100 training steps: 0.2810263567562424\n","Training loss per 100 training steps: 0.23652029094871047\n","Training loss per 100 training steps: 0.21925525233832344\n","Training loss per 100 training steps: 0.2062926709702138\n","Training loss per 100 training steps: 0.1929778854615255\n","Training loss per 100 training steps: 0.18158338125728699\n","Training loss epoch: 0.17974401960026795\n","Training accuracy epoch: 0.9436151960784315\n","Validating model...\n","Validation Loss: 0.11939524477986875\n","Validation Accuracy: 0.9641445287792536\n","Training epoch: 2\n","Training loss per 100 training steps: 0.006911841221153736\n","Training loss per 100 training steps: 0.054059238661781396\n","Training loss per 100 training steps: 0.060050589977694094\n","Training loss per 100 training steps: 0.06031982392959136\n","Training loss per 100 training steps: 0.06149821997282822\n","Training loss per 100 training steps: 0.06419551456447026\n","Training loss per 100 training steps: 0.06482482574132044\n","Training loss per 100 training steps: 0.0634274663037113\n","Training loss epoch: 0.06305763880888206\n","Training accuracy epoch: 0.980905112044818\n","Validating model...\n","Validation Loss: 0.14400444528562764\n","Validation Accuracy: 0.9613871758380772\n","Training epoch: 3\n","Training loss per 100 training steps: 0.011105704121291637\n","Training loss per 100 training steps: 0.028713686248785494\n","Training loss per 100 training steps: 0.0264908373549891\n","Training loss per 100 training steps: 0.031837230943533225\n","Training loss per 100 training steps: 0.03241054396675737\n","Training loss per 100 training steps: 0.03406605457360977\n","Training loss per 100 training steps: 0.03251821786756418\n","Training loss per 100 training steps: 0.03487451183616307\n","Training loss epoch: 0.035318848779291326\n","Training accuracy epoch: 0.9897146358543417\n","Validating model...\n","Validation Loss: 0.1625830047916822\n","Validation Accuracy: 0.9586298228969007\n","Training epoch: 4\n","Training loss per 100 training steps: 0.08401431143283844\n","Training loss per 100 training steps: 0.022156955053024733\n","Training loss per 100 training steps: 0.03811113186749926\n","Training loss per 100 training steps: 0.03743725311513093\n","Training loss per 100 training steps: 0.03710803017506499\n","Training loss per 100 training steps: 0.035853579534139174\n","Training loss per 100 training steps: 0.034596617027201744\n","Training loss per 100 training steps: 0.0341192517377195\n","Training loss epoch: 0.03402238540157039\n","Training accuracy epoch: 0.9881827731092437\n","Validating model...\n","Validation Loss: 0.16602242268980297\n","Validation Accuracy: 0.9669018817204301\n","Training epoch: 5\n","Training loss per 100 training steps: 0.006416394375264645\n","Training loss per 100 training steps: 0.021231920504337407\n","Training loss per 100 training steps: 0.021993225338664345\n","Training loss per 100 training steps: 0.023068836526556537\n","Training loss per 100 training steps: 0.023382582254915386\n","Training loss per 100 training steps: 0.024943534182153407\n","Training loss per 100 training steps: 0.023484805062032203\n","Training loss per 100 training steps: 0.023888575911496835\n","Training loss epoch: 0.02416104223080327\n","Training accuracy epoch: 0.9923406862745098\n","Validating model...\n","Validation Loss: 0.19630522280075477\n","Validation Accuracy: 0.9577008222643897\n","Training epoch: 6\n","Training loss per 100 training steps: 0.09836232662200928\n","Training loss per 100 training steps: 0.02544222409274466\n","Training loss per 100 training steps: 0.02495088823853797\n","Training loss per 100 training steps: 0.02422258102300614\n","Training loss per 100 training steps: 0.02519512987407354\n","Training loss per 100 training steps: 0.028112236454122294\n","Training loss per 100 training steps: 0.027837341857468556\n","Training loss per 100 training steps: 0.025871730162283824\n","Training loss epoch: 0.02577201846853474\n","Training accuracy epoch: 0.9928221288515406\n","Validating model...\n","Validation Loss: 0.18020956320020454\n","Validation Accuracy: 0.9650537634408602\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 31.7655341166667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.12496433571343207\n","Validation Accuracy: 0.9621109825102881\n","Validation duration: 2.324470033333273 minutes\n","F1-score (test): 87.3%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.78      0.86      0.82      1170\n","        test       0.90      0.91      0.91      2464\n","   treatment       0.90      0.82      0.86      1244\n","\n","   micro avg       0.87      0.87      0.87      4878\n","   macro avg       0.86      0.86      0.86      4878\n","weighted avg       0.87      0.87      0.87      4878\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0.75\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":26992357,"status":"ok","timestamp":1657464789533,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"1tBh5gOBHpN1","outputId":"9276520f-f4a7-44a8-acba-e16562935dda"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 100% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 26104\n","Points in y_train after augmentation: 26104\n","Device:  cuda\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c0e6b8eb256c4a89b64dcca543775583","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/422M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1495108604431152\n","Training loss per 100 training steps: 0.3183393379728688\n","Training loss per 100 training steps: 0.2590383980423212\n","Training loss per 100 training steps: 0.2258802483405955\n","Training loss per 100 training steps: 0.2082952411829069\n","Training loss per 100 training steps: 0.19269920793360104\n","Training loss per 100 training steps: 0.18176020235489565\n","Training loss per 100 training steps: 0.17268022409468867\n","Training loss per 100 training steps: 0.16676938969969804\n","Training loss epoch: 0.16610650205471114\n","Training accuracy epoch: 0.9476613562091503\n","Validating model...\n","Validation Loss: 0.14147221747621455\n","Validation Accuracy: 0.9570979601518027\n","Training epoch: 2\n","Training loss per 100 training steps: 0.01717899553477764\n","Training loss per 100 training steps: 0.07333351746846986\n","Training loss per 100 training steps: 0.0656317974804479\n","Training loss per 100 training steps: 0.058446426008382436\n","Training loss per 100 training steps: 0.05901168977802252\n","Training loss per 100 training steps: 0.058580162126906477\n","Training loss per 100 training steps: 0.05784997085995349\n","Training loss per 100 training steps: 0.06100204177079563\n","Training loss per 100 training steps: 0.06096028528135844\n","Training loss epoch: 0.06043395789817498\n","Training accuracy epoch: 0.9805836397058824\n","Validating model...\n","Validation Loss: 0.14952191673493123\n","Validation Accuracy: 0.9592524509803921\n","Training epoch: 3\n","Training loss per 100 training steps: 0.007000788580626249\n","Training loss per 100 training steps: 0.03679262040445747\n","Training loss per 100 training steps: 0.03558106011009094\n","Training loss per 100 training steps: 0.040391823602337514\n","Training loss per 100 training steps: 0.03892729395319431\n","Training loss per 100 training steps: 0.03593995979323796\n","Training loss per 100 training steps: 0.037048670290505396\n","Training loss per 100 training steps: 0.03722671361301063\n","Training loss per 100 training steps: 0.03838814622409001\n","Training loss epoch: 0.038262578577814566\n","Training accuracy epoch: 0.987515318627451\n","Validating model...\n","Validation Loss: 0.17338270675927384\n","Validation Accuracy: 0.9546469797596459\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0014147106558084488\n","Training loss per 100 training steps: 0.016717302457067543\n","Training loss per 100 training steps: 0.024411303670155995\n","Training loss per 100 training steps: 0.02540029712635142\n","Training loss per 100 training steps: 0.02431098228307996\n","Training loss per 100 training steps: 0.025785840307620305\n","Training loss per 100 training steps: 0.02594926800590842\n","Training loss per 100 training steps: 0.02691352570077541\n","Training loss per 100 training steps: 0.027533043627898976\n","Training loss epoch: 0.027941563303744154\n","Training accuracy epoch: 0.9916896446078431\n","Validating model...\n","Validation Loss: 0.17225796577415667\n","Validation Accuracy: 0.9604581752055661\n","Training epoch: 5\n","Training loss per 100 training steps: 0.001765072112902999\n","Training loss per 100 training steps: 0.016568038412623366\n","Training loss per 100 training steps: 0.014490666197912897\n","Training loss per 100 training steps: 0.016127728637926896\n","Training loss per 100 training steps: 0.017690197761547826\n","Training loss per 100 training steps: 0.01839665146588435\n","Training loss per 100 training steps: 0.021321918297062273\n","Training loss per 100 training steps: 0.021554449612777377\n","Training loss per 100 training steps: 0.020973666241646035\n","Training loss epoch: 0.020962462843013497\n","Training accuracy epoch: 0.9932598039215687\n","Validating model...\n","Validation Loss: 0.22002242731076538\n","Validation Accuracy: 0.956465449082859\n","Training epoch: 6\n","Training loss per 100 training steps: 0.03682326152920723\n","Training loss per 100 training steps: 0.012898713102265109\n","Training loss per 100 training steps: 0.014455662958543464\n","Training loss per 100 training steps: 0.015460211242761066\n","Training loss per 100 training steps: 0.014866779133379332\n","Training loss per 100 training steps: 0.01704967011224261\n","Training loss per 100 training steps: 0.018504382845870693\n","Training loss per 100 training steps: 0.019744549014126634\n","Training loss per 100 training steps: 0.022180126650394354\n","Training loss epoch: 0.02218365014678235\n","Training accuracy epoch: 0.9932215073529411\n","Validating model...\n","Validation Loss: 0.21380405244360423\n","Validation Accuracy: 0.954330724225174\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 35.6091499 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13985946177018815\n","Validation Accuracy: 0.9558376736111112\n","Validation duration: 2.2968572333333364 minutes\n","F1-score (test): 85.8%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.86      0.81      0.84      1170\n","        test       0.83      0.93      0.88      2464\n","   treatment       0.77      0.91      0.84      1244\n","\n","   micro avg       0.82      0.90      0.86      4878\n","   macro avg       0.82      0.89      0.85      4878\n","weighted avg       0.82      0.90      0.86      4878\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 26104\n","Points in y_train after augmentation: 26104\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0774667263031006\n","Training loss per 100 training steps: 0.3308149914413986\n","Training loss per 100 training steps: 0.2608447198139791\n","Training loss per 100 training steps: 0.22141915681057198\n","Training loss per 100 training steps: 0.20468452629259326\n","Training loss per 100 training steps: 0.19075429264851984\n","Training loss per 100 training steps: 0.17993696416362487\n","Training loss per 100 training steps: 0.16906201404641608\n","Training loss per 100 training steps: 0.1628966161345519\n","Training loss epoch: 0.16192810217562867\n","Training accuracy epoch: 0.9495761846405228\n","Validating model...\n","Validation Loss: 0.1495094913749627\n","Validation Accuracy: 0.9574043327008223\n","Training epoch: 2\n","Training loss per 100 training steps: 0.027001984417438507\n","Training loss per 100 training steps: 0.04929759923834354\n","Training loss per 100 training steps: 0.056539500021579585\n","Training loss per 100 training steps: 0.05509011811372573\n","Training loss per 100 training steps: 0.05734729552420873\n","Training loss per 100 training steps: 0.057759280274241064\n","Training loss per 100 training steps: 0.0586648611018679\n","Training loss per 100 training steps: 0.05881713411107144\n","Training loss per 100 training steps: 0.059207962897909076\n","Training loss epoch: 0.05872607410920489\n","Training accuracy epoch: 0.9821537990196079\n","Validating model...\n","Validation Loss: 0.16271710948500434\n","Validation Accuracy: 0.9595588235294118\n","Training epoch: 3\n","Training loss per 100 training steps: 0.00286427466198802\n","Training loss per 100 training steps: 0.032266669981884724\n","Training loss per 100 training steps: 0.04033605047499886\n","Training loss per 100 training steps: 0.03713033242088099\n","Training loss per 100 training steps: 0.03707673397207542\n","Training loss per 100 training steps: 0.037484741891200324\n","Training loss per 100 training steps: 0.03880680776130487\n","Training loss per 100 training steps: 0.03811852020534857\n","Training loss per 100 training steps: 0.03739338273951492\n","Training loss epoch: 0.03797124024073556\n","Training accuracy epoch: 0.989468443627451\n","Validating model...\n","Validation Loss: 0.16712199064318603\n","Validation Accuracy: 0.9632155281467426\n","Training epoch: 4\n","Training loss per 100 training steps: 0.010341472923755646\n","Training loss per 100 training steps: 0.023121598250138122\n","Training loss per 100 training steps: 0.018626339470362987\n","Training loss per 100 training steps: 0.021468491031942222\n","Training loss per 100 training steps: 0.02127533851619903\n","Training loss per 100 training steps: 0.023305582281219737\n","Training loss per 100 training steps: 0.024591323296694834\n","Training loss per 100 training steps: 0.02405917834802833\n","Training loss per 100 training steps: 0.024502453454785408\n","Training loss epoch: 0.02463852555787276\n","Training accuracy epoch: 0.9923662173202615\n","Validating model...\n","Validation Loss: 0.1696543782548842\n","Validation Accuracy: 0.9598553130929791\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0015061241574585438\n","Training loss per 100 training steps: 0.0148972139799262\n","Training loss per 100 training steps: 0.017378860116624668\n","Training loss per 100 training steps: 0.023589760555976235\n","Training loss per 100 training steps: 0.025574282467022116\n","Training loss per 100 training steps: 0.02721778458564546\n","Training loss per 100 training steps: 0.024932476166749457\n","Training loss per 100 training steps: 0.024666848678214736\n","Training loss per 100 training steps: 0.024489874276485163\n","Training loss epoch: 0.02460276246147616\n","Training accuracy epoch: 0.9932470383986929\n","Validating model...\n","Validation Loss: 0.18727344001344332\n","Validation Accuracy: 0.9598553130929791\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0005256042932160199\n","Training loss per 100 training steps: 0.026002666284070847\n","Training loss per 100 training steps: 0.02585997189018952\n","Training loss per 100 training steps: 0.023496852967999506\n","Training loss per 100 training steps: 0.022180792115840068\n","Training loss per 100 training steps: 0.02202478065429638\n","Training loss per 100 training steps: 0.020544644990502414\n","Training loss per 100 training steps: 0.020942702338555923\n","Training loss per 100 training steps: 0.020288666156585314\n","Training loss epoch: 0.020116668675057677\n","Training accuracy epoch: 0.9940640318627451\n","Validating model...\n","Validation Loss: 0.22639413274369943\n","Validation Accuracy: 0.9561689595192916\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 35.63502346666666 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13858442395010367\n","Validation Accuracy: 0.9580801504629629\n","Validation duration: 2.2773761166666646 minutes\n","F1-score (test): 85.4%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.86      0.77      0.81      1170\n","        test       0.87      0.89      0.88      2464\n","   treatment       0.90      0.80      0.85      1244\n","\n","   micro avg       0.87      0.83      0.85      4878\n","   macro avg       0.88      0.82      0.84      4878\n","weighted avg       0.87      0.83      0.85      4878\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 26104\n","Points in y_train after augmentation: 26104\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9635412693023682\n","Training loss per 100 training steps: 0.3525109660286124\n","Training loss per 100 training steps: 0.26011025165184515\n","Training loss per 100 training steps: 0.23097163179202432\n","Training loss per 100 training steps: 0.20650061027859884\n","Training loss per 100 training steps: 0.18925374128229305\n","Training loss per 100 training steps: 0.1785363771312695\n","Training loss per 100 training steps: 0.16894939539624582\n","Training loss per 100 training steps: 0.161531599125733\n","Training loss epoch: 0.1605806769412262\n","Training accuracy epoch: 0.9496017156862745\n","Validating model...\n","Validation Loss: 0.13498549719395883\n","Validation Accuracy: 0.9583234503478811\n","Training epoch: 2\n","Training loss per 100 training steps: 0.020131658762693405\n","Training loss per 100 training steps: 0.05510005271546358\n","Training loss per 100 training steps: 0.05079402586020094\n","Training loss per 100 training steps: 0.05055446501324677\n","Training loss per 100 training steps: 0.05146352167443333\n","Training loss per 100 training steps: 0.049358635764042036\n","Training loss per 100 training steps: 0.05094913340949635\n","Training loss per 100 training steps: 0.05443881252873888\n","Training loss per 100 training steps: 0.05419574607651711\n","Training loss epoch: 0.05452911160119031\n","Training accuracy epoch: 0.9829069648692811\n","Validating model...\n","Validation Loss: 0.1452939152345518\n","Validation Accuracy: 0.9622964104996837\n","Training epoch: 3\n","Training loss per 100 training steps: 0.08889832347631454\n","Training loss per 100 training steps: 0.030803111652696117\n","Training loss per 100 training steps: 0.031648659228841865\n","Training loss per 100 training steps: 0.030235820033056103\n","Training loss per 100 training steps: 0.02935314391621509\n","Training loss per 100 training steps: 0.03207865246450073\n","Training loss per 100 training steps: 0.032666911455894045\n","Training loss per 100 training steps: 0.03131118299536369\n","Training loss per 100 training steps: 0.032527792489177344\n","Training loss epoch: 0.03216776998024394\n","Training accuracy epoch: 0.990234375\n","Validating model...\n","Validation Loss: 0.1591217783082838\n","Validation Accuracy: 0.9619999209361164\n","Training epoch: 4\n","Training loss per 100 training steps: 0.010336358100175858\n","Training loss per 100 training steps: 0.017545478947237042\n","Training loss per 100 training steps: 0.02213973837300257\n","Training loss per 100 training steps: 0.022008982490648768\n","Training loss per 100 training steps: 0.02670069183519794\n","Training loss per 100 training steps: 0.027403950813999482\n","Training loss per 100 training steps: 0.02581489588923426\n","Training loss per 100 training steps: 0.02696778997905521\n","Training loss per 100 training steps: 0.02760675181245583\n","Training loss epoch: 0.02778046764156969\n","Training accuracy epoch: 0.9914088031045752\n","Validating model...\n","Validation Loss: 0.16048696300447987\n","Validation Accuracy: 0.9622865275142315\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0007536499761044979\n","Training loss per 100 training steps: 0.012373206367466073\n","Training loss per 100 training steps: 0.014832789281357672\n","Training loss per 100 training steps: 0.013717702008239257\n","Training loss per 100 training steps: 0.013188497215185209\n","Training loss per 100 training steps: 0.01811944150422151\n","Training loss per 100 training steps: 0.020958888508296795\n","Training loss per 100 training steps: 0.0225821390958404\n","Training loss per 100 training steps: 0.023204583796175942\n","Training loss epoch: 0.023115088958035154\n","Training accuracy epoch: 0.9928768382352942\n","Validating model...\n","Validation Loss: 0.1720749675467446\n","Validation Accuracy: 0.9632352941176471\n","Training epoch: 6\n","Training loss per 100 training steps: 0.01852409355342388\n","Training loss per 100 training steps: 0.01710248111382975\n","Training loss per 100 training steps: 0.015117306818123398\n","Training loss per 100 training steps: 0.02047232908082749\n","Training loss per 100 training steps: 0.02038903127396041\n","Training loss per 100 training steps: 0.020159820426189124\n","Training loss per 100 training steps: 0.019198460475502523\n","Training loss per 100 training steps: 0.01954902180107517\n","Training loss per 100 training steps: 0.01864435642804774\n","Training loss epoch: 0.01894581683967433\n","Training accuracy epoch: 0.9943321078431373\n","Validating model...\n","Validation Loss: 0.20153664593361134\n","Validation Accuracy: 0.95739444971537\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 35.818829099999995 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14659805139321921\n","Validation Accuracy: 0.9514612268518519\n","Validation duration: 2.287852449999991 minutes\n","F1-score (test): 84.0%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.63      0.91      0.74      1170\n","        test       0.90      0.88      0.89      2464\n","   treatment       0.87      0.84      0.86      1244\n","\n","   micro avg       0.81      0.88      0.84      4878\n","   macro avg       0.80      0.88      0.83      4878\n","weighted avg       0.83      0.88      0.85      4878\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 26104\n","Points in y_train after augmentation: 26104\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.5533101558685303\n","Training loss per 100 training steps: 0.35212393481247495\n","Training loss per 100 training steps: 0.26320473378551984\n","Training loss per 100 training steps: 0.22858264756101213\n","Training loss per 100 training steps: 0.2140126498578641\n","Training loss per 100 training steps: 0.20033468428567913\n","Training loss per 100 training steps: 0.1914775689770181\n","Training loss per 100 training steps: 0.1807355515289515\n","Training loss per 100 training steps: 0.1736598467942939\n","Training loss epoch: 0.17206518687653086\n","Training accuracy epoch: 0.945452920751634\n","Validating model...\n","Validation Loss: 0.1415981634784782\n","Validation Accuracy: 0.9573845667299178\n","Training epoch: 2\n","Training loss per 100 training steps: 0.039122410118579865\n","Training loss per 100 training steps: 0.061610592643287734\n","Training loss per 100 training steps: 0.05759717132699264\n","Training loss per 100 training steps: 0.06476874316754778\n","Training loss per 100 training steps: 0.06246766065650311\n","Training loss per 100 training steps: 0.06239210570950485\n","Training loss per 100 training steps: 0.06156306972761271\n","Training loss per 100 training steps: 0.06345786537112172\n","Training loss per 100 training steps: 0.06341896449188386\n","Training loss epoch: 0.06328099849534007\n","Training accuracy epoch: 0.9808517156862745\n","Validating model...\n","Validation Loss: 0.13841930608602934\n","Validation Accuracy: 0.9641544117647058\n","Training epoch: 3\n","Training loss per 100 training steps: 0.009991997852921486\n","Training loss per 100 training steps: 0.030670381083134746\n","Training loss per 100 training steps: 0.030829553853776028\n","Training loss per 100 training steps: 0.028803821820498867\n","Training loss per 100 training steps: 0.03168050803531813\n","Training loss per 100 training steps: 0.032536033346067215\n","Training loss per 100 training steps: 0.03445150800900241\n","Training loss per 100 training steps: 0.037402667982672166\n","Training loss per 100 training steps: 0.037877767049257216\n","Training loss epoch: 0.03779586871168445\n","Training accuracy epoch: 0.9885493259803921\n","Validating model...\n","Validation Loss: 0.1795232987993479\n","Validation Accuracy: 0.9598553130929791\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0607466995716095\n","Training loss per 100 training steps: 0.025031539412690235\n","Training loss per 100 training steps: 0.024592023953159493\n","Training loss per 100 training steps: 0.024403503092082814\n","Training loss per 100 training steps: 0.022185652944956967\n","Training loss per 100 training steps: 0.02511138704277416\n","Training loss per 100 training steps: 0.025936719533357227\n","Training loss per 100 training steps: 0.027418082131808737\n","Training loss per 100 training steps: 0.027024397883821046\n","Training loss epoch: 0.027438088667069822\n","Training accuracy epoch: 0.9922257965686274\n","Validating model...\n","Validation Loss: 0.1597764168063626\n","Validation Accuracy: 0.9632254111321948\n","Training epoch: 5\n","Training loss per 100 training steps: 0.009680657647550106\n","Training loss per 100 training steps: 0.010245257623189378\n","Training loss per 100 training steps: 0.014685837353292427\n","Training loss per 100 training steps: 0.01915322801800587\n","Training loss per 100 training steps: 0.018759012940450643\n","Training loss per 100 training steps: 0.020907505614459497\n","Training loss per 100 training steps: 0.022330552412725028\n","Training loss per 100 training steps: 0.023059568841904788\n","Training loss per 100 training steps: 0.022854409710845368\n","Training loss epoch: 0.02275332868535485\n","Training accuracy epoch: 0.992953431372549\n","Validating model...\n","Validation Loss: 0.20648289165261552\n","Validation Accuracy: 0.9589361954459203\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0027758809737861156\n","Training loss per 100 training steps: 0.021118484429829516\n","Training loss per 100 training steps: 0.02148751490928241\n","Training loss per 100 training steps: 0.02167388338597466\n","Training loss per 100 training steps: 0.021993096578074998\n","Training loss per 100 training steps: 0.020834919270721126\n","Training loss per 100 training steps: 0.022729156726505703\n","Training loss per 100 training steps: 0.02335180148481534\n","Training loss per 100 training steps: 0.0240736481465091\n","Training loss epoch: 0.02387184131407148\n","Training accuracy epoch: 0.9931832107843137\n","Validating model...\n","Validation Loss: 0.1890942933992026\n","Validation Accuracy: 0.9570880771663505\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0015091693494468927\n","Training loss per 100 training steps: 0.011325034485942001\n","Training loss per 100 training steps: 0.011399835013616216\n","Training loss per 100 training steps: 0.015352851548604397\n","Training loss per 100 training steps: 0.014379165363890679\n","Training loss per 100 training steps: 0.013401569836624149\n","Training loss per 100 training steps: 0.012521806083572234\n","Training loss per 100 training steps: 0.014230402627834548\n","Training loss per 100 training steps: 0.015735734123708642\n","Training loss epoch: 0.016649564016728725\n","Training accuracy epoch: 0.9948554942810458\n","Validating model...\n","Validation Loss: 0.17847356945247728\n","Validation Accuracy: 0.960171568627451\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 41.6565769 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.12705111583831982\n","Validation Accuracy: 0.9648959940843622\n","Validation duration: 2.2852896166666747 minutes\n","F1-score (test): 88.4%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.89      0.82      0.85      1170\n","        test       0.92      0.89      0.90      2464\n","   treatment       0.87      0.89      0.88      1244\n","\n","   micro avg       0.90      0.87      0.88      4878\n","   macro avg       0.89      0.86      0.88      4878\n","weighted avg       0.90      0.87      0.88      4878\n","\n","!!!!!! Starting model number 5 !!!!!!\n","Points in X_train after augmentation: 26104\n","Points in y_train after augmentation: 26104\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.154238224029541\n","Training loss per 100 training steps: 0.3076370672534893\n","Training loss per 100 training steps: 0.2519644657798593\n","Training loss per 100 training steps: 0.22546617824667786\n","Training loss per 100 training steps: 0.20383183669677454\n","Training loss per 100 training steps: 0.18885302880988966\n","Training loss per 100 training steps: 0.18021787120263322\n","Training loss per 100 training steps: 0.1695708800117205\n","Training loss per 100 training steps: 0.1640654051482803\n","Training loss epoch: 0.16331753170194205\n","Training accuracy epoch: 0.9491421568627451\n","Validating model...\n","Validation Loss: 0.1417437733114496\n","Validation Accuracy: 0.9616737824161923\n","Training epoch: 2\n","Training loss per 100 training steps: 0.035189613699913025\n","Training loss per 100 training steps: 0.04283703329032379\n","Training loss per 100 training steps: 0.05144696529903704\n","Training loss per 100 training steps: 0.05683328852094586\n","Training loss per 100 training steps: 0.0578341706714853\n","Training loss per 100 training steps: 0.05886746823897831\n","Training loss per 100 training steps: 0.05836441302180024\n","Training loss per 100 training steps: 0.059217911161490305\n","Training loss per 100 training steps: 0.05919229754272351\n","Training loss epoch: 0.06044580434664728\n","Training accuracy epoch: 0.9812219158496732\n","Validating model...\n","Validation Loss: 0.12687932976233937\n","Validation Accuracy: 0.9625929000632512\n","Training epoch: 3\n","Training loss per 100 training steps: 0.004442078992724419\n","Training loss per 100 training steps: 0.02531462749247301\n","Training loss per 100 training steps: 0.0263065505336706\n","Training loss per 100 training steps: 0.031086642607819116\n","Training loss per 100 training steps: 0.03386087978169893\n","Training loss per 100 training steps: 0.0347428037019348\n","Training loss per 100 training steps: 0.03642549991123215\n","Training loss per 100 training steps: 0.036261550314017316\n","Training loss per 100 training steps: 0.03955697850102574\n","Training loss epoch: 0.039853835397212496\n","Training accuracy epoch: 0.9879365808823529\n","Validating model...\n","Validation Loss: 0.17827964766412133\n","Validation Accuracy: 0.956791587602783\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0029743812046945095\n","Training loss per 100 training steps: 0.020981711679827514\n","Training loss per 100 training steps: 0.02414488861993516\n","Training loss per 100 training steps: 0.024306683576792675\n","Training loss per 100 training steps: 0.0234577963732536\n","Training loss per 100 training steps: 0.02395522823942288\n","Training loss per 100 training steps: 0.025289124995450676\n","Training loss per 100 training steps: 0.027525178444343944\n","Training loss per 100 training steps: 0.027891731110372964\n","Training loss epoch: 0.027834656033234092\n","Training accuracy epoch: 0.9917151756535948\n","Validating model...\n","Validation Loss: 0.19016660632869212\n","Validation Accuracy: 0.9570880771663505\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0007698361878283322\n","Training loss per 100 training steps: 0.016705031236426186\n","Training loss per 100 training steps: 0.01737662604889793\n","Training loss per 100 training steps: 0.01950824118861921\n","Training loss per 100 training steps: 0.025252484612579416\n","Training loss per 100 training steps: 0.025320848152316788\n","Training loss per 100 training steps: 0.02704029798596503\n","Training loss per 100 training steps: 0.028103191074286653\n","Training loss per 100 training steps: 0.028910083074183565\n","Training loss epoch: 0.028828789164435875\n","Training accuracy epoch: 0.9915364583333334\n","Validating model...\n","Validation Loss: 0.19410084784441792\n","Validation Accuracy: 0.9555463314358001\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0004907383699901402\n","Training loss per 100 training steps: 0.015188964568830607\n","Training loss per 100 training steps: 0.018717842918378476\n","Training loss per 100 training steps: 0.022426172069714218\n","Training loss per 100 training steps: 0.022116325043360013\n","Training loss per 100 training steps: 0.022305539483085397\n","Training loss per 100 training steps: 0.023735756401430035\n","Training loss per 100 training steps: 0.02352424151085896\n","Training loss per 100 training steps: 0.0230174066424699\n","Training loss epoch: 0.022928366592997705\n","Training accuracy epoch: 0.9923023897058824\n","Validating model...\n","Validation Loss: 0.17205409847191927\n","Validation Accuracy: 0.9616935483870968\n","Training epoch: 7\n","Training loss per 100 training steps: 0.005825594067573547\n","Training loss per 100 training steps: 0.01595450106891227\n","Training loss per 100 training steps: 0.014916667800723338\n","Training loss per 100 training steps: 0.015636521107300596\n","Training loss per 100 training steps: 0.01751263044648827\n","Training loss per 100 training steps: 0.01738760093303245\n","Training loss per 100 training steps: 0.018001378803228135\n","Training loss per 100 training steps: 0.01739522968121838\n","Training loss per 100 training steps: 0.016090956740946794\n","Training loss epoch: 0.016120927037076505\n","Training accuracy epoch: 0.9951235702614379\n","Validating model...\n","Validation Loss: 0.2202044565682288\n","Validation Accuracy: 0.9616935483870968\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 43.24466748333331 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13528473380413036\n","Validation Accuracy: 0.9592375578703703\n","Validation duration: 2.430258616666682 minutes\n","F1-score (test): 86.7%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.83      0.83      0.83      1170\n","        test       0.86      0.92      0.89      2464\n","   treatment       0.82      0.89      0.85      1244\n","\n","   micro avg       0.85      0.89      0.87      4878\n","   macro avg       0.84      0.88      0.86      4878\n","weighted avg       0.85      0.89      0.87      4878\n","\n","!!!!!! Starting model number 6 !!!!!!\n","Points in X_train after augmentation: 26104\n","Points in y_train after augmentation: 26104\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.162414312362671\n","Training loss per 100 training steps: 0.3434683360196281\n","Training loss per 100 training steps: 0.2732263617495547\n","Training loss per 100 training steps: 0.24173070088127918\n","Training loss per 100 training steps: 0.2146009213553551\n","Training loss per 100 training steps: 0.19707396967585633\n","Training loss per 100 training steps: 0.18443889994818885\n","Training loss per 100 training steps: 0.172565632390148\n","Training loss per 100 training steps: 0.16452858280030064\n","Training loss epoch: 0.16353565231981396\n","Training accuracy epoch: 0.9487208946078431\n","Validating model...\n","Validation Loss: 0.12866554713314948\n","Validation Accuracy: 0.962306293485136\n","Training epoch: 2\n","Training loss per 100 training steps: 0.025983156636357307\n","Training loss per 100 training steps: 0.06267795593035178\n","Training loss per 100 training steps: 0.0505913077536229\n","Training loss per 100 training steps: 0.05937249259636474\n","Training loss per 100 training steps: 0.0621951969228383\n","Training loss per 100 training steps: 0.06096611320489122\n","Training loss per 100 training steps: 0.06281821275174078\n","Training loss per 100 training steps: 0.062165772305624145\n","Training loss per 100 training steps: 0.06217346916702773\n","Training loss epoch: 0.06172213505238224\n","Training accuracy epoch: 0.9812729779411765\n","Validating model...\n","Validation Loss: 0.1478275470983456\n","Validation Accuracy: 0.964441018342821\n","Training epoch: 3\n","Training loss per 100 training steps: 0.012590227648615837\n","Training loss per 100 training steps: 0.030748663022929786\n","Training loss per 100 training steps: 0.03518750923552518\n","Training loss per 100 training steps: 0.03570329257821977\n","Training loss per 100 training steps: 0.03376379742499318\n","Training loss per 100 training steps: 0.03344954221247753\n","Training loss per 100 training steps: 0.03527696846131841\n","Training loss per 100 training steps: 0.035400620732754046\n","Training loss per 100 training steps: 0.034137196732541376\n","Training loss epoch: 0.033972655399731023\n","Training accuracy epoch: 0.9897620506535948\n","Validating model...\n","Validation Loss: 0.18070968161548223\n","Validation Accuracy: 0.9592524509803921\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0018445058958604932\n","Training loss per 100 training steps: 0.028049674677249913\n","Training loss per 100 training steps: 0.022467941641376065\n","Training loss per 100 training steps: 0.031985220887113835\n","Training loss per 100 training steps: 0.030912659882500762\n","Training loss per 100 training steps: 0.030230996927680744\n","Training loss per 100 training steps: 0.03009927266634464\n","Training loss per 100 training steps: 0.029320957904158274\n","Training loss per 100 training steps: 0.029487632666241416\n","Training loss epoch: 0.02988341996133029\n","Training accuracy epoch: 0.9913832720588235\n","Validating model...\n","Validation Loss: 0.15272261448605123\n","Validation Accuracy: 0.9619900379506642\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0035567430313676596\n","Training loss per 100 training steps: 0.01363265964647497\n","Training loss per 100 training steps: 0.017257811254384435\n","Training loss per 100 training steps: 0.018601227684793113\n","Training loss per 100 training steps: 0.020980967649836684\n","Training loss per 100 training steps: 0.02453188314306491\n","Training loss per 100 training steps: 0.0240027517127861\n","Training loss per 100 training steps: 0.02384507762394897\n","Training loss per 100 training steps: 0.024525777673293267\n","Training loss epoch: 0.02435163324683826\n","Training accuracy epoch: 0.9928002450980392\n","Validating model...\n","Validation Loss: 0.1672309573066955\n","Validation Accuracy: 0.964441018342821\n","Training epoch: 6\n","Training loss per 100 training steps: 0.003266529180109501\n","Training loss per 100 training steps: 0.014201259986978108\n","Training loss per 100 training steps: 0.015930819592730544\n","Training loss per 100 training steps: 0.014131841624294489\n","Training loss per 100 training steps: 0.012672783650133145\n","Training loss per 100 training steps: 0.016718277907007823\n","Training loss per 100 training steps: 0.019434738071921465\n","Training loss per 100 training steps: 0.019293540533630877\n","Training loss per 100 training steps: 0.02017906317088771\n","Training loss epoch: 0.020094233753030388\n","Training accuracy epoch: 0.9944725285947713\n","Validating model...\n","Validation Loss: 0.1815681395083255\n","Validation Accuracy: 0.9656763915243517\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 36.47219571666665 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13102952915586583\n","Validation Accuracy: 0.9576822916666666\n","Validation duration: 2.3724224333333344 minutes\n","F1-score (test): 86.3%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.80      0.84      0.82      1170\n","        test       0.85      0.92      0.88      2464\n","   treatment       0.90      0.83      0.86      1244\n","\n","   micro avg       0.85      0.88      0.86      4878\n","   macro avg       0.85      0.86      0.85      4878\n","weighted avg       0.85      0.88      0.86      4878\n","\n","!!!!!! Starting model number 7 !!!!!!\n","Points in X_train after augmentation: 26104\n","Points in y_train after augmentation: 26104\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9947845935821533\n","Training loss per 100 training steps: 0.3466285452394202\n","Training loss per 100 training steps: 0.2779206781977074\n","Training loss per 100 training steps: 0.23598320656873756\n","Training loss per 100 training steps: 0.21212178678658242\n","Training loss per 100 training steps: 0.19701176825185826\n","Training loss per 100 training steps: 0.1832987187777378\n","Training loss per 100 training steps: 0.17521806856778088\n","Training loss per 100 training steps: 0.16659780760637524\n","Training loss epoch: 0.16516583896665515\n","Training accuracy epoch: 0.9477124183006537\n","Validating model...\n","Validation Loss: 0.1299786400734721\n","Validation Accuracy: 0.9586199399114484\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04670148715376854\n","Training loss per 100 training steps: 0.05355901165005502\n","Training loss per 100 training steps: 0.05507817177017409\n","Training loss per 100 training steps: 0.05615408925793638\n","Training loss per 100 training steps: 0.05942917358611555\n","Training loss per 100 training steps: 0.06122409029268453\n","Training loss per 100 training steps: 0.06104639805835933\n","Training loss per 100 training steps: 0.06088244012100609\n","Training loss per 100 training steps: 0.06101754063289245\n","Training loss epoch: 0.06102898411236489\n","Training accuracy epoch: 0.9809921364379085\n","Validating model...\n","Validation Loss: 0.13131103820313572\n","Validation Accuracy: 0.969026723592663\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0067093526013195515\n","Training loss per 100 training steps: 0.02157048829243343\n","Training loss per 100 training steps: 0.029973642904495598\n","Training loss per 100 training steps: 0.028294673605193152\n","Training loss per 100 training steps: 0.03132326411441296\n","Training loss per 100 training steps: 0.034098866812226285\n","Training loss per 100 training steps: 0.038100454832952914\n","Training loss per 100 training steps: 0.04050215418956551\n","Training loss per 100 training steps: 0.04037987526213912\n","Training loss epoch: 0.0401456015355792\n","Training accuracy epoch: 0.9880514705882353\n","Validating model...\n","Validation Loss: 0.14795905248534194\n","Validation Accuracy: 0.9656763915243517\n","Training epoch: 4\n","Training loss per 100 training steps: 0.001342380535788834\n","Training loss per 100 training steps: 0.023748173700855343\n","Training loss per 100 training steps: 0.019560902416013964\n","Training loss per 100 training steps: 0.024204077717700764\n","Training loss per 100 training steps: 0.023084038095190215\n","Training loss per 100 training steps: 0.02210018825807893\n","Training loss per 100 training steps: 0.023776053300204093\n","Training loss per 100 training steps: 0.024369194685002708\n","Training loss per 100 training steps: 0.025272023732214845\n","Training loss epoch: 0.025062985764634504\n","Training accuracy epoch: 0.9918811274509803\n","Validating model...\n","Validation Loss: 0.17196169355755794\n","Validation Accuracy: 0.9613871758380772\n","Training epoch: 5\n","Training loss per 100 training steps: 0.010828934609889984\n","Training loss per 100 training steps: 0.005788517326040489\n","Training loss per 100 training steps: 0.014675923047149415\n","Training loss per 100 training steps: 0.014821858380351098\n","Training loss per 100 training steps: 0.01776787464509392\n","Training loss per 100 training steps: 0.019201628335556636\n","Training loss per 100 training steps: 0.018328679660225743\n","Training loss per 100 training steps: 0.018158833019235456\n","Training loss per 100 training steps: 0.018869575233324856\n","Training loss epoch: 0.01960214646418999\n","Training accuracy epoch: 0.9944342320261438\n","Validating model...\n","Validation Loss: 0.19894709210505016\n","Validation Accuracy: 0.9552399588867806\n","Training epoch: 6\n","Training loss per 100 training steps: 0.010920500382781029\n","Training loss per 100 training steps: 0.024461201967563167\n","Training loss per 100 training steps: 0.02664730408844603\n","Training loss per 100 training steps: 0.027984754804408093\n","Training loss per 100 training steps: 0.02880827976430492\n","Training loss per 100 training steps: 0.02820894308661263\n","Training loss per 100 training steps: 0.029323622551316646\n","Training loss per 100 training steps: 0.027498706240652357\n","Training loss per 100 training steps: 0.029139324888877962\n","Training loss epoch: 0.028912829161972874\n","Training accuracy epoch: 0.9918811274509803\n","Validating model...\n","Validation Loss: 0.16266688049183678\n","Validation Accuracy: 0.9672181372549019\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 38.23376644999998 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.12963172061480926\n","Validation Accuracy: 0.9592013888888888\n","Validation duration: 2.4489071833332976 minutes\n","F1-score (test): 86.5%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.81      0.84      0.82      1170\n","        test       0.88      0.90      0.89      2464\n","   treatment       0.82      0.91      0.86      1244\n","\n","   micro avg       0.85      0.88      0.86      4878\n","   macro avg       0.84      0.88      0.86      4878\n","weighted avg       0.85      0.88      0.86      4878\n","\n","!!!!!! Starting model number 8 !!!!!!\n","Points in X_train after augmentation: 26104\n","Points in y_train after augmentation: 26104\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.6525840759277344\n","Training loss per 100 training steps: 0.323848025624336\n","Training loss per 100 training steps: 0.2478985711885848\n","Training loss per 100 training steps: 0.21830992297458143\n","Training loss per 100 training steps: 0.20011182887563272\n","Training loss per 100 training steps: 0.18494894083295604\n","Training loss per 100 training steps: 0.17499969536423088\n","Training loss per 100 training steps: 0.1677013606549813\n","Training loss per 100 training steps: 0.15909096906537168\n","Training loss epoch: 0.15770698037779177\n","Training accuracy epoch: 0.9509931576797385\n","Validating model...\n","Validation Loss: 0.14450122355072595\n","Validation Accuracy: 0.9574043327008223\n","Training epoch: 2\n","Training loss per 100 training steps: 0.14058108627796173\n","Training loss per 100 training steps: 0.05765297885472416\n","Training loss per 100 training steps: 0.05467447344635368\n","Training loss per 100 training steps: 0.05458610341768167\n","Training loss per 100 training steps: 0.05491852927389799\n","Training loss per 100 training steps: 0.05727199467057976\n","Training loss per 100 training steps: 0.05898918980285495\n","Training loss per 100 training steps: 0.060361673518551644\n","Training loss per 100 training steps: 0.05890285787468377\n","Training loss epoch: 0.05866541356479894\n","Training accuracy epoch: 0.9819240196078431\n","Validating model...\n","Validation Loss: 0.15273296030343272\n","Validation Accuracy: 0.9604779411764706\n","Training epoch: 3\n","Training loss per 100 training steps: 0.01589883677661419\n","Training loss per 100 training steps: 0.031374351381690764\n","Training loss per 100 training steps: 0.025492609717879696\n","Training loss per 100 training steps: 0.03063737241759358\n","Training loss per 100 training steps: 0.0304701301116674\n","Training loss per 100 training steps: 0.030396410425627202\n","Training loss per 100 training steps: 0.0314631276851045\n","Training loss per 100 training steps: 0.032099449799866744\n","Training loss per 100 training steps: 0.03384227370057016\n","Training loss epoch: 0.034309536945596956\n","Training accuracy epoch: 0.989468443627451\n","Validating model...\n","Validation Loss: 0.21483013135330825\n","Validation Accuracy: 0.9472940385831752\n","Training epoch: 4\n","Training loss per 100 training steps: 0.015576943755149841\n","Training loss per 100 training steps: 0.028531321085814278\n","Training loss per 100 training steps: 0.027252139534629807\n","Training loss per 100 training steps: 0.026036970451763487\n","Training loss per 100 training steps: 0.026033889523915194\n","Training loss per 100 training steps: 0.02540766175987014\n","Training loss per 100 training steps: 0.026829319435545434\n","Training loss per 100 training steps: 0.027901478330022655\n","Training loss per 100 training steps: 0.02908430202911999\n","Training loss epoch: 0.029555915671313843\n","Training accuracy epoch: 0.9902726715686274\n","Validating model...\n","Validation Loss: 0.17507939418554122\n","Validation Accuracy: 0.9549039373814042\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0010150320595130324\n","Training loss per 100 training steps: 0.030868446551226447\n","Training loss per 100 training steps: 0.02337221301969289\n","Training loss per 100 training steps: 0.021846935997888804\n","Training loss per 100 training steps: 0.02287661756241945\n","Training loss per 100 training steps: 0.021285663385531155\n","Training loss per 100 training steps: 0.021049808016558837\n","Training loss per 100 training steps: 0.019921005416103338\n","Training loss per 100 training steps: 0.02200263647136808\n","Training loss epoch: 0.02189520661299777\n","Training accuracy epoch: 0.9936810661764706\n","Validating model...\n","Validation Loss: 0.20348982928051412\n","Validation Accuracy: 0.9574043327008223\n","Training epoch: 6\n","Training loss per 100 training steps: 0.004674961790442467\n","Training loss per 100 training steps: 0.028818829912095247\n","Training loss per 100 training steps: 0.023591922012138045\n","Training loss per 100 training steps: 0.02135908842155249\n","Training loss per 100 training steps: 0.021321882333722897\n","Training loss per 100 training steps: 0.021399540049385254\n","Training loss per 100 training steps: 0.022310288515760907\n","Training loss per 100 training steps: 0.02195130971891187\n","Training loss per 100 training steps: 0.022272209317033755\n","Training loss epoch: 0.022225123228571307\n","Training accuracy epoch: 0.9935278799019608\n","Validating model...\n","Validation Loss: 0.1987031825447761\n","Validation Accuracy: 0.9586199399114484\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 36.90991421666664 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.12878367497978616\n","Validation Accuracy: 0.9599609375\n","Validation duration: 2.414349933333324 minutes\n","F1-score (test): 86.9%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.86      0.83      0.84      1170\n","        test       0.87      0.92      0.89      2464\n","   treatment       0.82      0.88      0.85      1244\n","\n","   micro avg       0.85      0.88      0.87      4878\n","   macro avg       0.85      0.87      0.86      4878\n","weighted avg       0.85      0.88      0.87      4878\n","\n","!!!!!! Starting model number 9 !!!!!!\n","Points in X_train after augmentation: 26104\n","Points in y_train after augmentation: 26104\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9374312162399292\n","Training loss per 100 training steps: 0.3238026419156554\n","Training loss per 100 training steps: 0.25033431743452356\n","Training loss per 100 training steps: 0.2221593780696788\n","Training loss per 100 training steps: 0.20455432987941471\n","Training loss per 100 training steps: 0.1923267868888414\n","Training loss per 100 training steps: 0.18060787154374003\n","Training loss per 100 training steps: 0.17452236617611092\n","Training loss per 100 training steps: 0.16510260951462272\n","Training loss epoch: 0.16418103082105517\n","Training accuracy epoch: 0.9473422181372549\n","Validating model...\n","Validation Loss: 0.15333415984230883\n","Validation Accuracy: 0.9555759803921569\n","Training epoch: 2\n","Training loss per 100 training steps: 0.013817613944411278\n","Training loss per 100 training steps: 0.05824841031491166\n","Training loss per 100 training steps: 0.04954300896873911\n","Training loss per 100 training steps: 0.055804287842467146\n","Training loss per 100 training steps: 0.0549813308411956\n","Training loss per 100 training steps: 0.056826051456008865\n","Training loss per 100 training steps: 0.05794292947979793\n","Training loss per 100 training steps: 0.06033756606473113\n","Training loss per 100 training steps: 0.0612133561156675\n","Training loss epoch: 0.06175376823211634\n","Training accuracy epoch: 0.9809538398692811\n","Validating model...\n","Validation Loss: 0.14191695634850904\n","Validation Accuracy: 0.9586298228969007\n","Training epoch: 3\n","Training loss per 100 training steps: 0.033016715198755264\n","Training loss per 100 training steps: 0.025021643908048917\n","Training loss per 100 training steps: 0.027595504364421573\n","Training loss per 100 training steps: 0.027870426463923167\n","Training loss per 100 training steps: 0.03481356121287298\n","Training loss per 100 training steps: 0.033912244910514165\n","Training loss per 100 training steps: 0.035551606121158444\n","Training loss per 100 training steps: 0.034861197378273825\n","Training loss per 100 training steps: 0.03494092922626626\n","Training loss epoch: 0.035414315730247156\n","Training accuracy epoch: 0.9890088848039216\n","Validating model...\n","Validation Loss: 0.17411596294750423\n","Validation Accuracy: 0.9561788425047438\n","Training epoch: 4\n","Training loss per 100 training steps: 0.000878510472830385\n","Training loss per 100 training steps: 0.01942601157433012\n","Training loss per 100 training steps: 0.02244582445625985\n","Training loss per 100 training steps: 0.02392758673483945\n","Training loss per 100 training steps: 0.02605009371208078\n","Training loss per 100 training steps: 0.02719334925645372\n","Training loss per 100 training steps: 0.028688114740422457\n","Training loss per 100 training steps: 0.028441889007497258\n","Training loss per 100 training steps: 0.02944362623703965\n","Training loss epoch: 0.029654464370490612\n","Training accuracy epoch: 0.9906556372549019\n","Validating model...\n","Validation Loss: 0.1552829385861211\n","Validation Accuracy: 0.960171568627451\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0057767354883253574\n","Training loss per 100 training steps: 0.019500993831039377\n","Training loss per 100 training steps: 0.01705359699343857\n","Training loss per 100 training steps: 0.01931407990913948\n","Training loss per 100 training steps: 0.0235066053797877\n","Training loss per 100 training steps: 0.026399239019181498\n","Training loss per 100 training steps: 0.027859436828439114\n","Training loss per 100 training steps: 0.030988703992498604\n","Training loss per 100 training steps: 0.030598438942105715\n","Training loss epoch: 0.030235351311781487\n","Training accuracy epoch: 0.9913449754901961\n","Validating model...\n","Validation Loss: 0.16913465435009487\n","Validation Accuracy: 0.9644607843137255\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00145745521876961\n","Training loss per 100 training steps: 0.021118965841908154\n","Training loss per 100 training steps: 0.020274947824484243\n","Training loss per 100 training steps: 0.019437320828922224\n","Training loss per 100 training steps: 0.021067984445527006\n","Training loss per 100 training steps: 0.02311983047417277\n","Training loss per 100 training steps: 0.02261910185038634\n","Training loss per 100 training steps: 0.024006584781436194\n","Training loss per 100 training steps: 0.024440270101637525\n","Training loss epoch: 0.024585761953278728\n","Training accuracy epoch: 0.9931449142156863\n","Validating model...\n","Validation Loss: 0.1912473792517809\n","Validation Accuracy: 0.9580269607843137\n","Training epoch: 7\n","Training loss per 100 training steps: 0.007839031517505646\n","Training loss per 100 training steps: 0.02650855039203157\n","Training loss per 100 training steps: 0.025329089990746928\n","Training loss per 100 training steps: 0.022044124230392436\n","Training loss per 100 training steps: 0.0187014484345989\n","Training loss per 100 training steps: 0.01765380819309424\n","Training loss per 100 training steps: 0.01728260635213633\n","Training loss per 100 training steps: 0.01780163768313798\n","Training loss per 100 training steps: 0.01817078985728817\n","Training loss epoch: 0.01823268583898336\n","Training accuracy epoch: 0.9946257148692811\n","Validating model...\n","Validation Loss: 0.21434746286931664\n","Validation Accuracy: 0.956791587602783\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 43.68858790000001 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14382770752045973\n","Validation Accuracy: 0.9598524305555556\n","Validation duration: 2.4169613833333035 minutes\n","F1-score (test): 87.2%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.83      0.85      0.84      1170\n","        test       0.87      0.91      0.89      2464\n","   treatment       0.84      0.91      0.87      1244\n","\n","   micro avg       0.85      0.89      0.87      4878\n","   macro avg       0.84      0.89      0.87      4878\n","weighted avg       0.85      0.89      0.87      4878\n","\n","!!!!!! Starting model number 10 !!!!!!\n","Points in X_train after augmentation: 26104\n","Points in y_train after augmentation: 26104\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.970993995666504\n","Training loss per 100 training steps: 0.30852409452199936\n","Training loss per 100 training steps: 0.24093868036694194\n","Training loss per 100 training steps: 0.21384019824363712\n","Training loss per 100 training steps: 0.19756358755204334\n","Training loss per 100 training steps: 0.18578129320195366\n","Training loss per 100 training steps: 0.17924437954008407\n","Training loss per 100 training steps: 0.17185763379335722\n","Training loss per 100 training steps: 0.16514825714070736\n","Training loss epoch: 0.16375155803204203\n","Training accuracy epoch: 0.9483379289215687\n","Validating model...\n","Validation Loss: 0.15018564402856224\n","Validation Accuracy: 0.9570979601518027\n","Training epoch: 2\n","Training loss per 100 training steps: 0.01451118290424347\n","Training loss per 100 training steps: 0.047879296074861126\n","Training loss per 100 training steps: 0.056593766536179056\n","Training loss per 100 training steps: 0.057394743323066204\n","Training loss per 100 training steps: 0.05771868062052327\n","Training loss per 100 training steps: 0.058334081958395664\n","Training loss per 100 training steps: 0.05934927180179313\n","Training loss per 100 training steps: 0.060904182353523295\n","Training loss per 100 training steps: 0.0620476069462517\n","Training loss epoch: 0.061459760767391736\n","Training accuracy epoch: 0.9806219362745098\n","Validating model...\n","Validation Loss: 0.13897735003025874\n","Validation Accuracy: 0.9610610373181531\n","Training epoch: 3\n","Training loss per 100 training steps: 0.01442981418222189\n","Training loss per 100 training steps: 0.03409121144392371\n","Training loss per 100 training steps: 0.041939454925517594\n","Training loss per 100 training steps: 0.04005810266795361\n","Training loss per 100 training steps: 0.040652990740946866\n","Training loss per 100 training steps: 0.03714227896738387\n","Training loss per 100 training steps: 0.03855312282958311\n","Training loss per 100 training steps: 0.03938358214258026\n","Training loss per 100 training steps: 0.039986912451786795\n","Training loss epoch: 0.04057688987357359\n","Training accuracy epoch: 0.9870174632352942\n","Validating model...\n","Validation Loss: 0.16034582751237003\n","Validation Accuracy: 0.9610709203036053\n","Training epoch: 4\n","Training loss per 100 training steps: 0.04869868606328964\n","Training loss per 100 training steps: 0.03459470464541383\n","Training loss per 100 training steps: 0.03363907691068132\n","Training loss per 100 training steps: 0.030302147870213087\n","Training loss per 100 training steps: 0.03164831786923792\n","Training loss per 100 training steps: 0.03114443487340065\n","Training loss per 100 training steps: 0.03026949811991503\n","Training loss per 100 training steps: 0.03028572289379511\n","Training loss per 100 training steps: 0.029694793229364122\n","Training loss epoch: 0.03000130651413629\n","Training accuracy epoch: 0.9911534926470589\n","Validating model...\n","Validation Loss: 0.17518241844949195\n","Validation Accuracy: 0.9610808032890575\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0007980655645951629\n","Training loss per 100 training steps: 0.020190688757235092\n","Training loss per 100 training steps: 0.02010585413304556\n","Training loss per 100 training steps: 0.02334647662117706\n","Training loss per 100 training steps: 0.024246442271048142\n","Training loss per 100 training steps: 0.025108678217841584\n","Training loss per 100 training steps: 0.022719741225698396\n","Training loss per 100 training steps: 0.022680786100955887\n","Training loss per 100 training steps: 0.02214298303265644\n","Training loss epoch: 0.02209419482752827\n","Training accuracy epoch: 0.9932981004901961\n","Validating model...\n","Validation Loss: 0.19772903619941287\n","Validation Accuracy: 0.9604680581910183\n","Training epoch: 6\n","Training loss per 100 training steps: 0.02827025018632412\n","Training loss per 100 training steps: 0.021610684417093653\n","Training loss per 100 training steps: 0.019070068255218328\n","Training loss per 100 training steps: 0.02016078461631355\n","Training loss per 100 training steps: 0.020374002549298685\n","Training loss per 100 training steps: 0.021933678604281685\n","Training loss per 100 training steps: 0.0216904820299109\n","Training loss per 100 training steps: 0.02040245446923746\n","Training loss per 100 training steps: 0.021944352796617862\n","Training loss epoch: 0.02238652825947914\n","Training accuracy epoch: 0.9936427696078431\n","Validating model...\n","Validation Loss: 0.18215525567339844\n","Validation Accuracy: 0.9601616856419988\n","Training epoch: 7\n","Training loss per 100 training steps: 0.17262336611747742\n","Training loss per 100 training steps: 0.01967720405183073\n","Training loss per 100 training steps: 0.014733793618195443\n","Training loss per 100 training steps: 0.013945673220106161\n","Training loss per 100 training steps: 0.015132728652975116\n","Training loss per 100 training steps: 0.015784196359258016\n","Training loss per 100 training steps: 0.018440408274287445\n","Training loss per 100 training steps: 0.019382247060416562\n","Training loss per 100 training steps: 0.01838957684691983\n","Training loss epoch: 0.018134881549891433\n","Training accuracy epoch: 0.9944852941176471\n","Validating model...\n","Validation Loss: 0.2133782385095829\n","Validation Accuracy: 0.9613970588235294\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 42.44244476666669 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14417084660487522\n","Validation Accuracy: 0.9598323366769548\n","Validation duration: 2.346066116666649 minutes\n","F1-score (test): 86.4%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.85      0.82      0.83      1170\n","        test       0.83      0.92      0.87      2464\n","   treatment       0.89      0.86      0.87      1244\n","\n","   micro avg       0.85      0.88      0.86      4878\n","   macro avg       0.86      0.86      0.86      4878\n","weighted avg       0.85      0.88      0.86      4878\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 1\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zjhn7-LqHri0","outputId":"c8257b4b-d140-4ef1-9160-6dc6ce593765"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 200% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 39156\n","Points in y_train after augmentation: 39156\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9318190813064575\n","Training loss per 100 training steps: 0.31007086315957627\n","Training loss per 100 training steps: 0.26071831222567987\n","Training loss per 100 training steps: 0.22809826496344962\n","Training loss per 100 training steps: 0.20722715247032278\n","Training loss per 100 training steps: 0.19246887423129688\n","Training loss per 100 training steps: 0.1808172680531317\n","Training loss per 100 training steps: 0.1722098617397977\n","Training loss per 100 training steps: 0.16507800548589124\n","Training loss per 100 training steps: 0.15948607832566525\n","Training loss per 100 training steps: 0.15319364823444703\n","Training loss per 100 training steps: 0.14776006784479553\n","Training loss per 100 training steps: 0.1432910925899861\n","Training loss epoch: 0.1416431727438322\n","Training accuracy epoch: 0.9553206699346405\n","Validating model...\n","Validation Loss: 0.1817191027266923\n","Validation Accuracy: 0.953727862112587\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09854880720376968\n","Training loss per 100 training steps: 0.04527251457733259\n","Training loss per 100 training steps: 0.04414439166662056\n","Training loss per 100 training steps: 0.04616967174093056\n","Training loss per 100 training steps: 0.04792291552822414\n","Training loss per 100 training steps: 0.05153933853750301\n","Training loss per 100 training steps: 0.05119708157154172\n","Training loss per 100 training steps: 0.051758595009499794\n","Training loss per 100 training steps: 0.05213435281836341\n","Training loss per 100 training steps: 0.05209987184325322\n","Training loss per 100 training steps: 0.05252816508706477\n","Training loss per 100 training steps: 0.05199576287814158\n","Training loss per 100 training steps: 0.05230183248310431\n","Training loss epoch: 0.052409866908443424\n","Training accuracy epoch: 0.984375\n","Validating model...\n","Validation Loss: 0.14742579997069769\n","Validation Accuracy: 0.9583135673624289\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02031661383807659\n","Training loss per 100 training steps: 0.02666059309659332\n","Training loss per 100 training steps: 0.029315119361347376\n","Training loss per 100 training steps: 0.030593625131272787\n","Training loss per 100 training steps: 0.031995129963499784\n","Training loss per 100 training steps: 0.03149737902639756\n","Training loss per 100 training steps: 0.03144601565908126\n","Training loss per 100 training steps: 0.032287804082287784\n","Training loss per 100 training steps: 0.031211929230982167\n","Training loss per 100 training steps: 0.03227437677450548\n","Training loss per 100 training steps: 0.03176516112442325\n","Training loss per 100 training steps: 0.03276286368109421\n","Training loss per 100 training steps: 0.03327618859606337\n","Training loss epoch: 0.03354319123572364\n","Training accuracy epoch: 0.9898641748366013\n","Validating model...\n","Validation Loss: 0.19517814646664478\n","Validation Accuracy: 0.9543406072106262\n","Training epoch: 4\n","Training loss per 100 training steps: 0.05648631229996681\n","Training loss per 100 training steps: 0.029416405430437057\n","Training loss per 100 training steps: 0.027414433037748084\n","Training loss per 100 training steps: 0.02429895071645207\n","Training loss per 100 training steps: 0.023924156566659405\n","Training loss per 100 training steps: 0.024015703443406446\n","Training loss per 100 training steps: 0.02932054026325186\n","Training loss per 100 training steps: 0.03187023862712195\n","Training loss per 100 training steps: 0.033096480381779855\n","Training loss per 100 training steps: 0.03317372722339133\n","Training loss per 100 training steps: 0.03293397648821547\n","Training loss per 100 training steps: 0.03310350026930528\n","Training loss per 100 training steps: 0.03260524119024383\n","Training loss epoch: 0.03275869071530549\n","Training accuracy epoch: 0.9901296977124183\n","Validating model...\n","Validation Loss: 0.17783657638310438\n","Validation Accuracy: 0.9586199399114484\n","Training epoch: 5\n","Training loss per 100 training steps: 0.05090602859854698\n","Training loss per 100 training steps: 0.015506050383325178\n","Training loss per 100 training steps: 0.015494095495672067\n","Training loss per 100 training steps: 0.015109544449887683\n","Training loss per 100 training steps: 0.01804194672258473\n","Training loss per 100 training steps: 0.01743853918649442\n","Training loss per 100 training steps: 0.017531984809266182\n","Training loss per 100 training steps: 0.01724377383856045\n","Training loss per 100 training steps: 0.017626278939523638\n","Training loss per 100 training steps: 0.018410446225541083\n","Training loss per 100 training steps: 0.01903082391784862\n","Training loss per 100 training steps: 0.018817735059609444\n","Training loss per 100 training steps: 0.01879021737650729\n","Training loss epoch: 0.018780023177872734\n","Training accuracy epoch: 0.9943831699346405\n","Validating model...\n","Validation Loss: 0.19946343300426972\n","Validation Accuracy: 0.9592425679949399\n","Training epoch: 6\n","Training loss per 100 training steps: 0.011156275868415833\n","Training loss per 100 training steps: 0.007157638911786028\n","Training loss per 100 training steps: 0.012414019857330563\n","Training loss per 100 training steps: 0.016249567755326655\n","Training loss per 100 training steps: 0.01833258841894834\n","Training loss per 100 training steps: 0.017272360347064506\n","Training loss per 100 training steps: 0.01653038593111147\n","Training loss per 100 training steps: 0.017939498413109788\n","Training loss per 100 training steps: 0.018325591475457783\n","Training loss per 100 training steps: 0.01864756588514417\n","Training loss per 100 training steps: 0.018912828055951063\n","Training loss per 100 training steps: 0.01970087399828079\n","Training loss per 100 training steps: 0.020147705500919325\n","Training loss epoch: 0.019918751565431974\n","Training accuracy epoch: 0.9943576388888888\n","Validating model...\n","Validation Loss: 0.19613148818875653\n","Validation Accuracy: 0.9595588235294118\n","Training epoch: 7\n","Training loss per 100 training steps: 0.001062641735188663\n","Training loss per 100 training steps: 0.006834966590236711\n","Training loss per 100 training steps: 0.007159348448103673\n","Training loss per 100 training steps: 0.010105879914786734\n","Training loss per 100 training steps: 0.010780301004702788\n","Training loss per 100 training steps: 0.011833736695210203\n","Training loss per 100 training steps: 0.013710174758292875\n","Training loss per 100 training steps: 0.014728483637280989\n","Training loss per 100 training steps: 0.014761370653042227\n","Training loss per 100 training steps: 0.016311217422505728\n","Training loss per 100 training steps: 0.016831406996385016\n","Training loss per 100 training steps: 0.01754217459658369\n","Training loss per 100 training steps: 0.017580542772262623\n","Training loss epoch: 0.01773787595799696\n","Training accuracy epoch: 0.9948682598039216\n","Validating model...\n","Validation Loss: 0.26191824717234874\n","Validation Accuracy: 0.9405637254901961\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 63.479026749999925 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1411132394514762\n","Validation Accuracy: 0.9603226273148148\n","Validation duration: 2.371273533333321 minutes\n","F1-score (test): 86.9%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.77      0.89      0.82      1170\n","        test       0.90      0.89      0.90      2464\n","   treatment       0.84      0.88      0.86      1244\n","\n","   micro avg       0.85      0.89      0.87      4878\n","   macro avg       0.84      0.89      0.86      4878\n","weighted avg       0.85      0.89      0.87      4878\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 39156\n","Points in y_train after augmentation: 39156\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7278413772583008\n","Training loss per 100 training steps: 0.3311798270828653\n","Training loss per 100 training steps: 0.2600544784820421\n","Training loss per 100 training steps: 0.2308555445804004\n","Training loss per 100 training steps: 0.2133602360518942\n","Training loss per 100 training steps: 0.19789044403037923\n","Training loss per 100 training steps: 0.1885809155177951\n","Training loss per 100 training steps: 0.1768709264845772\n","Training loss per 100 training steps: 0.17108080052792765\n","Training loss per 100 training steps: 0.16384234261046784\n","Training loss per 100 training steps: 0.1586544310862941\n","Training loss per 100 training steps: 0.15426022511907767\n","Training loss per 100 training steps: 0.1484560951949962\n","Training loss epoch: 0.14685544179386484\n","Training accuracy epoch: 0.9529207516339869\n","Validating model...\n","Validation Loss: 0.16101836968742894\n","Validation Accuracy: 0.9540441176470589\n","Training epoch: 2\n","Training loss per 100 training steps: 0.12585557997226715\n","Training loss per 100 training steps: 0.0556271381348851\n","Training loss per 100 training steps: 0.05180229077379761\n","Training loss per 100 training steps: 0.05277253956471313\n","Training loss per 100 training steps: 0.05414300456749359\n","Training loss per 100 training steps: 0.05140692838795294\n","Training loss per 100 training steps: 0.05089656385206098\n","Training loss per 100 training steps: 0.05203811078840208\n","Training loss per 100 training steps: 0.052185624923987824\n","Training loss per 100 training steps: 0.05225096355246889\n","Training loss per 100 training steps: 0.053135643254434754\n","Training loss per 100 training steps: 0.05302734420319501\n","Training loss per 100 training steps: 0.05372605443515115\n","Training loss epoch: 0.05403280992589144\n","Training accuracy epoch: 0.9824805964052288\n","Validating model...\n","Validation Loss: 0.14158949251035594\n","Validation Accuracy: 0.9613674098671727\n","Training epoch: 3\n","Training loss per 100 training steps: 0.008709901012480259\n","Training loss per 100 training steps: 0.01808327362390862\n","Training loss per 100 training steps: 0.022323488540610354\n","Training loss per 100 training steps: 0.020919983349009526\n","Training loss per 100 training steps: 0.021272318824028892\n","Training loss per 100 training steps: 0.02150026231759252\n","Training loss per 100 training steps: 0.023189984341020296\n","Training loss per 100 training steps: 0.02488462208391077\n","Training loss per 100 training steps: 0.024923428713742844\n","Training loss per 100 training steps: 0.025033276523080975\n","Training loss per 100 training steps: 0.025756694350097854\n","Training loss per 100 training steps: 0.025872350339073567\n","Training loss per 100 training steps: 0.02794388058595553\n","Training loss epoch: 0.02772406803126977\n","Training accuracy epoch: 0.9916258169934641\n","Validating model...\n","Validation Loss: 0.22975492765416514\n","Validation Accuracy: 0.9534313725490197\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0016295312670990825\n","Training loss per 100 training steps: 0.02407163591412274\n","Training loss per 100 training steps: 0.02603551764296025\n","Training loss per 100 training steps: 0.024094067526222406\n","Training loss per 100 training steps: 0.023348080607533496\n","Training loss per 100 training steps: 0.02689608376401852\n","Training loss per 100 training steps: 0.027769470171493085\n","Training loss per 100 training steps: 0.030544630082682194\n","Training loss per 100 training steps: 0.0318860111245217\n","Training loss per 100 training steps: 0.03226518516484844\n","Training loss per 100 training steps: 0.03242779310062792\n","Training loss per 100 training steps: 0.032154793564665204\n","Training loss per 100 training steps: 0.03113524916246522\n","Training loss epoch: 0.030884088556917752\n","Training accuracy epoch: 0.9907322303921569\n","Validating model...\n","Validation Loss: 0.18363343167184926\n","Validation Accuracy: 0.9546568627450981\n","Training epoch: 5\n","Training loss per 100 training steps: 0.002389306668192148\n","Training loss per 100 training steps: 0.0254454888451826\n","Training loss per 100 training steps: 0.02565457140438986\n","Training loss per 100 training steps: 0.023032991747625953\n","Training loss per 100 training steps: 0.021386636641141297\n","Training loss per 100 training steps: 0.018702864938806775\n","Training loss per 100 training steps: 0.019011657970716588\n","Training loss per 100 training steps: 0.01969934244819818\n","Training loss per 100 training steps: 0.02034004805377589\n","Training loss per 100 training steps: 0.021380093977928404\n","Training loss per 100 training steps: 0.02212318102973805\n","Training loss per 100 training steps: 0.0225929667733319\n","Training loss per 100 training steps: 0.02267815743603519\n","Training loss epoch: 0.022516338830000142\n","Training accuracy epoch: 0.9933619281045751\n","Validating model...\n","Validation Loss: 0.2028306321045224\n","Validation Accuracy: 0.9632352941176471\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00021758192451670766\n","Training loss per 100 training steps: 0.013104301364688977\n","Training loss per 100 training steps: 0.01408854401556008\n","Training loss per 100 training steps: 0.013288687865684533\n","Training loss per 100 training steps: 0.014512578215397212\n","Training loss per 100 training steps: 0.01611724792366328\n","Training loss per 100 training steps: 0.017274364502892284\n","Training loss per 100 training steps: 0.018208732657445416\n","Training loss per 100 training steps: 0.0181394547406298\n","Training loss per 100 training steps: 0.018498086793776902\n","Training loss per 100 training steps: 0.01820340227658363\n","Training loss per 100 training steps: 0.018023572186112034\n","Training loss per 100 training steps: 0.018377106993120968\n","Training loss epoch: 0.018517471343728092\n","Training accuracy epoch: 0.9944597630718954\n","Validating model...\n","Validation Loss: 0.1958455645402793\n","Validation Accuracy: 0.9613871758380772\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0028284569270908833\n","Training loss per 100 training steps: 0.012796316268847504\n","Training loss per 100 training steps: 0.013640945856391385\n","Training loss per 100 training steps: 0.014487117220472816\n","Training loss per 100 training steps: 0.01466485694227299\n","Training loss per 100 training steps: 0.013903049569157094\n","Training loss per 100 training steps: 0.01716045910412056\n","Training loss per 100 training steps: 0.016689853016316567\n","Training loss per 100 training steps: 0.01657951495310746\n","Training loss per 100 training steps: 0.015473460097520778\n","Training loss per 100 training steps: 0.014658078016753036\n","Training loss per 100 training steps: 0.016509678347520144\n","Training loss per 100 training steps: 0.01654609515823058\n","Training loss epoch: 0.01655894635921844\n","Training accuracy epoch: 0.9952512254901961\n","Validating model...\n","Validation Loss: 0.24726200910363866\n","Validation Accuracy: 0.9525023719165086\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 65.8121499333333 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1433822975847121\n","Validation Accuracy: 0.9586749292695473\n","Validation duration: 2.4771447166667104 minutes\n","F1-score (test): 86.7%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.80      0.87      0.83      1170\n","        test       0.86      0.92      0.89      2464\n","   treatment       0.85      0.86      0.86      1244\n","\n","   micro avg       0.84      0.89      0.87      4878\n","   macro avg       0.84      0.88      0.86      4878\n","weighted avg       0.84      0.89      0.87      4878\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 39156\n","Points in y_train after augmentation: 39156\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.3186302185058594\n","Training loss per 100 training steps: 0.3417305005437667\n","Training loss per 100 training steps: 0.26403759967591334\n","Training loss per 100 training steps: 0.22990930862601017\n","Training loss per 100 training steps: 0.21079048790279173\n","Training loss per 100 training steps: 0.19375275848470555\n","Training loss per 100 training steps: 0.18177358211388506\n","Training loss per 100 training steps: 0.17314796062477317\n","Training loss per 100 training steps: 0.16690015639922584\n","Training loss per 100 training steps: 0.1622362229867128\n","Training loss per 100 training steps: 0.15439128186253664\n","Training loss per 100 training steps: 0.14832728272073434\n","Training loss per 100 training steps: 0.14524689220253775\n","Training loss epoch: 0.14404848380460558\n","Training accuracy epoch: 0.9546926062091504\n","Validating model...\n","Validation Loss: 0.13900447242685557\n","Validation Accuracy: 0.9592326850094877\n","Training epoch: 2\n","Training loss per 100 training steps: 0.009041307494044304\n","Training loss per 100 training steps: 0.045389919046146594\n","Training loss per 100 training steps: 0.04198746417188062\n","Training loss per 100 training steps: 0.04048233788864272\n","Training loss per 100 training steps: 0.04141274195566815\n","Training loss per 100 training steps: 0.04307341730238836\n","Training loss per 100 training steps: 0.043259224743466475\n","Training loss per 100 training steps: 0.045667858939103384\n","Training loss per 100 training steps: 0.045701505385475\n","Training loss per 100 training steps: 0.04634037446038778\n","Training loss per 100 training steps: 0.047662336892546286\n","Training loss per 100 training steps: 0.04771548766898373\n","Training loss per 100 training steps: 0.04853369826786813\n","Training loss epoch: 0.04860286544717858\n","Training accuracy epoch: 0.9855238970588235\n","Validating model...\n","Validation Loss: 0.15097021779123074\n","Validation Accuracy: 0.9577205882352942\n","Training epoch: 3\n","Training loss per 100 training steps: 0.06837606430053711\n","Training loss per 100 training steps: 0.03879031433267427\n","Training loss per 100 training steps: 0.032944405944444546\n","Training loss per 100 training steps: 0.03245386462353102\n","Training loss per 100 training steps: 0.03227889462388086\n","Training loss per 100 training steps: 0.032227028356242304\n","Training loss per 100 training steps: 0.031586903505725204\n","Training loss per 100 training steps: 0.030779769462605536\n","Training loss per 100 training steps: 0.030916700616039856\n","Training loss per 100 training steps: 0.030258965551034397\n","Training loss per 100 training steps: 0.03150052890070999\n","Training loss per 100 training steps: 0.0324473628046901\n","Training loss per 100 training steps: 0.03291272711706746\n","Training loss epoch: 0.03265884489867864\n","Training accuracy epoch: 0.9899407679738562\n","Validating model...\n","Validation Loss: 0.1658045338879353\n","Validation Accuracy: 0.9616935483870968\n","Training epoch: 4\n","Training loss per 100 training steps: 0.13135172426700592\n","Training loss per 100 training steps: 0.029556783773166378\n","Training loss per 100 training steps: 0.02782214196931411\n","Training loss per 100 training steps: 0.02905389017295332\n","Training loss per 100 training steps: 0.02907499705888813\n","Training loss per 100 training steps: 0.030021446172356886\n","Training loss per 100 training steps: 0.0283203662580678\n","Training loss per 100 training steps: 0.0280098829202903\n","Training loss per 100 training steps: 0.02727215945156836\n","Training loss per 100 training steps: 0.026403542690916923\n","Training loss per 100 training steps: 0.02767477258163711\n","Training loss per 100 training steps: 0.027918517886462525\n","Training loss per 100 training steps: 0.027817909001127225\n","Training loss epoch: 0.027774094242357297\n","Training accuracy epoch: 0.9918045343137255\n","Validating model...\n","Validation Loss: 0.22263644656848947\n","Validation Accuracy: 0.9515733712839974\n","Training epoch: 5\n","Training loss per 100 training steps: 0.21899066865444183\n","Training loss per 100 training steps: 0.023840305436342624\n","Training loss per 100 training steps: 0.019515953011291255\n","Training loss per 100 training steps: 0.018413251374176768\n","Training loss per 100 training steps: 0.01692319493859462\n","Training loss per 100 training steps: 0.01725044894984474\n","Training loss per 100 training steps: 0.018170699274255842\n","Training loss per 100 training steps: 0.018404210920215363\n","Training loss per 100 training steps: 0.0188564969620746\n","Training loss per 100 training steps: 0.017997147132132265\n","Training loss per 100 training steps: 0.019056584598794807\n","Training loss per 100 training steps: 0.019452452894003793\n","Training loss per 100 training steps: 0.01928650436247025\n","Training loss epoch: 0.019227609023735662\n","Training accuracy epoch: 0.9943065767973857\n","Validating model...\n","Validation Loss: 0.2428346557414853\n","Validation Accuracy: 0.9506641366223909\n","Training epoch: 6\n","Training loss per 100 training steps: 0.034945011138916016\n","Training loss per 100 training steps: 0.028750087287839465\n","Training loss per 100 training steps: 0.022918352377091288\n","Training loss per 100 training steps: 0.021605595909569574\n","Training loss per 100 training steps: 0.02129862714255318\n","Training loss per 100 training steps: 0.02123190518354178\n","Training loss per 100 training steps: 0.019073190747334767\n","Training loss per 100 training steps: 0.020670011675871024\n","Training loss per 100 training steps: 0.02132548874672803\n","Training loss per 100 training steps: 0.02128691909669584\n","Training loss per 100 training steps: 0.022251933774011353\n","Training loss per 100 training steps: 0.021564941732805286\n","Training loss per 100 training steps: 0.021547682498607442\n","Training loss epoch: 0.021518635182295767\n","Training accuracy epoch: 0.9935508578431373\n","Validating model...\n","Validation Loss: 0.21957335818967527\n","Validation Accuracy: 0.9607645477545858\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 55.025179500000014 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13011397134283065\n","Validation Accuracy: 0.960374871399177\n","Validation duration: 2.4042290500000187 minutes\n","F1-score (test): 86.7%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.79      0.85      0.82      1170\n","        test       0.89      0.88      0.89      2464\n","   treatment       0.90      0.85      0.87      1244\n","\n","   micro avg       0.87      0.87      0.87      4878\n","   macro avg       0.86      0.86      0.86      4878\n","weighted avg       0.87      0.87      0.87      4878\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 39156\n","Points in y_train after augmentation: 39156\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.227632522583008\n","Training loss per 100 training steps: 0.43938616655840734\n","Training loss per 100 training steps: 0.3221001050699113\n","Training loss per 100 training steps: 0.27760463058205936\n","Training loss per 100 training steps: 0.24875676592909488\n","Training loss per 100 training steps: 0.23058353783655725\n","Training loss per 100 training steps: 0.2140205337002737\n","Training loss per 100 training steps: 0.2008984785831896\n","Training loss per 100 training steps: 0.18923993431556083\n","Training loss per 100 training steps: 0.1805832575007624\n","Training loss per 100 training steps: 0.17281509515853574\n","Training loss per 100 training steps: 0.16399814649933372\n","Training loss per 100 training steps: 0.15722760869784097\n","Training loss epoch: 0.15625209286063302\n","Training accuracy epoch: 0.9519863153594772\n","Validating model...\n","Validation Loss: 0.13295870066127358\n","Validation Accuracy: 0.9580071948134092\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05749543756246567\n","Training loss per 100 training steps: 0.051353277689846474\n","Training loss per 100 training steps: 0.05139869809369626\n","Training loss per 100 training steps: 0.05458029758930052\n","Training loss per 100 training steps: 0.05583097872238936\n","Training loss per 100 training steps: 0.057402266314817395\n","Training loss per 100 training steps: 0.058587861199031886\n","Training loss per 100 training steps: 0.05765896285691441\n","Training loss per 100 training steps: 0.05685945876463306\n","Training loss per 100 training steps: 0.05643570713550793\n","Training loss per 100 training steps: 0.05681886681971688\n","Training loss per 100 training steps: 0.057484619345714326\n","Training loss per 100 training steps: 0.0572778161366115\n","Training loss epoch: 0.057082770600543266\n","Training accuracy epoch: 0.9825878267973857\n","Validating model...\n","Validation Loss: 0.15203219485998737\n","Validation Accuracy: 0.9613970588235294\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0030366829596459866\n","Training loss per 100 training steps: 0.02517160719190263\n","Training loss per 100 training steps: 0.027265692140590818\n","Training loss per 100 training steps: 0.029568674283870264\n","Training loss per 100 training steps: 0.029863156780206884\n","Training loss per 100 training steps: 0.03154393637134831\n","Training loss per 100 training steps: 0.030817286622450576\n","Training loss per 100 training steps: 0.032119280814311764\n","Training loss per 100 training steps: 0.03396898603983736\n","Training loss per 100 training steps: 0.03422694073066288\n","Training loss per 100 training steps: 0.033702077538192085\n","Training loss per 100 training steps: 0.03388978473230303\n","Training loss per 100 training steps: 0.03411100929414254\n","Training loss epoch: 0.03459428361434131\n","Training accuracy epoch: 0.9895067401960784\n","Validating model...\n","Validation Loss: 0.16814652760170729\n","Validation Accuracy: 0.9574043327008223\n","Training epoch: 4\n","Training loss per 100 training steps: 0.007106649689376354\n","Training loss per 100 training steps: 0.021749328607508896\n","Training loss per 100 training steps: 0.01929942493625819\n","Training loss per 100 training steps: 0.021999485302442667\n","Training loss per 100 training steps: 0.02243324849717412\n","Training loss per 100 training steps: 0.022977772448990335\n","Training loss per 100 training steps: 0.024293196293497892\n","Training loss per 100 training steps: 0.02468231257569203\n","Training loss per 100 training steps: 0.026796342426169486\n","Training loss per 100 training steps: 0.027633441626983224\n","Training loss per 100 training steps: 0.027962984574406727\n","Training loss per 100 training steps: 0.02796439831159382\n","Training loss per 100 training steps: 0.028037883012058666\n","Training loss epoch: 0.027887950097923084\n","Training accuracy epoch: 0.9917790032679739\n","Validating model...\n","Validation Loss: 0.18849284162541724\n","Validation Accuracy: 0.9570979601518027\n","Training epoch: 5\n","Training loss per 100 training steps: 0.010958361439406872\n","Training loss per 100 training steps: 0.01859346763484438\n","Training loss per 100 training steps: 0.014939630448711638\n","Training loss per 100 training steps: 0.0190101156498157\n","Training loss per 100 training steps: 0.02099889784211907\n","Training loss per 100 training steps: 0.02042548219587244\n","Training loss per 100 training steps: 0.022375478804214723\n","Training loss per 100 training steps: 0.02291511742402876\n","Training loss per 100 training steps: 0.021958660537730317\n","Training loss per 100 training steps: 0.021918649094981778\n","Training loss per 100 training steps: 0.02240627885889576\n","Training loss per 100 training steps: 0.02226973145013135\n","Training loss per 100 training steps: 0.022558861203037756\n","Training loss epoch: 0.0230838142599846\n","Training accuracy epoch: 0.9928870506535948\n","Validating model...\n","Validation Loss: 0.1834537209349447\n","Validation Accuracy: 0.954330724225174\n","Training epoch: 6\n","Training loss per 100 training steps: 0.054509516805410385\n","Training loss per 100 training steps: 0.01647412047406202\n","Training loss per 100 training steps: 0.01757974648595943\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 2\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"id":"D24RndOUWidH"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 200% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 39156\n","Points in y_train after augmentation: 39156\n","Device:  cuda\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ea2ebeb97534b1eb0e310d2a09a2578","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/422M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1073901653289795\n","Training loss per 100 training steps: 0.33980516458649446\n","Training loss per 100 training steps: 0.27579395710235804\n","Training loss per 100 training steps: 0.23963551254218995\n","Training loss per 100 training steps: 0.21404561766671792\n","Training loss per 100 training steps: 0.19911517668701337\n","Training loss per 100 training steps: 0.186150357209707\n","Training loss per 100 training steps: 0.17432101461544802\n","Training loss per 100 training steps: 0.1693327320128047\n","Training loss per 100 training steps: 0.16209815858039472\n","Training loss per 100 training steps: 0.15584412480743562\n","Training loss per 100 training steps: 0.15012367869053564\n","Training loss per 100 training steps: 0.1445186311088473\n","Training loss epoch: 0.143633583936558\n","Training accuracy epoch: 0.9554993872549019\n","Validating model...\n","Validation Loss: 0.15959973803347013\n","Validation Accuracy: 0.9574142156862745\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06444194167852402\n","Training loss per 100 training steps: 0.06520857143510908\n","Training loss per 100 training steps: 0.05218387923790698\n","Training loss per 100 training steps: 0.052747535084774935\n","Training loss per 100 training steps: 0.05105297076244411\n","Training loss per 100 training steps: 0.04825375372414503\n","Training loss per 100 training steps: 0.047305597245107064\n","Training loss per 100 training steps: 0.04839122577313136\n","Training loss per 100 training steps: 0.04855285097737204\n","Training loss per 100 training steps: 0.04813525818125396\n","Training loss per 100 training steps: 0.049468574136386036\n","Training loss per 100 training steps: 0.04897548221796603\n","Training loss per 100 training steps: 0.049351308075405796\n","Training loss epoch: 0.049575836869574716\n","Training accuracy epoch: 0.9844873366013073\n","Validating model...\n","Validation Loss: 0.1830641159367766\n","Validation Accuracy: 0.9546469797596459\n","Training epoch: 3\n","Training loss per 100 training steps: 0.1484602838754654\n","Training loss per 100 training steps: 0.025578727401069153\n","Training loss per 100 training steps: 0.027438564723981915\n","Training loss per 100 training steps: 0.0297561057718924\n","Training loss per 100 training steps: 0.030537485868563793\n","Training loss per 100 training steps: 0.030517066622391332\n","Training loss per 100 training steps: 0.029991410083517883\n","Training loss per 100 training steps: 0.030177421298765838\n","Training loss per 100 training steps: 0.03129216461449242\n","Training loss per 100 training steps: 0.03170426346060391\n","Training loss per 100 training steps: 0.031618060819253065\n","Training loss per 100 training steps: 0.03144189575569419\n","Training loss per 100 training steps: 0.03297349357858816\n","Training loss epoch: 0.03294079959604597\n","Training accuracy epoch: 0.9898386437908496\n","Validating model...\n","Validation Loss: 0.18754881356104378\n","Validation Accuracy: 0.9580269607843137\n","Training epoch: 4\n","Training loss per 100 training steps: 0.004035757388919592\n","Training loss per 100 training steps: 0.015775839529590368\n","Training loss per 100 training steps: 0.020250486893711415\n","Training loss per 100 training steps: 0.02251464677415711\n","Training loss per 100 training steps: 0.022650567704860756\n","Training loss per 100 training steps: 0.022283453172512638\n","Training loss per 100 training steps: 0.022338755909343228\n","Training loss per 100 training steps: 0.023217768370888472\n","Training loss per 100 training steps: 0.023638213312754914\n","Training loss per 100 training steps: 0.024204979589836\n","Training loss per 100 training steps: 0.02440912913041504\n","Training loss per 100 training steps: 0.02448260828755218\n","Training loss per 100 training steps: 0.025715064634242814\n","Training loss epoch: 0.02549610806170296\n","Training accuracy epoch: 0.9921619689542484\n","Validating model...\n","Validation Loss: 0.18545378846536942\n","Validation Accuracy: 0.9613970588235294\n","Training epoch: 5\n","Training loss per 100 training steps: 0.011026791296899319\n","Training loss per 100 training steps: 0.010889547295657467\n","Training loss per 100 training steps: 0.013380918628253814\n","Training loss per 100 training steps: 0.012627728385147847\n","Training loss per 100 training steps: 0.012632243426387028\n","Training loss per 100 training steps: 0.012353104687160036\n","Training loss per 100 training steps: 0.014820723168753082\n","Training loss per 100 training steps: 0.016198560984065132\n","Training loss per 100 training steps: 0.01601271857761686\n","Training loss per 100 training steps: 0.01612151404009189\n","Training loss per 100 training steps: 0.015791198885694625\n","Training loss per 100 training steps: 0.01588323663964811\n","Training loss per 100 training steps: 0.016647858116702326\n","Training loss epoch: 0.01655608592493224\n","Training accuracy epoch: 0.995031658496732\n","Validating model...\n","Validation Loss: 0.2036288971547608\n","Validation Accuracy: 0.9586298228969007\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0020393526647239923\n","Training loss per 100 training steps: 0.0140318907195089\n","Training loss per 100 training steps: 0.01699381425588123\n","Training loss per 100 training steps: 0.020044194152590313\n","Training loss per 100 training steps: 0.020982510401539856\n","Training loss per 100 training steps: 0.022875409764873223\n","Training loss per 100 training steps: 0.021886333148634394\n","Training loss per 100 training steps: 0.02282812937135249\n","Training loss per 100 training steps: 0.022773185318497795\n","Training loss per 100 training steps: 0.02185727669302903\n","Training loss per 100 training steps: 0.021886956414078753\n","Training loss per 100 training steps: 0.022405650994881347\n","Training loss per 100 training steps: 0.021814801061902787\n","Training loss epoch: 0.021739861453494276\n","Training accuracy epoch: 0.9934640522875817\n","Validating model...\n","Validation Loss: 0.24725750708631833\n","Validation Accuracy: 0.9537080961416825\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 55.27257386666667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14649295593941739\n","Validation Accuracy: 0.9572281700102881\n","Validation duration: 2.3828687166666667 minutes\n","F1-score (test): 86.1%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.77      0.80      0.79      1170\n","        test       0.92      0.86      0.89      2464\n","   treatment       0.91      0.85      0.88      1244\n","\n","   micro avg       0.88      0.85      0.86      4878\n","   macro avg       0.87      0.84      0.85      4878\n","weighted avg       0.88      0.85      0.86      4878\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 39156\n","Points in y_train after augmentation: 39156\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.2374396324157715\n","Training loss per 100 training steps: 0.33631557646659344\n","Training loss per 100 training steps: 0.26319319723331513\n","Training loss per 100 training steps: 0.22813965474406994\n","Training loss per 100 training steps: 0.20633609426275193\n","Training loss per 100 training steps: 0.19101481175630125\n","Training loss per 100 training steps: 0.1811026766223712\n","Training loss per 100 training steps: 0.17344931187805654\n","Training loss per 100 training steps: 0.16533563893053507\n","Training loss per 100 training steps: 0.16005671791087311\n","Training loss per 100 training steps: 0.15465120754467993\n","Training loss per 100 training steps: 0.15081735636504345\n","Training loss per 100 training steps: 0.14544961636352488\n","Training loss epoch: 0.14433859680966457\n","Training accuracy epoch: 0.9544117647058824\n","Validating model...\n","Validation Loss: 0.16025396850412055\n","Validation Accuracy: 0.9531151170145478\n","Training epoch: 2\n","Training loss per 100 training steps: 0.19302508234977722\n","Training loss per 100 training steps: 0.04828701523538347\n","Training loss per 100 training steps: 0.0473106864553677\n","Training loss per 100 training steps: 0.046546823343964434\n","Training loss per 100 training steps: 0.04821795837180294\n","Training loss per 100 training steps: 0.04840633767762011\n","Training loss per 100 training steps: 0.04819771062664861\n","Training loss per 100 training steps: 0.04966272622962667\n","Training loss per 100 training steps: 0.05166888650949723\n","Training loss per 100 training steps: 0.05079414143387774\n","Training loss per 100 training steps: 0.05122910263635531\n","Training loss per 100 training steps: 0.052431496363522304\n","Training loss per 100 training steps: 0.05303736775711242\n","Training loss epoch: 0.053446035353427686\n","Training accuracy epoch: 0.9837111928104575\n","Validating model...\n","Validation Loss: 0.1553041530652063\n","Validation Accuracy: 0.9610610373181531\n","Training epoch: 3\n","Training loss per 100 training steps: 0.004020565655082464\n","Training loss per 100 training steps: 0.02792454096327287\n","Training loss per 100 training steps: 0.029854599158546023\n","Training loss per 100 training steps: 0.02855012362888253\n","Training loss per 100 training steps: 0.029309262039355858\n","Training loss per 100 training steps: 0.028849388008643066\n","Training loss per 100 training steps: 0.03184371032236266\n","Training loss per 100 training steps: 0.03239879975984366\n","Training loss per 100 training steps: 0.03202975845333833\n","Training loss per 100 training steps: 0.03204518198045994\n","Training loss per 100 training steps: 0.03250183733490684\n","Training loss per 100 training steps: 0.032194067025239956\n","Training loss per 100 training steps: 0.032412677136908784\n","Training loss epoch: 0.03250249396715054\n","Training accuracy epoch: 0.9901960784313726\n","Validating model...\n","Validation Loss: 0.1703500980163203\n","Validation Accuracy: 0.9610808032890575\n","Training epoch: 4\n","Training loss per 100 training steps: 0.021718477830290794\n","Training loss per 100 training steps: 0.012381923685079708\n","Training loss per 100 training steps: 0.017312693447702848\n","Training loss per 100 training steps: 0.017529337651264913\n","Training loss per 100 training steps: 0.01884727972063777\n","Training loss per 100 training steps: 0.023598342200047792\n","Training loss per 100 training steps: 0.023398484126286978\n","Training loss per 100 training steps: 0.024351705884743287\n","Training loss per 100 training steps: 0.0257730719745819\n","Training loss per 100 training steps: 0.026000932735910632\n","Training loss per 100 training steps: 0.025956574943557208\n","Training loss per 100 training steps: 0.02647308425313117\n","Training loss per 100 training steps: 0.025958733262662285\n","Training loss epoch: 0.026183912202433775\n","Training accuracy epoch: 0.9920087826797386\n","Validating model...\n","Validation Loss: 0.19471248027106164\n","Validation Accuracy: 0.9524924889310563\n","Training epoch: 5\n","Training loss per 100 training steps: 0.003359454683959484\n","Training loss per 100 training steps: 0.025464874252245882\n","Training loss per 100 training steps: 0.02756337349516495\n","Training loss per 100 training steps: 0.024352527985399962\n","Training loss per 100 training steps: 0.02237787370285062\n","Training loss per 100 training steps: 0.0211917734828937\n","Training loss per 100 training steps: 0.022528644922963643\n","Training loss per 100 training steps: 0.02206018807750279\n","Training loss per 100 training steps: 0.02243348670774285\n","Training loss per 100 training steps: 0.0222664246002902\n","Training loss per 100 training steps: 0.02423418113822926\n","Training loss per 100 training steps: 0.02481629965708524\n","Training loss per 100 training steps: 0.02447673002468334\n","Training loss epoch: 0.024444996881559038\n","Training accuracy epoch: 0.9928002450980392\n","Validating model...\n","Validation Loss: 0.243905921281397\n","Validation Accuracy: 0.9574142156862745\n","Training epoch: 6\n","Training loss per 100 training steps: 0.010188951157033443\n","Training loss per 100 training steps: 0.018347995743728335\n","Training loss per 100 training steps: 0.01589066043814102\n","Training loss per 100 training steps: 0.012726581885227609\n","Training loss per 100 training steps: 0.014238594432976596\n","Training loss per 100 training steps: 0.013374132677174253\n","Training loss per 100 training steps: 0.013629396482767982\n","Training loss per 100 training steps: 0.015351446838106594\n","Training loss per 100 training steps: 0.016082877527776547\n","Training loss per 100 training steps: 0.017060743515634847\n","Training loss per 100 training steps: 0.01758642664188684\n","Training loss per 100 training steps: 0.018702403860700954\n","Training loss per 100 training steps: 0.01858530759787023\n","Training loss epoch: 0.019033255362599304\n","Training accuracy epoch: 0.9945720996732027\n","Validating model...\n","Validation Loss: 0.20597079504431368\n","Validation Accuracy: 0.9620098039215687\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0008586045587435365\n","Training loss per 100 training steps: 0.01640598584625796\n","Training loss per 100 training steps: 0.012176985825307433\n","Training loss per 100 training steps: 0.013967835431661498\n","Training loss per 100 training steps: 0.018814188686510556\n","Training loss per 100 training steps: 0.017337535728332507\n","Training loss per 100 training steps: 0.016605586678453313\n","Training loss per 100 training steps: 0.017070975473265033\n","Training loss per 100 training steps: 0.017535946443537426\n","Training loss per 100 training steps: 0.01783279946977239\n","Training loss per 100 training steps: 0.017940224610603517\n","Training loss per 100 training steps: 0.018448079815465757\n","Training loss per 100 training steps: 0.01835220103609991\n","Training loss epoch: 0.01846610150117342\n","Training accuracy epoch: 0.9941636029411766\n","Validating model...\n","Validation Loss: 0.21793810133885036\n","Validation Accuracy: 0.9521959993674889\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 64.62467756666668 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15410927276072336\n","Validation Accuracy: 0.9584418402777778\n","Validation duration: 2.3886434166666732 minutes\n","F1-score (test): 85.7%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.84      0.81      0.82      1170\n","        test       0.91      0.84      0.87      2464\n","   treatment       0.92      0.81      0.86      1244\n","\n","   micro avg       0.89      0.82      0.86      4878\n","   macro avg       0.89      0.82      0.85      4878\n","weighted avg       0.90      0.82      0.86      4878\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 39156\n","Points in y_train after augmentation: 39156\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.078758716583252\n","Training loss per 100 training steps: 0.324585930914572\n","Training loss per 100 training steps: 0.2612196903824065\n","Training loss per 100 training steps: 0.22147932417529861\n","Training loss per 100 training steps: 0.20401753360252278\n","Training loss per 100 training steps: 0.18822024016178207\n","Training loss per 100 training steps: 0.17813668663019994\n","Training loss per 100 training steps: 0.1711268787615708\n","Training loss per 100 training steps: 0.16529113086976446\n","Training loss per 100 training steps: 0.15838488070247747\n","Training loss per 100 training steps: 0.1523784751862894\n","Training loss per 100 training steps: 0.14825040844366796\n","Training loss per 100 training steps: 0.14343507429299882\n","Training loss epoch: 0.1429726165196032\n","Training accuracy epoch: 0.9554279003267974\n","Validating model...\n","Validation Loss: 0.12892801140654175\n","Validation Accuracy: 0.9601616856419988\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07791116088628769\n","Training loss per 100 training steps: 0.045055980547469586\n","Training loss per 100 training steps: 0.04898922537529925\n","Training loss per 100 training steps: 0.04547361273297644\n","Training loss per 100 training steps: 0.04877661967558898\n","Training loss per 100 training steps: 0.04741765478913563\n","Training loss per 100 training steps: 0.05044730599071232\n","Training loss per 100 training steps: 0.050464189720400524\n","Training loss per 100 training steps: 0.051548440576244386\n","Training loss per 100 training steps: 0.0516925929180764\n","Training loss per 100 training steps: 0.05151483890272306\n","Training loss per 100 training steps: 0.05207557533418279\n","Training loss per 100 training steps: 0.05094604460518849\n","Training loss epoch: 0.05102681320487237\n","Training accuracy epoch: 0.9848958333333334\n","Validating model...\n","Validation Loss: 0.17441000739470872\n","Validation Accuracy: 0.9540441176470589\n","Training epoch: 3\n","Training loss per 100 training steps: 0.01716546155512333\n","Training loss per 100 training steps: 0.02791136737548663\n","Training loss per 100 training steps: 0.02946818509429869\n","Training loss per 100 training steps: 0.028430564414454157\n","Training loss per 100 training steps: 0.030901784224584037\n","Training loss per 100 training steps: 0.029637433076893146\n","Training loss per 100 training steps: 0.02864621535458636\n","Training loss per 100 training steps: 0.03468442458322121\n","Training loss per 100 training steps: 0.035848672420971534\n","Training loss per 100 training steps: 0.037590604270652056\n","Training loss per 100 training steps: 0.037174614629719625\n","Training loss per 100 training steps: 0.03891223787198873\n","Training loss per 100 training steps: 0.03834813275817161\n","Training loss epoch: 0.038217183477755066\n","Training accuracy epoch: 0.9889450571895425\n","Validating model...\n","Validation Loss: 0.17500506880163563\n","Validation Accuracy: 0.9620098039215687\n","Training epoch: 4\n","Training loss per 100 training steps: 0.008213289082050323\n","Training loss per 100 training steps: 0.030944454517402215\n","Training loss per 100 training steps: 0.02599415859637263\n","Training loss per 100 training steps: 0.023618889194160955\n","Training loss per 100 training steps: 0.022349632540919488\n","Training loss per 100 training steps: 0.023915783933229316\n","Training loss per 100 training steps: 0.02584732839654718\n","Training loss per 100 training steps: 0.026089133780148877\n","Training loss per 100 training steps: 0.02570775584941605\n","Training loss per 100 training steps: 0.025490072069651\n","Training loss per 100 training steps: 0.026230045151597305\n","Training loss per 100 training steps: 0.02724622797569504\n","Training loss per 100 training steps: 0.02676338247589315\n","Training loss epoch: 0.026736099326775183\n","Training accuracy epoch: 0.9920598447712419\n","Validating model...\n","Validation Loss: 0.2004937556205322\n","Validation Accuracy: 0.9589460784313726\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0027961768209934235\n","Training loss per 100 training steps: 0.012574692869081742\n","Training loss per 100 training steps: 0.01623304128139778\n","Training loss per 100 training steps: 0.019096862340407472\n","Training loss per 100 training steps: 0.0182964797474286\n","Training loss per 100 training steps: 0.020280661905155806\n","Training loss per 100 training steps: 0.021114104731389423\n","Training loss per 100 training steps: 0.02165089266724036\n","Training loss per 100 training steps: 0.02081237713630909\n","Training loss per 100 training steps: 0.02040285482180843\n","Training loss per 100 training steps: 0.02076945705335242\n","Training loss per 100 training steps: 0.02093774478049986\n","Training loss per 100 training steps: 0.020621199441511157\n","Training loss epoch: 0.020498754189741234\n","Training accuracy epoch: 0.9938214869281046\n","Validating model...\n","Validation Loss: 0.1884825527318468\n","Validation Accuracy: 0.961703431372549\n","Training epoch: 6\n","Training loss per 100 training steps: 0.03556591272354126\n","Training loss per 100 training steps: 0.011310013757567936\n","Training loss per 100 training steps: 0.012738109166057438\n","Training loss per 100 training steps: 0.01700756571133214\n","Training loss per 100 training steps: 0.018485168825969695\n","Training loss per 100 training steps: 0.01982910803913282\n","Training loss per 100 training steps: 0.020154359944927168\n","Training loss per 100 training steps: 0.020065256331214608\n","Training loss per 100 training steps: 0.02086191978583173\n","Training loss per 100 training steps: 0.020819439244663063\n","Training loss per 100 training steps: 0.021150891380629373\n","Training loss per 100 training steps: 0.021295950052984076\n","Training loss per 100 training steps: 0.021972084931702975\n","Training loss epoch: 0.02167621220457649\n","Training accuracy epoch: 0.9933619281045751\n","Validating model...\n","Validation Loss: 0.20428765500472246\n","Validation Accuracy: 0.9604779411764706\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 54.62955839999998 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.13058673628041073\n","Validation Accuracy: 0.9598685056584363\n","Validation duration: 2.3534490666666597 minutes\n","F1-score (test): 86.7%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.85      0.80      0.82      1170\n","        test       0.85      0.93      0.89      2464\n","   treatment       0.87      0.86      0.87      1244\n","\n","   micro avg       0.85      0.88      0.87      4878\n","   macro avg       0.86      0.86      0.86      4878\n","weighted avg       0.85      0.88      0.87      4878\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 39156\n","Points in y_train after augmentation: 39156\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.02571964263916\n","Training loss per 100 training steps: 0.3219084577118554\n","Training loss per 100 training steps: 0.2512988806818033\n","Training loss per 100 training steps: 0.2250813901659559\n","Training loss per 100 training steps: 0.20671185431653574\n","Training loss per 100 training steps: 0.1944951096729946\n","Training loss per 100 training steps: 0.1860787469913839\n","Training loss per 100 training steps: 0.173413756959135\n","Training loss per 100 training steps: 0.16603235144356496\n","Training loss per 100 training steps: 0.15911359526785493\n","Training loss per 100 training steps: 0.15522060728725884\n","Training loss per 100 training steps: 0.14885964316610317\n","Training loss per 100 training steps: 0.14613344255163274\n","Training loss epoch: 0.1455171246837149\n","Training accuracy epoch: 0.9549632352941176\n","Validating model...\n","Validation Loss: 0.1420341980113995\n","Validation Accuracy: 0.9549533523086654\n","Training epoch: 2\n","Training loss per 100 training steps: 0.036885082721710205\n","Training loss per 100 training steps: 0.04324154996446859\n","Training loss per 100 training steps: 0.04847306697930566\n","Training loss per 100 training steps: 0.05147401274737293\n","Training loss per 100 training steps: 0.05136449247809995\n","Training loss per 100 training steps: 0.05173555067243118\n","Training loss per 100 training steps: 0.05026292441817258\n","Training loss per 100 training steps: 0.05082913985115193\n","Training loss per 100 training steps: 0.05151621875301999\n","Training loss per 100 training steps: 0.052369643352059056\n","Training loss per 100 training steps: 0.05243001534679363\n","Training loss per 100 training steps: 0.05308667696833942\n","Training loss per 100 training steps: 0.05421352971924452\n","Training loss epoch: 0.05423369001800893\n","Training accuracy epoch: 0.983312908496732\n","Validating model...\n","Validation Loss: 0.17434741968206843\n","Validation Accuracy: 0.9478969006957622\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04031825438141823\n","Training loss per 100 training steps: 0.01759315779292034\n","Training loss per 100 training steps: 0.03529655695307898\n","Training loss per 100 training steps: 0.036194547223959095\n","Training loss per 100 training steps: 0.03509016285018712\n","Training loss per 100 training steps: 0.03392518348882659\n","Training loss per 100 training steps: 0.032505022179261364\n","Training loss per 100 training steps: 0.0323347282462578\n","Training loss per 100 training steps: 0.03319026331759387\n","Training loss per 100 training steps: 0.03359402586038888\n","Training loss per 100 training steps: 0.03365047703561425\n","Training loss per 100 training steps: 0.03381277729161202\n","Training loss per 100 training steps: 0.033746594088062874\n","Training loss epoch: 0.033701719676767966\n","Training accuracy epoch: 0.9895833333333334\n","Validating model...\n","Validation Loss: 0.17805590457482692\n","Validation Accuracy: 0.9561788425047438\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0035360052715986967\n","Training loss per 100 training steps: 0.02084702061054684\n","Training loss per 100 training steps: 0.020961941538705255\n","Training loss per 100 training steps: 0.024277275747931298\n","Training loss per 100 training steps: 0.024212738982669745\n","Training loss per 100 training steps: 0.024969292480535497\n","Training loss per 100 training steps: 0.025982918579009525\n","Training loss per 100 training steps: 0.02596546742716288\n","Training loss per 100 training steps: 0.025750170788025283\n","Training loss per 100 training steps: 0.02626291766583976\n","Training loss per 100 training steps: 0.026146686150697405\n","Training loss per 100 training steps: 0.02616236200392004\n","Training loss per 100 training steps: 0.026150570515187287\n","Training loss epoch: 0.02646240614382383\n","Training accuracy epoch: 0.992468341503268\n","Validating model...\n","Validation Loss: 0.19739593071954362\n","Validation Accuracy: 0.9561788425047438\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0006413508672267199\n","Training loss per 100 training steps: 0.022076112653029677\n","Training loss per 100 training steps: 0.0202167322860616\n","Training loss per 100 training steps: 0.017366603270617464\n","Training loss per 100 training steps: 0.022472384626615126\n","Training loss per 100 training steps: 0.021562239291339727\n","Training loss per 100 training steps: 0.02020312713778453\n","Training loss per 100 training steps: 0.020424757375766007\n","Training loss per 100 training steps: 0.021840269828546467\n","Training loss per 100 training steps: 0.02189821023090557\n","Training loss per 100 training steps: 0.02281071923924766\n","Training loss per 100 training steps: 0.02270678700332561\n","Training loss per 100 training steps: 0.02318854314065422\n","Training loss epoch: 0.023328551798709858\n","Training accuracy epoch: 0.9930044934640523\n","Validating model...\n","Validation Loss: 0.19959249837191628\n","Validation Accuracy: 0.9549335863377609\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0006254191393963993\n","Training loss per 100 training steps: 0.01822696097692507\n","Training loss per 100 training steps: 0.015885693776877065\n","Training loss per 100 training steps: 0.013186315881009863\n","Training loss per 100 training steps: 0.01746606108897419\n","Training loss per 100 training steps: 0.016381535332702462\n","Training loss per 100 training steps: 0.015603779333156646\n","Training loss per 100 training steps: 0.01590129318534574\n","Training loss per 100 training steps: 0.015647460135682714\n","Training loss per 100 training steps: 0.01802152188284162\n","Training loss per 100 training steps: 0.018818038765695\n","Training loss per 100 training steps: 0.019147911782918737\n","Training loss per 100 training steps: 0.019581704790309972\n","Training loss epoch: 0.019354053656731113\n","Training accuracy epoch: 0.9945618872549019\n","Validating model...\n","Validation Loss: 0.20024716639611642\n","Validation Accuracy: 0.9607546647691335\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 55.333853866666686 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1411098350697473\n","Validation Accuracy: 0.9544632523148148\n","Validation duration: 2.371829733333349 minutes\n","F1-score (test): 84.3%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.72      0.87      0.79      1170\n","        test       0.91      0.82      0.86      2464\n","   treatment       0.87      0.84      0.86      1244\n","\n","   micro avg       0.85      0.84      0.84      4878\n","   macro avg       0.84      0.85      0.84      4878\n","weighted avg       0.86      0.84      0.84      4878\n","\n","!!!!!! Starting model number 5 !!!!!!\n","Points in X_train after augmentation: 39156\n","Points in y_train after augmentation: 39156\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7041548490524292\n","Training loss per 100 training steps: 0.331256231754133\n","Training loss per 100 training steps: 0.2562250534248589\n","Training loss per 100 training steps: 0.22714771697625666\n","Training loss per 100 training steps: 0.20270485571931648\n","Training loss per 100 training steps: 0.1886429356368344\n","Training loss per 100 training steps: 0.17736122350343278\n","Training loss per 100 training steps: 0.17074761640004144\n","Training loss per 100 training steps: 0.16415882899022466\n","Training loss per 100 training steps: 0.15894992731498156\n","Training loss per 100 training steps: 0.1531170496652433\n","Training loss per 100 training steps: 0.14875269921722362\n","Training loss per 100 training steps: 0.1455049080691602\n","Training loss epoch: 0.14489983014927513\n","Training accuracy epoch: 0.9558823529411765\n","Validating model...\n","Validation Loss: 0.13550734208604576\n","Validation Accuracy: 0.9589164294750159\n","Training epoch: 2\n","Training loss per 100 training steps: 0.02832172065973282\n","Training loss per 100 training steps: 0.0430223256716099\n","Training loss per 100 training steps: 0.0520326043676066\n","Training loss per 100 training steps: 0.053416274515819116\n","Training loss per 100 training steps: 0.050564292491415974\n","Training loss per 100 training steps: 0.050717622953970844\n","Training loss per 100 training steps: 0.05058791802226784\n","Training loss per 100 training steps: 0.04914411700926203\n","Training loss per 100 training steps: 0.0490208089515304\n","Training loss per 100 training steps: 0.049328493014422214\n","Training loss per 100 training steps: 0.049704714413851145\n","Training loss per 100 training steps: 0.0507382950346634\n","Training loss per 100 training steps: 0.05125316436782764\n","Training loss epoch: 0.05143004428102917\n","Training accuracy epoch: 0.9845281862745098\n","Validating model...\n","Validation Loss: 0.1552508640515061\n","Validation Accuracy: 0.9610906862745098\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0038629842456430197\n","Training loss per 100 training steps: 0.03634862639736108\n","Training loss per 100 training steps: 0.04020255461143473\n","Training loss per 100 training steps: 0.04048119961675504\n","Training loss per 100 training steps: 0.04020761526053298\n","Training loss per 100 training steps: 0.040803604808886035\n","Training loss per 100 training steps: 0.04038117501813804\n","Training loss per 100 training steps: 0.039346955323812036\n","Training loss per 100 training steps: 0.03955918968645431\n","Training loss per 100 training steps: 0.0385362305256244\n","Training loss per 100 training steps: 0.03844639870432228\n","Training loss per 100 training steps: 0.03826258015157991\n","Training loss per 100 training steps: 0.038038656332308206\n","Training loss epoch: 0.037702799460425415\n","Training accuracy epoch: 0.9882046568627451\n","Validating model...\n","Validation Loss: 0.17833692871927803\n","Validation Accuracy: 0.9601616856419988\n","Training epoch: 4\n","Training loss per 100 training steps: 0.02940130978822708\n","Training loss per 100 training steps: 0.021250403706920287\n","Training loss per 100 training steps: 0.028157490720295934\n","Training loss per 100 training steps: 0.026801524942431775\n","Training loss per 100 training steps: 0.02660512486319586\n","Training loss per 100 training steps: 0.023648521804048386\n","Training loss per 100 training steps: 0.02320763273056641\n","Training loss per 100 training steps: 0.023920454542345142\n","Training loss per 100 training steps: 0.025507502573197192\n","Training loss per 100 training steps: 0.02571693665053111\n","Training loss per 100 training steps: 0.025129350473525755\n","Training loss per 100 training steps: 0.025796596479748232\n","Training loss per 100 training steps: 0.026028983723057918\n","Training loss epoch: 0.02668725039922149\n","Training accuracy epoch: 0.9921875\n","Validating model...\n","Validation Loss: 0.161914613401499\n","Validation Accuracy: 0.9586397058823529\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0016440288163721561\n","Training loss per 100 training steps: 0.019929190091373825\n","Training loss per 100 training steps: 0.016808694706716\n","Training loss per 100 training steps: 0.015417766456142805\n","Training loss per 100 training steps: 0.016870540537402712\n","Training loss per 100 training steps: 0.015941709955196764\n","Training loss per 100 training steps: 0.017237676743135852\n","Training loss per 100 training steps: 0.017636807961640605\n","Training loss per 100 training steps: 0.018114756759401534\n","Training loss per 100 training steps: 0.01867872695587313\n","Training loss per 100 training steps: 0.01925782203667135\n","Training loss per 100 training steps: 0.019118269312738276\n","Training loss per 100 training steps: 0.01953336521141898\n","Training loss epoch: 0.019405495930228202\n","Training accuracy epoch: 0.9940767973856209\n","Validating model...\n","Validation Loss: 0.21207371322006843\n","Validation Accuracy: 0.9580170777988615\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00041348562808707356\n","Training loss per 100 training steps: 0.01938805003211912\n","Training loss per 100 training steps: 0.018106714392093066\n","Training loss per 100 training steps: 0.018886628915817612\n","Training loss per 100 training steps: 0.024409683933837207\n","Training loss per 100 training steps: 0.023419543966541053\n","Training loss per 100 training steps: 0.02429102202552466\n","Training loss per 100 training steps: 0.02394677622628796\n","Training loss per 100 training steps: 0.02377306650293591\n","Training loss per 100 training steps: 0.023120601392946992\n","Training loss per 100 training steps: 0.0225125270679838\n","Training loss per 100 training steps: 0.022664015178481323\n","Training loss per 100 training steps: 0.022563307801906917\n","Training loss epoch: 0.02250590569718613\n","Training accuracy epoch: 0.9934640522875817\n","Validating model...\n","Validation Loss: 0.20441751709643308\n","Validation Accuracy: 0.9570979601518027\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 55.23698741666667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.12559144988443693\n","Validation Accuracy: 0.9602502893518519\n","Validation duration: 2.3860968166666985 minutes\n","F1-score (test): 86.5%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.84      0.78      0.81      1170\n","        test       0.89      0.89      0.89      2464\n","   treatment       0.87      0.86      0.86      1244\n","\n","   micro avg       0.87      0.86      0.86      4878\n","   macro avg       0.87      0.84      0.85      4878\n","weighted avg       0.87      0.86      0.86      4878\n","\n","!!!!!! Starting model number 6 !!!!!!\n","Points in X_train after augmentation: 39156\n","Points in y_train after augmentation: 39156\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.953922152519226\n","Training loss per 100 training steps: 0.32372429229245325\n","Training loss per 100 training steps: 0.25145944298722256\n","Training loss per 100 training steps: 0.22281660231764727\n","Training loss per 100 training steps: 0.20209020026088542\n","Training loss per 100 training steps: 0.18963658138682057\n","Training loss per 100 training steps: 0.17865031288615962\n","Training loss per 100 training steps: 0.17084973096979061\n","Training loss per 100 training steps: 0.16433292997509158\n","Training loss per 100 training steps: 0.15693188613793863\n","Training loss per 100 training steps: 0.15121158605386092\n","Training loss per 100 training steps: 0.14805550226799172\n","Training loss per 100 training steps: 0.1431586297210903\n","Training loss epoch: 0.14196373818027924\n","Training accuracy epoch: 0.9550500408496733\n","Validating model...\n","Validation Loss: 0.14824465851929478\n","Validation Accuracy: 0.9552597248576851\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04329434409737587\n","Training loss per 100 training steps: 0.04687518992295286\n","Training loss per 100 training steps: 0.05116565092391478\n","Training loss per 100 training steps: 0.04937386586647202\n","Training loss per 100 training steps: 0.04734730721405473\n","Training loss per 100 training steps: 0.0483837865583251\n","Training loss per 100 training steps: 0.05004927177584967\n","Training loss per 100 training steps: 0.05022218956671171\n","Training loss per 100 training steps: 0.05009824849744955\n","Training loss per 100 training steps: 0.049668318611942076\n","Training loss per 100 training steps: 0.04929350319394184\n","Training loss per 100 training steps: 0.04943981159932139\n","Training loss per 100 training steps: 0.0503597597607912\n","Training loss epoch: 0.05022145932330769\n","Training accuracy epoch: 0.984375\n","Validating model...\n","Validation Loss: 0.14324765087233163\n","Validation Accuracy: 0.9629190385831752\n","Training epoch: 3\n","Training loss per 100 training steps: 0.017444077879190445\n","Training loss per 100 training steps: 0.03269906644709408\n","Training loss per 100 training steps: 0.032696073299559966\n","Training loss per 100 training steps: 0.03002909780770039\n","Training loss per 100 training steps: 0.030870973077173604\n","Training loss per 100 training steps: 0.030094354353441266\n","Training loss per 100 training steps: 0.0315667976030209\n","Training loss per 100 training steps: 0.03303469523142149\n","Training loss per 100 training steps: 0.032287800360686694\n","Training loss per 100 training steps: 0.03323841881216659\n","Training loss per 100 training steps: 0.03355068099452067\n","Training loss per 100 training steps: 0.03321726288236521\n","Training loss per 100 training steps: 0.03219607116560588\n","Training loss epoch: 0.03244203906364585\n","Training accuracy epoch: 0.9897722630718955\n","Validating model...\n","Validation Loss: 0.1714211389560517\n","Validation Accuracy: 0.9620098039215687\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0016180725069716573\n","Training loss per 100 training steps: 0.017310856849572964\n","Training loss per 100 training steps: 0.016475173258407978\n","Training loss per 100 training steps: 0.016281597179883204\n","Training loss per 100 training steps: 0.01685087071865085\n","Training loss per 100 training steps: 0.01913176133143906\n","Training loss per 100 training steps: 0.02106599585528849\n","Training loss per 100 training steps: 0.02100165371535882\n","Training loss per 100 training steps: 0.020581897318262325\n","Training loss per 100 training steps: 0.022002608988816657\n","Training loss per 100 training steps: 0.022465641095643057\n","Training loss per 100 training steps: 0.0236625410799222\n","Training loss per 100 training steps: 0.024194543477419637\n","Training loss epoch: 0.024226043968943498\n","Training accuracy epoch: 0.9927185457516341\n","Validating model...\n","Validation Loss: 0.20022217848956786\n","Validation Accuracy: 0.9604581752055661\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0013992454623803496\n","Training loss per 100 training steps: 0.02241315755971228\n","Training loss per 100 training steps: 0.016598545628210615\n","Training loss per 100 training steps: 0.013734539170351895\n","Training loss per 100 training steps: 0.01630754844745185\n","Training loss per 100 training steps: 0.016728795333612666\n","Training loss per 100 training steps: 0.016952099700054186\n","Training loss per 100 training steps: 0.016976950835326892\n","Training loss per 100 training steps: 0.01849925448490996\n","Training loss per 100 training steps: 0.017870678237250002\n","Training loss per 100 training steps: 0.01916040459032233\n","Training loss per 100 training steps: 0.02004396623880041\n","Training loss per 100 training steps: 0.02033138197996495\n","Training loss epoch: 0.020380910161328952\n","Training accuracy epoch: 0.9936938316993464\n","Validating model...\n","Validation Loss: 0.19828394625373597\n","Validation Accuracy: 0.9595588235294118\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0006057779537513852\n","Training loss per 100 training steps: 0.015474633067197369\n","Training loss per 100 training steps: 0.019096653493363362\n","Training loss per 100 training steps: 0.018561749804654373\n","Training loss per 100 training steps: 0.018497872490723537\n","Training loss per 100 training steps: 0.016788363755432453\n","Training loss per 100 training steps: 0.015090377874263313\n","Training loss per 100 training steps: 0.014410510177499619\n","Training loss per 100 training steps: 0.015063945520909755\n","Training loss per 100 training steps: 0.015777876827897882\n","Training loss per 100 training steps: 0.01610032115661068\n","Training loss per 100 training steps: 0.016614572208526048\n","Training loss per 100 training steps: 0.017022587974094103\n","Training loss epoch: 0.01732957960628637\n","Training accuracy epoch: 0.9950980392156863\n","Validating model...\n","Validation Loss: 0.17841384679709069\n","Validation Accuracy: 0.9613871758380772\n","Training epoch: 7\n","Training loss per 100 training steps: 0.007095607928931713\n","Training loss per 100 training steps: 0.027861488509017256\n","Training loss per 100 training steps: 0.022712914663076223\n","Training loss per 100 training steps: 0.021102998427160246\n","Training loss per 100 training steps: 0.018457361662571965\n","Training loss per 100 training steps: 0.016265062384448897\n","Training loss per 100 training steps: 0.016983474421482157\n","Training loss per 100 training steps: 0.01726930718823094\n","Training loss per 100 training steps: 0.017846311915473076\n","Training loss per 100 training steps: 0.01887017643862898\n","Training loss per 100 training steps: 0.018734074223070017\n","Training loss per 100 training steps: 0.01792719244572382\n","Training loss per 100 training steps: 0.017226597231411574\n","Training loss epoch: 0.017607079462120763\n","Training accuracy epoch: 0.9943065767973857\n","Validating model...\n","Validation Loss: 0.25716060765062493\n","Validation Accuracy: 0.950347881087919\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 62.785226750000035 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15763449504149524\n","Validation Accuracy: 0.9578068737139918\n","Validation duration: 2.3103499333332973 minutes\n","F1-score (test): 86.1%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.83      0.84      0.83      1170\n","        test       0.85      0.92      0.88      2464\n","   treatment       0.86      0.82      0.84      1244\n","\n","   micro avg       0.85      0.88      0.86      4878\n","   macro avg       0.84      0.86      0.85      4878\n","weighted avg       0.85      0.88      0.86      4878\n","\n","!!!!!! Starting model number 7 !!!!!!\n","Points in X_train after augmentation: 39156\n","Points in y_train after augmentation: 39156\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8589868545532227\n","Training loss per 100 training steps: 0.3455873953897764\n","Training loss per 100 training steps: 0.2793228942900896\n","Training loss per 100 training steps: 0.23615461389264988\n","Training loss per 100 training steps: 0.2116656093823345\n","Training loss per 100 training steps: 0.19912867114773233\n","Training loss per 100 training steps: 0.1861713978356547\n","Training loss per 100 training steps: 0.1738824717735024\n","Training loss per 100 training steps: 0.1665987782287859\n","Training loss per 100 training steps: 0.1621192812937189\n","Training loss per 100 training steps: 0.1558590607199405\n","Training loss per 100 training steps: 0.15054926250661155\n","Training loss per 100 training steps: 0.14527207011857896\n","Training loss epoch: 0.1440288863046661\n","Training accuracy epoch: 0.9545853758169934\n","Validating model...\n","Validation Loss: 0.14091120976909047\n","Validation Accuracy: 0.9589263124604681\n","Training epoch: 2\n","Training loss per 100 training steps: 0.03745049238204956\n","Training loss per 100 training steps: 0.04666279477994004\n","Training loss per 100 training steps: 0.049785837843268184\n","Training loss per 100 training steps: 0.04561963036909322\n","Training loss per 100 training steps: 0.04746748265613479\n","Training loss per 100 training steps: 0.049524965151254936\n","Training loss per 100 training steps: 0.049389634167015424\n","Training loss per 100 training steps: 0.051845995802714616\n","Training loss per 100 training steps: 0.05134268333856656\n","Training loss per 100 training steps: 0.05211707425853403\n","Training loss per 100 training steps: 0.05265882783298419\n","Training loss per 100 training steps: 0.05260487119500169\n","Training loss per 100 training steps: 0.05226704193196561\n","Training loss epoch: 0.052081922520776855\n","Training accuracy epoch: 0.9838643790849673\n","Validating model...\n","Validation Loss: 0.1545613265057624\n","Validation Accuracy: 0.9580170777988615\n","Training epoch: 3\n","Training loss per 100 training steps: 0.007062240969389677\n","Training loss per 100 training steps: 0.020057893676007868\n","Training loss per 100 training steps: 0.02425971241457624\n","Training loss per 100 training steps: 0.023626485545547103\n","Training loss per 100 training steps: 0.026484846578593926\n","Training loss per 100 training steps: 0.03142426385460124\n","Training loss per 100 training steps: 0.03334440504824092\n","Training loss per 100 training steps: 0.03399308838514703\n","Training loss per 100 training steps: 0.03534763092053769\n","Training loss per 100 training steps: 0.03468242109808492\n","Training loss per 100 training steps: 0.034754142580080784\n","Training loss per 100 training steps: 0.03399894706830661\n","Training loss per 100 training steps: 0.03418166437227982\n","Training loss epoch: 0.034233648857789255\n","Training accuracy epoch: 0.9897620506535948\n","Validating model...\n","Validation Loss: 0.16315962774188295\n","Validation Accuracy: 0.9604680581910183\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01245204545557499\n","Training loss per 100 training steps: 0.020628512699541978\n","Training loss per 100 training steps: 0.025714359654227168\n","Training loss per 100 training steps: 0.025076530341591154\n","Training loss per 100 training steps: 0.024235265564923628\n","Training loss per 100 training steps: 0.022853496771778895\n","Training loss per 100 training steps: 0.023393155456671318\n","Training loss per 100 training steps: 0.02388824776317207\n","Training loss per 100 training steps: 0.024644677835909335\n","Training loss per 100 training steps: 0.027710697244738822\n","Training loss per 100 training steps: 0.027812431195917604\n","Training loss per 100 training steps: 0.0275143436092243\n","Training loss per 100 training steps: 0.026956148717015807\n","Training loss epoch: 0.02750676481714822\n","Training accuracy epoch: 0.9912530637254903\n","Validating model...\n","Validation Loss: 0.1817673065507894\n","Validation Accuracy: 0.956791587602783\n","Training epoch: 5\n","Training loss per 100 training steps: 0.003664974821731448\n","Training loss per 100 training steps: 0.016411440845493615\n","Training loss per 100 training steps: 0.012557835039707012\n","Training loss per 100 training steps: 0.017459837885598066\n","Training loss per 100 training steps: 0.01687890714317275\n","Training loss per 100 training steps: 0.018227507709830507\n","Training loss per 100 training steps: 0.019723055836312748\n","Training loss per 100 training steps: 0.018994753377455386\n","Training loss per 100 training steps: 0.019204780195116868\n","Training loss per 100 training steps: 0.01934676551392394\n","Training loss per 100 training steps: 0.018880525424026712\n","Training loss per 100 training steps: 0.018973774252929457\n","Training loss per 100 training steps: 0.019471692044984036\n","Training loss epoch: 0.01936753923897425\n","Training accuracy epoch: 0.9945874183006536\n","Validating model...\n","Validation Loss: 0.21031783302454393\n","Validation Accuracy: 0.9610808032890575\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0029016376938670874\n","Training loss per 100 training steps: 0.017209731351289125\n","Training loss per 100 training steps: 0.01394875397003923\n","Training loss per 100 training steps: 0.012831228738708693\n","Training loss per 100 training steps: 0.011148502530857132\n","Training loss per 100 training steps: 0.013512786510502424\n","Training loss per 100 training steps: 0.014741494177253294\n","Training loss per 100 training steps: 0.01552590876297384\n","Training loss per 100 training steps: 0.016873098168374855\n","Training loss per 100 training steps: 0.017948947710410782\n","Training loss per 100 training steps: 0.019748347261535477\n","Training loss per 100 training steps: 0.019670158797074705\n","Training loss per 100 training steps: 0.019227590844942116\n","Training loss epoch: 0.019093207066602832\n","Training accuracy epoch: 0.9940257352941176\n","Validating model...\n","Validation Loss: 0.20242266294268368\n","Validation Accuracy: 0.9626126660341556\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 55.34544423333337 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.138811490584582\n","Validation Accuracy: 0.959398308899177\n","Validation duration: 2.395484549999977 minutes\n","F1-score (test): 86.3%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.77      0.83      0.80      1170\n","        test       0.88      0.91      0.89      2464\n","   treatment       0.89      0.83      0.86      1244\n","\n","   micro avg       0.85      0.87      0.86      4878\n","   macro avg       0.85      0.86      0.85      4878\n","weighted avg       0.86      0.87      0.86      4878\n","\n"]}],"source":["number_of_training_models = 7\n","target_augmented_percentage = 2\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TTDq-xbgHqXQ","outputId":"ac8d78e3-4f11-47ac-b3e6-18e616e82978"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 500% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 78312\n","Points in y_train after augmentation: 78312\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9732383489608765\n","Training loss per 100 training steps: 0.33665151993679526\n","Training loss per 100 training steps: 0.2663141649068143\n","Training loss per 100 training steps: 0.2299895799158766\n","Training loss per 100 training steps: 0.20599658447817118\n","Training loss per 100 training steps: 0.19293316075868325\n","Training loss per 100 training steps: 0.1829976627592326\n","Training loss per 100 training steps: 0.17317552613004772\n","Training loss per 100 training steps: 0.16447583763187545\n","Training loss per 100 training steps: 0.1586436227473847\n","Training loss per 100 training steps: 0.15289582919525252\n","Training loss per 100 training steps: 0.1481987458183646\n","Training loss per 100 training steps: 0.143602580720071\n","Training loss per 100 training steps: 0.13912465603963803\n","Training loss per 100 training steps: 0.13564421650051184\n","Training loss per 100 training steps: 0.13229312963166687\n","Training loss per 100 training steps: 0.12877821056705974\n","Training loss per 100 training steps: 0.12549109384667337\n","Training loss per 100 training steps: 0.12282250001062786\n","Training loss per 100 training steps: 0.12034010072737841\n","Training loss per 100 training steps: 0.11727844393195544\n","Training loss per 100 training steps: 0.11507983423700434\n","Training loss per 100 training steps: 0.11313417720969031\n","Training loss per 100 training steps: 0.1109214561442405\n","Training loss per 100 training steps: 0.10867943585680499\n","Training loss epoch: 0.10745764757999507\n","Training accuracy epoch: 0.9662607230392157\n","Validating model...\n","Validation Loss: 0.1892128879154174\n","Validation Accuracy: 0.9509803921568627\n","Training epoch: 2\n","Training loss per 100 training steps: 0.015727028250694275\n","Training loss per 100 training steps: 0.043354126399424445\n","Training loss per 100 training steps: 0.04010911770883151\n","Training loss per 100 training steps: 0.03875057094427215\n","Training loss per 100 training steps: 0.03824357529698599\n","Training loss per 100 training steps: 0.03964172446558405\n","Training loss per 100 training steps: 0.03786067044338794\n","Training loss per 100 training steps: 0.038601214933242665\n","Training loss per 100 training steps: 0.039980526810503805\n","Training loss per 100 training steps: 0.03957376790144579\n","Training loss per 100 training steps: 0.03957162895688804\n","Training loss per 100 training steps: 0.03927017328261502\n","Training loss per 100 training steps: 0.03931368648058186\n","Training loss per 100 training steps: 0.0394946612380071\n","Stopping epoch...\n","Training loss epoch: 0.0394946612380071\n","Training accuracy epoch: 0.9872694081475788\n","Validating model...\n","Validation Loss: 0.19087007337643003\n","Validation Accuracy: 0.9555660974067046\n","Training epoch: 3\n","Training loss per 100 training steps: 0.012597697786986828\n","Training loss per 100 training steps: 0.021009137107798195\n","Training loss per 100 training steps: 0.026709010343261952\n","Training loss per 100 training steps: 0.025729230394812404\n","Training loss per 100 training steps: 0.02566667685750146\n","Training loss per 100 training steps: 0.025838101489550503\n","Training loss per 100 training steps: 0.027403744292644413\n","Training loss per 100 training steps: 0.028137825540021644\n","Training loss per 100 training steps: 0.028960957335023768\n","Training loss per 100 training steps: 0.030128207033795054\n","Training loss per 100 training steps: 0.029712643737074468\n","Training loss per 100 training steps: 0.030740935295961606\n","Training loss per 100 training steps: 0.030385630345715967\n","Training loss per 100 training steps: 0.030670977112815034\n","Training loss per 100 training steps: 0.031033003649361172\n","Training loss per 100 training steps: 0.03066127411619213\n","Training loss per 100 training steps: 0.031196965305438962\n","Training loss per 100 training steps: 0.031457065205121024\n","Training loss per 100 training steps: 0.031776976686159183\n","Training loss per 100 training steps: 0.03164907307586191\n","Training loss per 100 training steps: 0.032297286938880045\n","Training loss per 100 training steps: 0.032209150350763396\n","Training loss per 100 training steps: 0.03226422629733567\n","Training loss per 100 training steps: 0.032535065107723436\n","Training loss per 100 training steps: 0.03269909657960131\n","Training loss epoch: 0.03286043553994591\n","Training accuracy epoch: 0.9902216094771242\n","Validating model...\n","Validation Loss: 0.22934886667073942\n","Validation Accuracy: 0.9448232922201139\n","Training epoch: 4\n","Training loss per 100 training steps: 0.14911732077598572\n","Training loss per 100 training steps: 0.019415646546236745\n","Training loss per 100 training steps: 0.036617557011256276\n","Training loss per 100 training steps: 0.035838687420742234\n","Training loss per 100 training steps: 0.03440341831914987\n","Training loss per 100 training steps: 0.03167262063500253\n","Training loss per 100 training steps: 0.029167922782929505\n","Training loss per 100 training steps: 0.02906306733537079\n","Training loss per 100 training steps: 0.028892576715408038\n","Training loss per 100 training steps: 0.028181974062536592\n","Training loss per 100 training steps: 0.027886872840580938\n","Training loss per 100 training steps: 0.028246060922538823\n","Training loss per 100 training steps: 0.02774135540811775\n","Training loss per 100 training steps: 0.02689659559166199\n","Training loss per 100 training steps: 0.027445375884935747\n","Training loss per 100 training steps: 0.027082693563747044\n","Training loss per 100 training steps: 0.026248777166689663\n","Training loss per 100 training steps: 0.026110503232331356\n","Training loss per 100 training steps: 0.025947518636702024\n","Training loss per 100 training steps: 0.025608632816181358\n","Training loss per 100 training steps: 0.02560617665417969\n","Training loss per 100 training steps: 0.02559044382614143\n","Training loss per 100 training steps: 0.025331525345618167\n","Training loss per 100 training steps: 0.02519708950085643\n","Training loss per 100 training steps: 0.02508871256086627\n","Training loss epoch: 0.025115844562543656\n","Training accuracy epoch: 0.9924938725490197\n","Validating model...\n","Validation Loss: 0.2120960392754105\n","Validation Accuracy: 0.9534313725490197\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0007166765280999243\n","Training loss per 100 training steps: 0.0289606723702734\n","Training loss per 100 training steps: 0.020107497125830726\n","Training loss per 100 training steps: 0.01787656381441705\n","Training loss per 100 training steps: 0.017908109862089856\n","Training loss per 100 training steps: 0.018843893028908765\n","Training loss per 100 training steps: 0.018108199797177975\n","Training loss per 100 training steps: 0.017708439620078616\n","Training loss per 100 training steps: 0.017808326151531634\n","Training loss per 100 training steps: 0.018314719483347494\n","Training loss per 100 training steps: 0.01780137131129311\n","Training loss per 100 training steps: 0.018912359083636615\n","Training loss per 100 training steps: 0.01911532938776068\n","Training loss per 100 training steps: 0.01969767204067687\n","Training loss per 100 training steps: 0.019450786397030424\n","Training loss per 100 training steps: 0.018813752988626767\n","Training loss per 100 training steps: 0.01845887938478922\n","Training loss per 100 training steps: 0.018202979783516773\n","Training loss per 100 training steps: 0.017769703875188645\n","Training loss per 100 training steps: 0.017536269545946493\n","Training loss per 100 training steps: 0.01773215823914802\n","Training loss per 100 training steps: 0.018358362656578055\n","Training loss per 100 training steps: 0.01838393914717982\n","Training loss per 100 training steps: 0.018456572965220814\n","Training loss per 100 training steps: 0.01866393505415692\n","Training loss epoch: 0.019000980361679885\n","Training accuracy epoch: 0.9945491217320261\n","Validating model...\n","Validation Loss: 0.23534677187939557\n","Validation Accuracy: 0.9469580170777989\n","Training epoch: 6\n","Training loss per 100 training steps: 0.002629158552736044\n","Training loss per 100 training steps: 0.011261168544758157\n","Training loss per 100 training steps: 0.018846596429076403\n","Training loss per 100 training steps: 0.018346254729545534\n","Training loss per 100 training steps: 0.017665259480748402\n","Training loss per 100 training steps: 0.017486203469422822\n","Training loss per 100 training steps: 0.01870052632272841\n","Training loss per 100 training steps: 0.01849675349011511\n","Training loss per 100 training steps: 0.018759856420713296\n","Training loss per 100 training steps: 0.01813462932259669\n","Training loss per 100 training steps: 0.017617259314921918\n","Training loss per 100 training steps: 0.01699028628837838\n","Training loss per 100 training steps: 0.016316281713378334\n","Training loss per 100 training steps: 0.016235290619367043\n","Training loss per 100 training steps: 0.016542701416522185\n","Training loss per 100 training steps: 0.016573936971269517\n","Training loss per 100 training steps: 0.016699376197117696\n","Training loss per 100 training steps: 0.01684071444651315\n","Training loss per 100 training steps: 0.01701492078256195\n","Training loss per 100 training steps: 0.01737830877008071\n","Training loss per 100 training steps: 0.018303663700643593\n","Training loss per 100 training steps: 0.018093251269588245\n","Training loss per 100 training steps: 0.01779807824572541\n","Training loss per 100 training steps: 0.018186979466784676\n","Training loss per 100 training steps: 0.018485756143845573\n","Training loss epoch: 0.01846476085970132\n","Training accuracy epoch: 0.9947916666666666\n","Validating model...\n","Validation Loss: 0.25355894740684615\n","Validation Accuracy: 0.9454558032890575\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 102.48416933333331 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.20025010521889003\n","Validation Accuracy: 0.9488932291666666\n","Validation duration: 2.4595518999999815 minutes\n","F1-score (test): 83.8%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.73      0.86      0.79      1170\n","        test       0.80      0.92      0.85      2464\n","   treatment       0.83      0.88      0.85      1244\n","\n","   micro avg       0.79      0.89      0.84      4878\n","   macro avg       0.79      0.89      0.83      4878\n","weighted avg       0.79      0.89      0.84      4878\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 78312\n","Points in y_train after augmentation: 78312\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.128765344619751\n","Training loss per 100 training steps: 0.36433345079421997\n","Training loss per 100 training steps: 0.27689993192455664\n","Training loss per 100 training steps: 0.2348312835837173\n","Training loss per 100 training steps: 0.2108196535419459\n","Training loss per 100 training steps: 0.19462786033840668\n","Training loss per 100 training steps: 0.1822418960887542\n","Training loss per 100 training steps: 0.17328782346512797\n","Training loss per 100 training steps: 0.16390687614253788\n","Training loss per 100 training steps: 0.15761691514613493\n","Training loss per 100 training steps: 0.152365700260817\n","Training loss per 100 training steps: 0.14718852649429318\n","Training loss per 100 training steps: 0.14282859714804907\n","Training loss per 100 training steps: 0.1370532220005087\n","Training loss per 100 training steps: 0.13409648699699891\n","Training loss per 100 training steps: 0.12984382953084658\n","Training loss per 100 training steps: 0.12713819013832592\n","Training loss per 100 training steps: 0.1241902595237122\n","Training loss per 100 training steps: 0.12206796338560132\n","Training loss per 100 training steps: 0.11922289238216797\n","Training loss per 100 training steps: 0.1166719882643136\n","Training loss per 100 training steps: 0.1140680310974316\n","Training loss per 100 training steps: 0.11183480892162423\n","Training loss per 100 training steps: 0.10999031325386634\n","Training loss per 100 training steps: 0.1078475537865387\n","Training loss epoch: 0.10714099512045447\n","Training accuracy epoch: 0.9663245506535948\n","Validating model...\n","Validation Loss: 0.15475507048512216\n","Validation Accuracy: 0.956791587602783\n","Training epoch: 2\n","Training loss per 100 training steps: 0.001427056617103517\n","Training loss per 100 training steps: 0.041175334148413255\n","Training loss per 100 training steps: 0.04130754118787579\n","Training loss per 100 training steps: 0.0360129388175716\n","Training loss per 100 training steps: 0.039274813612125245\n","Training loss per 100 training steps: 0.038499272960687086\n","Training loss per 100 training steps: 0.03917394918172672\n","Training loss per 100 training steps: 0.03859929583799665\n","Training loss per 100 training steps: 0.036642331470556316\n","Training loss per 100 training steps: 0.03718922464542668\n","Training loss per 100 training steps: 0.036378010727961055\n","Training loss per 100 training steps: 0.03581525340267532\n","Training loss per 100 training steps: 0.03584919721787667\n","Training loss per 100 training steps: 0.037047830566983644\n","Training loss per 100 training steps: 0.03744987522932115\n","Training loss per 100 training steps: 0.03775786964361929\n","Training loss per 100 training steps: 0.03801677184939142\n","Training loss per 100 training steps: 0.03811037255988195\n","Training loss per 100 training steps: 0.037643746821898715\n","Training loss per 100 training steps: 0.038094156854389764\n","Training loss per 100 training steps: 0.03794847790420677\n","Training loss per 100 training steps: 0.03794431990448433\n","Training loss per 100 training steps: 0.03768094599949438\n","Training loss per 100 training steps: 0.03740922350937121\n","Training loss per 100 training steps: 0.03691293950842733\n","Training loss epoch: 0.037167688069102416\n","Training accuracy epoch: 0.9888046364379085\n","Validating model...\n","Validation Loss: 0.2023460692315198\n","Validation Accuracy: 0.9506641366223909\n","Training epoch: 3\n","Training loss per 100 training steps: 0.009398517198860645\n","Training loss per 100 training steps: 0.012172528897875477\n","Training loss per 100 training steps: 0.01470979483883865\n","Training loss per 100 training steps: 0.017011242341621474\n","Training loss per 100 training steps: 0.020239380253896936\n","Training loss per 100 training steps: 0.022653046610429158\n","Training loss per 100 training steps: 0.023292563256283465\n","Training loss per 100 training steps: 0.022197033054584033\n","Training loss per 100 training steps: 0.023291432987174444\n","Training loss per 100 training steps: 0.023737486487161924\n","Training loss per 100 training steps: 0.023650785692797154\n","Training loss per 100 training steps: 0.023686679675177763\n","Training loss per 100 training steps: 0.02463344052267317\n","Training loss per 100 training steps: 0.024950612244606016\n","Training loss per 100 training steps: 0.024726379997492942\n","Training loss per 100 training steps: 0.024517338874062166\n","Training loss per 100 training steps: 0.024965093601254526\n","Training loss per 100 training steps: 0.025224744285997542\n","Training loss per 100 training steps: 0.024964006019101627\n","Training loss per 100 training steps: 0.024553092098298996\n","Training loss per 100 training steps: 0.025204391277340414\n","Training loss per 100 training steps: 0.0249233560524941\n","Training loss per 100 training steps: 0.025098049938583666\n","Training loss per 100 training steps: 0.02527722031346397\n","Training loss per 100 training steps: 0.02488537636449324\n","Training loss epoch: 0.02471295697441271\n","Training accuracy epoch: 0.9924555759803921\n","Validating model...\n","Validation Loss: 0.2164432680888864\n","Validation Accuracy: 0.9549434693232132\n","Training epoch: 4\n","Training loss per 100 training steps: 0.00242808205075562\n","Training loss per 100 training steps: 0.017427393698982437\n","Training loss per 100 training steps: 0.01607883213478429\n","Training loss per 100 training steps: 0.012164419396662275\n","Training loss per 100 training steps: 0.01158320800379642\n","Training loss per 100 training steps: 0.015235323041900313\n","Training loss per 100 training steps: 0.015559710023033482\n","Training loss per 100 training steps: 0.016418819738463625\n","Training loss per 100 training steps: 0.01670684872581032\n","Training loss per 100 training steps: 0.01802015695539537\n","Training loss per 100 training steps: 0.019336239540639875\n","Training loss per 100 training steps: 0.0191466729676101\n","Training loss per 100 training steps: 0.019377972626339682\n","Training loss per 100 training steps: 0.019076478055716873\n","Training loss per 100 training steps: 0.019059147877039252\n","Training loss per 100 training steps: 0.018809209564341005\n","Training loss per 100 training steps: 0.01854728851585895\n","Training loss per 100 training steps: 0.01823623839478282\n","Training loss per 100 training steps: 0.0190137764419898\n","Training loss per 100 training steps: 0.01936457391245663\n","Training loss per 100 training steps: 0.019247693249019374\n","Training loss per 100 training steps: 0.01969094564409863\n","Training loss per 100 training steps: 0.019637615053448722\n","Training loss per 100 training steps: 0.019966813315473387\n","Training loss per 100 training steps: 0.019900115084967637\n","Training loss epoch: 0.020092564241339952\n","Training accuracy epoch: 0.9939363766339869\n","Validating model...\n","Validation Loss: 0.20491669024340808\n","Validation Accuracy: 0.9512768817204301\n","Training epoch: 5\n","Training loss per 100 training steps: 0.11909794062376022\n","Training loss per 100 training steps: 0.017197943775508883\n","Training loss per 100 training steps: 0.011143339755429436\n","Training loss per 100 training steps: 0.014030967346617667\n","Training loss per 100 training steps: 0.01614142825096939\n","Training loss per 100 training steps: 0.015393875108452857\n","Training loss per 100 training steps: 0.01574170276993673\n","Training loss per 100 training steps: 0.015488175508444887\n","Training loss per 100 training steps: 0.015270929035530676\n","Training loss per 100 training steps: 0.01440378681721638\n","Training loss per 100 training steps: 0.014648624173967438\n","Training loss per 100 training steps: 0.016085662989709096\n","Training loss per 100 training steps: 0.01588477269919217\n","Training loss per 100 training steps: 0.015476006227842742\n","Training loss per 100 training steps: 0.016111256790248805\n","Training loss per 100 training steps: 0.016375246632800274\n","Training loss per 100 training steps: 0.017004813143251363\n","Training loss per 100 training steps: 0.017428853645164874\n","Training loss per 100 training steps: 0.018246857811420526\n","Training loss per 100 training steps: 0.018061909420375003\n","Training loss per 100 training steps: 0.01812865185948094\n","Training loss per 100 training steps: 0.018022709711023058\n","Training loss per 100 training steps: 0.018089055165066436\n","Training loss per 100 training steps: 0.017732758864982556\n","Training loss per 100 training steps: 0.01763128539439709\n","Training loss epoch: 0.017593029436438822\n","Training accuracy epoch: 0.9950086805555556\n","Validating model...\n","Validation Loss: 0.24212830826496323\n","Validation Accuracy: 0.9436076850094877\n","Training epoch: 6\n","Training loss per 100 training steps: 0.012204880826175213\n","Training loss per 100 training steps: 0.010399446842369582\n","Training loss per 100 training steps: 0.011807965492881517\n","Training loss per 100 training steps: 0.011759071355435937\n","Training loss per 100 training steps: 0.01689511530883764\n","Training loss per 100 training steps: 0.015281587850236582\n","Training loss per 100 training steps: 0.016178025563740765\n","Training loss per 100 training steps: 0.016797173541948797\n","Training loss per 100 training steps: 0.01616170423555142\n","Training loss per 100 training steps: 0.015893234211751418\n","Training loss per 100 training steps: 0.015268932125008024\n","Training loss per 100 training steps: 0.014288513766215401\n","Training loss per 100 training steps: 0.014516493687145799\n","Training loss per 100 training steps: 0.014176052621063702\n","Training loss per 100 training steps: 0.013839941825727347\n","Training loss per 100 training steps: 0.013701558671090413\n","Training loss per 100 training steps: 0.014548633327020008\n","Training loss per 100 training steps: 0.014615197397538216\n","Training loss per 100 training steps: 0.0147292998499799\n","Training loss per 100 training steps: 0.014848390830647\n","Training loss per 100 training steps: 0.014688902056187525\n","Training loss per 100 training steps: 0.014574808954707886\n","Training loss per 100 training steps: 0.014252135844142323\n","Training loss per 100 training steps: 0.014520456723060099\n","Training loss per 100 training steps: 0.014498680048142457\n","Training loss epoch: 0.014439781514451753\n","Training accuracy epoch: 0.9958001429738562\n","Validating model...\n","Validation Loss: 0.2545150744330849\n","Validation Accuracy: 0.9525122549019608\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 109.91915106666663 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1438548266936845\n","Validation Accuracy: 0.9582409014917695\n","Validation duration: 2.4236608833332864 minutes\n","F1-score (test): 86.2%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.85      0.82      0.83      1170\n","        test       0.89      0.88      0.88      2464\n","   treatment       0.84      0.85      0.85      1244\n","\n","   micro avg       0.87      0.86      0.86      4878\n","   macro avg       0.86      0.85      0.85      4878\n","weighted avg       0.87      0.86      0.86      4878\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 78312\n","Points in y_train after augmentation: 78312\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8416597843170166\n","Training loss per 100 training steps: 0.3450543340111133\n","Training loss per 100 training steps: 0.2625264359628828\n","Training loss per 100 training steps: 0.22168524187379995\n","Training loss per 100 training steps: 0.20421380624221522\n","Training loss per 100 training steps: 0.18675837528235661\n","Training loss per 100 training steps: 0.17945048107243391\n","Training loss per 100 training steps: 0.1703599784516606\n","Training loss per 100 training steps: 0.1622801845574684\n","Training loss per 100 training steps: 0.15714085896186258\n","Training loss per 100 training steps: 0.1518470989477418\n","Training loss per 100 training steps: 0.14719758837840788\n","Training loss per 100 training steps: 0.14135478024772655\n","Training loss per 100 training steps: 0.13775861422659444\n","Training loss per 100 training steps: 0.13359577147782695\n","Training loss per 100 training steps: 0.13003550416484058\n","Training loss per 100 training steps: 0.1264417307983053\n","Training loss per 100 training steps: 0.12430809718241334\n","Training loss per 100 training steps: 0.1226805245695374\n","Training loss per 100 training steps: 0.12064252744246566\n","Training loss per 100 training steps: 0.11774462436414047\n","Training loss per 100 training steps: 0.11586300381119082\n","Training loss per 100 training steps: 0.11373759976114066\n","Training loss per 100 training steps: 0.11120673148191192\n","Training loss per 100 training steps: 0.10910899220556192\n","Training loss epoch: 0.10815295942551993\n","Training accuracy epoch: 0.9665287990196079\n","Validating model...\n","Validation Loss: 0.20203513204115534\n","Validation Accuracy: 0.9552498418722328\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0015029190108180046\n","Training loss per 100 training steps: 0.0519463065187539\n","Training loss per 100 training steps: 0.048298530724097684\n","Training loss per 100 training steps: 0.0440150875107198\n","Training loss per 100 training steps: 0.045481796189663616\n","Training loss per 100 training steps: 0.045742205565991886\n","Training loss per 100 training steps: 0.044149740503551964\n","Training loss per 100 training steps: 0.045241017797711065\n","Training loss per 100 training steps: 0.043831718949865275\n","Training loss per 100 training steps: 0.043499994141240395\n","Training loss per 100 training steps: 0.043811963541355525\n","Training loss per 100 training steps: 0.042957364016948024\n","Training loss per 100 training steps: 0.042027743364907034\n","Training loss per 100 training steps: 0.04213406541852297\n","Training loss per 100 training steps: 0.04251936097195781\n","Training loss per 100 training steps: 0.04157226548973331\n","Training loss per 100 training steps: 0.04218840757974063\n","Training loss per 100 training steps: 0.042858723215365616\n","Training loss per 100 training steps: 0.04224369818972069\n","Training loss per 100 training steps: 0.04250939647722807\n","Training loss per 100 training steps: 0.04259793329405509\n","Training loss per 100 training steps: 0.04252859166621942\n","Training loss per 100 training steps: 0.042565713929248475\n","Stopping epoch...\n","Training loss epoch: 0.042565713929248475\n","Training accuracy epoch: 0.9869803498409814\n","Validating model...\n","Validation Loss: 0.1681813992649504\n","Validation Accuracy: 0.9583234503478811\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0734783411026001\n","Training loss per 100 training steps: 0.013805918901090251\n","Training loss per 100 training steps: 0.020153952275755564\n","Training loss per 100 training steps: 0.020880925185942444\n","Training loss per 100 training steps: 0.02020449934571841\n","Training loss per 100 training steps: 0.023063390536163842\n","Training loss per 100 training steps: 0.022512936258657384\n","Training loss per 100 training steps: 0.023768949592868818\n","Training loss per 100 training steps: 0.02400083182475599\n","Training loss per 100 training steps: 0.024462295439356983\n","Training loss per 100 training steps: 0.02464712134079908\n","Training loss per 100 training steps: 0.025859714966433564\n","Training loss per 100 training steps: 0.02656068710116305\n","Training loss per 100 training steps: 0.026892360074556206\n","Training loss per 100 training steps: 0.02721703505614004\n","Training loss per 100 training steps: 0.027396032680772234\n","Training loss per 100 training steps: 0.02766085543720951\n","Training loss per 100 training steps: 0.027832353764670387\n","Training loss per 100 training steps: 0.027522242128198628\n","Training loss per 100 training steps: 0.027492038371096043\n","Training loss per 100 training steps: 0.02767656951491581\n","Training loss per 100 training steps: 0.02800678400415772\n","Training loss per 100 training steps: 0.02836209972949592\n","Training loss per 100 training steps: 0.028091436954992687\n","Training loss per 100 training steps: 0.028360794385516842\n","Training loss epoch: 0.02829502960639432\n","Training accuracy epoch: 0.9917662377450981\n","Validating model...\n","Validation Loss: 0.20211098298308322\n","Validation Accuracy: 0.9531052340290955\n","Training epoch: 4\n","Training loss per 100 training steps: 0.013186393305659294\n","Training loss per 100 training steps: 0.015412086422386865\n","Training loss per 100 training steps: 0.020728056434532096\n","Training loss per 100 training steps: 0.017621588920501443\n","Training loss per 100 training steps: 0.017218722315425893\n","Training loss per 100 training steps: 0.016375564413153083\n","Training loss per 100 training steps: 0.017436309828248245\n","Training loss per 100 training steps: 0.017525839554820177\n","Training loss per 100 training steps: 0.018773453918732724\n","Training loss per 100 training steps: 0.018664021369278614\n","Training loss per 100 training steps: 0.020033580326487065\n","Training loss per 100 training steps: 0.020573069226413544\n","Training loss per 100 training steps: 0.020749878211123916\n","Training loss per 100 training steps: 0.021680020766074504\n","Training loss per 100 training steps: 0.021878339361690573\n","Training loss per 100 training steps: 0.021170692609683454\n","Training loss per 100 training steps: 0.021186479702277952\n","Training loss per 100 training steps: 0.021207695151088075\n","Training loss per 100 training steps: 0.020934787508444186\n","Training loss per 100 training steps: 0.021257429311467565\n","Training loss per 100 training steps: 0.021475490914244614\n","Training loss per 100 training steps: 0.02214825608668206\n","Training loss per 100 training steps: 0.02208341362947208\n","Training loss per 100 training steps: 0.021799756927493363\n","Training loss per 100 training steps: 0.021842683996763496\n","Training loss epoch: 0.02214319576704856\n","Training accuracy epoch: 0.9936683006535948\n","Validating model...\n","Validation Loss: 0.19411486348675966\n","Validation Accuracy: 0.955862586970272\n","Training epoch: 5\n","Training loss per 100 training steps: 0.005172466393560171\n","Training loss per 100 training steps: 0.01835406255835695\n","Training loss per 100 training steps: 0.01615932419761394\n","Training loss per 100 training steps: 0.01622560118086761\n","Training loss per 100 training steps: 0.01764058657895396\n","Training loss per 100 training steps: 0.017360902094926037\n","Training loss per 100 training steps: 0.018025563190565606\n","Training loss per 100 training steps: 0.018689016364337754\n","Training loss per 100 training steps: 0.023550604249138497\n","Training loss per 100 training steps: 0.02491071532358496\n","Training loss per 100 training steps: 0.026477156971017317\n","Training loss per 100 training steps: 0.026023587865649518\n","Training loss per 100 training steps: 0.025962662808753027\n","Training loss per 100 training steps: 0.025392554411134315\n","Training loss per 100 training steps: 0.024867678852526977\n","Training loss per 100 training steps: 0.024444612424344665\n","Training loss per 100 training steps: 0.0236967273452431\n","Training loss per 100 training steps: 0.0237358969464098\n","Training loss per 100 training steps: 0.024165734130723815\n","Training loss per 100 training steps: 0.024418604329514863\n","Training loss per 100 training steps: 0.024181284328583463\n","Training loss per 100 training steps: 0.02400010331011483\n","Training loss per 100 training steps: 0.02404157228339929\n","Training loss per 100 training steps: 0.024247560053476978\n","Training loss per 100 training steps: 0.02392294005045791\n","Training loss epoch: 0.02385031825564231\n","Training accuracy epoch: 0.9932853349673203\n","Validating model...\n","Validation Loss: 0.22376983187488947\n","Validation Accuracy: 0.9506542536369387\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0013501286739483476\n","Training loss per 100 training steps: 0.01743934686453598\n","Training loss per 100 training steps: 0.01744213594709852\n","Training loss per 100 training steps: 0.016290926212586845\n","Training loss per 100 training steps: 0.01450652316259975\n","Training loss per 100 training steps: 0.014023460366140666\n","Training loss per 100 training steps: 0.014501138183318978\n","Training loss per 100 training steps: 0.01564762621035259\n","Training loss per 100 training steps: 0.016720405336508724\n","Training loss per 100 training steps: 0.016404739143352397\n","Training loss per 100 training steps: 0.01710780383095167\n","Training loss per 100 training steps: 0.017427277779333252\n","Training loss per 100 training steps: 0.017790560177276073\n","Training loss per 100 training steps: 0.01821283675081108\n","Training loss per 100 training steps: 0.01760626426673754\n","Training loss per 100 training steps: 0.0179394175829972\n","Training loss per 100 training steps: 0.018184529180757705\n","Training loss per 100 training steps: 0.018046156220545766\n","Training loss per 100 training steps: 0.017920894494961453\n","Training loss per 100 training steps: 0.017967685268722954\n","Training loss per 100 training steps: 0.01833257999033117\n","Training loss per 100 training steps: 0.0181603125593708\n","Training loss per 100 training steps: 0.018090608501581534\n","Training loss per 100 training steps: 0.018113084437761915\n","Training loss per 100 training steps: 0.01819239557280927\n","Training loss epoch: 0.018073114315573582\n","Training accuracy epoch: 0.9951491013071896\n","Validating model...\n","Validation Loss: 0.24811712019907325\n","Validation Accuracy: 0.949745018975332\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0014865772100165486\n","Training loss per 100 training steps: 0.008340569283270927\n","Training loss per 100 training steps: 0.01275306343211299\n","Training loss per 100 training steps: 0.01301068534870188\n","Training loss per 100 training steps: 0.012173671830037494\n","Training loss per 100 training steps: 0.012375217478805637\n","Training loss per 100 training steps: 0.013358764911825229\n","Training loss per 100 training steps: 0.012560913022457272\n","Training loss per 100 training steps: 0.011934811246264212\n","Training loss per 100 training steps: 0.013845236018173853\n","Training loss per 100 training steps: 0.014252243760801413\n","Training loss per 100 training steps: 0.015234875166592424\n","Training loss per 100 training steps: 0.015376987288576286\n","Training loss per 100 training steps: 0.015437750216245594\n","Training loss per 100 training steps: 0.015333014957308462\n","Training loss per 100 training steps: 0.015352200890617685\n","Training loss per 100 training steps: 0.015300702836131296\n","Stopping epoch...\n","Training loss epoch: 0.015300702836131296\n","Training accuracy epoch: 0.9949445658963149\n","Validating model...\n","Validation Loss: 0.2854684854944079\n","Validation Accuracy: 0.9482230392156863\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 117.82383983333335 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16593914401669785\n","Validation Accuracy: 0.9565409593621399\n","Validation duration: 2.4015153833332685 minutes\n","F1-score (test): 85.7%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.75      0.86      0.80      1170\n","        test       0.86      0.91      0.88      2464\n","   treatment       0.93      0.80      0.86      1244\n","\n","   micro avg       0.84      0.87      0.86      4878\n","   macro avg       0.84      0.86      0.85      4878\n","weighted avg       0.85      0.87      0.86      4878\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 78312\n","Points in y_train after augmentation: 78312\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8724393844604492\n","Training loss per 100 training steps: 0.32894945011870697\n","Training loss per 100 training steps: 0.25730626915224747\n","Training loss per 100 training steps: 0.22415764463997362\n","Training loss per 100 training steps: 0.2090527093284148\n","Training loss per 100 training steps: 0.1940977598611124\n","Training loss per 100 training steps: 0.1827726862920191\n","Training loss per 100 training steps: 0.17206941847091597\n","Training loss per 100 training steps: 0.16599643870998643\n","Training loss per 100 training steps: 0.16029406164500956\n","Training loss per 100 training steps: 0.15334055866635815\n","Training loss per 100 training steps: 0.1477434754088905\n","Training loss per 100 training steps: 0.14276504089722766\n","Training loss per 100 training steps: 0.139612659985657\n","Training loss per 100 training steps: 0.1352885668135237\n","Training loss per 100 training steps: 0.13163294111298451\n","Training loss per 100 training steps: 0.1285186009912017\n","Training loss per 100 training steps: 0.12526404572914146\n","Training loss per 100 training steps: 0.12200861984161507\n","Training loss per 100 training steps: 0.11985409962779954\n","Training loss per 100 training steps: 0.11713400267216184\n","Training loss per 100 training steps: 0.11531380963141519\n","Training loss per 100 training steps: 0.11310413792209026\n","Training loss per 100 training steps: 0.11178061587045209\n","Training loss per 100 training steps: 0.11003054692930189\n","Training loss epoch: 0.10971968954808427\n","Training accuracy epoch: 0.9659926470588235\n","Validating model...\n","Validation Loss: 0.14165587692781734\n","Validation Accuracy: 0.9583234503478811\n","Training epoch: 2\n","Training loss per 100 training steps: 0.01093395333737135\n","Training loss per 100 training steps: 0.0292354391819779\n","Training loss per 100 training steps: 0.03322920578112594\n","Training loss per 100 training steps: 0.03287958491483759\n","Training loss per 100 training steps: 0.039166619841960446\n","Training loss per 100 training steps: 0.03997446949958072\n","Training loss per 100 training steps: 0.04093456074375405\n","Training loss per 100 training steps: 0.03926727128710522\n","Training loss per 100 training steps: 0.039544527154651586\n","Training loss per 100 training steps: 0.03853332158856427\n","Training loss per 100 training steps: 0.03934552516198841\n","Training loss per 100 training steps: 0.040827543409494724\n","Training loss per 100 training steps: 0.04209526205782606\n","Training loss per 100 training steps: 0.04287554471997643\n","Training loss per 100 training steps: 0.0424528333576091\n","Training loss per 100 training steps: 0.04258890719074498\n","Training loss per 100 training steps: 0.042746019893696564\n","Training loss per 100 training steps: 0.04256661055296611\n","Stopping epoch...\n","Training loss epoch: 0.04256661055296611\n","Training accuracy epoch: 0.9867173721340388\n","Validating model...\n","Validation Loss: 0.1794423372496157\n","Validation Accuracy: 0.9521959993674889\n","Training epoch: 3\n","Training loss per 100 training steps: 0.002254461869597435\n","Training loss per 100 training steps: 0.04982561444446426\n","Training loss per 100 training steps: 0.03889942965519485\n","Training loss per 100 training steps: 0.03551698673276333\n","Training loss per 100 training steps: 0.034533288421360726\n","Training loss per 100 training steps: 0.030485332185986216\n","Training loss per 100 training steps: 0.03130483073189184\n","Training loss per 100 training steps: 0.030059081230277045\n","Training loss per 100 training steps: 0.029531983163869926\n","Training loss per 100 training steps: 0.029628909639873337\n","Training loss per 100 training steps: 0.029120946262116344\n","Training loss per 100 training steps: 0.03008486641539522\n","Training loss per 100 training steps: 0.030773122717453274\n","Training loss per 100 training steps: 0.03126443537199285\n","Training loss per 100 training steps: 0.03156054212528445\n","Training loss per 100 training steps: 0.031508806401296434\n","Training loss per 100 training steps: 0.031858811968687235\n","Training loss per 100 training steps: 0.03210830402136619\n","Training loss per 100 training steps: 0.031729351036140836\n","Training loss per 100 training steps: 0.032044249694472726\n","Training loss per 100 training steps: 0.03191380846876108\n","Training loss per 100 training steps: 0.03197339652100348\n","Training loss per 100 training steps: 0.03243839840491644\n","Training loss per 100 training steps: 0.03257244959315404\n","Training loss per 100 training steps: 0.032853990182775\n","Training loss epoch: 0.03250071004982435\n","Training accuracy epoch: 0.9904513888888888\n","Validating model...\n","Validation Loss: 0.17494446732341792\n","Validation Accuracy: 0.9610906862745098\n","Training epoch: 4\n","Training loss per 100 training steps: 0.07670287042856216\n","Training loss per 100 training steps: 0.021329137275345845\n","Training loss per 100 training steps: 0.023717754621977283\n","Training loss per 100 training steps: 0.021642407819132112\n","Training loss per 100 training steps: 0.021560668635621616\n","Training loss per 100 training steps: 0.0224826304226214\n","Training loss per 100 training steps: 0.02185738637939579\n","Training loss per 100 training steps: 0.020921922044607827\n","Training loss per 100 training steps: 0.020319443901698993\n","Training loss per 100 training steps: 0.021525338962874733\n","Training loss per 100 training steps: 0.021858112881438154\n","Training loss per 100 training steps: 0.021602549583885702\n","Training loss per 100 training steps: 0.02154137061250164\n","Training loss per 100 training steps: 0.02163727606112311\n","Training loss per 100 training steps: 0.022134904572144617\n","Training loss per 100 training steps: 0.021882244491243933\n","Training loss per 100 training steps: 0.022334934771998046\n","Training loss per 100 training steps: 0.022550661305333237\n","Training loss per 100 training steps: 0.02286233640968295\n","Training loss per 100 training steps: 0.02276436491858719\n","Training loss per 100 training steps: 0.022792469830857608\n","Training loss per 100 training steps: 0.0227588781198609\n","Training loss per 100 training steps: 0.022843294150493347\n","Stopping epoch...\n","Training loss epoch: 0.022843294150493347\n","Training accuracy epoch: 0.9925176056338029\n","Validating model...\n","Validation Loss: 0.20986291227232226\n","Validation Accuracy: 0.9570880771663505\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0043498314917087555\n","Training loss per 100 training steps: 0.01993860931067709\n","Training loss per 100 training steps: 0.019061877823722043\n","Training loss per 100 training steps: 0.020773700143920684\n","Training loss per 100 training steps: 0.017758466484104375\n","Training loss per 100 training steps: 0.017505071585718634\n","Training loss per 100 training steps: 0.0182571606770601\n","Training loss per 100 training steps: 0.01929807755988179\n","Training loss per 100 training steps: 0.018687802178918335\n","Training loss per 100 training steps: 0.018825069750959832\n","Training loss per 100 training steps: 0.019635246476530307\n","Training loss per 100 training steps: 0.01883014169940397\n","Training loss per 100 training steps: 0.019734403371804758\n","Training loss per 100 training steps: 0.02140715995467674\n","Training loss per 100 training steps: 0.021989702548991283\n","Training loss per 100 training steps: 0.02216841549237916\n","Training loss per 100 training steps: 0.022088401408561994\n","Training loss per 100 training steps: 0.022007192753877036\n","Training loss per 100 training steps: 0.021262487235722844\n","Training loss per 100 training steps: 0.020986648102418518\n","Training loss per 100 training steps: 0.021069786060154052\n","Training loss per 100 training steps: 0.021104925621255582\n","Training loss per 100 training steps: 0.02105316739061581\n","Training loss per 100 training steps: 0.021191914572707138\n","Stopping epoch...\n","Training loss epoch: 0.021191914572707138\n","Training accuracy epoch: 0.9931279878313777\n","Validating model...\n","Validation Loss: 0.19560972316614034\n","Validation Accuracy: 0.9561689595192916\n","Training epoch: 6\n","Training loss per 100 training steps: 0.06216618791222572\n","Training loss per 100 training steps: 0.014946978154683273\n","Training loss per 100 training steps: 0.016181989860215885\n","Training loss per 100 training steps: 0.01597123528309352\n","Training loss per 100 training steps: 0.015694108285888637\n","Training loss per 100 training steps: 0.01660127450159343\n","Training loss per 100 training steps: 0.015224279945455926\n","Training loss per 100 training steps: 0.01625634110027432\n","Training loss per 100 training steps: 0.01495054928986764\n","Training loss per 100 training steps: 0.016839575177805974\n","Training loss per 100 training steps: 0.016607826816673856\n","Training loss per 100 training steps: 0.01696872102497231\n","Training loss per 100 training steps: 0.01713041073529285\n","Training loss per 100 training steps: 0.017410795625893954\n","Training loss per 100 training steps: 0.017713077798178347\n","Training loss per 100 training steps: 0.017873209697286653\n","Training loss per 100 training steps: 0.01760712984829754\n","Training loss per 100 training steps: 0.017734618616147318\n","Training loss per 100 training steps: 0.017544770214621756\n","Training loss per 100 training steps: 0.017582848738588355\n","Training loss per 100 training steps: 0.017624155080040404\n","Training loss per 100 training steps: 0.01739223142568313\n","Training loss per 100 training steps: 0.017104129159631404\n","Training loss per 100 training steps: 0.016979877449782833\n","Training loss per 100 training steps: 0.017161391192516556\n","Training loss epoch: 0.01750025020043657\n","Training accuracy epoch: 0.9948810253267973\n","Validating model...\n","Validation Loss: 0.2084302828252297\n","Validation Accuracy: 0.9518797438330171\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 102.58518858333336 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14750519710651133\n","Validation Accuracy: 0.9552228009259259\n","Validation duration: 2.4693047333332894 minutes\n","F1-score (test): 85.4%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.82      0.80      0.81      1170\n","        test       0.83      0.92      0.87      2464\n","   treatment       0.86      0.86      0.86      1244\n","\n","   micro avg       0.83      0.87      0.85      4878\n","   macro avg       0.84      0.86      0.85      4878\n","weighted avg       0.83      0.87      0.85      4878\n","\n","!!!!!! Starting model number 5 !!!!!!\n","Points in X_train after augmentation: 78312\n","Points in y_train after augmentation: 78312\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.237114191055298\n","Training loss per 100 training steps: 0.3317543575447975\n","Training loss per 100 training steps: 0.2674332705988961\n","Training loss per 100 training steps: 0.2303751418583615\n","Training loss per 100 training steps: 0.20829662308561386\n","Training loss per 100 training steps: 0.1998609075631329\n","Training loss per 100 training steps: 0.1849183147484917\n","Training loss per 100 training steps: 0.17665973553080616\n","Training loss per 100 training steps: 0.16819209269318874\n","Training loss per 100 training steps: 0.15955590630197208\n","Training loss per 100 training steps: 0.15425372121927255\n","Training loss per 100 training steps: 0.14863289287239803\n","Training loss per 100 training steps: 0.1443201116321889\n","Training loss per 100 training steps: 0.1412501840789206\n","Training loss per 100 training steps: 0.13768319048680136\n","Training loss per 100 training steps: 0.13543769855968665\n","Training loss per 100 training steps: 0.1323024767161877\n","Training loss per 100 training steps: 0.12913431337702502\n","Training loss per 100 training steps: 0.1259273699010184\n","Training loss per 100 training steps: 0.12385248080728088\n","Training loss per 100 training steps: 0.12083438314121171\n","Training loss per 100 training steps: 0.11890629148889804\n","Training loss per 100 training steps: 0.11590078407996925\n","Training loss per 100 training steps: 0.11372558666118034\n","Training loss per 100 training steps: 0.11158517531624222\n","Training loss epoch: 0.11063067428508505\n","Training accuracy epoch: 0.9659160539215687\n","Validating model...\n","Validation Loss: 0.15191313558984\n","Validation Accuracy: 0.9607645477545858\n","Training epoch: 2\n","Training loss per 100 training steps: 0.03734001889824867\n","Training loss per 100 training steps: 0.03656532259088581\n","Training loss per 100 training steps: 0.03984173960098765\n","Training loss per 100 training steps: 0.041177753420961256\n","Training loss per 100 training steps: 0.04327305529380979\n","Training loss per 100 training steps: 0.042912926021340614\n","Training loss per 100 training steps: 0.04218682641250247\n","Training loss per 100 training steps: 0.040360437442642234\n","Training loss per 100 training steps: 0.04050796655215702\n","Training loss per 100 training steps: 0.03984073012651587\n","Training loss per 100 training steps: 0.04055176276056404\n","Training loss per 100 training steps: 0.040722263541510775\n","Training loss per 100 training steps: 0.04163232586437877\n","Training loss per 100 training steps: 0.041577991166037165\n","Training loss per 100 training steps: 0.041497682317727276\n","Training loss per 100 training steps: 0.04131668240424394\n","Training loss per 100 training steps: 0.041284046661747745\n","Stopping epoch...\n","Training loss epoch: 0.041284046661747745\n","Training accuracy epoch: 0.9867465646470955\n","Validating model...\n","Validation Loss: 0.21418377770768368\n","Validation Accuracy: 0.9506443706514864\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0016702674329280853\n","Training loss per 100 training steps: 0.037014338668806955\n","Training loss per 100 training steps: 0.03330901351949057\n","Training loss per 100 training steps: 0.031658652597172744\n","Training loss per 100 training steps: 0.03203797268482654\n","Training loss per 100 training steps: 0.032856138794580214\n","Training loss per 100 training steps: 0.033169212180248674\n","Training loss per 100 training steps: 0.032389696230662665\n","Training loss per 100 training steps: 0.031593119051854926\n","Training loss per 100 training steps: 0.03216603426905217\n","Training loss per 100 training steps: 0.03236109883603619\n","Training loss per 100 training steps: 0.03273942372293521\n","Training loss per 100 training steps: 0.032647942395985605\n","Training loss per 100 training steps: 0.032940949508557464\n","Training loss per 100 training steps: 0.032582438530583284\n","Training loss per 100 training steps: 0.03165399840246809\n","Training loss per 100 training steps: 0.031769974580378585\n","Training loss per 100 training steps: 0.03191731190592695\n","Training loss per 100 training steps: 0.03180358090502927\n","Training loss per 100 training steps: 0.03125316812516353\n","Training loss per 100 training steps: 0.03150561713797312\n","Training loss per 100 training steps: 0.03194824299655283\n","Training loss per 100 training steps: 0.03202313826107046\n","Training loss per 100 training steps: 0.03201250205169817\n","Training loss per 100 training steps: 0.03191923700445078\n","Training loss epoch: 0.031664018991627955\n","Training accuracy epoch: 0.9905024509803921\n","Validating model...\n","Validation Loss: 0.19933648381094612\n","Validation Accuracy: 0.9574142156862745\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0005137261468917131\n","Training loss per 100 training steps: 0.026669629551539436\n","Training loss per 100 training steps: 0.02343791702494954\n","Training loss per 100 training steps: 0.02203650614482651\n","Training loss per 100 training steps: 0.023380810636786067\n","Training loss per 100 training steps: 0.02255523016860108\n","Training loss per 100 training steps: 0.023705037540063485\n","Training loss per 100 training steps: 0.02415213295332151\n","Training loss per 100 training steps: 0.025002573700807756\n","Training loss per 100 training steps: 0.024729084433663687\n","Training loss per 100 training steps: 0.024205925319796557\n","Training loss per 100 training steps: 0.02360000613155681\n","Training loss per 100 training steps: 0.02367437532542178\n","Training loss per 100 training steps: 0.023442394987002287\n","Training loss per 100 training steps: 0.023581593896491355\n","Training loss per 100 training steps: 0.023548298854455536\n","Stopping epoch...\n","Training loss epoch: 0.023548298854455536\n","Training accuracy epoch: 0.9920677881412392\n","Validating model...\n","Validation Loss: 0.19630847822740108\n","Validation Accuracy: 0.9537377450980392\n","Training epoch: 5\n","Training loss per 100 training steps: 0.03996178135275841\n","Training loss per 100 training steps: 0.01903771829680715\n","Training loss per 100 training steps: 0.015774441746426098\n","Training loss per 100 training steps: 0.01677074637325895\n","Training loss per 100 training steps: 0.016239497678219677\n","Training loss per 100 training steps: 0.0179899894529461\n","Training loss per 100 training steps: 0.018464520203159616\n","Training loss per 100 training steps: 0.017875013218144886\n","Training loss per 100 training steps: 0.017437818323758146\n","Training loss per 100 training steps: 0.01734897976106434\n","Training loss per 100 training steps: 0.018602017726168908\n","Training loss per 100 training steps: 0.01873723863703259\n","Training loss per 100 training steps: 0.018509967030692378\n","Training loss per 100 training steps: 0.017826636455980906\n","Training loss per 100 training steps: 0.017783649505145667\n","Training loss per 100 training steps: 0.017441621364549315\n","Training loss per 100 training steps: 0.017902363338076335\n","Training loss per 100 training steps: 0.01850897714635258\n","Training loss per 100 training steps: 0.018662669783819155\n","Training loss per 100 training steps: 0.01862999271772877\n","Training loss per 100 training steps: 0.01897185293673447\n","Training loss per 100 training steps: 0.01939831132359077\n","Training loss per 100 training steps: 0.019815939030620497\n","Training loss per 100 training steps: 0.01990666404395812\n","Training loss per 100 training steps: 0.020056956560794335\n","Training loss epoch: 0.020248080913782305\n","Training accuracy epoch: 0.9941023284313726\n","Validating model...\n","Validation Loss: 0.22366028099678065\n","Validation Accuracy: 0.9540243516761544\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0013377919094637036\n","Training loss per 100 training steps: 0.010493218901510682\n","Training loss per 100 training steps: 0.01487556241262433\n","Training loss per 100 training steps: 0.01533107022436543\n","Training loss per 100 training steps: 0.014926338235286914\n","Training loss per 100 training steps: 0.014145133869086732\n","Training loss per 100 training steps: 0.014127092434793785\n","Training loss per 100 training steps: 0.015289004033215686\n","Training loss per 100 training steps: 0.015048087464112334\n","Training loss per 100 training steps: 0.015014502539796035\n","Training loss per 100 training steps: 0.015168620794788517\n","Training loss per 100 training steps: 0.015117674668288172\n","Training loss per 100 training steps: 0.01622926508574889\n","Training loss per 100 training steps: 0.015892826835306097\n","Training loss per 100 training steps: 0.016179891177755774\n","Training loss per 100 training steps: 0.016605964219252502\n","Training loss per 100 training steps: 0.01620233879556117\n","Training loss per 100 training steps: 0.016511337579892222\n","Training loss per 100 training steps: 0.016447762113914632\n","Training loss per 100 training steps: 0.01683775583049604\n","Training loss per 100 training steps: 0.016803219977505546\n","Training loss per 100 training steps: 0.017021537846611482\n","Training loss per 100 training steps: 0.01731017698848448\n","Training loss per 100 training steps: 0.017208894325773477\n","Training loss per 100 training steps: 0.016936399809491073\n","Training loss epoch: 0.016802661272506715\n","Training accuracy epoch: 0.9951363357843137\n","Validating model...\n","Validation Loss: 0.267905573126008\n","Validation Accuracy: 0.9506740196078431\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 94.78689508333325 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15286656224769238\n","Validation Accuracy: 0.9557452417695473\n","Validation duration: 2.39677151666668 minutes\n","F1-score (test): 85.1%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.73      0.88      0.80      1170\n","        test       0.87      0.89      0.88      2464\n","   treatment       0.89      0.80      0.84      1244\n","\n","   micro avg       0.84      0.86      0.85      4878\n","   macro avg       0.83      0.86      0.84      4878\n","weighted avg       0.84      0.86      0.85      4878\n","\n","!!!!!! Starting model number 6 !!!!!!\n","Points in X_train after augmentation: 78312\n","Points in y_train after augmentation: 78312\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8841220140457153\n","Training loss per 100 training steps: 0.3272102980477975\n","Training loss per 100 training steps: 0.27133665310765676\n","Training loss per 100 training steps: 0.23266284902923526\n","Training loss per 100 training steps: 0.21140616920374872\n","Training loss per 100 training steps: 0.19439386071204143\n","Training loss per 100 training steps: 0.18535439023777484\n","Training loss per 100 training steps: 0.17364955088190107\n","Training loss per 100 training steps: 0.16514958545784192\n","Training loss per 100 training steps: 0.15847551519388164\n","Training loss per 100 training steps: 0.15184207998107296\n","Training loss per 100 training steps: 0.14487993128899718\n","Training loss per 100 training steps: 0.1406357299026992\n","Training loss per 100 training steps: 0.13577376700589486\n","Training loss per 100 training steps: 0.13146004711118575\n","Training loss per 100 training steps: 0.12896447554753435\n","Training loss per 100 training steps: 0.12727034864806133\n","Training loss per 100 training steps: 0.12473114101925366\n","Training loss per 100 training steps: 0.12210617712541803\n","Training loss per 100 training steps: 0.11982667679374358\n","Training loss per 100 training steps: 0.11789549632814886\n","Training loss per 100 training steps: 0.11546217542988221\n","Training loss per 100 training steps: 0.11328585695274668\n","Training loss per 100 training steps: 0.1114658882096683\n","Training loss per 100 training steps: 0.10984380744088396\n","Training loss epoch: 0.1094472771347605\n","Training accuracy epoch: 0.9656224468954249\n","Validating model...\n","Validation Loss: 0.15306540502762586\n","Validation Accuracy: 0.9570979601518027\n","Training epoch: 2\n","Training loss per 100 training steps: 0.16192349791526794\n","Training loss per 100 training steps: 0.04250601653383104\n","Training loss per 100 training steps: 0.039531026808174316\n","Training loss per 100 training steps: 0.03653763835749626\n","Training loss per 100 training steps: 0.03742558004628075\n","Training loss per 100 training steps: 0.037419069749793456\n","Training loss per 100 training steps: 0.0394006852234792\n","Training loss per 100 training steps: 0.03786133621073163\n","Training loss per 100 training steps: 0.03772932579674754\n","Training loss per 100 training steps: 0.03803951402222448\n","Training loss per 100 training steps: 0.037442071412030105\n","Training loss per 100 training steps: 0.03744605524676597\n","Training loss per 100 training steps: 0.03784390543229827\n","Training loss per 100 training steps: 0.03770074356479039\n","Training loss per 100 training steps: 0.03787146793965245\n","Training loss per 100 training steps: 0.03859140933987664\n","Training loss per 100 training steps: 0.03856344176933337\n","Training loss per 100 training steps: 0.038318657926010705\n","Training loss per 100 training steps: 0.03820242607300087\n","Training loss per 100 training steps: 0.037741419182279405\n","Training loss per 100 training steps: 0.03732137481068597\n","Training loss per 100 training steps: 0.03767305922734593\n","Training loss per 100 training steps: 0.03747740920054518\n","Training loss per 100 training steps: 0.03718890855624487\n","Training loss per 100 training steps: 0.03709738733315555\n","Training loss epoch: 0.03716965714911745\n","Training accuracy epoch: 0.9886769812091504\n","Validating model...\n","Validation Loss: 0.18554493406897082\n","Validation Accuracy: 0.9518995098039216\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0015829142648726702\n","Training loss per 100 training steps: 0.01621735859477874\n","Training loss per 100 training steps: 0.014922157429295953\n","Training loss per 100 training steps: 0.014997002680849672\n","Training loss per 100 training steps: 0.01758511537035364\n","Training loss per 100 training steps: 0.020842085452847627\n","Training loss per 100 training steps: 0.02251059688304987\n","Training loss per 100 training steps: 0.023406021579001794\n","Training loss per 100 training steps: 0.02394284217127583\n","Training loss per 100 training steps: 0.024355067655876955\n","Training loss per 100 training steps: 0.02426242430986646\n","Training loss per 100 training steps: 0.024551914858771864\n","Training loss per 100 training steps: 0.02421737454148072\n","Training loss per 100 training steps: 0.023732874589304287\n","Training loss per 100 training steps: 0.023683053870692108\n","Training loss per 100 training steps: 0.02413987771942048\n","Training loss per 100 training steps: 0.023827246516121725\n","Training loss per 100 training steps: 0.024613623983408474\n","Training loss per 100 training steps: 0.024928029932212256\n","Training loss per 100 training steps: 0.025131119929929384\n","Training loss per 100 training steps: 0.02485721836134941\n","Training loss per 100 training steps: 0.025359078617840126\n","Training loss per 100 training steps: 0.02591996011294971\n","Training loss per 100 training steps: 0.026218469397445408\n","Training loss per 100 training steps: 0.026591244675594282\n","Training loss epoch: 0.026565422891887163\n","Training accuracy epoch: 0.9920087826797386\n","Validating model...\n","Validation Loss: 0.2258940520846141\n","Validation Accuracy: 0.9509705091714105\n","Training epoch: 4\n","Training loss per 100 training steps: 0.007479136344045401\n","Training loss per 100 training steps: 0.014518002156193581\n","Training loss per 100 training steps: 0.014440901808457193\n","Training loss per 100 training steps: 0.016121407566015628\n","Training loss per 100 training steps: 0.016509735368923348\n","Training loss per 100 training steps: 0.015484882256162758\n","Training loss per 100 training steps: 0.015449567214000277\n","Training loss per 100 training steps: 0.01623689954398853\n","Training loss per 100 training steps: 0.016801453508405725\n","Training loss per 100 training steps: 0.016925683784711158\n","Training loss per 100 training steps: 0.017134527424783302\n","Training loss per 100 training steps: 0.01755685495087192\n","Training loss per 100 training steps: 0.019353407464374438\n","Training loss per 100 training steps: 0.02022704779437041\n","Training loss per 100 training steps: 0.019857743327114055\n","Training loss per 100 training steps: 0.019769359606312823\n","Training loss per 100 training steps: 0.02013677365220673\n","Training loss per 100 training steps: 0.0197592391324948\n","Training loss per 100 training steps: 0.019649402153104758\n","Training loss per 100 training steps: 0.01957853025557321\n","Training loss per 100 training steps: 0.019581088357951523\n","Training loss per 100 training steps: 0.02003126969777535\n","Training loss per 100 training steps: 0.020131716305875257\n","Training loss per 100 training steps: 0.0201509236478044\n","Training loss per 100 training steps: 0.020291674007813135\n","Training loss epoch: 0.02049646042040597\n","Training accuracy epoch: 0.9938342524509803\n","Validating model...\n","Validation Loss: 0.17869988403582088\n","Validation Accuracy: 0.9549632352941176\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0004592325130943209\n","Training loss per 100 training steps: 0.017269392548985366\n","Training loss per 100 training steps: 0.016565722407279677\n","Training loss per 100 training steps: 0.015538309361451876\n","Training loss per 100 training steps: 0.014539331995444884\n","Training loss per 100 training steps: 0.014159276242104014\n","Training loss per 100 training steps: 0.013731687576662311\n","Training loss per 100 training steps: 0.01408659915776326\n","Training loss per 100 training steps: 0.013142498755269742\n","Training loss per 100 training steps: 0.013480994854620556\n","Training loss per 100 training steps: 0.013536401708831266\n","Training loss per 100 training steps: 0.014712298826417232\n","Training loss per 100 training steps: 0.015126918392669754\n","Training loss per 100 training steps: 0.015675125255837648\n","Training loss per 100 training steps: 0.01616699895703829\n","Training loss per 100 training steps: 0.016952329552918356\n","Training loss per 100 training steps: 0.016928647298362267\n","Training loss per 100 training steps: 0.016976825677076132\n","Training loss per 100 training steps: 0.017453035278948145\n","Training loss per 100 training steps: 0.01767251050866948\n","Training loss per 100 training steps: 0.017778198384070406\n","Training loss per 100 training steps: 0.017916733756144197\n","Training loss per 100 training steps: 0.018179433421791378\n","Training loss per 100 training steps: 0.01830021656048932\n","Training loss per 100 training steps: 0.018395635391571977\n","Training loss epoch: 0.018236036610161654\n","Training accuracy epoch: 0.9944980596405228\n","Validating model...\n","Validation Loss: 0.23226898035799798\n","Validation Accuracy: 0.9543109582542695\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0003141435736324638\n","Training loss per 100 training steps: 0.013628454010782068\n","Training loss per 100 training steps: 0.009887823142930553\n","Training loss per 100 training steps: 0.009229252592978018\n","Training loss per 100 training steps: 0.010198241474726435\n","Training loss per 100 training steps: 0.009810062152512015\n","Training loss per 100 training steps: 0.009735977636066578\n","Training loss per 100 training steps: 0.012278223161330046\n","Training loss per 100 training steps: 0.012510618145432128\n","Training loss per 100 training steps: 0.012597637248556474\n","Training loss per 100 training steps: 0.012529559189021496\n","Training loss per 100 training steps: 0.012453309139155128\n","Training loss per 100 training steps: 0.01210870248652614\n","Training loss per 100 training steps: 0.012818022949891896\n","Training loss per 100 training steps: 0.013162295049676337\n","Training loss per 100 training steps: 0.013792788992715365\n","Training loss per 100 training steps: 0.013866194530019834\n","Training loss per 100 training steps: 0.014076214143288614\n","Training loss per 100 training steps: 0.014105729280614925\n","Training loss per 100 training steps: 0.014072595133502895\n","Training loss per 100 training steps: 0.014063441040555229\n","Training loss per 100 training steps: 0.014110483267707993\n","Stopping epoch...\n","Training loss epoch: 0.014110483267707993\n","Training accuracy epoch: 0.9955080913850547\n","Validating model...\n","Validation Loss: 0.21837335433769575\n","Validation Accuracy: 0.9525023719165086\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 107.50412433333355 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15846972739220494\n","Validation Accuracy: 0.9524739583333334\n","Validation duration: 2.4551225166665973 minutes\n","F1-score (test): 84.5%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.77      0.82      0.80      1170\n","        test       0.90      0.85      0.87      2464\n","   treatment       0.81      0.88      0.84      1244\n","\n","   micro avg       0.84      0.85      0.84      4878\n","   macro avg       0.83      0.85      0.84      4878\n","weighted avg       0.84      0.85      0.85      4878\n","\n","!!!!!! Starting model number 7 !!!!!!\n","Points in X_train after augmentation: 78312\n","Points in y_train after augmentation: 78312\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0828819274902344\n","Training loss per 100 training steps: 0.3807819285383909\n","Training loss per 100 training steps: 0.2860539850329433\n","Training loss per 100 training steps: 0.24772855004549424\n","Training loss per 100 training steps: 0.22667237883549823\n","Training loss per 100 training steps: 0.20516734925226984\n","Training loss per 100 training steps: 0.19444250241588312\n","Training loss per 100 training steps: 0.18473152005440488\n","Training loss per 100 training steps: 0.1737512396384012\n","Training loss per 100 training steps: 0.16667524169273593\n","Training loss per 100 training steps: 0.16095432677663504\n","Training loss per 100 training steps: 0.154484097596104\n","Training loss per 100 training steps: 0.14952922220251522\n","Training loss per 100 training steps: 0.14551003558890854\n","Training loss per 100 training steps: 0.1407147667721063\n","Training loss per 100 training steps: 0.13740526862628014\n","Training loss per 100 training steps: 0.13379891343917383\n","Training loss per 100 training steps: 0.1299451974702113\n","Training loss per 100 training steps: 0.12667787873589778\n","Training loss per 100 training steps: 0.12477409353337424\n","Training loss per 100 training steps: 0.12176190233243205\n","Training loss per 100 training steps: 0.11994191466704116\n","Training loss per 100 training steps: 0.11756955800417841\n","Training loss per 100 training steps: 0.11550503222510398\n","Training loss per 100 training steps: 0.11372739054630746\n","Training loss epoch: 0.11347383390257997\n","Training accuracy epoch: 0.9652394812091504\n","Validating model...\n","Validation Loss: 0.1511274477530855\n","Validation Accuracy: 0.9528186274509803\n","Training epoch: 2\n","Training loss per 100 training steps: 0.012575050815939903\n","Training loss per 100 training steps: 0.05022424529767641\n","Training loss per 100 training steps: 0.040198589533808365\n","Training loss per 100 training steps: 0.041916789357632434\n","Training loss per 100 training steps: 0.04303808472345135\n","Training loss per 100 training steps: 0.046747005006443416\n","Training loss per 100 training steps: 0.04572017064417624\n","Training loss per 100 training steps: 0.04612129288024738\n","Training loss per 100 training steps: 0.0461363328490569\n","Training loss per 100 training steps: 0.046444698430822086\n","Training loss per 100 training steps: 0.045541117125556904\n","Training loss per 100 training steps: 0.04444466083342054\n","Training loss per 100 training steps: 0.04533555321392489\n","Training loss per 100 training steps: 0.04498551748752942\n","Training loss per 100 training steps: 0.04421865138943027\n","Training loss per 100 training steps: 0.04468965067980044\n","Training loss per 100 training steps: 0.044164953768440346\n","Training loss per 100 training steps: 0.04411518389436727\n","Training loss per 100 training steps: 0.04380626637059528\n","Training loss per 100 training steps: 0.04412620945312847\n","Training loss per 100 training steps: 0.043844303883025015\n","Stopping epoch...\n","Training loss epoch: 0.043844303883025015\n","Training accuracy epoch: 0.9866941529235382\n","Validating model...\n","Validation Loss: 0.19360846305276294\n","Validation Accuracy: 0.9534116065781152\n","Training epoch: 3\n","Training loss per 100 training steps: 0.004733491223305464\n","Training loss per 100 training steps: 0.032216946614011754\n","Training loss per 100 training steps: 0.026887888269526743\n","Training loss per 100 training steps: 0.02443611300022471\n","Training loss per 100 training steps: 0.022948898665419434\n","Training loss per 100 training steps: 0.024277129232780748\n","Training loss per 100 training steps: 0.024917332999917295\n","Training loss per 100 training steps: 0.026095149440871226\n","Training loss per 100 training steps: 0.026798165631522663\n","Training loss per 100 training steps: 0.026661401207803786\n","Training loss per 100 training steps: 0.027433360884735754\n","Training loss per 100 training steps: 0.027928777435270235\n","Training loss per 100 training steps: 0.029612766288748774\n","Training loss per 100 training steps: 0.03019174400198117\n","Training loss per 100 training steps: 0.030743935046742287\n","Training loss per 100 training steps: 0.031162559599504727\n","Training loss per 100 training steps: 0.03086938245393505\n","Training loss per 100 training steps: 0.030465549962623302\n","Training loss per 100 training steps: 0.029888876506788935\n","Training loss per 100 training steps: 0.02999262772346499\n","Training loss per 100 training steps: 0.030033240953103935\n","Training loss per 100 training steps: 0.030326435167115466\n","Training loss per 100 training steps: 0.030675989587849235\n","Training loss per 100 training steps: 0.03059998454604436\n","Training loss per 100 training steps: 0.0302821227171833\n","Training loss epoch: 0.0304333857428681\n","Training accuracy epoch: 0.991357741013072\n","Validating model...\n","Validation Loss: 0.2855175751838924\n","Validation Accuracy: 0.9393382352941176\n","Training epoch: 4\n","Training loss per 100 training steps: 0.08858136087656021\n","Training loss per 100 training steps: 0.025360038551838496\n","Training loss per 100 training steps: 0.01762648157784669\n","Training loss per 100 training steps: 0.017473722332877733\n","Training loss per 100 training steps: 0.019303959555379023\n","Training loss per 100 training steps: 0.020571743900323715\n","Training loss per 100 training steps: 0.021167470335487947\n","Training loss per 100 training steps: 0.021857000083177477\n","Training loss per 100 training steps: 0.022101167732801467\n","Training loss per 100 training steps: 0.022899157970687107\n","Training loss per 100 training steps: 0.024262208773036507\n","Training loss per 100 training steps: 0.0234162187823695\n","Training loss per 100 training steps: 0.023133965753684343\n","Training loss per 100 training steps: 0.0238538048877834\n","Training loss per 100 training steps: 0.02357514063150328\n","Training loss per 100 training steps: 0.02367905655381541\n","Training loss per 100 training steps: 0.023706174477929057\n","Training loss per 100 training steps: 0.023409102057735373\n","Training loss per 100 training steps: 0.024108094887930035\n","Training loss per 100 training steps: 0.025065404375212867\n","Training loss per 100 training steps: 0.025247565976182225\n","Training loss per 100 training steps: 0.02516263291546887\n","Training loss per 100 training steps: 0.025437154419441988\n","Training loss per 100 training steps: 0.02522207005518942\n","Training loss per 100 training steps: 0.025485123032407866\n","Training loss epoch: 0.025331954789189516\n","Training accuracy epoch: 0.9929406658496732\n","Validating model...\n","Validation Loss: 0.23683748549442765\n","Validation Accuracy: 0.9540342346616066\n","Training epoch: 5\n","Training loss per 100 training steps: 0.136431485414505\n","Training loss per 100 training steps: 0.015004890295446362\n","Training loss per 100 training steps: 0.019056481442881044\n","Training loss per 100 training steps: 0.022478337264729996\n","Training loss per 100 training steps: 0.02039114895704646\n","Training loss per 100 training steps: 0.020022261758883782\n","Training loss per 100 training steps: 0.020014757459730255\n","Training loss per 100 training steps: 0.020972027402496055\n","Training loss per 100 training steps: 0.02020840785052032\n","Training loss per 100 training steps: 0.019300290100112635\n","Training loss per 100 training steps: 0.019481438337983114\n","Training loss per 100 training steps: 0.019897590026568542\n","Training loss per 100 training steps: 0.019338239406261056\n","Training loss per 100 training steps: 0.019082405199759168\n","Training loss per 100 training steps: 0.01899581518728577\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 5\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":14802462,"status":"ok","timestamp":1657586387678,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"IYz63Tge7KcA","outputId":"52d393cf-92bd-4f22-8eb9-be1776554af5"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 500% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 78312\n","Points in y_train after augmentation: 78312\n","Device:  cuda\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f85ac906facc4156a632d0b631e04ac4","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/422M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8314592838287354\n","Training loss per 100 training steps: 0.34974993979281715\n","Training loss per 100 training steps: 0.2724335819658874\n","Training loss per 100 training steps: 0.23463910786540207\n","Training loss per 100 training steps: 0.21444993137737314\n","Training loss per 100 training steps: 0.19494543937192912\n","Training loss per 100 training steps: 0.18393091171493323\n","Training loss per 100 training steps: 0.17553923925924275\n","Training loss per 100 training steps: 0.16941923714334728\n","Training loss per 100 training steps: 0.16411658032196724\n","Training loss per 100 training steps: 0.15702407227710008\n","Training loss per 100 training steps: 0.15280713278611616\n","Training loss per 100 training steps: 0.14686735533914536\n","Training loss per 100 training steps: 0.14361901576043773\n","Training loss per 100 training steps: 0.13902469115916088\n","Training loss per 100 training steps: 0.1359280006496855\n","Training loss per 100 training steps: 0.1331440373479466\n","Training loss per 100 training steps: 0.1307892645551806\n","Training loss per 100 training steps: 0.1284027532957492\n","Training loss per 100 training steps: 0.12607095394453044\n","Training loss per 100 training steps: 0.12343695247906546\n","Training loss per 100 training steps: 0.12059198020224232\n","Training loss per 100 training steps: 0.11802166083896162\n","Training loss per 100 training steps: 0.1153816570819674\n","Training loss per 100 training steps: 0.11319284064765835\n","Training loss epoch: 0.11186440075768403\n","Training accuracy epoch: 0.9644990808823529\n","Validating model...\n","Validation Loss: 0.1911340260754942\n","Validation Accuracy: 0.9481933902593296\n","Training epoch: 2\n","Training loss per 100 training steps: 0.036196328699588776\n","Training loss per 100 training steps: 0.033017065257899054\n","Training loss per 100 training steps: 0.031272018391150166\n","Training loss per 100 training steps: 0.034538887291674834\n","Training loss per 100 training steps: 0.03788403841258117\n","Training loss per 100 training steps: 0.03770164260222482\n","Training loss per 100 training steps: 0.03811813250155779\n","Training loss per 100 training steps: 0.03753967837254668\n","Training loss per 100 training steps: 0.03757095045523315\n","Training loss per 100 training steps: 0.03933474882940615\n","Training loss per 100 training steps: 0.04005891266995906\n","Training loss per 100 training steps: 0.04078288853520483\n","Training loss per 100 training steps: 0.040545947828110454\n","Training loss per 100 training steps: 0.042007105913904275\n","Training loss per 100 training steps: 0.04226120497318344\n","Training loss per 100 training steps: 0.04201686374190776\n","Training loss per 100 training steps: 0.04143199897113461\n","Training loss per 100 training steps: 0.04366035024032338\n","Training loss per 100 training steps: 0.043381473544011846\n","Training loss per 100 training steps: 0.043744218214767754\n","Training loss per 100 training steps: 0.043440079095607355\n","Training loss per 100 training steps: 0.04306422807098107\n","Training loss per 100 training steps: 0.04277898681654763\n","Training loss per 100 training steps: 0.043384008248208004\n","Training loss per 100 training steps: 0.042877206650452714\n","Training loss epoch: 0.04257678363210051\n","Training accuracy epoch: 0.9869664011437909\n","Validating model...\n","Validation Loss: 0.18715204781619832\n","Validation Accuracy: 0.9549434693232132\n","Training epoch: 3\n","Training loss per 100 training steps: 0.011152894236147404\n","Training loss per 100 training steps: 0.01817120735027532\n","Training loss per 100 training steps: 0.02097019515190255\n","Training loss per 100 training steps: 0.02064266829210739\n","Training loss per 100 training steps: 0.019262065594557044\n","Training loss per 100 training steps: 0.022517619639940763\n","Training loss per 100 training steps: 0.024864145846935838\n","Training loss per 100 training steps: 0.02598065602257122\n","Training loss per 100 training steps: 0.025829829465482398\n","Training loss per 100 training steps: 0.02598254720236558\n","Training loss per 100 training steps: 0.026914996365680406\n","Training loss per 100 training steps: 0.027302821508756948\n","Training loss per 100 training steps: 0.0268823125796622\n","Training loss per 100 training steps: 0.026654417994546462\n","Training loss per 100 training steps: 0.02737867581762619\n","Training loss per 100 training steps: 0.026892265229279275\n","Training loss per 100 training steps: 0.026817107064820742\n","Training loss per 100 training steps: 0.027105812363608758\n","Training loss per 100 training steps: 0.02752098374575816\n","Training loss per 100 training steps: 0.02794269851994512\n","Training loss per 100 training steps: 0.028268666017565905\n","Training loss per 100 training steps: 0.02810954107664171\n","Training loss per 100 training steps: 0.028277304204113955\n","Training loss per 100 training steps: 0.02874619197281968\n","Training loss per 100 training steps: 0.029188300519666126\n","Training loss epoch: 0.029222033953888386\n","Training accuracy epoch: 0.991064133986928\n","Validating model...\n","Validation Loss: 0.23051675572174182\n","Validation Accuracy: 0.9515931372549019\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0008722695638425648\n","Training loss per 100 training steps: 0.014069098371512137\n","Training loss per 100 training steps: 0.01552574701217149\n","Training loss per 100 training steps: 0.014988219315609454\n","Training loss per 100 training steps: 0.01506000322675808\n","Training loss per 100 training steps: 0.017798380384737175\n","Training loss per 100 training steps: 0.017027495749606717\n","Training loss per 100 training steps: 0.016346353563527326\n","Training loss per 100 training steps: 0.017291281786238958\n","Training loss per 100 training steps: 0.016777078774982825\n","Training loss per 100 training steps: 0.016011277715268543\n","Training loss per 100 training steps: 0.016589368318597357\n","Training loss per 100 training steps: 0.018426469916760696\n","Training loss per 100 training steps: 0.018015325658612278\n","Training loss per 100 training steps: 0.0186001680132948\n","Training loss per 100 training steps: 0.018750963206545082\n","Training loss per 100 training steps: 0.01920127677311019\n","Training loss per 100 training steps: 0.019262035260416397\n","Training loss per 100 training steps: 0.01922439455395204\n","Training loss per 100 training steps: 0.0201561635903258\n","Training loss per 100 training steps: 0.02035531728233082\n","Training loss per 100 training steps: 0.0204805014806158\n","Training loss per 100 training steps: 0.020221298163905912\n","Training loss per 100 training steps: 0.02008037347753024\n","Training loss per 100 training steps: 0.020259313029698318\n","Training loss epoch: 0.020083521187226186\n","Training accuracy epoch: 0.9939746732026143\n","Validating model...\n","Validation Loss: 0.2727536382378686\n","Validation Accuracy: 0.953401723592663\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0003149900585412979\n","Training loss per 100 training steps: 0.0128806870469465\n","Training loss per 100 training steps: 0.013716898597300513\n","Training loss per 100 training steps: 0.011491380158913912\n","Training loss per 100 training steps: 0.011516353746560695\n","Training loss per 100 training steps: 0.0108952405758236\n","Training loss per 100 training steps: 0.013036081612176191\n","Training loss per 100 training steps: 0.013436614866664908\n","Training loss per 100 training steps: 0.01369758952720342\n","Training loss per 100 training steps: 0.01330634552206022\n","Training loss per 100 training steps: 0.013874854821902422\n","Training loss per 100 training steps: 0.014422801796340796\n","Training loss per 100 training steps: 0.014919433451762686\n","Training loss per 100 training steps: 0.015339412403705217\n","Training loss per 100 training steps: 0.015879607774302994\n","Training loss per 100 training steps: 0.016347740451975786\n","Training loss per 100 training steps: 0.01675733482763376\n","Training loss per 100 training steps: 0.0170054662580651\n","Training loss per 100 training steps: 0.017067418988403475\n","Training loss per 100 training steps: 0.018548384431423117\n","Training loss per 100 training steps: 0.019239190509749066\n","Training loss per 100 training steps: 0.01944542680784456\n","Training loss per 100 training steps: 0.019391972691504375\n","Training loss per 100 training steps: 0.019452748076207137\n","Training loss per 100 training steps: 0.01915026020939908\n","Training loss epoch: 0.018953127599996424\n","Training accuracy epoch: 0.9944469975490197\n","Validating model...\n","Validation Loss: 0.2519522650171198\n","Validation Accuracy: 0.9531151170145478\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00035851626307703555\n","Training loss per 100 training steps: 0.014742118048125481\n","Training loss per 100 training steps: 0.014569092315618199\n","Training loss per 100 training steps: 0.015031868453782309\n","Training loss per 100 training steps: 0.01429423888419619\n","Training loss per 100 training steps: 0.013617231119333483\n","Training loss per 100 training steps: 0.013997161955718523\n","Training loss per 100 training steps: 0.013452732745895478\n","Training loss per 100 training steps: 0.01369934608755989\n","Training loss per 100 training steps: 0.01365763424620671\n","Training loss per 100 training steps: 0.013178472718062186\n","Training loss per 100 training steps: 0.013799832360744571\n","Training loss per 100 training steps: 0.013926948810700192\n","Training loss per 100 training steps: 0.01357226401301498\n","Training loss per 100 training steps: 0.013382059981256921\n","Training loss per 100 training steps: 0.013007885670243793\n","Training loss per 100 training steps: 0.012729175972593865\n","Training loss per 100 training steps: 0.01311167532062232\n","Training loss per 100 training steps: 0.013616121768681256\n","Training loss per 100 training steps: 0.013287788058071796\n","Training loss per 100 training steps: 0.013892190687738344\n","Training loss per 100 training steps: 0.013928388634385258\n","Training loss per 100 training steps: 0.01366234928736619\n","Training loss per 100 training steps: 0.01370741159866811\n","Training loss per 100 training steps: 0.01413256601595062\n","Training loss epoch: 0.01422834305158711\n","Training accuracy epoch: 0.9956597222222222\n","Validating model...\n","Validation Loss: 0.2791155992131726\n","Validation Accuracy: 0.9494386464263125\n","Training epoch: 7\n","Training loss per 100 training steps: 0.003966979682445526\n","Training loss per 100 training steps: 0.009758560585162354\n","Training loss per 100 training steps: 0.01538237413522221\n","Training loss per 100 training steps: 0.013309273913494377\n","Training loss per 100 training steps: 0.015253447151130025\n","Training loss per 100 training steps: 0.014282388497461627\n","Training loss per 100 training steps: 0.012937805429556191\n","Training loss per 100 training steps: 0.012934111662201311\n","Training loss per 100 training steps: 0.012074187749253435\n","Training loss per 100 training steps: 0.012146735470096356\n","Training loss per 100 training steps: 0.012004398529005722\n","Training loss per 100 training steps: 0.01254537153349962\n","Training loss per 100 training steps: 0.012868132015494369\n","Training loss per 100 training steps: 0.01236587093401618\n","Training loss per 100 training steps: 0.012379974936826969\n","Training loss per 100 training steps: 0.012318362202871738\n","Training loss per 100 training steps: 0.012360872912277892\n","Training loss per 100 training steps: 0.01237244253782093\n","Stopping epoch...\n","Training loss epoch: 0.01237244253782093\n","Training accuracy epoch: 0.9957929159318049\n","Validating model...\n","Validation Loss: 0.2715521128507224\n","Validation Accuracy: 0.9500316255534472\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 122.06389779999999 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.17966788625621863\n","Validation Accuracy: 0.9544793274176955\n","Validation duration: 2.3943764499999816 minutes\n","F1-score (test): 85.4%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.77      0.83      0.80      1170\n","        test       0.88      0.89      0.89      2464\n","   treatment       0.79      0.89      0.84      1244\n","\n","   micro avg       0.83      0.88      0.85      4878\n","   macro avg       0.82      0.87      0.84      4878\n","weighted avg       0.83      0.88      0.85      4878\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 78312\n","Points in y_train after augmentation: 78312\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8972344398498535\n","Training loss per 100 training steps: 0.3493547451378095\n","Training loss per 100 training steps: 0.2618370658639281\n","Training loss per 100 training steps: 0.2299579410068072\n","Training loss per 100 training steps: 0.207129736203338\n","Training loss per 100 training steps: 0.18667896301996803\n","Training loss per 100 training steps: 0.1779906367154764\n","Training loss per 100 training steps: 0.1695654074423621\n","Training loss per 100 training steps: 0.1635217744817541\n","Training loss per 100 training steps: 0.1570686862967313\n","Training loss per 100 training steps: 0.15099899527420485\n","Training loss per 100 training steps: 0.14637672247620576\n","Training loss per 100 training steps: 0.14131925689548155\n","Training loss per 100 training steps: 0.13659017078802532\n","Training loss per 100 training steps: 0.13246802267499486\n","Training loss per 100 training steps: 0.12853087943858857\n","Training loss per 100 training steps: 0.1247523603262816\n","Training loss per 100 training steps: 0.12257574669779144\n","Training loss per 100 training steps: 0.11994621009635183\n","Training loss per 100 training steps: 0.11733288621229376\n","Training loss per 100 training steps: 0.11533684321168483\n","Training loss per 100 training steps: 0.11411267650625187\n","Training loss per 100 training steps: 0.11241358436726272\n","Training loss per 100 training steps: 0.11013430939341831\n","Training loss per 100 training steps: 0.10821922797268867\n","Training loss epoch: 0.10760237860204797\n","Training accuracy epoch: 0.9657628676470589\n","Validating model...\n","Validation Loss: 0.1541730436683614\n","Validation Accuracy: 0.9574142156862745\n","Training epoch: 2\n","Training loss per 100 training steps: 0.03891978785395622\n","Training loss per 100 training steps: 0.029191412608252174\n","Training loss per 100 training steps: 0.031155040012863674\n","Training loss per 100 training steps: 0.03058542505558735\n","Training loss per 100 training steps: 0.03350141606737216\n","Training loss per 100 training steps: 0.034057876637750145\n","Training loss per 100 training steps: 0.034792007859730426\n","Training loss per 100 training steps: 0.03577241728719345\n","Training loss per 100 training steps: 0.03503826064746257\n","Training loss per 100 training steps: 0.03524703990159501\n","Training loss per 100 training steps: 0.035338982878081675\n","Training loss per 100 training steps: 0.034999861284274375\n","Training loss per 100 training steps: 0.03636750105573512\n","Training loss per 100 training steps: 0.03681197095729735\n","Training loss per 100 training steps: 0.03705414381074064\n","Training loss per 100 training steps: 0.03744959561913932\n","Training loss per 100 training steps: 0.03666918952415078\n","Training loss per 100 training steps: 0.03664159587880128\n","Training loss per 100 training steps: 0.03633262874543346\n","Training loss per 100 training steps: 0.03596886113012862\n","Training loss per 100 training steps: 0.03608921006544178\n","Training loss per 100 training steps: 0.036774944051457044\n","Training loss per 100 training steps: 0.036964092017042725\n","Training loss per 100 training steps: 0.03670617058610825\n","Training loss per 100 training steps: 0.03737350597758408\n","Training loss epoch: 0.03723466302011242\n","Training accuracy epoch: 0.9890599468954249\n","Validating model...\n","Validation Loss: 0.16657359948765268\n","Validation Accuracy: 0.9589361954459203\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0010987772839143872\n","Training loss per 100 training steps: 0.014958279927740667\n","Training loss per 100 training steps: 0.016578494667003757\n","Training loss per 100 training steps: 0.01777032631066217\n","Training loss per 100 training steps: 0.02081453710409567\n","Training loss per 100 training steps: 0.02503161867243689\n","Training loss per 100 training steps: 0.02586381614261054\n","Training loss per 100 training steps: 0.027868000739358266\n","Training loss per 100 training steps: 0.027251508356221053\n","Training loss per 100 training steps: 0.02734382080043774\n","Training loss per 100 training steps: 0.028395922936962397\n","Training loss per 100 training steps: 0.02915917474761677\n","Training loss per 100 training steps: 0.02897676045821217\n","Training loss per 100 training steps: 0.028503724864855983\n","Training loss per 100 training steps: 0.028341629615164756\n","Training loss per 100 training steps: 0.028285113324638345\n","Training loss per 100 training steps: 0.028717710938778795\n","Training loss per 100 training steps: 0.027764081146067186\n","Training loss per 100 training steps: 0.02776469630001705\n","Training loss per 100 training steps: 0.02783427598965971\n","Training loss per 100 training steps: 0.02736676787764731\n","Training loss per 100 training steps: 0.02714851069837976\n","Training loss per 100 training steps: 0.026953400021896095\n","Training loss per 100 training steps: 0.026695940972801067\n","Training loss per 100 training steps: 0.026906417650126625\n","Training loss epoch: 0.02700431653936879\n","Training accuracy epoch: 0.9921109068627451\n","Validating model...\n","Validation Loss: 0.18866904000163892\n","Validation Accuracy: 0.9540243516761544\n","Training epoch: 4\n","Training loss per 100 training steps: 0.02385590225458145\n","Training loss per 100 training steps: 0.014437479539866568\n","Training loss per 100 training steps: 0.017905820482259905\n","Training loss per 100 training steps: 0.01714829093418115\n","Training loss per 100 training steps: 0.01733058620609478\n","Training loss per 100 training steps: 0.016632695974198405\n","Training loss per 100 training steps: 0.015414446633069031\n","Training loss per 100 training steps: 0.016070582491672696\n","Training loss per 100 training steps: 0.018201433244441373\n","Training loss per 100 training steps: 0.01825177143716481\n","Training loss per 100 training steps: 0.017845240753670513\n","Training loss per 100 training steps: 0.01786599008948119\n","Training loss per 100 training steps: 0.017653048080745016\n","Training loss per 100 training steps: 0.017855559281287996\n","Training loss per 100 training steps: 0.017722307197045557\n","Training loss per 100 training steps: 0.017365052277629613\n","Training loss per 100 training steps: 0.017740980368128646\n","Training loss per 100 training steps: 0.01812268749884396\n","Training loss per 100 training steps: 0.018592327609127875\n","Training loss per 100 training steps: 0.018912000225896307\n","Training loss per 100 training steps: 0.018535261444095497\n","Training loss per 100 training steps: 0.019386437607441562\n","Training loss per 100 training steps: 0.02014835242817699\n","Training loss per 100 training steps: 0.02065888233644104\n","Training loss per 100 training steps: 0.02039154203399196\n","Training loss epoch: 0.02062351017763171\n","Training accuracy epoch: 0.9941023284313726\n","Validating model...\n","Validation Loss: 0.1956268683373791\n","Validation Accuracy: 0.9549434693232132\n","Training epoch: 5\n","Training loss per 100 training steps: 0.05927366018295288\n","Training loss per 100 training steps: 0.01656108646680103\n","Training loss per 100 training steps: 0.014849885881386712\n","Training loss per 100 training steps: 0.015203004155875194\n","Training loss per 100 training steps: 0.015205904994181856\n","Training loss per 100 training steps: 0.016010966277009174\n","Training loss per 100 training steps: 0.015868691736828873\n","Training loss per 100 training steps: 0.016561419691119662\n","Training loss per 100 training steps: 0.016549713860765362\n","Training loss per 100 training steps: 0.01611105786006201\n","Training loss per 100 training steps: 0.016431709332199725\n","Training loss per 100 training steps: 0.01691529109696328\n","Training loss per 100 training steps: 0.01668827664388308\n","Training loss per 100 training steps: 0.016848224852859646\n","Training loss per 100 training steps: 0.016842061724347955\n","Training loss per 100 training steps: 0.016801485552965827\n","Training loss per 100 training steps: 0.016900940945955407\n","Training loss per 100 training steps: 0.016922851819917855\n","Stopping epoch...\n","Training loss epoch: 0.016922851819917855\n","Training accuracy epoch: 0.9944701646090535\n","Validating model...\n","Validation Loss: 0.21256356814653068\n","Validation Accuracy: 0.9530953510436433\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00042283086804673076\n","Training loss per 100 training steps: 0.012848526969584313\n","Training loss per 100 training steps: 0.011414143189983917\n","Training loss per 100 training steps: 0.012255523391016735\n","Training loss per 100 training steps: 0.01404300945037073\n","Training loss per 100 training steps: 0.014969227439192372\n","Training loss per 100 training steps: 0.013714279291810705\n","Training loss per 100 training steps: 0.013614363891492148\n","Training loss per 100 training steps: 0.014760301159519295\n","Training loss per 100 training steps: 0.014681002131531666\n","Training loss per 100 training steps: 0.014382905211458638\n","Training loss per 100 training steps: 0.014937012382884186\n","Training loss per 100 training steps: 0.014063167671703316\n","Training loss per 100 training steps: 0.015005624405508084\n","Training loss per 100 training steps: 0.015051519537935189\n","Training loss per 100 training steps: 0.015829280447688044\n","Training loss per 100 training steps: 0.016257342569240555\n","Training loss per 100 training steps: 0.016235345372976315\n","Training loss per 100 training steps: 0.01637022734522694\n","Training loss per 100 training steps: 0.016222147797104913\n","Training loss per 100 training steps: 0.0163071510046659\n","Stopping epoch...\n","Training loss epoch: 0.0163071510046659\n","Training accuracy epoch: 0.9947682408795602\n","Validating model...\n","Validation Loss: 0.22808915292490364\n","Validation Accuracy: 0.953125\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 97.56553994999997 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14435567057026438\n","Validation Accuracy: 0.9575376157407407\n","Validation duration: 2.3586232166666377 minutes\n","F1-score (test): 86.0%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.84      0.82      0.83      1170\n","        test       0.83      0.92      0.87      2464\n","   treatment       0.86      0.85      0.86      1244\n","\n","   micro avg       0.84      0.88      0.86      4878\n","   macro avg       0.84      0.87      0.85      4878\n","weighted avg       0.84      0.88      0.86      4878\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 78312\n","Points in y_train after augmentation: 78312\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.153498649597168\n","Training loss per 100 training steps: 0.33683513518017116\n","Training loss per 100 training steps: 0.25945926277865816\n","Training loss per 100 training steps: 0.23842858251468882\n","Training loss per 100 training steps: 0.21111578908876663\n","Training loss per 100 training steps: 0.19427409203920118\n","Training loss per 100 training steps: 0.1833205498776673\n","Training loss per 100 training steps: 0.1742242033455186\n","Training loss per 100 training steps: 0.1671292993505154\n","Training loss per 100 training steps: 0.15975870869973144\n","Training loss per 100 training steps: 0.15478703792539092\n","Training loss per 100 training steps: 0.14872187818231383\n","Training loss per 100 training steps: 0.14341087535924768\n","Training loss per 100 training steps: 0.13910023681363085\n","Training loss per 100 training steps: 0.13507518312743574\n","Training loss per 100 training steps: 0.13141611923909138\n","Training loss per 100 training steps: 0.12753770568300163\n","Training loss per 100 training steps: 0.12469680551821415\n","Training loss per 100 training steps: 0.12211168062675906\n","Training loss per 100 training steps: 0.1195699425289522\n","Training loss per 100 training steps: 0.1178502660045849\n","Training loss per 100 training steps: 0.11605689602134717\n","Training loss per 100 training steps: 0.11427738305885998\n","Training loss per 100 training steps: 0.11224866344375711\n","Training loss per 100 training steps: 0.11050007871766403\n","Training loss epoch: 0.10970728905745775\n","Training accuracy epoch: 0.9660564746732027\n","Validating model...\n","Validation Loss: 0.16807844500541322\n","Validation Accuracy: 0.9570880771663505\n","Training epoch: 2\n","Training loss per 100 training steps: 0.007389523088932037\n","Training loss per 100 training steps: 0.03421966594558597\n","Training loss per 100 training steps: 0.03898999186444666\n","Training loss per 100 training steps: 0.04221927960410225\n","Training loss per 100 training steps: 0.03783818949752794\n","Training loss per 100 training steps: 0.037567884600551674\n","Training loss per 100 training steps: 0.03737420418593\n","Training loss per 100 training steps: 0.03767939996864938\n","Training loss per 100 training steps: 0.03745806754698841\n","Training loss per 100 training steps: 0.038537667030356174\n","Training loss per 100 training steps: 0.03905008051315435\n","Training loss per 100 training steps: 0.03861721890761122\n","Training loss per 100 training steps: 0.03892174156167103\n","Training loss per 100 training steps: 0.0388571305990489\n","Training loss per 100 training steps: 0.03927591095650173\n","Training loss per 100 training steps: 0.03956959235463226\n","Training loss per 100 training steps: 0.03895708801725319\n","Training loss per 100 training steps: 0.03964236333306431\n","Training loss per 100 training steps: 0.03948205902578523\n","Training loss per 100 training steps: 0.039209729085837676\n","Training loss per 100 training steps: 0.039905056705415214\n","Training loss per 100 training steps: 0.03976988844610317\n","Training loss per 100 training steps: 0.03938648963986357\n","Training loss per 100 training steps: 0.039458037270427564\n","Training loss per 100 training steps: 0.039054347391271865\n","Training loss epoch: 0.039155633959696796\n","Training accuracy epoch: 0.9879110498366013\n","Validating model...\n","Validation Loss: 0.1904599035670068\n","Validation Accuracy: 0.9527988614800759\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0013957676710560918\n","Training loss per 100 training steps: 0.02035452797720762\n","Training loss per 100 training steps: 0.020970244897805752\n","Training loss per 100 training steps: 0.02235796361765399\n","Training loss per 100 training steps: 0.022686049494460663\n","Training loss per 100 training steps: 0.024116691476944858\n","Training loss per 100 training steps: 0.023083326908479\n","Training loss per 100 training steps: 0.02455705492947619\n","Training loss per 100 training steps: 0.024781265799790755\n","Training loss per 100 training steps: 0.024272730866657117\n","Training loss per 100 training steps: 0.02396497008224039\n","Training loss per 100 training steps: 0.024443815510923186\n","Training loss per 100 training steps: 0.024265781553507657\n","Training loss per 100 training steps: 0.02346252123974127\n","Training loss per 100 training steps: 0.02461619916356151\n","Training loss per 100 training steps: 0.024727972275722713\n","Training loss per 100 training steps: 0.02517923297829491\n","Training loss per 100 training steps: 0.025063721843731013\n","Training loss per 100 training steps: 0.026151725341925332\n","Training loss per 100 training steps: 0.026161126405144015\n","Training loss per 100 training steps: 0.02621466417182675\n","Training loss per 100 training steps: 0.02616150494257606\n","Training loss per 100 training steps: 0.026119567115844906\n","Stopping epoch...\n","Training loss epoch: 0.026119567115844906\n","Training accuracy epoch: 0.9918077010449795\n","Validating model...\n","Validation Loss: 0.22541522146995846\n","Validation Accuracy: 0.9561788425047438\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0027568202931433916\n","Training loss per 100 training steps: 0.017613428963393223\n","Training loss per 100 training steps: 0.01815359827601038\n","Training loss per 100 training steps: 0.019089770473899904\n","Training loss per 100 training steps: 0.019916368091626713\n","Training loss per 100 training steps: 0.01979549584435434\n","Training loss per 100 training steps: 0.019251205431191465\n","Training loss per 100 training steps: 0.017731737267310595\n","Training loss per 100 training steps: 0.018178459526288625\n","Training loss per 100 training steps: 0.01913071311980086\n","Training loss per 100 training steps: 0.01944940811862417\n","Training loss per 100 training steps: 0.01931767837077107\n","Training loss per 100 training steps: 0.020684864237915646\n","Training loss per 100 training steps: 0.02039823778557451\n","Training loss per 100 training steps: 0.021113508922979776\n","Training loss per 100 training steps: 0.02058818461781503\n","Training loss per 100 training steps: 0.02087772215104306\n","Training loss per 100 training steps: 0.02121538297798371\n","Training loss per 100 training steps: 0.021100055356637646\n","Training loss per 100 training steps: 0.021744435541015468\n","Training loss per 100 training steps: 0.022021212138393875\n","Training loss per 100 training steps: 0.022322591958566226\n","Training loss per 100 training steps: 0.022229856764198207\n","Training loss per 100 training steps: 0.022085622522356615\n","Training loss per 100 training steps: 0.021972043632726965\n","Training loss epoch: 0.021694481811584197\n","Training accuracy epoch: 0.9934768178104575\n","Validating model...\n","Validation Loss: 0.27506270698687135\n","Validation Accuracy: 0.9531151170145478\n","Training epoch: 5\n","Training loss per 100 training steps: 0.00042176313581876457\n","Training loss per 100 training steps: 0.0187217593830601\n","Training loss per 100 training steps: 0.021319595220319485\n","Training loss per 100 training steps: 0.019182167446169813\n","Training loss per 100 training steps: 0.019641679470517186\n","Training loss per 100 training steps: 0.019540809701017813\n","Training loss per 100 training steps: 0.0191085474562986\n","Training loss per 100 training steps: 0.018481179674185652\n","Training loss per 100 training steps: 0.018452692614058682\n","Training loss per 100 training steps: 0.018678894205330976\n","Training loss per 100 training steps: 0.018370710404752997\n","Training loss per 100 training steps: 0.018542592000051244\n","Training loss per 100 training steps: 0.018289710313269935\n","Training loss per 100 training steps: 0.017651648746665735\n","Training loss per 100 training steps: 0.018506375774226817\n","Training loss per 100 training steps: 0.018459405636742646\n","Training loss per 100 training steps: 0.018881028880133453\n","Training loss per 100 training steps: 0.018699877149999173\n","Training loss per 100 training steps: 0.01851687039065102\n","Training loss per 100 training steps: 0.018456387376875532\n","Training loss per 100 training steps: 0.018283729080156838\n","Training loss per 100 training steps: 0.01849202476202491\n","Training loss per 100 training steps: 0.018794182658325397\n","Training loss per 100 training steps: 0.018560678482936292\n","Training loss per 100 training steps: 0.01809517150335124\n","Training loss epoch: 0.018051633882193344\n","Training accuracy epoch: 0.9947150735294118\n","Validating model...\n","Validation Loss: 0.24895249037916645\n","Validation Accuracy: 0.953727862112587\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0014285445213317871\n","Training loss per 100 training steps: 0.012334251838651517\n","Training loss per 100 training steps: 0.01092824542015184\n","Training loss per 100 training steps: 0.012294018866584317\n","Training loss per 100 training steps: 0.01269941443968859\n","Training loss per 100 training steps: 0.012234656478663718\n","Training loss per 100 training steps: 0.012475511187747274\n","Training loss per 100 training steps: 0.012413565901366492\n","Training loss per 100 training steps: 0.01185660372103347\n","Training loss per 100 training steps: 0.011494513198060614\n","Training loss per 100 training steps: 0.011610214431224354\n","Training loss per 100 training steps: 0.011858217567592158\n","Training loss per 100 training steps: 0.012010629553749173\n","Training loss per 100 training steps: 0.012265609862240548\n","Training loss per 100 training steps: 0.012554412401140618\n","Training loss per 100 training steps: 0.013431158781871894\n","Training loss per 100 training steps: 0.013665744931064452\n","Training loss per 100 training steps: 0.013824263703709932\n","Training loss per 100 training steps: 0.013551708711708995\n","Training loss per 100 training steps: 0.013841626905545325\n","Training loss per 100 training steps: 0.013866802291960956\n","Training loss per 100 training steps: 0.01390984090929977\n","Training loss per 100 training steps: 0.014069594661957821\n","Training loss per 100 training steps: 0.01371572282757478\n","Training loss per 100 training steps: 0.014181870239340331\n","Training loss epoch: 0.014389164594764652\n","Training accuracy epoch: 0.995953329248366\n","Validating model...\n","Validation Loss: 0.20427669424622996\n","Validation Accuracy: 0.9506740196078431\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 107.45934313333333 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1637331304324713\n","Validation Accuracy: 0.9573567708333334\n","Validation duration: 2.3983642166666566 minutes\n","F1-score (test): 86.0%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.80      0.83      0.81      1170\n","        test       0.86      0.92      0.89      2464\n","   treatment       0.80      0.89      0.84      1244\n","\n","   micro avg       0.83      0.89      0.86      4878\n","   macro avg       0.82      0.88      0.85      4878\n","weighted avg       0.83      0.89      0.86      4878\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 78312\n","Points in y_train after augmentation: 78312\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.4532527923583984\n","Training loss per 100 training steps: 0.34769596441621237\n","Training loss per 100 training steps: 0.26455642308910093\n","Training loss per 100 training steps: 0.23175794368863503\n","Training loss per 100 training steps: 0.2119835000926457\n","Training loss per 100 training steps: 0.19775074475840804\n","Training loss per 100 training steps: 0.18699420521736218\n","Training loss per 100 training steps: 0.17802526918804532\n","Training loss per 100 training steps: 0.16874541361268597\n","Training loss per 100 training steps: 0.15998973107414027\n","Training loss per 100 training steps: 0.15408895049638652\n","Training loss per 100 training steps: 0.1495611837982191\n","Training loss per 100 training steps: 0.14463107464552005\n","Training loss per 100 training steps: 0.14000395747740252\n","Training loss per 100 training steps: 0.13631756286130822\n","Training loss per 100 training steps: 0.13241737136695791\n","Training loss per 100 training steps: 0.1295617882091509\n","Training loss per 100 training steps: 0.12634256704209995\n","Training loss per 100 training steps: 0.12364427595896267\n","Training loss per 100 training steps: 0.12122340164397663\n","Training loss per 100 training steps: 0.11862158120692666\n","Training loss per 100 training steps: 0.11666890260440319\n","Training loss per 100 training steps: 0.11432042892125567\n","Training loss per 100 training steps: 0.1127969019622878\n","Training loss per 100 training steps: 0.11065066450100251\n","Training loss epoch: 0.10966665796691885\n","Training accuracy epoch: 0.9663117851307189\n","Validating model...\n","Validation Loss: 0.2075749120946663\n","Validation Accuracy: 0.9393382352941176\n","Training epoch: 2\n","Training loss per 100 training steps: 0.007942844182252884\n","Training loss per 100 training steps: 0.043575378814320276\n","Training loss per 100 training steps: 0.038807652868673354\n","Training loss per 100 training steps: 0.03890002826609698\n","Training loss per 100 training steps: 0.038251303088519734\n","Training loss per 100 training steps: 0.03836287016369925\n","Training loss per 100 training steps: 0.04110595404571225\n","Training loss per 100 training steps: 0.04197224985572148\n","Training loss per 100 training steps: 0.041146739318367494\n","Training loss per 100 training steps: 0.0418529226299304\n","Training loss per 100 training steps: 0.04105592337874259\n","Training loss per 100 training steps: 0.04033206424887724\n","Training loss per 100 training steps: 0.04012842080976299\n","Training loss per 100 training steps: 0.04149777927934301\n","Training loss per 100 training steps: 0.04147632028674665\n","Training loss per 100 training steps: 0.041970367932655794\n","Training loss per 100 training steps: 0.042197640714235825\n","Training loss per 100 training steps: 0.04196936229079038\n","Training loss per 100 training steps: 0.041891539511110194\n","Training loss per 100 training steps: 0.04223828222836998\n","Stopping epoch...\n","Training loss epoch: 0.04223828222836998\n","Training accuracy epoch: 0.9869147816938454\n","Validating model...\n","Validation Loss: 0.19321362688274615\n","Validation Accuracy: 0.953727862112587\n","Training epoch: 3\n","Training loss per 100 training steps: 0.07879036664962769\n","Training loss per 100 training steps: 0.029809127295491202\n","Training loss per 100 training steps: 0.030812338590842037\n","Training loss per 100 training steps: 0.03163566870268348\n","Training loss per 100 training steps: 0.03044490473647718\n","Training loss per 100 training steps: 0.029571837441323738\n","Training loss per 100 training steps: 0.03059456763355551\n","Training loss per 100 training steps: 0.03125558823483103\n","Training loss per 100 training steps: 0.030244544905399063\n","Training loss per 100 training steps: 0.03178818297574081\n","Training loss per 100 training steps: 0.030392716164861704\n","Training loss per 100 training steps: 0.03174289669840603\n","Training loss per 100 training steps: 0.030928115294991555\n","Training loss per 100 training steps: 0.03131945573591233\n","Training loss per 100 training steps: 0.0311496682084722\n","Training loss per 100 training steps: 0.0310389357235897\n","Training loss per 100 training steps: 0.031434484318448724\n","Training loss per 100 training steps: 0.031357598012737534\n","Training loss per 100 training steps: 0.031615688388433115\n","Training loss per 100 training steps: 0.03177263567208514\n","Training loss per 100 training steps: 0.03200259981240524\n","Training loss per 100 training steps: 0.03204054352170699\n","Training loss per 100 training steps: 0.0320537709596084\n","Training loss per 100 training steps: 0.03236463759562149\n","Training loss per 100 training steps: 0.03239068960973722\n","Training loss epoch: 0.0321437645389612\n","Training accuracy epoch: 0.9906428717320261\n","Validating model...\n","Validation Loss: 0.20041132955663546\n","Validation Accuracy: 0.9561887254901961\n","Training epoch: 4\n","Training loss per 100 training steps: 0.003258197568356991\n","Training loss per 100 training steps: 0.01014081630468228\n","Training loss per 100 training steps: 0.018919781865171258\n","Training loss per 100 training steps: 0.020313974839475266\n","Training loss per 100 training steps: 0.021154690177027896\n","Training loss per 100 training steps: 0.021119569899343413\n","Training loss per 100 training steps: 0.022959790761751947\n","Training loss per 100 training steps: 0.022749905185511163\n","Training loss per 100 training steps: 0.022809517475770272\n","Training loss per 100 training steps: 0.022553867707461827\n","Training loss per 100 training steps: 0.022459113808888636\n","Training loss per 100 training steps: 0.02195775227338724\n","Training loss per 100 training steps: 0.02228061399936277\n","Training loss per 100 training steps: 0.02253488644756075\n","Training loss per 100 training steps: 0.022880447344884345\n","Training loss per 100 training steps: 0.023228427484528347\n","Training loss per 100 training steps: 0.023080673207486753\n","Training loss per 100 training steps: 0.023064043934889096\n","Training loss per 100 training steps: 0.023033875697764092\n","Training loss per 100 training steps: 0.0232293800894071\n","Stopping epoch...\n","Training loss epoch: 0.0232293800894071\n","Training accuracy epoch: 0.992832719621252\n","Validating model...\n","Validation Loss: 0.20490965883386797\n","Validation Accuracy: 0.9512768817204301\n","Training epoch: 5\n","Training loss per 100 training steps: 0.00287289684638381\n","Training loss per 100 training steps: 0.01228524789967376\n","Training loss per 100 training steps: 0.01655577672655585\n","Training loss per 100 training steps: 0.01458664610203583\n","Training loss per 100 training steps: 0.014627009870981197\n","Training loss per 100 training steps: 0.014371819315823734\n","Training loss per 100 training steps: 0.014437764484607037\n","Training loss per 100 training steps: 0.015549356515302848\n","Training loss per 100 training steps: 0.016558916016847558\n","Training loss per 100 training steps: 0.017626540412290444\n","Training loss per 100 training steps: 0.01766541117244056\n","Training loss per 100 training steps: 0.017485083890613855\n","Training loss per 100 training steps: 0.016924891750102925\n","Training loss per 100 training steps: 0.016764299268665395\n","Training loss per 100 training steps: 0.017573059364059333\n","Training loss per 100 training steps: 0.01801020504547697\n","Training loss per 100 training steps: 0.018561809041638164\n","Training loss per 100 training steps: 0.018314961766099046\n","Training loss per 100 training steps: 0.018421312852462617\n","Training loss per 100 training steps: 0.01832894021726866\n","Training loss per 100 training steps: 0.018733093940712917\n","Training loss per 100 training steps: 0.01924489500659933\n","Training loss per 100 training steps: 0.01983876758109704\n","Training loss per 100 training steps: 0.019675143709354297\n","Training loss per 100 training steps: 0.020380645318977486\n","Training loss epoch: 0.020498528917735657\n","Training accuracy epoch: 0.9939874387254902\n","Validating model...\n","Validation Loss: 0.21117387595358214\n","Validation Accuracy: 0.9512768817204301\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0013683560537174344\n","Training loss per 100 training steps: 0.00724458612045181\n","Training loss per 100 training steps: 0.007466987507844654\n","Training loss per 100 training steps: 0.009509869685057749\n","Training loss per 100 training steps: 0.010338885727533872\n","Training loss per 100 training steps: 0.010268641097703252\n","Training loss per 100 training steps: 0.010541660137191829\n","Training loss per 100 training steps: 0.011286096768550868\n","Training loss per 100 training steps: 0.01112923697441869\n","Training loss per 100 training steps: 0.011867392877514336\n","Training loss per 100 training steps: 0.012405834256310231\n","Training loss per 100 training steps: 0.013192148648332236\n","Training loss per 100 training steps: 0.014360784936608834\n","Training loss per 100 training steps: 0.01515159250834638\n","Training loss per 100 training steps: 0.016427619100163413\n","Training loss per 100 training steps: 0.016503664542253244\n","Training loss per 100 training steps: 0.016519986658294385\n","Training loss per 100 training steps: 0.01701231190440534\n","Training loss per 100 training steps: 0.016998622717384154\n","Training loss per 100 training steps: 0.017291526699187595\n","Training loss per 100 training steps: 0.017055595408651036\n","Training loss per 100 training steps: 0.017247366997603906\n","Training loss per 100 training steps: 0.01745732686459157\n","Training loss per 100 training steps: 0.01720209603970794\n","Training loss per 100 training steps: 0.01692613571319802\n","Training loss epoch: 0.016737658824928562\n","Training accuracy epoch: 0.9951491013071896\n","Validating model...\n","Validation Loss: 0.3015665532996839\n","Validation Accuracy: 0.9463848039215687\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0021621508058160543\n","Training loss per 100 training steps: 0.009900666811788169\n","Training loss per 100 training steps: 0.01187895344172382\n","Training loss per 100 training steps: 0.014815630865289305\n","Training loss per 100 training steps: 0.015671533773236757\n","Training loss per 100 training steps: 0.014113307016416143\n","Training loss per 100 training steps: 0.014275050488953497\n","Training loss per 100 training steps: 0.014063003711056076\n","Training loss per 100 training steps: 0.014848695075455949\n","Training loss per 100 training steps: 0.014602878778088465\n","Training loss per 100 training steps: 0.015187910494730589\n","Training loss per 100 training steps: 0.014963319845601812\n","Training loss per 100 training steps: 0.014683117286321924\n","Training loss per 100 training steps: 0.015091638743072436\n","Training loss per 100 training steps: 0.015783370913930044\n","Training loss per 100 training steps: 0.015552097759867269\n","Training loss per 100 training steps: 0.015918198709588046\n","Training loss per 100 training steps: 0.016067495466311785\n","Training loss per 100 training steps: 0.0163920249003762\n","Training loss per 100 training steps: 0.016251593430599492\n","Training loss per 100 training steps: 0.016128371891834754\n","Training loss per 100 training steps: 0.016033244553198954\n","Training loss per 100 training steps: 0.016187684598836564\n","Training loss per 100 training steps: 0.016218841089677583\n","Training loss per 100 training steps: 0.01587668941278179\n","Training loss epoch: 0.015776439215924674\n","Training accuracy epoch: 0.9955193014705882\n","Validating model...\n","Validation Loss: 0.2536141098159943\n","Validation Accuracy: 0.9497351359898798\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 116.96386296666667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.20824885985287742\n","Validation Accuracy: 0.950536908436214\n","Validation duration: 2.3809728666666463 minutes\n","F1-score (test): 84.5%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     problem       0.77      0.84      0.80      1170\n","        test       0.79      0.94      0.86      2464\n","   treatment       0.86      0.85      0.86      1244\n","\n","   micro avg       0.80      0.89      0.84      4878\n","   macro avg       0.81      0.88      0.84      4878\n","weighted avg       0.80      0.89      0.84      4878\n","\n"]}],"source":["number_of_training_models = 4\n","target_augmented_percentage = 5\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"bert_100_perc.ipynb","version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0108d79e6c044e25a5e22c7f965a3a51":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"023a35f772554933bab0d59f35b77bb6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0480ac1a2e8049299bf02279f6a61db8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08ff6bb81d00489eb652ae37cc6857b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0a139111b1d14abdbe78f1954f4db074":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd70526c927f40399354f60c836e6a28","max":227845,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dde3a25f3a7446edb26d09eb71e3ca74","value":227845}},"1758fd8b39c540119fe23e9ff392c616":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19c3618a1e154f289602544cb0974f6a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d6c5480caeb4e4fa2625ea4f04521ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f705afa1c244f5f8872f72a5a478674","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6c719a58e6494e398d89d457746fb90e","value":442221694}},"1ea2ebeb97534b1eb0e310d2a09a2578":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_50fc8ee8549a4c4baf8a4fd6bb38af53","IPY_MODEL_fecf780839074232b9abb31cd20b9412","IPY_MODEL_e596df6babe4418bb69835220e92c131"],"layout":"IPY_MODEL_f79d30bb531b44a2b2ef771899f4ffd4"}},"1fed38aba5a64fd591c9d0f45e35f3c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"235b742a69954796a4a5d871d6677d46":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1758fd8b39c540119fe23e9ff392c616","placeholder":"​","style":"IPY_MODEL_08ff6bb81d00489eb652ae37cc6857b5","value":" 422M/422M [00:06\u0026lt;00:00, 67.9MB/s]"}},"276c19cb8e774d37a90c777410668893":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d1c57b6981e4461daee162bbc97c0901","IPY_MODEL_1d6c5480caeb4e4fa2625ea4f04521ec","IPY_MODEL_235b742a69954796a4a5d871d6677d46"],"layout":"IPY_MODEL_4c124e1ccbdb44588bbac71b260bf35e"}},"3d64df06d90a4c0eafea39ddb86b4328":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41464c41b75c40678b743de76f4fec13":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"437d49453a6e44d48e69e9fbfb9b06c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4aff7cd3b4cb4749940853b250455730":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c124e1ccbdb44588bbac71b260bf35e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ec11bb27fa14af4a534b4d27780feec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_743f7124084e4f6da79c6f4e44e6148d","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8e45129b040e45b28678630f09084e34","value":442221694}},"4f705afa1c244f5f8872f72a5a478674":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50fc8ee8549a4c4baf8a4fd6bb38af53":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19c3618a1e154f289602544cb0974f6a","placeholder":"​","style":"IPY_MODEL_f3c72e4f20ca4849bfd11dba2518eb61","value":"Downloading: 100%"}},"5dbec3254d8945de947a51c8b8722eae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b561df2db37d40e2a9bdd50a1574932d","placeholder":"​","style":"IPY_MODEL_d909485c9dad4ff5991451f9cafd5211","value":"Downloading: 100%"}},"6c719a58e6494e398d89d457746fb90e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6c8f0806beb14cb09bc44876c54417c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"743f7124084e4f6da79c6f4e44e6148d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74b60ce626e340aa9067ed587bfb23d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_786fb40cfe344acc988a6da9b9d5da0d","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a590a2164128496b8a82c97ceafffe56","value":442221694}},"786fb40cfe344acc988a6da9b9d5da0d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7983bc4a426942b5b4b3eaa3cd98d1b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7cf791b898894496a3a02b723b4924dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d64df06d90a4c0eafea39ddb86b4328","placeholder":"​","style":"IPY_MODEL_6c8f0806beb14cb09bc44876c54417c9","value":"Downloading: 100%"}},"7eb2f29f94da4242b4b0266f347f2e0f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"81e044dbdc2e483db517e0c38f11bfc2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"836046a4d4aa4d0b81ed1af91176ad53":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fb1c461d8cae4076972d8d6ee88c879a","IPY_MODEL_f511c5eb3976465f95eb0aecce8e6dac","IPY_MODEL_d98a30e13b254efda4f9b605bfb18adb"],"layout":"IPY_MODEL_41464c41b75c40678b743de76f4fec13"}},"8689c4e734064d47a4d246abb047ef1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8759855cfe104f19832b822b0a9f9a74":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87f6aaf645a74035a929b54417644e8e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0480ac1a2e8049299bf02279f6a61db8","placeholder":"​","style":"IPY_MODEL_f02afbb6520348a284cfcccadd5df703","value":" 223k/223k [00:00\u0026lt;00:00, 650kB/s]"}},"8e45129b040e45b28678630f09084e34":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"982807cbbacd4346822fffd0efe539eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f8fa12cf7c94f7d98a380d12d5f8827":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8759855cfe104f19832b822b0a9f9a74","placeholder":"​","style":"IPY_MODEL_4aff7cd3b4cb4749940853b250455730","value":" 422M/422M [00:06\u0026lt;00:00, 67.3MB/s]"}},"a590a2164128496b8a82c97ceafffe56":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b31964c688ae482184788d604cdff405":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b320abd492d14e489149b93ee6884490":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b561df2db37d40e2a9bdd50a1574932d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6d6c473dea240a982cffe91821a3ee4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0e6b8eb256c4a89b64dcca543775583":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c7ea245d764d4a1e8b67c1f4bf9309d3","IPY_MODEL_4ec11bb27fa14af4a534b4d27780feec","IPY_MODEL_ce4aec64e56b4ec895f6f2666d26b14a"],"layout":"IPY_MODEL_e5f6e33318a8416e92946d514219ffb5"}},"c119eeda369f481c97005130b44e4ca0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c7ea245d764d4a1e8b67c1f4bf9309d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6d6c473dea240a982cffe91821a3ee4","placeholder":"​","style":"IPY_MODEL_982807cbbacd4346822fffd0efe539eb","value":"Downloading: 100%"}},"ce4aec64e56b4ec895f6f2666d26b14a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1c744f4f23848b1a95ba17021bbbb89","placeholder":"​","style":"IPY_MODEL_1fed38aba5a64fd591c9d0f45e35f3c9","value":" 422M/422M [00:11\u0026lt;00:00, 42.9MB/s]"}},"d1c57b6981e4461daee162bbc97c0901":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_023a35f772554933bab0d59f35b77bb6","placeholder":"​","style":"IPY_MODEL_7eb2f29f94da4242b4b0266f347f2e0f","value":"Downloading: 100%"}},"d1c744f4f23848b1a95ba17021bbbb89":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5f7825ec8434b4cb56939cfed2d6128":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d909485c9dad4ff5991451f9cafd5211":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d98a30e13b254efda4f9b605bfb18adb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8f6009764664e0e9cae3069af4acedf","placeholder":"​","style":"IPY_MODEL_8689c4e734064d47a4d246abb047ef1e","value":" 385/385 [00:00\u0026lt;00:00, 14.4kB/s]"}},"dd70526c927f40399354f60c836e6a28":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dde3a25f3a7446edb26d09eb71e3ca74":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"df64da9ae9f1418fb0d359b775c06c33":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2a31a50a2fa4c1ea0c10b181e7ec21a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e596df6babe4418bb69835220e92c131":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b320abd492d14e489149b93ee6884490","placeholder":"​","style":"IPY_MODEL_7983bc4a426942b5b4b3eaa3cd98d1b1","value":" 422M/422M [00:06\u0026lt;00:00, 70.5MB/s]"}},"e5f6e33318a8416e92946d514219ffb5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8f6009764664e0e9cae3069af4acedf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f02afbb6520348a284cfcccadd5df703":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f3c72e4f20ca4849bfd11dba2518eb61":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f511c5eb3976465f95eb0aecce8e6dac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0108d79e6c044e25a5e22c7f965a3a51","max":385,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e2a31a50a2fa4c1ea0c10b181e7ec21a","value":385}},"f6c82d5ab1664ebb81a6a49b66cd0d13":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5dbec3254d8945de947a51c8b8722eae","IPY_MODEL_0a139111b1d14abdbe78f1954f4db074","IPY_MODEL_87f6aaf645a74035a929b54417644e8e"],"layout":"IPY_MODEL_81e044dbdc2e483db517e0c38f11bfc2"}},"f79d30bb531b44a2b2ef771899f4ffd4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f85ac906facc4156a632d0b631e04ac4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7cf791b898894496a3a02b723b4924dd","IPY_MODEL_74b60ce626e340aa9067ed587bfb23d6","IPY_MODEL_9f8fa12cf7c94f7d98a380d12d5f8827"],"layout":"IPY_MODEL_df64da9ae9f1418fb0d359b775c06c33"}},"fb1c461d8cae4076972d8d6ee88c879a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b31964c688ae482184788d604cdff405","placeholder":"​","style":"IPY_MODEL_c119eeda369f481c97005130b44e4ca0","value":"Downloading: 100%"}},"fecf780839074232b9abb31cd20b9412":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5f7825ec8434b4cb56939cfed2d6128","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_437d49453a6e44d48e69e9fbfb9b06c0","value":442221694}}}}},"nbformat":4,"nbformat_minor":5}