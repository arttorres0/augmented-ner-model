{"cells":[{"cell_type":"markdown","metadata":{"id":"FFh7WVoJH5dr"},"source":["Adapted from [ner_with_bilstm_and_crf](https://www.kaggle.com/nikkisharma536/ner-with-bilstm-and-crf/notebook)\n","Altigran Soares da Silva\n","IComp/UFAM - 15/03/2021\n"],"id":"FFh7WVoJH5dr"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":22667,"status":"ok","timestamp":1660204157501,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"instant-coupon","outputId":"d00c360e-f599-49c8-c09c-d4539c554b64"},"outputs":[{"name":"stdout","output_type":"stream","text":["Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 5.1 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 11.6 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 64.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 78.5 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.21.1\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["yaml"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[?25l\r\u001b[K     |███████▌                        | 10 kB 27.9 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 43 kB 1.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=39bfb3912ffe070e6751372bc34964c4efaef1099484c67aede2819fd82c1a35\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n"]}],"source":["# For this to work, use:\n","# Keras 2.3.1\n","# Also remember to use GPU in your colab notebook\n","%tensorflow_version 2.x\n","\n","# Code to read csv file into Colaboratory:\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","from math import nan\n","from future.utils import iteritems\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import math\n","import random\n","import json\n","import pickle\n","import time\n","from requests import get\n","\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import torch\n","from torch import cuda\n","from torch.utils.data import Dataset, DataLoader\n","\n","!pip install sentencepiece\n","!pip install transformers\n","from transformers import BertForTokenClassification, AutoTokenizer\n","\n","!pip install seqeval\n","from seqeval.metrics import f1_score, classification_report"],"id":"instant-coupon"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mmt06ncv89hH"},"outputs":[],"source":["# Code to read csv file from google drive into Colaboratory:\n","DATA_TRAINING_FILE_ID = '1InFG9u6SJZJfUsEr6A-oqvvI_oZJl6d9'\n","DATA_TRAINING_FILENAME = 'ner_training_dataset.csv'\n","DATA_DEV_FILE_ID = '1d32cwSV9lmpIxhBhSwtDo27GB9K3XQYb'\n","DATA_DEV_FILENAME = 'ner_validation_dataset.csv'\n","DATA_TEST_FILE_ID = '1L-fnx31bK0nZAl9_DDfo7-25H7PYU0l8'\n","DATA_TEST_FILENAME = 'ner_test_dataset.csv'\n","BACKUP_FOLDER_ID = '1YWR4Ip8w94RwFMyMtNpRa9M0FpiJtqd5'\n","\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","downloaded_training = drive.CreateFile({'id': DATA_TRAINING_FILE_ID})\n","downloaded_training.GetContentFile(DATA_TRAINING_FILENAME)\n","downloaded_dev = drive.CreateFile({'id': DATA_DEV_FILE_ID})\n","downloaded_dev.GetContentFile(DATA_DEV_FILENAME)\n","downloaded_test = drive.CreateFile({'id': DATA_TEST_FILE_ID})\n","downloaded_test.GetContentFile(DATA_TEST_FILENAME)\n","\n","# Read the csv file in a dataframe called \"data\"\n","training_data = pd.read_csv(DATA_TRAINING_FILENAME, encoding=\"latin1\")\n","dev_data = pd.read_csv(DATA_DEV_FILENAME, encoding=\"latin1\")\n","test_data = pd.read_csv(DATA_TEST_FILENAME, encoding=\"latin1\")\n","# Fill NaN values using the specified method\n","# Ffill propagate last valid observation/value forward to next valid \n","training_data = training_data.fillna(method=\"ffill\")\n","dev_data = dev_data.fillna(method=\"ffill\")\n","test_data = test_data.fillna(method=\"ffill\")\n","\n","notebook_filename = get('http://172.28.0.2:9000/api/sessions').json()[0]['name']"],"id":"Mmt06ncv89hH"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":588},"executionInfo":{"elapsed":732,"status":"ok","timestamp":1660204173716,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"adverse-doctor","outputId":"7ff341f6-2598-4bf4-d01f-cec6480e108d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of training sentences:  13867\n","Number of dev sentences:  2448\n","Number of test sentences:  27625\n","Number of words in the training dataset:  14450\n","Number of words in the dev dataset:  5242\n","Number of words in the test dataset:  21696\n","Tags in the training dataset: ['I-treatment', 'B-problem', 'B-treatment', 'I-test', 'I-problem', 'O', 'B-test']\n","Number of Labels in the training dataset:  7\n","Tags in the dev dataset: ['I-treatment', 'B-problem', 'B-treatment', 'I-test', 'I-problem', 'O', 'B-test']\n","Number of Labels in the dev dataset:  7\n","Tags in the test dataset: ['I-treatment', 'B-problem', 'B-treatment', 'I-test', 'I-problem', 'O', 'B-test']\n","Number of Labels in the test dataset:  7\n","What the training dataset looks like:\n"]},{"data":{"text/html":["\n","  <div id=\"df-57d76005-fedd-4510-bb65-ca9fd2f752dc\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence #</th>\n","      <th>Word</th>\n","      <th>Tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sentence: 5851</td>\n","      <td>0802338</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sentence: 15815</td>\n","      <td>The</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sentence: 15815</td>\n","      <td>visualized</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sentence: 15815</td>\n","      <td>paranasal</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sentence: 15815</td>\n","      <td>sinuses</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Sentence: 15815</td>\n","      <td>are</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Sentence: 15815</td>\n","      <td>clear</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Sentence: 15815</td>\n","      <td>.</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Sentence: 4203</td>\n","      <td>Chem-7</td>\n","      <td>B-test</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Sentence: 4203</td>\n","      <td>:</td>\n","      <td>O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57d76005-fedd-4510-bb65-ca9fd2f752dc')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-57d76005-fedd-4510-bb65-ca9fd2f752dc button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-57d76005-fedd-4510-bb65-ca9fd2f752dc');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["        Sentence #        Word     Tag\n","0   Sentence: 5851     0802338       O\n","1  Sentence: 15815         The       O\n","2  Sentence: 15815  visualized       O\n","3  Sentence: 15815   paranasal       O\n","4  Sentence: 15815     sinuses       O\n","5  Sentence: 15815         are       O\n","6  Sentence: 15815       clear       O\n","7  Sentence: 15815           .       O\n","8   Sentence: 4203      Chem-7  B-test\n","9   Sentence: 4203           :       O"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Explore the input dataset\n","print(\"Number of training sentences: \", len(training_data.groupby(['Sentence #'])))\n","print(\"Number of dev sentences: \", len(dev_data.groupby(['Sentence #'])))\n","print(\"Number of test sentences: \", len(test_data.groupby(['Sentence #'])))\n","\n","training_words = list(set(training_data[\"Word\"].values))\n","n_training_words = len(training_words)\n","print(\"Number of words in the training dataset: \", n_training_words)\n","dev_words = list(set(dev_data[\"Word\"].values))\n","n_dev_words = len(dev_words)\n","print(\"Number of words in the dev dataset: \", n_dev_words)\n","test_words = list(set(test_data[\"Word\"].values))\n","n_test_words = len(test_words)\n","print(\"Number of words in the test dataset: \", n_test_words)\n","\n","training_tags = list(set(training_data[\"Tag\"].values))\n","print(\"Tags in the training dataset:\", training_tags)\n","n_training_tags = len(training_tags)\n","print(\"Number of Labels in the training dataset: \", n_training_tags)\n","dev_tags = list(set(dev_data[\"Tag\"].values))\n","print(\"Tags in the dev dataset:\", dev_tags)\n","n_dev_tags = len(dev_tags)\n","print(\"Number of Labels in the dev dataset: \", n_dev_tags)\n","test_tags = list(set(test_data[\"Tag\"].values))\n","print(\"Tags in the test dataset:\", test_tags)\n","n_test_tags = len(test_tags)\n","print(\"Number of Labels in the test dataset: \", n_test_tags)\n","\n","print(\"What the training dataset looks like:\")\n","# Show the first 10 rows\n","training_data.head(n=10)"],"id":"adverse-doctor"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3558,"status":"ok","timestamp":1660204177270,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"painful-karaoke","outputId":"27f52944-3bd3-43da-e2f3-57b19caabf8e"},"outputs":[{"data":{"text/plain":["[('Admission', 'O'), ('Date', 'O'), (':', 'O')]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# SentenceGetter re-organize \"data\" as an arry of sentences\n","# Each sentence is a list of pairs <word,tag> \n","class SentenceGetter(object):\n","    \n","    def __init__(self, dataset):\n","        self.n_sent = 1\n","        self.dataset = dataset\n","        self.empty = False\n","        agg_func = lambda s: [(w, t) for w,t in zip(s[\"Word\"].values.tolist(),\n","                                                        s[\"Tag\"].values.tolist())]\n","        self.grouped = self.dataset.groupby(\"Sentence #\").apply(agg_func)\n","        self.sentences = [s for s in self.grouped]\n","    \n","    def get_next(self):\n","        try:\n","            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n","            self.n_sent += 1\n","            return s\n","        except:\n","            return None\n","\n","training_getter = SentenceGetter(training_data)\n","training_sentences = training_getter.sentences\n","dev_getter = SentenceGetter(dev_data)\n","dev_sentences = dev_getter.sentences\n","test_getter = SentenceGetter(test_data)\n","test_sentences = test_getter.sentences\n","\n","# Example: training sentence #200 \n","training_sentences[200]"],"id":"painful-karaoke"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1660204177271,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"round-providence","outputId":"52c08d46-ff9f-4e84-f395-154d763b75b1"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Explore set of sentences\n","# Plot sentences by length\n","plt.hist([len(s) for s in training_sentences], bins=50)\n","plt.title('Token per training sentence')\n","plt.xlabel('Len (number of token)')\n","plt.ylabel('# samples')\n","plt.show()"],"id":"round-providence"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"elapsed":601,"status":"ok","timestamp":1660204177867,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"urxTzspTyPq5","outputId":"7b9a8f64-4d20-4b83-c640-e04bf1f6baf0"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Explore set of sentences\n","# Plot sentences by length\n","plt.hist([len(s) for s in dev_sentences], bins=50)\n","plt.title('Token per dev sentence')\n","plt.xlabel('Len (number of token)')\n","plt.ylabel('# samples')\n","plt.show()"],"id":"urxTzspTyPq5"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1660204177868,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"JJ91V_51yPw9","outputId":"ddc950bc-5632-4708-8c8b-4c63bc827a1c"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Explore set of sentences\n","# Plot sentences by length\n","plt.hist([len(s) for s in test_sentences], bins=50)\n","plt.title('Token per test sentence')\n","plt.xlabel('Len (number of token)')\n","plt.ylabel('# samples')\n","plt.show()"],"id":"JJ91V_51yPw9"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1660204178281,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"juvenile-scene","outputId":"33b5befa-9a4c-4c45-81e3-c6c84410c9c6"},"outputs":[{"name":"stdout","output_type":"stream","text":["17077\n","curettage\n","2\n","I-problem\n"]}],"source":["# Keras (and most other ML packages) expect all the ids to be numeric, \n","# this is an optimisation to save memory. \n","# We will create the following dictionaries:\n","# word2idx: assign a numeric index to each word in the dataset\n","# idx2word: inverted version of word2idx\n","# tag2idx: assign a numeric index to each tag in the dataset\n","# idx2tag: inverted version of tag2idx\n","\n","# Group training, dev and test data in order to create word-index dicts and to\n","# convert data to numeric indeces later\n","data = pd.concat([training_data, dev_data, test_data])\n","\n","# words <= list of all words in the input dataset\n","words = list(set(data[\"Word\"].values))\n","n_words = len(words)\n","\n","# tags <= list of all tags in the input dataset\n","tags = []\n","for tag in set(data[\"Tag\"].values):\n","    if tag is nan or isinstance(tag, float):\n","        tags.append('unk')\n","    else:\n","        tags.append(tag)\n","n_tags = len(tags)\n","\n","# Dictionaries\n","word2idx = {w: i for i, w in enumerate(words)}\n","idx2word = {i: w for w, i in iteritems(word2idx)}\n","tag2idx = {t: i for i, t in enumerate(tags)}\n","idx2tag = {v: k for k, v in iteritems(tag2idx)}\n","\n","# Index number for the word 'comprehension'\n","print(word2idx['comprehension'])\n","# Word of index 10\n","print(idx2word[10])\n","# Index number for the tag 'B-treatment'\n","print(tag2idx['B-treatment'])\n","# Tag of index 4\n","print(idx2tag[4])"],"id":"juvenile-scene"},{"cell_type":"code","execution_count":null,"metadata":{"id":"delayed-dryer"},"outputs":[],"source":["# Convert train, dev and test data to numeric values\n","X_train = [[word2idx[w[0]] for w in s] for s in training_sentences]\n","y_train = [[tag2idx[w[1]] for w in s] for s in training_sentences]\n","\n","X_dev = [[word2idx[w[0]] for w in s] for s in dev_sentences]\n","y_dev = [[tag2idx[w[1]] for w in s] for s in dev_sentences]\n","\n","X_test = [[word2idx[w[0]] for w in s] for s in test_sentences]\n","y_test = [[tag2idx[w[1]] for w in s] for s in test_sentences]"],"id":"delayed-dryer"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1660204178282,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"Ttsyh05Rhovo","outputId":"e946efe5-c094-44d3-fc16-2657fe38a508"},"outputs":[{"name":"stdout","output_type":"stream","text":["Points in X_train before removal: 13867\n","Points in y_train before removal: 13867\n","Points in X_train before removal: 10400\n","Points in y_train before removal: 10400\n"]}],"source":["# Use this function to randomly remove some points from training dataset\n","# Use removal percentage in decimal value. E.g.: if you set as 0.5, it will\n","# remove 50% of the dataset\n","\n","def random_remove_data_points(dataset, labels, removal_percentage):\n","    if removal_percentage < 0 or removal_percentage > 1:\n","        raise Exception(\"Invalid removal percentage\")\n","    \n","    if removal_percentage == 1:\n","        raise Exception(\"You can't remove the entire dataset\")\n","    \n","    number_of_points_remaining = round(len(dataset)*(1-removal_percentage))\n","\n","    try_again = True\n","\n","    while try_again:\n","      random_idxs = np.random.choice(len(dataset), number_of_points_remaining, replace=False)\n","      cut_dataset_sentences = [dataset[i] for i in random_idxs]\n","      cut_dataset_labels = [labels[i] for i in random_idxs]\n","      cut_tags = list(set([idx2tag[j] for sub in cut_dataset_labels for j in sub]))\n","\n","      if all(i in cut_tags for i in tags if i[:2] == \"B-\"):\n","        try_again = False\n","\n","    return cut_dataset_sentences, cut_dataset_labels \n","\n","print(f\"Points in X_train before removal: {len(X_train)}\")\n","print(f\"Points in y_train before removal: {len(y_train)}\")\n","X_train, y_train = random_remove_data_points(X_train, y_train, 0.25)\n","print(f\"Points in X_train before removal: {len(X_train)}\")\n","print(f\"Points in y_train before removal: {len(y_train)}\")"],"id":"Ttsyh05Rhovo"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0SN-NYLpgsFa"},"outputs":[],"source":["# Aux functions to save data and dicts, if data consistency is important\n","# and there is desire to not random split again\n","\n","def save_backup_dataset(dataset, filename):\n","  dataset_df = pd.DataFrame(dataset)\n","  dataset_df.to_csv(filename, index=False)\n","  gfile = drive.CreateFile({'parents': [{'id': BACKUP_FOLDER_ID}]})\n","  gfile.SetContentFile(filename)\n","  gfile.Upload()\n","\n","def save_backup_dict(dict, filename):\n","  dict_file = open(filename, \"wb\")\n","  pickle.dump(dict, dict_file)\n","  dict_file.close()\n","  gfile = drive.CreateFile({'parents': [{'id': BACKUP_FOLDER_ID}]})\n","  gfile.SetContentFile(filename)\n","  gfile.Upload()"],"id":"0SN-NYLpgsFa"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":242},"executionInfo":{"elapsed":13,"status":"error","timestamp":1663003713071,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"MzRQfI30tuI2","outputId":"20aea735-7838-410e-c714-56ce6af21d5d"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d1eb312330ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Check some points before saving\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"]}],"source":["# Uncomment this cell if you want to save data for further use\n","\n","# Check some points before saving\n","print(X_train[0])\n","print(y_train[0])\n","print(X_dev[0])\n","print(y_dev[0])\n","print(X_test[0])\n","print(y_test[0])\n","print(word2idx['comprehension'])\n","print(tag2idx['B-treatment'])\n","print(idx2tag[2])\n","print(idx2word[100])\n","print(n_words)\n","print(n_tags)\n","\n","X_train_filename = f'{notebook_filename}_X_train.csv'\n","y_train_filename = f'{notebook_filename}_y_train.csv'\n","X_dev_filename = f'{notebook_filename}_X_dev.csv'\n","y_dev_filename = f'{notebook_filename}_y_dev.csv'\n","X_test_filename = f'{notebook_filename}_X_test.csv'\n","y_test_filename = f'{notebook_filename}_y_test.csv'\n","\n","word2idx_filename = f'{notebook_filename}_word2idx.pkl'\n","idx2word_filename = f'{notebook_filename}_idx2word.pkl'\n","tag2idx_filename = f'{notebook_filename}_tag2idx.pkl'\n","idx2tag_filename = f'{notebook_filename}_idx2tag.pkl'\n","\n","others_filename = f'{notebook_filename}_others.pkl'\n","\n","save_backup_dataset(X_train, X_train_filename)\n","save_backup_dataset(y_train, y_train_filename)\n","save_backup_dataset(X_dev, X_dev_filename)\n","save_backup_dataset(y_dev, y_dev_filename)\n","save_backup_dataset(X_test, X_test_filename)\n","save_backup_dataset(y_test, y_test_filename)\n","\n","save_backup_dict(word2idx, word2idx_filename)\n","save_backup_dict(idx2word, idx2word_filename)\n","save_backup_dict(tag2idx, tag2idx_filename)\n","save_backup_dict(idx2tag, idx2tag_filename)\n","\n","save_backup_dict({\"n_words\":n_words, \"n_tags\":n_tags}, others_filename)"],"id":"MzRQfI30tuI2"},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["c631fa573bc34eafbf113d4e018afe65","a111c5e826ab4be58cae5a7f3af95e94","535290cff93a45f4bada025eaab4eff8","4f0a61d7e48543b08b387e33475d295d","11121e627af64c21a10ac585c21ebe9f","8a988982cc84417d848419ce63f65d14","f9905291d00843b598bde6f6db21b2be","86eea101b95e4e3ba1698223e507a48d","8bb580a498994889a2df1592a0a15f1d","7b76e80d789248b393adfd553f87a5b3","590227fa043b407db61c2b0b5ca03da1"]},"executionInfo":{"elapsed":97459,"status":"ok","timestamp":1663274407616,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"zvip_oC0j5-y","outputId":"5ed52153-3b2f-4bdd-bdbd-c4a8f5e5c1a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 14.1 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.22.0-py3-none-any.whl (4.9 MB)\n","\u001b[K     |████████████████████████████████| 4.9 MB 14.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Collecting huggingface-hub<1.0,>=0.9.0\n","  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n","\u001b[K     |████████████████████████████████| 120 kB 94.6 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 87.6 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.22.0\n"]},{"output_type":"stream","name":"stderr","text":["The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"]},{"output_type":"stream","name":"stdout","text":["Moving 0 files to the new cache system\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c631fa573bc34eafbf113d4e018afe65"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 2.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=76dcabc76c41bee418958b627e04a2633c2a2c00244390ba8cd391b74317f99c\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n","[2158, 24943]\n","[5, 5]\n","[26193, 5489, 13041, 21644, 21084, 14996, 22881, 12397, 16282, 13698, 12383, 3573]\n","[1, 4, 4, 4, 4, 4, 5, 6, 3, 3, 3, 5]\n","[13337, 16888, 13823]\n","[5, 5, 5]\n","17077\n","2\n","B-treatment\n","lovenox\n","28388\n","7\n"]}],"source":["# Uncomment this cell if you want to load saved data\n","\n","# Re-import necessary libs\n","import pandas as pd\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","import pickle, math\n","from requests import get\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import random\n","import time\n","%tensorflow_version 2.x\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import torch\n","from torch import cuda\n","from torch.utils.data import Dataset, DataLoader\n","!pip install sentencepiece\n","!pip install transformers\n","from transformers import BertForTokenClassification, AutoTokenizer\n","import matplotlib.pyplot as plt\n","!pip install seqeval\n","from seqeval.metrics import f1_score, classification_report\n","\n","BACKUP_FOLDER_ID = '1YWR4Ip8w94RwFMyMtNpRa9M0FpiJtqd5'\n","notebook_filename = get('http://172.28.0.2:9000/api/sessions').json()[0]['name']\n","\n","X_train_filename = f'{notebook_filename}_X_train.csv'\n","y_train_filename = f'{notebook_filename}_y_train.csv'\n","X_dev_filename = f'{notebook_filename}_X_dev.csv'\n","y_dev_filename = f'{notebook_filename}_y_dev.csv'\n","X_test_filename = f'{notebook_filename}_X_test.csv'\n","y_test_filename = f'{notebook_filename}_y_test.csv'\n","\n","word2idx_filename = f'{notebook_filename}_word2idx.pkl'\n","idx2word_filename = f'{notebook_filename}_idx2word.pkl'\n","tag2idx_filename = f'{notebook_filename}_tag2idx.pkl'\n","idx2tag_filename = f'{notebook_filename}_idx2tag.pkl'\n","\n","others_filename = f'{notebook_filename}_others.pkl'\n","\n","# Re-get important variables\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","def get_backup_files_ids(folder_id):\n","  file_list = drive.ListFile({'q': \"'{}' in parents and trashed=false\".format(folder_id)}).GetList()\n","  return file_list\n","\n","def load_backup_dataset(file_id):\n","  downloaded = drive.CreateFile({'id':file_id})\n","  downloaded.GetContentFile(f\"{file_id}.csv\")\n","\n","  dataset = pd.read_csv(f\"{file_id}.csv\", encoding=\"latin1\")\n","  dataset = dataset.values.tolist()\n","  dataset = [ [ int(word) for word in sentence if str(word) != 'nan' ] for sentence in dataset]\n","  return dataset\n","\n","def load_backup_dict(file_id):\n","  downloaded = drive.CreateFile({'id':file_id})\n","  downloaded.GetContentFile(f\"{file_id}.pkl\")\n","\n","  dict_file = open(f\"{file_id}.pkl\", \"rb\")\n","  out_dict = pickle.load(dict_file)\n","  return out_dict\n","\n","backup_file_list = get_backup_files_ids(BACKUP_FOLDER_ID)\n","\n","X_train_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == X_train_filename][0]['id']\n","y_train_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == y_train_filename][0]['id']\n","X_dev_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == X_dev_filename][0]['id']\n","y_dev_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == y_dev_filename][0]['id']\n","X_test_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == X_test_filename][0]['id']\n","y_test_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == y_test_filename][0]['id']\n","\n","word2idx_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == word2idx_filename][0]['id']\n","idx2word_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == idx2word_filename][0]['id']\n","tag2idx_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == tag2idx_filename][0]['id']\n","idx2tag_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == idx2tag_filename][0]['id']\n","\n","others_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == others_filename][0]['id']\n","\n","X_train = load_backup_dataset(X_train_file_id)\n","y_train = load_backup_dataset(y_train_file_id)\n","X_dev = load_backup_dataset(X_dev_file_id)\n","y_dev = load_backup_dataset(y_dev_file_id)\n","X_test = load_backup_dataset(X_test_file_id)\n","y_test = load_backup_dataset(y_test_file_id)\n","\n","word2idx = load_backup_dict(word2idx_file_id)\n","idx2word = load_backup_dict(idx2word_file_id)\n","tag2idx = load_backup_dict(tag2idx_file_id)\n","idx2tag = load_backup_dict(idx2tag_file_id)\n","\n","others = load_backup_dict(others_file_id)\n","\n","n_words = others[\"n_words\"]\n","n_tags = others[\"n_tags\"]\n","\n","# Check some points after loading data to see if they match the ones before saving\n","print(X_train[0])\n","print(y_train[0])\n","print(X_dev[0])\n","print(y_dev[0])\n","print(X_test[0])\n","print(y_test[0])\n","print(word2idx['comprehension'])\n","print(tag2idx['B-treatment'])\n","print(idx2tag[2])\n","print(idx2word[100])\n","print(n_words)\n","print(n_tags)"],"id":"zvip_oC0j5-y"},{"cell_type":"code","execution_count":2,"metadata":{"id":"ux5-6tyMhovp","executionInfo":{"status":"ok","timestamp":1663274407616,"user_tz":240,"elapsed":7,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}}},"outputs":[],"source":["# Aux function to help in augmentation. Generates a dict where entities\n","# are the keys, and words are the values.\n","\n","def create_entities_dict(dataset, labels, decoded_word=False):\n","    entities_dict = {}\n","    \n","    for i, sentence in enumerate(dataset):\n","        for k, word in enumerate(sentence):\n","            tag = idx2tag[labels[i][k]]\n","            if tag[:2] == \"B-\":\n","                if decoded_word:\n","                    word_list = [idx2word[word]]\n","                else:\n","                    word_list = [word]\n","                j = k + 1\n","                if j < len(labels[i]):\n","                    while idx2tag[labels[i][j]][:2] == \"I-\":\n","                        if decoded_word:\n","                            word_list.append(idx2word[dataset[i][j]])\n","                        else:\n","                            word_list.append(dataset[i][j])\n","                        j = j+1\n","                        if j == len(labels[i]):\n","                            break\n","                        \n","                if entities_dict.get(tag):\n","                    if word_list not in entities_dict[tag]:\n","                        entities_dict[tag].append(word_list)\n","                else:\n","                    entities_dict[tag] = [word_list]\n","                    \n","    return entities_dict\n","\n","entities_dict = create_entities_dict(X_train, y_train)"],"id":"ux5-6tyMhovp"},{"cell_type":"code","execution_count":3,"metadata":{"id":"2wRVTj71hovp","executionInfo":{"status":"ok","timestamp":1663274407616,"user_tz":240,"elapsed":6,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}}},"outputs":[],"source":["# Augmentation function using entity replacement technique.\n","# It will generate a new dataset, with X% more points based on\n","# the original dataset. E.g.: if you set augmentation percentage as 0.5 and dataset has\n","# 1000 points, it will generate a dataset with 1500 points.\n","\n","def generate_sentences(dataset, labels, entities_dict, augmented_set_size_percentage):\n","    if augmented_set_size_percentage < 0:\n","        raise Exception(\"Invalid augmented set size percentage\")\n","\n","    number_of_new_sentences = math.ceil(augmented_set_size_percentage * len(dataset))\n","    random_idxs = np.random.choice(len(dataset), number_of_new_sentences, replace=True)\n","    \n","    base_sequences = [dataset[i] for i in random_idxs]\n","    base_labels = [labels[i] for i in random_idxs]\n","\n","    new_sequences = []\n","    new_labels = []\n","    \n","    for k, sequence in enumerate(base_sequences):\n","        new_sequence = []\n","        new_label = []\n","\n","        for i, word in enumerate(sequence):\n","            tag = idx2tag[base_labels[k][i]]\n","            if tag == \"O\":\n","                new_sequence.append(word)\n","                new_label.append(base_labels[k][i])\n","            elif tag[:2] == \"B-\":\n","                same_entities_type_tmp = entities_dict[tag]\n","                same_entities_type = np.array(same_entities_type_tmp, dtype=object)\n","                random_entity_idx = np.random.choice(len(same_entities_type), 1)[0]\n","                random_entity = same_entities_type[random_entity_idx]\n","                random_number_of_tokens = random.randint(1, len(random_entity))\n","                random_entity_tokens = np.random.choice(random_entity, random_number_of_tokens, replace = False).tolist()\n","                entity = tag[2:]\n","                decoded_token_labels = [f\"I-{entity}\" for token in random_entity_tokens]\n","                decoded_token_labels[0] = tag\n","                encoded_token_labels = [tag2idx[label] for label in decoded_token_labels]\n","                new_sequence = new_sequence + random_entity_tokens\n","                new_label = new_label + encoded_token_labels\n","\n","        new_sequences.append(new_sequence)\n","        new_labels.append(new_label)\n","\n","    augmented_X_train = dataset + new_sequences\n","    augmented_y_train = labels + new_labels\n","\n","    print(f\"Points in X_train after augmentation: {len(augmented_X_train)}\")\n","    print(f\"Points in y_train after augmentation: {len(augmented_y_train)}\")\n","\n","    return augmented_X_train, augmented_y_train"],"id":"2wRVTj71hovp"},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["addd27a142ba46ff80e97790370921bf","01b2505f04ec478a936db3d74bfc6a81","491bd9fea64049babacf83a7bd0948ff","66c397fcea274c1185f0917419c219b4","2322b3af723747c0bdf4fad716dc19ba","941ab7af1311403f91f264e28faba315","75ade324d0cb4d8ca43cebfe6bb140d9","585265746b0f4578b0ae9a9247d2394b","9bd824919b9f47eebb9bc757d6caf087","d509ff9d70884d689598ddeef8cddc19","e52bd61e089b46d1965f10203624b568","697a349b7b8b42bf899447f187c7c6fb","b103889bf8134f3182fbac1c4624ea5e","d982cc83a9ae43999d026d862c649fa0","cbfa298ce7f5434da8b3e272bfc7f0ef","96bcf4fe895145a09485cbb0cd70043f","d2ea4d0941344b6d972a65fce125fc76","b121188b42ab49aeaacff5a047f625c5","359b414844324309936cb62140ffd2b3","18f6f36dc74d43aeb6a0f4474f60fa16","abc7e8745f584378843a5b2f3c7e3ebd","4e6fc455ecc247bd93c72de835c66054"]},"executionInfo":{"elapsed":3967,"status":"ok","timestamp":1663274411578,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"mYHzTnzZZfBg","outputId":"cc3c655c-f3ba-4c1e-9710-20f49940f7cb"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/385 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"addd27a142ba46ff80e97790370921bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/228k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"697a349b7b8b42bf899447f187c7c6fb"}},"metadata":{}}],"source":["tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n","\n","class dataset(Dataset):\n","  def __init__(self, dataframe, tokenizer, max_len):\n","        self.len = len(dataframe)\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","  def __getitem__(self, index):\n","        # step 1: get the sentence and word labels\n","        sentence = self.data.sentence[index]\n","        word_labels = self.data.word_labels[index].split(\",\") \n","\n","        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n","        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n","        encoding = self.tokenizer(sentence,\n","                             is_split_into_words=True,\n","                             return_offsets_mapping=True, \n","                             padding='max_length', \n","                             truncation=True, \n","                             max_length=self.max_len)\n","        \n","        # step 3: create token labels only for first word pieces of each tokenized word\n","        labels = [tag2idx[label] for label in word_labels] \n","        # code based on https://huggingface.co/transformers/custom_datasets.html#tok-ner\n","        # create an empty array of -100 of length max_length\n","        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n","        \n","        # set only labels whose first offset position is 0 and the second is not 0\n","        i = 0\n","        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n","          if mapping[0] == 0 and mapping[1] != 0:\n","            # overwrite label\n","            encoded_labels[idx] = labels[i]\n","            i += 1\n","\n","        # step 4: turn everything into PyTorch tensors\n","        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n","        item['labels'] = torch.as_tensor(encoded_labels)\n","        \n","        return item\n","\n","  def __len__(self):\n","        return self.len"],"id":"mYHzTnzZZfBg"},{"cell_type":"code","execution_count":5,"metadata":{"id":"d8H1s-6b_-pM","executionInfo":{"status":"ok","timestamp":1663274411578,"user_tz":240,"elapsed":5,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}}},"outputs":[],"source":["# some configuration variables\n","LEARNING_RATE = 5e-05\n","MAX_GRAD_NORM = 10\n","TRAINING_STOP_LOSS_PERCENTAGE = 1\n","\n","# Model creation function\n","def create_model(maxlen, n_labels, training_set, testing_set, validation_set):\n","  device = 'cuda' if cuda.is_available() else 'cpu'\n","  print(\"Device: \", device)\n","\n","  model = BertForTokenClassification.from_pretrained('allenai/scibert_scivocab_uncased', num_labels=n_labels)\n","  model.to(device)\n","\n","  optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n","\n","  TRAIN_BATCH_SIZE = round(0.05*len(training_set))\n","  if TRAIN_BATCH_SIZE > 32:\n","    TRAIN_BATCH_SIZE = 32\n","  if TRAIN_BATCH_SIZE < 10:\n","    TRAIN_BATCH_SIZE = 10\n","\n","  VALID_BATCH_SIZE = round(0.1*len(validation_set))\n","  if VALID_BATCH_SIZE > 32:\n","    VALID_BATCH_SIZE = 32\n","  if VALID_BATCH_SIZE < 10:\n","    VALID_BATCH_SIZE = 10\n","\n","  train_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                  'shuffle': True,\n","                  'num_workers': 0\n","                  }\n","\n","  test_params = {'batch_size': VALID_BATCH_SIZE,\n","                  'shuffle': True,\n","                  'num_workers': 0\n","                  }\n","\n","  training_loader = DataLoader(training_set, **train_params)\n","  testing_loader = DataLoader(testing_set, **test_params)\n","  validation_loader = DataLoader(validation_set, **test_params)\n","\n","  return model, device, optimizer, training_loader, testing_loader, validation_loader"],"id":"d8H1s-6b_-pM"},{"cell_type":"code","execution_count":6,"metadata":{"id":"cjp-jXx4AmiV","executionInfo":{"status":"ok","timestamp":1663274411578,"user_tz":240,"elapsed":5,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}}},"outputs":[],"source":["# Model training function\n","def train(model, device, optimizer, training_loader, epoch, training_stop_loss_percentage):\n","    tr_loss, tr_accuracy = 0, 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","    tr_preds, tr_labels = [], []\n","    losses = []\n","    # put model in training mode\n","    model.train()\n","    \n","    for idx, batch in enumerate(training_loader):\n","        \n","        ids = batch['input_ids'].to(device, dtype = torch.long)\n","        mask = batch['attention_mask'].to(device, dtype = torch.long)\n","        labels = batch['labels'].to(device, dtype = torch.long)\n","\n","        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels, return_dict = False)\n","        tr_loss += loss.item()\n","\n","        nb_tr_steps += 1\n","        nb_tr_examples += labels.size(0)\n","        \n","        if idx % 100==0:\n","            loss_step = tr_loss/nb_tr_steps\n","            print(f\"Training loss per 100 training steps: {loss_step}\")\n","            losses.append(loss_step)\n","            last_5_losses = losses[-5:]\n","            loss_min = min(last_5_losses)\n","            loss_max = max(last_5_losses)\n","            if len(last_5_losses) > 1 and (loss_max - loss_min)/loss_max < training_stop_loss_percentage/100:\n","              print(\"Stopping epoch...\")\n","              break\n","           \n","        # compute training accuracy\n","        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","        \n","        # only compute accuracy at active labels\n","        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n","        \n","        labels = torch.masked_select(flattened_targets, active_accuracy)\n","        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","        \n","        tr_labels.extend(labels)\n","        tr_preds.extend(predictions)\n","\n","        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n","        tr_accuracy += tmp_tr_accuracy\n","    \n","        # gradient clipping\n","        torch.nn.utils.clip_grad_norm_(\n","            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n","        )\n","        \n","        # backward pass\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    epoch_loss = tr_loss / nb_tr_steps\n","    tr_accuracy = tr_accuracy / nb_tr_steps\n","    print(f\"Training loss epoch: {epoch_loss}\")\n","    print(f\"Training accuracy epoch: {tr_accuracy}\")"],"id":"cjp-jXx4AmiV"},{"cell_type":"code","execution_count":7,"metadata":{"id":"JvdztU6FA8Bd","executionInfo":{"status":"ok","timestamp":1663274411579,"user_tz":240,"elapsed":6,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}}},"outputs":[],"source":["# Model testing function\n","def test(model, device, testing_loader):\n","    print(\"Validating model...\")\n","    # put model in evaluation mode\n","    model.eval()\n","    \n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_examples, nb_eval_steps = 0, 0\n","    eval_preds, eval_labels = [], []\n","    \n","    with torch.no_grad():\n","        for idx, batch in enumerate(testing_loader):\n","            \n","            ids = batch['input_ids'].to(device, dtype = torch.long)\n","            mask = batch['attention_mask'].to(device, dtype = torch.long)\n","            labels = batch['labels'].to(device, dtype = torch.long)\n","            \n","            loss, eval_logits = model(input_ids=ids, attention_mask=mask, labels=labels, return_dict = False)\n","            \n","            eval_loss += loss.item()\n","\n","            nb_eval_steps += 1\n","            nb_eval_examples += labels.size(0)\n","        \n","            # compute evaluation accuracy\n","            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","            \n","            # only compute accuracy at active labels\n","            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","        \n","            labels = torch.masked_select(flattened_targets, active_accuracy)\n","            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","            \n","            eval_labels.extend(labels)\n","            eval_preds.extend(predictions)\n","            \n","            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n","            eval_accuracy += tmp_eval_accuracy\n","\n","    labels = [idx2tag[id.item()] for id in eval_labels]\n","    predictions = [idx2tag[id.item()] for id in eval_preds]\n","    \n","    eval_loss = eval_loss / nb_eval_steps\n","    eval_accuracy = eval_accuracy / nb_eval_steps\n","    print(f\"Validation Loss: {eval_loss}\")\n","    print(f\"Validation Accuracy: {eval_accuracy}\")\n","\n","    return labels, predictions, eval_loss"],"id":"JvdztU6FA8Bd"},{"cell_type":"code","execution_count":8,"metadata":{"id":"jMknjbDrh6Fk","executionInfo":{"status":"ok","timestamp":1663274411579,"user_tz":240,"elapsed":5,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}}},"outputs":[],"source":["def create_train_and_validate_model(augmented_percentage):\n","\n","  augmented_X_train, augmented_y_train = generate_sentences(X_train, y_train, entities_dict, augmented_percentage)\n","\n","  maxlen_X_train = max([len(s) for s in augmented_X_train])\n","  maxlen_X_test = max([len(s) for s in X_test])\n","  maxlen_X_dev = max([len(s) for s in X_dev])\n","  maxlen_y_train = max([len(s) for s in augmented_y_train])\n","  maxlen_y_test = max([len(s) for s in y_test])\n","  maxlen_y_dev = max([len(s) for s in y_dev])\n","\n","  maxlen = max([maxlen_X_train, maxlen_X_test, maxlen_X_dev, maxlen_y_train, maxlen_y_test, maxlen_y_dev])\n","\n","  augmented_X_train_words = [[idx2word[word] for word in sentence] for sentence in augmented_X_train]\n","  X_dev_words = [[idx2word[word] for word in sentence] for sentence in X_dev]\n","  X_test_words = [[idx2word[word] for word in sentence] for sentence in X_test]\n","  augmented_y_train_tags = [','.join([idx2tag[tag] for tag in sentence]) for sentence in augmented_y_train]\n","  y_dev_tags = [','.join([idx2tag[tag] for tag in sentence]) for sentence in y_dev]\n","  y_test_tags = [','.join([idx2tag[tag] for tag in sentence]) for sentence in y_test]\n","\n","  new_train_df = pd.DataFrame({\"sentence\": augmented_X_train_words, \"word_labels\": augmented_y_train_tags}).reset_index(drop=True)\n","  new_test_df = pd.DataFrame({\"sentence\": X_test_words, \"word_labels\": y_test_tags}).reset_index(drop=True)\n","  new_val_df = pd.DataFrame({\"sentence\": X_dev_words, \"word_labels\": y_dev_tags}).reset_index(drop=True)\n","\n","  training_set = dataset(new_train_df, tokenizer, maxlen)\n","  testing_set = dataset(new_test_df, tokenizer, maxlen)\n","  validation_set = dataset(new_val_df, tokenizer, maxlen)\n","\n","  model, device, optimizer, training_loader, testing_loader, val_loader = create_model(maxlen, len(tag2idx), training_set, testing_set, validation_set)\n","\n","  training_start_time = time.clock()\n","  min_val_loss = 0\n","  MAX_PATIENCE = 5\n","  patience = 0\n","\n","  for epoch in range(100):\n","    print(f\"Training epoch: {epoch + 1}\")\n","    if patience == MAX_PATIENCE:\n","      print(\"Patience limit reached\")\n","      break\n","    train(model, device, optimizer, training_loader, epoch, TRAINING_STOP_LOSS_PERCENTAGE)\n","    labels, predictions, val_loss = test(model, device, val_loader)\n","    if ((min_val_loss == 0) or (min_val_loss != 0 and val_loss < min_val_loss)):\n","      min_val_loss = val_loss\n","      torch.save(model.state_dict(), 'checkpoint.pt')\n","      patience = 0\n","    else:\n","      patience = patience + 1\n","  print(f\"Training duration: {(time.clock() - training_start_time)/60} minutes\")\n","\n","  checkpoint = torch.load('checkpoint.pt')\n","  model.load_state_dict(checkpoint)\n","\n","  validation_start_time = time.clock()\n","  labels, predictions, test_loss = test(model, device, testing_loader)\n","  labels = [labels]\n","  predictions = [predictions]\n","  print(f\"Validation duration: {(time.clock() - validation_start_time)/60} minutes\")\n","\n","  print(\"F1-score (test): {:.1%}\".format(f1_score(labels, predictions)))\n","  print(classification_report(labels, predictions))"],"id":"jMknjbDrh6Fk"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d7e790affc224260ba0287b41d541400","33e9181dfd65491cb79b59c2b88700b6","1595efc37ff34a24beb6036eb3b1fc16","3124d71931f44156a6737e7747a2ea67","7f39218bd9e94f42804878d7b24bf091","06fb4d9d9a314f9f96a25e5a9ba72dce","e7a7ede4d38646049398f410b2a6436d","082416fbe0374a70aa840d32373b1804","1adf0f98ae5f420a8d9754a48719ab18","860be2970fe04c79a6295e7ece6c32b5","91b53b5485fd46f8a6d4049fbeb9f213"]},"id":"bM0wPLD5kaw4","outputId":"0f2a5268-0e9c-4b60-a23b-8be0cbdb5f24"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 10400\n","Points in y_train after augmentation: 10400\n","Device:  cuda\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d7e790affc224260ba0287b41d541400","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/422M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.3203089237213135\n","Training loss per 100 training steps: 0.40761561514717515\n","Training loss per 100 training steps: 0.3028717945649553\n","Training loss per 100 training steps: 0.2597341483019515\n","Training loss epoch: 0.2512640300163856\n","Training accuracy epoch: 0.91981688390127\n","Validating model...\n","Validation Loss: 0.13302011889490215\n","Validation Accuracy: 0.9574930571189033\n","Training epoch: 2\n","Training loss per 100 training steps: 0.10531175881624222\n","Training loss per 100 training steps: 0.09124035397452293\n","Training loss per 100 training steps: 0.09804092038107749\n","Training loss per 100 training steps: 0.09594611368726852\n","Training loss epoch: 0.0952254389742246\n","Training accuracy epoch: 0.9694504683638766\n","Validating model...\n","Validation Loss: 0.14844561370646026\n","Validation Accuracy: 0.9563273218678909\n","Training epoch: 3\n","Training loss per 100 training steps: 0.047116708010435104\n","Training loss per 100 training steps: 0.05026771921184984\n","Training loss per 100 training steps: 0.055307311112459616\n","Training loss per 100 training steps: 0.056702777628858024\n","Training loss epoch: 0.05689052287202615\n","Training accuracy epoch: 0.9817463097815567\n","Validating model...\n","Validation Loss: 0.15477102327269393\n","Validation Accuracy: 0.9587845108824316\n","Training epoch: 4\n","Training loss per 100 training steps: 0.028631897643208504\n","Training loss per 100 training steps: 0.04413912292468444\n","Training loss per 100 training steps: 0.045235003894936315\n","Training loss per 100 training steps: 0.04201446577328013\n","Training loss epoch: 0.04188773590283325\n","Training accuracy epoch: 0.98717935687216\n","Validating model...\n","Validation Loss: 0.16893240640109236\n","Validation Accuracy: 0.9585744086338482\n","Training epoch: 5\n","Training loss per 100 training steps: 0.012831621803343296\n","Training loss per 100 training steps: 0.025112443761485123\n","Training loss per 100 training steps: 0.027659039165991457\n","Training loss per 100 training steps: 0.029307410950955015\n","Training loss epoch: 0.02936168019623997\n","Training accuracy epoch: 0.9908572082986589\n","Validating model...\n","Validation Loss: 0.16557044204469626\n","Validation Accuracy: 0.9585916671993582\n","Training epoch: 6\n","Training loss per 100 training steps: 0.009079726412892342\n","Training loss per 100 training steps: 0.01943097204329575\n","Training loss per 100 training steps: 0.021551359010471116\n","Training loss per 100 training steps: 0.02483258563971017\n","Training loss epoch: 0.024559269770979882\n","Training accuracy epoch: 0.9925588650903923\n","Validating model...\n","Validation Loss: 0.18336195101834496\n","Validation Accuracy: 0.9601560241343163\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 22.446727066666668 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14249950173824025\n","Validation Accuracy: 0.9551748864525857\n","Validation duration: 3.6336561666666665 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.86      0.84     12546\n","        test       0.84      0.86      0.85      9012\n","   treatment       0.84      0.83      0.84      9297\n","\n","   micro avg       0.83      0.85      0.84     30855\n","   macro avg       0.84      0.85      0.84     30855\n","weighted avg       0.83      0.85      0.84     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 10400\n","Points in y_train after augmentation: 10400\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1714978218078613\n","Training loss per 100 training steps: 0.3961095093648032\n","Training loss per 100 training steps: 0.28823489221322596\n","Training loss per 100 training steps: 0.2473734506959733\n","Training loss epoch: 0.24176963525322767\n","Training accuracy epoch: 0.9240612688864929\n","Validating model...\n","Validation Loss: 0.13831515982747078\n","Validation Accuracy: 0.9557598605684339\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07780487090349197\n","Training loss per 100 training steps: 0.09563073584127545\n","Training loss per 100 training steps: 0.09526635203232516\n","Training loss per 100 training steps: 0.09245152334586726\n","Training loss epoch: 0.09236828974806345\n","Training accuracy epoch: 0.9704033667092682\n","Validating model...\n","Validation Loss: 0.14085623455028257\n","Validation Accuracy: 0.9555936249594793\n","Training epoch: 3\n","Training loss per 100 training steps: 0.08618216961622238\n","Training loss per 100 training steps: 0.05318350656105593\n","Training loss per 100 training steps: 0.055600239665928614\n","Training loss per 100 training steps: 0.06059607341297689\n","Training loss epoch: 0.06159892155144077\n","Training accuracy epoch: 0.9796261816453407\n","Validating model...\n","Validation Loss: 0.14834650158398338\n","Validation Accuracy: 0.9587578574990826\n","Training epoch: 4\n","Training loss per 100 training steps: 0.023636359721422195\n","Training loss per 100 training steps: 0.03540351849722464\n","Training loss per 100 training steps: 0.035592719767733816\n","Training loss per 100 training steps: 0.03623391426728413\n","Training loss epoch: 0.03732301356127629\n","Training accuracy epoch: 0.9878709257486837\n","Validating model...\n","Validation Loss: 0.13216077127530204\n","Validation Accuracy: 0.9623700184272199\n","Training epoch: 5\n","Training loss per 100 training steps: 0.021200381219387054\n","Training loss per 100 training steps: 0.0196234747654491\n","Training loss per 100 training steps: 0.02690986790219368\n","Training loss per 100 training steps: 0.027375528703759304\n","Training loss epoch: 0.027809474979384016\n","Training accuracy epoch: 0.9913113105641086\n","Validating model...\n","Validation Loss: 0.16373338066525273\n","Validation Accuracy: 0.9624584657250306\n","Training epoch: 6\n","Training loss per 100 training steps: 0.08747697621583939\n","Training loss per 100 training steps: 0.02264185256375424\n","Training loss per 100 training steps: 0.02129956250732292\n","Training loss per 100 training steps: 0.02247466569560645\n","Training loss epoch: 0.02371645953398771\n","Training accuracy epoch: 0.9925497534743895\n","Validating model...\n","Validation Loss: 0.18525452079711022\n","Validation Accuracy: 0.9567211482981169\n","Training epoch: 7\n","Training loss per 100 training steps: 0.02161204256117344\n","Training loss per 100 training steps: 0.023077676688219504\n","Training loss per 100 training steps: 0.022359509160626328\n","Training loss per 100 training steps: 0.023102561023126533\n","Training loss epoch: 0.022687870249367106\n","Training accuracy epoch: 0.9932761710761537\n","Validating model...\n","Validation Loss: 0.19128886780810433\n","Validation Accuracy: 0.9608992228052604\n","Training epoch: 8\n","Training loss per 100 training steps: 0.015074226073920727\n","Training loss per 100 training steps: 0.01443192076847409\n","Training loss per 100 training steps: 0.016040332058058885\n","Training loss per 100 training steps: 0.020042367460437433\n","Training loss epoch: 0.020290678859813713\n","Training accuracy epoch: 0.9939037814478511\n","Validating model...\n","Validation Loss: 0.19317080088975755\n","Validation Accuracy: 0.9568275779929661\n","Training epoch: 9\n","Training loss per 100 training steps: 0.040856584906578064\n","Training loss per 100 training steps: 0.02141634210492346\n","Training loss per 100 training steps: 0.02566868929593217\n","Training loss per 100 training steps: 0.02378114282294328\n","Training loss epoch: 0.023330481689817342\n","Training accuracy epoch: 0.992789665034243\n","Validating model...\n","Validation Loss: 0.19601526401646727\n","Validation Accuracy: 0.959625557333261\n","Training epoch: 10\n","Patience limit reached\n","Training duration: 33.0319339 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1671942451837283\n","Validation Accuracy: 0.9549753318649836\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validation duration: 3.137380300000003 minutes\n","F1-score (test): 84.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.85      0.85      0.85     12546\n","        test       0.82      0.86      0.84      9012\n","   treatment       0.82      0.86      0.84      9297\n","\n","   micro avg       0.83      0.85      0.84     30855\n","   macro avg       0.83      0.85      0.84     30855\n","weighted avg       0.83      0.85      0.84     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 10400\n","Points in y_train after augmentation: 10400\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.008451223373413\n","Training loss per 100 training steps: 0.3925555350609345\n","Training loss per 100 training steps: 0.29391942195483106\n","Training loss per 100 training steps: 0.251383598671106\n","Training loss epoch: 0.243870289933223\n","Training accuracy epoch: 0.923264095590192\n","Validating model...\n","Validation Loss: 0.1447831860610417\n","Validation Accuracy: 0.9540533625447262\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0721995010972023\n","Training loss per 100 training steps: 0.10331678847865303\n","Training loss per 100 training steps: 0.10314682940604972\n","Training loss per 100 training steps: 0.10050909681573658\n","Training loss epoch: 0.09962300357910303\n","Training accuracy epoch: 0.968374994403505\n","Validating model...\n","Validation Loss: 0.13142263654667835\n","Validation Accuracy: 0.9592927346595542\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04425365850329399\n","Training loss per 100 training steps: 0.05735627788183565\n","Training loss per 100 training steps: 0.061011760062375915\n","Training loss per 100 training steps: 0.06224158610932009\n","Training loss epoch: 0.06223270321551424\n","Training accuracy epoch: 0.9806090420352068\n","Validating model...\n","Validation Loss: 0.1652428795184408\n","Validation Accuracy: 0.9552218120163679\n","Training epoch: 4\n","Training loss per 100 training steps: 0.05897236987948418\n","Training loss per 100 training steps: 0.037051044469053794\n","Training loss per 100 training steps: 0.03723628403484562\n","Training loss per 100 training steps: 0.03765200406036021\n","Training loss epoch: 0.03818382469758105\n","Training accuracy epoch: 0.9876296262446712\n","Validating model...\n","Validation Loss: 0.16451377419198487\n","Validation Accuracy: 0.958407739969226\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0071929641999304295\n","Training loss per 100 training steps: 0.029929704911140078\n","Training loss per 100 training steps: 0.029899423362789165\n","Training loss per 100 training steps: 0.03180514663447041\n","Training loss epoch: 0.032149189687334004\n","Training accuracy epoch: 0.9901340259296229\n","Validating model...\n","Validation Loss: 0.17104141068245685\n","Validation Accuracy: 0.9594271657750176\n","Training epoch: 6\n","Training loss per 100 training steps: 0.011752801947295666\n","Training loss per 100 training steps: 0.027234103440740468\n","Training loss per 100 training steps: 0.025447779725449374\n","Training loss per 100 training steps: 0.024622476119795608\n","Training loss epoch: 0.023862065044231714\n","Training accuracy epoch: 0.9928551029550391\n","Validating model...\n","Validation Loss: 0.2038655114033586\n","Validation Accuracy: 0.9596368249651674\n","Training epoch: 7\n","Training loss per 100 training steps: 0.01069790031760931\n","Training loss per 100 training steps: 0.01809759500222096\n","Training loss per 100 training steps: 0.019202281684158322\n","Training loss per 100 training steps: 0.02406878466350475\n","Training loss epoch: 0.024386226908984378\n","Training accuracy epoch: 0.9926715006136785\n","Validating model...\n","Validation Loss: 0.1758012273711721\n","Validation Accuracy: 0.9598404937016399\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 25.6806751 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14430508486973984\n","Validation Accuracy: 0.955517256717541\n","Validation duration: 3.1697266666666715 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.84      0.87      0.85     12546\n","        test       0.85      0.88      0.87      9012\n","   treatment       0.83      0.87      0.85      9297\n","\n","   micro avg       0.84      0.87      0.86     30855\n","   macro avg       0.84      0.87      0.86     30855\n","weighted avg       0.84      0.87      0.86     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 10400\n","Points in y_train after augmentation: 10400\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9377415180206299\n","Training loss per 100 training steps: 0.3953828287154141\n","Training loss per 100 training steps: 0.2896611706460293\n","Training loss per 100 training steps: 0.2525927035441232\n","Training loss epoch: 0.2461658541399699\n","Training accuracy epoch: 0.9215872098971158\n","Validating model...\n","Validation Loss: 0.1477250370450995\n","Validation Accuracy: 0.9515839993045422\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09828754514455795\n","Training loss per 100 training steps: 0.10702183940401762\n","Training loss per 100 training steps: 0.10407628531368514\n","Training loss per 100 training steps: 0.10102868669873655\n","Training loss epoch: 0.10095668718791925\n","Training accuracy epoch: 0.9668259079237845\n","Validating model...\n","Validation Loss: 0.13930271556238075\n","Validation Accuracy: 0.9578567813558272\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04596981778740883\n","Training loss per 100 training steps: 0.052552913647550756\n","Training loss per 100 training steps: 0.05455774698285988\n","Training loss per 100 training steps: 0.054316890455373995\n","Training loss epoch: 0.05428531147109775\n","Training accuracy epoch: 0.9826527116423018\n","Validating model...\n","Validation Loss: 0.14887696781570647\n","Validation Accuracy: 0.9593794156699007\n","Training epoch: 4\n","Training loss per 100 training steps: 0.031121108680963516\n","Training loss per 100 training steps: 0.032867631662895185\n","Training loss per 100 training steps: 0.035017779182679766\n","Training loss per 100 training steps: 0.038319337450159696\n","Training loss epoch: 0.03797463853127108\n","Training accuracy epoch: 0.9878356585308266\n","Validating model...\n","Validation Loss: 0.15040144998604407\n","Validation Accuracy: 0.961794590417272\n","Training epoch: 5\n","Training loss per 100 training steps: 0.005704713519662619\n","Training loss per 100 training steps: 0.03076065346451089\n","Training loss per 100 training steps: 0.027591044854127167\n","Training loss per 100 training steps: 0.027596773317105375\n","Training loss epoch: 0.027490637719702834\n","Training accuracy epoch: 0.9918219959510706\n","Validating model...\n","Validation Loss: 0.1615203687884881\n","Validation Accuracy: 0.9639292764797912\n","Training epoch: 6\n","Training loss per 100 training steps: 0.04045429453253746\n","Training loss per 100 training steps: 0.021176300633993773\n","Training loss per 100 training steps: 0.019591065754115452\n","Training loss per 100 training steps: 0.021036207497829997\n","Training loss epoch: 0.02062559615014694\n","Training accuracy epoch: 0.994101857302983\n","Validating model...\n","Validation Loss: 0.1803213629399898\n","Validation Accuracy: 0.9619614143797282\n","Training epoch: 7\n","Training loss per 100 training steps: 0.024806980043649673\n","Training loss per 100 training steps: 0.019066618070799377\n","Training loss per 100 training steps: 0.02742166967427738\n","Training loss per 100 training steps: 0.028732639442714692\n","Training loss epoch: 0.02842458912744545\n","Training accuracy epoch: 0.9915419805248524\n","Validating model...\n","Validation Loss: 0.1986251880789732\n","Validation Accuracy: 0.9581909051243915\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 25.722768416666653 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15023117874753317\n","Validation Accuracy: 0.9554051493201067\n","Validation duration: 3.140964150000006 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.86      0.83     12546\n","        test       0.82      0.88      0.85      9012\n","   treatment       0.86      0.84      0.85      9297\n","\n","   micro avg       0.82      0.86      0.84     30855\n","   macro avg       0.83      0.86      0.84     30855\n","weighted avg       0.82      0.86      0.84     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n","Points in X_train after augmentation: 10400\n","Points in y_train after augmentation: 10400\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0849807262420654\n","Training loss per 100 training steps: 0.3975902706532195\n","Training loss per 100 training steps: 0.29414225608777644\n","Training loss per 100 training steps: 0.25121300600691887\n","Training loss epoch: 0.24597891992101303\n","Training accuracy epoch: 0.9220359594863503\n","Validating model...\n","Validation Loss: 0.1376576946637073\n","Validation Accuracy: 0.9548596736425078\n","Training epoch: 2\n","Training loss per 100 training steps: 0.13924121856689453\n","Training loss per 100 training steps: 0.09218650286334872\n","Training loss per 100 training steps: 0.09471587805698316\n","Training loss per 100 training steps: 0.09772497464738712\n","Training loss epoch: 0.09840389366046741\n","Training accuracy epoch: 0.9683691725077513\n","Validating model...\n","Validation Loss: 0.13263989629393275\n","Validation Accuracy: 0.9589178253634156\n","Training epoch: 3\n","Training loss per 100 training steps: 0.05259533226490021\n","Training loss per 100 training steps: 0.05714804586484143\n","Training loss per 100 training steps: 0.05607603387490137\n","Training loss per 100 training steps: 0.059069659344332164\n","Training loss epoch: 0.06020203057389993\n","Training accuracy epoch: 0.9809588423480543\n","Validating model...\n","Validation Loss: 0.14900561865999715\n","Validation Accuracy: 0.9579571525467002\n","Training epoch: 4\n","Training loss per 100 training steps: 0.07265229523181915\n","Training loss per 100 training steps: 0.04297628718437535\n","Training loss per 100 training steps: 0.03973103129995329\n","Training loss per 100 training steps: 0.04310909904805677\n","Training loss epoch: 0.04281684961026678\n","Training accuracy epoch: 0.9865747232189397\n","Validating model...\n","Validation Loss: 0.14982943829487672\n","Validation Accuracy: 0.9585461221416813\n","Training epoch: 5\n","Training loss per 100 training steps: 0.01872233860194683\n","Training loss per 100 training steps: 0.025508495471278887\n","Training loss per 100 training steps: 0.02659986676058653\n","Training loss per 100 training steps: 0.02695927539963331\n","Training loss epoch: 0.02775141124165832\n","Training accuracy epoch: 0.9911995007483293\n","Validating model...\n","Validation Loss: 0.17167727375257905\n","Validation Accuracy: 0.9586729535913507\n","Training epoch: 6\n","Training loss per 100 training steps: 0.021341506391763687\n","Training loss per 100 training steps: 0.025949483705075955\n","Training loss per 100 training steps: 0.025150933209111662\n","Training loss per 100 training steps: 0.024147884504857203\n","Training loss epoch: 0.024384483070327687\n","Training accuracy epoch: 0.9929728603738782\n","Validating model...\n","Validation Loss: 0.18330692049938363\n","Validation Accuracy: 0.9582646859575453\n","Training epoch: 7\n","Training loss per 100 training steps: 0.04778638482093811\n","Training loss per 100 training steps: 0.015189903631511301\n","Training loss per 100 training steps: 0.01843340435952634\n","Training loss per 100 training steps: 0.020618617873440846\n","Training loss epoch: 0.0212495186065252\n","Training accuracy epoch: 0.9936439416055494\n","Validating model...\n","Validation Loss: 0.17143745297058063\n","Validation Accuracy: 0.9588183982224091\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 25.740472383333326 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14827833413275787\n","Validation Accuracy: 0.9541926383990422\n","Validation duration: 3.139198083333334 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.3%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.85      0.84     12546\n","        test       0.84      0.85      0.84      9012\n","   treatment       0.83      0.86      0.85      9297\n","\n","   micro avg       0.83      0.85      0.84     30855\n","   macro avg       0.83      0.85      0.84     30855\n","weighted avg       0.83      0.85      0.84     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n","Points in X_train after augmentation: 10400\n","Points in y_train after augmentation: 10400\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8840433359146118\n","Training loss per 100 training steps: 0.38999292822462495\n","Training loss per 100 training steps: 0.2895164326278131\n","Training loss per 100 training steps: 0.24965097084393928\n","Training loss epoch: 0.2423498176611387\n","Training accuracy epoch: 0.9235961657485446\n","Validating model...\n","Validation Loss: 0.14957445068889624\n","Validation Accuracy: 0.9528221213384709\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06703794747591019\n","Training loss per 100 training steps: 0.1046767127100784\n","Training loss per 100 training steps: 0.09941111872000481\n","Training loss per 100 training steps: 0.09783270869069915\n","Training loss epoch: 0.09612333870851077\n","Training accuracy epoch: 0.9691190211901384\n","Validating model...\n","Validation Loss: 0.14981616385184326\n","Validation Accuracy: 0.9560497150144557\n","Training epoch: 3\n","Training loss per 100 training steps: 0.09054494649171829\n","Training loss per 100 training steps: 0.04668251520234833\n","Training loss per 100 training steps: 0.05204184875309245\n","Training loss per 100 training steps: 0.05553592187491713\n","Training loss epoch: 0.05628868877457885\n","Training accuracy epoch: 0.9820114303228548\n","Validating model...\n","Validation Loss: 0.1415369357345263\n","Validation Accuracy: 0.9598382373024703\n","Training epoch: 4\n","Training loss per 100 training steps: 0.059165578335523605\n","Training loss per 100 training steps: 0.04175690926915717\n","Training loss per 100 training steps: 0.0453318615724328\n","Training loss per 100 training steps: 0.04374428018710987\n","Training loss epoch: 0.043781081677342834\n","Training accuracy epoch: 0.9860357337992501\n","Validating model...\n","Validation Loss: 0.17520441061684064\n","Validation Accuracy: 0.9551829522568546\n","Training epoch: 5\n","Training loss per 100 training steps: 0.06444720178842545\n","Training loss per 100 training steps: 0.03066642703096576\n","Training loss per 100 training steps: 0.032427093407384755\n","Training loss per 100 training steps: 0.031412561595412065\n","Training loss epoch: 0.032494922606632684\n","Training accuracy epoch: 0.990063884536093\n","Validating model...\n","Validation Loss: 0.16549822908233514\n","Validation Accuracy: 0.9568718313537731\n","Training epoch: 6\n","Training loss per 100 training steps: 0.07152247428894043\n","Training loss per 100 training steps: 0.026766540067694564\n","Training loss per 100 training steps: 0.02440055804524052\n","Training loss per 100 training steps: 0.023551072962071585\n","Training loss epoch: 0.025026691394786423\n","Training accuracy epoch: 0.9920175778486359\n","Validating model...\n","Validation Loss: 0.1771672722315053\n","Validation Accuracy: 0.9573798704908782\n","Training epoch: 7\n","Training loss per 100 training steps: 0.007255771663039923\n","Training loss per 100 training steps: 0.021240684752453966\n","Training loss per 100 training steps: 0.020179586013864763\n","Training loss per 100 training steps: 0.022331088598998593\n","Training loss epoch: 0.022664959436604896\n","Training accuracy epoch: 0.9928123844654356\n","Validating model...\n","Validation Loss: 0.19048696482106559\n","Validation Accuracy: 0.96090465099048\n","Training epoch: 8\n","Training loss per 100 training steps: 0.0060117500834167\n","Training loss per 100 training steps: 0.01231728544940545\n","Training loss per 100 training steps: 0.01619660029933783\n","Training loss per 100 training steps: 0.018296948252354076\n","Training loss epoch: 0.018869654808838208\n","Training accuracy epoch: 0.9939370471920131\n","Validating model...\n","Validation Loss: 0.20090107189176917\n","Validation Accuracy: 0.9556876636688229\n","Training epoch: 9\n","Patience limit reached\n","Training duration: 29.40101006666667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1649103025168491\n","Validation Accuracy: 0.9556777111789457\n","Validation duration: 3.13043438333331 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.87      0.85     12546\n","        test       0.81      0.86      0.84      9012\n","   treatment       0.85      0.84      0.85      9297\n","\n","   micro avg       0.83      0.86      0.85     30855\n","   macro avg       0.83      0.86      0.85     30855\n","weighted avg       0.83      0.86      0.85     30855\n","\n","!!!!!! Starting model number 7 !!!!!!\n","Points in X_train after augmentation: 10400\n","Points in y_train after augmentation: 10400\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.965802788734436\n","Training loss per 100 training steps: 0.4066520165836457\n","Training loss per 100 training steps: 0.3006540688116159\n","Training loss per 100 training steps: 0.2566983938415185\n","Training loss epoch: 0.24761659684089513\n","Training accuracy epoch: 0.92102741878044\n","Validating model...\n","Validation Loss: 0.13979145879675817\n","Validation Accuracy: 0.9550458491713547\n","Training epoch: 2\n","Training loss per 100 training steps: 0.13407091796398163\n","Training loss per 100 training steps: 0.0918639843342918\n","Training loss per 100 training steps: 0.0965130996348253\n","Training loss per 100 training steps: 0.09558796054959\n","Training loss epoch: 0.09598828614044648\n","Training accuracy epoch: 0.9695458764714197\n","Validating model...\n","Validation Loss: 0.1367836839870199\n","Validation Accuracy: 0.95645632153329\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04423562437295914\n","Training loss per 100 training steps: 0.05414161362712926\n","Training loss per 100 training steps: 0.057418335182823944\n","Training loss per 100 training steps: 0.05877652756585136\n","Training loss epoch: 0.05923011345645556\n","Training accuracy epoch: 0.9815116940471124\n","Validating model...\n","Validation Loss: 0.15222488275983118\n","Validation Accuracy: 0.9592212930120435\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03437165543437004\n","Training loss per 100 training steps: 0.03902324316285477\n","Training loss per 100 training steps: 0.03857501958200328\n","Training loss per 100 training steps: 0.04165125732074965\n","Training loss epoch: 0.04156861617946281\n","Training accuracy epoch: 0.9869303143604999\n","Validating model...\n","Validation Loss: 0.1663965562044026\n","Validation Accuracy: 0.957900202354335\n","Training epoch: 5\n","Training loss per 100 training steps: 0.055277615785598755\n","Training loss per 100 training steps: 0.029773098439678992\n","Training loss per 100 training steps: 0.030374750527391088\n","Training loss per 100 training steps: 0.030903072150554076\n","Training loss epoch: 0.030592651334233008\n","Training accuracy epoch: 0.9904898587660877\n","Validating model...\n","Validation Loss: 0.17480881517003108\n","Validation Accuracy: 0.9583566088931271\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0014364355010911822\n","Training loss per 100 training steps: 0.018945423251082474\n","Training loss per 100 training steps: 0.02410579857182462\n","Training loss per 100 training steps: 0.02565614017928669\n","Training loss epoch: 0.02545618801950835\n","Training accuracy epoch: 0.9921920370755496\n","Validating model...\n","Validation Loss: 0.17194325566388569\n","Validation Accuracy: 0.9603146849238453\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0044258818961679935\n","Training loss per 100 training steps: 0.01739872859717153\n","Training loss per 100 training steps: 0.017075037275439832\n","Training loss per 100 training steps: 0.019507186059268388\n","Training loss epoch: 0.02019881353400146\n","Training accuracy epoch: 0.9939728222785427\n","Validating model...\n","Validation Loss: 0.1811224619960775\n","Validation Accuracy: 0.9594541203797283\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 25.72814516666667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1493307672854927\n","Validation Accuracy: 0.9542362903200221\n","Validation duration: 3.1239853000000037 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.84      0.85      0.85     12546\n","        test       0.80      0.89      0.84      9012\n","   treatment       0.82      0.84      0.83      9297\n","\n","   micro avg       0.82      0.86      0.84     30855\n","   macro avg       0.82      0.86      0.84     30855\n","weighted avg       0.82      0.86      0.84     30855\n","\n","!!!!!! Starting model number 8 !!!!!!\n","Points in X_train after augmentation: 10400\n","Points in y_train after augmentation: 10400\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1901283264160156\n","Training loss per 100 training steps: 0.4016031239292409\n","Training loss per 100 training steps: 0.29460552979761095\n","Training loss per 100 training steps: 0.25276825888905413\n","Training loss epoch: 0.2473306303987136\n","Training accuracy epoch: 0.9215851595528272\n","Validating model...\n","Validation Loss: 0.13780866839088401\n","Validation Accuracy: 0.9569523133025384\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07523573935031891\n","Training loss per 100 training steps: 0.09492982702680153\n","Training loss per 100 training steps: 0.09269119482209433\n","Training loss per 100 training steps: 0.09728689391500134\n","Training loss epoch: 0.09688833209757622\n","Training accuracy epoch: 0.9694482900254441\n","Validating model...\n","Validation Loss: 0.14829488867869625\n","Validation Accuracy: 0.9539604475533855\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04933161288499832\n","Training loss per 100 training steps: 0.05849022608213496\n","Training loss per 100 training steps: 0.05563429592001201\n","Training loss per 100 training steps: 0.058240247067323954\n","Training loss epoch: 0.059456257258470244\n","Training accuracy epoch: 0.9818171180873893\n","Validating model...\n","Validation Loss: 0.13911855179671342\n","Validation Accuracy: 0.9597694763885206\n","Training epoch: 4\n","Training loss per 100 training steps: 0.011110926046967506\n","Training loss per 100 training steps: 0.03861610375178775\n","Training loss per 100 training steps: 0.03910263611666339\n","Training loss per 100 training steps: 0.041489524399379016\n","Training loss epoch: 0.042776095369257604\n","Training accuracy epoch: 0.9865087977935453\n","Validating model...\n","Validation Loss: 0.14779373514768365\n","Validation Accuracy: 0.9608375289197377\n","Training epoch: 5\n","Training loss per 100 training steps: 0.013677633367478848\n","Training loss per 100 training steps: 0.02805159771169471\n","Training loss per 100 training steps: 0.02722070054776633\n","Training loss per 100 training steps: 0.031425869023501626\n","Training loss epoch: 0.031037741627257604\n","Training accuracy epoch: 0.990637997511246\n","Validating model...\n","Validation Loss: 0.17778116631527224\n","Validation Accuracy: 0.9563085595400617\n","Training epoch: 6\n","Training loss per 100 training steps: 0.005099989473819733\n","Training loss per 100 training steps: 0.022419237874051794\n","Training loss per 100 training steps: 0.0287303233360501\n","Training loss per 100 training steps: 0.03222966580876022\n","Training loss epoch: 0.032168786022453925\n","Training accuracy epoch: 0.9900970297502076\n","Validating model...\n","Validation Loss: 0.17505602331759482\n","Validation Accuracy: 0.958426126597085\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 22.005465650000012 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15010059571661125\n","Validation Accuracy: 0.9527009889334663\n","Validation duration: 3.186955833333347 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.85      0.82     12546\n","        test       0.84      0.87      0.85      9012\n","   treatment       0.83      0.85      0.84      9297\n","\n","   micro avg       0.82      0.85      0.83     30855\n","   macro avg       0.82      0.86      0.84     30855\n","weighted avg       0.82      0.85      0.83     30855\n","\n","!!!!!! Starting model number 9 !!!!!!\n","Points in X_train after augmentation: 10400\n","Points in y_train after augmentation: 10400\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.27486515045166\n","Training loss per 100 training steps: 0.421496577192061\n","Training loss per 100 training steps: 0.30806759668894074\n","Training loss per 100 training steps: 0.2607883518171865\n","Training loss epoch: 0.2526194076010814\n","Training accuracy epoch: 0.9192598619460296\n","Validating model...\n","Validation Loss: 0.14102444531662123\n","Validation Accuracy: 0.9562310465334741\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04746827855706215\n","Training loss per 100 training steps: 0.08841471269837406\n","Training loss per 100 training steps: 0.09838966520234424\n","Training loss per 100 training steps: 0.0976084413631909\n","Training loss epoch: 0.09750222608447075\n","Training accuracy epoch: 0.9682725811052451\n","Validating model...\n","Validation Loss: 0.13316817349427706\n","Validation Accuracy: 0.9573965475221343\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0441327765583992\n","Training loss per 100 training steps: 0.05163347442164132\n","Training loss per 100 training steps: 0.05738470775645171\n","Training loss per 100 training steps: 0.05991235169956454\n","Training loss epoch: 0.060678560805435364\n","Training accuracy epoch: 0.9802579252438434\n","Validating model...\n","Validation Loss: 0.14660596437510345\n","Validation Accuracy: 0.9593598938742174\n","Training epoch: 4\n","Training loss per 100 training steps: 0.019321560859680176\n","Training loss per 100 training steps: 0.03810198574861751\n","Training loss per 100 training steps: 0.038985478577078944\n","Training loss per 100 training steps: 0.03911199719193345\n","Training loss epoch: 0.0397990068141371\n","Training accuracy epoch: 0.9872519496355047\n","Validating model...\n","Validation Loss: 0.15462373262392237\n","Validation Accuracy: 0.9586441209524438\n","Training epoch: 5\n","Training loss per 100 training steps: 0.03822391852736473\n","Training loss per 100 training steps: 0.029813426444168654\n","Training loss per 100 training steps: 0.03050400727643951\n","Training loss per 100 training steps: 0.03167164665329706\n","Training loss epoch: 0.032751414056939\n","Training accuracy epoch: 0.989814546198417\n","Validating model...\n","Validation Loss: 0.16031887055096494\n","Validation Accuracy: 0.9569919379600874\n","Training epoch: 6\n","Training loss per 100 training steps: 0.025762509554624557\n","Training loss per 100 training steps: 0.023291027373957014\n","Training loss per 100 training steps: 0.025836402807495933\n","Training loss per 100 training steps: 0.02779340536868899\n","Training loss epoch: 0.028564629412900944\n","Training accuracy epoch: 0.9909094510169432\n","Validating model...\n","Validation Loss: 0.15214693920033706\n","Validation Accuracy: 0.959348404225453\n","Training epoch: 7\n","Training loss per 100 training steps: 0.017500905320048332\n","Training loss per 100 training steps: 0.02336489027227727\n","Training loss per 100 training steps: 0.021263258377917166\n","Training loss per 100 training steps: 0.023516467546748673\n","Training loss epoch: 0.024056904100490592\n","Training accuracy epoch: 0.9926709479365409\n","Validating model...\n","Validation Loss: 0.17151800705144157\n","Validation Accuracy: 0.9598464926898671\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 25.725487216666654 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14802121283288147\n","Validation Accuracy: 0.9537175436248998\n","Validation duration: 3.125277366666675 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.1%\n","              precision    recall  f1-score   support\n","\n","     problem       0.84      0.86      0.85     12546\n","        test       0.83      0.83      0.83      9012\n","   treatment       0.82      0.87      0.84      9297\n","\n","   micro avg       0.83      0.85      0.84     30855\n","   macro avg       0.83      0.85      0.84     30855\n","weighted avg       0.83      0.85      0.84     30855\n","\n","!!!!!! Starting model number 10 !!!!!!\n","Points in X_train after augmentation: 10400\n","Points in y_train after augmentation: 10400\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.3954944610595703\n","Training loss per 100 training steps: 0.39055789298940413\n","Training loss per 100 training steps: 0.2896832868790449\n","Training loss per 100 training steps: 0.25248253881386745\n","Training loss epoch: 0.24495492782730321\n","Training accuracy epoch: 0.9217799632212728\n","Validating model...\n","Validation Loss: 0.13812804464008901\n","Validation Accuracy: 0.9550541084797127\n","Training epoch: 2\n","Training loss per 100 training steps: 0.13426531851291656\n","Training loss per 100 training steps: 0.09379527337922908\n","Training loss per 100 training steps: 0.09533472225737216\n","Training loss per 100 training steps: 0.0962680158455952\n","Training loss epoch: 0.09551175453628485\n","Training accuracy epoch: 0.9687797916195008\n","Validating model...\n","Validation Loss: 0.1241398138030396\n","Validation Accuracy: 0.9615926641027186\n","Training epoch: 3\n","Training loss per 100 training steps: 0.13377878069877625\n","Training loss per 100 training steps: 0.054102768466835566\n","Training loss per 100 training steps: 0.059765131740983746\n","Training loss per 100 training steps: 0.05940889060014605\n","Training loss epoch: 0.059611698856147435\n","Training accuracy epoch: 0.9810337498095257\n","Validating model...\n","Validation Loss: 0.1433611964540822\n","Validation Accuracy: 0.9609279912759772\n","Training epoch: 4\n","Training loss per 100 training steps: 0.009129929356276989\n","Training loss per 100 training steps: 0.03923815779277299\n","Training loss per 100 training steps: 0.03937518379572241\n","Training loss per 100 training steps: 0.04105301513073601\n","Training loss epoch: 0.0419405929529323\n","Training accuracy epoch: 0.9873060514519578\n","Validating model...\n","Validation Loss: 0.16685805255668118\n","Validation Accuracy: 0.9570419352739675\n","Training epoch: 5\n","Training loss per 100 training steps: 0.02075936086475849\n","Training loss per 100 training steps: 0.03242274935099084\n","Training loss per 100 training steps: 0.034544049955635744\n","Training loss per 100 training steps: 0.03836869065761195\n","Training loss epoch: 0.039333771526670225\n","Training accuracy epoch: 0.9874512075719272\n","Validating model...\n","Validation Loss: 0.18395013207352007\n","Validation Accuracy: 0.9518369255191383\n","Training epoch: 6\n","Training loss per 100 training steps: 0.014744699001312256\n","Training loss per 100 training steps: 0.02379986957190466\n","Training loss per 100 training steps: 0.024243211692815358\n","Training loss per 100 training steps: 0.024485558172783806\n","Training loss epoch: 0.024880317005758674\n","Training accuracy epoch: 0.9921362120787129\n","Validating model...\n","Validation Loss: 0.1628441596766571\n","Validation Accuracy: 0.9604870948954182\n","Training epoch: 7\n","Training loss per 100 training steps: 0.05645662546157837\n","Training loss per 100 training steps: 0.01890161407346109\n","Training loss per 100 training steps: 0.023205565930395133\n","Training loss per 100 training steps: 0.02092280829258795\n","Training loss epoch: 0.02115625034372967\n","Training accuracy epoch: 0.9937217873014337\n","Validating model...\n","Validation Loss: 0.1873928230957358\n","Validation Accuracy: 0.958630906796567\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 25.716152349999994 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14841764813819383\n","Validation Accuracy: 0.9560640483675207\n","Validation duration: 3.1898797166666553 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.84      0.84     12546\n","        test       0.84      0.87      0.85      9012\n","   treatment       0.83      0.88      0.85      9297\n","\n","   micro avg       0.83      0.86      0.85     30855\n","   macro avg       0.83      0.86      0.85     30855\n","weighted avg       0.83      0.86      0.85     30855\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"bM0wPLD5kaw4"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jhz9BiIwGCsV","executionInfo":{"status":"ok","timestamp":1663048589514,"user_tz":240,"elapsed":7008437,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}},"outputId":"74f58239-4bf4-42e9-c092-288e3b4dcb35"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 25.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 13000\n","Points in y_train after augmentation: 13000\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9079480171203613\n","Training loss per 100 training steps: 0.3830591710192142\n","Training loss per 100 training steps: 0.28656814992427826\n","Training loss per 100 training steps: 0.24676575873084242\n","Training loss per 100 training steps: 0.22490343504452942\n","Training loss epoch: 0.22465390938103053\n","Training accuracy epoch: 0.9286786475964465\n","Validating model...\n","Validation Loss: 0.13577487636599447\n","Validation Accuracy: 0.9561244862208454\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06522779166698456\n","Training loss per 100 training steps: 0.08742816582100817\n","Training loss per 100 training steps: 0.09776971781098132\n","Training loss per 100 training steps: 0.09495680391837988\n","Training loss per 100 training steps: 0.09476221801058164\n","Training loss epoch: 0.09508490639782216\n","Training accuracy epoch: 0.9689744213061773\n","Validating model...\n","Validation Loss: 0.14318906878689666\n","Validation Accuracy: 0.9558890650100874\n","Training epoch: 3\n","Training loss per 100 training steps: 0.05096049606800079\n","Training loss per 100 training steps: 0.04610811617907764\n","Training loss per 100 training steps: 0.04716306841417925\n","Training loss per 100 training steps: 0.05107999986588361\n","Training loss per 100 training steps: 0.05343497792105573\n","Training loss epoch: 0.053274231818699135\n","Training accuracy epoch: 0.983356466596764\n","Validating model...\n","Validation Loss: 0.1615341164461978\n","Validation Accuracy: 0.9571183721381358\n","Training epoch: 4\n","Training loss per 100 training steps: 0.06436076015233994\n","Training loss per 100 training steps: 0.035331195764391136\n","Training loss per 100 training steps: 0.03640362086117416\n","Training loss per 100 training steps: 0.03768381228642631\n","Training loss per 100 training steps: 0.03867019874861283\n","Training loss epoch: 0.03906684633200251\n","Training accuracy epoch: 0.9875974953106897\n","Validating model...\n","Validation Loss: 0.18804934035454476\n","Validation Accuracy: 0.9551154387695542\n","Training epoch: 5\n","Training loss per 100 training steps: 0.027677787467837334\n","Training loss per 100 training steps: 0.03156962498358571\n","Training loss per 100 training steps: 0.029115995059753607\n","Training loss per 100 training steps: 0.029630143635525706\n","Training loss per 100 training steps: 0.030612184989505315\n","Training loss epoch: 0.030596582269918456\n","Training accuracy epoch: 0.9906523757276529\n","Validating model...\n","Validation Loss: 0.1659654299789048\n","Validation Accuracy: 0.9585694065036419\n","Training epoch: 6\n","Training loss per 100 training steps: 0.005979306995868683\n","Training loss per 100 training steps: 0.020346303719400178\n","Training loss per 100 training steps: 0.018869262425557927\n","Training loss per 100 training steps: 0.020780864983883707\n","Training loss per 100 training steps: 0.021289171517461986\n","Training loss epoch: 0.021335488231909856\n","Training accuracy epoch: 0.993828667221308\n","Validating model...\n","Validation Loss: 0.18361589454066057\n","Validation Accuracy: 0.9591256145558009\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 27.129017700000016 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14759612198988045\n","Validation Accuracy: 0.9525048728387645\n","Validation duration: 3.14567086666666 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 83.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.82      0.82     12546\n","        test       0.82      0.88      0.85      9012\n","   treatment       0.80      0.87      0.83      9297\n","\n","   micro avg       0.81      0.85      0.83     30855\n","   macro avg       0.81      0.86      0.83     30855\n","weighted avg       0.81      0.85      0.83     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 13000\n","Points in y_train after augmentation: 13000\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9052163362503052\n","Training loss per 100 training steps: 0.4040420615289471\n","Training loss per 100 training steps: 0.29779118520962955\n","Training loss per 100 training steps: 0.2548135355968907\n","Training loss per 100 training steps: 0.22827927710167933\n","Training loss epoch: 0.2265532085402006\n","Training accuracy epoch: 0.9287716417276388\n","Validating model...\n","Validation Loss: 0.14243329671973531\n","Validation Accuracy: 0.9529974834081216\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0997057557106018\n","Training loss per 100 training steps: 0.09895185115608839\n","Stopping epoch...\n","Training loss epoch: 0.09895185115608839\n","Training accuracy epoch: 0.9595286695881858\n","Validating model...\n","Validation Loss: 0.16531837252633913\n","Validation Accuracy: 0.9495749259425178\n","Training epoch: 3\n","Training loss per 100 training steps: 0.10222838073968887\n","Training loss per 100 training steps: 0.08556896106035698\n","Training loss per 100 training steps: 0.08867465511464806\n","Training loss per 100 training steps: 0.08956752325163728\n","Training loss per 100 training steps: 0.0887602424560268\n","Training loss epoch: 0.0884458572541979\n","Training accuracy epoch: 0.9717499310580201\n","Validating model...\n","Validation Loss: 0.1467393326343267\n","Validation Accuracy: 0.956430239711306\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0593251958489418\n","Training loss per 100 training steps: 0.047934935105466606\n","Training loss per 100 training steps: 0.047349379624967554\n","Training loss per 100 training steps: 0.04662293716538017\n","Training loss per 100 training steps: 0.047859512544132565\n","Training loss epoch: 0.04800401288954225\n","Training accuracy epoch: 0.9852210512673785\n","Validating model...\n","Validation Loss: 0.1527980028941937\n","Validation Accuracy: 0.9605651675503937\n","Training epoch: 5\n","Training loss per 100 training steps: 0.006526361219584942\n","Training loss per 100 training steps: 0.02973946088943446\n","Training loss per 100 training steps: 0.030767235957058287\n","Training loss per 100 training steps: 0.031560101283735834\n","Training loss per 100 training steps: 0.03381538948368169\n","Training loss epoch: 0.0338325204681811\n","Training accuracy epoch: 0.9896677269648088\n","Validating model...\n","Validation Loss: 0.1629204130731523\n","Validation Accuracy: 0.9590846982324261\n","Training epoch: 6\n","Training loss per 100 training steps: 0.02156456559896469\n","Training loss per 100 training steps: 0.023343926968772223\n","Training loss per 100 training steps: 0.025222492872260104\n","Training loss per 100 training steps: 0.025886305691202503\n","Training loss per 100 training steps: 0.027326889846914046\n","Training loss epoch: 0.027429375803087786\n","Training accuracy epoch: 0.9918081436283869\n","Validating model...\n","Validation Loss: 0.17596649211625776\n","Validation Accuracy: 0.9595789507259576\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 23.963840499999968 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15113458208550043\n","Validation Accuracy: 0.9528268793260222\n","Validation duration: 3.1363946000000094 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 83.1%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.85      0.83     12546\n","        test       0.81      0.87      0.84      9012\n","   treatment       0.83      0.83      0.83      9297\n","\n","   micro avg       0.81      0.85      0.83     30855\n","   macro avg       0.82      0.85      0.83     30855\n","weighted avg       0.81      0.85      0.83     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 13000\n","Points in y_train after augmentation: 13000\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1671574115753174\n","Training loss per 100 training steps: 0.408883936629437\n","Training loss per 100 training steps: 0.30022221566432744\n","Training loss per 100 training steps: 0.25947798110321907\n","Training loss per 100 training steps: 0.23181978641008202\n","Training loss epoch: 0.23074625816003988\n","Training accuracy epoch: 0.9258823088307215\n","Validating model...\n","Validation Loss: 0.15817842366439955\n","Validation Accuracy: 0.9471100743068527\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09059377759695053\n","Training loss per 100 training steps: 0.08881211457866253\n","Training loss per 100 training steps: 0.09139774433008177\n","Training loss per 100 training steps: 0.09367475295099012\n","Training loss per 100 training steps: 0.09523575255261767\n","Training loss epoch: 0.09472917804965882\n","Training accuracy epoch: 0.9697841390732258\n","Validating model...\n","Validation Loss: 0.14340968763866982\n","Validation Accuracy: 0.9573063191577281\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03145250678062439\n","Training loss per 100 training steps: 0.048134721170115\n","Training loss per 100 training steps: 0.05094740678097552\n","Training loss per 100 training steps: 0.054911934895954556\n","Training loss per 100 training steps: 0.055029775968234884\n","Training loss epoch: 0.05508717187252399\n","Training accuracy epoch: 0.9826808922262439\n","Validating model...\n","Validation Loss: 0.15042137521524707\n","Validation Accuracy: 0.9585109936636034\n","Training epoch: 4\n","Training loss per 100 training steps: 0.05164238065481186\n","Training loss per 100 training steps: 0.03230811993471614\n","Training loss per 100 training steps: 0.03142093942588686\n","Training loss per 100 training steps: 0.03348404051429682\n","Training loss per 100 training steps: 0.03559191065359665\n","Training loss epoch: 0.03547256919658338\n","Training accuracy epoch: 0.9891680602872807\n","Validating model...\n","Validation Loss: 0.16029499686480342\n","Validation Accuracy: 0.959473466836205\n","Training epoch: 5\n","Training loss per 100 training steps: 0.00940506998449564\n","Training loss per 100 training steps: 0.025954510745739953\n","Training loss per 100 training steps: 0.028678434326392204\n","Training loss per 100 training steps: 0.029333091436876017\n","Training loss per 100 training steps: 0.030010142663210407\n","Training loss epoch: 0.030150829068401084\n","Training accuracy epoch: 0.990744257812571\n","Validating model...\n","Validation Loss: 0.1776047246893505\n","Validation Accuracy: 0.958307313967496\n","Training epoch: 6\n","Training loss per 100 training steps: 0.03325768560171127\n","Training loss per 100 training steps: 0.028142706313548555\n","Training loss per 100 training steps: 0.03190354768485665\n","Training loss per 100 training steps: 0.03173992154381835\n","Training loss per 100 training steps: 0.03057284411559685\n","Training loss epoch: 0.0304578988351207\n","Training accuracy epoch: 0.9907841809990385\n","Validating model...\n","Validation Loss: 0.1822343510515117\n","Validation Accuracy: 0.9598114783141743\n","Training epoch: 7\n","Training loss per 100 training steps: 0.03633750602602959\n","Training loss per 100 training steps: 0.01579416449594376\n","Training loss per 100 training steps: 0.01872631136892104\n","Training loss per 100 training steps: 0.020217364872658804\n","Training loss per 100 training steps: 0.01954612870305252\n","Training loss epoch: 0.01950468475251351\n","Training accuracy epoch: 0.9939363270101591\n","Validating model...\n","Validation Loss: 0.23571518087735424\n","Validation Accuracy: 0.9508944832482935\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 31.710295083333282 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15648743219423555\n","Validation Accuracy: 0.9532313667627248\n","Validation duration: 3.151061600000018 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 84.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.88      0.84     12546\n","        test       0.85      0.87      0.86      9012\n","   treatment       0.84      0.86      0.85      9297\n","\n","   micro avg       0.82      0.87      0.85     30855\n","   macro avg       0.83      0.87      0.85     30855\n","weighted avg       0.82      0.87      0.85     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 13000\n","Points in y_train after augmentation: 13000\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.304074764251709\n","Training loss per 100 training steps: 0.40543632592895246\n","Training loss per 100 training steps: 0.29589638721883593\n","Training loss per 100 training steps: 0.2548419820683145\n","Training loss per 100 training steps: 0.23283944487980476\n","Training loss epoch: 0.23203304288245244\n","Training accuracy epoch: 0.9253927399132204\n","Validating model...\n","Validation Loss: 0.1370902353196175\n","Validation Accuracy: 0.955560849582808\n","Training epoch: 2\n","Training loss per 100 training steps: 0.059502843767404556\n","Training loss per 100 training steps: 0.08277539376833357\n","Training loss per 100 training steps: 0.08964794318641152\n","Training loss per 100 training steps: 0.08890316307705601\n","Training loss per 100 training steps: 0.09123088140505137\n","Training loss epoch: 0.09100815391794982\n","Training accuracy epoch: 0.9705766039338151\n","Validating model...\n","Validation Loss: 0.1386957209823387\n","Validation Accuracy: 0.9566455113405731\n","Training epoch: 3\n","Training loss per 100 training steps: 0.030847664922475815\n","Training loss per 100 training steps: 0.045890908360960755\n","Training loss per 100 training steps: 0.0499751063003506\n","Training loss per 100 training steps: 0.05439549852533891\n","Training loss per 100 training steps: 0.05572800607446052\n","Training loss epoch: 0.055552647469670535\n","Training accuracy epoch: 0.9825266768106486\n","Validating model...\n","Validation Loss: 0.14822437219902293\n","Validation Accuracy: 0.9599291811574062\n","Training epoch: 4\n","Training loss per 100 training steps: 0.011980756185948849\n","Training loss per 100 training steps: 0.032598797937320304\n","Training loss per 100 training steps: 0.0345202662665814\n","Training loss per 100 training steps: 0.036373261762612755\n","Training loss per 100 training steps: 0.03624878737331134\n","Training loss epoch: 0.036054294212854006\n","Training accuracy epoch: 0.9885605507687345\n","Validating model...\n","Validation Loss: 0.17589010732466137\n","Validation Accuracy: 0.9577048135893513\n","Training epoch: 5\n","Training loss per 100 training steps: 0.008564676158130169\n","Training loss per 100 training steps: 0.019871486241394416\n","Training loss per 100 training steps: 0.019871247156791907\n","Training loss per 100 training steps: 0.023228004350067052\n","Training loss per 100 training steps: 0.024675847002144837\n","Training loss epoch: 0.024767599692419446\n","Training accuracy epoch: 0.9924092361116259\n","Validating model...\n","Validation Loss: 0.20031791417436165\n","Validation Accuracy: 0.9563921641364127\n","Training epoch: 6\n","Training loss per 100 training steps: 0.05157283693552017\n","Training loss per 100 training steps: 0.028884891107088268\n","Training loss per 100 training steps: 0.02872006119627376\n","Training loss per 100 training steps: 0.028920371784670804\n","Training loss per 100 training steps: 0.02825921604716384\n","Training loss epoch: 0.02870756164032975\n","Training accuracy epoch: 0.9908973742695418\n","Validating model...\n","Validation Loss: 0.17974574369221152\n","Validation Accuracy: 0.9581712011617567\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 27.174129299999972 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1471321788461258\n","Validation Accuracy: 0.9527109599903879\n","Validation duration: 3.127350583333343 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 82.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.87      0.83     12546\n","        test       0.83      0.80      0.81      9012\n","   treatment       0.78      0.86      0.82      9297\n","\n","   micro avg       0.80      0.85      0.82     30855\n","   macro avg       0.80      0.84      0.82     30855\n","weighted avg       0.80      0.85      0.82     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n","Points in X_train after augmentation: 13000\n","Points in y_train after augmentation: 13000\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9637168645858765\n","Training loss per 100 training steps: 0.3988451599927232\n","Training loss per 100 training steps: 0.29646182801593\n","Training loss per 100 training steps: 0.2547167260632959\n","Training loss per 100 training steps: 0.23094264696586755\n","Training loss epoch: 0.22972386502443426\n","Training accuracy epoch: 0.9275369199616921\n","Validating model...\n","Validation Loss: 0.1511083743111654\n","Validation Accuracy: 0.9510710302102218\n","Training epoch: 2\n","Training loss per 100 training steps: 0.21258343756198883\n","Training loss per 100 training steps: 0.09227109471760174\n","Training loss per 100 training steps: 0.09196548470161596\n","Training loss per 100 training steps: 0.092002464869861\n","Training loss per 100 training steps: 0.09440225761086492\n","Training loss epoch: 0.09459754216647193\n","Training accuracy epoch: 0.9701591603034337\n","Validating model...\n","Validation Loss: 0.1403691065437221\n","Validation Accuracy: 0.9585995587475052\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0528268963098526\n","Training loss per 100 training steps: 0.04884004378737421\n","Training loss per 100 training steps: 0.05266539380301846\n","Training loss per 100 training steps: 0.05238957293842149\n","Training loss per 100 training steps: 0.055817324582817136\n","Training loss epoch: 0.05712904101775396\n","Training accuracy epoch: 0.9822370264599868\n","Validating model...\n","Validation Loss: 0.15142907625572247\n","Validation Accuracy: 0.9565835622517288\n","Training epoch: 4\n","Training loss per 100 training steps: 0.013703417964279652\n","Training loss per 100 training steps: 0.03582601671540501\n","Training loss per 100 training steps: 0.03571889914145962\n","Training loss per 100 training steps: 0.037147523037024906\n","Training loss per 100 training steps: 0.0377904156634022\n","Training loss epoch: 0.03763517937382697\n","Training accuracy epoch: 0.9884441643591123\n","Validating model...\n","Validation Loss: 0.18617377292316456\n","Validation Accuracy: 0.9559304636991813\n","Training epoch: 5\n","Training loss per 100 training steps: 0.016193216666579247\n","Training loss per 100 training steps: 0.02528623779336599\n","Training loss per 100 training steps: 0.029263861093378224\n","Training loss per 100 training steps: 0.02831954928463096\n","Training loss per 100 training steps: 0.02996292604775658\n","Training loss epoch: 0.02985911282421266\n","Training accuracy epoch: 0.9908467938020177\n","Validating model...\n","Validation Loss: 0.17355167273093353\n","Validation Accuracy: 0.9573675631421847\n","Training epoch: 6\n","Training loss per 100 training steps: 0.016429074108600616\n","Training loss per 100 training steps: 0.026280118535171346\n","Training loss per 100 training steps: 0.02541412121908211\n","Training loss per 100 training steps: 0.027090325813115483\n","Training loss per 100 training steps: 0.02733358753841612\n","Training loss epoch: 0.02719679830011772\n","Training accuracy epoch: 0.9915079639850162\n","Validating model...\n","Validation Loss: 0.18515951827458746\n","Validation Accuracy: 0.9534434438387002\n","Training epoch: 7\n","Training loss per 100 training steps: 0.004061800893396139\n","Training loss per 100 training steps: 0.02736346377520868\n","Training loss per 100 training steps: 0.02595381858811913\n","Training loss per 100 training steps: 0.023436549081555274\n","Training loss per 100 training steps: 0.023539612033001457\n","Training loss epoch: 0.02376995175421588\n","Training accuracy epoch: 0.9925699413311246\n","Validating model...\n","Validation Loss: 0.1862569818539279\n","Validation Accuracy: 0.9559874439591906\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 31.64734203333331 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15505366722182198\n","Validation Accuracy: 0.95269651526564\n","Validation duration: 3.119267583333385 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 83.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.88      0.84     12546\n","        test       0.79      0.88      0.83      9012\n","   treatment       0.83      0.85      0.84      9297\n","\n","   micro avg       0.81      0.87      0.84     30855\n","   macro avg       0.81      0.87      0.84     30855\n","weighted avg       0.81      0.87      0.84     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n","Points in X_train after augmentation: 13000\n","Points in y_train after augmentation: 13000\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0624327659606934\n","Training loss per 100 training steps: 0.41572485023205824\n","Training loss per 100 training steps: 0.30686889681501767\n","Training loss per 100 training steps: 0.25869133214518875\n","Training loss per 100 training steps: 0.2333008951305451\n","Training loss epoch: 0.23235414748329494\n","Training accuracy epoch: 0.9263610494529404\n","Validating model...\n","Validation Loss: 0.13593949055807156\n","Validation Accuracy: 0.9578780880528217\n","Training epoch: 2\n","Training loss per 100 training steps: 0.08302242308855057\n","Training loss per 100 training steps: 0.08909630812335723\n","Training loss per 100 training steps: 0.09342399801113713\n","Training loss per 100 training steps: 0.09237163955735606\n","Training loss per 100 training steps: 0.09254970358094744\n","Training loss epoch: 0.09264207361563491\n","Training accuracy epoch: 0.9706622968335298\n","Validating model...\n","Validation Loss: 0.141524676596383\n","Validation Accuracy: 0.9555887194480587\n","Training epoch: 3\n","Training loss per 100 training steps: 0.08297755569219589\n","Training loss per 100 training steps: 0.049165676663731145\n","Training loss per 100 training steps: 0.05194894717056397\n","Training loss per 100 training steps: 0.05376818810861892\n","Training loss per 100 training steps: 0.05522260851194232\n","Training loss epoch: 0.05493924942689076\n","Training accuracy epoch: 0.9824609562510893\n","Validating model...\n","Validation Loss: 0.15562555228372094\n","Validation Accuracy: 0.9565824271574297\n","Training epoch: 4\n","Training loss per 100 training steps: 0.030684370547533035\n","Training loss per 100 training steps: 0.03243580484177253\n","Training loss per 100 training steps: 0.03357512047294231\n","Training loss per 100 training steps: 0.036065821021878816\n","Training loss per 100 training steps: 0.03611266451012204\n","Training loss epoch: 0.03587770963051066\n","Training accuracy epoch: 0.9887104030658053\n","Validating model...\n","Validation Loss: 0.17479479578988893\n","Validation Accuracy: 0.9582645041724343\n","Training epoch: 5\n","Training loss per 100 training steps: 0.002160077216103673\n","Training loss per 100 training steps: 0.02184173957984157\n","Training loss per 100 training steps: 0.02740187655766008\n","Training loss per 100 training steps: 0.030048486477683028\n","Training loss per 100 training steps: 0.030809531766663484\n","Training loss epoch: 0.030794496652876147\n","Training accuracy epoch: 0.9905584513480444\n","Validating model...\n","Validation Loss: 0.16654835948599622\n","Validation Accuracy: 0.9583886351202445\n","Training epoch: 6\n","Training loss per 100 training steps: 0.010378191247582436\n","Training loss per 100 training steps: 0.021532513149368514\n","Training loss per 100 training steps: 0.024591301879451716\n","Training loss per 100 training steps: 0.024006607596711426\n","Training loss per 100 training steps: 0.024511469674396543\n","Training loss epoch: 0.024597859277827\n","Training accuracy epoch: 0.9925811948981482\n","Validating model...\n","Validation Loss: 0.16852692729950725\n","Validation Accuracy: 0.9585503286950711\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 27.12581443333329 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14194076778625864\n","Validation Accuracy: 0.9551154332368786\n","Validation duration: 3.1228185166666664 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 84.1%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.84      0.83     12546\n","        test       0.85      0.87      0.86      9012\n","   treatment       0.84      0.84      0.84      9297\n","\n","   micro avg       0.83      0.85      0.84     30855\n","   macro avg       0.84      0.85      0.84     30855\n","weighted avg       0.83      0.85      0.84     30855\n","\n","!!!!!! Starting model number 7 !!!!!!\n","Points in X_train after augmentation: 13000\n","Points in y_train after augmentation: 13000\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9577995538711548\n","Training loss per 100 training steps: 0.45133859863375675\n","Training loss per 100 training steps: 0.3265960137197627\n","Training loss per 100 training steps: 0.2772462699450924\n","Training loss per 100 training steps: 0.2494472423359343\n","Training loss epoch: 0.24749816786635126\n","Training accuracy epoch: 0.9224228524294745\n","Validating model...\n","Validation Loss: 0.16170967554117177\n","Validation Accuracy: 0.9461719483744532\n","Training epoch: 2\n","Training loss per 100 training steps: 0.08476591855287552\n","Training loss per 100 training steps: 0.09429103414537293\n","Training loss per 100 training steps: 0.09568410290785097\n","Training loss per 100 training steps: 0.09574123031995027\n","Training loss per 100 training steps: 0.09520954451177668\n","Training loss epoch: 0.09492338678161144\n","Training accuracy epoch: 0.9696000505601619\n","Validating model...\n","Validation Loss: 0.13586679833953258\n","Validation Accuracy: 0.9590137199150804\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0380537174642086\n","Training loss per 100 training steps: 0.0594135916026512\n","Training loss per 100 training steps: 0.06057150959875898\n","Training loss per 100 training steps: 0.05873297683684236\n","Training loss per 100 training steps: 0.059280770370955034\n","Training loss epoch: 0.05905505560603935\n","Training accuracy epoch: 0.9817690608382523\n","Validating model...\n","Validation Loss: 0.14099455245637468\n","Validation Accuracy: 0.9587838204611949\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01841561682522297\n","Training loss per 100 training steps: 0.03307794524116976\n","Training loss per 100 training steps: 0.03386670850166375\n","Training loss per 100 training steps: 0.03753692966551703\n","Training loss per 100 training steps: 0.03914684181199165\n","Training loss epoch: 0.03994264665714188\n","Training accuracy epoch: 0.9875779889820602\n","Validating model...\n","Validation Loss: 0.15965568530675653\n","Validation Accuracy: 0.9551842356086776\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0061566694639623165\n","Training loss per 100 training steps: 0.02437821688075172\n","Training loss per 100 training steps: 0.025496555906975298\n","Training loss per 100 training steps: 0.026001944345115775\n","Training loss per 100 training steps: 0.02915864965084132\n","Training loss epoch: 0.02923351533182368\n","Training accuracy epoch: 0.9911098681254545\n","Validating model...\n","Validation Loss: 0.16287462374304312\n","Validation Accuracy: 0.9591909876370648\n","Training epoch: 6\n","Training loss per 100 training steps: 0.03680482134222984\n","Training loss per 100 training steps: 0.02010636778241761\n","Training loss per 100 training steps: 0.020517458151724764\n","Training loss per 100 training steps: 0.022619292786286098\n","Training loss per 100 training steps: 0.02415439632037269\n","Training loss epoch: 0.024266060191453765\n","Training accuracy epoch: 0.9925389905823431\n","Validating model...\n","Validation Loss: 0.18431331611589177\n","Validation Accuracy: 0.956719712488109\n","Training epoch: 7\n","Training loss per 100 training steps: 0.00598022248595953\n","Training loss per 100 training steps: 0.019613394894669442\n","Training loss per 100 training steps: 0.018613309774661333\n","Training loss per 100 training steps: 0.020938093909387324\n","Training loss per 100 training steps: 0.021537304811755618\n","Training loss epoch: 0.02151802486593604\n","Training accuracy epoch: 0.9932338730105467\n","Validating model...\n","Validation Loss: 0.18672358265219183\n","Validation Accuracy: 0.9601279878544701\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 31.64505695000001 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.15261693106084648\n","Validation Accuracy: 0.9534342575951539\n","Validation duration: 3.1242668166666894 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 84.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.85      0.84     12546\n","        test       0.83      0.85      0.84      9012\n","   treatment       0.82      0.87      0.84      9297\n","\n","   micro avg       0.82      0.86      0.84     30855\n","   macro avg       0.82      0.86      0.84     30855\n","weighted avg       0.82      0.86      0.84     30855\n","\n","!!!!!! Starting model number 8 !!!!!!\n","Points in X_train after augmentation: 13000\n","Points in y_train after augmentation: 13000\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0352087020874023\n","Training loss per 100 training steps: 0.43208680914180114\n","Training loss per 100 training steps: 0.31471863718916526\n","Training loss per 100 training steps: 0.26751180683754605\n","Training loss per 100 training steps: 0.24240712941324621\n","Training loss epoch: 0.24134437766392927\n","Training accuracy epoch: 0.9239395057007064\n","Validating model...\n","Validation Loss: 0.1591645750616278\n","Validation Accuracy: 0.9505611976402223\n","Training epoch: 2\n","Training loss per 100 training steps: 0.19075839221477509\n","Training loss per 100 training steps: 0.09917204452697004\n","Training loss per 100 training steps: 0.0986815887452358\n","Training loss per 100 training steps: 0.10195151985038159\n","Training loss per 100 training steps: 0.09826692418564585\n","Training loss epoch: 0.09811514023810405\n","Training accuracy epoch: 0.968232333725011\n","Validating model...\n","Validation Loss: 0.14060703834349458\n","Validation Accuracy: 0.9585298404191623\n","Training epoch: 3\n","Training loss per 100 training steps: 0.044191572815179825\n","Training loss per 100 training steps: 0.05403991474650136\n","Training loss per 100 training steps: 0.05844686197728586\n","Training loss per 100 training steps: 0.05931726001060732\n","Training loss per 100 training steps: 0.058793658809852496\n","Training loss epoch: 0.05886337854521903\n","Training accuracy epoch: 0.9813002933383183\n","Validating model...\n","Validation Loss: 0.15769565555375892\n","Validation Accuracy: 0.9586297488597426\n","Training epoch: 4\n","Training loss per 100 training steps: 0.007827041670680046\n","Training loss per 100 training steps: 0.03716717634838775\n","Training loss per 100 training steps: 0.03664604941526641\n","Training loss per 100 training steps: 0.03601437114547332\n","Training loss per 100 training steps: 0.03674412661515399\n","Training loss epoch: 0.036514597238414444\n","Training accuracy epoch: 0.9882781789406206\n","Validating model...\n","Validation Loss: 0.18174468469503638\n","Validation Accuracy: 0.9564463675944243\n","Training epoch: 5\n","Training loss per 100 training steps: 0.011171135120093822\n","Training loss per 100 training steps: 0.030293883726987436\n","Training loss per 100 training steps: 0.02818247962532222\n","Training loss per 100 training steps: 0.025924232300290485\n","Training loss per 100 training steps: 0.027560933124961474\n","Training loss epoch: 0.02752692529620461\n","Training accuracy epoch: 0.991248367075006\n","Validating model...\n","Validation Loss: 0.17595597859713938\n","Validation Accuracy: 0.9589694458935777\n","Training epoch: 6\n","Training loss per 100 training steps: 0.02960953675210476\n","Training loss per 100 training steps: 0.023776348101639068\n","Training loss per 100 training steps: 0.02305228539814348\n","Training loss per 100 training steps: 0.023423342171521158\n","Training loss per 100 training steps: 0.023440722427928953\n","Training loss epoch: 0.02329746835206633\n","Training accuracy epoch: 0.9932422313636486\n","Validating model...\n","Validation Loss: 0.19142567913060066\n","Validation Accuracy: 0.956921695537993\n","Training epoch: 7\n","Training loss per 100 training steps: 0.01688910834491253\n","Training loss per 100 training steps: 0.0161568112060483\n","Training loss per 100 training steps: 0.01839247667485505\n","Training loss per 100 training steps: 0.018424836849481287\n","Training loss per 100 training steps: 0.018711175833871715\n","Training loss epoch: 0.01868938020054658\n","Training accuracy epoch: 0.9943120575562278\n","Validating model...\n","Validation Loss: 0.1969591485360613\n","Validation Accuracy: 0.9584923215729144\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 31.642661833333356 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.15902676817064207\n","Validation Accuracy: 0.9533857164586187\n","Validation duration: 3.1367103500000666 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 83.8%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.84      0.83     12546\n","        test       0.85      0.88      0.86      9012\n","   treatment       0.83      0.83      0.83      9297\n","\n","   micro avg       0.83      0.85      0.84     30855\n","   macro avg       0.83      0.85      0.84     30855\n","weighted avg       0.83      0.85      0.84     30855\n","\n","!!!!!! Starting model number 9 !!!!!!\n","Points in X_train after augmentation: 13000\n","Points in y_train after augmentation: 13000\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0366172790527344\n","Training loss per 100 training steps: 0.3925679239011047\n","Training loss per 100 training steps: 0.2939701478427915\n","Training loss per 100 training steps: 0.25198636065388835\n","Training loss per 100 training steps: 0.22817104379936792\n","Training loss epoch: 0.22726908122493683\n","Training accuracy epoch: 0.9285562649100142\n","Validating model...\n","Validation Loss: 0.16152678501441495\n","Validation Accuracy: 0.9495005762689044\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09670598059892654\n","Training loss per 100 training steps: 0.09622288987704433\n","Stopping epoch...\n","Training loss epoch: 0.09622288987704433\n","Training accuracy epoch: 0.9598750623386034\n","Validating model...\n","Validation Loss: 0.15588857746356494\n","Validation Accuracy: 0.953825748655458\n","Training epoch: 3\n","Training loss per 100 training steps: 0.08825293183326721\n","Training loss per 100 training steps: 0.08151792823383124\n","Training loss per 100 training steps: 0.07955680969657737\n","Training loss per 100 training steps: 0.08254680858980679\n","Training loss per 100 training steps: 0.08666825629863656\n","Training loss epoch: 0.08708447756140472\n","Training accuracy epoch: 0.9722327077300044\n","Validating model...\n","Validation Loss: 0.13413212893458157\n","Validation Accuracy: 0.9574830793163237\n","Training epoch: 4\n","Training loss per 100 training steps: 0.07367460429668427\n","Training loss per 100 training steps: 0.05191182217901886\n","Training loss per 100 training steps: 0.05217909994326643\n","Training loss per 100 training steps: 0.05143693991800603\n","Training loss per 100 training steps: 0.053094535446528375\n","Training loss epoch: 0.05297576099078123\n","Training accuracy epoch: 0.983146011791422\n","Validating model...\n","Validation Loss: 0.148869315525154\n","Validation Accuracy: 0.9595075370440648\n","Training epoch: 5\n","Training loss per 100 training steps: 0.026805028319358826\n","Training loss per 100 training steps: 0.034045078024028404\n","Training loss per 100 training steps: 0.031345523828964925\n","Training loss per 100 training steps: 0.03064211710755314\n","Training loss per 100 training steps: 0.03256377806838258\n","Training loss epoch: 0.032697195132864815\n","Training accuracy epoch: 0.9896370159939553\n","Validating model...\n","Validation Loss: 0.15499921045689422\n","Validation Accuracy: 0.9596861151573164\n","Training epoch: 6\n","Training loss per 100 training steps: 0.026959123089909554\n","Training loss per 100 training steps: 0.02304859483605343\n","Training loss per 100 training steps: 0.023792940450239167\n","Training loss per 100 training steps: 0.024722589664486084\n","Training loss per 100 training steps: 0.026947699900033727\n","Training loss epoch: 0.026994574912285994\n","Training accuracy epoch: 0.9915392800511917\n","Validating model...\n","Validation Loss: 0.16570551974045766\n","Validation Accuracy: 0.9599891150293601\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0064712148159742355\n","Training loss per 100 training steps: 0.022846895009555883\n","Training loss per 100 training steps: 0.02441989078733199\n","Training loss per 100 training steps: 0.024502955730602245\n","Training loss per 100 training steps: 0.024382094538217863\n","Training loss epoch: 0.02450382950142511\n","Training accuracy epoch: 0.9924641144409411\n","Validating model...\n","Validation Loss: 0.17994964771069488\n","Validation Accuracy: 0.9597260544501505\n","Training epoch: 8\n","Training loss per 100 training steps: 0.009222150780260563\n","Training loss per 100 training steps: 0.014703161996042375\n","Training loss per 100 training steps: 0.01529168443095787\n","Training loss per 100 training steps: 0.016743142184769685\n","Training loss per 100 training steps: 0.01879400553987675\n","Training loss epoch: 0.019089446632484436\n","Training accuracy epoch: 0.9942882129830121\n","Validating model...\n","Validation Loss: 0.18761941188244852\n","Validation Accuracy: 0.9572349803054423\n","Training epoch: 9\n","Patience limit reached\n","Training duration: 33.01885351666667 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.15455147468687588\n","Validation Accuracy: 0.9517999829485829\n","Validation duration: 3.1325940499998977 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 83.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.85      0.82     12546\n","        test       0.80      0.89      0.85      9012\n","   treatment       0.83      0.85      0.84      9297\n","\n","   micro avg       0.81      0.86      0.84     30855\n","   macro avg       0.81      0.86      0.84     30855\n","weighted avg       0.81      0.86      0.84     30855\n","\n","!!!!!! Starting model number 10 !!!!!!\n","Points in X_train after augmentation: 13000\n","Points in y_train after augmentation: 13000\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0217506885528564\n","Training loss per 100 training steps: 0.4123083607542633\n","Training loss per 100 training steps: 0.30152111170600304\n","Training loss per 100 training steps: 0.25984405102424846\n","Training loss per 100 training steps: 0.23390494094710992\n","Training loss epoch: 0.2320968999529683\n","Training accuracy epoch: 0.9272426558538038\n","Validating model...\n","Validation Loss: 0.15312627872282808\n","Validation Accuracy: 0.9524219022713837\n","Training epoch: 2\n","Training loss per 100 training steps: 0.15340463817119598\n","Training loss per 100 training steps: 0.09635453084760373\n","Training loss per 100 training steps: 0.093871104456855\n","Training loss per 100 training steps: 0.09008689338582694\n","Training loss per 100 training steps: 0.09184082199417594\n","Training loss epoch: 0.09153417255775202\n","Training accuracy epoch: 0.9698345860227497\n","Validating model...\n","Validation Loss: 0.14793073675026755\n","Validation Accuracy: 0.9550676022344234\n","Training epoch: 3\n","Training loss per 100 training steps: 0.06670212000608444\n","Training loss per 100 training steps: 0.04769191961726266\n","Training loss per 100 training steps: 0.04702504863151678\n","Training loss per 100 training steps: 0.0494701299913834\n","Training loss per 100 training steps: 0.0537782886786679\n","Training loss epoch: 0.0542442920458725\n","Training accuracy epoch: 0.982865376821043\n","Validating model...\n","Validation Loss: 0.16378216894174163\n","Validation Accuracy: 0.9548817124753078\n","Training epoch: 4\n","Training loss per 100 training steps: 0.045829277485609055\n","Training loss per 100 training steps: 0.03471076527223139\n","Training loss per 100 training steps: 0.03937537026063386\n","Training loss per 100 training steps: 0.039693745428640584\n","Training loss per 100 training steps: 0.03876864298495308\n","Training loss epoch: 0.03894906551336883\n","Training accuracy epoch: 0.9881775222340902\n","Validating model...\n","Validation Loss: 0.17745974669595818\n","Validation Accuracy: 0.9577999254649749\n","Training epoch: 5\n","Training loss per 100 training steps: 0.05290861800312996\n","Training loss per 100 training steps: 0.03254691710451267\n","Training loss per 100 training steps: 0.030201893745787182\n","Training loss per 100 training steps: 0.02887475448374349\n","Training loss per 100 training steps: 0.03052994589050744\n","Training loss epoch: 0.03062751387899252\n","Training accuracy epoch: 0.9904431469510976\n","Validating model...\n","Validation Loss: 0.18053667939135007\n","Validation Accuracy: 0.9564612897804234\n","Training epoch: 6\n","Training loss per 100 training steps: 0.03211193531751633\n","Training loss per 100 training steps: 0.024240639190982547\n","Training loss per 100 training steps: 0.022419367084020182\n","Training loss per 100 training steps: 0.024739882537470108\n","Training loss per 100 training steps: 0.02536818801432365\n","Training loss epoch: 0.025540828263199446\n","Training accuracy epoch: 0.9922435911969452\n","Validating model...\n","Validation Loss: 0.17792703424181258\n","Validation Accuracy: 0.9604316755519251\n","Training epoch: 7\n","Training loss per 100 training steps: 0.012466543354094028\n","Training loss per 100 training steps: 0.022160797894558878\n","Training loss per 100 training steps: 0.02062448361437925\n","Training loss per 100 training steps: 0.020364320844696505\n","Training loss per 100 training steps: 0.02015316637379217\n","Training loss epoch: 0.02029325147685698\n","Training accuracy epoch: 0.9937329811980958\n","Validating model...\n","Validation Loss: 0.2183166408742016\n","Validation Accuracy: 0.956701018277333\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 31.636654183333302 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.16585646845784072\n","Validation Accuracy: 0.9492249499360226\n","Validation duration: 3.1228189333332312 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 82.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.78      0.87      0.82     12546\n","        test       0.86      0.74      0.80      9012\n","   treatment       0.82      0.86      0.84      9297\n","\n","   micro avg       0.82      0.83      0.82     30855\n","   macro avg       0.82      0.82      0.82     30855\n","weighted avg       0.82      0.83      0.82     30855\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0.25\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"Jhz9BiIwGCsV"},{"cell_type":"code","execution_count":null,"metadata":{"id":"jdO4m5O4Hlo3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663070587388,"user_tz":240,"elapsed":13698479,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}},"outputId":"8ff36f8b-6f05-4624-c3ca-50d68442e365"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 50.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 15600\n","Points in y_train after augmentation: 15600\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.049926996231079\n","Training loss per 100 training steps: 0.4008155125792664\n","Training loss per 100 training steps: 0.2995872188971114\n","Training loss per 100 training steps: 0.2549110775893907\n","Training loss per 100 training steps: 0.23005867080572537\n","Training loss epoch: 0.21551942052777673\n","Training accuracy epoch: 0.9322888497642698\n","Validating model...\n","Validation Loss: 0.15181760049679063\n","Validation Accuracy: 0.9516726260647504\n","Training epoch: 2\n","Training loss per 100 training steps: 0.13016054034233093\n","Training loss per 100 training steps: 0.09024752931909101\n","Training loss per 100 training steps: 0.08614405671329196\n","Training loss per 100 training steps: 0.08753388442804548\n","Training loss per 100 training steps: 0.0869681116755578\n","Training loss epoch: 0.08673183815210264\n","Training accuracy epoch: 0.9729559218840983\n","Validating model...\n","Validation Loss: 0.15220638567751105\n","Validation Accuracy: 0.9554430848869345\n","Training epoch: 3\n","Training loss per 100 training steps: 0.045274972915649414\n","Training loss per 100 training steps: 0.05151112749250514\n","Training loss per 100 training steps: 0.04982371633381245\n","Training loss per 100 training steps: 0.051388694600749796\n","Training loss per 100 training steps: 0.052003181785080316\n","Training loss epoch: 0.05250123006217258\n","Training accuracy epoch: 0.9837638169620415\n","Validating model...\n","Validation Loss: 0.15816094496517213\n","Validation Accuracy: 0.9580291682101856\n","Training epoch: 4\n","Training loss per 100 training steps: 0.06585470587015152\n","Training loss per 100 training steps: 0.028299959685358377\n","Training loss per 100 training steps: 0.03055269215997327\n","Training loss per 100 training steps: 0.03290915029491623\n","Training loss per 100 training steps: 0.03408765449813402\n","Training loss epoch: 0.03466472939061398\n","Training accuracy epoch: 0.9889572722868225\n","Validating model...\n","Validation Loss: 0.17205672343442965\n","Validation Accuracy: 0.9574607033579732\n","Training epoch: 5\n","Training loss per 100 training steps: 0.006527503952383995\n","Training loss per 100 training steps: 0.02431406742561203\n","Training loss per 100 training steps: 0.024445396750141398\n","Training loss per 100 training steps: 0.02402953214423601\n","Training loss per 100 training steps: 0.025982521825058946\n","Training loss epoch: 0.02829733552038097\n","Training accuracy epoch: 0.9911139235554505\n","Validating model...\n","Validation Loss: 0.19185630419569744\n","Validation Accuracy: 0.9540579566942731\n","Training epoch: 6\n","Training loss per 100 training steps: 0.040358204394578934\n","Training loss per 100 training steps: 0.01821287238271907\n","Training loss per 100 training steps: 0.020825143617668202\n","Training loss per 100 training steps: 0.021682726956657954\n","Training loss per 100 training steps: 0.021763124815716718\n","Training loss epoch: 0.02333659270397086\n","Training accuracy epoch: 0.9927704537270657\n","Validating model...\n","Validation Loss: 0.2253817335956476\n","Validation Accuracy: 0.9515635484575917\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 32.25644251666672 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16280042236300046\n","Validation Accuracy: 0.9497101331158424\n","Validation duration: 3.113467883333336 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 82.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.77      0.86      0.81     12546\n","        test       0.84      0.84      0.84      9012\n","   treatment       0.86      0.79      0.82      9297\n","\n","   micro avg       0.81      0.83      0.82     30855\n","   macro avg       0.82      0.83      0.82     30855\n","weighted avg       0.81      0.83      0.82     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 15600\n","Points in y_train after augmentation: 15600\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.080531358718872\n","Training loss per 100 training steps: 0.40443910481316026\n","Training loss per 100 training steps: 0.3055088676475174\n","Training loss per 100 training steps: 0.2597160039352024\n","Training loss per 100 training steps: 0.23500635526944277\n","Training loss epoch: 0.21695237318969895\n","Training accuracy epoch: 0.932325577404797\n","Validating model...\n","Validation Loss: 0.1469018017123272\n","Validation Accuracy: 0.952511591891586\n","Training epoch: 2\n","Training loss per 100 training steps: 0.10696505755186081\n","Training loss per 100 training steps: 0.08820847391455185\n","Training loss per 100 training steps: 0.0878231510941625\n","Training loss per 100 training steps: 0.08697717878627173\n","Training loss per 100 training steps: 0.08646663408285178\n","Training loss epoch: 0.08590559635528928\n","Training accuracy epoch: 0.9723730542532883\n","Validating model...\n","Validation Loss: 0.14594112697069522\n","Validation Accuracy: 0.9561929733613436\n","Training epoch: 3\n","Training loss per 100 training steps: 0.13445204496383667\n","Training loss per 100 training steps: 0.049949593980344806\n","Training loss per 100 training steps: 0.04751632440909373\n","Training loss per 100 training steps: 0.0479240393207294\n","Training loss per 100 training steps: 0.04951177977671164\n","Training loss epoch: 0.04981983261188629\n","Training accuracy epoch: 0.9843624722116945\n","Validating model...\n","Validation Loss: 0.15083405888312823\n","Validation Accuracy: 0.9587339107643442\n","Training epoch: 4\n","Training loss per 100 training steps: 0.029049552977085114\n","Training loss per 100 training steps: 0.031380931076842665\n","Training loss per 100 training steps: 0.03213389045257696\n","Training loss per 100 training steps: 0.03336690216900725\n","Training loss per 100 training steps: 0.03515395886517894\n","Training loss epoch: 0.035985435938393914\n","Training accuracy epoch: 0.9885731926075036\n","Validating model...\n","Validation Loss: 0.16493219088811378\n","Validation Accuracy: 0.9572239019777018\n","Training epoch: 5\n","Training loss per 100 training steps: 0.02454068325459957\n","Training loss per 100 training steps: 0.024889087616834827\n","Training loss per 100 training steps: 0.026789328935370775\n","Training loss per 100 training steps: 0.027523117578136688\n","Training loss per 100 training steps: 0.027451435031144045\n","Training loss epoch: 0.027536488913446205\n","Training accuracy epoch: 0.9914445448315687\n","Validating model...\n","Validation Loss: 0.17206066193712222\n","Validation Accuracy: 0.9583828359205906\n","Training epoch: 6\n","Training loss per 100 training steps: 0.001871768618002534\n","Training loss per 100 training steps: 0.01526129820054434\n","Training loss per 100 training steps: 0.01807542179134299\n","Training loss per 100 training steps: 0.019011619052945627\n","Training loss per 100 training steps: 0.019739306406141202\n","Training loss epoch: 0.020685424734542497\n","Training accuracy epoch: 0.9936808542017787\n","Validating model...\n","Validation Loss: 0.1867385557066504\n","Validation Accuracy: 0.9600647691588071\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0018639516783878207\n","Training loss per 100 training steps: 0.020077981618417444\n","Training loss per 100 training steps: 0.01819058530066227\n","Training loss per 100 training steps: 0.01810559478531935\n","Training loss per 100 training steps: 0.017750827536222633\n","Training loss epoch: 0.018274418736419634\n","Training accuracy epoch: 0.9945920193873061\n","Validating model...\n","Validation Loss: 0.20094294104023608\n","Validation Accuracy: 0.9565431445147116\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 37.57955989999997 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16091832176230295\n","Validation Accuracy: 0.952436403121124\n","Validation duration: 3.1229920999999496 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 83.3%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.86      0.83     12546\n","        test       0.82      0.87      0.84      9012\n","   treatment       0.81      0.86      0.83      9297\n","\n","   micro avg       0.81      0.86      0.83     30855\n","   macro avg       0.81      0.86      0.83     30855\n","weighted avg       0.81      0.86      0.83     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 15600\n","Points in y_train after augmentation: 15600\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8436211347579956\n","Training loss per 100 training steps: 0.3938376053725139\n","Training loss per 100 training steps: 0.2915358378816007\n","Training loss per 100 training steps: 0.25425927868218123\n","Training loss per 100 training steps: 0.22701489605343997\n","Training loss epoch: 0.2100673148820757\n","Training accuracy epoch: 0.9332199446967911\n","Validating model...\n","Validation Loss: 0.14178921652401422\n","Validation Accuracy: 0.9549232315859109\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04371100664138794\n","Training loss per 100 training steps: 0.08412124251596409\n","Training loss per 100 training steps: 0.08098640354971091\n","Training loss per 100 training steps: 0.07945040056475769\n","Training loss per 100 training steps: 0.0808414538202812\n","Training loss epoch: 0.08096916576251999\n","Training accuracy epoch: 0.974212485243007\n","Validating model...\n","Validation Loss: 0.1467319205403328\n","Validation Accuracy: 0.955960517190366\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03760048374533653\n","Training loss per 100 training steps: 0.04302863455792465\n","Training loss per 100 training steps: 0.0440076513294668\n","Training loss per 100 training steps: 0.0473939871517601\n","Training loss per 100 training steps: 0.04847512869373373\n","Training loss epoch: 0.04894574419747977\n","Training accuracy epoch: 0.9846235637513977\n","Validating model...\n","Validation Loss: 0.1468166148761747\n","Validation Accuracy: 0.9597416789219537\n","Training epoch: 4\n","Training loss per 100 training steps: 0.029199576005339622\n","Training loss per 100 training steps: 0.02738457420808586\n","Training loss per 100 training steps: 0.029289183344122078\n","Training loss per 100 training steps: 0.03230968278645541\n","Training loss per 100 training steps: 0.03228271880304381\n","Training loss epoch: 0.03251306361067453\n","Training accuracy epoch: 0.9898589906072809\n","Validating model...\n","Validation Loss: 0.17715927113041088\n","Validation Accuracy: 0.9567132584351028\n","Training epoch: 5\n","Training loss per 100 training steps: 0.013983132317662239\n","Training loss per 100 training steps: 0.030175849034607707\n","Training loss per 100 training steps: 0.028352364134367796\n","Training loss per 100 training steps: 0.028475243105004662\n","Training loss per 100 training steps: 0.02846176836526711\n","Training loss epoch: 0.02859093765335751\n","Training accuracy epoch: 0.9910506403428341\n","Validating model...\n","Validation Loss: 0.18386404073567358\n","Validation Accuracy: 0.9545671739976489\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0473017618060112\n","Training loss per 100 training steps: 0.020092382597723182\n","Training loss per 100 training steps: 0.019384302799786854\n","Training loss per 100 training steps: 0.02030791517674298\n","Training loss per 100 training steps: 0.021128104526016565\n","Training loss epoch: 0.023577195359513234\n","Training accuracy epoch: 0.9928255335070393\n","Validating model...\n","Validation Loss: 0.19991182402840682\n","Validation Accuracy: 0.954631436693043\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 32.14996038333326 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15891643616163897\n","Validation Accuracy: 0.9505639341278008\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation duration: 3.1109949666667185 minutes\n","F1-score (test): 82.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.83      0.82     12546\n","        test       0.83      0.83      0.83      9012\n","   treatment       0.82      0.85      0.83      9297\n","\n","   micro avg       0.82      0.84      0.83     30855\n","   macro avg       0.82      0.84      0.83     30855\n","weighted avg       0.82      0.84      0.83     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 15600\n","Points in y_train after augmentation: 15600\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9586379528045654\n","Training loss per 100 training steps: 0.41036952050900694\n","Training loss per 100 training steps: 0.3021438064711604\n","Training loss per 100 training steps: 0.2605755602278781\n","Training loss per 100 training steps: 0.23325711956939793\n","Training loss epoch: 0.215769875359523\n","Training accuracy epoch: 0.9318527099963909\n","Validating model...\n","Validation Loss: 0.1438089506579684\n","Validation Accuracy: 0.9510498462464714\n","Training epoch: 2\n","Training loss per 100 training steps: 0.08245614171028137\n","Training loss per 100 training steps: 0.08288755652374856\n","Stopping epoch...\n","Training loss epoch: 0.08288755652374856\n","Training accuracy epoch: 0.9643554287256455\n","Validating model...\n","Validation Loss: 0.15533941930958203\n","Validation Accuracy: 0.9546899792207767\n","Training epoch: 3\n","Training loss per 100 training steps: 0.041710708290338516\n","Training loss per 100 training steps: 0.07348643938577411\n","Training loss per 100 training steps: 0.07296695401289718\n","Training loss per 100 training steps: 0.07485647287306398\n","Training loss per 100 training steps: 0.07540032631274025\n","Training loss epoch: 0.07775256940407953\n","Training accuracy epoch: 0.9752883054519843\n","Validating model...\n","Validation Loss: 0.15700637573352108\n","Validation Accuracy: 0.952638721574835\n","Training epoch: 4\n","Training loss per 100 training steps: 0.02011803910136223\n","Training loss per 100 training steps: 0.03635149751098292\n","Training loss per 100 training steps: 0.04143216806134922\n","Training loss per 100 training steps: 0.04602989511861407\n","Training loss per 100 training steps: 0.048111840799227916\n","Training loss epoch: 0.048271686740440974\n","Training accuracy epoch: 0.9851495339122592\n","Validating model...\n","Validation Loss: 0.16650367920081338\n","Validation Accuracy: 0.9567872978909676\n","Training epoch: 5\n","Training loss per 100 training steps: 0.10331001877784729\n","Training loss per 100 training steps: 0.02530028767731631\n","Training loss per 100 training steps: 0.02683928951711408\n","Training loss per 100 training steps: 0.029404550431098207\n","Training loss per 100 training steps: 0.030914170275026576\n","Training loss epoch: 0.03141065551584479\n","Training accuracy epoch: 0.9904854137974162\n","Validating model...\n","Validation Loss: 0.1775108048232732\n","Validation Accuracy: 0.957555765665219\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0037602917291224003\n","Training loss per 100 training steps: 0.02735640308335608\n","Training loss per 100 training steps: 0.027540336267452743\n","Training loss per 100 training steps: 0.02709107808737808\n","Training loss per 100 training steps: 0.027100674206352655\n","Training loss epoch: 0.027218978716533813\n","Training accuracy epoch: 0.9918362591572881\n","Validating model...\n","Validation Loss: 0.20527235179075173\n","Validation Accuracy: 0.9537505179431783\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 28.13438966666666 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.15549749587188233\n","Validation Accuracy: 0.949243246209519\n","Validation duration: 3.132033566666723 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 82.3%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.83      0.81     12546\n","        test       0.82      0.86      0.84      9012\n","   treatment       0.83      0.83      0.83      9297\n","\n","   micro avg       0.81      0.84      0.82     30855\n","   macro avg       0.81      0.84      0.83     30855\n","weighted avg       0.81      0.84      0.82     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n","Points in X_train after augmentation: 15600\n","Points in y_train after augmentation: 15600\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9416898488998413\n","Training loss per 100 training steps: 0.43124817156850703\n","Training loss per 100 training steps: 0.3156235427294501\n","Training loss per 100 training steps: 0.2696727667239021\n","Training loss per 100 training steps: 0.2409118677110892\n","Training loss epoch: 0.22077379924947488\n","Training accuracy epoch: 0.930180634744164\n","Validating model...\n","Validation Loss: 0.14715387822165119\n","Validation Accuracy: 0.9518128305659802\n","Training epoch: 2\n","Training loss per 100 training steps: 0.15125121176242828\n","Training loss per 100 training steps: 0.08878854642815814\n","Training loss per 100 training steps: 0.08757660435558996\n","Training loss per 100 training steps: 0.08906116782133762\n","Training loss per 100 training steps: 0.08935996294114507\n","Training loss epoch: 0.0905695577022299\n","Training accuracy epoch: 0.9708993788639595\n","Validating model...\n","Validation Loss: 0.14595163678871348\n","Validation Accuracy: 0.9561502429927136\n","Training epoch: 3\n","Training loss per 100 training steps: 0.024177310988307\n","Training loss per 100 training steps: 0.05510792363951407\n","Training loss per 100 training steps: 0.053596731557960235\n","Training loss per 100 training steps: 0.05537620114094494\n","Training loss per 100 training steps: 0.054233349293024466\n","Training loss epoch: 0.054282958798690654\n","Training accuracy epoch: 0.9831514214724596\n","Validating model...\n","Validation Loss: 0.15371526794677431\n","Validation Accuracy: 0.9585251725740376\n","Training epoch: 4\n","Training loss per 100 training steps: 0.025879060849547386\n","Training loss per 100 training steps: 0.03076557443929043\n","Training loss per 100 training steps: 0.031059917847890018\n","Training loss per 100 training steps: 0.03472590136057094\n","Training loss per 100 training steps: 0.03410203934140838\n","Training loss epoch: 0.03567599603614281\n","Training accuracy epoch: 0.9889892270802363\n","Validating model...\n","Validation Loss: 0.1538480023381772\n","Validation Accuracy: 0.9566151174730708\n","Training epoch: 5\n","Training loss per 100 training steps: 0.10428319126367569\n","Training loss per 100 training steps: 0.023771288753994327\n","Training loss per 100 training steps: 0.021338981205588255\n","Training loss per 100 training steps: 0.024004059754377013\n","Training loss per 100 training steps: 0.028435596116549076\n","Training loss epoch: 0.030203636313195066\n","Training accuracy epoch: 0.9907528399536166\n","Validating model...\n","Validation Loss: 0.1920197383536921\n","Validation Accuracy: 0.9542052889014696\n","Training epoch: 6\n","Training loss per 100 training steps: 0.02195475623011589\n","Training loss per 100 training steps: 0.022645928941916048\n","Training loss per 100 training steps: 0.023728976691076858\n","Training loss per 100 training steps: 0.023579327856032704\n","Training loss per 100 training steps: 0.023705812540669412\n","Training loss epoch: 0.02389066817883505\n","Training accuracy epoch: 0.9925819033177842\n","Validating model...\n","Validation Loss: 0.19252721336367842\n","Validation Accuracy: 0.9563339736167403\n","Training epoch: 7\n","Training loss per 100 training steps: 0.007244451902806759\n","Training loss per 100 training steps: 0.015748082728143598\n","Training loss per 100 training steps: 0.018262334149423524\n","Training loss per 100 training steps: 0.018647669708941047\n","Training loss per 100 training steps: 0.0190119756353169\n","Training loss epoch: 0.020885086716648925\n","Training accuracy epoch: 0.9940318206016596\n","Validating model...\n","Validation Loss: 0.1921646406075784\n","Validation Accuracy: 0.9571518578125288\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 37.601874300000055 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.1625679134848286\n","Validation Accuracy: 0.9522570710104802\n","Validation duration: 3.151947600000009 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 83.1%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.85      0.84     12546\n","        test       0.77      0.89      0.82      9012\n","   treatment       0.79      0.88      0.83      9297\n","\n","   micro avg       0.80      0.87      0.83     30855\n","   macro avg       0.79      0.87      0.83     30855\n","weighted avg       0.80      0.87      0.83     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n","Points in X_train after augmentation: 15600\n","Points in y_train after augmentation: 15600\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.867986798286438\n","Training loss per 100 training steps: 0.39883497379498906\n","Training loss per 100 training steps: 0.2980709731652962\n","Training loss per 100 training steps: 0.25739160982081266\n","Training loss per 100 training steps: 0.23160973086748782\n","Training loss epoch: 0.21748260023515123\n","Training accuracy epoch: 0.9296529118123411\n","Validating model...\n","Validation Loss: 0.13234497669648815\n","Validation Accuracy: 0.9577034163998227\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06743905693292618\n","Training loss per 100 training steps: 0.08266143142107395\n","Training loss per 100 training steps: 0.08141459557528964\n","Training loss per 100 training steps: 0.08344717843897417\n","Training loss per 100 training steps: 0.08163584301485088\n","Training loss epoch: 0.08142414678376718\n","Training accuracy epoch: 0.9741698842122575\n","Validating model...\n","Validation Loss: 0.14375995936525332\n","Validation Accuracy: 0.9553826358651868\n","Training epoch: 3\n","Training loss per 100 training steps: 0.12265672534704208\n","Training loss per 100 training steps: 0.04398127802933502\n","Training loss per 100 training steps: 0.048826445665544095\n","Training loss per 100 training steps: 0.04915861933464277\n","Training loss per 100 training steps: 0.050429233848036006\n","Training loss epoch: 0.05238179307713433\n","Training accuracy epoch: 0.9834984956553414\n","Validating model...\n","Validation Loss: 0.1438777849029798\n","Validation Accuracy: 0.9599582305280392\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01748550869524479\n","Training loss per 100 training steps: 0.03282687627585918\n","Training loss per 100 training steps: 0.030950294713146836\n","Training loss per 100 training steps: 0.030591455546975063\n","Training loss per 100 training steps: 0.031002382867147408\n","Training loss epoch: 0.030836346239084378\n","Training accuracy epoch: 0.9904491170866246\n","Validating model...\n","Validation Loss: 0.20112132614889702\n","Validation Accuracy: 0.9522168321056818\n","Training epoch: 5\n","Training loss per 100 training steps: 0.004092190880328417\n","Training loss per 100 training steps: 0.023089735103093346\n","Training loss per 100 training steps: 0.02560687175197805\n","Training loss per 100 training steps: 0.025745924801041258\n","Training loss per 100 training steps: 0.025688863299732467\n","Training loss epoch: 0.026636159138016396\n","Training accuracy epoch: 0.9919059544656769\n","Validating model...\n","Validation Loss: 0.17354202258412715\n","Validation Accuracy: 0.9567476192138927\n","Training epoch: 6\n","Training loss per 100 training steps: 0.02456783689558506\n","Training loss per 100 training steps: 0.01860988580294433\n","Training loss per 100 training steps: 0.018722945031656685\n","Training loss per 100 training steps: 0.020257907998871887\n","Training loss per 100 training steps: 0.019799379509655372\n","Training loss epoch: 0.02056814203173357\n","Training accuracy epoch: 0.9939178495048466\n","Validating model...\n","Validation Loss: 0.18085071051420717\n","Validation Accuracy: 0.9581292459120356\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 32.21555824999996 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.1461165054147218\n","Validation Accuracy: 0.9534222635285815\n","Validation duration: 3.12287943333334 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 83.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.84      0.82     12546\n","        test       0.83      0.87      0.85      9012\n","   treatment       0.83      0.84      0.83      9297\n","\n","   micro avg       0.82      0.85      0.83     30855\n","   macro avg       0.82      0.85      0.84     30855\n","weighted avg       0.82      0.85      0.83     30855\n","\n","!!!!!! Starting model number 7 !!!!!!\n","Points in X_train after augmentation: 15600\n","Points in y_train after augmentation: 15600\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.3694281578063965\n","Training loss per 100 training steps: 0.4129649240634229\n","Training loss per 100 training steps: 0.3143574187708138\n","Training loss per 100 training steps: 0.26785955496404656\n","Training loss per 100 training steps: 0.24015495915922738\n","Training loss epoch: 0.221766414975778\n","Training accuracy epoch: 0.929985892059251\n","Validating model...\n","Validation Loss: 0.14194080644807258\n","Validation Accuracy: 0.9533589259558384\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07015719264745712\n","Training loss per 100 training steps: 0.08211166390429923\n","Training loss per 100 training steps: 0.07966618879295106\n","Training loss per 100 training steps: 0.08263834735898432\n","Training loss per 100 training steps: 0.08631718493974826\n","Training loss epoch: 0.08585567877186104\n","Training accuracy epoch: 0.9724055302735253\n","Validating model...\n","Validation Loss: 0.15224950755764913\n","Validation Accuracy: 0.9559415823158259\n","Training epoch: 3\n","Training loss per 100 training steps: 0.08345988392829895\n","Training loss per 100 training steps: 0.052707048626339965\n","Training loss per 100 training steps: 0.05296041770833568\n","Training loss per 100 training steps: 0.05400365097695757\n","Training loss per 100 training steps: 0.054038975215946645\n","Training loss epoch: 0.0533707415490396\n","Training accuracy epoch: 0.9833284696783062\n","Validating model...\n","Validation Loss: 0.16105106228648067\n","Validation Accuracy: 0.9580382351081641\n","Training epoch: 4\n","Training loss per 100 training steps: 0.06833991408348083\n","Training loss per 100 training steps: 0.030821509305433842\n","Training loss per 100 training steps: 0.03143902122453133\n","Training loss per 100 training steps: 0.032596390834774364\n","Training loss per 100 training steps: 0.03367445879311596\n","Training loss epoch: 0.034506838536367095\n","Training accuracy epoch: 0.9892987405740973\n","Validating model...\n","Validation Loss: 0.179948716968685\n","Validation Accuracy: 0.9555143078025363\n","Training epoch: 5\n","Training loss per 100 training steps: 0.010207044892013073\n","Training loss per 100 training steps: 0.02331205463212094\n","Training loss per 100 training steps: 0.024528914707798548\n","Training loss per 100 training steps: 0.02578738406188384\n","Training loss per 100 training steps: 0.02531314686627622\n","Training loss epoch: 0.024881944947157505\n","Training accuracy epoch: 0.9924560812171203\n","Validating model...\n","Validation Loss: 0.1846446500026754\n","Validation Accuracy: 0.9591565314406805\n","Training epoch: 6\n","Training loss per 100 training steps: 0.031529709696769714\n","Training loss per 100 training steps: 0.016839936445928225\n","Training loss per 100 training steps: 0.01819231375253792\n","Training loss per 100 training steps: 0.018125619033260265\n","Training loss per 100 training steps: 0.01850763665778711\n","Training loss epoch: 0.019279371246053327\n","Training accuracy epoch: 0.9941289801292227\n","Validating model...\n","Validation Loss: 0.2005521574521788\n","Validation Accuracy: 0.9579973895152434\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 32.2001317333333 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.15608221627944321\n","Validation Accuracy: 0.9515665871247031\n","Validation duration: 3.1316356833332977 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 83.1%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.83      0.83     12546\n","        test       0.84      0.85      0.84      9012\n","   treatment       0.77      0.88      0.82      9297\n","\n","   micro avg       0.81      0.85      0.83     30855\n","   macro avg       0.81      0.85      0.83     30855\n","weighted avg       0.81      0.85      0.83     30855\n","\n","!!!!!! Starting model number 8 !!!!!!\n","Points in X_train after augmentation: 15600\n","Points in y_train after augmentation: 15600\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.426107168197632\n","Training loss per 100 training steps: 0.42973511525900054\n","Training loss per 100 training steps: 0.31564272304450103\n","Training loss per 100 training steps: 0.2683028782597214\n","Training loss per 100 training steps: 0.23871546971641872\n","Training loss epoch: 0.22095399772839958\n","Training accuracy epoch: 0.9310865893155408\n","Validating model...\n","Validation Loss: 0.14566580752854225\n","Validation Accuracy: 0.9542411858818091\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06781281530857086\n","Training loss per 100 training steps: 0.08991003017134891\n","Training loss per 100 training steps: 0.08762104053569225\n","Training loss per 100 training steps: 0.08506197747511424\n","Training loss per 100 training steps: 0.08760804894549815\n","Training loss epoch: 0.0876192863721431\n","Training accuracy epoch: 0.971943919597171\n","Validating model...\n","Validation Loss: 0.14730818296310963\n","Validation Accuracy: 0.9552729711877073\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04023388400673866\n","Training loss per 100 training steps: 0.046780808957865336\n","Training loss per 100 training steps: 0.04822332112915555\n","Training loss per 100 training steps: 0.04992310726779987\n","Training loss per 100 training steps: 0.05327591635495833\n","Training loss epoch: 0.054824551827938404\n","Training accuracy epoch: 0.9826346843594391\n","Validating model...\n","Validation Loss: 0.1552279597366011\n","Validation Accuracy: 0.9532440312227689\n","Training epoch: 4\n","Training loss per 100 training steps: 0.04546060040593147\n","Training loss per 100 training steps: 0.035340085653311544\n","Training loss per 100 training steps: 0.03453083091128191\n","Training loss per 100 training steps: 0.034639296665682495\n","Training loss per 100 training steps: 0.035033058721753316\n","Training loss epoch: 0.03572784710177373\n","Training accuracy epoch: 0.9891009564688459\n","Validating model...\n","Validation Loss: 0.16187184775707783\n","Validation Accuracy: 0.9590058836812777\n","Training epoch: 5\n","Training loss per 100 training steps: 0.024482060223817825\n","Training loss per 100 training steps: 0.021746305375369174\n","Training loss per 100 training steps: 0.02394877734828036\n","Training loss per 100 training steps: 0.024449553678703318\n","Training loss per 100 training steps: 0.02446718144223577\n","Training loss epoch: 0.02548466474638458\n","Training accuracy epoch: 0.9923244648580494\n","Validating model...\n","Validation Loss: 0.16946998773166885\n","Validation Accuracy: 0.9611206091463531\n","Training epoch: 6\n","Training loss per 100 training steps: 0.006661060266196728\n","Training loss per 100 training steps: 0.021595925141107475\n","Training loss per 100 training steps: 0.021599973719312222\n","Training loss per 100 training steps: 0.023053018792386963\n","Training loss per 100 training steps: 0.022623407285622184\n","Training loss epoch: 0.022331846124930575\n","Training accuracy epoch: 0.9931009083310591\n","Validating model...\n","Validation Loss: 0.1760009154677391\n","Validation Accuracy: 0.960491440013453\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 32.179013899999944 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.15404227191875516\n","Validation Accuracy: 0.952826677345887\n","Validation duration: 3.1171591999999992 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 83.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.82      0.82     12546\n","        test       0.85      0.86      0.86      9012\n","   treatment       0.82      0.84      0.83      9297\n","\n","   micro avg       0.83      0.84      0.84     30855\n","   macro avg       0.83      0.84      0.84     30855\n","weighted avg       0.83      0.84      0.84     30855\n","\n","!!!!!! Starting model number 9 !!!!!!\n","Points in X_train after augmentation: 15600\n","Points in y_train after augmentation: 15600\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7530591487884521\n","Training loss per 100 training steps: 0.37903908426218696\n","Training loss per 100 training steps: 0.2891095745659883\n","Training loss per 100 training steps: 0.2531625112005048\n","Training loss per 100 training steps: 0.22803580954187827\n","Training loss epoch: 0.2134853454619707\n","Training accuracy epoch: 0.9327573926211562\n","Validating model...\n","Validation Loss: 0.15851619892886706\n","Validation Accuracy: 0.9470590136598299\n","Training epoch: 2\n","Training loss per 100 training steps: 0.10550597310066223\n","Training loss per 100 training steps: 0.0927765471030875\n","Training loss per 100 training steps: 0.09053145010784194\n","Training loss per 100 training steps: 0.0874747686471753\n","Training loss per 100 training steps: 0.08783256721466855\n","Training loss epoch: 0.08715561659029517\n","Training accuracy epoch: 0.9720513768202862\n","Validating model...\n","Validation Loss: 0.14597207387643202\n","Validation Accuracy: 0.9556001583953262\n","Training epoch: 3\n","Training loss per 100 training steps: 0.018564444035291672\n","Training loss per 100 training steps: 0.04864760993122317\n","Training loss per 100 training steps: 0.049542816476294056\n","Training loss per 100 training steps: 0.05049745758927344\n","Training loss per 100 training steps: 0.051258645927361644\n","Training loss epoch: 0.052606743084816415\n","Training accuracy epoch: 0.9833106661986628\n","Validating model...\n","Validation Loss: 0.14936961245710972\n","Validation Accuracy: 0.9554861940664587\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0146259143948555\n","Training loss per 100 training steps: 0.03183460402035034\n","Training loss per 100 training steps: 0.03306673014008287\n","Training loss per 100 training steps: 0.034555786640454465\n","Training loss per 100 training steps: 0.034618152421028205\n","Training loss epoch: 0.03386072859026828\n","Training accuracy epoch: 0.9897692876603481\n","Validating model...\n","Validation Loss: 0.19069373556836086\n","Validation Accuracy: 0.9553341581258341\n","Training epoch: 5\n","Training loss per 100 training steps: 0.010091678239405155\n","Training loss per 100 training steps: 0.018381793297467624\n","Training loss per 100 training steps: 0.02372797446346272\n","Training loss per 100 training steps: 0.025741183860737992\n","Training loss per 100 training steps: 0.02547475165107457\n","Training loss epoch: 0.026249487365125564\n","Training accuracy epoch: 0.9922460919677965\n","Validating model...\n","Validation Loss: 0.17992485355730956\n","Validation Accuracy: 0.9585592228585992\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0066357566975057125\n","Training loss per 100 training steps: 0.020822635548659554\n","Training loss per 100 training steps: 0.025330640497821296\n","Training loss per 100 training steps: 0.02545067650904922\n","Training loss per 100 training steps: 0.02496839927723097\n","Training loss epoch: 0.02567396119769403\n","Training accuracy epoch: 0.9922998815435814\n","Validating model...\n","Validation Loss: 0.20314564511131544\n","Validation Accuracy: 0.9580789301851873\n","Training epoch: 7\n","Training loss per 100 training steps: 0.004945356398820877\n","Training loss per 100 training steps: 0.021129907169932554\n","Training loss per 100 training steps: 0.020275587829372\n","Training loss per 100 training steps: 0.020325312816941696\n","Training loss per 100 training steps: 0.019896953676460296\n","Training loss epoch: 0.019270544769824483\n","Training accuracy epoch: 0.9939737957210936\n","Validating model...\n","Validation Loss: 0.20026582520600264\n","Validation Accuracy: 0.9602644391868954\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 37.51287493333329 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.16873575651078243\n","Validation Accuracy: 0.9521950070534423\n","Validation duration: 3.129662316666751 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 83.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.86      0.83     12546\n","        test       0.83      0.86      0.84      9012\n","   treatment       0.85      0.82      0.84      9297\n","\n","   micro avg       0.82      0.85      0.84     30855\n","   macro avg       0.83      0.85      0.84     30855\n","weighted avg       0.82      0.85      0.84     30855\n","\n","!!!!!! Starting model number 10 !!!!!!\n","Points in X_train after augmentation: 15600\n","Points in y_train after augmentation: 15600\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.2021994590759277\n","Training loss per 100 training steps: 0.41707961873547866\n","Training loss per 100 training steps: 0.3130807931076235\n","Training loss per 100 training steps: 0.26955737537422847\n","Training loss per 100 training steps: 0.24066468357965537\n","Training loss epoch: 0.2239817662821075\n","Training accuracy epoch: 0.9298772805006441\n","Validating model...\n","Validation Loss: 0.14273801010537457\n","Validation Accuracy: 0.9529713129847341\n","Training epoch: 2\n","Training loss per 100 training steps: 0.1456833928823471\n","Training loss per 100 training steps: 0.08589888159370068\n","Training loss per 100 training steps: 0.08766797447660521\n","Training loss per 100 training steps: 0.0882344621069655\n","Training loss per 100 training steps: 0.08750406742569737\n","Training loss epoch: 0.08655796477525327\n","Training accuracy epoch: 0.9729937043769865\n","Validating model...\n","Validation Loss: 0.15838067250495608\n","Validation Accuracy: 0.9552778710488199\n","Training epoch: 3\n","Training loss per 100 training steps: 0.05003473907709122\n","Training loss per 100 training steps: 0.04720050704176768\n","Training loss per 100 training steps: 0.04616277562500677\n","Training loss per 100 training steps: 0.04875517865964691\n","Training loss per 100 training steps: 0.053315735908638584\n","Training loss epoch: 0.05340236389091559\n","Training accuracy epoch: 0.9833918662137785\n","Validating model...\n","Validation Loss: 0.15577151623929475\n","Validation Accuracy: 0.9593907672966969\n","Training epoch: 4\n","Training loss per 100 training steps: 0.06661751866340637\n","Training loss per 100 training steps: 0.0294553292016176\n","Training loss per 100 training steps: 0.032157336991854864\n","Training loss per 100 training steps: 0.03291005820602154\n","Training loss per 100 training steps: 0.035966576470127166\n","Training loss epoch: 0.03576647276850799\n","Training accuracy epoch: 0.9889017066026289\n","Validating model...\n","Validation Loss: 0.17067060876008752\n","Validation Accuracy: 0.957452630405138\n","Training epoch: 5\n","Training loss per 100 training steps: 0.07695655524730682\n","Training loss per 100 training steps: 0.021707826033511228\n","Training loss per 100 training steps: 0.021942059201332024\n","Training loss per 100 training steps: 0.02215553010311875\n","Training loss per 100 training steps: 0.020893089911038814\n","Training loss epoch: 0.021437808525363044\n","Training accuracy epoch: 0.9935443614009376\n","Validating model...\n","Validation Loss: 0.21739928899695735\n","Validation Accuracy: 0.9564764866574103\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0061949496157467365\n","Training loss per 100 training steps: 0.02026713788129002\n","Training loss per 100 training steps: 0.01637324007385554\n","Training loss per 100 training steps: 0.017827402470607087\n","Training loss per 100 training steps: 0.021415035385363258\n","Training loss epoch: 0.021938062009122985\n","Training accuracy epoch: 0.9932379790121467\n","Validating model...\n","Validation Loss: 0.18724562657101976\n","Validation Accuracy: 0.9607903202205946\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 32.218689733333306 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.15286674391461053\n","Validation Accuracy: 0.9514821133455547\n","Validation duration: 3.1383739499999743 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 82.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.84      0.82     12546\n","        test       0.84      0.82      0.83      9012\n","   treatment       0.84      0.83      0.83      9297\n","\n","   micro avg       0.82      0.83      0.83     30855\n","   macro avg       0.82      0.83      0.83     30855\n","weighted avg       0.82      0.83      0.83     30855\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0.5\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"jdO4m5O4Hlo3"},{"cell_type":"code","execution_count":null,"metadata":{"id":"oKNxFPucHn_R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663096880869,"user_tz":240,"elapsed":331130,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}},"outputId":"6a200878-e435-482a-d8bd-61210b31cf52"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 75.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 18200\n","Points in y_train after augmentation: 18200\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.287151336669922\n","Training loss per 100 training steps: 0.430377853683906\n","Training loss per 100 training steps: 0.31723537852070227\n","Training loss per 100 training steps: 0.2692449155613236\n","Training loss per 100 training steps: 0.24038142418289124\n","Training loss per 100 training steps: 0.22067435174630193\n","Training loss epoch: 0.21024370464203332\n","Training accuracy epoch: 0.9333362515861734\n","Validating model...\n","Validation Loss: 0.13635875732190422\n","Validation Accuracy: 0.9555969041973891\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06050816923379898\n","Training loss per 100 training steps: 0.08199495617484692\n","Training loss per 100 training steps: 0.08475782207458915\n","Training loss per 100 training steps: 0.08002915433252175\n","Training loss per 100 training steps: 0.08130469003185964\n","Training loss per 100 training steps: 0.08095291874254357\n","Training loss epoch: 0.08103985629275258\n","Training accuracy epoch: 0.9751069268494645\n","Validating model...\n","Validation Loss: 0.16508402694742402\n","Validation Accuracy: 0.9532096425510735\n","Training epoch: 3\n","Training loss per 100 training steps: 0.039769407361745834\n","Training loss per 100 training steps: 0.045878592523570995\n","Training loss per 100 training steps: 0.04736373896145294\n","Training loss per 100 training steps: 0.0466160829050584\n","Training loss per 100 training steps: 0.047837297709663384\n","Training loss per 100 training steps: 0.04935496595191831\n","Training loss epoch: 0.050524681161676646\n","Training accuracy epoch: 0.9838087102005064\n","Validating model...\n","Validation Loss: 0.16938041612602672\n","Validation Accuracy: 0.9563157083039264\n","Training epoch: 4\n","Training loss per 100 training steps: 0.012139338999986649\n","Training loss per 100 training steps: 0.030568444419025193\n","Training loss per 100 training steps: 0.03741892206654027\n","Training loss per 100 training steps: 0.03578823865499607\n","Training loss per 100 training steps: 0.034762599235493456\n","Training loss per 100 training steps: 0.03440325661606997\n","Training loss epoch: 0.034020644687901794\n","Training accuracy epoch: 0.9897760872421856\n","Validating model...\n","Validation Loss: 0.1759938227327226\n","Validation Accuracy: 0.9582987172076172\n","Training epoch: 5\n","Training loss per 100 training steps: 0.006888068281114101\n","Training loss per 100 training steps: 0.021247159191729998\n","Training loss per 100 training steps: 0.02260657950780535\n","Training loss per 100 training steps: 0.022610291467741305\n","Training loss per 100 training steps: 0.024731743852886606\n","Training loss per 100 training steps: 0.024888053318920605\n","Training loss epoch: 0.024579368017757924\n","Training accuracy epoch: 0.9924142010239958\n","Validating model...\n","Validation Loss: 0.20860325595871967\n","Validation Accuracy: 0.956463060365261\n","Training epoch: 6\n","Training loss per 100 training steps: 0.03201396390795708\n","Training loss per 100 training steps: 0.017208944880783946\n","Training loss per 100 training steps: 0.018102836453289823\n","Training loss per 100 training steps: 0.01887084657345292\n","Training loss per 100 training steps: 0.019753421248390253\n","Training loss per 100 training steps: 0.020812011688044703\n","Training loss epoch: 0.02095016048334642\n","Training accuracy epoch: 0.9939315040415622\n","Validating model...\n","Validation Loss: 0.1899687276258097\n","Validation Accuracy: 0.9594715129297504\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 37.27287923333339 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14937761499486105\n","Validation Accuracy: 0.9510510641934936\n","Validation duration: 3.1284943666666853 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 82.8%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.87      0.82     12546\n","        test       0.83      0.85      0.84      9012\n","   treatment       0.78      0.87      0.83      9297\n","\n","   micro avg       0.80      0.86      0.83     30855\n","   macro avg       0.80      0.86      0.83     30855\n","weighted avg       0.80      0.86      0.83     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 18200\n","Points in y_train after augmentation: 18200\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9498547315597534\n","Training loss per 100 training steps: 0.39764722008811365\n","Training loss per 100 training steps: 0.3049257053664668\n","Training loss per 100 training steps: 0.25747126922555935\n","Training loss per 100 training steps: 0.23254959381875254\n","Training loss per 100 training steps: 0.2136693448571864\n","Training loss epoch: 0.2036467397516767\n","Training accuracy epoch: 0.9353815672026308\n","Validating model...\n","Validation Loss: 0.16664367851305317\n","Validation Accuracy: 0.9480990810762582\n","Training epoch: 2\n","Training loss per 100 training steps: 0.12934444844722748\n","Training loss per 100 training steps: 0.08101038811820568\n","Training loss per 100 training steps: 0.07723060661268916\n","Training loss per 100 training steps: 0.08052397903946051\n","Training loss per 100 training steps: 0.08165550522942867\n","Training loss per 100 training steps: 0.07898432653427065\n","Training loss epoch: 0.07949835065791551\n","Training accuracy epoch: 0.9751001180412034\n","Validating model...\n","Validation Loss: 0.16123756679234566\n","Validation Accuracy: 0.953576365942716\n","Training epoch: 3\n","Training loss per 100 training steps: 0.030488932505249977\n","Training loss per 100 training steps: 0.04242228542795718\n","Training loss per 100 training steps: 0.051178930063189854\n","Training loss per 100 training steps: 0.05061735422118409\n","Training loss per 100 training steps: 0.05121539345596385\n","Training loss per 100 training steps: 0.0525305634076352\n","Training loss epoch: 0.05299868014099335\n","Training accuracy epoch: 0.983371834314397\n","Validating model...\n","Validation Loss: 0.15127454683571667\n","Validation Accuracy: 0.9569226810380703\n","Training epoch: 4\n","Training loss per 100 training steps: 0.015400447882711887\n","Training loss per 100 training steps: 0.029298167482092238\n","Training loss per 100 training steps: 0.029564033403751713\n","Training loss per 100 training steps: 0.030081875986988933\n","Training loss per 100 training steps: 0.031024044649292277\n","Training loss per 100 training steps: 0.03228780058767468\n","Training loss epoch: 0.03186376960371148\n","Training accuracy epoch: 0.9903101557072657\n","Validating model...\n","Validation Loss: 0.1718852334419967\n","Validation Accuracy: 0.9585787585555875\n","Training epoch: 5\n","Training loss per 100 training steps: 0.018591562286019325\n","Training loss per 100 training steps: 0.016541353645872805\n","Training loss per 100 training steps: 0.020417270152736918\n","Training loss per 100 training steps: 0.0272918861576718\n","Training loss per 100 training steps: 0.02787399738318661\n","Training loss per 100 training steps: 0.027296546482510804\n","Training loss epoch: 0.02733741377346113\n","Training accuracy epoch: 0.9919408532088909\n","Validating model...\n","Validation Loss: 0.17906786997306656\n","Validation Accuracy: 0.9578990775544605\n","Training epoch: 6\n","Training loss per 100 training steps: 0.008293933235108852\n","Training loss per 100 training steps: 0.015590945884324886\n","Training loss per 100 training steps: 0.015351157049174695\n","Training loss per 100 training steps: 0.016295933955100726\n","Training loss per 100 training steps: 0.01808845100785313\n","Training loss per 100 training steps: 0.018910943352333374\n","Training loss epoch: 0.019716931275234873\n","Training accuracy epoch: 0.9940357878734344\n","Validating model...\n","Validation Loss: 0.2065533809605744\n","Validation Accuracy: 0.9533611467605559\n","Training epoch: 7\n","Training loss per 100 training steps: 0.014629839919507504\n","Training loss per 100 training steps: 0.015031404440558635\n","Training loss per 100 training steps: 0.014166594409402367\n","Training loss per 100 training steps: 0.01658583070813644\n","Training loss per 100 training steps: 0.017713529448561426\n","Training loss per 100 training steps: 0.01913174721988628\n","Training loss epoch: 0.018896298735588297\n","Training accuracy epoch: 0.9943258857512969\n","Validating model...\n","Validation Loss: 0.19585983211464889\n","Validation Accuracy: 0.9585369416478349\n","Training epoch: 8\n","Training loss per 100 training steps: 0.0820741131901741\n","Training loss per 100 training steps: 0.01544244033180749\n","Training loss per 100 training steps: 0.01430539213600499\n","Training loss per 100 training steps: 0.014669761730282973\n","Training loss per 100 training steps: 0.014803609117866143\n","Training loss per 100 training steps: 0.01504786236265334\n","Training loss epoch: 0.015218432346223453\n","Training accuracy epoch: 0.9953755794517662\n","Validating model...\n","Validation Loss: 0.1922505365249205\n","Validation Accuracy: 0.9613828585986076\n","Training epoch: 9\n","Patience limit reached\n","Training duration: 49.73387446666663 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.17038403647085135\n","Validation Accuracy: 0.9521065054144621\n","Validation duration: 3.126015499999994 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 82.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.87      0.83     12546\n","        test       0.79      0.84      0.82      9012\n","   treatment       0.84      0.82      0.83      9297\n","\n","   micro avg       0.81      0.85      0.83     30855\n","   macro avg       0.81      0.84      0.83     30855\n","weighted avg       0.81      0.85      0.83     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 18200\n","Points in y_train after augmentation: 18200\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.044574499130249\n","Training loss per 100 training steps: 0.39886827626735855\n","Training loss per 100 training steps: 0.29624117002706624\n","Training loss per 100 training steps: 0.2544516506558439\n","Training loss per 100 training steps: 0.22795622235633192\n","Training loss per 100 training steps: 0.20995550973716373\n","Training loss epoch: 0.20097473698466858\n","Training accuracy epoch: 0.9367525322344943\n","Validating model...\n","Validation Loss: 0.14792909509466065\n","Validation Accuracy: 0.9514822435093226\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09636063873767853\n","Training loss per 100 training steps: 0.08146102218381544\n","Training loss per 100 training steps: 0.08202744665930965\n","Training loss per 100 training steps: 0.08036116759394886\n","Training loss per 100 training steps: 0.07966100322570364\n","Training loss per 100 training steps: 0.08017971002851834\n","Training loss epoch: 0.07988502488754728\n","Training accuracy epoch: 0.9747471121715824\n","Validating model...\n","Validation Loss: 0.15540992122675693\n","Validation Accuracy: 0.9552947146336158\n","Training epoch: 3\n","Training loss per 100 training steps: 0.08451428264379501\n","Training loss per 100 training steps: 0.047481808931299364\n","Training loss per 100 training steps: 0.048631321425684056\n","Training loss per 100 training steps: 0.04761776923700128\n","Training loss per 100 training steps: 0.04691262018374467\n","Training loss per 100 training steps: 0.0475550745000427\n","Training loss epoch: 0.04815325711204004\n","Training accuracy epoch: 0.9855143438834073\n","Validating model...\n","Validation Loss: 0.1741197943058494\n","Validation Accuracy: 0.9503789931174585\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03445597365498543\n","Training loss per 100 training steps: 0.029554424735966443\n","Training loss per 100 training steps: 0.029970749146976873\n","Training loss per 100 training steps: 0.030935542378729315\n","Training loss per 100 training steps: 0.030615996394626928\n","Training loss per 100 training steps: 0.03172071763925894\n","Training loss epoch: 0.031568843010004434\n","Training accuracy epoch: 0.9904008177516279\n","Validating model...\n","Validation Loss: 0.18628369364887476\n","Validation Accuracy: 0.9551965038945498\n","Training epoch: 5\n","Training loss per 100 training steps: 0.023923780769109726\n","Training loss per 100 training steps: 0.02367619798278971\n","Training loss per 100 training steps: 0.026659886537476522\n","Training loss per 100 training steps: 0.028140308715997146\n","Training loss per 100 training steps: 0.026769616290697004\n","Training loss per 100 training steps: 0.026881409851051568\n","Training loss epoch: 0.027480725598356216\n","Training accuracy epoch: 0.9915998133604387\n","Validating model...\n","Validation Loss: 0.19800083029579807\n","Validation Accuracy: 0.9531714078559521\n","Training epoch: 6\n","Training loss per 100 training steps: 0.011795951053500175\n","Training loss per 100 training steps: 0.021531477150977543\n","Training loss per 100 training steps: 0.021659394246595565\n","Training loss per 100 training steps: 0.021630914775079172\n","Training loss per 100 training steps: 0.02204626021347011\n","Training loss per 100 training steps: 0.02154838385877428\n","Training loss epoch: 0.022486225943599118\n","Training accuracy epoch: 0.9933694516230129\n","Validating model...\n","Validation Loss: 0.21277390067259988\n","Validation Accuracy: 0.9520865248238862\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 37.30562874999996 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1658160614843601\n","Validation Accuracy: 0.9492613448566802\n","Validation duration: 3.126582033333398 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 82.3%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.79      0.81     12546\n","        test       0.81      0.86      0.83      9012\n","   treatment       0.79      0.86      0.83      9297\n","\n","   micro avg       0.81      0.83      0.82     30855\n","   macro avg       0.81      0.84      0.82     30855\n","weighted avg       0.81      0.83      0.82     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 18200\n","Points in y_train after augmentation: 18200\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.3024280071258545\n","Training loss per 100 training steps: 0.4099275426256775\n","Training loss per 100 training steps: 0.30868975152794403\n","Training loss per 100 training steps: 0.26302564849588167\n","Training loss per 100 training steps: 0.23785658677728694\n","Training loss per 100 training steps: 0.21855371796382878\n","Training loss epoch: 0.20877946841879133\n","Training accuracy epoch: 0.9338673752929516\n","Validating model...\n","Validation Loss: 0.15813945437019522\n","Validation Accuracy: 0.9509390614530387\n","Training epoch: 2\n","Training loss per 100 training steps: 0.21609221398830414\n","Training loss per 100 training steps: 0.09594784315564844\n","Training loss per 100 training steps: 0.09400978982819254\n","Training loss per 100 training steps: 0.08849282223310483\n","Training loss per 100 training steps: 0.08953110231295637\n","Training loss per 100 training steps: 0.08774401764283161\n","Training loss epoch: 0.08625872559380604\n","Training accuracy epoch: 0.9728186862869135\n","Validating model...\n","Validation Loss: 0.17463956482998735\n","Validation Accuracy: 0.950808799268098\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03455452620983124\n","Training loss per 100 training steps: 0.04180817017654455\n","Training loss per 100 training steps: 0.04390646736322907\n","Training loss per 100 training steps: 0.043967605464816394\n","Training loss per 100 training steps: 0.044781207902463815\n","Training loss per 100 training steps: 0.04583245463959293\n","Training loss epoch: 0.04699733490631744\n","Training accuracy epoch: 0.9854205697235614\n","Validating model...\n","Validation Loss: 0.16733887939193806\n","Validation Accuracy: 0.9560425054296237\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03887683153152466\n","Training loss per 100 training steps: 0.035153279770257895\n","Training loss per 100 training steps: 0.029800272602889113\n","Training loss per 100 training steps: 0.030419876825673958\n","Training loss per 100 training steps: 0.03076341091637776\n","Training loss per 100 training steps: 0.0313100065836616\n","Training loss epoch: 0.0327768774176514\n","Training accuracy epoch: 0.9895410472940364\n","Validating model...\n","Validation Loss: 0.18214145196335657\n","Validation Accuracy: 0.9552589228579699\n","Training epoch: 5\n","Training loss per 100 training steps: 0.019366241991519928\n","Training loss per 100 training steps: 0.02156190781987798\n","Training loss per 100 training steps: 0.02280330971874927\n","Training loss per 100 training steps: 0.02462001260295758\n","Training loss per 100 training steps: 0.026499285441916202\n","Training loss per 100 training steps: 0.027780934816696672\n","Training loss epoch: 0.028795923723230345\n","Training accuracy epoch: 0.9913208733341472\n","Validating model...\n","Validation Loss: 0.18569973899753062\n","Validation Accuracy: 0.956262042467074\n","Training epoch: 6\n","Training loss per 100 training steps: 0.032663535326719284\n","Training loss per 100 training steps: 0.02943108566704732\n","Training loss per 100 training steps: 0.029809790779257297\n","Training loss per 100 training steps: 0.02689105040313323\n","Training loss per 100 training steps: 0.025033473512715197\n","Training loss per 100 training steps: 0.025153782724903827\n","Training loss epoch: 0.024686971801985383\n","Training accuracy epoch: 0.992639803613745\n","Validating model...\n","Validation Loss: 0.19860513295446122\n","Validation Accuracy: 0.9580603872823181\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 37.33693201666659 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16578260725536556\n","Validation Accuracy: 0.9497437279127584\n","Validation duration: 3.125985049999872 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 82.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.77      0.83      0.80     12546\n","        test       0.83      0.86      0.84      9012\n","   treatment       0.83      0.82      0.83      9297\n","\n","   micro avg       0.81      0.84      0.82     30855\n","   macro avg       0.81      0.84      0.82     30855\n","weighted avg       0.81      0.84      0.82     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n","Points in X_train after augmentation: 18200\n","Points in y_train after augmentation: 18200\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.967677354812622\n","Training loss per 100 training steps: 0.42327419203696864\n","Training loss per 100 training steps: 0.3111250434645373\n","Training loss per 100 training steps: 0.26705562120359205\n","Training loss per 100 training steps: 0.23766742030767135\n","Training loss per 100 training steps: 0.2182080940438245\n","Training loss epoch: 0.20854786215824694\n","Training accuracy epoch: 0.9348209172132745\n","Validating model...\n","Validation Loss: 0.14682407084513793\n","Validation Accuracy: 0.9526958039138554\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05313335731625557\n","Training loss per 100 training steps: 0.08554203241215189\n","Training loss per 100 training steps: 0.08128356387773852\n","Training loss per 100 training steps: 0.08461392287820875\n","Training loss per 100 training steps: 0.08489364758598389\n","Training loss per 100 training steps: 0.0844535957185362\n","Training loss epoch: 0.0839769451556521\n","Training accuracy epoch: 0.9734757216490729\n","Validating model...\n","Validation Loss: 0.14656237846651635\n","Validation Accuracy: 0.9532726136125883\n","Training epoch: 3\n","Training loss per 100 training steps: 0.055821049958467484\n","Training loss per 100 training steps: 0.04105179827881626\n","Training loss per 100 training steps: 0.0435424576298014\n","Training loss per 100 training steps: 0.044368195040399\n","Training loss per 100 training steps: 0.04582182085780227\n","Training loss per 100 training steps: 0.04628625211116306\n","Training loss epoch: 0.04716949570991151\n","Training accuracy epoch: 0.9850482816557298\n","Validating model...\n","Validation Loss: 0.16831716241968142\n","Validation Accuracy: 0.9556063426478325\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01360024232417345\n","Training loss per 100 training steps: 0.027380169997462026\n","Training loss per 100 training steps: 0.03322881878995387\n","Training loss per 100 training steps: 0.032412004578963816\n","Training loss per 100 training steps: 0.03362412353341196\n","Training loss per 100 training steps: 0.035343744369602935\n","Training loss epoch: 0.0356883246321493\n","Training accuracy epoch: 0.9889704183712853\n","Validating model...\n","Validation Loss: 0.1630089230980579\n","Validation Accuracy: 0.959558886491955\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0053948271088302135\n","Training loss per 100 training steps: 0.022370421012407077\n","Training loss per 100 training steps: 0.025784018785989293\n","Training loss per 100 training steps: 0.025696115299867484\n","Training loss per 100 training steps: 0.026597398731269945\n","Training loss per 100 training steps: 0.02680098451650748\n","Training loss epoch: 0.026632808320108073\n","Training accuracy epoch: 0.9916904019337235\n","Validating model...\n","Validation Loss: 0.18325035512302215\n","Validation Accuracy: 0.9587241719913593\n","Training epoch: 6\n","Training loss per 100 training steps: 0.002902337582781911\n","Training loss per 100 training steps: 0.017694944278383168\n","Training loss per 100 training steps: 0.018477046804326536\n","Training loss per 100 training steps: 0.019796953970903648\n","Training loss per 100 training steps: 0.020031080718275317\n","Training loss per 100 training steps: 0.020665300109013802\n","Training loss epoch: 0.021124509786299032\n","Training accuracy epoch: 0.9934146714341505\n","Validating model...\n","Validation Loss: 0.19179134390183858\n","Validation Accuracy: 0.9581615672350005\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0033245356753468513\n","Training loss per 100 training steps: 0.015707301950464856\n","Training loss per 100 training steps: 0.022321360050938068\n","Training loss per 100 training steps: 0.021309117513629097\n","Training loss per 100 training steps: 0.020736482463898417\n","Training loss per 100 training steps: 0.02062082730907298\n","Training loss epoch: 0.020702308630364128\n","Training accuracy epoch: 0.993916604268266\n","Validating model...\n","Validation Loss: 0.2083558254911528\n","Validation Accuracy: 0.9566666882639763\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 43.546996116666804 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15625728957712892\n","Validation Accuracy: 0.9538046451662391\n","Validation duration: 3.123263816666683 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 84.1%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.85      0.84     12546\n","        test       0.82      0.87      0.84      9012\n","   treatment       0.83      0.84      0.84      9297\n","\n","   micro avg       0.83      0.86      0.84     30855\n","   macro avg       0.83      0.86      0.84     30855\n","weighted avg       0.83      0.86      0.84     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n","Points in X_train after augmentation: 18200\n","Points in y_train after augmentation: 18200\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.2554423809051514\n","Training loss per 100 training steps: 0.4102836212161744\n","Training loss per 100 training steps: 0.30774427331353893\n","Training loss per 100 training steps: 0.2598595345807432\n","Training loss per 100 training steps: 0.23383393306796094\n","Training loss per 100 training steps: 0.21392593032377447\n","Training loss epoch: 0.2037367642560879\n","Training accuracy epoch: 0.9361932129397711\n","Validating model...\n","Validation Loss: 0.14501418961913554\n","Validation Accuracy: 0.9525859655616626\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07521378248929977\n","Training loss per 100 training steps: 0.0862776603697255\n","Training loss per 100 training steps: 0.08416759263983561\n","Training loss per 100 training steps: 0.08502596910065195\n","Training loss per 100 training steps: 0.08302872319777782\n","Training loss per 100 training steps: 0.08129728102718226\n","Training loss epoch: 0.08110436609322581\n","Training accuracy epoch: 0.9744870541405635\n","Validating model...\n","Validation Loss: 0.1673155687991288\n","Validation Accuracy: 0.9493988781086014\n","Training epoch: 3\n","Training loss per 100 training steps: 0.1167927086353302\n","Training loss per 100 training steps: 0.05540257619491013\n","Training loss per 100 training steps: 0.05397262013475619\n","Training loss per 100 training steps: 0.05479321486403256\n","Training loss per 100 training steps: 0.05257689488814805\n","Training loss per 100 training steps: 0.052071467706535805\n","Training loss epoch: 0.05192177343388499\n","Training accuracy epoch: 0.9838111238885145\n","Validating model...\n","Validation Loss: 0.1625007547365574\n","Validation Accuracy: 0.9555028761474132\n","Training epoch: 4\n","Training loss per 100 training steps: 0.013806142844259739\n","Training loss per 100 training steps: 0.024369934871147324\n","Training loss per 100 training steps: 0.028908231973286663\n","Training loss per 100 training steps: 0.029392615225215586\n","Training loss per 100 training steps: 0.03150949730831628\n","Training loss per 100 training steps: 0.03183948388369661\n","Training loss epoch: 0.032679462249297485\n","Training accuracy epoch: 0.989792018599839\n","Validating model...\n","Validation Loss: 0.18429516826744202\n","Validation Accuracy: 0.9554406211339396\n","Training epoch: 5\n","Training loss per 100 training steps: 0.07392760366201401\n","Training loss per 100 training steps: 0.02842032280289522\n","Training loss per 100 training steps: 0.02489724478380875\n","Training loss per 100 training steps: 0.026119010242172502\n","Training loss per 100 training steps: 0.027389917258774755\n","Training loss per 100 training steps: 0.02786070809298996\n","Training loss epoch: 0.02906161603932752\n","Training accuracy epoch: 0.9907967148852809\n","Validating model...\n","Validation Loss: 0.18645076613341058\n","Validation Accuracy: 0.9584619257310386\n","Training epoch: 6\n","Training loss per 100 training steps: 0.015502488240599632\n","Training loss per 100 training steps: 0.018335300039541494\n","Training loss per 100 training steps: 0.019612051036025847\n","Training loss per 100 training steps: 0.018556464935515226\n","Training loss per 100 training steps: 0.018875483003244074\n","Training loss per 100 training steps: 0.019090898426415998\n","Training loss epoch: 0.01966157879200412\n","Training accuracy epoch: 0.9940181266003225\n","Validating model...\n","Validation Loss: 0.19655041717440375\n","Validation Accuracy: 0.9577211581915327\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 37.34097273333318 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.14843185406385195\n","Validation Accuracy: 0.9527894008269473\n","Validation duration: 3.1228045999998963 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 83.8%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.83      0.83     12546\n","        test       0.83      0.87      0.85      9012\n","   treatment       0.81      0.86      0.83      9297\n","\n","   micro avg       0.82      0.85      0.84     30855\n","   macro avg       0.82      0.85      0.84     30855\n","weighted avg       0.83      0.85      0.84     30855\n","\n","!!!!!! Starting model number 7 !!!!!!\n","Points in X_train after augmentation: 18200\n","Points in y_train after augmentation: 18200\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.2361323833465576\n","Training loss per 100 training steps: 0.4125823821171676\n","Training loss per 100 training steps: 0.30807640952109105\n","Training loss per 100 training steps: 0.26624194767784043\n","Training loss per 100 training steps: 0.2385428286856621\n","Training loss per 100 training steps: 0.219690135247009\n","Training loss epoch: 0.21003309021554953\n","Training accuracy epoch: 0.9338114666814435\n","Validating model...\n","Validation Loss: 0.149647946251774\n","Validation Accuracy: 0.9538960171396121\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05517477169632912\n","Training loss per 100 training steps: 0.08256636877166162\n","Training loss per 100 training steps: 0.08055835004562317\n","Training loss per 100 training steps: 0.07854431604601418\n","Training loss per 100 training steps: 0.0792828505496469\n","Training loss per 100 training steps: 0.07944434683048678\n","Training loss epoch: 0.07920823292233875\n","Training accuracy epoch: 0.9752684888530412\n","Validating model...\n","Validation Loss: 0.14917111339942588\n","Validation Accuracy: 0.9535400968222995\n","Training epoch: 3\n","Training loss per 100 training steps: 0.10900231450796127\n","Training loss per 100 training steps: 0.05127121374416765\n","Training loss per 100 training steps: 0.0508647989528022\n","Training loss per 100 training steps: 0.0504672331286848\n","Training loss per 100 training steps: 0.05145194963958495\n","Training loss per 100 training steps: 0.05057243907177252\n","Training loss epoch: 0.05111598155849167\n","Training accuracy epoch: 0.9842986634584759\n","Validating model...\n","Validation Loss: 0.16047991574862852\n","Validation Accuracy: 0.9595676526759589\n","Training epoch: 4\n","Training loss per 100 training steps: 0.011057347059249878\n","Training loss per 100 training steps: 0.02301264861033824\n","Training loss per 100 training steps: 0.02765963418468305\n","Training loss per 100 training steps: 0.030034911845682306\n","Training loss per 100 training steps: 0.03191075566444811\n","Training loss per 100 training steps: 0.032607975176897105\n","Training loss epoch: 0.03325378524639966\n","Training accuracy epoch: 0.989469880400304\n","Validating model...\n","Validation Loss: 0.18569720300615994\n","Validation Accuracy: 0.9562765280211993\n","Training epoch: 5\n","Training loss per 100 training steps: 0.03450148180127144\n","Training loss per 100 training steps: 0.01924583173038825\n","Training loss per 100 training steps: 0.022461827978751257\n","Training loss per 100 training steps: 0.022222971754454916\n","Training loss per 100 training steps: 0.022670967037849907\n","Training loss per 100 training steps: 0.023673851573942025\n","Training loss epoch: 0.024584751142645567\n","Training accuracy epoch: 0.9923111666323101\n","Validating model...\n","Validation Loss: 0.19885071382446626\n","Validation Accuracy: 0.9554486089251305\n","Training epoch: 6\n","Training loss per 100 training steps: 0.03881017118692398\n","Training loss per 100 training steps: 0.021591453675853807\n","Training loss per 100 training steps: 0.023253040761798065\n","Training loss per 100 training steps: 0.025132041170216935\n","Training loss per 100 training steps: 0.02442163103515575\n","Training loss per 100 training steps: 0.024983667565914924\n","Training loss epoch: 0.02495711786436778\n","Training accuracy epoch: 0.9922850965192705\n","Validating model...\n","Validation Loss: 0.1948607883645923\n","Validation Accuracy: 0.9578422055667946\n","Training epoch: 7\n","Training loss per 100 training steps: 0.014335663057863712\n","Training loss per 100 training steps: 0.01938738740143818\n","Training loss per 100 training steps: 0.01954334461771934\n","Training loss per 100 training steps: 0.020142520649089442\n","Training loss per 100 training steps: 0.020016022283029962\n","Training loss per 100 training steps: 0.019605302366025156\n","Training loss epoch: 0.019513190554396407\n","Training accuracy epoch: 0.9937172431325457\n","Validating model...\n","Validation Loss: 0.21210515217299197\n","Validation Accuracy: 0.9586597537764905\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 43.50083728333314 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15781090728921332\n","Validation Accuracy: 0.9532353847051176\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation duration: 3.1286190000001324 minutes\n","F1-score (test): 83.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.85      0.84     12546\n","        test       0.78      0.88      0.83      9012\n","   treatment       0.84      0.83      0.83      9297\n","\n","   micro avg       0.82      0.85      0.84     30855\n","   macro avg       0.82      0.85      0.83     30855\n","weighted avg       0.82      0.85      0.84     30855\n","\n","!!!!!! Starting model number 8 !!!!!!\n","Points in X_train after augmentation: 18200\n","Points in y_train after augmentation: 18200\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.168778896331787\n","Training loss per 100 training steps: 0.42428327698518736\n","Training loss per 100 training steps: 0.3107874467783603\n","Training loss per 100 training steps: 0.2653791597886537\n","Training loss per 100 training steps: 0.23755048126205244\n","Training loss per 100 training steps: 0.21953252731207126\n","Training loss epoch: 0.20840548175290516\n","Training accuracy epoch: 0.9334552097971675\n","Validating model...\n","Validation Loss: 0.1499898678490094\n","Validation Accuracy: 0.9536020779777108\n","Training epoch: 2\n","Training loss per 100 training steps: 0.08456704020500183\n","Training loss per 100 training steps: 0.08625769475013903\n","Training loss per 100 training steps: 0.08264675457957224\n","Training loss per 100 training steps: 0.08037448682485031\n","Training loss per 100 training steps: 0.07957633695172661\n","Training loss per 100 training steps: 0.07960340489508833\n","Training loss epoch: 0.07900242430038475\n","Training accuracy epoch: 0.9747489384912352\n","Validating model...\n","Validation Loss: 0.1502183372179022\n","Validation Accuracy: 0.9573075867291045\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03878820315003395\n","Training loss per 100 training steps: 0.04757697385560611\n","Training loss per 100 training steps: 0.04862153108477296\n","Training loss per 100 training steps: 0.04895758520397187\n","Training loss per 100 training steps: 0.049379433253245834\n","Training loss per 100 training steps: 0.049376901372999486\n","Training loss epoch: 0.04936774262932566\n","Training accuracy epoch: 0.984309143475615\n","Validating model...\n","Validation Loss: 0.1561196719344657\n","Validation Accuracy: 0.956666437693808\n","Training epoch: 4\n","Training loss per 100 training steps: 0.017041172832250595\n","Training loss per 100 training steps: 0.02683864960257923\n","Training loss per 100 training steps: 0.029093982828479834\n","Training loss per 100 training steps: 0.02994322674109158\n","Training loss per 100 training steps: 0.0317334310494786\n","Training loss per 100 training steps: 0.03316879389921906\n","Training loss epoch: 0.0335347028884968\n","Training accuracy epoch: 0.9895379209247179\n","Validating model...\n","Validation Loss: 0.16667816135427588\n","Validation Accuracy: 0.9590400986806489\n","Training epoch: 5\n","Training loss per 100 training steps: 0.01462909858673811\n","Training loss per 100 training steps: 0.027523088211880646\n","Training loss per 100 training steps: 0.028624437160359055\n","Training loss per 100 training steps: 0.02956703541749327\n","Training loss per 100 training steps: 0.029165049362230924\n","Training loss per 100 training steps: 0.029461328793937962\n","Training loss epoch: 0.029989492820873726\n","Training accuracy epoch: 0.9905867166037892\n","Validating model...\n","Validation Loss: 0.1787800810469145\n","Validation Accuracy: 0.9584630929550936\n","Training epoch: 6\n","Training loss per 100 training steps: 0.012678301893174648\n","Training loss per 100 training steps: 0.01797547723779842\n","Training loss per 100 training steps: 0.019006746207173932\n","Training loss per 100 training steps: 0.024013934636866036\n","Training loss per 100 training steps: 0.024486738489940763\n","Training loss per 100 training steps: 0.024148229123632278\n","Training loss epoch: 0.023995390374447517\n","Training accuracy epoch: 0.9924819951788427\n","Validating model...\n","Validation Loss: 0.18745858484709804\n","Validation Accuracy: 0.9594894572307041\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 37.28585689999988 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15876608872915515\n","Validation Accuracy: 0.9515685433846153\n","Validation duration: 3.113810199999959 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 82.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.77      0.87      0.82     12546\n","        test       0.81      0.86      0.84      9012\n","   treatment       0.84      0.81      0.82      9297\n","\n","   micro avg       0.80      0.85      0.83     30855\n","   macro avg       0.81      0.85      0.83     30855\n","weighted avg       0.80      0.85      0.83     30855\n","\n","!!!!!! Starting model number 9 !!!!!!\n","Points in X_train after augmentation: 18200\n","Points in y_train after augmentation: 18200\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8575904369354248\n","Training loss per 100 training steps: 0.4062326366063392\n","Training loss per 100 training steps: 0.30056607146835446\n","Training loss per 100 training steps: 0.2591134683782872\n","Training loss per 100 training steps: 0.23314368097747948\n","Training loss per 100 training steps: 0.21494823152165926\n","Training loss epoch: 0.20523913636777438\n","Training accuracy epoch: 0.9353692534579208\n","Validating model...\n","Validation Loss: 0.14440842156673406\n","Validation Accuracy: 0.9543173397647093\n","Training epoch: 2\n","Training loss per 100 training steps: 0.08822815120220184\n","Training loss per 100 training steps: 0.08768789308827997\n","Stopping epoch...\n","Training loss epoch: 0.08768789308827997\n","Training accuracy epoch: 0.9624194659940956\n","Validating model...\n","Validation Loss: 0.14080955218765642\n","Validation Accuracy: 0.9551634858276276\n","Training epoch: 3\n","Training loss per 100 training steps: 0.019916057586669922\n","Training loss per 100 training steps: 0.07452861625369232\n","Training loss per 100 training steps: 0.07513955091844447\n","Training loss per 100 training steps: 0.07392482463567458\n","Training loss per 100 training steps: 0.07299918844654896\n","Training loss per 100 training steps: 0.07304555955091993\n","Training loss epoch: 0.07211486755515104\n","Training accuracy epoch: 0.9774942407210656\n","Validating model...\n","Validation Loss: 0.14185136871097923\n","Validation Accuracy: 0.9581638944656315\n","Training epoch: 4\n","Training loss per 100 training steps: 0.055085740983486176\n","Training loss per 100 training steps: 0.040659261883540763\n","Training loss per 100 training steps: 0.03646990139238926\n","Training loss per 100 training steps: 0.039448961052050396\n","Training loss per 100 training steps: 0.0412812070619719\n","Training loss per 100 training steps: 0.04267698097272317\n","Training loss epoch: 0.043131432645571184\n","Training accuracy epoch: 0.9864865234173203\n","Validating model...\n","Validation Loss: 0.1740684477830088\n","Validation Accuracy: 0.9535081563020172\n","Training epoch: 5\n","Training loss per 100 training steps: 0.020667970180511475\n","Training loss per 100 training steps: 0.02710199967432435\n","Training loss per 100 training steps: 0.029955317096006292\n","Training loss per 100 training steps: 0.030341751473581424\n","Training loss per 100 training steps: 0.03196380608378355\n","Training loss per 100 training steps: 0.0325905170501721\n","Training loss epoch: 0.032174476411321276\n","Training accuracy epoch: 0.9899116093664349\n","Validating model...\n","Validation Loss: 0.2098358923980555\n","Validation Accuracy: 0.9521042128348763\n","Training epoch: 6\n","Training loss per 100 training steps: 0.031984347850084305\n","Training loss per 100 training steps: 0.021854345679241646\n","Training loss per 100 training steps: 0.023025017777001437\n","Training loss per 100 training steps: 0.026737246684036976\n","Training loss per 100 training steps: 0.027766529450360268\n","Training loss per 100 training steps: 0.030706345190121206\n","Training loss epoch: 0.03049455135592189\n","Training accuracy epoch: 0.9904350946568886\n","Validating model...\n","Validation Loss: 0.184307895999934\n","Validation Accuracy: 0.9555763092906485\n","Training epoch: 7\n","Training loss per 100 training steps: 0.09268061816692352\n","Training loss per 100 training steps: 0.02249837200454722\n","Training loss per 100 training steps: 0.018987281109549253\n","Training loss per 100 training steps: 0.01958767451002476\n","Training loss per 100 training steps: 0.020748789825167813\n","Training loss per 100 training steps: 0.020134917036198012\n","Training loss epoch: 0.021283391582912984\n","Training accuracy epoch: 0.9936685285165969\n","Validating model...\n","Validation Loss: 0.18734863727026946\n","Validation Accuracy: 0.9573618574824935\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 38.57937988333336 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15252883490218125\n","Validation Accuracy: 0.9536380426295414\n","Validation duration: 3.1216949833333882 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 84.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.87      0.83     12546\n","        test       0.84      0.89      0.87      9012\n","   treatment       0.83      0.85      0.84      9297\n","\n","   micro avg       0.82      0.87      0.84     30855\n","   macro avg       0.82      0.87      0.84     30855\n","weighted avg       0.82      0.87      0.84     30855\n","\n","!!!!!! Starting model number 10 !!!!!!\n","Points in X_train after augmentation: 18200\n","Points in y_train after augmentation: 18200\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1388132572174072\n","Training loss per 100 training steps: 0.4175968364913865\n","Training loss per 100 training steps: 0.3075119107590979\n","Training loss per 100 training steps: 0.26057116184816803\n","Training loss per 100 training steps: 0.23316620839318433\n","Training loss per 100 training steps: 0.21367049242505531\n","Training loss epoch: 0.20454002241153918\n","Training accuracy epoch: 0.9350471237169169\n","Validating model...\n","Validation Loss: 0.1495039165987597\n","Validation Accuracy: 0.9507301548770813\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07152094691991806\n","Training loss per 100 training steps: 0.09499736040793728\n","Training loss per 100 training steps: 0.08475772721405646\n","Training loss per 100 training steps: 0.0838676079167084\n","Training loss per 100 training steps: 0.0842067401698254\n","Training loss per 100 training steps: 0.08283128253669439\n","Training loss epoch: 0.08261496599874932\n","Training accuracy epoch: 0.9738296483718786\n","Validating model...\n","Validation Loss: 0.1406282126274589\n","Validation Accuracy: 0.958044595145562\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0757920891046524\n","Training loss per 100 training steps: 0.04540872774409628\n","Training loss per 100 training steps: 0.04466488322623037\n","Training loss per 100 training steps: 0.045699558233180115\n","Training loss per 100 training steps: 0.044605932138660494\n","Training loss per 100 training steps: 0.045008382958428794\n","Training loss epoch: 0.04541427478307174\n","Training accuracy epoch: 0.9858265319485828\n","Validating model...\n","Validation Loss: 0.15420812073272544\n","Validation Accuracy: 0.9586558140225352\n","Training epoch: 4\n","Training loss per 100 training steps: 0.04716954752802849\n","Training loss per 100 training steps: 0.028667031418495248\n","Training loss per 100 training steps: 0.03150403800545566\n","Training loss per 100 training steps: 0.031532487809964364\n","Training loss per 100 training steps: 0.031750959660358576\n","Training loss per 100 training steps: 0.031165217491379845\n","Training loss epoch: 0.031396348002777553\n","Training accuracy epoch: 0.9902372474725435\n","Validating model...\n","Validation Loss: 0.17514464405498334\n","Validation Accuracy: 0.9582238908198639\n","Training epoch: 5\n","Training loss per 100 training steps: 0.008681741543114185\n","Training loss per 100 training steps: 0.022588573928719553\n","Training loss per 100 training steps: 0.022673484762442478\n","Training loss per 100 training steps: 0.022689375073217364\n","Training loss per 100 training steps: 0.023142703477162033\n","Training loss per 100 training steps: 0.02456468985889557\n","Training loss epoch: 0.024987371331215827\n","Training accuracy epoch: 0.9920740922435783\n","Validating model...\n","Validation Loss: 0.17912928934221145\n","Validation Accuracy: 0.9585806927613062\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0030959052965044975\n","Training loss per 100 training steps: 0.01888087635633932\n","Training loss per 100 training steps: 0.019128904425983886\n","Training loss per 100 training steps: 0.018420543560415562\n","Training loss per 100 training steps: 0.018867221547472418\n","Training loss per 100 training steps: 0.019365726986459872\n","Training loss epoch: 0.01999227567302736\n","Training accuracy epoch: 0.993765655095558\n","Validating model...\n","Validation Loss: 0.2010801912923404\n","Validation Accuracy: 0.9560110453008939\n","Training epoch: 7\n","Training loss per 100 training steps: 0.006726025138050318\n","Training loss per 100 training steps: 0.016192038496264653\n","Training loss per 100 training steps: 0.019523287149706844\n","Training loss per 100 training steps: 0.01807656286936408\n","Training loss per 100 training steps: 0.01806280558012621\n","Training loss per 100 training steps: 0.018821790109169175\n","Training loss epoch: 0.019156206426822853\n","Training accuracy epoch: 0.9944322862391403\n","Validating model...\n","Validation Loss: 0.1931073756815938\n","Validation Accuracy: 0.9571208880619271\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 43.51201745000023 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.15963813767518364\n","Validation Accuracy: 0.9530949493553379\n","Validation duration: 3.123926049999864 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 83.8%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.87      0.84     12546\n","        test       0.83      0.85      0.84      9012\n","   treatment       0.81      0.85      0.83      9297\n","\n","   micro avg       0.82      0.86      0.84     30855\n","   macro avg       0.82      0.86      0.84     30855\n","weighted avg       0.82      0.86      0.84     30855\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0.75\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"oKNxFPucHn_R"},{"cell_type":"code","execution_count":null,"metadata":{"id":"1tBh5gOBHpN1","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f794176752c147a8978620015ef059df","db1a788a2ed64374b3f0707280cbf94e","8878302fdb034699a5bd4071a04de8be","1cb888d325ef4dc3b022d0e7b234963a","898922645c0b44a7abbc8da8412dfc8b","6f216f0060794c27b2a603a9e7caedb5","bfb1229dab304099bd5505078880f204","e6691a45f7b44d05bd9029381a28db3f","6a1169ca86a74125a8e0badc1838b8e2","3b63def031f54ab6beff9d81c39a3d50","78e1e51f7f1d49539e408765d5661e28"]},"outputId":"0b9b47d8-6ec1-47c0-e7dd-7ee8a8f851af"},"outputs":[{"output_type":"stream","name":"stdout","text":["!!!!!! Augmented Percentage 100% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 20800\n","Points in y_train after augmentation: 20800\n","Device:  cuda\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/422M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f794176752c147a8978620015ef059df"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.246690511703491\n","Training loss per 100 training steps: 0.4194496993602502\n","Training loss per 100 training steps: 0.31579105253910544\n","Training loss per 100 training steps: 0.26508890762553855\n","Training loss per 100 training steps: 0.2332174828011273\n","Training loss per 100 training steps: 0.2163256583605222\n","Training loss per 100 training steps: 0.20480479144440117\n","Training loss epoch: 0.1986109001132158\n","Training accuracy epoch: 0.9363861338464105\n","Validating model...\n","Validation Loss: 0.16333829522036114\n","Validation Accuracy: 0.9512129519272369\n","Training epoch: 2\n","Training loss per 100 training steps: 0.10454727709293365\n","Training loss per 100 training steps: 0.0708835114641945\n","Training loss per 100 training steps: 0.07206431514495493\n","Training loss per 100 training steps: 0.07487719963641955\n","Training loss per 100 training steps: 0.07603956510003963\n","Training loss per 100 training steps: 0.07683626084054956\n","Training loss per 100 training steps: 0.07628637891473518\n","Training loss epoch: 0.07590106478390786\n","Training accuracy epoch: 0.9762731486198621\n","Validating model...\n","Validation Loss: 0.15197425713012744\n","Validation Accuracy: 0.957875656548783\n","Training epoch: 3\n","Training loss per 100 training steps: 0.006396388169378042\n","Training loss per 100 training steps: 0.03938499174661713\n","Training loss per 100 training steps: 0.04080418171708597\n","Training loss per 100 training steps: 0.04290553692657117\n","Training loss per 100 training steps: 0.04623671514307267\n","Training loss per 100 training steps: 0.04560217728974026\n","Training loss per 100 training steps: 0.04673966467837662\n","Training loss epoch: 0.04648232398590503\n","Training accuracy epoch: 0.9857345014395005\n","Validating model...\n","Validation Loss: 0.17222938729546866\n","Validation Accuracy: 0.9558933864566909\n","Training epoch: 4\n","Training loss per 100 training steps: 0.013929596170783043\n","Training loss per 100 training steps: 0.024910868435987447\n","Training loss per 100 training steps: 0.02732165709117066\n","Training loss per 100 training steps: 0.028683099696920115\n","Training loss per 100 training steps: 0.027544423179501235\n","Training loss per 100 training steps: 0.028218227062195896\n","Training loss per 100 training steps: 0.029919147983847337\n","Training loss epoch: 0.030525821671785358\n","Training accuracy epoch: 0.9905308064130505\n","Validating model...\n","Validation Loss: 0.17144150700565283\n","Validation Accuracy: 0.9577022837852028\n","Training epoch: 5\n","Training loss per 100 training steps: 0.02479850873351097\n","Training loss per 100 training steps: 0.020676961912667508\n","Training loss per 100 training steps: 0.02345450162633892\n","Training loss per 100 training steps: 0.023384046014297777\n","Training loss per 100 training steps: 0.02410666882614965\n","Training loss per 100 training steps: 0.02496303458562857\n","Training loss per 100 training steps: 0.025603132961746367\n","Training loss epoch: 0.02565811079935744\n","Training accuracy epoch: 0.9921446023340343\n","Validating model...\n","Validation Loss: 0.19046225373379208\n","Validation Accuracy: 0.9567053465504493\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0030493319500237703\n","Training loss per 100 training steps: 0.0207017182423226\n","Training loss per 100 training steps: 0.018948652944585486\n","Training loss per 100 training steps: 0.019284726852285012\n","Training loss per 100 training steps: 0.01874504657346114\n","Training loss per 100 training steps: 0.019889877489377594\n","Training loss per 100 training steps: 0.020284180383073218\n","Training loss epoch: 0.020732891344411586\n","Training accuracy epoch: 0.9935293281029265\n","Validating model...\n","Validation Loss: 0.2074253799290965\n","Validation Accuracy: 0.955251963578813\n","Training epoch: 7\n","Training loss per 100 training steps: 0.00963470246642828\n","Training loss per 100 training steps: 0.016237470727081937\n","Training loss per 100 training steps: 0.01548532534515791\n","Training loss per 100 training steps: 0.01628096692430001\n","Training loss per 100 training steps: 0.015944949596202317\n","Training loss per 100 training steps: 0.018035794431406415\n","Training loss per 100 training steps: 0.018147166358481723\n","Training loss epoch: 0.018000054770158244\n","Training accuracy epoch: 0.9944897514186332\n","Validating model...\n","Validation Loss: 0.22460614490873096\n","Validation Accuracy: 0.9567884539113877\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 49.4630978 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.17105465776209408\n","Validation Accuracy: 0.9537363351984168\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validation duration: 3.2131300999999968 minutes\n","F1-score (test): 83.9%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.85      0.83     12546\n","        test       0.83      0.89      0.86      9012\n","   treatment       0.82      0.85      0.83      9297\n","\n","   micro avg       0.82      0.86      0.84     30855\n","   macro avg       0.82      0.86      0.84     30855\n","weighted avg       0.82      0.86      0.84     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 20800\n","Points in y_train after augmentation: 20800\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.6878021955490112\n","Training loss per 100 training steps: 0.3866094520481506\n","Training loss per 100 training steps: 0.29012094723496273\n","Training loss per 100 training steps: 0.25232156538141526\n","Training loss per 100 training steps: 0.2288676714826552\n","Training loss per 100 training steps: 0.21125785510860637\n","Training loss per 100 training steps: 0.19874656433162097\n","Training loss epoch: 0.19198925684564389\n","Training accuracy epoch: 0.9392692312854487\n","Validating model...\n","Validation Loss: 0.1407605680552396\n","Validation Accuracy: 0.9553195311436251\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05614791065454483\n","Training loss per 100 training steps: 0.07552655230248624\n","Training loss per 100 training steps: 0.07400009596016054\n","Training loss per 100 training steps: 0.07568057621071159\n","Training loss per 100 training steps: 0.07509175670261209\n","Training loss per 100 training steps: 0.07594688033904441\n","Training loss per 100 training steps: 0.07696054263905112\n","Training loss epoch: 0.07749762397689315\n","Training accuracy epoch: 0.9753808917894405\n","Validating model...\n","Validation Loss: 0.1507287708824718\n","Validation Accuracy: 0.9533971672986931\n","Training epoch: 3\n","Training loss per 100 training steps: 0.029699718579649925\n","Training loss per 100 training steps: 0.03865282798628553\n","Training loss per 100 training steps: 0.03979816190221935\n","Training loss per 100 training steps: 0.03904978068161793\n","Training loss per 100 training steps: 0.0404408542413794\n","Training loss per 100 training steps: 0.04238206098421278\n","Training loss per 100 training steps: 0.043945864431432974\n","Training loss epoch: 0.04349218415490423\n","Training accuracy epoch: 0.9868464245749515\n","Validating model...\n","Validation Loss: 0.16824919561093504\n","Validation Accuracy: 0.9567587593593728\n","Training epoch: 4\n","Training loss per 100 training steps: 0.05536913871765137\n","Training loss per 100 training steps: 0.03275612872186126\n","Training loss per 100 training steps: 0.032836463393884435\n","Training loss per 100 training steps: 0.034145565742960945\n","Training loss per 100 training steps: 0.03319099341505242\n","Training loss per 100 training steps: 0.03309900856887301\n","Training loss per 100 training steps: 0.03376067869331124\n","Training loss epoch: 0.034169906518207144\n","Training accuracy epoch: 0.9893025217509017\n","Validating model...\n","Validation Loss: 0.16783619070933622\n","Validation Accuracy: 0.9583930714219014\n","Training epoch: 5\n","Training loss per 100 training steps: 0.043556902557611465\n","Training loss per 100 training steps: 0.02166549691764435\n","Training loss per 100 training steps: 0.020368214046225804\n","Training loss per 100 training steps: 0.019608782613232262\n","Training loss per 100 training steps: 0.02006284052917172\n","Training loss per 100 training steps: 0.02126908185450312\n","Training loss per 100 training steps: 0.022126972025063526\n","Training loss epoch: 0.02214088846087599\n","Training accuracy epoch: 0.9933452825928091\n","Validating model...\n","Validation Loss: 0.19009908034720205\n","Validation Accuracy: 0.9573499603882542\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0361444465816021\n","Training loss per 100 training steps: 0.016671357943219972\n","Training loss per 100 training steps: 0.017608800986654297\n","Training loss per 100 training steps: 0.01859124443312779\n","Training loss per 100 training steps: 0.01905536729981194\n","Training loss per 100 training steps: 0.02002509391600333\n","Training loss per 100 training steps: 0.020245810929211648\n","Training loss epoch: 0.020876778317257188\n","Training accuracy epoch: 0.9936167085564274\n","Validating model...\n","Validation Loss: 0.18630315220684973\n","Validation Accuracy: 0.9574028982888632\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 42.34038346666667 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.1562167742393083\n","Validation Accuracy: 0.951025310652994\n","Validation duration: 3.158719283333342 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 82.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.76      0.87      0.81     12546\n","        test       0.85      0.85      0.85      9012\n","   treatment       0.82      0.85      0.83      9297\n","\n","   micro avg       0.80      0.85      0.83     30855\n","   macro avg       0.81      0.85      0.83     30855\n","weighted avg       0.80      0.85      0.83     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 20800\n","Points in y_train after augmentation: 20800\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.364230155944824\n","Training loss per 100 training steps: 0.42347989578058226\n","Training loss per 100 training steps: 0.31353443314261104\n","Training loss per 100 training steps: 0.26782947601719553\n","Training loss per 100 training steps: 0.24069907437276067\n","Training loss per 100 training steps: 0.2213180926061438\n","Training loss per 100 training steps: 0.2051771298769905\n","Training loss epoch: 0.19861068658530712\n","Training accuracy epoch: 0.9375288998695706\n","Validating model...\n","Validation Loss: 0.16263976637515928\n","Validation Accuracy: 0.9485944169543656\n","Training epoch: 2\n","Training loss per 100 training steps: 0.060331568121910095\n","Training loss per 100 training steps: 0.07681039737371526\n","Training loss per 100 training steps: 0.07637069225125942\n","Training loss per 100 training steps: 0.07693184535343979\n","Training loss per 100 training steps: 0.07736808124539486\n","Training loss per 100 training steps: 0.07611334454379752\n","Training loss per 100 training steps: 0.07605889886803616\n","Training loss epoch: 0.07633364824148325\n","Training accuracy epoch: 0.9759083236940062\n","Validating model...\n","Validation Loss: 0.1459227195493393\n","Validation Accuracy: 0.9567843896442103\n","Training epoch: 3\n","Training loss per 100 training steps: 0.020705049857497215\n","Training loss per 100 training steps: 0.042713605535981976\n","Training loss per 100 training steps: 0.04543391659633437\n","Training loss per 100 training steps: 0.044391534662499184\n","Training loss per 100 training steps: 0.04345497930598935\n","Training loss per 100 training steps: 0.04428609049118713\n","Training loss per 100 training steps: 0.04567394662298225\n","Training loss epoch: 0.0470508434322591\n","Training accuracy epoch: 0.9853946910896443\n","Validating model...\n","Validation Loss: 0.17444129583316964\n","Validation Accuracy: 0.9533165036401449\n","Training epoch: 4\n","Training loss per 100 training steps: 0.009072046726942062\n","Training loss per 100 training steps: 0.033716982368859325\n","Training loss per 100 training steps: 0.034209230490751676\n","Training loss per 100 training steps: 0.035848310803592305\n","Training loss per 100 training steps: 0.035276434605504545\n","Training loss per 100 training steps: 0.03437144485857159\n","Training loss per 100 training steps: 0.03344660605355856\n","Training loss epoch: 0.03338903118623421\n","Training accuracy epoch: 0.9897677923940341\n","Validating model...\n","Validation Loss: 0.18065120089895925\n","Validation Accuracy: 0.9566941011579168\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0032960064709186554\n","Training loss per 100 training steps: 0.018113678588651785\n","Training loss per 100 training steps: 0.0228464338822471\n","Training loss per 100 training steps: 0.02300023461654906\n","Training loss per 100 training steps: 0.02281433212027381\n","Training loss per 100 training steps: 0.023114178471217033\n","Training loss per 100 training steps: 0.024229850088898556\n","Training loss epoch: 0.02471541652527566\n","Training accuracy epoch: 0.9927526017425752\n","Validating model...\n","Validation Loss: 0.2034721067780024\n","Validation Accuracy: 0.9522795380619841\n","Training epoch: 6\n","Training loss per 100 training steps: 0.013537376187741756\n","Training loss per 100 training steps: 0.01651159760088079\n","Training loss per 100 training steps: 0.016656351581549468\n","Training loss per 100 training steps: 0.016372627667437595\n","Training loss per 100 training steps: 0.01806488914076736\n","Training loss per 100 training steps: 0.01847372646571347\n","Training loss per 100 training steps: 0.018771731417983332\n","Training loss epoch: 0.018605869891247354\n","Training accuracy epoch: 0.99450114893545\n","Validating model...\n","Validation Loss: 0.209658362793845\n","Validation Accuracy: 0.9550166676460728\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0038029314018785954\n","Training loss per 100 training steps: 0.01640429132327548\n","Training loss per 100 training steps: 0.017409590465324788\n","Training loss per 100 training steps: 0.016522118873953003\n","Training loss per 100 training steps: 0.016059441902608544\n","Training loss per 100 training steps: 0.017032774725506926\n","Training loss per 100 training steps: 0.017610822490861208\n","Training loss epoch: 0.017622888017302524\n","Training accuracy epoch: 0.9948046293437898\n","Validating model...\n","Validation Loss: 0.21444432154394588\n","Validation Accuracy: 0.9558510220672429\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 49.53444975000001 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.1733816670064159\n","Validation Accuracy: 0.9504262668219993\n","Validation duration: 3.144981450000008 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 83.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.86      0.83     12546\n","        test       0.80      0.89      0.84      9012\n","   treatment       0.82      0.85      0.84      9297\n","\n","   micro avg       0.81      0.87      0.83     30855\n","   macro avg       0.81      0.87      0.84     30855\n","weighted avg       0.81      0.87      0.83     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 20800\n","Points in y_train after augmentation: 20800\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.813798427581787\n","Training loss per 100 training steps: 0.38642522759071674\n","Training loss per 100 training steps: 0.2879053359267427\n","Training loss per 100 training steps: 0.24998141594998463\n","Training loss per 100 training steps: 0.22667866707442705\n","Training loss per 100 training steps: 0.20981696598276406\n","Training loss per 100 training steps: 0.196348635073807\n","Training loss epoch: 0.19085810935268036\n","Training accuracy epoch: 0.9396788057919927\n","Validating model...\n","Validation Loss: 0.14247960645657082\n","Validation Accuracy: 0.9543041450874324\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09943190962076187\n","Training loss per 100 training steps: 0.06933276269972177\n","Training loss per 100 training steps: 0.0729181108954571\n","Training loss per 100 training steps: 0.0739475392389956\n","Training loss per 100 training steps: 0.07509343171993879\n","Training loss per 100 training steps: 0.0759396242970478\n","Training loss per 100 training steps: 0.07546320677225087\n","Training loss epoch: 0.0751227363356604\n","Training accuracy epoch: 0.9767671069552988\n","Validating model...\n","Validation Loss: 0.17528273803847177\n","Validation Accuracy: 0.9497943179537984\n","Training epoch: 3\n","Training loss per 100 training steps: 0.017798734828829765\n","Training loss per 100 training steps: 0.03845857612622699\n","Training loss per 100 training steps: 0.03910029957080213\n","Training loss per 100 training steps: 0.04084437189815547\n","Training loss per 100 training steps: 0.04293344990626684\n","Training loss per 100 training steps: 0.04417619139082477\n","Training loss per 100 training steps: 0.04582711945779113\n","Training loss epoch: 0.045256683249205634\n","Training accuracy epoch: 0.9859229519865642\n","Validating model...\n","Validation Loss: 0.16935938645105858\n","Validation Accuracy: 0.9567693717241386\n","Training epoch: 4\n","Training loss per 100 training steps: 0.015943055972456932\n","Training loss per 100 training steps: 0.024281809756550754\n","Training loss per 100 training steps: 0.025495005306435645\n","Training loss per 100 training steps: 0.027820099191972213\n","Training loss per 100 training steps: 0.028693594697205595\n","Training loss per 100 training steps: 0.029240256847168678\n","Training loss per 100 training steps: 0.02982766044069664\n","Training loss epoch: 0.030293858093746868\n","Training accuracy epoch: 0.9906124272952788\n","Validating model...\n","Validation Loss: 0.2001667260736614\n","Validation Accuracy: 0.9525099691530547\n","Training epoch: 5\n","Training loss per 100 training steps: 0.01881733164191246\n","Training loss per 100 training steps: 0.022182134241741702\n","Training loss per 100 training steps: 0.02357041380896386\n","Training loss per 100 training steps: 0.026016752552736142\n","Training loss per 100 training steps: 0.026100155941856343\n","Training loss per 100 training steps: 0.026069878435790346\n","Training loss per 100 training steps: 0.026730260577172153\n","Training loss epoch: 0.026808562555099624\n","Training accuracy epoch: 0.991650102979699\n","Validating model...\n","Validation Loss: 0.18365342334493415\n","Validation Accuracy: 0.9568116138417456\n","Training epoch: 6\n","Training loss per 100 training steps: 0.007026689127087593\n","Training loss per 100 training steps: 0.014709764933052224\n","Training loss per 100 training steps: 0.01682639433782251\n","Training loss per 100 training steps: 0.017470716698748057\n","Training loss per 100 training steps: 0.018531873676910803\n","Training loss per 100 training steps: 0.018687561776060537\n","Training loss per 100 training steps: 0.01927184381118562\n","Training loss epoch: 0.01954976937858961\n","Training accuracy epoch: 0.9940778054877862\n","Validating model...\n","Validation Loss: 0.20541560115268478\n","Validation Accuracy: 0.9567727003277421\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 42.45265988333331 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.15693820046726614\n","Validation Accuracy: 0.9527316486654892\n","Validation duration: 3.1449299833333497 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 83.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.83      0.82     12546\n","        test       0.84      0.85      0.84      9012\n","   treatment       0.80      0.85      0.83      9297\n","\n","   micro avg       0.82      0.84      0.83     30855\n","   macro avg       0.82      0.84      0.83     30855\n","weighted avg       0.82      0.84      0.83     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n","Points in X_train after augmentation: 20800\n","Points in y_train after augmentation: 20800\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9831502437591553\n","Training loss per 100 training steps: 0.41544406049617444\n","Training loss per 100 training steps: 0.3059501030774259\n","Training loss per 100 training steps: 0.2602663300312635\n","Training loss per 100 training steps: 0.23485594293906206\n","Training loss per 100 training steps: 0.21616279471018715\n","Training loss per 100 training steps: 0.20338705654710085\n","Training loss epoch: 0.19721341117356833\n","Training accuracy epoch: 0.937516857226109\n","Validating model...\n","Validation Loss: 0.14153550641441887\n","Validation Accuracy: 0.9536947731054988\n","Training epoch: 2\n","Training loss per 100 training steps: 0.03473052382469177\n","Training loss per 100 training steps: 0.07038535552080905\n","Training loss per 100 training steps: 0.06955447886139154\n","Training loss per 100 training steps: 0.07094331361211069\n","Training loss per 100 training steps: 0.07301674844195458\n","Training loss per 100 training steps: 0.07347635573757712\n","Training loss per 100 training steps: 0.07331797545589816\n","Training loss epoch: 0.07292818202637136\n","Training accuracy epoch: 0.9770686861511033\n","Validating model...\n","Validation Loss: 0.15290002143857154\n","Validation Accuracy: 0.9565970034632053\n","Training epoch: 3\n","Training loss per 100 training steps: 0.027548013255000114\n","Training loss per 100 training steps: 0.041319701488655394\n","Training loss per 100 training steps: 0.04065010589732793\n","Training loss per 100 training steps: 0.039451608718202705\n","Training loss per 100 training steps: 0.040496238689646684\n","Training loss per 100 training steps: 0.04316840118667233\n","Training loss per 100 training steps: 0.043522388729330355\n","Training loss epoch: 0.044170526481018615\n","Training accuracy epoch: 0.9860059702387712\n","Validating model...\n","Validation Loss: 0.16205430229182366\n","Validation Accuracy: 0.9582647977266892\n","Training epoch: 4\n","Training loss per 100 training steps: 0.016338592395186424\n","Training loss per 100 training steps: 0.03597238087348898\n","Training loss per 100 training steps: 0.0316576082728553\n","Training loss per 100 training steps: 0.03070603359716502\n","Training loss per 100 training steps: 0.02986829814981864\n","Training loss per 100 training steps: 0.0301970796066591\n","Training loss per 100 training steps: 0.030853264390594774\n","Training loss epoch: 0.030966868462542502\n","Training accuracy epoch: 0.990620354931202\n","Validating model...\n","Validation Loss: 0.16492028013113644\n","Validation Accuracy: 0.9591141543400047\n","Training epoch: 5\n","Training loss per 100 training steps: 0.02742135338485241\n","Training loss per 100 training steps: 0.018609673074114663\n","Training loss per 100 training steps: 0.023084855533612714\n","Training loss per 100 training steps: 0.023105132416357903\n","Training loss per 100 training steps: 0.02440004781796655\n","Training loss per 100 training steps: 0.025814913747462254\n","Training loss per 100 training steps: 0.02556331192504323\n","Training loss epoch: 0.02580064136033448\n","Training accuracy epoch: 0.9922502668683078\n","Validating model...\n","Validation Loss: 0.19395237891971098\n","Validation Accuracy: 0.956537048229984\n","Training epoch: 6\n","Training loss per 100 training steps: 0.006685966160148382\n","Training loss per 100 training steps: 0.016612926344756074\n","Training loss per 100 training steps: 0.01614204988729751\n","Training loss per 100 training steps: 0.018009285763253387\n","Training loss per 100 training steps: 0.019098018322553964\n","Training loss per 100 training steps: 0.018459669794567105\n","Training loss per 100 training steps: 0.018784668504176413\n","Training loss epoch: 0.019251029219505233\n","Training accuracy epoch: 0.9941131323517921\n","Validating model...\n","Validation Loss: 0.18154339024240707\n","Validation Accuracy: 0.9581641980515045\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 42.47576443333334 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.15321503635452785\n","Validation Accuracy: 0.9519097670974515\n","Validation duration: 3.158648716666691 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 82.9%\n","              precision    recall  f1-score   support\n","\n","     problem       0.78      0.85      0.81     12546\n","        test       0.83      0.85      0.84      9012\n","   treatment       0.84      0.83      0.84      9297\n","\n","   micro avg       0.81      0.84      0.83     30855\n","   macro avg       0.82      0.84      0.83     30855\n","weighted avg       0.81      0.84      0.83     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n","Points in X_train after augmentation: 20800\n","Points in y_train after augmentation: 20800\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8100496530532837\n","Training loss per 100 training steps: 0.40001059898940644\n","Training loss per 100 training steps: 0.30746810638637684\n","Training loss per 100 training steps: 0.26199391957038265\n","Training loss per 100 training steps: 0.2348710499295124\n","Training loss per 100 training steps: 0.2165611283909418\n","Training loss per 100 training steps: 0.20375619097899478\n","Training loss epoch: 0.19766949150424737\n","Training accuracy epoch: 0.9386322523371258\n","Validating model...\n","Validation Loss: 0.139879726574986\n","Validation Accuracy: 0.9549988636696599\n","Training epoch: 2\n","Training loss per 100 training steps: 0.1212838888168335\n","Training loss per 100 training steps: 0.06899070446517798\n","Training loss per 100 training steps: 0.07599887940152293\n","Training loss per 100 training steps: 0.07856983550827319\n","Training loss per 100 training steps: 0.07798493119476925\n","Training loss per 100 training steps: 0.0782301486246734\n","Training loss per 100 training steps: 0.07711324563014403\n","Training loss epoch: 0.0773618445566927\n","Training accuracy epoch: 0.9757518009185072\n","Validating model...\n","Validation Loss: 0.16695635458575442\n","Validation Accuracy: 0.948260286012654\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03774036839604378\n","Training loss per 100 training steps: 0.03874233232737325\n","Training loss per 100 training steps: 0.03985629323059091\n","Training loss per 100 training steps: 0.0402747774674585\n","Training loss per 100 training steps: 0.041166212838816635\n","Training loss per 100 training steps: 0.044281428855027775\n","Training loss per 100 training steps: 0.04563259468111713\n","Training loss epoch: 0.04547578713247696\n","Training accuracy epoch: 0.9857313703505021\n","Validating model...\n","Validation Loss: 0.16407159278048322\n","Validation Accuracy: 0.9566609270030303\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03880568593740463\n","Training loss per 100 training steps: 0.030275072531295147\n","Training loss per 100 training steps: 0.027041778172278284\n","Training loss per 100 training steps: 0.029495371097584325\n","Training loss per 100 training steps: 0.030594619245621426\n","Training loss per 100 training steps: 0.03142069237740774\n","Training loss per 100 training steps: 0.031830974805715825\n","Training loss epoch: 0.03233924658109362\n","Training accuracy epoch: 0.9899091150594557\n","Validating model...\n","Validation Loss: 0.18543106123847378\n","Validation Accuracy: 0.9547810920665061\n","Training epoch: 5\n","Training loss per 100 training steps: 0.006188992410898209\n","Training loss per 100 training steps: 0.021141475603666783\n","Training loss per 100 training steps: 0.021093817850556317\n","Training loss per 100 training steps: 0.021801263338768626\n","Training loss per 100 training steps: 0.023382783869450953\n","Training loss per 100 training steps: 0.024583123211875304\n","Training loss per 100 training steps: 0.024412245576435735\n","Training loss epoch: 0.024894888724486988\n","Training accuracy epoch: 0.9922900924164628\n","Validating model...\n","Validation Loss: 0.20476468120302474\n","Validation Accuracy: 0.9549828370462274\n","Training epoch: 6\n","Training loss per 100 training steps: 0.005411986261606216\n","Training loss per 100 training steps: 0.01962054592769335\n","Training loss per 100 training steps: 0.022337305239072784\n","Training loss per 100 training steps: 0.02269563819432594\n","Training loss per 100 training steps: 0.02195991709131046\n","Training loss per 100 training steps: 0.022333680346636974\n","Training loss per 100 training steps: 0.022717568242748867\n","Training loss epoch: 0.023304890375763464\n","Training accuracy epoch: 0.9927165432044582\n","Validating model...\n","Validation Loss: 0.19625257320290843\n","Validation Accuracy: 0.957439797605133\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 42.49692328333334 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.14679218815527512\n","Validation Accuracy: 0.9532459951165547\n","Validation duration: 3.140960166666628 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 82.9%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.87      0.83     12546\n","        test       0.83      0.85      0.84      9012\n","   treatment       0.80      0.85      0.82      9297\n","\n","   micro avg       0.80      0.86      0.83     30855\n","   macro avg       0.81      0.86      0.83     30855\n","weighted avg       0.80      0.86      0.83     30855\n","\n","!!!!!! Starting model number 7 !!!!!!\n","Points in X_train after augmentation: 20800\n","Points in y_train after augmentation: 20800\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.221381902694702\n","Training loss per 100 training steps: 0.407352312292793\n","Training loss per 100 training steps: 0.3037784777729962\n","Training loss per 100 training steps: 0.2595255792116208\n","Training loss per 100 training steps: 0.23391658045407246\n","Training loss per 100 training steps: 0.21621243036287036\n","Training loss per 100 training steps: 0.2004309918997986\n","Training loss epoch: 0.19474356275338392\n","Training accuracy epoch: 0.9382435554065904\n","Validating model...\n","Validation Loss: 0.14722010865807533\n","Validation Accuracy: 0.9518771379828453\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07844395190477371\n","Training loss per 100 training steps: 0.08332639654157775\n","Training loss per 100 training steps: 0.08080610711201655\n","Training loss per 100 training steps: 0.07805964417532829\n","Training loss per 100 training steps: 0.07497931189807201\n","Training loss per 100 training steps: 0.07402306052292892\n","Training loss per 100 training steps: 0.07596004092461506\n","Training loss epoch: 0.07597419926896691\n","Training accuracy epoch: 0.9767140926839045\n","Validating model...\n","Validation Loss: 0.1633852982966157\n","Validation Accuracy: 0.9514582738460031\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03190033882856369\n","Training loss per 100 training steps: 0.05019775215112189\n","Training loss per 100 training steps: 0.046631153147037495\n","Training loss per 100 training steps: 0.044694877418370735\n","Training loss per 100 training steps: 0.04760603253913119\n","Training loss per 100 training steps: 0.0480084541958279\n","Training loss per 100 training steps: 0.04755208507906986\n","Training loss epoch: 0.04668772961980162\n","Training accuracy epoch: 0.985208954787058\n","Validating model...\n","Validation Loss: 0.18707580187103964\n","Validation Accuracy: 0.9554633107987555\n","Training epoch: 4\n","Training loss per 100 training steps: 0.02910320833325386\n","Training loss per 100 training steps: 0.02766386487366779\n","Training loss per 100 training steps: 0.025921733938423983\n","Training loss per 100 training steps: 0.027278547350625102\n","Training loss per 100 training steps: 0.02911893838765146\n","Training loss per 100 training steps: 0.029407691816867195\n","Training loss per 100 training steps: 0.029971168126919447\n","Training loss epoch: 0.02994313920301815\n","Training accuracy epoch: 0.9906553023532001\n","Validating model...\n","Validation Loss: 0.18550224217598316\n","Validation Accuracy: 0.9553278467602176\n","Training epoch: 5\n","Training loss per 100 training steps: 0.010323149152100086\n","Training loss per 100 training steps: 0.019787664035344404\n","Training loss per 100 training steps: 0.02060175263461893\n","Training loss per 100 training steps: 0.022046831141355947\n","Training loss per 100 training steps: 0.022919915665865428\n","Training loss per 100 training steps: 0.02415203590279709\n","Training loss per 100 training steps: 0.025736588050499744\n","Training loss epoch: 0.026051269487227097\n","Training accuracy epoch: 0.9921227253398714\n","Validating model...\n","Validation Loss: 0.1767643935397848\n","Validation Accuracy: 0.9573581537286119\n","Training epoch: 6\n","Training loss per 100 training steps: 0.018647579476237297\n","Training loss per 100 training steps: 0.015165789616478626\n","Training loss per 100 training steps: 0.0165160985916056\n","Training loss per 100 training steps: 0.017692737178250442\n","Training loss per 100 training steps: 0.018063012603292954\n","Training loss per 100 training steps: 0.019258242323548495\n","Training loss per 100 training steps: 0.019646193573759643\n","Training loss epoch: 0.019549008295154914\n","Training accuracy epoch: 0.9942191098617804\n","Validating model...\n","Validation Loss: 0.20479903527378263\n","Validation Accuracy: 0.958371537545652\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 42.475790983333354 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.1549205295245715\n","Validation Accuracy: 0.9502621224770407\n","Validation duration: 3.1414635499999957 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 81.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.75      0.85      0.80     12546\n","        test       0.84      0.84      0.84      9012\n","   treatment       0.83      0.82      0.83      9297\n","\n","   micro avg       0.80      0.84      0.82     30855\n","   macro avg       0.81      0.84      0.82     30855\n","weighted avg       0.80      0.84      0.82     30855\n","\n","!!!!!! Starting model number 8 !!!!!!\n","Points in X_train after augmentation: 20800\n","Points in y_train after augmentation: 20800\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.169245958328247\n","Training loss per 100 training steps: 0.4143886445182385\n","Training loss per 100 training steps: 0.30974883982791235\n","Training loss per 100 training steps: 0.25972425633193646\n","Training loss per 100 training steps: 0.23406837348294376\n","Training loss per 100 training steps: 0.21730351628003244\n","Training loss per 100 training steps: 0.20373445899906056\n","Training loss epoch: 0.19758864605942597\n","Training accuracy epoch: 0.9379931004754254\n","Validating model...\n","Validation Loss: 0.14516604783666598\n","Validation Accuracy: 0.9542115582173261\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07838542759418488\n","Training loss per 100 training steps: 0.076643017507942\n","Training loss per 100 training steps: 0.08061922863774483\n","Training loss per 100 training steps: 0.07861787877494215\n","Training loss per 100 training steps: 0.07700602613863282\n","Training loss per 100 training steps: 0.07864766300074057\n","Training loss per 100 training steps: 0.07827354887013824\n","Training loss epoch: 0.07750540051036156\n","Training accuracy epoch: 0.9757304836063411\n","Validating model...\n","Validation Loss: 0.15429183248091827\n","Validation Accuracy: 0.9560828413702238\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0742688849568367\n","Training loss per 100 training steps: 0.04288611638055432\n","Training loss per 100 training steps: 0.04463388755760012\n","Training loss per 100 training steps: 0.04439996544463541\n","Training loss per 100 training steps: 0.044957695982913645\n","Training loss per 100 training steps: 0.04447522167648057\n","Training loss per 100 training steps: 0.043698485344865305\n","Training loss epoch: 0.04393982004410086\n","Training accuracy epoch: 0.9859001098725858\n","Validating model...\n","Validation Loss: 0.1778904866402993\n","Validation Accuracy: 0.9525742423907835\n","Training epoch: 4\n","Training loss per 100 training steps: 0.05941572040319443\n","Training loss per 100 training steps: 0.0326838885217278\n","Training loss per 100 training steps: 0.03146188785912775\n","Training loss per 100 training steps: 0.03217200097044701\n","Training loss per 100 training steps: 0.031778419804596746\n","Training loss per 100 training steps: 0.03222497935293469\n","Training loss per 100 training steps: 0.032420656018535575\n","Training loss epoch: 0.03216094102101544\n","Training accuracy epoch: 0.9903147680232791\n","Validating model...\n","Validation Loss: 0.18671277237983494\n","Validation Accuracy: 0.9562185326600807\n","Training epoch: 5\n","Training loss per 100 training steps: 0.040304992347955704\n","Training loss per 100 training steps: 0.02007147137624313\n","Training loss per 100 training steps: 0.02032989946359639\n","Training loss per 100 training steps: 0.0218215553291866\n","Training loss per 100 training steps: 0.023072300507847286\n","Training loss per 100 training steps: 0.024057876452071195\n","Training loss per 100 training steps: 0.025220321287391722\n","Training loss epoch: 0.025427726928252153\n","Training accuracy epoch: 0.9921403514244473\n","Validating model...\n","Validation Loss: 0.18722136319893135\n","Validation Accuracy: 0.9539074621207854\n","Training epoch: 6\n","Training loss per 100 training steps: 0.023752130568027496\n","Training loss per 100 training steps: 0.018444599802744124\n","Training loss per 100 training steps: 0.015361175292336025\n","Training loss per 100 training steps: 0.015954920186941973\n","Training loss per 100 training steps: 0.0164811239735905\n","Training loss per 100 training steps: 0.017294951732874105\n","Training loss per 100 training steps: 0.01734555097295478\n","Training loss epoch: 0.017537807949612703\n","Training accuracy epoch: 0.9947130622208293\n","Validating model...\n","Validation Loss: 0.2122337104534948\n","Validation Accuracy: 0.9579989329624475\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 42.462646983333315 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 1\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"1tBh5gOBHpN1"},{"cell_type":"code","source":["number_of_training_models = 3\n","target_augmented_percentage = 1\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["105feddb6f034fe194158159b05a740f","89d3749f6f3e43928c0a545a99eb07c9","45e2bf54206d462ba2bee09bd760580e","97ab2f9a065e4410b401370a62e3d337","2121861b1bcd454ea310bdc072279747","f5dcfdb74f564920a4de7b9402613dfe","808597727b9446e99aaf8570728ff4fa","30dcd7346c9c46beb27912724d826ece","a74b1376988f43619ccc8e52d0e060a8","118c4e85f70345fb8ca60a169683b738","e35669675ce7403194e16f9cd2e0ec56"]},"id":"_mFCu8SwXhVB","outputId":"6b2b9de2-69af-49fc-e97d-f27cc0c222e4"},"id":"_mFCu8SwXhVB","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["!!!!!! Augmented Percentage 100% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 20800\n","Points in y_train after augmentation: 20800\n","Device:  cuda\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/422M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"105feddb6f034fe194158159b05a740f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.270570993423462\n","Training loss per 100 training steps: 0.411135001495333\n","Training loss per 100 training steps: 0.3121064038419012\n","Training loss per 100 training steps: 0.2700617905966071\n","Training loss per 100 training steps: 0.24370232674100453\n","Training loss per 100 training steps: 0.22314586547647647\n","Training loss per 100 training steps: 0.20771047159310388\n","Training loss epoch: 0.2027204612699839\n","Training accuracy epoch: 0.935552350655726\n","Validating model...\n","Validation Loss: 0.14307405930254366\n","Validation Accuracy: 0.9543852490396686\n","Training epoch: 2\n","Training loss per 100 training steps: 0.043826907873153687\n","Training loss per 100 training steps: 0.07193276030703051\n","Training loss per 100 training steps: 0.07284050934313245\n","Training loss per 100 training steps: 0.07439126142693615\n","Training loss per 100 training steps: 0.0767121072045697\n","Training loss per 100 training steps: 0.07734883664930592\n","Training loss per 100 training steps: 0.07798208571434294\n","Training loss epoch: 0.07845631727733864\n","Training accuracy epoch: 0.9755849779957342\n","Validating model...\n","Validation Loss: 0.1514497251528037\n","Validation Accuracy: 0.9545513953288187\n","Training epoch: 3\n","Training loss per 100 training steps: 0.041067346930503845\n","Training loss per 100 training steps: 0.04567253310694405\n","Training loss per 100 training steps: 0.04443409688891241\n","Training loss per 100 training steps: 0.04551124278969593\n","Training loss per 100 training steps: 0.04503388441936519\n","Training loss per 100 training steps: 0.045109200032015226\n","Training loss per 100 training steps: 0.047355044626176804\n","Training loss epoch: 0.04711231388294926\n","Training accuracy epoch: 0.9852211537363753\n","Validating model...\n","Validation Loss: 0.18413779778139933\n","Validation Accuracy: 0.952575919837129\n","Training epoch: 4\n","Training loss per 100 training steps: 0.04338826611638069\n","Training loss per 100 training steps: 0.03289867454153107\n","Training loss per 100 training steps: 0.03450158538426555\n","Training loss per 100 training steps: 0.0335925416989976\n","Training loss per 100 training steps: 0.03345191631956198\n","Training loss per 100 training steps: 0.03392040589684899\n","Training loss per 100 training steps: 0.03360602212217505\n","Training loss epoch: 0.03384679446928203\n","Training accuracy epoch: 0.9894015746258025\n","Validating model...\n","Validation Loss: 0.19041006060849344\n","Validation Accuracy: 0.9559564394665588\n","Training epoch: 5\n","Training loss per 100 training steps: 0.019201239570975304\n","Training loss per 100 training steps: 0.024333096400945272\n","Training loss per 100 training steps: 0.025439667061379\n","Training loss per 100 training steps: 0.025991265187070914\n","Training loss per 100 training steps: 0.025017417087091917\n","Training loss per 100 training steps: 0.024344748780554246\n","Training loss per 100 training steps: 0.02489641326886002\n","Training loss epoch: 0.025007222877152693\n","Training accuracy epoch: 0.9924028009480753\n","Validating model...\n","Validation Loss: 0.18180414525090488\n","Validation Accuracy: 0.9593104776357987\n","Training epoch: 6\n","Training loss per 100 training steps: 0.007215890567749739\n","Training loss per 100 training steps: 0.023543443827023083\n","Training loss per 100 training steps: 0.02297390051347097\n","Training loss per 100 training steps: 0.020554233960261216\n","Training loss per 100 training steps: 0.021119130234335065\n","Training loss per 100 training steps: 0.021009918517352243\n","Training loss per 100 training steps: 0.020177241260694888\n","Training loss epoch: 0.01991075631347485\n","Training accuracy epoch: 0.994031999940674\n","Validating model...\n","Validation Loss: 0.20452025288401485\n","Validation Accuracy: 0.9585919641322753\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 24.60095421666667 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.1488904560187452\n","Validation Accuracy: 0.9530314892929\n","Validation duration: 2.0373535666666687 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 83.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.86      0.83     12546\n","        test       0.83      0.88      0.85      9012\n","   treatment       0.84      0.82      0.83      9297\n","\n","   micro avg       0.82      0.85      0.84     30855\n","   macro avg       0.82      0.85      0.84     30855\n","weighted avg       0.82      0.85      0.84     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 20800\n","Points in y_train after augmentation: 20800\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.610809326171875\n","Training loss per 100 training steps: 0.3956721700949244\n","Training loss per 100 training steps: 0.2926162675912701\n","Training loss per 100 training steps: 0.2512365532451096\n","Training loss per 100 training steps: 0.22443250101291926\n","Training loss per 100 training steps: 0.20781971627991355\n","Training loss per 100 training steps: 0.19503012229184838\n","Training loss epoch: 0.1901038489290155\n","Training accuracy epoch: 0.9398841888616224\n","Validating model...\n","Validation Loss: 0.14723801888622245\n","Validation Accuracy: 0.9536420944706218\n","Training epoch: 2\n","Training loss per 100 training steps: 0.13443376123905182\n","Training loss per 100 training steps: 0.07524456363171339\n","Training loss per 100 training steps: 0.0725688740555475\n","Training loss per 100 training steps: 0.07571508391045553\n","Training loss per 100 training steps: 0.07860958745512656\n","Training loss per 100 training steps: 0.07646254146891737\n","Training loss per 100 training steps: 0.07610099039779675\n","Training loss epoch: 0.07572122026378146\n","Training accuracy epoch: 0.9765640928275937\n","Validating model...\n","Validation Loss: 0.13860705233626552\n","Validation Accuracy: 0.9561581705696565\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02517881989479065\n","Training loss per 100 training steps: 0.04159997840928338\n","Training loss per 100 training steps: 0.04138375345075419\n","Training loss per 100 training steps: 0.041790453715565494\n","Training loss per 100 training steps: 0.042096769550125444\n","Training loss per 100 training steps: 0.04250409594572478\n","Training loss per 100 training steps: 0.04410952033289862\n","Training loss epoch: 0.04434069954342424\n","Training accuracy epoch: 0.9859007889318909\n","Validating model...\n","Validation Loss: 0.15809264202154688\n","Validation Accuracy: 0.9561032994018076\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01229187287390232\n","Training loss per 100 training steps: 0.02271785579061615\n","Training loss per 100 training steps: 0.024070822034640452\n","Training loss per 100 training steps: 0.025611032678264554\n","Training loss per 100 training steps: 0.027488379327126285\n","Training loss per 100 training steps: 0.028450954912398605\n","Training loss per 100 training steps: 0.028267689824926383\n","Training loss epoch: 0.029118919844040646\n","Training accuracy epoch: 0.9906389355545793\n","Validating model...\n","Validation Loss: 0.18101678866070586\n","Validation Accuracy: 0.9562582337995671\n","Training epoch: 5\n","Training loss per 100 training steps: 0.03541305288672447\n","Training loss per 100 training steps: 0.03824621157623864\n","Training loss per 100 training steps: 0.03437525710607624\n","Training loss per 100 training steps: 0.0320191146481776\n","Training loss per 100 training steps: 0.03161924078095556\n","Training loss per 100 training steps: 0.030196874083889772\n","Training loss per 100 training steps: 0.03182587028072741\n","Training loss epoch: 0.031659580129556934\n","Training accuracy epoch: 0.9902076877258128\n","Validating model...\n","Validation Loss: 0.2069686040366915\n","Validation Accuracy: 0.9552211810670279\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0016403712797909975\n","Training loss per 100 training steps: 0.017570223090455563\n","Training loss per 100 training steps: 0.01874727760505311\n","Training loss per 100 training steps: 0.019050957593854913\n","Training loss per 100 training steps: 0.018517161961186194\n","Training loss per 100 training steps: 0.018297223566646526\n","Training loss per 100 training steps: 0.01806008710546075\n","Training loss epoch: 0.018310438904087418\n","Training accuracy epoch: 0.9944851709082032\n","Validating model...\n","Validation Loss: 0.22019593335397833\n","Validation Accuracy: 0.9536667202586709\n","Training epoch: 7\n","Training loss per 100 training steps: 0.057313717901706696\n","Training loss per 100 training steps: 0.021489974188544595\n","Training loss per 100 training steps: 0.020492566982863367\n","Training loss per 100 training steps: 0.018199628919627567\n","Training loss per 100 training steps: 0.01614277851797595\n","Training loss per 100 training steps: 0.01835229062801622\n","Training loss per 100 training steps: 0.018553683140297487\n","Training loss epoch: 0.019197264519327573\n","Training accuracy epoch: 0.994261327481523\n","Validating model...\n","Validation Loss: 0.21272960018560097\n","Validation Accuracy: 0.9553135735237605\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 28.02727528333333 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.1589276891059449\n","Validation Accuracy: 0.952717713478013\n","Validation duration: 1.9064486666666653 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 83.3%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.87      0.83     12546\n","        test       0.81      0.89      0.85      9012\n","   treatment       0.79      0.86      0.82      9297\n","\n","   micro avg       0.80      0.87      0.83     30855\n","   macro avg       0.80      0.87      0.83     30855\n","weighted avg       0.80      0.87      0.83     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 20800\n","Points in y_train after augmentation: 20800\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9153800010681152\n","Training loss per 100 training steps: 0.413472321954104\n","Training loss per 100 training steps: 0.30201975411888377\n","Training loss per 100 training steps: 0.2587261047041\n","Training loss per 100 training steps: 0.231380944802168\n","Training loss per 100 training steps: 0.2142856988364351\n","Training loss per 100 training steps: 0.19905594961342715\n","Training loss epoch: 0.19429880001224004\n","Training accuracy epoch: 0.9386210602860017\n","Validating model...\n","Validation Loss: 0.14620996818139956\n","Validation Accuracy: 0.9527195066550589\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07447994500398636\n","Training loss per 100 training steps: 0.06794208917988113\n","Training loss per 100 training steps: 0.06982181553928117\n","Training loss per 100 training steps: 0.07148341573403523\n","Training loss per 100 training steps: 0.07181764022212596\n","Training loss per 100 training steps: 0.07267529194516514\n","Training loss per 100 training steps: 0.07479331075692683\n","Training loss epoch: 0.07464310489881497\n","Training accuracy epoch: 0.9762611763200242\n","Validating model...\n","Validation Loss: 0.15427050795164202\n","Validation Accuracy: 0.9556879176550032\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02202204242348671\n","Training loss per 100 training steps: 0.04374928083639629\n","Training loss per 100 training steps: 0.041374442074911214\n","Training loss per 100 training steps: 0.04310017084838989\n","Training loss per 100 training steps: 0.04476780349393364\n","Training loss per 100 training steps: 0.045765593955609314\n","Training loss per 100 training steps: 0.045899051682444014\n","Training loss epoch: 0.04549970568730854\n","Training accuracy epoch: 0.9854452174666816\n","Validating model...\n","Validation Loss: 0.16211659923897354\n","Validation Accuracy: 0.9585510486023096\n","Training epoch: 4\n","Training loss per 100 training steps: 0.05679136887192726\n","Training loss per 100 training steps: 0.034034627711049995\n","Training loss per 100 training steps: 0.03356833064544075\n","Training loss per 100 training steps: 0.03377174826623544\n","Training loss per 100 training steps: 0.032286572651566\n","Training loss per 100 training steps: 0.03278446640306247\n","Training loss per 100 training steps: 0.032284484952285315\n","Training loss epoch: 0.03234757389264325\n","Training accuracy epoch: 0.9901259259825824\n","Validating model...\n","Validation Loss: 0.17434773176860113\n","Validation Accuracy: 0.9561722416797556\n","Training epoch: 5\n","Training loss per 100 training steps: 0.051729124039411545\n","Training loss per 100 training steps: 0.022027461700219807\n","Training loss per 100 training steps: 0.02052702902861412\n","Training loss per 100 training steps: 0.020756360334290062\n","Training loss per 100 training steps: 0.021096661950355894\n","Training loss per 100 training steps: 0.021871660021598453\n","Training loss per 100 training steps: 0.023037264556290828\n","Training loss epoch: 0.02328072941253105\n","Training accuracy epoch: 0.9927447037092105\n","Validating model...\n","Validation Loss: 0.19614322147295846\n","Validation Accuracy: 0.9569040526688476\n","Training epoch: 6\n","Training loss per 100 training steps: 0.01295559760183096\n","Training loss per 100 training steps: 0.01742456926351026\n","Training loss per 100 training steps: 0.016255469754713574\n","Training loss per 100 training steps: 0.01923953257543669\n","Training loss per 100 training steps: 0.018427876960701004\n","Training loss per 100 training steps: 0.018299582736852938\n","Training loss per 100 training steps: 0.018940526026765197\n","Training loss epoch: 0.019314603842436693\n","Training accuracy epoch: 0.9942130395755289\n","Validating model...\n","Validation Loss: 0.18613871361141082\n","Validation Accuracy: 0.9569200736612259\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 23.979070366666672 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n"]}]},{"cell_type":"code","source":["number_of_training_models = 1\n","target_augmented_percentage = 1\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"metadata":{"id":"ka4Q2DDCrn7t","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["5b36f27f2a26406caf7ea9c1ee2cac0e","b7b792856a1740a1a02f832912822940","ff531fefa439415c9fbae9e904baf492","0e5f5dd0ddc24e7098087c2641595f2b","7337660960104fa987723c5d2c335658","d476390ea7b54c0781c51b4a620a6345","693a26e28794428988c459e38a82c290","4e8494a4d1634008b8a92632a58af86d","5086d87cdbc54da1ba3480c73c29d626","eb8760dbfc164a09a84b582e23df2bb5","f98e5596133045deaec8d624b8ffce66"]},"executionInfo":{"status":"ok","timestamp":1663202542505,"user_tz":240,"elapsed":2788649,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}},"outputId":"42f52682-ccda-4664-8cf6-edcf664a2a28"},"id":"ka4Q2DDCrn7t","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["!!!!!! Augmented Percentage 100% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 20800\n","Points in y_train after augmentation: 20800\n","Device:  cuda\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b36f27f2a26406caf7ea9c1ee2cac0e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9953007698059082\n","Training loss per 100 training steps: 0.42017369105084107\n","Training loss per 100 training steps: 0.30427725123825355\n","Training loss per 100 training steps: 0.2609349141188238\n","Training loss per 100 training steps: 0.2338954883411601\n","Training loss per 100 training steps: 0.2165255128515665\n","Training loss per 100 training steps: 0.2029319603024004\n","Training loss epoch: 0.1973401693125757\n","Training accuracy epoch: 0.9381438422290066\n","Validating model...\n","Validation Loss: 0.13724648836371187\n","Validation Accuracy: 0.9539184638154129\n","Training epoch: 2\n","Training loss per 100 training steps: 0.10620805621147156\n","Training loss per 100 training steps: 0.074851520276527\n","Training loss per 100 training steps: 0.07799801558478554\n","Training loss per 100 training steps: 0.07706433414571309\n","Training loss per 100 training steps: 0.07776016340663011\n","Training loss per 100 training steps: 0.07887213394610944\n","Training loss per 100 training steps: 0.07843958154264931\n","Training loss epoch: 0.07825381125395114\n","Training accuracy epoch: 0.9756602186469534\n","Validating model...\n","Validation Loss: 0.14402687612485576\n","Validation Accuracy: 0.9560063995857436\n","Training epoch: 3\n","Training loss per 100 training steps: 0.022084221243858337\n","Training loss per 100 training steps: 0.04380537090952148\n","Training loss per 100 training steps: 0.04215809642175092\n","Training loss per 100 training steps: 0.042949302125090974\n","Training loss per 100 training steps: 0.042195759244504714\n","Training loss per 100 training steps: 0.04266635433839497\n","Training loss per 100 training steps: 0.041878501318252576\n","Training loss epoch: 0.04193712252013099\n","Training accuracy epoch: 0.9871184282924503\n","Validating model...\n","Validation Loss: 0.174013592641462\n","Validation Accuracy: 0.9559826906724836\n","Training epoch: 4\n","Training loss per 100 training steps: 0.008726097643375397\n","Training loss per 100 training steps: 0.024025191482626787\n","Training loss per 100 training steps: 0.024898075661390316\n","Training loss per 100 training steps: 0.0251330172057508\n","Training loss per 100 training steps: 0.02724710924747142\n","Training loss per 100 training steps: 0.02811651944276689\n","Training loss per 100 training steps: 0.02922485568215869\n","Training loss epoch: 0.029415741328758977\n","Training accuracy epoch: 0.9909649288290526\n","Validating model...\n","Validation Loss: 0.17936148366274\n","Validation Accuracy: 0.9589022758390029\n","Training epoch: 5\n","Training loss per 100 training steps: 0.007943320088088512\n","Training loss per 100 training steps: 0.02086906152717437\n","Training loss per 100 training steps: 0.028128674140881136\n","Training loss per 100 training steps: 0.026629118706746356\n","Training loss per 100 training steps: 0.028678724623983146\n","Training loss per 100 training steps: 0.027898843498587303\n","Training loss per 100 training steps: 0.02753961669444223\n","Training loss epoch: 0.028096531425835566\n","Training accuracy epoch: 0.9913919512258265\n","Validating model...\n","Validation Loss: 0.17723055590282788\n","Validation Accuracy: 0.9579347461356439\n","Training epoch: 6\n","Training loss per 100 training steps: 0.010733976028859615\n","Training loss per 100 training steps: 0.02124403325822389\n","Training loss per 100 training steps: 0.018102780122753577\n","Training loss per 100 training steps: 0.018237433915024165\n","Training loss per 100 training steps: 0.02060609276122251\n","Training loss per 100 training steps: 0.02179430335607452\n","Training loss per 100 training steps: 0.021933600437018117\n","Training loss epoch: 0.02144632735777682\n","Training accuracy epoch: 0.9934228381224407\n","Validating model...\n","Validation Loss: 0.19895222800021822\n","Validation Accuracy: 0.9591636852896238\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 42.87858958333333 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.1531591786554566\n","Validation Accuracy: 0.9514691444540242\n","Validation duration: 3.2165451333333293 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 82.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.85      0.83     12546\n","        test       0.85      0.81      0.83      9012\n","   treatment       0.77      0.88      0.82      9297\n","\n","   micro avg       0.81      0.85      0.83     30855\n","   macro avg       0.81      0.85      0.83     30855\n","weighted avg       0.81      0.85      0.83     30855\n","\n"]}]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Zjhn7-LqHri0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663245005215,"user_tz":240,"elapsed":98690,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}},"outputId":"b623298c-96cf-4942-c3c2-4523da5622da"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 200% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 31200\n","Points in y_train after augmentation: 31200\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.132916212081909\n","Training loss per 100 training steps: 0.4131303828689131\n","Training loss per 100 training steps: 0.30534487721783604\n","Training loss per 100 training steps: 0.25862575191199977\n","Training loss per 100 training steps: 0.23284918396847504\n","Training loss per 100 training steps: 0.2128016639969306\n","Training loss per 100 training steps: 0.19979592269525154\n","Training loss per 100 training steps: 0.1867401701917662\n","Training loss per 100 training steps: 0.17734646142115085\n","Training loss per 100 training steps: 0.1699785796592589\n","Training loss epoch: 0.16470014612453107\n","Training accuracy epoch: 0.9483854703858051\n","Validating model...\n","Validation Loss: 0.1463401877841392\n","Validation Accuracy: 0.9555939865958115\n","Training epoch: 2\n","Training loss per 100 training steps: 0.11462537199258804\n","Training loss per 100 training steps: 0.06134255827948599\n","Training loss per 100 training steps: 0.06317537736648055\n","Training loss per 100 training steps: 0.06398712101692575\n","Training loss per 100 training steps: 0.06081530896301133\n","Training loss per 100 training steps: 0.0595111456734989\n","Training loss per 100 training steps: 0.059587043077032546\n","Training loss per 100 training steps: 0.0599679807911809\n","Training loss per 100 training steps: 0.060491979947678756\n","Training loss per 100 training steps: 0.061040387562291076\n","Training loss epoch: 0.061251586514214675\n","Training accuracy epoch: 0.981155382603043\n","Validating model...\n","Validation Loss: 0.16855002608295386\n","Validation Accuracy: 0.9511839192472954\n","Training epoch: 3\n","Training loss per 100 training steps: 0.017754850909113884\n","Training loss per 100 training steps: 0.030075676291996596\n","Training loss per 100 training steps: 0.032440767786813096\n","Training loss per 100 training steps: 0.033275493618682574\n","Training loss per 100 training steps: 0.03365841476267617\n","Training loss per 100 training steps: 0.03482568485777594\n","Training loss per 100 training steps: 0.034588044679750025\n","Training loss per 100 training steps: 0.03435936552489352\n","Training loss per 100 training steps: 0.034114397884844765\n","Training loss per 100 training steps: 0.034108405884396134\n","Training loss epoch: 0.034439753582163786\n","Training accuracy epoch: 0.9893163631844442\n","Validating model...\n","Validation Loss: 0.184883416666613\n","Validation Accuracy: 0.9548713964188984\n","Training epoch: 4\n","Training loss per 100 training steps: 0.014302370138466358\n","Training loss per 100 training steps: 0.02016245697320688\n","Training loss per 100 training steps: 0.020564466095135653\n","Training loss per 100 training steps: 0.02489665475561039\n","Training loss per 100 training steps: 0.024444182371741573\n","Training loss per 100 training steps: 0.024481539002214437\n","Training loss per 100 training steps: 0.02408649871639517\n","Training loss per 100 training steps: 0.025142737643191387\n","Training loss per 100 training steps: 0.02548606296842534\n","Training loss per 100 training steps: 0.02563182232419771\n","Training loss epoch: 0.025861974933710046\n","Training accuracy epoch: 0.9921200969298986\n","Validating model...\n","Validation Loss: 0.18858884622088887\n","Validation Accuracy: 0.9564274588978511\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0228535495698452\n","Training loss per 100 training steps: 0.016264171724548877\n","Training loss per 100 training steps: 0.020395139748038287\n","Training loss per 100 training steps: 0.019797405293574898\n","Training loss per 100 training steps: 0.021188680303922885\n","Training loss per 100 training steps: 0.020261645020114002\n","Training loss per 100 training steps: 0.02130666853334699\n","Training loss per 100 training steps: 0.021803780479460275\n","Training loss per 100 training steps: 0.022051869802492043\n","Training loss per 100 training steps: 0.022253379949095136\n","Training loss epoch: 0.022296603247344206\n","Training accuracy epoch: 0.9931230532558376\n","Validating model...\n","Validation Loss: 0.1968095461269478\n","Validation Accuracy: 0.9559321748968685\n","Training epoch: 6\n","Training loss per 100 training steps: 0.003649470629170537\n","Training loss per 100 training steps: 0.01391680098869515\n","Training loss per 100 training steps: 0.015461622197986047\n","Training loss per 100 training steps: 0.01770939204895612\n","Training loss per 100 training steps: 0.020456155274569073\n","Training loss per 100 training steps: 0.01986098919311741\n","Training loss per 100 training steps: 0.020394467182847563\n","Training loss per 100 training steps: 0.020220779156312013\n","Training loss per 100 training steps: 0.020320063140529608\n","Training loss per 100 training steps: 0.01976424154813751\n","Training loss epoch: 0.019537554087851627\n","Training accuracy epoch: 0.9939590407736489\n","Validating model...\n","Validation Loss: 0.2186222541351597\n","Validation Accuracy: 0.9551117943535068\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 63.52643485 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16704109780645618\n","Validation Accuracy: 0.9517637538047301\n","Validation duration: 3.1323182666666676 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 82.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.82      0.82      0.82     12546\n","        test       0.81      0.84      0.83      9012\n","   treatment       0.79      0.88      0.83      9297\n","\n","   micro avg       0.81      0.84      0.83     30855\n","   macro avg       0.81      0.85      0.83     30855\n","weighted avg       0.81      0.84      0.83     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 31200\n","Points in y_train after augmentation: 31200\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.171631097793579\n","Training loss per 100 training steps: 0.39231366354345093\n","Training loss per 100 training steps: 0.29468737527802213\n","Training loss per 100 training steps: 0.25237477469285857\n","Training loss per 100 training steps: 0.22526868981799283\n","Training loss per 100 training steps: 0.20825827012429693\n","Training loss per 100 training steps: 0.1951345782572041\n","Training loss per 100 training steps: 0.18447874302041853\n","Training loss per 100 training steps: 0.17547369375824928\n","Training loss per 100 training steps: 0.16762880406256653\n","Training loss epoch: 0.16273524430699837\n","Training accuracy epoch: 0.9488923085575599\n","Validating model...\n","Validation Loss: 0.16281361495713134\n","Validation Accuracy: 0.9505634547353834\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05403580144047737\n","Training loss per 100 training steps: 0.07087162475442828\n","Training loss per 100 training steps: 0.06392778815071455\n","Training loss per 100 training steps: 0.06319935444860017\n","Training loss per 100 training steps: 0.064860497349339\n","Training loss per 100 training steps: 0.06413285526727697\n","Training loss per 100 training steps: 0.06415311990076437\n","Training loss per 100 training steps: 0.06375972335671902\n","Training loss per 100 training steps: 0.06303523153708446\n","Training loss per 100 training steps: 0.0626115715195767\n","Training loss epoch: 0.06267871774852467\n","Training accuracy epoch: 0.9804354649373317\n","Validating model...\n","Validation Loss: 0.15699382837523113\n","Validation Accuracy: 0.9555885684077887\n","Training epoch: 3\n","Training loss per 100 training steps: 0.06981343030929565\n","Training loss per 100 training steps: 0.032778833294287324\n","Training loss per 100 training steps: 0.02981339693063666\n","Training loss per 100 training steps: 0.03212950398593962\n","Training loss per 100 training steps: 0.032325240603254465\n","Training loss per 100 training steps: 0.03280044922327712\n","Training loss per 100 training steps: 0.034524564884936965\n","Training loss per 100 training steps: 0.03535160363228997\n","Training loss per 100 training steps: 0.03630199766252481\n","Training loss per 100 training steps: 0.0367601420931269\n","Training loss epoch: 0.037400817281196416\n","Training accuracy epoch: 0.9881904867258899\n","Validating model...\n","Validation Loss: 0.18195582275557054\n","Validation Accuracy: 0.9565066590453887\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03633948415517807\n","Training loss per 100 training steps: 0.021087688078071074\n","Training loss per 100 training steps: 0.020105071364095742\n","Training loss per 100 training steps: 0.02116389850083355\n","Training loss per 100 training steps: 0.02189754946343136\n","Training loss per 100 training steps: 0.022088471031770994\n","Training loss per 100 training steps: 0.02182023639075176\n","Training loss per 100 training steps: 0.021730341776104754\n","Training loss per 100 training steps: 0.02240445789969416\n","Training loss per 100 training steps: 0.02245756059611882\n","Training loss epoch: 0.02295763321692506\n","Training accuracy epoch: 0.9931867683073727\n","Validating model...\n","Validation Loss: 0.19039746004386576\n","Validation Accuracy: 0.9549485887801995\n","Training epoch: 5\n","Training loss per 100 training steps: 0.033512745052576065\n","Training loss per 100 training steps: 0.020802617508175754\n","Training loss per 100 training steps: 0.023596860849198917\n","Training loss per 100 training steps: 0.026171947599495406\n","Training loss per 100 training steps: 0.027607250476036536\n","Training loss per 100 training steps: 0.027938001219042857\n","Training loss per 100 training steps: 0.027112609702945004\n","Training loss per 100 training steps: 0.026601542233616996\n","Training loss per 100 training steps: 0.026792013662641685\n","Training loss per 100 training steps: 0.026341144051082375\n","Training loss epoch: 0.025800247427780563\n","Training accuracy epoch: 0.9922051841016607\n","Validating model...\n","Validation Loss: 0.19812010673960284\n","Validation Accuracy: 0.9594683311532471\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0063112592324614525\n","Training loss per 100 training steps: 0.013657730664034366\n","Training loss per 100 training steps: 0.013465295764397534\n","Training loss per 100 training steps: 0.014177833636217068\n","Training loss per 100 training steps: 0.014540811224336599\n","Training loss per 100 training steps: 0.015368903800287468\n","Training loss per 100 training steps: 0.01539277077533193\n","Training loss per 100 training steps: 0.015839609694959445\n","Training loss per 100 training steps: 0.015447432031685233\n","Training loss per 100 training steps: 0.01565268280238937\n","Training loss epoch: 0.016146237315708557\n","Training accuracy epoch: 0.9953514324441052\n","Validating model...\n","Validation Loss: 0.211869900078549\n","Validation Accuracy: 0.9521473011870895\n","Training epoch: 7\n","Training loss per 100 training steps: 0.009274069219827652\n","Training loss per 100 training steps: 0.019207750760032657\n","Training loss per 100 training steps: 0.01861959687678551\n","Training loss per 100 training steps: 0.018110813364344787\n","Training loss per 100 training steps: 0.016880836174649156\n","Training loss per 100 training steps: 0.016804347037590536\n","Training loss per 100 training steps: 0.01762384490265717\n","Training loss per 100 training steps: 0.01890586283329951\n","Training loss per 100 training steps: 0.018740456293194034\n","Training loss per 100 training steps: 0.0192666043471607\n","Training loss epoch: 0.019335243017830624\n","Training accuracy epoch: 0.9940919799867464\n","Validating model...\n","Validation Loss: 0.22454510832374747\n","Validation Accuracy: 0.9556288508921914\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 73.90599111666668 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.17792352956840424\n","Validation Accuracy: 0.9499229952472014\n","Validation duration: 3.117130716666664 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 83.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.85      0.82     12546\n","        test       0.81      0.87      0.84      9012\n","   treatment       0.80      0.87      0.83      9297\n","\n","   micro avg       0.80      0.86      0.83     30855\n","   macro avg       0.80      0.86      0.83     30855\n","weighted avg       0.80      0.86      0.83     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 31200\n","Points in y_train after augmentation: 31200\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9301530122756958\n","Training loss per 100 training steps: 0.37567743939338344\n","Training loss per 100 training steps: 0.29311086337513\n","Training loss per 100 training steps: 0.2530375925260921\n","Training loss per 100 training steps: 0.22671917230912725\n","Training loss per 100 training steps: 0.20941322543351593\n","Training loss per 100 training steps: 0.1946237547022481\n","Training loss per 100 training steps: 0.18236571617594544\n","Training loss per 100 training steps: 0.1732942784128341\n","Training loss per 100 training steps: 0.16466364498094105\n","Training loss epoch: 0.16002842142031742\n","Training accuracy epoch: 0.9497218655625987\n","Validating model...\n","Validation Loss: 0.1540034223686565\n","Validation Accuracy: 0.9517669371795505\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06505260616540909\n","Training loss per 100 training steps: 0.06068584689464752\n","Training loss per 100 training steps: 0.06574525892623324\n","Training loss per 100 training steps: 0.06374786971786688\n","Training loss per 100 training steps: 0.06258172853652416\n","Training loss per 100 training steps: 0.06180626738857396\n","Training loss per 100 training steps: 0.061434443196291086\n","Training loss per 100 training steps: 0.06147828875255695\n","Training loss per 100 training steps: 0.06238892310986135\n","Training loss per 100 training steps: 0.06186912226471037\n","Training loss epoch: 0.06218211700423406\n","Training accuracy epoch: 0.9806810005181681\n","Validating model...\n","Validation Loss: 0.15740906743502076\n","Validation Accuracy: 0.9562405462766624\n","Training epoch: 3\n","Training loss per 100 training steps: 0.025915062054991722\n","Training loss per 100 training steps: 0.034762085945631314\n","Training loss per 100 training steps: 0.03372480340223222\n","Training loss per 100 training steps: 0.03386826086959545\n","Training loss per 100 training steps: 0.032225934257312794\n","Training loss per 100 training steps: 0.032576627251385396\n","Training loss per 100 training steps: 0.03342231155873684\n","Training loss per 100 training steps: 0.03401679235554371\n","Training loss per 100 training steps: 0.034605631410619814\n","Training loss per 100 training steps: 0.035318078158721\n","Training loss epoch: 0.03538755446314239\n","Training accuracy epoch: 0.9889179937699653\n","Validating model...\n","Validation Loss: 0.1907232128712651\n","Validation Accuracy: 0.9508010658717644\n","Training epoch: 4\n","Training loss per 100 training steps: 0.03977899253368378\n","Training loss per 100 training steps: 0.023277795345679222\n","Training loss per 100 training steps: 0.025790585501499437\n","Training loss per 100 training steps: 0.025928088218635844\n","Training loss per 100 training steps: 0.025926416351383277\n","Training loss per 100 training steps: 0.026632642844215987\n","Training loss per 100 training steps: 0.026208731734012555\n","Training loss per 100 training steps: 0.02658869890272272\n","Training loss per 100 training steps: 0.027160082027094017\n","Training loss per 100 training steps: 0.026941652841412242\n","Training loss epoch: 0.02705401665608709\n","Training accuracy epoch: 0.9915010821935635\n","Validating model...\n","Validation Loss: 0.1867485089324318\n","Validation Accuracy: 0.9550994508866364\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0799737274646759\n","Training loss per 100 training steps: 0.019536907367389833\n","Training loss per 100 training steps: 0.01924888030289955\n","Training loss per 100 training steps: 0.018167830508900806\n","Training loss per 100 training steps: 0.01755635379725066\n","Training loss per 100 training steps: 0.018104541393430502\n","Training loss per 100 training steps: 0.018511452528633746\n","Training loss per 100 training steps: 0.018919641293142556\n","Training loss per 100 training steps: 0.019720742469338106\n","Training loss per 100 training steps: 0.019979155139415394\n","Training loss epoch: 0.02017464531457219\n","Training accuracy epoch: 0.9939101198906696\n","Validating model...\n","Validation Loss: 0.21673400874261733\n","Validation Accuracy: 0.9530290088506839\n","Training epoch: 6\n","Training loss per 100 training steps: 0.014802968129515648\n","Training loss per 100 training steps: 0.015624757976003803\n","Training loss per 100 training steps: 0.017376702661690908\n","Training loss per 100 training steps: 0.019112129531146344\n","Training loss per 100 training steps: 0.017878869629292016\n","Training loss per 100 training steps: 0.017226660527133692\n","Training loss per 100 training steps: 0.01725933625338213\n","Training loss per 100 training steps: 0.017847593663203546\n","Training loss per 100 training steps: 0.018655790087597483\n","Training loss per 100 training steps: 0.01915712990996647\n","Training loss epoch: 0.01926477238216485\n","Training accuracy epoch: 0.9941910236749752\n","Validating model...\n","Validation Loss: 0.2271711231729427\n","Validation Accuracy: 0.9532001159646534\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 63.39935566666669 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16156601258424214\n","Validation Accuracy: 0.9497556757489662\n","Validation duration: 3.1323613000000177 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 81.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.77      0.86      0.81     12546\n","        test       0.81      0.84      0.83      9012\n","   treatment       0.84      0.80      0.82      9297\n","\n","   micro avg       0.80      0.84      0.82     30855\n","   macro avg       0.80      0.83      0.82     30855\n","weighted avg       0.80      0.84      0.82     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 31200\n","Points in y_train after augmentation: 31200\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9840446710586548\n","Training loss per 100 training steps: 0.39888593377453263\n","Training loss per 100 training steps: 0.3013524083948847\n","Training loss per 100 training steps: 0.25702286552501674\n","Training loss per 100 training steps: 0.22697792195731267\n","Training loss per 100 training steps: 0.21008346792674826\n","Training loss per 100 training steps: 0.1951257734561026\n","Training loss per 100 training steps: 0.1836502366405666\n","Training loss per 100 training steps: 0.17356871638200555\n","Training loss per 100 training steps: 0.16606193006278475\n","Training loss epoch: 0.1610486683746179\n","Training accuracy epoch: 0.9495671651818843\n","Validating model...\n","Validation Loss: 0.14970046734171255\n","Validation Accuracy: 0.9525695531305077\n","Training epoch: 2\n","Training loss per 100 training steps: 0.053055476397275925\n","Training loss per 100 training steps: 0.06046605167338754\n","Training loss per 100 training steps: 0.06010556548592908\n","Training loss per 100 training steps: 0.06042152569718981\n","Training loss per 100 training steps: 0.06379857728666535\n","Training loss per 100 training steps: 0.06427352753432539\n","Training loss per 100 training steps: 0.06196444395064886\n","Training loss per 100 training steps: 0.06105008426410666\n","Training loss per 100 training steps: 0.060138099660024924\n","Training loss per 100 training steps: 0.06074645906168922\n","Training loss epoch: 0.060563786564967956\n","Training accuracy epoch: 0.9812037648719146\n","Validating model...\n","Validation Loss: 0.1591701830749388\n","Validation Accuracy: 0.9569417303496613\n","Training epoch: 3\n","Training loss per 100 training steps: 0.012812785804271698\n","Training loss per 100 training steps: 0.02996220988553423\n","Training loss per 100 training steps: 0.03274077257206339\n","Training loss per 100 training steps: 0.03386393364439982\n","Training loss per 100 training steps: 0.034083078602883975\n","Training loss per 100 training steps: 0.03555823771116656\n","Training loss per 100 training steps: 0.035938070075680964\n","Training loss per 100 training steps: 0.03568880633100968\n","Training loss per 100 training steps: 0.0356688345663282\n","Training loss per 100 training steps: 0.03589385253603112\n","Training loss epoch: 0.036176559153156214\n","Training accuracy epoch: 0.9892020663810905\n","Validating model...\n","Validation Loss: 0.17868772911077196\n","Validation Accuracy: 0.9570078617344268\n","Training epoch: 4\n","Training loss per 100 training steps: 0.006987710949033499\n","Training loss per 100 training steps: 0.0192757130146377\n","Training loss per 100 training steps: 0.020566587047929418\n","Training loss per 100 training steps: 0.02258545691356298\n","Training loss per 100 training steps: 0.02317487985648196\n","Training loss per 100 training steps: 0.02304268426061078\n","Training loss per 100 training steps: 0.0236194686865947\n","Training loss per 100 training steps: 0.023694155356044962\n","Training loss per 100 training steps: 0.025648900525503154\n","Training loss per 100 training steps: 0.027420020818200736\n","Training loss epoch: 0.027752353045373008\n","Training accuracy epoch: 0.9914743839378435\n","Validating model...\n","Validation Loss: 0.20447272313879683\n","Validation Accuracy: 0.9552392578421771\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0064563448540866375\n","Training loss per 100 training steps: 0.018381639163581525\n","Training loss per 100 training steps: 0.020604229326573065\n","Training loss per 100 training steps: 0.02003037741162545\n","Training loss per 100 training steps: 0.021223334516450865\n","Training loss per 100 training steps: 0.02183893570449192\n","Training loss per 100 training steps: 0.02175508545041038\n","Training loss per 100 training steps: 0.02215892224402875\n","Training loss per 100 training steps: 0.021569727988086394\n","Training loss per 100 training steps: 0.02164886928672285\n","Training loss epoch: 0.021382507596415683\n","Training accuracy epoch: 0.9936220343499159\n","Validating model...\n","Validation Loss: 0.20226759061991395\n","Validation Accuracy: 0.9575107217268375\n","Training epoch: 6\n","Training loss per 100 training steps: 0.007795053068548441\n","Training loss per 100 training steps: 0.01787290107896828\n","Training loss per 100 training steps: 0.017783065188666854\n","Training loss per 100 training steps: 0.019722368866762152\n","Training loss per 100 training steps: 0.01945267537373009\n","Training loss per 100 training steps: 0.01872125245814775\n","Training loss per 100 training steps: 0.01860984173007139\n","Training loss per 100 training steps: 0.018377375020163955\n","Training loss per 100 training steps: 0.0185371331174244\n","Training loss per 100 training steps: 0.01844358149473788\n","Training loss epoch: 0.018605321550873133\n","Training accuracy epoch: 0.994496440633892\n","Validating model...\n","Validation Loss: 0.20815140746727392\n","Validation Accuracy: 0.9538293338572406\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 63.30998306666664 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16352090205354788\n","Validation Accuracy: 0.9515334883764877\n","Validation duration: 3.1184408166667104 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 82.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.83      0.82     12546\n","        test       0.82      0.86      0.84      9012\n","   treatment       0.79      0.84      0.82      9297\n","\n","   micro avg       0.81      0.84      0.82     30855\n","   macro avg       0.81      0.84      0.82     30855\n","weighted avg       0.81      0.84      0.82     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n","Points in X_train after augmentation: 31200\n","Points in y_train after augmentation: 31200\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.6954047679901123\n","Training loss per 100 training steps: 0.37898436328857255\n","Training loss per 100 training steps: 0.284608694562568\n","Training loss per 100 training steps: 0.2409366551489628\n","Training loss per 100 training steps: 0.21736376089255263\n","Training loss per 100 training steps: 0.2021316147545081\n","Training loss per 100 training steps: 0.18837922152299155\n","Training loss per 100 training steps: 0.17884776138630132\n","Training loss per 100 training steps: 0.16993725145661207\n","Training loss per 100 training steps: 0.16370741383572596\n","Training loss epoch: 0.15810853514151696\n","Training accuracy epoch: 0.950651057030404\n","Validating model...\n","Validation Loss: 0.17184239272753915\n","Validation Accuracy: 0.9494734877220786\n","Training epoch: 2\n","Training loss per 100 training steps: 0.08976927399635315\n","Training loss per 100 training steps: 0.05933956654355078\n","Training loss per 100 training steps: 0.05776258473011169\n","Training loss per 100 training steps: 0.057105616828816576\n","Training loss per 100 training steps: 0.05744252077238797\n","Training loss per 100 training steps: 0.058335440528454505\n","Training loss per 100 training steps: 0.05874809041230346\n","Training loss per 100 training steps: 0.05880977430237396\n","Training loss per 100 training steps: 0.05861325875086275\n","Training loss per 100 training steps: 0.057640817822355125\n","Training loss epoch: 0.057848010791752204\n","Training accuracy epoch: 0.9816742363136142\n","Validating model...\n","Validation Loss: 0.16601097424115455\n","Validation Accuracy: 0.9536933584273126\n","Training epoch: 3\n","Training loss per 100 training steps: 0.056597981601953506\n","Training loss per 100 training steps: 0.03912045038074698\n","Training loss per 100 training steps: 0.04027076484635472\n","Training loss per 100 training steps: 0.037156643489827446\n","Training loss per 100 training steps: 0.03657060865129337\n","Training loss per 100 training steps: 0.03658365853690355\n","Training loss per 100 training steps: 0.0359454723706503\n","Training loss per 100 training steps: 0.03705263385793643\n","Training loss per 100 training steps: 0.0372507455183214\n","Training loss per 100 training steps: 0.03743028805072272\n","Training loss epoch: 0.037090950283962185\n","Training accuracy epoch: 0.9885082937650516\n","Validating model...\n","Validation Loss: 0.16449443653056567\n","Validation Accuracy: 0.9588300727991299\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01649056375026703\n","Training loss per 100 training steps: 0.02318691551664586\n","Training loss per 100 training steps: 0.02367589983073253\n","Training loss per 100 training steps: 0.024437700000771806\n","Training loss per 100 training steps: 0.026819727588006576\n","Training loss per 100 training steps: 0.027648012724553073\n","Training loss per 100 training steps: 0.028343471446310477\n","Training loss per 100 training steps: 0.028434248123035306\n","Training loss per 100 training steps: 0.02799985446309823\n","Training loss per 100 training steps: 0.027373861496190238\n","Training loss epoch: 0.027743561829422385\n","Training accuracy epoch: 0.9914797435720445\n","Validating model...\n","Validation Loss: 0.17242192561653527\n","Validation Accuracy: 0.9565500872843101\n","Training epoch: 5\n","Training loss per 100 training steps: 0.009737109765410423\n","Training loss per 100 training steps: 0.018480669998674478\n","Training loss per 100 training steps: 0.014714773181960246\n","Training loss per 100 training steps: 0.01631113709908975\n","Training loss per 100 training steps: 0.0162064913997631\n","Training loss per 100 training steps: 0.01686893122774008\n","Training loss per 100 training steps: 0.016953056120409007\n","Training loss per 100 training steps: 0.017249952994513533\n","Training loss per 100 training steps: 0.017427358808741206\n","Training loss per 100 training steps: 0.01798653224146936\n","Training loss epoch: 0.017938781472949836\n","Training accuracy epoch: 0.9945499990268776\n","Validating model...\n","Validation Loss: 0.1984434377299259\n","Validation Accuracy: 0.9585101355367909\n","Training epoch: 6\n","Training loss per 100 training steps: 0.011398142203688622\n","Training loss per 100 training steps: 0.015159572619889485\n","Training loss per 100 training steps: 0.015543960669339723\n","Training loss per 100 training steps: 0.015194049905741934\n","Training loss per 100 training steps: 0.015240945997215375\n","Training loss per 100 training steps: 0.01523354134127124\n","Training loss per 100 training steps: 0.014674676994464985\n","Training loss per 100 training steps: 0.015814747943547217\n","Training loss per 100 training steps: 0.016313366893541997\n","Training loss per 100 training steps: 0.01623389749533469\n","Training loss epoch: 0.016287581292369093\n","Training accuracy epoch: 0.9948895960389259\n","Validating model...\n","Validation Loss: 0.21989753975399903\n","Validation Accuracy: 0.9562690770360606\n","Training epoch: 7\n","Training loss per 100 training steps: 0.002988578751683235\n","Training loss per 100 training steps: 0.014191506317549266\n","Training loss per 100 training steps: 0.017370038856960722\n","Training loss per 100 training steps: 0.017171814092481353\n","Training loss per 100 training steps: 0.017359405086536026\n","Training loss per 100 training steps: 0.017570864506511522\n","Training loss per 100 training steps: 0.018126886077513827\n","Training loss per 100 training steps: 0.018662362839781167\n","Training loss per 100 training steps: 0.0189313783002638\n","Training loss per 100 training steps: 0.01957853399255568\n","Training loss epoch: 0.019293345172086564\n","Training accuracy epoch: 0.9941677705349203\n","Validating model...\n","Validation Loss: 0.2008040374411004\n","Validation Accuracy: 0.9574678931367528\n","Training epoch: 8\n","Training loss per 100 training steps: 0.006165582686662674\n","Training loss per 100 training steps: 0.014013253486920424\n","Training loss per 100 training steps: 0.01594752805039347\n","Training loss per 100 training steps: 0.014811707442325456\n","Training loss per 100 training steps: 0.013704336254144474\n","Training loss per 100 training steps: 0.012868925509590956\n","Training loss per 100 training steps: 0.012992858815048752\n","Training loss per 100 training steps: 0.013648672789230959\n","Training loss per 100 training steps: 0.013120413399749108\n","Training loss per 100 training steps: 0.013270480532434818\n","Training loss epoch: 0.01386926044148799\n","Training accuracy epoch: 0.9958430971017618\n","Validating model...\n","Validation Loss: 0.20818630784943506\n","Validation Accuracy: 0.953331102811438\n","Training epoch: 9\n","Patience limit reached\n","Training duration: 84.3819597166667 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.19867769939204058\n","Validation Accuracy: 0.9506022191543754\n","Validation duration: 3.1544551666666547 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 83.0%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.87      0.83     12546\n","        test       0.82      0.84      0.83      9012\n","   treatment       0.81      0.86      0.83      9297\n","\n","   micro avg       0.81      0.85      0.83     30855\n","   macro avg       0.81      0.85      0.83     30855\n","weighted avg       0.81      0.85      0.83     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n","Points in X_train after augmentation: 31200\n","Points in y_train after augmentation: 31200\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.332486391067505\n","Training loss per 100 training steps: 0.41231207114340057\n","Training loss per 100 training steps: 0.29759085250656997\n","Training loss per 100 training steps: 0.2496842136761279\n","Training loss per 100 training steps: 0.2210898507767336\n","Training loss per 100 training steps: 0.20420040266807685\n","Training loss per 100 training steps: 0.19199828023769694\n","Training loss per 100 training steps: 0.18102225773939903\n","Training loss per 100 training steps: 0.172724433803696\n","Training loss per 100 training steps: 0.1654993488384074\n","Training loss epoch: 0.16044584628481132\n","Training accuracy epoch: 0.9499965057035272\n","Validating model...\n","Validation Loss: 0.15938532037974953\n","Validation Accuracy: 0.9509990270879827\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09518339484930038\n","Training loss per 100 training steps: 0.053998918876531396\n","Training loss per 100 training steps: 0.05368433552168643\n","Training loss per 100 training steps: 0.055851277742114076\n","Training loss per 100 training steps: 0.05805899182501762\n","Training loss per 100 training steps: 0.05705933972074095\n","Training loss per 100 training steps: 0.057595427348720106\n","Training loss per 100 training steps: 0.05800795968497084\n","Training loss per 100 training steps: 0.05752424537419305\n","Training loss per 100 training steps: 0.05735887057736069\n","Training loss epoch: 0.05682453053215375\n","Training accuracy epoch: 0.982299892963969\n","Validating model...\n","Validation Loss: 0.1682228229988318\n","Validation Accuracy: 0.953011782343023\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04029422253370285\n","Training loss per 100 training steps: 0.03172282141974509\n","Training loss per 100 training steps: 0.031848534855954534\n","Training loss per 100 training steps: 0.03264710331564627\n","Training loss per 100 training steps: 0.03428461597396289\n","Training loss per 100 training steps: 0.035810956365694695\n","Training loss per 100 training steps: 0.0363567096205233\n","Training loss per 100 training steps: 0.036974377800629454\n","Training loss per 100 training steps: 0.03670646141128575\n","Training loss per 100 training steps: 0.036567527864884986\n","Training loss epoch: 0.03627805988590878\n","Training accuracy epoch: 0.9890093259580467\n","Validating model...\n","Validation Loss: 0.17843027357253935\n","Validation Accuracy: 0.9521044147215214\n","Training epoch: 4\n","Training loss per 100 training steps: 0.004119326826184988\n","Training loss per 100 training steps: 0.022211719866805146\n","Training loss per 100 training steps: 0.022497747837686308\n","Training loss per 100 training steps: 0.023279441237848784\n","Training loss per 100 training steps: 0.02434909817219208\n","Training loss per 100 training steps: 0.02533547040502617\n","Training loss per 100 training steps: 0.025421716399899933\n","Training loss per 100 training steps: 0.02540803193656087\n","Training loss per 100 training steps: 0.02452503115571826\n","Training loss per 100 training steps: 0.025031522622310787\n","Training loss epoch: 0.02535970907425508\n","Training accuracy epoch: 0.9923672776378445\n","Validating model...\n","Validation Loss: 0.22453729363230915\n","Validation Accuracy: 0.9525426966197774\n","Training epoch: 5\n","Training loss per 100 training steps: 0.00507702399045229\n","Training loss per 100 training steps: 0.016507720153451446\n","Training loss per 100 training steps: 0.01699791941241551\n","Training loss per 100 training steps: 0.016911240626997514\n","Training loss per 100 training steps: 0.017813815120108278\n","Training loss per 100 training steps: 0.018380798286286196\n","Training loss per 100 training steps: 0.018166589992606667\n","Training loss per 100 training steps: 0.01814376109067288\n","Training loss per 100 training steps: 0.01874563326486084\n","Training loss per 100 training steps: 0.020087222628158204\n","Training loss epoch: 0.02003742055218213\n","Training accuracy epoch: 0.9939759311060156\n","Validating model...\n","Validation Loss: 0.2062490889923526\n","Validation Accuracy: 0.9557462186339868\n","Training epoch: 6\n","Training loss per 100 training steps: 0.12477514892816544\n","Training loss per 100 training steps: 0.016281755237107044\n","Training loss per 100 training steps: 0.016437150102423793\n","Training loss per 100 training steps: 0.015782476300617333\n","Training loss per 100 training steps: 0.015058436819211117\n","Training loss per 100 training steps: 0.014325907587214557\n","Training loss per 100 training steps: 0.015789713615002636\n","Training loss per 100 training steps: 0.015892304581586345\n","Training loss per 100 training steps: 0.015834419209268535\n","Training loss per 100 training steps: 0.016260493408957574\n","Training loss epoch: 0.0161023954654602\n","Training accuracy epoch: 0.995284519210881\n","Validating model...\n","Validation Loss: 0.223785488793699\n","Validation Accuracy: 0.9546931058341432\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 63.27194005000001 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.17205402247081683\n","Validation Accuracy: 0.9469987056783657\n","Validation duration: 3.116493966666652 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 81.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.75      0.85      0.80     12546\n","        test       0.82      0.82      0.82      9012\n","   treatment       0.83      0.84      0.83      9297\n","\n","   micro avg       0.79      0.84      0.82     30855\n","   macro avg       0.80      0.84      0.82     30855\n","weighted avg       0.80      0.84      0.82     30855\n","\n","!!!!!! Starting model number 7 !!!!!!\n","Points in X_train after augmentation: 31200\n","Points in y_train after augmentation: 31200\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.976534128189087\n","Training loss per 100 training steps: 0.3873072970326584\n","Training loss per 100 training steps: 0.2878338643233871\n","Training loss per 100 training steps: 0.24613531584235718\n","Training loss per 100 training steps: 0.22080111164051547\n","Training loss per 100 training steps: 0.2053363682393602\n","Training loss per 100 training steps: 0.1916950221596512\n","Training loss per 100 training steps: 0.1799339860805261\n","Training loss per 100 training steps: 0.17369968956161974\n","Training loss per 100 training steps: 0.16567655342665152\n","Training loss epoch: 0.16136994138360022\n","Training accuracy epoch: 0.9497506354447869\n","Validating model...\n","Validation Loss: 0.15965588122315996\n","Validation Accuracy: 0.9505210453288893\n","Training epoch: 2\n","Training loss per 100 training steps: 0.1463976949453354\n","Training loss per 100 training steps: 0.0563633334408007\n","Training loss per 100 training steps: 0.0552668409463741\n","Training loss per 100 training steps: 0.05793104284254221\n","Training loss per 100 training steps: 0.05827498955633538\n","Training loss per 100 training steps: 0.06000906355100909\n","Training loss per 100 training steps: 0.05988949079712707\n","Training loss per 100 training steps: 0.061341021279372625\n","Training loss per 100 training steps: 0.061733409569665006\n","Training loss per 100 training steps: 0.06163548369148744\n","Training loss epoch: 0.062396428792809065\n","Training accuracy epoch: 0.9808387239050651\n","Validating model...\n","Validation Loss: 0.16060633609047184\n","Validation Accuracy: 0.9525724736465309\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0800529271364212\n","Training loss per 100 training steps: 0.0393822300247848\n","Training loss per 100 training steps: 0.03596168661151841\n","Training loss per 100 training steps: 0.03466204407375826\n","Training loss per 100 training steps: 0.033459476149406406\n","Training loss per 100 training steps: 0.03480779239117816\n","Training loss per 100 training steps: 0.035936396186644466\n","Training loss per 100 training steps: 0.03624432950317807\n","Training loss per 100 training steps: 0.0364759282261882\n","Training loss per 100 training steps: 0.03634389538755155\n","Training loss epoch: 0.036317466666969736\n","Training accuracy epoch: 0.9888365460019833\n","Validating model...\n","Validation Loss: 0.183282627470114\n","Validation Accuracy: 0.9538371185860212\n","Training epoch: 4\n","Training loss per 100 training steps: 0.030694549903273582\n","Training loss per 100 training steps: 0.024172377967423216\n","Training loss per 100 training steps: 0.02447183741562402\n","Training loss per 100 training steps: 0.022816088871312548\n","Training loss per 100 training steps: 0.022750456042894326\n","Training loss per 100 training steps: 0.022502231220631098\n","Training loss per 100 training steps: 0.022396655274809225\n","Training loss per 100 training steps: 0.02222462571463541\n","Training loss per 100 training steps: 0.023113744053539102\n","Training loss per 100 training steps: 0.023635427010908195\n","Training loss epoch: 0.023727813606293727\n","Training accuracy epoch: 0.9927956625072233\n","Validating model...\n","Validation Loss: 0.1757593872388462\n","Validation Accuracy: 0.9591327456843892\n","Training epoch: 5\n","Training loss per 100 training steps: 0.012173027731478214\n","Training loss per 100 training steps: 0.019298088133431934\n","Training loss per 100 training steps: 0.02134770952803384\n","Training loss per 100 training steps: 0.022020944540560604\n","Training loss per 100 training steps: 0.021178279774167117\n","Training loss per 100 training steps: 0.02069215279524707\n","Training loss per 100 training steps: 0.020193293950339926\n","Training loss per 100 training steps: 0.021081696955215442\n","Training loss per 100 training steps: 0.021901496308309242\n","Training loss per 100 training steps: 0.022004258732937307\n","Training loss epoch: 0.02242168781072952\n","Training accuracy epoch: 0.9932626556935729\n","Validating model...\n","Validation Loss: 0.19662821747652895\n","Validation Accuracy: 0.9555633034096499\n","Training epoch: 6\n","Training loss per 100 training steps: 0.012625429779291153\n","Training loss per 100 training steps: 0.015459544320434037\n","Training loss per 100 training steps: 0.015016630326110444\n","Training loss per 100 training steps: 0.01619540686905539\n","Training loss per 100 training steps: 0.016704669832762916\n","Training loss per 100 training steps: 0.017311149692263255\n","Training loss per 100 training steps: 0.01804935465214856\n","Training loss per 100 training steps: 0.01886531714930069\n","Training loss per 100 training steps: 0.01933440597183315\n","Training loss per 100 training steps: 0.019228912962474743\n","Training loss epoch: 0.01977608145098202\n","Training accuracy epoch: 0.9939108104449758\n","Validating model...\n","Validation Loss: 0.20792293229273387\n","Validation Accuracy: 0.9576369441713134\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 63.16738144999999 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.17177214948417344\n","Validation Accuracy: 0.9491043230285007\n","Validation duration: 3.1127001499999705 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 81.5%\n","              precision    recall  f1-score   support\n","\n","     problem       0.77      0.84      0.80     12546\n","        test       0.81      0.84      0.82      9012\n","   treatment       0.83      0.82      0.82      9297\n","\n","   micro avg       0.80      0.83      0.82     30855\n","   macro avg       0.80      0.83      0.82     30855\n","weighted avg       0.80      0.83      0.82     30855\n","\n","!!!!!! Starting model number 8 !!!!!!\n","Points in X_train after augmentation: 31200\n","Points in y_train after augmentation: 31200\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9827545881271362\n","Training loss per 100 training steps: 0.39585722577158766\n","Training loss per 100 training steps: 0.2955838027433376\n","Training loss per 100 training steps: 0.25477208096868176\n","Training loss per 100 training steps: 0.22671090240155967\n","Training loss per 100 training steps: 0.2075744604100724\n","Training loss per 100 training steps: 0.19389019865610835\n","Training loss per 100 training steps: 0.18376684169711469\n","Training loss per 100 training steps: 0.17605368518613548\n","Training loss per 100 training steps: 0.16799420274620447\n","Training loss epoch: 0.16358022573475656\n","Training accuracy epoch: 0.9487939918106123\n","Validating model...\n","Validation Loss: 0.16017830974192587\n","Validation Accuracy: 0.9508741853658659\n","Training epoch: 2\n","Training loss per 100 training steps: 0.10189007222652435\n","Training loss per 100 training steps: 0.06323564646415192\n","Training loss per 100 training steps: 0.06641808082697107\n","Training loss per 100 training steps: 0.06363904989012006\n","Training loss per 100 training steps: 0.06198911408910022\n","Training loss per 100 training steps: 0.060204781689485926\n","Training loss per 100 training steps: 0.05925420422134874\n","Training loss per 100 training steps: 0.058240480566219284\n","Training loss per 100 training steps: 0.058350407531526816\n","Training loss per 100 training steps: 0.05817304400558667\n","Training loss epoch: 0.05816795384917313\n","Training accuracy epoch: 0.9820126916904504\n","Validating model...\n","Validation Loss: 0.15153722855709978\n","Validation Accuracy: 0.9585599843565338\n","Training epoch: 3\n","Training loss per 100 training steps: 0.1093386709690094\n","Training loss per 100 training steps: 0.028517727064669575\n","Training loss per 100 training steps: 0.028811946629421478\n","Training loss per 100 training steps: 0.030262053061966658\n","Training loss per 100 training steps: 0.032019357359271375\n","Training loss per 100 training steps: 0.03163231522176682\n","Training loss per 100 training steps: 0.03234286717555258\n","Training loss per 100 training steps: 0.033187074727742814\n","Training loss per 100 training steps: 0.03386713783143346\n","Training loss per 100 training steps: 0.033908607756184594\n","Training loss epoch: 0.03422332188054824\n","Training accuracy epoch: 0.9893434052562867\n","Validating model...\n","Validation Loss: 0.18478930971355406\n","Validation Accuracy: 0.9552519717217156\n","Training epoch: 4\n","Training loss per 100 training steps: 0.007406278513371944\n","Training loss per 100 training steps: 0.0213126388774945\n","Training loss per 100 training steps: 0.02781701947339991\n","Training loss per 100 training steps: 0.029152005250284146\n","Training loss per 100 training steps: 0.028841270287137972\n","Training loss per 100 training steps: 0.030317003386533873\n","Training loss per 100 training steps: 0.02987996575694931\n","Training loss per 100 training steps: 0.029852003772917753\n","Training loss per 100 training steps: 0.02916562072846971\n","Training loss per 100 training steps: 0.028764270559969107\n","Training loss epoch: 0.028558497802945428\n","Training accuracy epoch: 0.991274264748403\n","Validating model...\n","Validation Loss: 0.18179318045761872\n","Validation Accuracy: 0.9573550959327175\n","Training epoch: 5\n","Training loss per 100 training steps: 0.01085381768643856\n","Training loss per 100 training steps: 0.021701733761531585\n","Training loss per 100 training steps: 0.020268766961549292\n","Training loss per 100 training steps: 0.020160855307318024\n","Training loss per 100 training steps: 0.019385599768999267\n","Training loss per 100 training steps: 0.01933595707139071\n","Training loss per 100 training steps: 0.01918434614459744\n","Training loss per 100 training steps: 0.01919038229622445\n","Training loss per 100 training steps: 0.01991457736697926\n","Training loss per 100 training steps: 0.020537538304412014\n","Training loss epoch: 0.020307918582499647\n","Training accuracy epoch: 0.9938665640821472\n","Validating model...\n","Validation Loss: 0.24386262893676758\n","Validation Accuracy: 0.9535710896917508\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0010480640921741724\n","Training loss per 100 training steps: 0.016881526285312184\n","Training loss per 100 training steps: 0.015812146821724184\n","Training loss per 100 training steps: 0.015037990345411154\n","Training loss per 100 training steps: 0.01677196177377736\n","Training loss per 100 training steps: 0.017032382022381477\n","Training loss per 100 training steps: 0.01754222505707228\n","Training loss per 100 training steps: 0.017178664092696406\n","Training loss per 100 training steps: 0.017663692993287912\n","Training loss per 100 training steps: 0.018153217206119256\n","Training loss epoch: 0.018043599626488195\n","Training accuracy epoch: 0.9946304168923362\n","Validating model...\n","Validation Loss: 0.2127407779312366\n","Validation Accuracy: 0.9553614538435372\n","Training epoch: 7\n","Training loss per 100 training steps: 0.00704673258587718\n","Training loss per 100 training steps: 0.009664119115516562\n","Training loss per 100 training steps: 0.011320012255684143\n","Training loss per 100 training steps: 0.011898725403127017\n","Training loss per 100 training steps: 0.011506250933839817\n","Training loss per 100 training steps: 0.013047463836335668\n","Training loss per 100 training steps: 0.013463349296731143\n","Training loss per 100 training steps: 0.013617443846148065\n","Training loss per 100 training steps: 0.014215696198512892\n","Training loss per 100 training steps: 0.015079267034369142\n","Training loss epoch: 0.014960066509874873\n","Training accuracy epoch: 0.9955212979025724\n","Validating model...\n","Validation Loss: 0.2189260528652699\n","Validation Accuracy: 0.9587364815903133\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 73.70378904999998 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.16885483544212077\n","Validation Accuracy: 0.9535188455801019\n","Validation duration: 3.1275713333333743 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 83.8%\n","              precision    recall  f1-score   support\n","\n","     problem       0.83      0.85      0.84     12546\n","        test       0.81      0.88      0.85      9012\n","   treatment       0.82      0.84      0.83      9297\n","\n","   micro avg       0.82      0.86      0.84     30855\n","   macro avg       0.82      0.86      0.84     30855\n","weighted avg       0.82      0.86      0.84     30855\n","\n","!!!!!! Starting model number 9 !!!!!!\n","Points in X_train after augmentation: 31200\n","Points in y_train after augmentation: 31200\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9626251459121704\n","Training loss per 100 training steps: 0.4018428867111112\n","Training loss per 100 training steps: 0.3051728627723248\n","Training loss per 100 training steps: 0.2605028321898459\n","Training loss per 100 training steps: 0.23262474585575355\n","Training loss per 100 training steps: 0.21282799266085414\n","Training loss per 100 training steps: 0.1990010703227385\n","Training loss per 100 training steps: 0.1899225011457305\n","Training loss per 100 training steps: 0.17904962927158852\n","Training loss per 100 training steps: 0.17138791412784904\n","Training loss epoch: 0.1656331426707598\n","Training accuracy epoch: 0.9481226166818977\n","Validating model...\n","Validation Loss: 0.14522232606329702\n","Validation Accuracy: 0.9559372470717373\n","Training epoch: 2\n","Training loss per 100 training steps: 0.02912573330104351\n","Training loss per 100 training steps: 0.06291644769434881\n","Training loss per 100 training steps: 0.06322627794460871\n","Training loss per 100 training steps: 0.061948203543615694\n","Training loss per 100 training steps: 0.0656255528172873\n","Training loss per 100 training steps: 0.06606593648131617\n","Training loss per 100 training steps: 0.06687217407368631\n","Training loss per 100 training steps: 0.06848792126070118\n","Training loss per 100 training steps: 0.0673394420122572\n","Training loss per 100 training steps: 0.06635931685523488\n","Training loss epoch: 0.06574643270184215\n","Training accuracy epoch: 0.9798188751389655\n","Validating model...\n","Validation Loss: 0.15359418571914557\n","Validation Accuracy: 0.9557297265923504\n","Training epoch: 3\n","Training loss per 100 training steps: 0.009404841810464859\n","Training loss per 100 training steps: 0.03364913036014036\n","Training loss per 100 training steps: 0.03420608973163018\n","Training loss per 100 training steps: 0.03458420929972367\n","Training loss per 100 training steps: 0.0363039892617418\n","Training loss per 100 training steps: 0.035521081151271575\n","Training loss per 100 training steps: 0.03721042366186234\n","Training loss per 100 training steps: 0.03739262209423338\n","Training loss per 100 training steps: 0.0376037935156331\n","Training loss per 100 training steps: 0.03807557142144803\n","Training loss epoch: 0.03821042368678042\n","Training accuracy epoch: 0.9883970835362794\n","Validating model...\n","Validation Loss: 0.18560421653091908\n","Validation Accuracy: 0.9558638535520587\n","Training epoch: 4\n","Training loss per 100 training steps: 0.026939718052744865\n","Training loss per 100 training steps: 0.02381733052967356\n","Training loss per 100 training steps: 0.023140990865111018\n","Training loss per 100 training steps: 0.022221246885872164\n","Training loss per 100 training steps: 0.022995872215043865\n","Training loss per 100 training steps: 0.02416048113067547\n","Training loss per 100 training steps: 0.024267857119200067\n","Training loss per 100 training steps: 0.024799827707897522\n","Training loss per 100 training steps: 0.025054941892367524\n","Training loss per 100 training steps: 0.025599123120680554\n","Training loss epoch: 0.0266530069293908\n","Training accuracy epoch: 0.9919878576548414\n","Validating model...\n","Validation Loss: 0.20268166481287447\n","Validation Accuracy: 0.9489622241340657\n","Training epoch: 5\n","Training loss per 100 training steps: 0.01803792081773281\n","Training loss per 100 training steps: 0.02570921341349177\n","Training loss per 100 training steps: 0.023070788732034834\n","Training loss per 100 training steps: 0.022053778088192123\n","Training loss per 100 training steps: 0.021718975181222202\n","Training loss per 100 training steps: 0.02261021927623227\n","Training loss per 100 training steps: 0.022229868671541086\n","Training loss per 100 training steps: 0.022338353792235678\n","Training loss per 100 training steps: 0.023428272300673948\n","Training loss per 100 training steps: 0.024176392756674086\n","Training loss epoch: 0.023804733583626028\n","Training accuracy epoch: 0.9927390890895224\n","Validating model...\n","Validation Loss: 0.19334007751245003\n","Validation Accuracy: 0.9597473657346807\n","Training epoch: 6\n","Training loss per 100 training steps: 0.017191912978887558\n","Training loss per 100 training steps: 0.013310275644543443\n","Training loss per 100 training steps: 0.013622948988479799\n","Training loss per 100 training steps: 0.012500007606000852\n","Training loss per 100 training steps: 0.014434683099119086\n","Training loss per 100 training steps: 0.015007764928773912\n","Training loss per 100 training steps: 0.015226387945338914\n","Training loss per 100 training steps: 0.015508995635551899\n","Training loss per 100 training steps: 0.016726940614854413\n","Training loss per 100 training steps: 0.017148908424141046\n","Training loss epoch: 0.017377797499693072\n","Training accuracy epoch: 0.9947697534362167\n","Validating model...\n","Validation Loss: 0.22598310661586848\n","Validation Accuracy: 0.955345727393184\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 63.200642466666736 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.15763724765619608\n","Validation Accuracy: 0.9524251837277414\n","Validation duration: 3.123272766666681 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 83.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.78      0.87      0.82     12546\n","        test       0.83      0.87      0.85      9012\n","   treatment       0.81      0.85      0.83      9297\n","\n","   micro avg       0.81      0.86      0.83     30855\n","   macro avg       0.81      0.86      0.83     30855\n","weighted avg       0.81      0.86      0.83     30855\n","\n","!!!!!! Starting model number 10 !!!!!!\n","Points in X_train after augmentation: 31200\n","Points in y_train after augmentation: 31200\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0850789546966553\n","Training loss per 100 training steps: 0.4084156117964499\n","Training loss per 100 training steps: 0.3053013255161729\n","Training loss per 100 training steps: 0.256966936244224\n","Training loss per 100 training steps: 0.2299779586939889\n","Training loss per 100 training steps: 0.20790579697923983\n","Training loss per 100 training steps: 0.19398962957366137\n","Training loss per 100 training steps: 0.18348841064114033\n","Training loss per 100 training steps: 0.17469363942853966\n","Training loss per 100 training steps: 0.16645441003367056\n","Training loss epoch: 0.16113490642836462\n","Training accuracy epoch: 0.9496910200860186\n","Validating model...\n","Validation Loss: 0.15203850617172657\n","Validation Accuracy: 0.9542022541140842\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04256033897399902\n","Training loss per 100 training steps: 0.05009074990019793\n","Training loss per 100 training steps: 0.05477807964360462\n","Training loss per 100 training steps: 0.059173120984009335\n","Training loss per 100 training steps: 0.06052389902589922\n","Training loss per 100 training steps: 0.0603731088990907\n","Training loss per 100 training steps: 0.06110062469695749\n","Training loss per 100 training steps: 0.06031543328446707\n","Training loss per 100 training steps: 0.05988307614181744\n","Training loss per 100 training steps: 0.059823199917462044\n","Training loss epoch: 0.05947649718954777\n","Training accuracy epoch: 0.981650826798372\n","Validating model...\n","Validation Loss: 0.16750770579878385\n","Validation Accuracy: 0.9517091637152013\n","Training epoch: 3\n","Training loss per 100 training steps: 0.017511259764432907\n","Training loss per 100 training steps: 0.03249874623667559\n","Training loss per 100 training steps: 0.03255129388107256\n","Training loss per 100 training steps: 0.03216165120781483\n","Training loss per 100 training steps: 0.03305455024163715\n","Training loss per 100 training steps: 0.03450144905254929\n","Training loss per 100 training steps: 0.03451545411463635\n","Training loss per 100 training steps: 0.03516174551729278\n","Training loss per 100 training steps: 0.03654540386213718\n","Training loss per 100 training steps: 0.03663555293919707\n","Training loss epoch: 0.036738121376540034\n","Training accuracy epoch: 0.9887319737873367\n","Validating model...\n","Validation Loss: 0.1861742679513507\n","Validation Accuracy: 0.9502351556356897\n","Training epoch: 4\n","Training loss per 100 training steps: 0.024192873388528824\n","Training loss per 100 training steps: 0.023276669495407087\n","Training loss per 100 training steps: 0.025592814698880213\n","Training loss per 100 training steps: 0.0272245529402462\n","Training loss per 100 training steps: 0.026466596505240053\n","Training loss per 100 training steps: 0.02663207295566366\n","Training loss per 100 training steps: 0.026718336370961118\n","Training loss per 100 training steps: 0.026955735253584644\n","Training loss per 100 training steps: 0.02688135243702294\n","Training loss per 100 training steps: 0.02614295172074047\n","Training loss epoch: 0.025849267582600123\n","Training accuracy epoch: 0.9923129596537417\n","Validating model...\n","Validation Loss: 0.20316571835428476\n","Validation Accuracy: 0.9567351929391035\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0067128282971680164\n","Training loss per 100 training steps: 0.015248536396659865\n","Training loss per 100 training steps: 0.01431650773612539\n","Training loss per 100 training steps: 0.01580228795605113\n","Training loss per 100 training steps: 0.017541750809989178\n","Training loss per 100 training steps: 0.018501817024964236\n","Training loss per 100 training steps: 0.019823311835219626\n","Training loss per 100 training steps: 0.019258145737715334\n","Training loss per 100 training steps: 0.01953763920544852\n","Training loss per 100 training steps: 0.020064811171008584\n","Training loss epoch: 0.020548177348518482\n","Training accuracy epoch: 0.9939004528208338\n","Validating model...\n","Validation Loss: 0.18835420318721952\n","Validation Accuracy: 0.9566235459588247\n","Training epoch: 6\n","Training loss per 100 training steps: 0.004421090707182884\n","Training loss per 100 training steps: 0.016933870797465084\n","Training loss per 100 training steps: 0.017610570336506697\n","Training loss per 100 training steps: 0.017278260709772016\n","Training loss per 100 training steps: 0.017905000161769755\n","Training loss per 100 training steps: 0.01660781223683022\n","Training loss per 100 training steps: 0.01618833171432592\n","Training loss per 100 training steps: 0.016742470961912885\n","Training loss per 100 training steps: 0.017028387409346975\n","Training loss per 100 training steps: 0.018004662205113566\n","Training loss epoch: 0.018211047499580905\n","Training accuracy epoch: 0.9943894260384185\n","Validating model...\n","Validation Loss: 0.21496676472197104\n","Validation Accuracy: 0.9552205776469828\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 63.359710733333365 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.16956763233476388\n","Validation Accuracy: 0.9492420787227707\n","Validation duration: 3.125553150000026 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 83.1%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.86      0.82     12546\n","        test       0.81      0.88      0.84      9012\n","   treatment       0.82      0.84      0.83      9297\n","\n","   micro avg       0.80      0.86      0.83     30855\n","   macro avg       0.81      0.86      0.83     30855\n","weighted avg       0.80      0.86      0.83     30855\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 2\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"Zjhn7-LqHri0"},{"cell_type":"code","execution_count":9,"metadata":{"id":"TTDq-xbgHqXQ","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["9210d842c1594f8a8ad3d30d6fad0a2a","4d41ee073a6b4f9bb6112d03c2666c70","19c686e869bf409d9ef70824a3c1913e","86f31acba0d64c9198aa0de1c22b0b43","45d3eff351424c35924a119ba4c2db06","7d99347b22734b029064dadd85f7555f","b22a0690c25c46139d1aee16937afc51","b6af09be8da74f87a9a48ab37dbe255f","d2dc5739ee5446c0a9e439769417ff78","901e562e03d041189bc873b3d5f5eebc","d337f2283fb240beb42fb3960abab836"]},"executionInfo":{"status":"ok","timestamp":1663346023705,"user_tz":240,"elapsed":7731129,"user":{"displayName":"Altigran Soares","userId":"17972430181076780193"}},"outputId":"c92750b8-8620-4c82-8f47-3b4b10c57286"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 500% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n","Points in X_train after augmentation: 62400\n","Points in y_train after augmentation: 62400\n","Device:  cuda\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9210d842c1594f8a8ad3d30d6fad0a2a","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.2121124267578125\n","Training loss per 100 training steps: 0.3807277767227428\n","Training loss per 100 training steps: 0.28263013461484243\n","Training loss per 100 training steps: 0.23412666681448485\n","Training loss per 100 training steps: 0.2136439014124008\n","Training loss per 100 training steps: 0.19549397366891008\n","Training loss per 100 training steps: 0.18390980289440087\n","Training loss per 100 training steps: 0.1739295965908215\n","Training loss per 100 training steps: 0.16566158902974387\n","Training loss per 100 training steps: 0.15844274554132887\n","Training loss per 100 training steps: 0.15230378492472024\n","Training loss per 100 training steps: 0.14787898167373983\n","Training loss per 100 training steps: 0.14251109707300286\n","Training loss per 100 training steps: 0.13820412712061433\n","Training loss per 100 training steps: 0.1343179744795273\n","Training loss per 100 training steps: 0.13028440303321207\n","Training loss per 100 training steps: 0.12680675775664327\n","Training loss per 100 training steps: 0.1235922656368589\n","Training loss per 100 training steps: 0.12099061724701395\n","Training loss per 100 training steps: 0.11863082724313267\n","Training loss epoch: 0.11730165289977613\n","Training accuracy epoch: 0.963789068157773\n","Validating model...\n","Validation Loss: 0.162335161555123\n","Validation Accuracy: 0.9520939796351862\n","Training epoch: 2\n","Training loss per 100 training steps: 0.021258750930428505\n","Training loss per 100 training steps: 0.038981424195064916\n","Training loss per 100 training steps: 0.0449095513551167\n","Training loss per 100 training steps: 0.04258326235988434\n","Training loss per 100 training steps: 0.042453686717173034\n","Training loss per 100 training steps: 0.04314072363165964\n","Training loss per 100 training steps: 0.04289647183201265\n","Training loss per 100 training steps: 0.04264572912065868\n","Training loss per 100 training steps: 0.042199508480892774\n","Training loss per 100 training steps: 0.04191114473002616\n","Training loss per 100 training steps: 0.04163809209507513\n","Training loss per 100 training steps: 0.04150869718331549\n","Training loss per 100 training steps: 0.041028298147574846\n","Training loss per 100 training steps: 0.04136108027965827\n","Training loss per 100 training steps: 0.041226430506918106\n","Training loss per 100 training steps: 0.040993909120403335\n","Training loss per 100 training steps: 0.04069354054375524\n","Training loss per 100 training steps: 0.040808980551992884\n","Training loss per 100 training steps: 0.04087626515712635\n","Training loss per 100 training steps: 0.04074189707171172\n","Stopping epoch...\n","Training loss epoch: 0.04074189707171172\n","Training accuracy epoch: 0.9869360948850048\n","Validating model...\n","Validation Loss: 0.18977719342166727\n","Validation Accuracy: 0.9541266442159881\n","Training epoch: 3\n","Training loss per 100 training steps: 0.006345347501337528\n","Training loss per 100 training steps: 0.02286805261426725\n","Training loss per 100 training steps: 0.022335779562706024\n","Training loss per 100 training steps: 0.023667791782703524\n","Training loss per 100 training steps: 0.024113529899298096\n","Training loss per 100 training steps: 0.024789986215850632\n","Training loss per 100 training steps: 0.02532122419581837\n","Training loss per 100 training steps: 0.025480096401881223\n","Training loss per 100 training steps: 0.02588856712365337\n","Training loss per 100 training steps: 0.02605618031125166\n","Training loss per 100 training steps: 0.02584562507186124\n","Training loss per 100 training steps: 0.025878257278196908\n","Training loss per 100 training steps: 0.026089673881877686\n","Stopping epoch...\n","Training loss epoch: 0.026089673881877686\n","Training accuracy epoch: 0.9913965610467484\n","Validating model...\n","Validation Loss: 0.2076887890890047\n","Validation Accuracy: 0.9512122895785908\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0034032694529742002\n","Training loss per 100 training steps: 0.019119418471692\n","Training loss per 100 training steps: 0.023279355201796068\n","Training loss per 100 training steps: 0.022913915541431438\n","Training loss per 100 training steps: 0.02169408309424384\n","Training loss per 100 training steps: 0.022248291986773232\n","Training loss per 100 training steps: 0.02271956295439797\n","Training loss per 100 training steps: 0.023058440262908795\n","Training loss per 100 training steps: 0.02348013491876721\n","Training loss per 100 training steps: 0.023056117545520796\n","Training loss per 100 training steps: 0.023105731725259652\n","Training loss per 100 training steps: 0.022944945838221167\n","Training loss per 100 training steps: 0.023205004854253388\n","Training loss per 100 training steps: 0.023244189161472282\n","Training loss per 100 training steps: 0.0234042310477836\n","Training loss per 100 training steps: 0.02339927477460866\n","Training loss per 100 training steps: 0.02319086793666737\n","Stopping epoch...\n","Training loss epoch: 0.02319086793666737\n","Training accuracy epoch: 0.9922812833549268\n","Validating model...\n","Validation Loss: 0.22535535654464325\n","Validation Accuracy: 0.9515998290694339\n","Training epoch: 5\n","Training loss per 100 training steps: 0.004416731186211109\n","Training loss per 100 training steps: 0.014446813826988645\n","Training loss per 100 training steps: 0.013600962460521766\n","Training loss per 100 training steps: 0.013897258900121424\n","Training loss per 100 training steps: 0.015767254894094175\n","Training loss per 100 training steps: 0.01565388087954692\n","Training loss per 100 training steps: 0.016169704584995233\n","Training loss per 100 training steps: 0.01700513275870296\n","Training loss per 100 training steps: 0.017291457381447693\n","Training loss per 100 training steps: 0.017674912634092724\n","Training loss per 100 training steps: 0.017503370227537337\n","Training loss per 100 training steps: 0.017624361801574888\n","Training loss per 100 training steps: 0.01748608348804482\n","Training loss per 100 training steps: 0.017570468777866544\n","Training loss per 100 training steps: 0.01778448399212504\n","Training loss per 100 training steps: 0.018157219111722096\n","Training loss per 100 training steps: 0.018383609379479124\n","Training loss per 100 training steps: 0.018890360594451424\n","Training loss per 100 training steps: 0.019281552604761342\n","Training loss per 100 training steps: 0.01924524319362824\n","Training loss epoch: 0.019257233211358724\n","Training accuracy epoch: 0.9942835415280392\n","Validating model...\n","Validation Loss: 0.21969654009520234\n","Validation Accuracy: 0.9536561217064995\n","Training epoch: 6\n","Training loss per 100 training steps: 0.005268444772809744\n","Training loss per 100 training steps: 0.01318220225552392\n","Training loss per 100 training steps: 0.012499124373092701\n","Training loss per 100 training steps: 0.012072615187715328\n","Training loss per 100 training steps: 0.011609870790899614\n","Training loss per 100 training steps: 0.01154060702959281\n","Training loss per 100 training steps: 0.012016577276285193\n","Training loss per 100 training steps: 0.012405792244856335\n","Training loss per 100 training steps: 0.012692212995704055\n","Training loss per 100 training steps: 0.013344274212975913\n","Training loss per 100 training steps: 0.013747961324008464\n","Training loss per 100 training steps: 0.01379476098138232\n","Training loss per 100 training steps: 0.014183480924300808\n","Training loss per 100 training steps: 0.014213139071398333\n","Training loss per 100 training steps: 0.01417272407857149\n","Training loss per 100 training steps: 0.014172986939672842\n","Training loss per 100 training steps: 0.014173800686516753\n","Stopping epoch...\n","Training loss epoch: 0.014173800686516753\n","Training accuracy epoch: 0.9951245775613159\n","Validating model...\n","Validation Loss: 0.22984203691412877\n","Validation Accuracy: 0.9535976894538887\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 105.68782695 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1830427931040672\n","Validation Accuracy: 0.9484902056548593\n","Validation duration: 3.023608416666669 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 82.1%\n","              precision    recall  f1-score   support\n","\n","     problem       0.78      0.84      0.81     12546\n","        test       0.82      0.85      0.84      9012\n","   treatment       0.83      0.82      0.82      9297\n","\n","   micro avg       0.80      0.84      0.82     30855\n","   macro avg       0.81      0.84      0.82     30855\n","weighted avg       0.81      0.84      0.82     30855\n","\n","!!!!!! Starting model number 2 !!!!!!\n","Points in X_train after augmentation: 62400\n","Points in y_train after augmentation: 62400\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9609220027923584\n","Training loss per 100 training steps: 0.3786202579146565\n","Training loss per 100 training steps: 0.28163301403546215\n","Training loss per 100 training steps: 0.2407784484995164\n","Training loss per 100 training steps: 0.21515662423764678\n","Training loss per 100 training steps: 0.19854906875781433\n","Training loss per 100 training steps: 0.18676869296616008\n","Training loss per 100 training steps: 0.17539960903496868\n","Training loss per 100 training steps: 0.16681132427929493\n","Training loss per 100 training steps: 0.1591142350446007\n","Training loss per 100 training steps: 0.15213165502366308\n","Training loss per 100 training steps: 0.1465721751261269\n","Training loss per 100 training steps: 0.142132790650642\n","Training loss per 100 training steps: 0.13729028256723141\n","Training loss per 100 training steps: 0.1332590864289241\n","Training loss per 100 training steps: 0.1294905280627355\n","Training loss per 100 training steps: 0.12597758414108612\n","Training loss per 100 training steps: 0.12272218202154805\n","Training loss per 100 training steps: 0.11976833724422481\n","Training loss per 100 training steps: 0.11685433770127708\n","Training loss epoch: 0.11551176697135163\n","Training accuracy epoch: 0.9640496046661711\n","Validating model...\n","Validation Loss: 0.1724953344696528\n","Validation Accuracy: 0.95302603578329\n","Training epoch: 2\n","Training loss per 100 training steps: 0.03898973390460014\n","Training loss per 100 training steps: 0.04287513177426956\n","Training loss per 100 training steps: 0.04079153001035068\n","Training loss per 100 training steps: 0.045983648819514736\n","Training loss per 100 training steps: 0.0461943565555465\n","Training loss per 100 training steps: 0.046334553174878994\n","Training loss per 100 training steps: 0.04664563356484976\n","Training loss per 100 training steps: 0.04637188396115021\n","Training loss per 100 training steps: 0.04567705315029651\n","Training loss per 100 training steps: 0.04471751183636288\n","Training loss per 100 training steps: 0.04466221135385989\n","Training loss per 100 training steps: 0.04444320982454901\n","Training loss per 100 training steps: 0.04413918842449877\n","Training loss per 100 training steps: 0.04364796184546684\n","Training loss per 100 training steps: 0.04389551251134213\n","Training loss per 100 training steps: 0.04421655545467207\n","Training loss per 100 training steps: 0.043803845978994095\n","Training loss per 100 training steps: 0.04335035530572154\n","Training loss per 100 training steps: 0.0432095843926279\n","Training loss per 100 training steps: 0.042931002708517414\n","Training loss epoch: 0.04267050485705766\n","Training accuracy epoch: 0.9869966710750018\n","Validating model...\n","Validation Loss: 0.1803649945620012\n","Validation Accuracy: 0.9547426209993986\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03926408663392067\n","Training loss per 100 training steps: 0.022760186723599415\n","Training loss per 100 training steps: 0.024327088312468312\n","Training loss per 100 training steps: 0.02255977399877746\n","Training loss per 100 training steps: 0.022354736090974506\n","Training loss per 100 training steps: 0.024175745333282803\n","Training loss per 100 training steps: 0.024151144212789015\n","Training loss per 100 training steps: 0.024109481411890395\n","Training loss per 100 training steps: 0.024152505896216987\n","Training loss per 100 training steps: 0.02424669159745816\n","Stopping epoch...\n","Training loss epoch: 0.02424669159745816\n","Training accuracy epoch: 0.9913669072360277\n","Validating model...\n","Validation Loss: 0.19219569472426717\n","Validation Accuracy: 0.9514231562617138\n","Training epoch: 4\n","Training loss per 100 training steps: 0.008613135665655136\n","Training loss per 100 training steps: 0.022546909270591407\n","Training loss per 100 training steps: 0.020814555971964323\n","Training loss per 100 training steps: 0.02204368612322913\n","Training loss per 100 training steps: 0.022123329558420203\n","Training loss per 100 training steps: 0.022399986905655537\n","Training loss per 100 training steps: 0.02236700120113539\n","Training loss per 100 training steps: 0.02217974474319136\n","Training loss per 100 training steps: 0.021385454844917984\n","Training loss per 100 training steps: 0.021651736636508875\n","Training loss per 100 training steps: 0.021212412211498558\n","Training loss per 100 training steps: 0.02123205389769441\n","Training loss per 100 training steps: 0.021580660996583876\n","Training loss per 100 training steps: 0.02199207709412388\n","Training loss per 100 training steps: 0.022284345918067956\n","Training loss per 100 training steps: 0.022187509725875017\n","Training loss per 100 training steps: 0.02220652591728903\n","Training loss per 100 training steps: 0.023177382504493728\n","Training loss per 100 training steps: 0.023215660977160903\n","Training loss per 100 training steps: 0.023468186226524614\n","Training loss epoch: 0.023436988787770344\n","Training accuracy epoch: 0.9929047368033237\n","Validating model...\n","Validation Loss: 0.2038649261094533\n","Validation Accuracy: 0.9507419753158404\n","Training epoch: 5\n","Training loss per 100 training steps: 0.009424900636076927\n","Training loss per 100 training steps: 0.014656574339121764\n","Training loss per 100 training steps: 0.013793712024810372\n","Training loss per 100 training steps: 0.0136035897182993\n","Training loss per 100 training steps: 0.014263636424132748\n","Training loss per 100 training steps: 0.01425512546888704\n","Training loss per 100 training steps: 0.016173360067189783\n","Training loss per 100 training steps: 0.016600652138348677\n","Training loss per 100 training steps: 0.016930212366898876\n","Training loss per 100 training steps: 0.016988280094200905\n","Training loss per 100 training steps: 0.017717326809150318\n","Training loss per 100 training steps: 0.017881289377211056\n","Training loss per 100 training steps: 0.01859372373024821\n","Training loss per 100 training steps: 0.0188927324305434\n","Training loss per 100 training steps: 0.018933145541049686\n","Training loss per 100 training steps: 0.018867696887015197\n","Training loss per 100 training steps: 0.018708010798056295\n","Training loss per 100 training steps: 0.018752973553638558\n","Training loss per 100 training steps: 0.01900187805746011\n","Training loss per 100 training steps: 0.018887396298113684\n","Training loss epoch: 0.01888139261018622\n","Training accuracy epoch: 0.9942540349907026\n","Validating model...\n","Validation Loss: 0.2131644341272193\n","Validation Accuracy: 0.9531679640589825\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0038886000402271748\n","Training loss per 100 training steps: 0.010086409516787008\n","Training loss per 100 training steps: 0.010210849026615374\n","Training loss per 100 training steps: 0.010237425155461954\n","Training loss per 100 training steps: 0.0103439513290971\n","Training loss per 100 training steps: 0.010701457909777752\n","Training loss per 100 training steps: 0.011342221622013591\n","Training loss per 100 training steps: 0.012045635326802678\n","Training loss per 100 training steps: 0.012532927615035525\n","Training loss per 100 training steps: 0.01303305075703898\n","Training loss per 100 training steps: 0.013341233534774474\n","Training loss per 100 training steps: 0.013827401840283013\n","Training loss per 100 training steps: 0.014590089612832948\n","Training loss per 100 training steps: 0.014677042914966985\n","Training loss per 100 training steps: 0.014640573280537568\n","Training loss per 100 training steps: 0.01465196137158771\n","Training loss per 100 training steps: 0.014658100018539535\n","Stopping epoch...\n","Training loss epoch: 0.014658100018539535\n","Training accuracy epoch: 0.995037197636678\n","Validating model...\n","Validation Loss: 0.2057347306376928\n","Validation Accuracy: 0.953921564583265\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 106.49703366666667 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.18958130938537782\n","Validation Accuracy: 0.9493958419690054\n","Validation duration: 3.02440193333332 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 82.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.78      0.86      0.82     12546\n","        test       0.81      0.85      0.83      9012\n","   treatment       0.82      0.84      0.83      9297\n","\n","   micro avg       0.80      0.85      0.83     30855\n","   macro avg       0.81      0.85      0.83     30855\n","weighted avg       0.80      0.85      0.83     30855\n","\n","!!!!!! Starting model number 3 !!!!!!\n","Points in X_train after augmentation: 62400\n","Points in y_train after augmentation: 62400\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.771616816520691\n","Training loss per 100 training steps: 0.38970243052975967\n","Training loss per 100 training steps: 0.2936060566325389\n","Training loss per 100 training steps: 0.2485260419002997\n","Training loss per 100 training steps: 0.22076313867421815\n","Training loss per 100 training steps: 0.19960328169955227\n","Training loss per 100 training steps: 0.18636484437632977\n","Training loss per 100 training steps: 0.1752397829478078\n","Training loss per 100 training steps: 0.16604316949416487\n","Training loss per 100 training steps: 0.15879413496897238\n","Training loss per 100 training steps: 0.1522037494968582\n","Training loss per 100 training steps: 0.14645956543956856\n","Training loss per 100 training steps: 0.14134804408479293\n","Training loss per 100 training steps: 0.13654366587872097\n","Training loss per 100 training steps: 0.1326316756593179\n","Training loss per 100 training steps: 0.1285249517714328\n","Training loss per 100 training steps: 0.12528696103192527\n","Training loss per 100 training steps: 0.1224824717853641\n","Training loss per 100 training steps: 0.11939321804832023\n","Training loss per 100 training steps: 0.11678559094939826\n","Training loss epoch: 0.11570944759278343\n","Training accuracy epoch: 0.9641174960068364\n","Validating model...\n","Validation Loss: 0.15846305964635565\n","Validation Accuracy: 0.9519867855861546\n","Training epoch: 2\n","Training loss per 100 training steps: 0.013314015232026577\n","Training loss per 100 training steps: 0.04014798651661466\n","Training loss per 100 training steps: 0.04108640524577257\n","Training loss per 100 training steps: 0.04094444962212215\n","Training loss per 100 training steps: 0.04064333440266791\n","Training loss per 100 training steps: 0.04183052905357467\n","Training loss per 100 training steps: 0.04216799265650812\n","Training loss per 100 training steps: 0.04199750334411041\n","Training loss per 100 training steps: 0.041609270508620844\n","Training loss per 100 training steps: 0.0414849178721874\n","Training loss per 100 training steps: 0.04184837723904467\n","Training loss per 100 training steps: 0.04214320629395267\n","Training loss per 100 training steps: 0.0419028142919232\n","Training loss per 100 training steps: 0.04166760728379524\n","Training loss per 100 training steps: 0.04126065212709405\n","Training loss per 100 training steps: 0.04114644485510275\n","Training loss per 100 training steps: 0.04094129802410763\n","Training loss per 100 training steps: 0.040824879053651605\n","Training loss per 100 training steps: 0.04063147405030072\n","Training loss per 100 training steps: 0.04041478561011115\n","Training loss epoch: 0.04058125988938487\n","Training accuracy epoch: 0.9876000005534074\n","Validating model...\n","Validation Loss: 0.1758197085665805\n","Validation Accuracy: 0.9508521589227055\n","Training epoch: 3\n","Training loss per 100 training steps: 0.015550400130450726\n","Training loss per 100 training steps: 0.026208964133828803\n","Training loss per 100 training steps: 0.026835218936075173\n","Training loss per 100 training steps: 0.027241234698733532\n","Training loss per 100 training steps: 0.02631314182111139\n","Training loss per 100 training steps: 0.025722158055807354\n","Training loss per 100 training steps: 0.02482365513008906\n","Training loss per 100 training steps: 0.024896280568016006\n","Training loss per 100 training steps: 0.024840537099383966\n","Training loss per 100 training steps: 0.024782369016141493\n","Training loss per 100 training steps: 0.025188761719778834\n","Training loss per 100 training steps: 0.025486411618366567\n","Training loss per 100 training steps: 0.026141246073537325\n","Training loss per 100 training steps: 0.026258326892499066\n","Training loss per 100 training steps: 0.0264129697611598\n","Training loss per 100 training steps: 0.02641724361946557\n","Training loss per 100 training steps: 0.026332684046240392\n","Training loss per 100 training steps: 0.02653873449592232\n","Training loss per 100 training steps: 0.02688248558552974\n","Training loss per 100 training steps: 0.027024864889696038\n","Training loss epoch: 0.027024717211711388\n","Training accuracy epoch: 0.9918602306567197\n","Validating model...\n","Validation Loss: 0.21497546410937976\n","Validation Accuracy: 0.9495764572741102\n","Training epoch: 4\n","Training loss per 100 training steps: 0.033967312425374985\n","Training loss per 100 training steps: 0.015146950652850516\n","Training loss per 100 training steps: 0.014499161860862728\n","Training loss per 100 training steps: 0.015546965076989553\n","Training loss per 100 training steps: 0.015666905497569484\n","Training loss per 100 training steps: 0.015737046284948247\n","Training loss per 100 training steps: 0.016355779508317427\n","Training loss per 100 training steps: 0.01762239283050235\n","Training loss per 100 training steps: 0.018170102367349977\n","Training loss per 100 training steps: 0.01822863800839943\n","Training loss per 100 training steps: 0.018540304283772898\n","Training loss per 100 training steps: 0.018604883327617054\n","Training loss per 100 training steps: 0.01855670267641025\n","Training loss per 100 training steps: 0.018784948680820094\n","Training loss per 100 training steps: 0.01851845353699358\n","Training loss per 100 training steps: 0.018462480026698095\n","Training loss per 100 training steps: 0.018843958359010992\n","Training loss per 100 training steps: 0.01910426330449895\n","Training loss per 100 training steps: 0.019116207150795934\n","Training loss per 100 training steps: 0.018979812957274668\n","Training loss epoch: 0.018952467762536774\n","Training accuracy epoch: 0.9942841835478505\n","Validating model...\n","Validation Loss: 0.21587880679055468\n","Validation Accuracy: 0.9518598872582545\n","Training epoch: 5\n","Training loss per 100 training steps: 0.009205888956785202\n","Training loss per 100 training steps: 0.013288531315831081\n","Training loss per 100 training steps: 0.014697233703006546\n","Training loss per 100 training steps: 0.014873027247719025\n","Training loss per 100 training steps: 0.015208101176758101\n","Training loss per 100 training steps: 0.015315354415783687\n","Training loss per 100 training steps: 0.015275930216397041\n","Training loss per 100 training steps: 0.015232379909184796\n","Training loss per 100 training steps: 0.01569756769453313\n","Training loss per 100 training steps: 0.015857358368513014\n","Training loss per 100 training steps: 0.015552554340375663\n","Training loss per 100 training steps: 0.015538785400939767\n","Training loss per 100 training steps: 0.015631818772520643\n","Training loss per 100 training steps: 0.01569935498533389\n","Training loss per 100 training steps: 0.015828619499750327\n","Training loss per 100 training steps: 0.0160303088597259\n","Training loss per 100 training steps: 0.015995336450768144\n","Training loss per 100 training steps: 0.01606386785729701\n","Training loss per 100 training steps: 0.016011616329618287\n","Training loss per 100 training steps: 0.016160035538653708\n","Training loss epoch: 0.016140518219699748\n","Training accuracy epoch: 0.9951007665304249\n","Validating model...\n","Validation Loss: 0.2536525701644359\n","Validation Accuracy: 0.9495363856613452\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0014932377962395549\n","Training loss per 100 training steps: 0.011731180287482641\n","Training loss per 100 training steps: 0.012304338597749308\n","Training loss per 100 training steps: 0.012054353517204047\n","Training loss per 100 training steps: 0.01206673763560577\n","Training loss per 100 training steps: 0.012485973909712199\n","Training loss per 100 training steps: 0.012049936403967084\n","Training loss per 100 training steps: 0.011873079597110994\n","Training loss per 100 training steps: 0.012169963729695142\n","Training loss per 100 training steps: 0.012175639810953568\n","Training loss per 100 training steps: 0.01231815750500979\n","Training loss per 100 training steps: 0.012187620217948484\n","Training loss per 100 training steps: 0.012348272741190545\n","Training loss per 100 training steps: 0.012775942075473319\n","Training loss per 100 training steps: 0.012959464757317603\n","Training loss per 100 training steps: 0.013222339044428284\n","Training loss per 100 training steps: 0.013454190495142642\n","Training loss per 100 training steps: 0.01358971833645114\n","Training loss per 100 training steps: 0.013808502430599615\n","Training loss per 100 training steps: 0.013942880518072768\n","Training loss epoch: 0.013919119851921912\n","Training accuracy epoch: 0.9957639802669958\n","Validating model...\n","Validation Loss: 0.25402970445136747\n","Validation Accuracy: 0.9509454527472653\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 120.74409545000002 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1733721079416918\n","Validation Accuracy: 0.9493753465591136\n","Validation duration: 3.0361253333333176 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 82.7%\n","              precision    recall  f1-score   support\n","\n","     problem       0.81      0.84      0.82     12546\n","        test       0.80      0.87      0.83      9012\n","   treatment       0.80      0.86      0.83      9297\n","\n","   micro avg       0.80      0.86      0.83     30855\n","   macro avg       0.80      0.86      0.83     30855\n","weighted avg       0.80      0.86      0.83     30855\n","\n","!!!!!! Starting model number 4 !!!!!!\n","Points in X_train after augmentation: 62400\n","Points in y_train after augmentation: 62400\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1361544132232666\n","Training loss per 100 training steps: 0.3845853355556431\n","Training loss per 100 training steps: 0.2805125927969591\n","Training loss per 100 training steps: 0.2398976993273659\n","Training loss per 100 training steps: 0.21489693073003072\n","Training loss per 100 training steps: 0.19815761350586028\n","Training loss per 100 training steps: 0.1843087162617935\n","Training loss per 100 training steps: 0.1741444032065326\n","Training loss per 100 training steps: 0.1649506316635381\n","Training loss per 100 training steps: 0.15712435960099846\n","Training loss per 100 training steps: 0.15279839619376384\n","Training loss per 100 training steps: 0.14660483270335425\n","Training loss per 100 training steps: 0.1415010585296871\n","Training loss per 100 training steps: 0.136917105318977\n","Training loss per 100 training steps: 0.13324463377499968\n","Training loss per 100 training steps: 0.13008259627087007\n","Training loss per 100 training steps: 0.12701904571159678\n","Training loss per 100 training steps: 0.12405340449018365\n","Training loss per 100 training steps: 0.12123444194086869\n","Training loss per 100 training steps: 0.1181704518833501\n","Training loss epoch: 0.11707490838108918\n","Training accuracy epoch: 0.9636875188694217\n","Validating model...\n","Validation Loss: 0.18610727893454687\n","Validation Accuracy: 0.9466171685632966\n","Training epoch: 2\n","Training loss per 100 training steps: 0.026708006858825684\n","Training loss per 100 training steps: 0.03993823062766823\n","Training loss per 100 training steps: 0.041202945013840996\n","Training loss per 100 training steps: 0.04126372079417555\n","Training loss per 100 training steps: 0.04255000976648209\n","Training loss per 100 training steps: 0.043802688997369\n","Training loss per 100 training steps: 0.04372854284692661\n","Training loss per 100 training steps: 0.04339332866997919\n","Training loss per 100 training steps: 0.042649603456365745\n","Training loss per 100 training steps: 0.042755725826359\n","Training loss per 100 training steps: 0.04210464874367145\n","Training loss per 100 training steps: 0.04165529777345795\n","Training loss per 100 training steps: 0.041625970081627044\n","Training loss per 100 training steps: 0.04111539320739274\n","Training loss per 100 training steps: 0.04122451241143104\n","Training loss per 100 training steps: 0.041894033821197295\n","Training loss per 100 training steps: 0.04206153392324342\n","Training loss per 100 training steps: 0.0418668806197413\n","Training loss per 100 training steps: 0.041953774938747176\n","Training loss per 100 training steps: 0.04178900650300934\n","Stopping epoch...\n","Training loss epoch: 0.04178900650300934\n","Training accuracy epoch: 0.9867221114410075\n","Validating model...\n","Validation Loss: 0.16691378952766006\n","Validation Accuracy: 0.9547814012626186\n","Training epoch: 3\n","Training loss per 100 training steps: 0.01227687206119299\n","Training loss per 100 training steps: 0.023677057524368463\n","Training loss per 100 training steps: 0.027516311496746406\n","Training loss per 100 training steps: 0.026517379037692426\n","Training loss per 100 training steps: 0.02571199715463793\n","Training loss per 100 training steps: 0.02660161378387243\n","Training loss per 100 training steps: 0.026895401803617786\n","Training loss per 100 training steps: 0.02736107590477103\n","Training loss per 100 training steps: 0.027527298221144286\n","Training loss per 100 training steps: 0.02771676792387182\n","Training loss per 100 training steps: 0.027535944816725725\n","Training loss per 100 training steps: 0.027211108560207385\n","Training loss per 100 training steps: 0.02722207678467009\n","Training loss per 100 training steps: 0.026955539145484368\n","Training loss per 100 training steps: 0.02681827538555852\n","Training loss per 100 training steps: 0.02669109410315015\n","Training loss per 100 training steps: 0.02658970649029855\n","Training loss per 100 training steps: 0.026423098860819907\n","Training loss per 100 training steps: 0.02645024217133602\n","Training loss per 100 training steps: 0.026252358293881946\n","Training loss epoch: 0.026200389370131187\n","Training accuracy epoch: 0.9919144798992849\n","Validating model...\n","Validation Loss: 0.22505002471243407\n","Validation Accuracy: 0.9488707632432474\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0027588880620896816\n","Training loss per 100 training steps: 0.021255042293860514\n","Training loss per 100 training steps: 0.021997402755448606\n","Training loss per 100 training steps: 0.020485913394130396\n","Training loss per 100 training steps: 0.020307609111772026\n","Training loss per 100 training steps: 0.019469145701583774\n","Training loss per 100 training steps: 0.019238745461790645\n","Training loss per 100 training steps: 0.01973535560831074\n","Training loss per 100 training steps: 0.01938862288532053\n","Training loss per 100 training steps: 0.01960390581646402\n","Training loss per 100 training steps: 0.01976536185134432\n","Training loss per 100 training steps: 0.019839888885554872\n","Training loss per 100 training steps: 0.01996406765760242\n","Training loss per 100 training steps: 0.019670604732613988\n","Training loss per 100 training steps: 0.019649283134565123\n","Training loss per 100 training steps: 0.019604942030236924\n","Training loss per 100 training steps: 0.01963661524490366\n","Training loss per 100 training steps: 0.019540798590288032\n","Stopping epoch...\n","Training loss epoch: 0.019540798590288032\n","Training accuracy epoch: 0.9934379336950737\n","Validating model...\n","Validation Loss: 0.21865476953325333\n","Validation Accuracy: 0.952810940887318\n","Training epoch: 5\n","Training loss per 100 training steps: 0.005654565989971161\n","Training loss per 100 training steps: 0.013973400122970159\n","Training loss per 100 training steps: 0.012655846077823706\n","Training loss per 100 training steps: 0.013116333978556164\n","Training loss per 100 training steps: 0.013522623539548088\n","Training loss per 100 training steps: 0.013966903553814618\n","Training loss per 100 training steps: 0.014681883278719696\n","Training loss per 100 training steps: 0.014973874099568574\n","Training loss per 100 training steps: 0.014998481074448665\n","Training loss per 100 training steps: 0.015161151906072817\n","Training loss per 100 training steps: 0.015132633001027447\n","Training loss per 100 training steps: 0.015321027293200094\n","Training loss per 100 training steps: 0.01591566900039215\n","Training loss per 100 training steps: 0.015668710714901727\n","Training loss per 100 training steps: 0.015786895292696758\n","Training loss per 100 training steps: 0.0159579712999451\n","Training loss per 100 training steps: 0.01607944833755064\n","Training loss per 100 training steps: 0.01622285436606719\n","Training loss per 100 training steps: 0.016279360183483887\n","Training loss per 100 training steps: 0.016499817268425664\n","Training loss epoch: 0.01645850136828346\n","Training accuracy epoch: 0.9951472416353675\n","Validating model...\n","Validation Loss: 0.23739576068791476\n","Validation Accuracy: 0.9504506991817802\n","Training epoch: 6\n","Training loss per 100 training steps: 0.036882854998111725\n","Training loss per 100 training steps: 0.011417845227481281\n","Training loss per 100 training steps: 0.012805254966314808\n","Training loss per 100 training steps: 0.011684153235814862\n","Training loss per 100 training steps: 0.012048080633256521\n","Training loss per 100 training steps: 0.011932039877929365\n","Training loss per 100 training steps: 0.012650396410346198\n","Training loss per 100 training steps: 0.012803971382619756\n","Training loss per 100 training steps: 0.012730030271157967\n","Training loss per 100 training steps: 0.013381977576229977\n","Training loss per 100 training steps: 0.01363897890724592\n","Training loss per 100 training steps: 0.013473519496506036\n","Training loss per 100 training steps: 0.013524794678617565\n","Training loss per 100 training steps: 0.013521952028757195\n","Training loss per 100 training steps: 0.013867412003044782\n","Training loss per 100 training steps: 0.014232994008385937\n","Training loss per 100 training steps: 0.014670311282808064\n","Training loss per 100 training steps: 0.01502575905532334\n","Training loss per 100 training steps: 0.015343645451570574\n","Training loss per 100 training steps: 0.015411748230590622\n","Training loss epoch: 0.01542152492497385\n","Training accuracy epoch: 0.9952794044949217\n","Validating model...\n","Validation Loss: 0.22725653777794017\n","Validation Accuracy: 0.9504051192619485\n","Training epoch: 7\n","Training loss per 100 training steps: 0.005911591928452253\n","Training loss per 100 training steps: 0.007766591967947984\n","Training loss per 100 training steps: 0.011552277579295464\n","Training loss per 100 training steps: 0.010894430456280807\n","Training loss per 100 training steps: 0.010899781652997965\n","Training loss per 100 training steps: 0.011812773803232736\n","Training loss per 100 training steps: 0.011601582032633393\n","Training loss per 100 training steps: 0.011734505893737968\n","Training loss per 100 training steps: 0.011688371262406714\n","Training loss per 100 training steps: 0.011450005094186103\n","Training loss per 100 training steps: 0.011341234516912047\n","Training loss per 100 training steps: 0.011275348440687626\n","Training loss per 100 training steps: 0.011388066943540923\n","Training loss per 100 training steps: 0.011633680672392404\n","Training loss per 100 training steps: 0.011959934043653557\n","Training loss per 100 training steps: 0.012013076815562528\n","Training loss per 100 training steps: 0.012072805227971896\n","Training loss per 100 training steps: 0.012276550384810446\n","Training loss per 100 training steps: 0.01251342324043428\n","Training loss per 100 training steps: 0.012612749214464716\n","Training loss epoch: 0.012638301007406344\n","Training accuracy epoch: 0.9962897426760228\n","Validating model...\n","Validation Loss: 0.25346473652821083\n","Validation Accuracy: 0.9507287435662897\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 137.9349172833333 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.19357331917422857\n","Validation Accuracy: 0.9499377617991138\n","Validation duration: 3.036621683333336 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 82.8%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.85      0.82     12546\n","        test       0.82      0.86      0.84      9012\n","   treatment       0.79      0.86      0.82      9297\n","\n","   micro avg       0.80      0.86      0.83     30855\n","   macro avg       0.80      0.86      0.83     30855\n","weighted avg       0.80      0.86      0.83     30855\n","\n","!!!!!! Starting model number 5 !!!!!!\n","Points in X_train after augmentation: 62400\n","Points in y_train after augmentation: 62400\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9969948530197144\n","Training loss per 100 training steps: 0.38441733639724185\n","Training loss per 100 training steps: 0.29008257229678075\n","Training loss per 100 training steps: 0.24330240642757114\n","Training loss per 100 training steps: 0.21808245253663258\n","Training loss per 100 training steps: 0.19998596036460942\n","Training loss per 100 training steps: 0.18625104844185852\n","Training loss per 100 training steps: 0.17662028811829492\n","Training loss per 100 training steps: 0.16763152018161526\n","Training loss per 100 training steps: 0.15986794285211592\n","Training loss per 100 training steps: 0.15397064411616349\n","Training loss per 100 training steps: 0.1492075314457705\n","Training loss per 100 training steps: 0.14359752704962456\n","Training loss per 100 training steps: 0.13872330655257212\n","Training loss per 100 training steps: 0.1347273662972193\n","Training loss per 100 training steps: 0.1310788489038064\n","Training loss per 100 training steps: 0.12777501182877304\n","Training loss per 100 training steps: 0.12492316769357159\n","Training loss per 100 training steps: 0.12226833109984352\n","Training loss per 100 training steps: 0.11979834643510542\n","Training loss epoch: 0.11835238945861466\n","Training accuracy epoch: 0.9632718046738734\n","Validating model...\n","Validation Loss: 0.167737436214728\n","Validation Accuracy: 0.9525545099358351\n","Training epoch: 2\n","Training loss per 100 training steps: 0.008575578220188618\n","Training loss per 100 training steps: 0.04254132606513282\n","Training loss per 100 training steps: 0.04138349856838436\n","Training loss per 100 training steps: 0.04041741219847355\n","Training loss per 100 training steps: 0.041103063705156644\n","Training loss per 100 training steps: 0.043406579840534226\n","Training loss per 100 training steps: 0.04426289529240568\n","Training loss per 100 training steps: 0.043925071208234266\n","Training loss per 100 training steps: 0.04439277859746517\n","Training loss per 100 training steps: 0.043891425641175034\n","Training loss per 100 training steps: 0.043476154315764536\n","Training loss per 100 training steps: 0.04313129088211192\n","Training loss per 100 training steps: 0.04276076418934677\n","Training loss per 100 training steps: 0.04310231252418091\n","Training loss per 100 training steps: 0.04272786856344439\n","Training loss per 100 training steps: 0.042624781156879545\n","Training loss per 100 training steps: 0.04269469372487786\n","Training loss per 100 training steps: 0.042417544151792115\n","Training loss per 100 training steps: 0.04222284256461759\n","Training loss per 100 training steps: 0.0420645932037543\n","Training loss epoch: 0.042118279436328565\n","Training accuracy epoch: 0.9869321142486822\n","Validating model...\n","Validation Loss: 0.1829698094024698\n","Validation Accuracy: 0.9532077389321196\n","Training epoch: 3\n","Training loss per 100 training steps: 0.007072407752275467\n","Training loss per 100 training steps: 0.025089119634784683\n","Training loss per 100 training steps: 0.02736851897650162\n","Training loss per 100 training steps: 0.026426835784083696\n","Training loss per 100 training steps: 0.02687915547723601\n","Training loss per 100 training steps: 0.026280977651060924\n","Training loss per 100 training steps: 0.0256624111182505\n","Training loss per 100 training steps: 0.025599460253073834\n","Training loss per 100 training steps: 0.025263898367808953\n","Training loss per 100 training steps: 0.024583477082334874\n","Training loss per 100 training steps: 0.024733556589218914\n","Training loss per 100 training steps: 0.02506270588714089\n","Training loss per 100 training steps: 0.025615849919066798\n","Training loss per 100 training steps: 0.025332166660412592\n","Training loss per 100 training steps: 0.025096067026396947\n","Training loss per 100 training steps: 0.02530538984715146\n","Training loss per 100 training steps: 0.025314134080671933\n","Training loss per 100 training steps: 0.02556805160792278\n","Training loss per 100 training steps: 0.02561869749456201\n","Training loss per 100 training steps: 0.02608075211397377\n","Training loss epoch: 0.026141868524316055\n","Training accuracy epoch: 0.9919606973919864\n","Validating model...\n","Validation Loss: 0.1946291591391548\n","Validation Accuracy: 0.9514969883212707\n","Training epoch: 4\n","Training loss per 100 training steps: 0.004323444329202175\n","Training loss per 100 training steps: 0.018070224490440864\n","Training loss per 100 training steps: 0.018670659578018427\n","Training loss per 100 training steps: 0.01804277895597054\n","Training loss per 100 training steps: 0.018001950135964905\n","Training loss per 100 training steps: 0.01778676133899589\n","Training loss per 100 training steps: 0.01856990764401822\n","Training loss per 100 training steps: 0.01867241651484392\n","Training loss per 100 training steps: 0.01865245713273903\n","Training loss per 100 training steps: 0.018845730952812063\n","Training loss per 100 training steps: 0.018930833628850074\n","Training loss per 100 training steps: 0.018745817953171283\n","Training loss per 100 training steps: 0.018931499766067623\n","Training loss per 100 training steps: 0.01906437840366229\n","Training loss per 100 training steps: 0.01921356252586897\n","Training loss per 100 training steps: 0.019263331686479437\n","Training loss per 100 training steps: 0.019390994417646912\n","Training loss per 100 training steps: 0.019606467239369256\n","Training loss per 100 training steps: 0.019771302280495607\n","Training loss per 100 training steps: 0.01979662885898352\n","Training loss epoch: 0.0197788902435404\n","Training accuracy epoch: 0.9940147438168238\n","Validating model...\n","Validation Loss: 0.20396518654056958\n","Validation Accuracy: 0.953747144732931\n","Training epoch: 5\n","Training loss per 100 training steps: 0.005657471716403961\n","Training loss per 100 training steps: 0.010643034340787245\n","Training loss per 100 training steps: 0.011103010928042266\n","Training loss per 100 training steps: 0.013827179896943442\n","Training loss per 100 training steps: 0.014007856851747606\n","Training loss per 100 training steps: 0.014831120101392255\n","Training loss per 100 training steps: 0.0152112498011693\n","Training loss per 100 training steps: 0.016018699808133408\n","Training loss per 100 training steps: 0.017234646577898038\n","Training loss per 100 training steps: 0.017303388831799372\n","Training loss per 100 training steps: 0.01764354062330089\n","Training loss per 100 training steps: 0.018153398046934565\n","Training loss per 100 training steps: 0.018287493807677475\n","Training loss per 100 training steps: 0.01824115907981554\n","Training loss per 100 training steps: 0.018209815486971183\n","Training loss per 100 training steps: 0.017876879125986688\n","Training loss per 100 training steps: 0.01762832422093929\n","Training loss per 100 training steps: 0.017537405334220667\n","Training loss per 100 training steps: 0.0174234673950049\n","Training loss per 100 training steps: 0.017444221275332353\n","Training loss epoch: 0.017456577595656154\n","Training accuracy epoch: 0.9947402411310753\n","Validating model...\n","Validation Loss: 0.21879648736545018\n","Validation Accuracy: 0.9531542148055945\n","Training epoch: 6\n","Training loss per 100 training steps: 0.015537859871983528\n","Training loss per 100 training steps: 0.01315383031436399\n","Training loss per 100 training steps: 0.011436496717497401\n","Training loss per 100 training steps: 0.011232676542889284\n","Training loss per 100 training steps: 0.011755199993622636\n","Training loss per 100 training steps: 0.01183276441794757\n","Training loss per 100 training steps: 0.011338012337774896\n","Training loss per 100 training steps: 0.01091828598300747\n","Training loss per 100 training steps: 0.011547862104030929\n","Training loss per 100 training steps: 0.011796434621524828\n","Training loss per 100 training steps: 0.011892791302420188\n","Training loss per 100 training steps: 0.011949225406420013\n","Training loss per 100 training steps: 0.012065434778844131\n","Training loss per 100 training steps: 0.012492600914512687\n","Training loss per 100 training steps: 0.012882619409140221\n","Training loss per 100 training steps: 0.013435445867268199\n","Training loss per 100 training steps: 0.013718612052945695\n","Training loss per 100 training steps: 0.01398731498704385\n","Training loss per 100 training steps: 0.013985697449206802\n","Training loss per 100 training steps: 0.014139786869017916\n","Training loss epoch: 0.01410451430252765\n","Training accuracy epoch: 0.9957567346382238\n","Validating model...\n","Validation Loss: 0.240533035865368\n","Validation Accuracy: 0.9542932356492947\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 120.72451676666667 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.18070048422345686\n","Validation Accuracy: 0.9489711080744904\n","Validation duration: 3.033326233333355 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 81.8%\n","              precision    recall  f1-score   support\n","\n","     problem       0.77      0.85      0.80     12546\n","        test       0.81      0.83      0.82      9012\n","   treatment       0.80      0.86      0.83      9297\n","\n","   micro avg       0.79      0.85      0.82     30855\n","   macro avg       0.79      0.85      0.82     30855\n","weighted avg       0.79      0.85      0.82     30855\n","\n","!!!!!! Starting model number 6 !!!!!!\n","Points in X_train after augmentation: 62400\n","Points in y_train after augmentation: 62400\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.813321828842163\n","Training loss per 100 training steps: 0.38628024165288055\n","Training loss per 100 training steps: 0.2846268772041027\n","Training loss per 100 training steps: 0.24197150427736713\n","Training loss per 100 training steps: 0.21214899465330223\n","Training loss per 100 training steps: 0.19241146027610567\n","Training loss per 100 training steps: 0.1811296355239613\n","Training loss per 100 training steps: 0.17046264284815155\n","Training loss per 100 training steps: 0.16168968924571214\n","Training loss per 100 training steps: 0.15477505802992447\n","Training loss per 100 training steps: 0.1487245788652595\n","Training loss per 100 training steps: 0.14397740075457757\n","Training loss per 100 training steps: 0.13872600506392496\n","Training loss per 100 training steps: 0.134417802418978\n","Training loss per 100 training steps: 0.1306713814165797\n","Training loss per 100 training steps: 0.12779021377598918\n","Training loss per 100 training steps: 0.12418764198826002\n","Training loss per 100 training steps: 0.12094278071926516\n","Training loss per 100 training steps: 0.11870765898336369\n","Training loss per 100 training steps: 0.11642062959767317\n","Training loss epoch: 0.11537561680667867\n","Training accuracy epoch: 0.9642103990205999\n","Validating model...\n","Validation Loss: 0.1718752978780827\n","Validation Accuracy: 0.9454578222188686\n","Training epoch: 2\n","Training loss per 100 training steps: 0.23037171363830566\n","Training loss per 100 training steps: 0.040664116019788796\n","Training loss per 100 training steps: 0.0444365701330038\n","Training loss per 100 training steps: 0.043311892972293736\n","Training loss per 100 training steps: 0.043739579238828985\n","Training loss per 100 training steps: 0.042110503351449696\n","Training loss per 100 training steps: 0.041373938508796664\n","Training loss per 100 training steps: 0.04036536174756575\n","Training loss per 100 training steps: 0.03959782615396428\n","Training loss per 100 training steps: 0.039585137788488524\n","Training loss per 100 training steps: 0.03927919312859871\n","Training loss per 100 training steps: 0.03896960473674807\n","Training loss per 100 training steps: 0.038921573681956145\n","Training loss per 100 training steps: 0.038945181724697\n","Training loss per 100 training steps: 0.0390514908324386\n","Stopping epoch...\n","Training loss epoch: 0.0390514908324386\n","Training accuracy epoch: 0.9873856904058009\n","Validating model...\n","Validation Loss: 0.18233379020125834\n","Validation Accuracy: 0.9519897830139523\n","Training epoch: 3\n","Training loss per 100 training steps: 0.07778826355934143\n","Training loss per 100 training steps: 0.02664508332618245\n","Training loss per 100 training steps: 0.030487272650957922\n","Training loss per 100 training steps: 0.028260189582333835\n","Training loss per 100 training steps: 0.02694031366546571\n","Training loss per 100 training steps: 0.027369784288612118\n","Training loss per 100 training steps: 0.027588558127211033\n","Training loss per 100 training steps: 0.02760190074033132\n","Training loss per 100 training steps: 0.027766912577373817\n","Training loss per 100 training steps: 0.028205246066743846\n","Training loss per 100 training steps: 0.02900440225688895\n","Training loss per 100 training steps: 0.029223988460948678\n","Training loss per 100 training steps: 0.029095144615548164\n","Training loss per 100 training steps: 0.028797382515959646\n","Training loss per 100 training steps: 0.02922952636422591\n","Training loss per 100 training steps: 0.029039811323022097\n","Training loss per 100 training steps: 0.029087268311613537\n","Training loss per 100 training steps: 0.029182796488266365\n","Training loss per 100 training steps: 0.029360932708140785\n","Training loss per 100 training steps: 0.02931712592559044\n","Training loss epoch: 0.029295603673403652\n","Training accuracy epoch: 0.9911529923026243\n","Validating model...\n","Validation Loss: 0.20168285628224347\n","Validation Accuracy: 0.9534928727321417\n","Training epoch: 4\n","Training loss per 100 training steps: 0.04586607217788696\n","Training loss per 100 training steps: 0.016164361136172447\n","Training loss per 100 training steps: 0.017049590153191053\n","Training loss per 100 training steps: 0.015786180570891803\n","Training loss per 100 training steps: 0.016268203324728885\n","Training loss per 100 training steps: 0.01623652871287318\n","Training loss per 100 training steps: 0.0168953903446349\n","Training loss per 100 training steps: 0.01727944008787475\n","Training loss per 100 training steps: 0.018239249794752093\n","Training loss per 100 training steps: 0.01906053646874369\n","Training loss per 100 training steps: 0.01940812807905578\n","Training loss per 100 training steps: 0.019372106339447505\n","Training loss per 100 training steps: 0.019455136184182816\n","Training loss per 100 training steps: 0.01949841716639242\n","Training loss per 100 training steps: 0.019255251214117593\n","Training loss per 100 training steps: 0.019267038599715795\n","Training loss per 100 training steps: 0.019267582083568862\n","Training loss per 100 training steps: 0.019615721807020963\n","Training loss per 100 training steps: 0.019644235478069524\n","Training loss per 100 training steps: 0.019754539052658185\n","Training loss epoch: 0.01984594908122045\n","Training accuracy epoch: 0.994018704705387\n","Validating model...\n","Validation Loss: 0.21454303939040606\n","Validation Accuracy: 0.9515913298905248\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0151864318177104\n","Training loss per 100 training steps: 0.013049723098105244\n","Training loss per 100 training steps: 0.014277879556464911\n","Training loss per 100 training steps: 0.014950435617520935\n","Training loss per 100 training steps: 0.015633423412781896\n","Training loss per 100 training steps: 0.01619027123264615\n","Training loss per 100 training steps: 0.017297328545765395\n","Training loss per 100 training steps: 0.017238179228309086\n","Training loss per 100 training steps: 0.01774413667125953\n","Training loss per 100 training steps: 0.018003835075043377\n","Training loss per 100 training steps: 0.017784301361830145\n","Training loss per 100 training steps: 0.01806807807531651\n","Training loss per 100 training steps: 0.017624220846768127\n","Training loss per 100 training steps: 0.017493980914447566\n","Training loss per 100 training steps: 0.017735585431733848\n","Training loss per 100 training steps: 0.017607720080196305\n","Training loss per 100 training steps: 0.017872327826005337\n","Training loss per 100 training steps: 0.017842614860917226\n","Training loss per 100 training steps: 0.017969055576050868\n","Training loss per 100 training steps: 0.01783211373221026\n","Training loss epoch: 0.017728118047189826\n","Training accuracy epoch: 0.9946484234065016\n","Validating model...\n","Validation Loss: 0.23190509849651295\n","Validation Accuracy: 0.9535549771382175\n","Training epoch: 6\n","Training loss per 100 training steps: 0.037996064871549606\n","Training loss per 100 training steps: 0.00983507977279899\n","Training loss per 100 training steps: 0.011498105696814288\n","Training loss per 100 training steps: 0.0126339950875021\n","Training loss per 100 training steps: 0.013035707706350373\n","Training loss per 100 training steps: 0.012808173371361803\n","Training loss per 100 training steps: 0.013328273870618844\n","Training loss per 100 training steps: 0.013477715703966987\n","Training loss per 100 training steps: 0.013142171426632323\n","Training loss per 100 training steps: 0.01350194240417502\n","Training loss per 100 training steps: 0.013245884524782762\n","Training loss per 100 training steps: 0.013556415257931262\n","Training loss per 100 training steps: 0.013925332292510377\n","Training loss per 100 training steps: 0.014407522024137242\n","Training loss per 100 training steps: 0.014453434098060233\n","Training loss per 100 training steps: 0.014424867273715442\n","Training loss per 100 training steps: 0.014638133408105235\n","Training loss per 100 training steps: 0.01454456453422912\n","Training loss per 100 training steps: 0.014371270225763743\n","Training loss per 100 training steps: 0.01423078344460215\n","Training loss epoch: 0.0142213174746333\n","Training accuracy epoch: 0.9958217058623756\n","Validating model...\n","Validation Loss: 0.22810184747561232\n","Validation Accuracy: 0.9513851708037827\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 115.35508423333327 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.1926109790974469\n","Validation Accuracy: 0.9418359852979092\n","Validation duration: 3.042764516666648 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 80.4%\n","              precision    recall  f1-score   support\n","\n","     problem       0.74      0.83      0.78     12546\n","        test       0.79      0.86      0.82      9012\n","   treatment       0.78      0.86      0.82      9297\n","\n","   micro avg       0.76      0.85      0.80     30855\n","   macro avg       0.77      0.85      0.81     30855\n","weighted avg       0.76      0.85      0.80     30855\n","\n","!!!!!! Starting model number 7 !!!!!!\n","Points in X_train after augmentation: 62400\n","Points in y_train after augmentation: 62400\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8006120920181274\n","Training loss per 100 training steps: 0.39104384051101043\n","Training loss per 100 training steps: 0.28720503806400655\n","Training loss per 100 training steps: 0.24873673139864028\n","Training loss per 100 training steps: 0.22032251320732874\n","Training loss per 100 training steps: 0.2043949495461916\n","Training loss per 100 training steps: 0.19070975203067064\n","Training loss per 100 training steps: 0.17836708107434437\n","Training loss per 100 training steps: 0.16879273475160572\n","Training loss per 100 training steps: 0.16075250050662857\n","Training loss per 100 training steps: 0.15366730380330706\n","Training loss per 100 training steps: 0.14835842666161211\n","Training loss per 100 training steps: 0.14317273800350497\n","Training loss per 100 training steps: 0.13881270038457924\n","Training loss per 100 training steps: 0.134348930985129\n","Training loss per 100 training steps: 0.13071622575746775\n","Training loss per 100 training steps: 0.12759750337659298\n","Training loss per 100 training steps: 0.12490440985715692\n","Training loss per 100 training steps: 0.12190290134599735\n","Training loss per 100 training steps: 0.11929502255890297\n","Training loss epoch: 0.11809942789399662\n","Training accuracy epoch: 0.9634906416964758\n","Validating model...\n","Validation Loss: 0.16988470760936086\n","Validation Accuracy: 0.9541728423465899\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04349071532487869\n","Training loss per 100 training steps: 0.04105841447968073\n","Training loss per 100 training steps: 0.04143608062741212\n","Training loss per 100 training steps: 0.04152591959758974\n","Training loss per 100 training steps: 0.040914747992326084\n","Training loss per 100 training steps: 0.04175755083040444\n","Training loss per 100 training steps: 0.0418063588928549\n","Training loss per 100 training steps: 0.04286156342425962\n","Training loss per 100 training steps: 0.042886802128175465\n","Training loss per 100 training steps: 0.042900702410887157\n","Training loss per 100 training steps: 0.04308188585196989\n","Training loss per 100 training steps: 0.043290784828437595\n","Stopping epoch...\n","Training loss epoch: 0.043290784828437595\n","Training accuracy epoch: 0.9858409373758164\n","Validating model...\n","Validation Loss: 0.17401095905474254\n","Validation Accuracy: 0.9538086021304277\n","Training epoch: 3\n","Training loss per 100 training steps: 0.06538465619087219\n","Training loss per 100 training steps: 0.03465055093736305\n","Training loss per 100 training steps: 0.03422712270154233\n","Training loss per 100 training steps: 0.03500865988798464\n","Training loss per 100 training steps: 0.034120337100771544\n","Training loss per 100 training steps: 0.034254546581856726\n","Training loss per 100 training steps: 0.03563776786091231\n","Training loss per 100 training steps: 0.03510908216481149\n","Training loss per 100 training steps: 0.034274905271532846\n","Training loss per 100 training steps: 0.03378136422586928\n","Training loss per 100 training steps: 0.03379425460849047\n","Training loss per 100 training steps: 0.03343332223602648\n","Training loss per 100 training steps: 0.033441024141496266\n","Training loss per 100 training steps: 0.03359084360503364\n","Training loss per 100 training steps: 0.03336946706624594\n","Training loss per 100 training steps: 0.03386383554778762\n","Training loss per 100 training steps: 0.03403224855907748\n","Training loss per 100 training steps: 0.0341212093615346\n","Training loss per 100 training steps: 0.03388402550026846\n","Training loss per 100 training steps: 0.03365279373130822\n","Training loss epoch: 0.033515422298895335\n","Training accuracy epoch: 0.9898526896713014\n","Validating model...\n","Validation Loss: 0.1984769379744282\n","Validation Accuracy: 0.9508939663758805\n","Training epoch: 4\n","Training loss per 100 training steps: 0.002970401430502534\n","Training loss per 100 training steps: 0.022430448346808185\n","Training loss per 100 training steps: 0.02101363335412913\n","Training loss per 100 training steps: 0.020317319041872985\n","Training loss per 100 training steps: 0.020607663310386073\n","Training loss per 100 training steps: 0.02068132323309586\n","Training loss per 100 training steps: 0.02095891412387458\n","Training loss per 100 training steps: 0.021870675338076802\n","Training loss per 100 training steps: 0.022204042955539474\n","Training loss per 100 training steps: 0.022162058183558483\n","Training loss per 100 training steps: 0.02195234303283584\n","Training loss per 100 training steps: 0.02191770717564659\n","Training loss per 100 training steps: 0.021961055531517\n","Training loss per 100 training steps: 0.0219639243563776\n","Training loss per 100 training steps: 0.021772576390973675\n","Stopping epoch...\n","Training loss epoch: 0.021772576390973675\n","Training accuracy epoch: 0.9927113912607223\n","Validating model...\n","Validation Loss: 0.23999804863101476\n","Validation Accuracy: 0.9486770132636839\n","Training epoch: 5\n","Training loss per 100 training steps: 0.02165035717189312\n","Training loss per 100 training steps: 0.022632570038226867\n","Training loss per 100 training steps: 0.019446069229595752\n","Training loss per 100 training steps: 0.018791660494356727\n","Training loss per 100 training steps: 0.019313995974768936\n","Training loss per 100 training steps: 0.018874060844852887\n","Training loss per 100 training steps: 0.018542709199985963\n","Training loss per 100 training steps: 0.019207060485948727\n","Training loss per 100 training steps: 0.019385406274604874\n","Training loss per 100 training steps: 0.019202258915872468\n","Training loss per 100 training steps: 0.01870847875871077\n","Training loss per 100 training steps: 0.019092368831126135\n","Training loss per 100 training steps: 0.019128116499065546\n","Training loss per 100 training steps: 0.01945692460854154\n","Training loss per 100 training steps: 0.019429075063777446\n","Training loss per 100 training steps: 0.020046056570832853\n","Training loss per 100 training steps: 0.02038113144988053\n","Training loss per 100 training steps: 0.0201494844845705\n","Training loss per 100 training steps: 0.020123995861896588\n","Training loss per 100 training steps: 0.020098767843728087\n","Training loss epoch: 0.01998928579127189\n","Training accuracy epoch: 0.9940385163944332\n","Validating model...\n","Validation Loss: 0.21844986598793562\n","Validation Accuracy: 0.9531878869515944\n","Training epoch: 6\n","Training loss per 100 training steps: 0.028945187106728554\n","Training loss per 100 training steps: 0.010320742821463818\n","Training loss per 100 training steps: 0.011010352763942726\n","Training loss per 100 training steps: 0.012745355540558547\n","Training loss per 100 training steps: 0.01329281037610066\n","Training loss per 100 training steps: 0.01392432102924696\n","Training loss per 100 training steps: 0.013741457162594605\n","Training loss per 100 training steps: 0.01376686928487056\n","Training loss per 100 training steps: 0.01384080192845195\n","Training loss per 100 training steps: 0.01367023726321212\n","Training loss per 100 training steps: 0.013772604230398356\n","Training loss per 100 training steps: 0.01405702862223971\n","Training loss per 100 training steps: 0.014621667907018153\n","Training loss per 100 training steps: 0.0151029130448785\n","Training loss per 100 training steps: 0.015391609207624394\n","Training loss per 100 training steps: 0.01529866216012156\n","Training loss per 100 training steps: 0.015283841072705103\n","Training loss per 100 training steps: 0.015573688401826734\n","Training loss per 100 training steps: 0.015522209835983205\n","Training loss per 100 training steps: 0.015422144156660156\n","Training loss epoch: 0.015437672925711526\n","Training accuracy epoch: 0.9953194633780287\n","Validating model...\n","Validation Loss: 0.24080499387406684\n","Validation Accuracy: 0.9521842760718218\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 106.50671003333336 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.19302922344973517\n","Validation Accuracy: 0.9477931708731775\n","Validation duration: 3.0306705999999393 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 81.6%\n","              precision    recall  f1-score   support\n","\n","     problem       0.79      0.84      0.81     12546\n","        test       0.82      0.83      0.82      9012\n","   treatment       0.85      0.79      0.82      9297\n","\n","   micro avg       0.81      0.82      0.82     30855\n","   macro avg       0.82      0.82      0.82     30855\n","weighted avg       0.81      0.82      0.82     30855\n","\n","!!!!!! Starting model number 8 !!!!!!\n","Points in X_train after augmentation: 62400\n","Points in y_train after augmentation: 62400\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0041708946228027\n","Training loss per 100 training steps: 0.4076479124550772\n","Training loss per 100 training steps: 0.2977214581634275\n","Training loss per 100 training steps: 0.2529630048256182\n","Training loss per 100 training steps: 0.22563183592850727\n","Training loss per 100 training steps: 0.20618060885922995\n","Training loss per 100 training steps: 0.19084364174866736\n","Training loss per 100 training steps: 0.1793494401247202\n","Training loss per 100 training steps: 0.16969483984766828\n","Training loss per 100 training steps: 0.16139759865799272\n","Training loss per 100 training steps: 0.15436558211901477\n","Training loss per 100 training steps: 0.14868458877863205\n","Training loss per 100 training steps: 0.14431101185301448\n","Training loss per 100 training steps: 0.1399030396832922\n","Training loss per 100 training steps: 0.13617907088485245\n","Training loss per 100 training steps: 0.1324110674084866\n","Training loss per 100 training steps: 0.12866884262285322\n","Training loss per 100 training steps: 0.12567261180241998\n","Training loss per 100 training steps: 0.12274980500287716\n","Training loss per 100 training steps: 0.12038210740015068\n","Training loss epoch: 0.11904891042014919\n","Training accuracy epoch: 0.9628524578488297\n","Validating model...\n","Validation Loss: 0.17295452604046116\n","Validation Accuracy: 0.9516214140692645\n","Training epoch: 2\n","Training loss per 100 training steps: 0.02502807229757309\n","Training loss per 100 training steps: 0.0358226776196815\n","Training loss per 100 training steps: 0.037134403386616624\n","Training loss per 100 training steps: 0.03763941887640812\n","Training loss per 100 training steps: 0.037609015767662284\n","Training loss per 100 training steps: 0.038569769311553155\n","Training loss per 100 training steps: 0.040537260348611076\n","Training loss per 100 training steps: 0.0409040798520478\n","Training loss per 100 training steps: 0.04056081070870477\n","Training loss per 100 training steps: 0.04002001369139438\n","Training loss per 100 training steps: 0.04009409590771275\n","Training loss per 100 training steps: 0.039944096490910797\n","Training loss per 100 training steps: 0.039441770088039244\n","Training loss per 100 training steps: 0.03995964346474307\n","Training loss per 100 training steps: 0.03972328661526849\n","Training loss per 100 training steps: 0.039941140042269216\n","Training loss per 100 training steps: 0.03952304027241065\n","Training loss per 100 training steps: 0.040030987079291966\n","Training loss per 100 training steps: 0.03982008883144204\n","Training loss per 100 training steps: 0.039956230195489044\n","Training loss epoch: 0.03988391730026939\n","Training accuracy epoch: 0.9876704879813378\n","Validating model...\n","Validation Loss: 0.1797513724002358\n","Validation Accuracy: 0.9527091785919984\n","Training epoch: 3\n","Training loss per 100 training steps: 0.015422249212861061\n","Training loss per 100 training steps: 0.019780713882721443\n","Training loss per 100 training steps: 0.020489356084379243\n","Training loss per 100 training steps: 0.022248656082081538\n","Training loss per 100 training steps: 0.02277728471617003\n","Training loss per 100 training steps: 0.023825523404947327\n","Training loss per 100 training steps: 0.02385100906776007\n","Training loss per 100 training steps: 0.02427309712118731\n","Training loss per 100 training steps: 0.023943465532236193\n","Training loss per 100 training steps: 0.02415662826766073\n","Training loss per 100 training steps: 0.025033805885335447\n","Training loss per 100 training steps: 0.025265037791729887\n","Training loss per 100 training steps: 0.024942293147836424\n","Training loss per 100 training steps: 0.024968995333296305\n","Training loss per 100 training steps: 0.02525412797092591\n","Training loss per 100 training steps: 0.025233953853130344\n","Training loss per 100 training steps: 0.025300418706986003\n","Training loss per 100 training steps: 0.025707156511080034\n","Training loss per 100 training steps: 0.02573482569608049\n","Training loss per 100 training steps: 0.025545280060347765\n","Training loss epoch: 0.025614956113933704\n","Training accuracy epoch: 0.99208781735365\n","Validating model...\n","Validation Loss: 0.207060527118443\n","Validation Accuracy: 0.9514097707598214\n","Training epoch: 4\n","Training loss per 100 training steps: 0.04074263945221901\n","Training loss per 100 training steps: 0.016492752705258087\n","Training loss per 100 training steps: 0.01774249921103393\n","Training loss per 100 training steps: 0.01801853305499682\n","Training loss per 100 training steps: 0.01782685300377964\n","Training loss per 100 training steps: 0.017389344173762856\n","Training loss per 100 training steps: 0.016978155118663147\n","Training loss per 100 training steps: 0.017999780878862073\n","Training loss per 100 training steps: 0.019142363201595725\n","Training loss per 100 training steps: 0.019563326727012047\n","Training loss per 100 training steps: 0.019816003302171533\n","Training loss per 100 training steps: 0.019650132971138844\n","Training loss per 100 training steps: 0.020073057601198697\n","Training loss per 100 training steps: 0.020243681854109203\n","Training loss per 100 training steps: 0.020093653066262276\n","Training loss per 100 training steps: 0.0204492358130643\n","Training loss per 100 training steps: 0.020342111118481918\n","Training loss per 100 training steps: 0.020651801063703523\n","Training loss per 100 training steps: 0.020642931950747862\n","Training loss per 100 training steps: 0.020471943758565515\n","Training loss epoch: 0.02047100569700631\n","Training accuracy epoch: 0.9938539292404798\n","Validating model...\n","Validation Loss: 0.23888657401715005\n","Validation Accuracy: 0.9494760581992147\n","Training epoch: 5\n","Training loss per 100 training steps: 0.01844940520823002\n","Training loss per 100 training steps: 0.015733956060220145\n","Training loss per 100 training steps: 0.01654748229914581\n","Training loss per 100 training steps: 0.016401509104019645\n","Training loss per 100 training steps: 0.016166668712304315\n","Training loss per 100 training steps: 0.015875219358730795\n","Training loss per 100 training steps: 0.01577266467155613\n","Training loss per 100 training steps: 0.01561870205738567\n","Training loss per 100 training steps: 0.015083939083253084\n","Training loss per 100 training steps: 0.014500085025217971\n","Training loss per 100 training steps: 0.01451650251906326\n","Training loss per 100 training steps: 0.014422000469484466\n","Training loss per 100 training steps: 0.01488911683167033\n","Training loss per 100 training steps: 0.015550756764068998\n","Training loss per 100 training steps: 0.01613386394341774\n","Training loss per 100 training steps: 0.01630381279801289\n","Training loss per 100 training steps: 0.016496425337870886\n","Training loss per 100 training steps: 0.016209625248968473\n","Training loss per 100 training steps: 0.016536342709828535\n","Training loss per 100 training steps: 0.016576317158061155\n","Training loss epoch: 0.016525620964970678\n","Training accuracy epoch: 0.9950766835736089\n","Validating model...\n","Validation Loss: 0.2212501275171707\n","Validation Accuracy: 0.9519745228057762\n","Training epoch: 6\n","Training loss per 100 training steps: 0.004248654469847679\n","Training loss per 100 training steps: 0.010159035027718706\n","Training loss per 100 training steps: 0.011829670393968057\n","Training loss per 100 training steps: 0.010888673545637221\n","Training loss per 100 training steps: 0.012052222510885117\n","Training loss per 100 training steps: 0.013194476991058596\n","Training loss per 100 training steps: 0.013135373785643577\n","Training loss per 100 training steps: 0.013606242935703642\n","Training loss per 100 training steps: 0.01387087059834101\n","Training loss per 100 training steps: 0.014346157488151899\n","Training loss per 100 training steps: 0.014527324307087733\n","Training loss per 100 training steps: 0.01429026363106431\n","Training loss per 100 training steps: 0.01423867668845628\n","Training loss per 100 training steps: 0.014415744618443969\n","Training loss per 100 training steps: 0.014346391593910778\n","Training loss per 100 training steps: 0.014555816889797455\n","Training loss per 100 training steps: 0.01447268552718567\n","Training loss per 100 training steps: 0.014419595302598426\n","Training loss per 100 training steps: 0.01435080199752207\n","Training loss per 100 training steps: 0.014383468870414964\n","Training loss epoch: 0.014339376696936178\n","Training accuracy epoch: 0.9956562720968792\n","Validating model...\n","Validation Loss: 0.23759505293005473\n","Validation Accuracy: 0.9530471083542749\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 120.56404399999992 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.18326161538101993\n","Validation Accuracy: 0.948004346964302\n","Validation duration: 3.004688550000113 minutes\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["F1-score (test): 82.2%\n","              precision    recall  f1-score   support\n","\n","     problem       0.76      0.85      0.80     12546\n","        test       0.82      0.87      0.84      9012\n","   treatment       0.82      0.83      0.83      9297\n","\n","   micro avg       0.80      0.85      0.82     30855\n","   macro avg       0.80      0.85      0.82     30855\n","weighted avg       0.80      0.85      0.82     30855\n","\n","!!!!!! Starting model number 9 !!!!!!\n","Points in X_train after augmentation: 62400\n","Points in y_train after augmentation: 62400\n","Device:  cuda\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.850407361984253\n","Training loss per 100 training steps: 0.4015478837755647\n","Training loss per 100 training steps: 0.29429944630582533\n","Training loss per 100 training steps: 0.24937452338759686\n","Training loss per 100 training steps: 0.22175522059425154\n","Training loss per 100 training steps: 0.20132801105117726\n","Training loss per 100 training steps: 0.1867553878532174\n","Training loss per 100 training steps: 0.17588279797122966\n","Training loss per 100 training steps: 0.1675122283647923\n","Training loss per 100 training steps: 0.1603861753172453\n","Training loss per 100 training steps: 0.15392477004384095\n","Training loss per 100 training steps: 0.148290337087057\n","Training loss per 100 training steps: 0.14352795878482624\n","Training loss per 100 training steps: 0.13868275153122092\n","Training loss per 100 training steps: 0.1350923347480324\n","Training loss per 100 training steps: 0.13216933982755782\n","Training loss per 100 training steps: 0.1285787711064241\n","Training loss per 100 training steps: 0.12511670849242768\n","Training loss per 100 training steps: 0.1222095244296768\n","Training loss per 100 training steps: 0.11945615806957331\n","Training loss epoch: 0.11811410868313546\n","Training accuracy epoch: 0.9631075996083207\n","Validating model...\n","Validation Loss: 0.15671294026512217\n","Validation Accuracy: 0.9544046736170252\n","Training epoch: 2\n","Training loss per 100 training steps: 0.03042418323457241\n","Training loss per 100 training steps: 0.035797849587985486\n","Training loss per 100 training steps: 0.03742841243470523\n","Training loss per 100 training steps: 0.0399974322347187\n","Training loss per 100 training steps: 0.039322886311163444\n","Training loss per 100 training steps: 0.04076239178486971\n","Training loss per 100 training steps: 0.04518404985877209\n","Training loss per 100 training steps: 0.045640133916149274\n","Training loss per 100 training steps: 0.045987568091084896\n","Training loss per 100 training steps: 0.04597723822121805\n","Training loss per 100 training steps: 0.04531409117145711\n","Training loss per 100 training steps: 0.04489670721809807\n","Training loss per 100 training steps: 0.04521771203331047\n","Training loss per 100 training steps: 0.04485938307771217\n","Training loss per 100 training steps: 0.04432986951569397\n","Training loss per 100 training steps: 0.04362798096589759\n","Training loss per 100 training steps: 0.04348620135124207\n","Training loss per 100 training steps: 0.04312589120909326\n","Training loss per 100 training steps: 0.04293842828835928\n","Training loss per 100 training steps: 0.04303597663777847\n","Training loss epoch: 0.042901785070590004\n","Training accuracy epoch: 0.9869940510683503\n","Validating model...\n","Validation Loss: 0.18111655988137831\n","Validation Accuracy: 0.9529601360088021\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0203052069991827\n","Training loss per 100 training steps: 0.02415360436581149\n","Training loss per 100 training steps: 0.024201539193919458\n","Training loss per 100 training steps: 0.024458331643430472\n","Training loss per 100 training steps: 0.024694363132991278\n","Training loss per 100 training steps: 0.024230467386896017\n","Training loss per 100 training steps: 0.024290870287426176\n","Training loss per 100 training steps: 0.024743810236771538\n","Training loss per 100 training steps: 0.02486175149123995\n","Training loss per 100 training steps: 0.02483836177981497\n","Training loss per 100 training steps: 0.024902067022639085\n","Training loss per 100 training steps: 0.025004071905890938\n","Training loss per 100 training steps: 0.02537167351886779\n","Training loss per 100 training steps: 0.02537026812244052\n","Training loss per 100 training steps: 0.025420081322174454\n","Training loss per 100 training steps: 0.02536208522395925\n","Training loss per 100 training steps: 0.02555547570614848\n","Stopping epoch...\n","Training loss epoch: 0.02555547570614848\n","Training accuracy epoch: 0.991569470190444\n","Validating model...\n","Validation Loss: 0.20030275555690388\n","Validation Accuracy: 0.9501549220357467\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01600387878715992\n","Training loss per 100 training steps: 0.021093513520369953\n","Training loss per 100 training steps: 0.019260598139244304\n","Training loss per 100 training steps: 0.02162509499832468\n","Training loss per 100 training steps: 0.021409736741264524\n","Training loss per 100 training steps: 0.021855868247756826\n","Training loss per 100 training steps: 0.022113822557178548\n","Training loss per 100 training steps: 0.02289415802167245\n","Training loss per 100 training steps: 0.023931359577986217\n","Training loss per 100 training steps: 0.023901746648371004\n","Training loss per 100 training steps: 0.02335029253508192\n","Training loss per 100 training steps: 0.023143411695391074\n","Training loss per 100 training steps: 0.023567889893708012\n","Training loss per 100 training steps: 0.023921181861275224\n","Training loss per 100 training steps: 0.023801216484441508\n","Training loss per 100 training steps: 0.023406808641313392\n","Training loss per 100 training steps: 0.023354055214004164\n","Training loss per 100 training steps: 0.023371621526485236\n","Training loss per 100 training steps: 0.02339082639340892\n","Training loss per 100 training steps: 0.023480058694555342\n","Stopping epoch...\n","Training loss epoch: 0.023480058694555342\n","Training accuracy epoch: 0.9922253593751537\n","Validating model...\n","Validation Loss: 0.2267634967559731\n","Validation Accuracy: 0.9510962464589866\n","Training epoch: 5\n","Training loss per 100 training steps: 0.009429263882339\n","Training loss per 100 training steps: 0.013813802891752065\n","Training loss per 100 training steps: 0.016836700991690344\n","Training loss per 100 training steps: 0.016379824650792584\n","Training loss per 100 training steps: 0.0172998731670799\n","Training loss per 100 training steps: 0.017250864662438213\n","Training loss per 100 training steps: 0.017770039508647646\n","Training loss per 100 training steps: 0.01700910015073047\n","Training loss per 100 training steps: 0.01664364464357484\n","Training loss per 100 training steps: 0.01630251862785234\n","Training loss per 100 training steps: 0.01591351656145514\n","Training loss per 100 training steps: 0.016016712897077272\n","Training loss per 100 training steps: 0.01600793579473929\n","Training loss per 100 training steps: 0.01565940850661081\n","Training loss per 100 training steps: 0.015826795132422165\n","Training loss per 100 training steps: 0.016040101094278204\n","Training loss per 100 training steps: 0.016375572995361895\n","Training loss per 100 training steps: 0.016145743528974837\n","Training loss per 100 training steps: 0.01589520530993056\n","Training loss per 100 training steps: 0.01591673495544755\n","Training loss epoch: 0.015833834856367992\n","Training accuracy epoch: 0.9952171416921209\n","Validating model...\n","Validation Loss: 0.24172901704471994\n","Validation Accuracy: 0.9532502448555578\n","Training epoch: 6\n","Training loss per 100 training steps: 0.062049441039562225\n","Training loss per 100 training steps: 0.012674862931547041\n","Training loss per 100 training steps: 0.0111773370758489\n","Training loss per 100 training steps: 0.010730114633386082\n","Training loss per 100 training steps: 0.011244099619354185\n","Training loss per 100 training steps: 0.013093307467296946\n","Training loss per 100 training steps: 0.012836538713733192\n","Training loss per 100 training steps: 0.012854683988920437\n","Training loss per 100 training steps: 0.013112679529569888\n","Training loss per 100 training steps: 0.013348689498308117\n","Training loss per 100 training steps: 0.014307697711003172\n","Training loss per 100 training steps: 0.014884157831325207\n","Training loss per 100 training steps: 0.014854528892348244\n","Training loss per 100 training steps: 0.014978735833320975\n","Training loss per 100 training steps: 0.014962760053246732\n","Training loss per 100 training steps: 0.014916674711781914\n","Stopping epoch...\n","Training loss epoch: 0.014916674711781914\n","Training accuracy epoch: 0.9949024647490677\n","Validating model...\n","Validation Loss: 0.23098739681692868\n","Validation Accuracy: 0.9547051736567567\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 111.48268748333334 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.17331112628798345\n","Validation Accuracy: 0.9503776988012504\n","Validation duration: 3.0128044666666636 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 82.8%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.85      0.82     12546\n","        test       0.79      0.87      0.83      9012\n","   treatment       0.84      0.84      0.84      9297\n","\n","   micro avg       0.81      0.85      0.83     30855\n","   macro avg       0.81      0.85      0.83     30855\n","weighted avg       0.81      0.85      0.83     30855\n","\n","!!!!!! Starting model number 10 !!!!!!\n","Points in X_train after augmentation: 62400\n","Points in y_train after augmentation: 62400\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.34167742729187\n","Training loss per 100 training steps: 0.3856649055781931\n","Training loss per 100 training steps: 0.2867838721073682\n","Training loss per 100 training steps: 0.24487013399501972\n","Training loss per 100 training steps: 0.21891609890075248\n","Training loss per 100 training steps: 0.1992965741287508\n","Training loss per 100 training steps: 0.18661621194053907\n","Training loss per 100 training steps: 0.1764099113377457\n","Training loss per 100 training steps: 0.16620445973036366\n","Training loss per 100 training steps: 0.15867289229731316\n","Training loss per 100 training steps: 0.15313053671196178\n","Training loss per 100 training steps: 0.14711836728772368\n","Training loss per 100 training steps: 0.14229302936319654\n","Training loss per 100 training steps: 0.13692512423792233\n","Training loss per 100 training steps: 0.13285881894235788\n","Training loss per 100 training steps: 0.12911552305474164\n","Training loss per 100 training steps: 0.12637323101919648\n","Training loss per 100 training steps: 0.123504738899376\n","Training loss per 100 training steps: 0.12116938529857774\n","Training loss per 100 training steps: 0.11812197399971863\n","Training loss epoch: 0.11716986271887063\n","Training accuracy epoch: 0.9639901936062415\n","Validating model...\n","Validation Loss: 0.14917183575498594\n","Validation Accuracy: 0.9552095991131717\n","Training epoch: 2\n","Training loss per 100 training steps: 0.052188802510499954\n","Training loss per 100 training steps: 0.0461997083978414\n","Training loss per 100 training steps: 0.04432198273907624\n","Training loss per 100 training steps: 0.04275325361014254\n","Training loss per 100 training steps: 0.042335895682682756\n","Training loss per 100 training steps: 0.04251900125255886\n","Training loss per 100 training steps: 0.042015300639447896\n","Training loss per 100 training steps: 0.04337921952755694\n","Training loss per 100 training steps: 0.04361169269167761\n","Training loss per 100 training steps: 0.04310713033295225\n","Training loss per 100 training steps: 0.0432459305889056\n","Training loss per 100 training steps: 0.042880788692894925\n","Training loss per 100 training steps: 0.04295402553690897\n","Training loss per 100 training steps: 0.04329980652046309\n","Stopping epoch...\n","Training loss epoch: 0.04329980652046309\n","Training accuracy epoch: 0.9860125571608578\n","Validating model...\n","Validation Loss: 0.17073370801744522\n","Validation Accuracy: 0.9539608294940795\n","Training epoch: 3\n","Training loss per 100 training steps: 0.018360866233706474\n","Training loss per 100 training steps: 0.0249617625936165\n","Training loss per 100 training steps: 0.02575291518761373\n","Training loss per 100 training steps: 0.026123296549122942\n","Training loss per 100 training steps: 0.027844317929477818\n","Training loss per 100 training steps: 0.028036799812094566\n","Training loss per 100 training steps: 0.028448143644264578\n","Training loss per 100 training steps: 0.028917449449598204\n","Training loss per 100 training steps: 0.030422348091489266\n","Training loss per 100 training steps: 0.030620991472143484\n","Training loss per 100 training steps: 0.03139176562464062\n","Training loss per 100 training steps: 0.03108940498904874\n","Training loss per 100 training steps: 0.031022491580606992\n","Training loss per 100 training steps: 0.03087354273864424\n","Training loss per 100 training steps: 0.03075359332046008\n","Training loss per 100 training steps: 0.031084974646606457\n","Training loss per 100 training steps: 0.031223408923332266\n","Training loss per 100 training steps: 0.03194543770111321\n","Training loss per 100 training steps: 0.031912338967867625\n","Training loss per 100 training steps: 0.03207481959091253\n","Training loss epoch: 0.03205798752862626\n","Training accuracy epoch: 0.9902090712384304\n","Validating model...\n","Validation Loss: 0.18167339156490642\n","Validation Accuracy: 0.9540214352149776\n","Training epoch: 4\n","Training loss per 100 training steps: 0.017794905230402946\n","Training loss per 100 training steps: 0.020217145374736352\n","Training loss per 100 training steps: 0.021598476375596812\n","Training loss per 100 training steps: 0.02057699418098409\n","Training loss per 100 training steps: 0.020790383382729413\n","Training loss per 100 training steps: 0.021279427066641467\n","Training loss per 100 training steps: 0.021465775816714525\n","Training loss per 100 training steps: 0.021449056937184567\n","Training loss per 100 training steps: 0.021347839320377888\n","Training loss per 100 training steps: 0.021576588672674164\n","Training loss per 100 training steps: 0.021397886887394156\n","Training loss per 100 training steps: 0.021746676445921306\n","Training loss per 100 training steps: 0.021997860346160452\n","Training loss per 100 training steps: 0.022305205822512466\n","Training loss per 100 training steps: 0.022077401966849697\n","Training loss per 100 training steps: 0.022377018303874705\n","Training loss per 100 training steps: 0.02276195612355606\n","Training loss per 100 training steps: 0.02256694973417958\n","Training loss per 100 training steps: 0.02282636003053723\n","Training loss per 100 training steps: 0.02258964397465376\n","Training loss epoch: 0.022402422491532677\n","Training accuracy epoch: 0.9933507046218453\n","Validating model...\n","Validation Loss: 0.2064592077747568\n","Validation Accuracy: 0.9553090141565838\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0013951308792456985\n","Training loss per 100 training steps: 0.011032554754955086\n","Training loss per 100 training steps: 0.014920768032049695\n","Training loss per 100 training steps: 0.017825779627290775\n","Training loss per 100 training steps: 0.017403585383113464\n","Training loss per 100 training steps: 0.01805905150860723\n","Training loss per 100 training steps: 0.017978291011896966\n","Training loss per 100 training steps: 0.017691755772243783\n","Training loss per 100 training steps: 0.017446135657456657\n","Training loss per 100 training steps: 0.017469707845531136\n","Training loss per 100 training steps: 0.017777505214994802\n","Training loss per 100 training steps: 0.018068709391403773\n","Training loss per 100 training steps: 0.01783285967302997\n","Training loss per 100 training steps: 0.018170007076868746\n","Training loss per 100 training steps: 0.01778701271350013\n","Training loss per 100 training steps: 0.017541126393430587\n","Training loss per 100 training steps: 0.01717939462898771\n","Training loss per 100 training steps: 0.017268501270400482\n","Training loss per 100 training steps: 0.017312525188528247\n","Training loss per 100 training steps: 0.017493010650899997\n","Training loss epoch: 0.017679638571825286\n","Training accuracy epoch: 0.9949270946325044\n","Validating model...\n","Validation Loss: 0.23254903372038493\n","Validation Accuracy: 0.9491707715375917\n","Training epoch: 6\n","Training loss per 100 training steps: 0.013309234753251076\n","Training loss per 100 training steps: 0.01563843656769299\n","Training loss per 100 training steps: 0.014163375327674052\n","Training loss per 100 training steps: 0.014070621900108838\n","Training loss per 100 training steps: 0.014142003571199477\n","Training loss per 100 training steps: 0.014689847176275058\n","Training loss per 100 training steps: 0.013871036652113759\n","Training loss per 100 training steps: 0.014104305818876565\n","Training loss per 100 training steps: 0.013843501958276347\n","Training loss per 100 training steps: 0.01417261404888477\n","Training loss per 100 training steps: 0.014049596126421822\n","Training loss per 100 training steps: 0.014713943041906524\n","Training loss per 100 training steps: 0.015014473501402694\n","Training loss per 100 training steps: 0.015205556632256347\n","Training loss per 100 training steps: 0.015592693492345084\n","Training loss per 100 training steps: 0.015783363365494386\n","Training loss per 100 training steps: 0.016052787316070728\n","Training loss per 100 training steps: 0.01634371103583367\n","Training loss per 100 training steps: 0.016822780099612605\n","Training loss per 100 training steps: 0.017283958183510376\n","Training loss epoch: 0.017270807962393005\n","Training accuracy epoch: 0.9948250526066534\n","Validating model...\n","Validation Loss: 0.22739093767648394\n","Validation Accuracy: 0.952260200203233\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 113.97831856666659 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.17996352494056164\n","Validation Accuracy: 0.9492345079692005\n","Validation duration: 3.0229910000001836 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 82.1%\n","              precision    recall  f1-score   support\n","\n","     problem       0.80      0.84      0.82     12546\n","        test       0.81      0.85      0.83      9012\n","   treatment       0.79      0.85      0.82      9297\n","\n","   micro avg       0.80      0.84      0.82     30855\n","   macro avg       0.80      0.84      0.82     30855\n","weighted avg       0.80      0.84      0.82     30855\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 5\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"TTDq-xbgHqXQ"}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"06fb4d9d9a314f9f96a25e5a9ba72dce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"082416fbe0374a70aa840d32373b1804":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1595efc37ff34a24beb6036eb3b1fc16":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_082416fbe0374a70aa840d32373b1804","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1adf0f98ae5f420a8d9754a48719ab18","value":442221694}},"1adf0f98ae5f420a8d9754a48719ab18":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3124d71931f44156a6737e7747a2ea67":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_860be2970fe04c79a6295e7ece6c32b5","placeholder":"​","style":"IPY_MODEL_91b53b5485fd46f8a6d4049fbeb9f213","value":" 422M/422M [00:10&lt;00:00, 42.9MB/s]"}},"33e9181dfd65491cb79b59c2b88700b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_06fb4d9d9a314f9f96a25e5a9ba72dce","placeholder":"​","style":"IPY_MODEL_e7a7ede4d38646049398f410b2a6436d","value":"Downloading pytorch_model.bin: 100%"}},"7f39218bd9e94f42804878d7b24bf091":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"860be2970fe04c79a6295e7ece6c32b5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91b53b5485fd46f8a6d4049fbeb9f213":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7e790affc224260ba0287b41d541400":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_33e9181dfd65491cb79b59c2b88700b6","IPY_MODEL_1595efc37ff34a24beb6036eb3b1fc16","IPY_MODEL_3124d71931f44156a6737e7747a2ea67"],"layout":"IPY_MODEL_7f39218bd9e94f42804878d7b24bf091"}},"e7a7ede4d38646049398f410b2a6436d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f794176752c147a8978620015ef059df":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_db1a788a2ed64374b3f0707280cbf94e","IPY_MODEL_8878302fdb034699a5bd4071a04de8be","IPY_MODEL_1cb888d325ef4dc3b022d0e7b234963a"],"layout":"IPY_MODEL_898922645c0b44a7abbc8da8412dfc8b"}},"db1a788a2ed64374b3f0707280cbf94e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f216f0060794c27b2a603a9e7caedb5","placeholder":"​","style":"IPY_MODEL_bfb1229dab304099bd5505078880f204","value":"Downloading pytorch_model.bin: 100%"}},"8878302fdb034699a5bd4071a04de8be":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6691a45f7b44d05bd9029381a28db3f","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6a1169ca86a74125a8e0badc1838b8e2","value":442221694}},"1cb888d325ef4dc3b022d0e7b234963a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b63def031f54ab6beff9d81c39a3d50","placeholder":"​","style":"IPY_MODEL_78e1e51f7f1d49539e408765d5661e28","value":" 422M/422M [00:11&lt;00:00, 42.8MB/s]"}},"898922645c0b44a7abbc8da8412dfc8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f216f0060794c27b2a603a9e7caedb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfb1229dab304099bd5505078880f204":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6691a45f7b44d05bd9029381a28db3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a1169ca86a74125a8e0badc1838b8e2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3b63def031f54ab6beff9d81c39a3d50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78e1e51f7f1d49539e408765d5661e28":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"105feddb6f034fe194158159b05a740f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_89d3749f6f3e43928c0a545a99eb07c9","IPY_MODEL_45e2bf54206d462ba2bee09bd760580e","IPY_MODEL_97ab2f9a065e4410b401370a62e3d337"],"layout":"IPY_MODEL_2121861b1bcd454ea310bdc072279747"}},"89d3749f6f3e43928c0a545a99eb07c9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5dcfdb74f564920a4de7b9402613dfe","placeholder":"​","style":"IPY_MODEL_808597727b9446e99aaf8570728ff4fa","value":"Downloading pytorch_model.bin: 100%"}},"45e2bf54206d462ba2bee09bd760580e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_30dcd7346c9c46beb27912724d826ece","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a74b1376988f43619ccc8e52d0e060a8","value":442221694}},"97ab2f9a065e4410b401370a62e3d337":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_118c4e85f70345fb8ca60a169683b738","placeholder":"​","style":"IPY_MODEL_e35669675ce7403194e16f9cd2e0ec56","value":" 422M/422M [00:07&lt;00:00, 56.3MB/s]"}},"2121861b1bcd454ea310bdc072279747":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5dcfdb74f564920a4de7b9402613dfe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"808597727b9446e99aaf8570728ff4fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30dcd7346c9c46beb27912724d826ece":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a74b1376988f43619ccc8e52d0e060a8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"118c4e85f70345fb8ca60a169683b738":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e35669675ce7403194e16f9cd2e0ec56":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c631fa573bc34eafbf113d4e018afe65":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a111c5e826ab4be58cae5a7f3af95e94","IPY_MODEL_535290cff93a45f4bada025eaab4eff8","IPY_MODEL_4f0a61d7e48543b08b387e33475d295d"],"layout":"IPY_MODEL_11121e627af64c21a10ac585c21ebe9f"}},"a111c5e826ab4be58cae5a7f3af95e94":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a988982cc84417d848419ce63f65d14","placeholder":"​","style":"IPY_MODEL_f9905291d00843b598bde6f6db21b2be","value":""}},"535290cff93a45f4bada025eaab4eff8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_86eea101b95e4e3ba1698223e507a48d","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8bb580a498994889a2df1592a0a15f1d","value":0}},"4f0a61d7e48543b08b387e33475d295d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b76e80d789248b393adfd553f87a5b3","placeholder":"​","style":"IPY_MODEL_590227fa043b407db61c2b0b5ca03da1","value":" 0/0 [00:00&lt;?, ?it/s]"}},"11121e627af64c21a10ac585c21ebe9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a988982cc84417d848419ce63f65d14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9905291d00843b598bde6f6db21b2be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"86eea101b95e4e3ba1698223e507a48d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"8bb580a498994889a2df1592a0a15f1d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7b76e80d789248b393adfd553f87a5b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"590227fa043b407db61c2b0b5ca03da1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"addd27a142ba46ff80e97790370921bf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_01b2505f04ec478a936db3d74bfc6a81","IPY_MODEL_491bd9fea64049babacf83a7bd0948ff","IPY_MODEL_66c397fcea274c1185f0917419c219b4"],"layout":"IPY_MODEL_2322b3af723747c0bdf4fad716dc19ba"}},"01b2505f04ec478a936db3d74bfc6a81":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_941ab7af1311403f91f264e28faba315","placeholder":"​","style":"IPY_MODEL_75ade324d0cb4d8ca43cebfe6bb140d9","value":"Downloading: 100%"}},"491bd9fea64049babacf83a7bd0948ff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_585265746b0f4578b0ae9a9247d2394b","max":385,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9bd824919b9f47eebb9bc757d6caf087","value":385}},"66c397fcea274c1185f0917419c219b4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d509ff9d70884d689598ddeef8cddc19","placeholder":"​","style":"IPY_MODEL_e52bd61e089b46d1965f10203624b568","value":" 385/385 [00:00&lt;00:00, 14.5kB/s]"}},"2322b3af723747c0bdf4fad716dc19ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"941ab7af1311403f91f264e28faba315":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75ade324d0cb4d8ca43cebfe6bb140d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"585265746b0f4578b0ae9a9247d2394b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bd824919b9f47eebb9bc757d6caf087":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d509ff9d70884d689598ddeef8cddc19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e52bd61e089b46d1965f10203624b568":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"697a349b7b8b42bf899447f187c7c6fb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b103889bf8134f3182fbac1c4624ea5e","IPY_MODEL_d982cc83a9ae43999d026d862c649fa0","IPY_MODEL_cbfa298ce7f5434da8b3e272bfc7f0ef"],"layout":"IPY_MODEL_96bcf4fe895145a09485cbb0cd70043f"}},"b103889bf8134f3182fbac1c4624ea5e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2ea4d0941344b6d972a65fce125fc76","placeholder":"​","style":"IPY_MODEL_b121188b42ab49aeaacff5a047f625c5","value":"Downloading: 100%"}},"d982cc83a9ae43999d026d862c649fa0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_359b414844324309936cb62140ffd2b3","max":227845,"min":0,"orientation":"horizontal","style":"IPY_MODEL_18f6f36dc74d43aeb6a0f4474f60fa16","value":227845}},"cbfa298ce7f5434da8b3e272bfc7f0ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_abc7e8745f584378843a5b2f3c7e3ebd","placeholder":"​","style":"IPY_MODEL_4e6fc455ecc247bd93c72de835c66054","value":" 228k/228k [00:00&lt;00:00, 644kB/s]"}},"96bcf4fe895145a09485cbb0cd70043f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2ea4d0941344b6d972a65fce125fc76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b121188b42ab49aeaacff5a047f625c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"359b414844324309936cb62140ffd2b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18f6f36dc74d43aeb6a0f4474f60fa16":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"abc7e8745f584378843a5b2f3c7e3ebd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e6fc455ecc247bd93c72de835c66054":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b36f27f2a26406caf7ea9c1ee2cac0e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b7b792856a1740a1a02f832912822940","IPY_MODEL_ff531fefa439415c9fbae9e904baf492","IPY_MODEL_0e5f5dd0ddc24e7098087c2641595f2b"],"layout":"IPY_MODEL_7337660960104fa987723c5d2c335658"}},"b7b792856a1740a1a02f832912822940":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d476390ea7b54c0781c51b4a620a6345","placeholder":"​","style":"IPY_MODEL_693a26e28794428988c459e38a82c290","value":"Downloading: 100%"}},"ff531fefa439415c9fbae9e904baf492":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e8494a4d1634008b8a92632a58af86d","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5086d87cdbc54da1ba3480c73c29d626","value":442221694}},"0e5f5dd0ddc24e7098087c2641595f2b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb8760dbfc164a09a84b582e23df2bb5","placeholder":"​","style":"IPY_MODEL_f98e5596133045deaec8d624b8ffce66","value":" 442M/442M [00:09&lt;00:00, 45.9MB/s]"}},"7337660960104fa987723c5d2c335658":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d476390ea7b54c0781c51b4a620a6345":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"693a26e28794428988c459e38a82c290":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e8494a4d1634008b8a92632a58af86d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5086d87cdbc54da1ba3480c73c29d626":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eb8760dbfc164a09a84b582e23df2bb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f98e5596133045deaec8d624b8ffce66":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9210d842c1594f8a8ad3d30d6fad0a2a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4d41ee073a6b4f9bb6112d03c2666c70","IPY_MODEL_19c686e869bf409d9ef70824a3c1913e","IPY_MODEL_86f31acba0d64c9198aa0de1c22b0b43"],"layout":"IPY_MODEL_45d3eff351424c35924a119ba4c2db06"}},"4d41ee073a6b4f9bb6112d03c2666c70":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d99347b22734b029064dadd85f7555f","placeholder":"​","style":"IPY_MODEL_b22a0690c25c46139d1aee16937afc51","value":"Downloading: 100%"}},"19c686e869bf409d9ef70824a3c1913e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6af09be8da74f87a9a48ab37dbe255f","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d2dc5739ee5446c0a9e439769417ff78","value":442221694}},"86f31acba0d64c9198aa0de1c22b0b43":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_901e562e03d041189bc873b3d5f5eebc","placeholder":"​","style":"IPY_MODEL_d337f2283fb240beb42fb3960abab836","value":" 442M/442M [00:16&lt;00:00, 25.7MB/s]"}},"45d3eff351424c35924a119ba4c2db06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d99347b22734b029064dadd85f7555f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b22a0690c25c46139d1aee16937afc51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b6af09be8da74f87a9a48ab37dbe255f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2dc5739ee5446c0a9e439769417ff78":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"901e562e03d041189bc873b3d5f5eebc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d337f2283fb240beb42fb3960abab836":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}