{"cells":[{"cell_type":"markdown","metadata":{"id":"FFh7WVoJH5dr"},"source":["Adapted from [ner_with_bilstm_and_crf](https://www.kaggle.com/nikkisharma536/ner-with-bilstm-and-crf/notebook)\n","Altigran Soares da Silva\n","IComp/UFAM - 15/03/2021\n"],"id":"FFh7WVoJH5dr"},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":190721,"status":"ok","timestamp":1666941691934,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"zvip_oC0j5-y","outputId":"392411ba-bbb8-4151-cf12-de24e5f1e7df"},"outputs":[{"output_type":"stream","name":"stdout","text":["Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 4.8 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n","\u001b[K     |████████████████████████████████| 5.3 MB 4.7 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 67.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n","\u001b[K     |████████████████████████████████| 163 kB 88.4 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.23.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 1.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=ee38202982ce66f1fe5d76a30aed1657e38ab1632cf6b6abc7505bf18217cac2\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n","[38, 9828, 11595, 17260, 14340, 11382, 2719, 4418, 332, 3312, 5556, 13073]\n","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[8046, 10853, 15408, 11382, 4005, 1023, 5556, 17246, 17691, 8789, 11038, 13073]\n","[4, 1, 1, 0, 2, 3, 4, 0, 0, 0, 0, 0]\n","[13907, 8259, 12121, 18312, 13073, 8814, 9754, 9828, 232, 14415, 13073]\n","[2, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0]\n","3970\n","4\n","B-Chemical\n","View\n","18533\n","5\n"]}],"source":["# Uncomment this cell if you want to load saved data\n","\n","# Re-import necessary libs\n","import pandas as pd\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","import pickle, math\n","from requests import get\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import random\n","import time\n","%tensorflow_version 2.x\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import torch\n","from torch import cuda\n","from torch.utils.data import Dataset, DataLoader\n","!pip install sentencepiece\n","!pip install transformers\n","from transformers import BertForTokenClassification, AutoTokenizer\n","import matplotlib.pyplot as plt\n","!pip install seqeval\n","from seqeval.metrics import f1_score, classification_report\n","\n","BACKUP_FOLDER_ID = '1EwDUGjrtg8AiUhBFAImg5vEUXxYEqQcS'\n","notebook_filename = get('http://172.28.0.2:9000/api/sessions').json()[0]['name'].replace(\"_CWR\",\"\")\n","\n","X_train_filename = f'{notebook_filename}_X_train.csv'\n","y_train_filename = f'{notebook_filename}_y_train.csv'\n","X_dev_filename = f'{notebook_filename}_X_dev.csv'\n","y_dev_filename = f'{notebook_filename}_y_dev.csv'\n","X_test_filename = f'{notebook_filename}_X_test.csv'\n","y_test_filename = f'{notebook_filename}_y_test.csv'\n","\n","word2idx_filename = f'{notebook_filename}_word2idx.pkl'\n","idx2word_filename = f'{notebook_filename}_idx2word.pkl'\n","tag2idx_filename = f'{notebook_filename}_tag2idx.pkl'\n","idx2tag_filename = f'{notebook_filename}_idx2tag.pkl'\n","\n","others_filename = f'{notebook_filename}_others.pkl'\n","\n","# Re-get important variables\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","def get_backup_files_ids(folder_id):\n","  file_list = drive.ListFile({'q': \"'{}' in parents and trashed=false\".format(folder_id)}).GetList()\n","  return file_list\n","\n","def load_backup_dataset(file_id):\n","  downloaded = drive.CreateFile({'id':file_id})\n","  downloaded.GetContentFile(f\"{file_id}.csv\")\n","\n","  dataset = pd.read_csv(f\"{file_id}.csv\", encoding=\"latin1\")\n","  dataset = dataset.values.tolist()\n","  dataset = [ [ int(word) for word in sentence if str(word) != 'nan' ] for sentence in dataset]\n","  return dataset\n","\n","def load_backup_dict(file_id):\n","  downloaded = drive.CreateFile({'id':file_id})\n","  downloaded.GetContentFile(f\"{file_id}.pkl\")\n","\n","  dict_file = open(f\"{file_id}.pkl\", \"rb\")\n","  out_dict = pickle.load(dict_file)\n","  return out_dict\n","\n","backup_file_list = get_backup_files_ids(BACKUP_FOLDER_ID)\n","\n","X_train_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == X_train_filename][0]['id']\n","y_train_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == y_train_filename][0]['id']\n","X_dev_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == X_dev_filename][0]['id']\n","y_dev_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == y_dev_filename][0]['id']\n","X_test_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == X_test_filename][0]['id']\n","y_test_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == y_test_filename][0]['id']\n","\n","word2idx_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == word2idx_filename][0]['id']\n","idx2word_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == idx2word_filename][0]['id']\n","tag2idx_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == tag2idx_filename][0]['id']\n","idx2tag_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == idx2tag_filename][0]['id']\n","\n","others_file_id = [backup_file for backup_file in backup_file_list if backup_file['title'] == others_filename][0]['id']\n","\n","X_train = load_backup_dataset(X_train_file_id)\n","y_train = load_backup_dataset(y_train_file_id)\n","X_dev = load_backup_dataset(X_dev_file_id)\n","y_dev = load_backup_dataset(y_dev_file_id)\n","X_test = load_backup_dataset(X_test_file_id)\n","y_test = load_backup_dataset(y_test_file_id)\n","\n","word2idx = load_backup_dict(word2idx_file_id)\n","idx2word = load_backup_dict(idx2word_file_id)\n","tag2idx = load_backup_dict(tag2idx_file_id)\n","idx2tag = load_backup_dict(idx2tag_file_id)\n","\n","others = load_backup_dict(others_file_id)\n","\n","n_words = others[\"n_words\"]\n","n_tags = others[\"n_tags\"]\n","\n","# Check some points after loading data to see if they match the ones before saving\n","print(X_train[0])\n","print(y_train[0])\n","print(X_dev[0])\n","print(y_dev[0])\n","print(X_test[0])\n","print(y_test[0])\n","print(word2idx['incidence'])\n","print(tag2idx['B-Disease'])\n","print(idx2tag[2])\n","print(idx2word[100])\n","print(n_words)\n","print(n_tags)"],"id":"zvip_oC0j5-y"},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["e0c735b1553040eba5d4121424132937","80d599a4d2f84b28a446b2623ec38b41","ff3ed544fa284ef7a3b2b92383f027cc","6536b532f1384782800c806561663765","d557a5729739409d8b81767bcf9d96d3","94b54acd9e8946eb806fcaa617ac06a2","bb54d058950645cd94ae5d5586945918","96511072903a44abbbc015fc8e9b75a4","47cddd2f081f498fa57de353e7909669","af1851777b8b4dce8d9bc711f2df0e90","4f9ebcd5f5be4f2daf51be7fc63f80ef","477c2dee0fde4d288d6089cb972f328a","ff3f6dd76daa475cbed802c23d176a48","359642753acc48319b4d58797d331359","af6b4c0f9127404ba9c3af4e78b6faf9","dcc981fb03b049ef80b77a5f16b1d673","c8877048532e4cc59523a20c349ac234","d4f71e53bb5146f7b9b4abf578f1020f","91eb8b6a07324de09316daa5049eb28c","f80eed4cf1ec4e6386db032ebc96a20c","767cbd9ba11e45149f4bac28d6a6f564","d8a05c16f4f44ced9ae6f32d666afe1c"]},"executionInfo":{"elapsed":2955,"status":"ok","timestamp":1666941694886,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"2wRVTj71hovp","outputId":"60c715c9-069c-42d3-bcb5-0970b96cd26a"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/385 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0c735b1553040eba5d4121424132937"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/228k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"477c2dee0fde4d288d6089cb972f328a"}},"metadata":{}}],"source":["tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n","\n","from transformers import pipeline\n","from future.utils import iteritems\n","\n","# Augmentation function using entity replacement technique.\n","# It will generate a new dataset, with X% more points based on\n","# the original dataset. E.g.: if you set augmentation percentage as 0.5 and dataset has\n","# 1000 points, it will generate a dataset with 1500 points.\n","\n","def generate_sentences(dataset, labels, augmented_set_size_percentage):\n","    if augmented_set_size_percentage < 0:\n","        raise Exception(\"Invalid augmented set size percentage\")\n","\n","    unmasker = pipeline('fill-mask', model='allenai/scibert_scivocab_uncased')\n","    \n","    number_of_new_sentences = math.ceil(augmented_set_size_percentage * len(dataset))\n","\n","    found_subset = False\n","\n","    while not found_subset:\n","      random_idxs = np.random.choice(len(dataset), number_of_new_sentences, replace=True)\n","      base_labels = [labels[i] for i in random_idxs]\n","      found_subset = all([tag2idx[\"O\"] in labels for labels in base_labels])\n","\n","    base_sequences = [dataset[i] for i in random_idxs]\n","\n","    new_sequences = []\n","    new_labels = []\n","    \n","    for k, sequence in enumerate(base_sequences):\n","      sequence_str = [idx2word[word] for word in sequence]\n","\n","      # check max number of tokens bert support and truncate sentence before augmentation\n","      # augmented sentence will be shorter than original sentence if higher than bert limit\n","      encoding = tokenizer(sequence_str,\n","                             is_split_into_words=True, \n","                             return_offsets_mapping=True, \n","                             truncation=True, \n","                             max_length=512)\n","      \n","      max_n_of_tokens = len([mapping for mapping in encoding[\"offset_mapping\"] if mapping[0] == 0 and mapping[1] != 0])\n","\n","      truncated_sequence_str = sequence_str[:max_n_of_tokens]\n","      truncated_labels = base_labels[k][:max_n_of_tokens]\n","\n","      # print(len(sequence_str),len(truncated_sequence_str),len(base_labels[k]),len(truncated_labels))\n","\n","      replaceable_indices = [i for i,label in enumerate(truncated_labels) if label == tag2idx[\"O\"]]\n","      replace_percent = round(random.uniform(0.1, 1), 1)\n","      replace_qty = max(math.floor(replace_percent*len(replaceable_indices)), 1)\n","      replace_indices = random.sample(replaceable_indices, k=replace_qty)\n","      replace_indices.sort()\n","\n","      masked_text_list = [\"[MASK]\" if i in replace_indices else word for i,word in enumerate(truncated_sequence_str)]\n","      new_mask_sent = ' '.join(masked_text_list)\n","      augmented_text_list = unmasker(new_mask_sent)\n","\n","      augmented_sentence = truncated_sequence_str.copy()\n","      if len(replace_indices) == 1:\n","        augmented_text_list = [augmented_text_list]\n","\n","      for i,index in enumerate(replace_indices):\n","        available_words = [word[\"token_str\"] for word in augmented_text_list[i] if word[\"token_str\"] != truncated_sequence_str[index]]\n","        new_word = random.choice(available_words)\n","        if new_word != \"[UNK]\":\n","          augmented_sentence[index] = new_word\n","\n","      # print(\"Original text->\",len(sequence_str),sequence_str)\n","      # print(\"Augmented text->\",len(sequence_str),augmented_sentence)\n","\n","      new_sequences.append(augmented_sentence)\n","      new_labels.append(truncated_labels)\n","\n","    all_words = list(set([word for seq in new_sequences for word in seq]))\n","    updated_word2idx = word2idx.copy()\n","    updated_idx2word = idx2word.copy()\n","    for word in all_words:\n","      try:\n","        updated_word2idx[word]\n","      except:\n","        updated_word2idx[word] = len(updated_word2idx)\n","    updated_idx2word = {i: w for w, i in iteritems(updated_word2idx)}\n","\n","    new_sequences = [[updated_word2idx[word] for word in seq] for seq in new_sequences]\n","\n","    augmented_X_train = dataset + new_sequences\n","    augmented_y_train = labels + new_labels\n","\n","    print(f\"Points in X_train after augmentation: {len(augmented_X_train)}\")\n","    print(f\"Points in y_train after augmentation: {len(augmented_y_train)}\")\n","\n","    return augmented_X_train, augmented_y_train, updated_word2idx, updated_idx2word"],"id":"2wRVTj71hovp"},{"cell_type":"code","execution_count":3,"metadata":{"id":"mYHzTnzZZfBg","executionInfo":{"status":"ok","timestamp":1666941695909,"user_tz":240,"elapsed":610,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"}}},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n","\n","class dataset(Dataset):\n","  def __init__(self, dataframe, tokenizer, max_len):\n","        self.len = len(dataframe)\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","  def __getitem__(self, index):\n","        # step 1: get the sentence and word labels\n","        sentence = self.data.sentence[index]\n","        word_labels = self.data.word_labels[index].split(\",\") \n","\n","        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n","        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n","        encoding = self.tokenizer(sentence,\n","                             is_split_into_words=True,\n","                             return_offsets_mapping=True, \n","                             padding='max_length', \n","                             truncation=True, \n","                             max_length=self.max_len)\n","        \n","        # step 3: create token labels only for first word pieces of each tokenized word\n","        labels = [tag2idx[label] for label in word_labels] \n","        # code based on https://huggingface.co/transformers/custom_datasets.html#tok-ner\n","        # create an empty array of -100 of length max_length\n","        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n","        \n","        # set only labels whose first offset position is 0 and the second is not 0\n","        i = 0\n","        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n","          if mapping[0] == 0 and mapping[1] != 0:\n","            # overwrite label\n","            encoded_labels[idx] = labels[i]\n","            i += 1\n","\n","        # step 4: turn everything into PyTorch tensors\n","        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n","        item['labels'] = torch.as_tensor(encoded_labels)\n","        \n","        return item\n","\n","  def __len__(self):\n","        return self.len"],"id":"mYHzTnzZZfBg"},{"cell_type":"code","execution_count":4,"metadata":{"id":"d8H1s-6b_-pM","executionInfo":{"status":"ok","timestamp":1666941695910,"user_tz":240,"elapsed":9,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"}}},"outputs":[],"source":["# some configuration variables\n","LEARNING_RATE = 5e-05\n","MAX_GRAD_NORM = 10\n","TRAINING_STOP_LOSS_PERCENTAGE = 1\n","\n","# Model creation function\n","def create_model(maxlen, n_labels, training_set, testing_set, validation_set):\n","  device = 'cuda' if cuda.is_available() else 'cpu'\n","  print(\"Device: \", device)\n","\n","  model = BertForTokenClassification.from_pretrained('allenai/scibert_scivocab_uncased', num_labels=n_labels)\n","  model.to(device)\n","\n","  optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n","\n","  TRAIN_BATCH_SIZE = round(0.05*len(training_set))\n","  if TRAIN_BATCH_SIZE > 16:\n","    TRAIN_BATCH_SIZE = 16\n","  if TRAIN_BATCH_SIZE < 10:\n","    TRAIN_BATCH_SIZE = 10\n","\n","  VALID_BATCH_SIZE = round(0.1*len(validation_set))\n","  if VALID_BATCH_SIZE > 16:\n","    VALID_BATCH_SIZE = 16\n","  if VALID_BATCH_SIZE < 10:\n","    VALID_BATCH_SIZE = 10\n","\n","  train_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                  'shuffle': True,\n","                  'num_workers': 0\n","                  }\n","\n","  test_params = {'batch_size': VALID_BATCH_SIZE,\n","                  'shuffle': True,\n","                  'num_workers': 0\n","                  }\n","\n","  training_loader = DataLoader(training_set, **train_params)\n","  testing_loader = DataLoader(testing_set, **test_params)\n","  validation_loader = DataLoader(validation_set, **test_params)\n","\n","  return model, device, optimizer, training_loader, testing_loader, validation_loader"],"id":"d8H1s-6b_-pM"},{"cell_type":"code","execution_count":5,"metadata":{"id":"cjp-jXx4AmiV","executionInfo":{"status":"ok","timestamp":1666941695910,"user_tz":240,"elapsed":8,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"}}},"outputs":[],"source":["# Model training function\n","def train(model, device, optimizer, training_loader, epoch, training_stop_loss_percentage):\n","    tr_loss, tr_accuracy = 0, 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","    tr_preds, tr_labels = [], []\n","    losses = []\n","    # put model in training mode\n","    model.train()\n","    \n","    for idx, batch in enumerate(training_loader):\n","        \n","        ids = batch['input_ids'].to(device, dtype = torch.long)\n","        mask = batch['attention_mask'].to(device, dtype = torch.long)\n","        labels = batch['labels'].to(device, dtype = torch.long)\n","\n","        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels, return_dict = False)\n","        tr_loss += loss.item()\n","\n","        nb_tr_steps += 1\n","        nb_tr_examples += labels.size(0)\n","        \n","        if idx % 100==0:\n","            loss_step = tr_loss/nb_tr_steps\n","            print(f\"Training loss per 100 training steps: {loss_step}\")\n","            losses.append(loss_step)\n","            last_5_losses = losses[-5:]\n","            loss_min = min(last_5_losses)\n","            loss_max = max(last_5_losses)\n","            if len(last_5_losses) > 1 and (loss_max - loss_min)/loss_max < training_stop_loss_percentage/100:\n","              print(\"Stopping epoch...\")\n","              break\n","           \n","        # compute training accuracy\n","        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","        \n","        # only compute accuracy at active labels\n","        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n","        \n","        labels = torch.masked_select(flattened_targets, active_accuracy)\n","        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","        \n","        tr_labels.extend(labels)\n","        tr_preds.extend(predictions)\n","\n","        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n","        tr_accuracy += tmp_tr_accuracy\n","    \n","        # gradient clipping\n","        torch.nn.utils.clip_grad_norm_(\n","            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n","        )\n","        \n","        # backward pass\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    epoch_loss = tr_loss / nb_tr_steps\n","    tr_accuracy = tr_accuracy / nb_tr_steps\n","    print(f\"Training loss epoch: {epoch_loss}\")\n","    print(f\"Training accuracy epoch: {tr_accuracy}\")"],"id":"cjp-jXx4AmiV"},{"cell_type":"code","execution_count":6,"metadata":{"id":"JvdztU6FA8Bd","executionInfo":{"status":"ok","timestamp":1666941695911,"user_tz":240,"elapsed":9,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"}}},"outputs":[],"source":["# Model testing function\n","def test(model, device, testing_loader):\n","    print(\"Validating model...\")\n","    # put model in evaluation mode\n","    model.eval()\n","    \n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_examples, nb_eval_steps = 0, 0\n","    eval_preds, eval_labels = [], []\n","    \n","    with torch.no_grad():\n","        for idx, batch in enumerate(testing_loader):\n","            \n","            ids = batch['input_ids'].to(device, dtype = torch.long)\n","            mask = batch['attention_mask'].to(device, dtype = torch.long)\n","            labels = batch['labels'].to(device, dtype = torch.long)\n","            \n","            loss, eval_logits = model(input_ids=ids, attention_mask=mask, labels=labels, return_dict = False)\n","            \n","            eval_loss += loss.item()\n","\n","            nb_eval_steps += 1\n","            nb_eval_examples += labels.size(0)\n","        \n","            # compute evaluation accuracy\n","            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","            \n","            # only compute accuracy at active labels\n","            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","        \n","            labels = torch.masked_select(flattened_targets, active_accuracy)\n","            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","            \n","            eval_labels.extend(labels)\n","            eval_preds.extend(predictions)\n","            \n","            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n","            eval_accuracy += tmp_eval_accuracy\n","\n","    labels = [idx2tag[id.item()] for id in eval_labels]\n","    predictions = [idx2tag[id.item()] for id in eval_preds]\n","    \n","    eval_loss = eval_loss / nb_eval_steps\n","    eval_accuracy = eval_accuracy / nb_eval_steps\n","    print(f\"Validation Loss: {eval_loss}\")\n","    print(f\"Validation Accuracy: {eval_accuracy}\")\n","\n","    return labels, predictions, eval_loss"],"id":"JvdztU6FA8Bd"},{"cell_type":"code","execution_count":7,"metadata":{"id":"jMknjbDrh6Fk","executionInfo":{"status":"ok","timestamp":1666941695911,"user_tz":240,"elapsed":9,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"}}},"outputs":[],"source":["def create_train_and_validate_model(augmented_percentage):\n","\n","  augmented_X_train, augmented_y_train, updated_word2idx, updated_idx2word = generate_sentences(X_train, y_train, augmented_percentage)\n","\n","  maxlen_X_train = max([len(s) for s in augmented_X_train])\n","  maxlen_X_test = max([len(s) for s in X_test])\n","  maxlen_X_dev = max([len(s) for s in X_dev])\n","  maxlen_y_train = max([len(s) for s in augmented_y_train])\n","  maxlen_y_test = max([len(s) for s in y_test])\n","  maxlen_y_dev = max([len(s) for s in y_dev])\n","\n","  maxlen = max([maxlen_X_train, maxlen_X_test, maxlen_X_dev, maxlen_y_train, maxlen_y_test, maxlen_y_dev])\n","\n","  if maxlen > 512:\n","    maxlen = 512\n","\n","  augmented_X_train_words = [[updated_idx2word[word] for word in sentence] for sentence in augmented_X_train]\n","  X_dev_words = [[updated_idx2word[word] for word in sentence] for sentence in X_dev]\n","  X_test_words = [[updated_idx2word[word] for word in sentence] for sentence in X_test]\n","  augmented_y_train_tags = [','.join([idx2tag[tag] for tag in sentence]) for sentence in augmented_y_train]\n","  y_dev_tags = [','.join([idx2tag[tag] for tag in sentence]) for sentence in y_dev]\n","  y_test_tags = [','.join([idx2tag[tag] for tag in sentence]) for sentence in y_test]\n","\n","  new_train_df = pd.DataFrame({\"sentence\": augmented_X_train_words, \"word_labels\": augmented_y_train_tags}).reset_index(drop=True)\n","  new_test_df = pd.DataFrame({\"sentence\": X_test_words, \"word_labels\": y_test_tags}).reset_index(drop=True)\n","  new_val_df = pd.DataFrame({\"sentence\": X_dev_words, \"word_labels\": y_dev_tags}).reset_index(drop=True)\n","\n","  training_set = dataset(new_train_df, tokenizer, maxlen)\n","  testing_set = dataset(new_test_df, tokenizer, maxlen)\n","  validation_set = dataset(new_val_df, tokenizer, maxlen)\n","\n","  model, device, optimizer, training_loader, testing_loader, val_loader = create_model(maxlen, len(tag2idx), training_set, testing_set, validation_set)\n","\n","  training_start_time = time.clock()\n","  min_val_loss = 0\n","  MAX_PATIENCE = 5\n","  patience = 0\n","\n","  for epoch in range(100):\n","    print(f\"Training epoch: {epoch + 1}\")\n","    if patience == MAX_PATIENCE:\n","      print(\"Patience limit reached\")\n","      break\n","    train(model, device, optimizer, training_loader, epoch, TRAINING_STOP_LOSS_PERCENTAGE)\n","    labels, predictions, val_loss = test(model, device, val_loader)\n","    if ((min_val_loss == 0) or (min_val_loss != 0 and val_loss < min_val_loss)):\n","      min_val_loss = val_loss\n","      torch.save(model.state_dict(), 'checkpoint.pt')\n","      patience = 0\n","    else:\n","      patience = patience + 1\n","  print(f\"Training duration: {(time.clock() - training_start_time)/60} minutes\")\n","\n","  checkpoint = torch.load('checkpoint.pt')\n","  model.load_state_dict(checkpoint)\n","\n","  validation_start_time = time.clock()\n","  labels, predictions, test_loss = test(model, device, testing_loader)\n","  labels = [labels]\n","  predictions = [predictions]\n","  print(f\"Validation duration: {(time.clock() - validation_start_time)/60} minutes\")\n","\n","  print(\"F1-score (test): {:.1%}\".format(f1_score(labels, predictions)))\n","  print(classification_report(labels, predictions))"],"id":"jMknjbDrh6Fk"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["30fd7733890e43deb85fef8f6d1f0c26","73b8a843f1c24871a5bd2ce347e38488","57eb5e4091b6425391e7d24cb66e9c4b","2820b745bf554c21ab1cb07a8cb6ef91","ecf3d5d4026c4744a69df7f7d7fe5f52","03174a9e298c421db09bae5ab3c7f612","e06107533ab049508edf9f6d724d857c","1347f3d0e6dd480b9710e8faa9f6de00","c01ca9f35f0e4024ab39bce7e42b637c","165186d7f5fb43c4a1570c8e753014c3","9bc265cb8db247c7958204cdfd8e2cdf"]},"executionInfo":{"elapsed":9636026,"status":"ok","timestamp":1666857494754,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"Jhz9BiIwGCsV","outputId":"930fa085-d6ea-4e7d-8f77-1e664ef2234f"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 25.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"30fd7733890e43deb85fef8f6d1f0c26","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 938\n","Points in y_train after augmentation: 938\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.067539930343628\n","Training loss epoch: 0.23349043979483136\n","Training accuracy epoch: 0.9281817718622991\n","Validating model...\n","Validation Loss: 0.08749619043535656\n","Validation Accuracy: 0.9696917168326212\n","Training epoch: 2\n","Training loss per 100 training steps: 0.053251706063747406\n","Training loss epoch: 0.06380673968312094\n","Training accuracy epoch: 0.9791789195940973\n","Validating model...\n","Validation Loss: 0.07099897485403787\n","Validation Accuracy: 0.9763364824211916\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02353999763727188\n","Training loss epoch: 0.03395073830891969\n","Training accuracy epoch: 0.9892735538956974\n","Validating model...\n","Validation Loss: 0.0796014057797572\n","Validation Accuracy: 0.9747137706879673\n","Training epoch: 4\n","Training loss per 100 training steps: 0.032576724886894226\n","Training loss epoch: 0.02141835288760268\n","Training accuracy epoch: 0.9933896791834073\n","Validating model...\n","Validation Loss: 0.08083195591138469\n","Validation Accuracy: 0.9768770519447992\n","Training epoch: 5\n","Training loss per 100 training steps: 0.00831135269254446\n","Training loss epoch: 0.01563321309700861\n","Training accuracy epoch: 0.9951416930480891\n","Validating model...\n","Validation Loss: 0.0867490257535662\n","Validation Accuracy: 0.9769354681108383\n","Training epoch: 6\n","Training loss per 100 training steps: 0.006061049178242683\n","Training loss epoch: 0.011053518792693267\n","Training accuracy epoch: 0.9967811030680888\n","Validating model...\n","Validation Loss: 0.09978563793831402\n","Validation Accuracy: 0.9747637453282957\n","Training epoch: 7\n","Training loss per 100 training steps: 0.00656725000590086\n","Training loss epoch: 0.006668171316574691\n","Training accuracy epoch: 0.9977726818964187\n","Validating model...\n","Validation Loss: 0.10255894035337464\n","Validation Accuracy: 0.9757726448976591\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 13.91643565 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07742427236267499\n","Validation Accuracy: 0.9737578210134983\n","Validation duration: 0.6136376000000003 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.6%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.88      0.93      0.91      4985\n","     Disease       0.74      0.83      0.78      4416\n","\n","   micro avg       0.81      0.88      0.85      9401\n","   macro avg       0.81      0.88      0.84      9401\n","weighted avg       0.81      0.88      0.85      9401\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 938\n","Points in y_train after augmentation: 938\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7804497480392456\n","Training loss epoch: 0.2179822107240305\n","Training accuracy epoch: 0.9321541624647111\n","Validating model...\n","Validation Loss: 0.07869398369202538\n","Validation Accuracy: 0.9734521310025299\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06770320236682892\n","Training loss epoch: 0.05498229765917285\n","Training accuracy epoch: 0.9820341966536025\n","Validating model...\n","Validation Loss: 0.07119362280955391\n","Validation Accuracy: 0.9756599536693694\n","Training epoch: 3\n","Training loss per 100 training steps: 0.024900538846850395\n","Training loss epoch: 0.026787367807227676\n","Training accuracy epoch: 0.9916969478963207\n","Validating model...\n","Validation Loss: 0.07708555826592067\n","Validation Accuracy: 0.9751589886877007\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01355823501944542\n","Training loss epoch: 0.016596223535489733\n","Training accuracy epoch: 0.9946121182555763\n","Validating model...\n","Validation Loss: 0.08654232669089522\n","Validation Accuracy: 0.9768170042085438\n","Training epoch: 5\n","Training loss per 100 training steps: 0.013035763055086136\n","Training loss epoch: 0.010940847405374555\n","Training accuracy epoch: 0.9968444614853806\n","Validating model...\n","Validation Loss: 0.09177434923393386\n","Validation Accuracy: 0.9773460003719121\n","Training epoch: 6\n","Training loss per 100 training steps: 0.004907442256808281\n","Training loss epoch: 0.0066442790133405035\n","Training accuracy epoch: 0.9977531486502984\n","Validating model...\n","Validation Loss: 0.09902594167561758\n","Validation Accuracy: 0.9781144374426909\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0014883192488923669\n","Training loss epoch: 0.007095369145321518\n","Training accuracy epoch: 0.9979135982746106\n","Validating model...\n","Validation Loss: 0.10050992691327655\n","Validation Accuracy: 0.9763491239917615\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 14.076197500000001 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07613917552526035\n","Validation Accuracy: 0.9744526614863271\n","Validation duration: 0.6134174166666677 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.7%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.90      0.91      0.91      4985\n","     Disease       0.75      0.82      0.78      4416\n","\n","   micro avg       0.82      0.87      0.85      9401\n","   macro avg       0.82      0.87      0.85      9401\n","weighted avg       0.83      0.87      0.85      9401\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 938\n","Points in y_train after augmentation: 938\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8806660175323486\n","Training loss epoch: 0.223928554457123\n","Training accuracy epoch: 0.9320081989300446\n","Validating model...\n","Validation Loss: 0.08760128690609856\n","Validation Accuracy: 0.9719590492335133\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06376560777425766\n","Training loss epoch: 0.06059294108743385\n","Training accuracy epoch: 0.9808027438410449\n","Validating model...\n","Validation Loss: 0.08254627516818425\n","Validation Accuracy: 0.9714633093160677\n","Training epoch: 3\n","Training loss per 100 training steps: 0.01959478110074997\n","Training loss epoch: 0.0343608747283786\n","Training accuracy epoch: 0.9891978074249492\n","Validating model...\n","Validation Loss: 0.0800035870264447\n","Validation Accuracy: 0.9755447613242674\n","Training epoch: 4\n","Training loss per 100 training steps: 0.012484099715948105\n","Training loss epoch: 0.020519880459533405\n","Training accuracy epoch: 0.9939826787089017\n","Validating model...\n","Validation Loss: 0.08749622759956216\n","Validation Accuracy: 0.9718969618622539\n","Training epoch: 5\n","Training loss per 100 training steps: 0.015396379865705967\n","Training loss epoch: 0.015408693662828814\n","Training accuracy epoch: 0.9950974910293074\n","Validating model...\n","Validation Loss: 0.08059246595653277\n","Validation Accuracy: 0.9784887846993429\n","Training epoch: 6\n","Training loss per 100 training steps: 0.013590437360107899\n","Training loss epoch: 0.007434561564508131\n","Training accuracy epoch: 0.9979488629798435\n","Validating model...\n","Validation Loss: 0.10028184453646342\n","Validation Accuracy: 0.9766926860988602\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0038628990296274424\n","Training loss epoch: 0.007827457890972117\n","Training accuracy epoch: 0.9979504236461635\n","Validating model...\n","Validation Loss: 0.09522130573907542\n","Validation Accuracy: 0.9779560357832656\n","Training epoch: 8\n","Training loss per 100 training steps: 0.00655410997569561\n","Training loss epoch: 0.005991147098060445\n","Training accuracy epoch: 0.998221270147724\n","Validating model...\n","Validation Loss: 0.09788229860483653\n","Validation Accuracy: 0.9779375999955144\n","Training epoch: 9\n","Patience limit reached\n","Training duration: 16.101893949999997 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.08327859303071386\n","Validation Accuracy: 0.9746754195094389\n","Validation duration: 0.6164864999999964 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.4%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.92      0.92      0.92      4985\n","     Disease       0.75      0.82      0.78      4416\n","\n","   micro avg       0.83      0.87      0.85      9401\n","   macro avg       0.83      0.87      0.85      9401\n","weighted avg       0.84      0.87      0.85      9401\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 938\n","Points in y_train after augmentation: 938\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8701428174972534\n","Training loss epoch: 0.23794105920498654\n","Training accuracy epoch: 0.9293070564394351\n","Validating model...\n","Validation Loss: 0.09051935800484248\n","Validation Accuracy: 0.9689202111189964\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0904182493686676\n","Training loss epoch: 0.06340639261623561\n","Training accuracy epoch: 0.9793738495342099\n","Validating model...\n","Validation Loss: 0.06935461651947764\n","Validation Accuracy: 0.9760307087168151\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04328897222876549\n","Training loss epoch: 0.03538159230502985\n","Training accuracy epoch: 0.9887538094494874\n","Validating model...\n","Validation Loss: 0.06809131464078313\n","Validation Accuracy: 0.9772986276557958\n","Training epoch: 4\n","Training loss per 100 training steps: 0.027139805257320404\n","Training loss epoch: 0.01946479558818421\n","Training accuracy epoch: 0.9938385528378095\n","Validating model...\n","Validation Loss: 0.08747082106059506\n","Validation Accuracy: 0.9760607153327963\n","Training epoch: 5\n","Training loss per 100 training steps: 0.01271025650203228\n","Training loss epoch: 0.01594084140576296\n","Training accuracy epoch: 0.9952157895779205\n","Validating model...\n","Validation Loss: 0.08476048885356813\n","Validation Accuracy: 0.9761991051728103\n","Training epoch: 6\n","Training loss per 100 training steps: 0.008166328072547913\n","Training loss epoch: 0.012016646848139117\n","Training accuracy epoch: 0.9962906800028763\n","Validating model...\n","Validation Loss: 0.08809339083612912\n","Validation Accuracy: 0.9776258899542406\n","Training epoch: 7\n","Training loss per 100 training steps: 0.011917105875909328\n","Training loss epoch: 0.005759685298317443\n","Training accuracy epoch: 0.9982148985916057\n","Validating model...\n","Validation Loss: 0.09791826149300924\n","Validation Accuracy: 0.9775541074105767\n","Training epoch: 8\n","Training loss per 100 training steps: 0.009184835478663445\n","Training loss epoch: 0.003931959508918226\n","Training accuracy epoch: 0.9988915282223542\n","Validating model...\n","Validation Loss: 0.10437355231907633\n","Validation Accuracy: 0.9778597861618636\n","Training epoch: 9\n","Patience limit reached\n","Training duration: 16.082896999999996 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07612295833135409\n","Validation Accuracy: 0.9750767746821741\n","Validation duration: 0.6173429666666682 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.0%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.92      0.89      0.91      4985\n","     Disease       0.75      0.83      0.79      4416\n","\n","   micro avg       0.84      0.86      0.85      9401\n","   macro avg       0.84      0.86      0.85      9401\n","weighted avg       0.84      0.86      0.85      9401\n","\n","!!!!!! Starting model number 5 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 938\n","Points in y_train after augmentation: 938\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8580154180526733\n","Training loss epoch: 0.21616980629199642\n","Training accuracy epoch: 0.93338227228949\n","Validating model...\n","Validation Loss: 0.08726730924986657\n","Validation Accuracy: 0.9697033353259474\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07563408464193344\n","Training loss epoch: 0.056738406182977104\n","Training accuracy epoch: 0.9817900525322897\n","Validating model...\n","Validation Loss: 0.06875804752584487\n","Validation Accuracy: 0.9773965119102564\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04816020280122757\n","Training loss epoch: 0.030316666115896177\n","Training accuracy epoch: 0.9906192627145262\n","Validating model...\n","Validation Loss: 0.07553154129594092\n","Validation Accuracy: 0.9770414796734753\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01263959240168333\n","Training loss epoch: 0.01536882812378265\n","Training accuracy epoch: 0.9951944127621443\n","Validating model...\n","Validation Loss: 0.07949026697684848\n","Validation Accuracy: 0.977467663184742\n","Training epoch: 5\n","Training loss per 100 training steps: 0.01737821474671364\n","Training loss epoch: 0.01080648024503331\n","Training accuracy epoch: 0.9969147549626554\n","Validating model...\n","Validation Loss: 0.0902361147223957\n","Validation Accuracy: 0.9768763607556842\n","Training epoch: 6\n","Training loss per 100 training steps: 0.007707017473876476\n","Training loss epoch: 0.0068395103454211\n","Training accuracy epoch: 0.9981129997705046\n","Validating model...\n","Validation Loss: 0.09289719473334059\n","Validation Accuracy: 0.9776062376261861\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0020282778423279524\n","Training loss epoch: 0.005889841726333913\n","Training accuracy epoch: 0.9983061118288461\n","Validating model...\n","Validation Loss: 0.09800334446250446\n","Validation Accuracy: 0.9766333713754874\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 14.071717850000004 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07331076264381409\n","Validation Accuracy: 0.975652065205805\n","Validation duration: 0.6158764999999978 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.2%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.90      0.92      0.91      4985\n","     Disease       0.76      0.82      0.79      4416\n","\n","   micro avg       0.83      0.87      0.85      9401\n","   macro avg       0.83      0.87      0.85      9401\n","weighted avg       0.83      0.87      0.85      9401\n","\n","!!!!!! Starting model number 6 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 938\n","Points in y_train after augmentation: 938\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.4690030813217163\n","Training loss epoch: 0.19780645487924753\n","Training accuracy epoch: 0.9406204493070541\n","Validating model...\n","Validation Loss: 0.07995683262272486\n","Validation Accuracy: 0.9721333001546744\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05328052118420601\n","Training loss epoch: 0.05704996504394685\n","Training accuracy epoch: 0.9815717355919701\n","Validating model...\n","Validation Loss: 0.07077783638877529\n","Validation Accuracy: 0.9769006530732103\n","Training epoch: 3\n","Training loss per 100 training steps: 0.025014247745275497\n","Training loss epoch: 0.028844106752993696\n","Training accuracy epoch: 0.9908257690620528\n","Validating model...\n","Validation Loss: 0.07808122742507193\n","Validation Accuracy: 0.9753970685823073\n","Training epoch: 4\n","Training loss per 100 training steps: 0.011228364892303944\n","Training loss epoch: 0.01664778946551605\n","Training accuracy epoch: 0.9951658077737711\n","Validating model...\n","Validation Loss: 0.08692240070492502\n","Validation Accuracy: 0.9750387025864157\n","Training epoch: 5\n","Training loss per 100 training steps: 0.00905093178153038\n","Training loss epoch: 0.011175030777309785\n","Training accuracy epoch: 0.9964020812113389\n","Validating model...\n","Validation Loss: 0.09707848171866129\n","Validation Accuracy: 0.9727344097188277\n","Training epoch: 6\n","Training loss per 100 training steps: 0.004076744429767132\n","Training loss epoch: 0.009643940983134938\n","Training accuracy epoch: 0.9969679420028682\n","Validating model...\n","Validation Loss: 0.10775688603993445\n","Validation Accuracy: 0.9734889173379555\n","Training epoch: 7\n","Training loss per 100 training steps: 0.007861221209168434\n","Training loss epoch: 0.007475077143033682\n","Training accuracy epoch: 0.9976198931415965\n","Validating model...\n","Validation Loss: 0.09888263401531037\n","Validation Accuracy: 0.9764271996872393\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 14.069859566666674 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07502178043600112\n","Validation Accuracy: 0.9755411101191777\n","Validation duration: 0.6153078166666698 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.7%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.92      0.91      0.91      4985\n","     Disease       0.74      0.82      0.78      4416\n","\n","   micro avg       0.83      0.87      0.85      9401\n","   macro avg       0.83      0.86      0.84      9401\n","weighted avg       0.83      0.87      0.85      9401\n","\n","!!!!!! Starting model number 7 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 938\n","Points in y_train after augmentation: 938\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8298048973083496\n","Training loss epoch: 0.23733160366951409\n","Training accuracy epoch: 0.9282766633360471\n","Validating model...\n","Validation Loss: 0.08124099399835344\n","Validation Accuracy: 0.9725705323880679\n","Training epoch: 2\n","Training loss per 100 training steps: 0.08466556668281555\n","Training loss epoch: 0.06139642489537344\n","Training accuracy epoch: 0.9807203987041125\n","Validating model...\n","Validation Loss: 0.07759970881872708\n","Validation Accuracy: 0.9740211178203972\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04037158936262131\n","Training loss epoch: 0.030862403307425772\n","Training accuracy epoch: 0.9902471407685188\n","Validating model...\n","Validation Loss: 0.08043893243348788\n","Validation Accuracy: 0.9759096565748256\n","Training epoch: 4\n","Training loss per 100 training steps: 0.012386971153318882\n","Training loss epoch: 0.01775517628796525\n","Training accuracy epoch: 0.9944193099177911\n","Validating model...\n","Validation Loss: 0.07934190128885564\n","Validation Accuracy: 0.9777378528399604\n","Training epoch: 5\n","Training loss per 100 training steps: 0.024117499589920044\n","Training loss epoch: 0.010635016628114854\n","Training accuracy epoch: 0.9968185694747559\n","Validating model...\n","Validation Loss: 0.0898615683591555\n","Validation Accuracy: 0.9772936822742948\n","Training epoch: 6\n","Training loss per 100 training steps: 0.009013423696160316\n","Training loss epoch: 0.008764924899817018\n","Training accuracy epoch: 0.9976117135512385\n","Validating model...\n","Validation Loss: 0.09591587490978695\n","Validation Accuracy: 0.9772263183659887\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0025485276710242033\n","Training loss epoch: 0.006489856888824221\n","Training accuracy epoch: 0.9982764391373902\n","Validating model...\n","Validation Loss: 0.08983816502113191\n","Validation Accuracy: 0.9781349449188438\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 14.068048066666657 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.0765924591511961\n","Validation Accuracy: 0.9743183882940997\n","Validation duration: 0.6115605166666531 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.1%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.86      0.96      0.91      4985\n","     Disease       0.73      0.80      0.77      4416\n","\n","   micro avg       0.80      0.89      0.84      9401\n","   macro avg       0.80      0.88      0.84      9401\n","weighted avg       0.80      0.89      0.84      9401\n","\n","!!!!!! Starting model number 8 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 938\n","Points in y_train after augmentation: 938\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.5629839897155762\n","Training loss epoch: 0.2027693947745582\n","Training accuracy epoch: 0.9386739519349282\n","Validating model...\n","Validation Loss: 0.08022834833652254\n","Validation Accuracy: 0.9730364507245609\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07963059097528458\n","Training loss epoch: 0.053768635238126174\n","Training accuracy epoch: 0.9830034929866369\n","Validating model...\n","Validation Loss: 0.07363652396533224\n","Validation Accuracy: 0.975684353632673\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03509886562824249\n","Training loss epoch: 0.035347816439629615\n","Training accuracy epoch: 0.9889718962804264\n","Validating model...\n","Validation Loss: 0.07224838066077421\n","Validation Accuracy: 0.9777946520084424\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01433086208999157\n","Training loss epoch: 0.01587280978338193\n","Training accuracy epoch: 0.9953499521919733\n","Validating model...\n","Validation Loss: 0.08124218895913117\n","Validation Accuracy: 0.9776167504250864\n","Training epoch: 5\n","Training loss per 100 training steps: 0.006522953975945711\n","Training loss epoch: 0.0108977683338384\n","Training accuracy epoch: 0.9966275558053809\n","Validating model...\n","Validation Loss: 0.09130945340508506\n","Validation Accuracy: 0.9770583797943748\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0015554914716631174\n","Training loss epoch: 0.006665304520214766\n","Training accuracy epoch: 0.9980999178120123\n","Validating model...\n","Validation Loss: 0.09337042337135663\n","Validation Accuracy: 0.9775742011185998\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0012512757675722241\n","Training loss epoch: 0.004832734915198979\n","Training accuracy epoch: 0.9985985199898574\n","Validating model...\n","Validation Loss: 0.0972892376520331\n","Validation Accuracy: 0.9783678991980463\n","Training epoch: 8\n","Training loss per 100 training steps: 0.0015420832205563784\n","Training loss epoch: 0.004241127750177284\n","Training accuracy epoch: 0.9988573635788138\n","Validating model...\n","Validation Loss: 0.10651335031503723\n","Validation Accuracy: 0.9770929083843856\n","Training epoch: 9\n","Patience limit reached\n","Training duration: 16.09278193333333 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.0764850742582764\n","Validation Accuracy: 0.9762556220833961\n","Validation duration: 0.6128865333333428 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.6%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.91      0.93      0.92      4985\n","     Disease       0.75      0.83      0.79      4416\n","\n","   micro avg       0.83      0.88      0.86      9401\n","   macro avg       0.83      0.88      0.85      9401\n","weighted avg       0.84      0.88      0.86      9401\n","\n","!!!!!! Starting model number 9 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 938\n","Points in y_train after augmentation: 938\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.4429229497909546\n","Training loss epoch: 0.21652772182882843\n","Training accuracy epoch: 0.9337427667581149\n","Validating model...\n","Validation Loss: 0.08707072331555306\n","Validation Accuracy: 0.9700009038963648\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04305258020758629\n","Training loss epoch: 0.06263627307647365\n","Training accuracy epoch: 0.9800814723813829\n","Validating model...\n","Validation Loss: 0.07168585088636194\n","Validation Accuracy: 0.9753880378112739\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03201599419116974\n","Training loss epoch: 0.03357198952018457\n","Training accuracy epoch: 0.9894562977605572\n","Validating model...\n","Validation Loss: 0.0737461212372023\n","Validation Accuracy: 0.9760932513759291\n","Training epoch: 4\n","Training loss per 100 training steps: 0.023768026381731033\n","Training loss epoch: 0.018292459248865054\n","Training accuracy epoch: 0.9944098426046853\n","Validating model...\n","Validation Loss: 0.0783633017055099\n","Validation Accuracy: 0.9777450096554716\n","Training epoch: 5\n","Training loss per 100 training steps: 0.010477454401552677\n","Training loss epoch: 0.013693922972780163\n","Training accuracy epoch: 0.9957254822542563\n","Validating model...\n","Validation Loss: 0.08966303297451564\n","Validation Accuracy: 0.9753563803552272\n","Training epoch: 6\n","Training loss per 100 training steps: 0.002690367866307497\n","Training loss epoch: 0.008656538308645456\n","Training accuracy epoch: 0.9973057143304755\n","Validating model...\n","Validation Loss: 0.097548969799564\n","Validation Accuracy: 0.9762067556313949\n","Training epoch: 7\n","Training loss per 100 training steps: 0.027198072522878647\n","Training loss epoch: 0.007123820825037941\n","Training accuracy epoch: 0.9978677477599165\n","Validating model...\n","Validation Loss: 0.10762356523246992\n","Validation Accuracy: 0.975300220882895\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 14.069216466666663 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07497129784453482\n","Validation Accuracy: 0.9741976405044351\n","Validation duration: 0.6130197499999971 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.8%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.91      0.92      0.91      4985\n","     Disease       0.75      0.80      0.78      4416\n","\n","   micro avg       0.83      0.86      0.85      9401\n","   macro avg       0.83      0.86      0.84      9401\n","weighted avg       0.84      0.86      0.85      9401\n","\n","!!!!!! Starting model number 10 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 938\n","Points in y_train after augmentation: 938\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.4148907661437988\n","Training loss epoch: 0.19728997659127592\n","Training accuracy epoch: 0.9390324617583049\n","Validating model...\n","Validation Loss: 0.08245410368083016\n","Validation Accuracy: 0.9718971740801837\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05999034270644188\n","Training loss epoch: 0.05637837772778535\n","Training accuracy epoch: 0.9819719491398347\n","Validating model...\n","Validation Loss: 0.07566606809222509\n","Validation Accuracy: 0.9746353244558363\n","Training epoch: 3\n","Training loss per 100 training steps: 0.030289335176348686\n","Training loss epoch: 0.029009614329216844\n","Training accuracy epoch: 0.9907262480947231\n","Validating model...\n","Validation Loss: 0.07706021824999461\n","Validation Accuracy: 0.9765478809454834\n","Training epoch: 4\n","Training loss per 100 training steps: 0.009988822974264622\n","Training loss epoch: 0.015077170868546276\n","Training accuracy epoch: 0.9955229282972109\n","Validating model...\n","Validation Loss: 0.07900226459143654\n","Validation Accuracy: 0.977362773232889\n","Training epoch: 5\n","Training loss per 100 training steps: 0.014738628640770912\n","Training loss epoch: 0.01122447260323975\n","Training accuracy epoch: 0.9964297698841343\n","Validating model...\n","Validation Loss: 0.11102494763003455\n","Validation Accuracy: 0.9687351080652297\n","Training epoch: 6\n","Training loss per 100 training steps: 0.019822880625724792\n","Training loss epoch: 0.008441021942170494\n","Training accuracy epoch: 0.9974473112411326\n","Validating model...\n","Validation Loss: 0.09677034208462351\n","Validation Accuracy: 0.9766043852370915\n","Training epoch: 7\n","Training loss per 100 training steps: 0.019098326563835144\n","Training loss epoch: 0.0069180651265985755\n","Training accuracy epoch: 0.9980234820962038\n","Validating model...\n","Validation Loss: 0.10029548232162756\n","Validation Accuracy: 0.9767958407048065\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 14.058647033333333 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07882033306218329\n","Validation Accuracy: 0.9740665099632018\n","Validation duration: 0.6116376833333258 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.3%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.86      0.95      0.90      4985\n","     Disease       0.72      0.83      0.77      4416\n","\n","   micro avg       0.80      0.90      0.84      9401\n","   macro avg       0.79      0.89      0.84      9401\n","weighted avg       0.80      0.90      0.84      9401\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0.25\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"Jhz9BiIwGCsV"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10952127,"status":"ok","timestamp":1666868446875,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"},"user_tz":240},"id":"jdO4m5O4Hlo3","outputId":"6e96a1f4-52a2-417d-a821-59606ca025a6"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 50.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 1125\n","Points in y_train after augmentation: 1125\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.5778884887695312\n","Training loss epoch: 0.17171112883468748\n","Training accuracy epoch: 0.9454502552074742\n","Validating model...\n","Validation Loss: 0.08037770533609012\n","Validation Accuracy: 0.9717209476027643\n","Training epoch: 2\n","Training loss per 100 training steps: 0.057869795709848404\n","Training loss epoch: 0.046694828682697156\n","Training accuracy epoch: 0.9857022125502234\n","Validating model...\n","Validation Loss: 0.0773710190422005\n","Validation Accuracy: 0.9732451191914981\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02071770839393139\n","Training loss epoch: 0.02503987662756527\n","Training accuracy epoch: 0.9923034564906911\n","Validating model...\n","Validation Loss: 0.07907714963787132\n","Validation Accuracy: 0.9749906035496811\n","Training epoch: 4\n","Training loss per 100 training steps: 0.018966950476169586\n","Training loss epoch: 0.016604664266555453\n","Training accuracy epoch: 0.994772200368596\n","Validating model...\n","Validation Loss: 0.08932569628906628\n","Validation Accuracy: 0.9766904693732648\n","Training epoch: 5\n","Training loss per 100 training steps: 0.002258698921650648\n","Training loss epoch: 0.009023496917199711\n","Training accuracy epoch: 0.9972820751167081\n","Validating model...\n","Validation Loss: 0.08326243644668943\n","Validation Accuracy: 0.9775309075584961\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0019169672159478068\n","Training loss epoch: 0.0049940540019134195\n","Training accuracy epoch: 0.9984353777705963\n","Validating model...\n","Validation Loss: 0.10665009794608941\n","Validation Accuracy: 0.9739562662873833\n","Training epoch: 7\n","Training loss per 100 training steps: 0.010726245120167732\n","Training loss epoch: 0.003621935183231548\n","Training accuracy epoch: 0.9989297404090876\n","Validating model...\n","Validation Loss: 0.1115228423168735\n","Validation Accuracy: 0.9759821756444363\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 15.978535100000014 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.08220529497142821\n","Validation Accuracy: 0.9723884401785003\n","Validation duration: 0.6164883166666792 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.7%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.86      0.95      0.91      4985\n","     Disease       0.74      0.83      0.78      4416\n","\n","   micro avg       0.80      0.90      0.85      9401\n","   macro avg       0.80      0.89      0.84      9401\n","weighted avg       0.80      0.90      0.85      9401\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 1125\n","Points in y_train after augmentation: 1125\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.712296485900879\n","Training loss epoch: 0.18666188020101734\n","Training accuracy epoch: 0.9420053838703027\n","Validating model...\n","Validation Loss: 0.08153392167554961\n","Validation Accuracy: 0.9712670446703681\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0579523891210556\n","Training loss epoch: 0.0489389615684328\n","Training accuracy epoch: 0.9849641216995918\n","Validating model...\n","Validation Loss: 0.07209358423475236\n","Validation Accuracy: 0.9754869092933653\n","Training epoch: 3\n","Training loss per 100 training steps: 0.026140453293919563\n","Training loss epoch: 0.024580167278542484\n","Training accuracy epoch: 0.9922635648268906\n","Validating model...\n","Validation Loss: 0.0751500189718273\n","Validation Accuracy: 0.9769871697133364\n","Training epoch: 4\n","Training loss per 100 training steps: 0.014673389494419098\n","Training loss epoch: 0.014179336694134792\n","Training accuracy epoch: 0.995423513685223\n","Validating model...\n","Validation Loss: 0.0837591194089443\n","Validation Accuracy: 0.9770328140896961\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0073814671486616135\n","Training loss epoch: 0.009983316026168915\n","Training accuracy epoch: 0.9970009336313747\n","Validating model...\n","Validation Loss: 0.0921330786058827\n","Validation Accuracy: 0.9763009438384266\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0028050686232745647\n","Training loss epoch: 0.0054825326562268845\n","Training accuracy epoch: 0.9983988508821218\n","Validating model...\n","Validation Loss: 0.09440392790923989\n","Validation Accuracy: 0.9775550924171034\n","Training epoch: 7\n","Training loss per 100 training steps: 0.002458186587318778\n","Training loss epoch: 0.0033224000231507167\n","Training accuracy epoch: 0.9990748479942351\n","Validating model...\n","Validation Loss: 0.10148917821546395\n","Validation Accuracy: 0.9789671419802117\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 15.990071266666686 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07752231957893523\n","Validation Accuracy: 0.973955314928158\n","Validation duration: 0.6159581500000059 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.6%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.91      0.91      0.91      4985\n","     Disease       0.74      0.82      0.78      4416\n","\n","   micro avg       0.82      0.87      0.85      9401\n","   macro avg       0.82      0.87      0.84      9401\n","weighted avg       0.83      0.87      0.85      9401\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 1125\n","Points in y_train after augmentation: 1125\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.296595573425293\n","Training loss epoch: 0.1731205893234468\n","Training accuracy epoch: 0.9481288447137873\n","Validating model...\n","Validation Loss: 0.07676472958354723\n","Validation Accuracy: 0.9732364532686608\n","Training epoch: 2\n","Training loss per 100 training steps: 0.045732781291007996\n","Training loss epoch: 0.04942760225647772\n","Training accuracy epoch: 0.9840470368976717\n","Validating model...\n","Validation Loss: 0.06785151545727064\n","Validation Accuracy: 0.9767343130319891\n","Training epoch: 3\n","Training loss per 100 training steps: 0.019453946501016617\n","Training loss epoch: 0.02669480039646298\n","Training accuracy epoch: 0.9915614753194191\n","Validating model...\n","Validation Loss: 0.07622840249585727\n","Validation Accuracy: 0.9762126829244535\n","Training epoch: 4\n","Training loss per 100 training steps: 0.009389800950884819\n","Training loss epoch: 0.01521230328985503\n","Training accuracy epoch: 0.9956171319987275\n","Validating model...\n","Validation Loss: 0.0851330929805362\n","Validation Accuracy: 0.9752991962757692\n","Training epoch: 5\n","Training loss per 100 training steps: 0.008717929944396019\n","Training loss epoch: 0.009487539636377822\n","Training accuracy epoch: 0.9970489154402595\n","Validating model...\n","Validation Loss: 0.09823993277100343\n","Validation Accuracy: 0.9746294732779157\n","Training epoch: 6\n","Training loss per 100 training steps: 0.004856952000409365\n","Training loss epoch: 0.0063551546379425365\n","Training accuracy epoch: 0.9981689588678818\n","Validating model...\n","Validation Loss: 0.09351597868260883\n","Validation Accuracy: 0.9770718531441195\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0017523927381262183\n","Training loss epoch: 0.004411634362735589\n","Training accuracy epoch: 0.9987582195123723\n","Validating model...\n","Validation Loss: 0.11382391108643442\n","Validation Accuracy: 0.9740219739157538\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 15.98360220000001 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.0721500055894019\n","Validation Accuracy: 0.9753866825099973\n","Validation duration: 0.6138244000000062 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.1%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.89      0.93      0.91      4985\n","     Disease       0.75      0.83      0.79      4416\n","\n","   micro avg       0.82      0.88      0.85      9401\n","   macro avg       0.82      0.88      0.85      9401\n","weighted avg       0.82      0.88      0.85      9401\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 1125\n","Points in y_train after augmentation: 1125\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.6759424209594727\n","Training loss epoch: 0.19233109356022218\n","Training accuracy epoch: 0.9404055811681686\n","Validating model...\n","Validation Loss: 0.08529396491154792\n","Validation Accuracy: 0.9705920593002325\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05338319018483162\n","Training loss epoch: 0.0498242621952799\n","Training accuracy epoch: 0.9843073721198775\n","Validating model...\n","Validation Loss: 0.07343364932707377\n","Validation Accuracy: 0.9753977924472221\n","Training epoch: 3\n","Training loss per 100 training steps: 0.022724363952875137\n","Training loss epoch: 0.025182308747210135\n","Training accuracy epoch: 0.992060567183296\n","Validating model...\n","Validation Loss: 0.0846875710265031\n","Validation Accuracy: 0.9770975616162159\n","Training epoch: 4\n","Training loss per 100 training steps: 0.02096492610871792\n","Training loss epoch: 0.015232411655925319\n","Training accuracy epoch: 0.9952030199785759\n","Validating model...\n","Validation Loss: 0.08218437285413818\n","Validation Accuracy: 0.9774159181739692\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0037587368860840797\n","Training loss epoch: 0.009916258880763616\n","Training accuracy epoch: 0.997037179765102\n","Validating model...\n","Validation Loss: 0.10039502985420681\n","Validation Accuracy: 0.9745406938565175\n","Training epoch: 6\n","Training loss per 100 training steps: 0.004478876478970051\n","Training loss epoch: 0.007170845373225412\n","Training accuracy epoch: 0.9979212801139884\n","Validating model...\n","Validation Loss: 0.1045118925708627\n","Validation Accuracy: 0.9760566803554551\n","Training epoch: 7\n","Training loss per 100 training steps: 0.004204698838293552\n","Training loss epoch: 0.005040230399200981\n","Training accuracy epoch: 0.9984934330646694\n","Validating model...\n","Validation Loss: 0.11290727242354363\n","Validation Accuracy: 0.9751949622677731\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 15.992672416666665 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07871646528679227\n","Validation Accuracy: 0.973556249042608\n","Validation duration: 0.6148022000000007 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.7%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.94      0.88      0.91      4985\n","     Disease       0.75      0.83      0.79      4416\n","\n","   micro avg       0.84      0.86      0.85      9401\n","   macro avg       0.84      0.85      0.85      9401\n","weighted avg       0.85      0.86      0.85      9401\n","\n","!!!!!! Starting model number 5 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 1125\n","Points in y_train after augmentation: 1125\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7906618118286133\n","Training loss epoch: 0.18427182660556177\n","Training accuracy epoch: 0.9421402169963858\n","Validating model...\n","Validation Loss: 0.07707178758250342\n","Validation Accuracy: 0.9733452508698376\n","Training epoch: 2\n","Training loss per 100 training steps: 0.039499182254076004\n","Training loss epoch: 0.04753051438486912\n","Training accuracy epoch: 0.985034037031764\n","Validating model...\n","Validation Loss: 0.07330024461188013\n","Validation Accuracy: 0.9753883319743795\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02480374090373516\n","Training loss epoch: 0.024591735269034833\n","Training accuracy epoch: 0.9924317791353083\n","Validating model...\n","Validation Loss: 0.08844764938666708\n","Validation Accuracy: 0.9718732124024979\n","Training epoch: 4\n","Training loss per 100 training steps: 0.005594966933131218\n","Training loss epoch: 0.013928218606964384\n","Training accuracy epoch: 0.9960023375521342\n","Validating model...\n","Validation Loss: 0.08632312049823147\n","Validation Accuracy: 0.9762256440536665\n","Training epoch: 5\n","Training loss per 100 training steps: 0.007797962054610252\n","Training loss epoch: 0.008299035877710812\n","Training accuracy epoch: 0.9974196503638996\n","Validating model...\n","Validation Loss: 0.09654715988371107\n","Validation Accuracy: 0.9764770052736145\n","Training epoch: 6\n","Training loss per 100 training steps: 0.006897955201566219\n","Training loss epoch: 0.0072611877629139895\n","Training accuracy epoch: 0.9978902109159561\n","Validating model...\n","Validation Loss: 0.10028334328579525\n","Validation Accuracy: 0.9756810961803392\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0017512845806777477\n","Training loss epoch: 0.007040285260226368\n","Training accuracy epoch: 0.9980473862441688\n","Validating model...\n","Validation Loss: 0.11031078730547239\n","Validation Accuracy: 0.9739215390180093\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 15.9833778333333 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07774564612006384\n","Validation Accuracy: 0.9739836316523298\n","Validation duration: 0.6130363499999779 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.2%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.89      0.94      0.91      4985\n","     Disease       0.74      0.83      0.78      4416\n","\n","   micro avg       0.82      0.89      0.85      9401\n","   macro avg       0.81      0.89      0.85      9401\n","weighted avg       0.82      0.89      0.85      9401\n","\n","!!!!!! Starting model number 6 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 1125\n","Points in y_train after augmentation: 1125\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.4305928945541382\n","Training loss epoch: 0.18431539219659818\n","Training accuracy epoch: 0.944250300712358\n","Validating model...\n","Validation Loss: 0.08416875404497934\n","Validation Accuracy: 0.9712461954041873\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09264086931943893\n","Training loss epoch: 0.05145909162369412\n","Training accuracy epoch: 0.9830906261700402\n","Validating model...\n","Validation Loss: 0.07312774409850438\n","Validation Accuracy: 0.9742018576653562\n","Training epoch: 3\n","Training loss per 100 training steps: 0.020758062601089478\n","Training loss epoch: 0.027398216000325243\n","Training accuracy epoch: 0.9911553015901798\n","Validating model...\n","Validation Loss: 0.07693203656919419\n","Validation Accuracy: 0.9770987266848343\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01400532852858305\n","Training loss epoch: 0.015247307098011526\n","Training accuracy epoch: 0.9951072220343252\n","Validating model...\n","Validation Loss: 0.09195971441647363\n","Validation Accuracy: 0.9737771312232807\n","Training epoch: 5\n","Training loss per 100 training steps: 0.006006181705743074\n","Training loss epoch: 0.010194901845903255\n","Training accuracy epoch: 0.9968964180407659\n","Validating model...\n","Validation Loss: 0.08735850400158338\n","Validation Accuracy: 0.97692662094108\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0035940269008278847\n","Training loss epoch: 0.009011205490744134\n","Training accuracy epoch: 0.9973774144172453\n","Validating model...\n","Validation Loss: 0.10226814241872893\n","Validation Accuracy: 0.974849741869968\n","Training epoch: 7\n","Training loss per 100 training steps: 0.004467037972062826\n","Training loss epoch: 0.004876799124758691\n","Training accuracy epoch: 0.998423936088441\n","Validating model...\n","Validation Loss: 0.10349013999341027\n","Validation Accuracy: 0.9763669206383793\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 15.986418466666692 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.08049451506563596\n","Validation Accuracy: 0.9715629864175946\n","Validation duration: 0.6104159333333276 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.2%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.90      0.93      0.92      4985\n","     Disease       0.71      0.83      0.77      4416\n","\n","   micro avg       0.80      0.88      0.84      9401\n","   macro avg       0.81      0.88      0.84      9401\n","weighted avg       0.81      0.88      0.85      9401\n","\n","!!!!!! Starting model number 7 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 1125\n","Points in y_train after augmentation: 1125\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.6970486640930176\n","Training loss epoch: 0.17761524766683578\n","Training accuracy epoch: 0.9436882869375545\n","Validating model...\n","Validation Loss: 0.0941885281058531\n","Validation Accuracy: 0.9665462505062167\n","Training epoch: 2\n","Training loss per 100 training steps: 0.08758334070444107\n","Training loss epoch: 0.045239293554299315\n","Training accuracy epoch: 0.9858930932841661\n","Validating model...\n","Validation Loss: 0.07264747594793637\n","Validation Accuracy: 0.9748684052610218\n","Training epoch: 3\n","Training loss per 100 training steps: 0.027034178376197815\n","Training loss epoch: 0.02669223180224358\n","Training accuracy epoch: 0.9916018226173999\n","Validating model...\n","Validation Loss: 0.07794528105665767\n","Validation Accuracy: 0.9754087356742454\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0107700414955616\n","Training loss epoch: 0.01696410651554839\n","Training accuracy epoch: 0.9947634507239718\n","Validating model...\n","Validation Loss: 0.08277981713532455\n","Validation Accuracy: 0.9775557099901865\n","Training epoch: 5\n","Training loss per 100 training steps: 0.004764041863381863\n","Training loss epoch: 0.008805663590516212\n","Training accuracy epoch: 0.997212607183417\n","Validating model...\n","Validation Loss: 0.0990248451985064\n","Validation Accuracy: 0.9747289280436253\n","Training epoch: 6\n","Training loss per 100 training steps: 0.008520316332578659\n","Training loss epoch: 0.006805179054475009\n","Training accuracy epoch: 0.9980744513842004\n","Validating model...\n","Validation Loss: 0.10065558747876258\n","Validation Accuracy: 0.9770969460832385\n","Training epoch: 7\n","Training loss per 100 training steps: 0.004452262539416552\n","Training loss epoch: 0.005277196651662398\n","Training accuracy epoch: 0.9984764521529698\n","Validating model...\n","Validation Loss: 0.10176035785485828\n","Validation Accuracy: 0.9766409294475452\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 15.983952949999972 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07638569028368072\n","Validation Accuracy: 0.9744866491164543\n","Validation duration: 0.6150189499999518 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.2%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.90      0.93      0.91      4985\n","     Disease       0.72      0.82      0.77      4416\n","\n","   micro avg       0.81      0.88      0.84      9401\n","   macro avg       0.81      0.88      0.84      9401\n","weighted avg       0.81      0.88      0.84      9401\n","\n","!!!!!! Starting model number 8 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 1125\n","Points in y_train after augmentation: 1125\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.1053903102874756\n","Training loss epoch: 0.19974567651958533\n","Training accuracy epoch: 0.9387382903646609\n","Validating model...\n","Validation Loss: 0.07752142728321136\n","Validation Accuracy: 0.9732598732493996\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04730493947863579\n","Training loss epoch: 0.04980023483365354\n","Training accuracy epoch: 0.9844343097979306\n","Validating model...\n","Validation Loss: 0.07486303638489473\n","Validation Accuracy: 0.974747229724094\n","Training epoch: 3\n","Training loss per 100 training steps: 0.028235137462615967\n","Training loss epoch: 0.02542143002887007\n","Training accuracy epoch: 0.9920727663046861\n","Validating model...\n","Validation Loss: 0.0753364727965423\n","Validation Accuracy: 0.9778086883347348\n","Training epoch: 4\n","Training loss per 100 training steps: 0.009551335126161575\n","Training loss epoch: 0.01468215527301523\n","Training accuracy epoch: 0.9955925682395927\n","Validating model...\n","Validation Loss: 0.08959144513521876\n","Validation Accuracy: 0.9769862163388799\n","Training epoch: 5\n","Training loss per 100 training steps: 0.008350647985935211\n","Training loss epoch: 0.010464224626611866\n","Training accuracy epoch: 0.9966726109944938\n","Validating model...\n","Validation Loss: 0.09869252683387862\n","Validation Accuracy: 0.9755615575559575\n","Training epoch: 6\n","Training loss per 100 training steps: 0.001356837572529912\n","Training loss epoch: 0.005817613925975026\n","Training accuracy epoch: 0.9982037520931438\n","Validating model...\n","Validation Loss: 0.1072680392553882\n","Validation Accuracy: 0.9761630115629725\n","Training epoch: 7\n","Training loss per 100 training steps: 0.017647676169872284\n","Training loss epoch: 0.004488649990403054\n","Training accuracy epoch: 0.9986509573956133\n","Validating model...\n","Validation Loss: 0.11585141736127082\n","Validation Accuracy: 0.9755669506021408\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 15.974209233333324 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.0792711643236024\n","Validation Accuracy: 0.9735293953676669\n","Validation duration: 0.611395700000018 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.8%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.93      0.88      0.90      4985\n","     Disease       0.72      0.83      0.77      4416\n","\n","   micro avg       0.82      0.86      0.84      9401\n","   macro avg       0.82      0.86      0.84      9401\n","weighted avg       0.83      0.86      0.84      9401\n","\n","!!!!!! Starting model number 9 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 1125\n","Points in y_train after augmentation: 1125\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8186160326004028\n","Training loss epoch: 0.20452534664474742\n","Training accuracy epoch: 0.9354960152170898\n","Validating model...\n","Validation Loss: 0.08398279269772863\n","Validation Accuracy: 0.9708950509441776\n","Training epoch: 2\n","Training loss per 100 training steps: 0.05303496867418289\n","Training loss epoch: 0.05273880481615033\n","Training accuracy epoch: 0.9824069781836683\n","Validating model...\n","Validation Loss: 0.07279281678890424\n","Validation Accuracy: 0.975633680021436\n","Training epoch: 3\n","Training loss per 100 training steps: 0.04630173742771149\n","Training loss epoch: 0.030828193774525548\n","Training accuracy epoch: 0.9905042870914358\n","Validating model...\n","Validation Loss: 0.07842355440296823\n","Validation Accuracy: 0.9758090212772775\n","Training epoch: 4\n","Training loss per 100 training steps: 0.012985175475478172\n","Training loss epoch: 0.01681446424409957\n","Training accuracy epoch: 0.9948175340125046\n","Validating model...\n","Validation Loss: 0.0823908026906706\n","Validation Accuracy: 0.9775767988145111\n","Training epoch: 5\n","Training loss per 100 training steps: 0.008023595437407494\n","Training loss epoch: 0.012883999968655932\n","Training accuracy epoch: 0.996218739489542\n","Validating model...\n","Validation Loss: 0.08832294523479446\n","Validation Accuracy: 0.9774109693070866\n","Training epoch: 6\n","Training loss per 100 training steps: 0.009872552938759327\n","Training loss epoch: 0.007204601646099292\n","Training accuracy epoch: 0.9978011603754199\n","Validating model...\n","Validation Loss: 0.09655175363970181\n","Validation Accuracy: 0.9771966573710236\n","Training epoch: 7\n","Training loss per 100 training steps: 0.007105900906026363\n","Training loss epoch: 0.005674463772201832\n","Training accuracy epoch: 0.998170823630935\n","Validating model...\n","Validation Loss: 0.10797724074551038\n","Validation Accuracy: 0.9768163139891691\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 15.973152483333312 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07856741529845056\n","Validation Accuracy: 0.9743363989865346\n","Validation duration: 0.6124877333333643 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.5%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.90      0.92      0.91      4985\n","     Disease       0.74      0.82      0.77      4416\n","\n","   micro avg       0.82      0.87      0.84      9401\n","   macro avg       0.82      0.87      0.84      9401\n","weighted avg       0.82      0.87      0.85      9401\n","\n","!!!!!! Starting model number 10 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 1125\n","Points in y_train after augmentation: 1125\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7719818353652954\n","Training loss epoch: 0.19653129493686514\n","Training accuracy epoch: 0.9393675534410506\n","Validating model...\n","Validation Loss: 0.07953635538144717\n","Validation Accuracy: 0.9737644698106745\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0457431897521019\n","Training loss epoch: 0.054738625595477264\n","Training accuracy epoch: 0.9825972764203633\n","Validating model...\n","Validation Loss: 0.07674407240535532\n","Validation Accuracy: 0.972174817712147\n","Training epoch: 3\n","Training loss per 100 training steps: 0.016767995432019234\n","Training loss epoch: 0.029212547872792666\n","Training accuracy epoch: 0.9912912371457345\n","Validating model...\n","Validation Loss: 0.07268784756934832\n","Validation Accuracy: 0.9760818890672477\n","Training epoch: 4\n","Training loss per 100 training steps: 0.02068314701318741\n","Training loss epoch: 0.019143513154605746\n","Training accuracy epoch: 0.9941367599672603\n","Validating model...\n","Validation Loss: 0.0860971048001259\n","Validation Accuracy: 0.9768203008795142\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0035104933194816113\n","Training loss epoch: 0.011797716980472103\n","Training accuracy epoch: 0.9964915911119064\n","Validating model...\n","Validation Loss: 0.0874221119142714\n","Validation Accuracy: 0.9761341118017136\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0018279814394190907\n","Training loss epoch: 0.008405300229459896\n","Training accuracy epoch: 0.9975975640550676\n","Validating model...\n","Validation Loss: 0.09829013274302559\n","Validation Accuracy: 0.9757327212829853\n","Training epoch: 7\n","Training loss per 100 training steps: 0.001326326746493578\n","Training loss epoch: 0.005341542205891349\n","Training accuracy epoch: 0.998468665431627\n","Validating model...\n","Validation Loss: 0.10084130159682697\n","Validation Accuracy: 0.9763156618549054\n","Training epoch: 8\n","Training loss per 100 training steps: 0.003874964313581586\n","Training loss epoch: 0.0031681996159432587\n","Training accuracy epoch: 0.9990842071991192\n","Validating model...\n","Validation Loss: 0.11179391129149331\n","Validation Accuracy: 0.9768418161235177\n","Training epoch: 9\n","Patience limit reached\n","Training duration: 18.317219416666678 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07763758065208556\n","Validation Accuracy: 0.9742507171837068\n","Validation duration: 0.6086458333333212 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.8%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.87      0.95      0.91      4985\n","     Disease       0.72      0.86      0.78      4416\n","\n","   micro avg       0.80      0.90      0.85      9401\n","   macro avg       0.80      0.90      0.85      9401\n","weighted avg       0.80      0.90      0.85      9401\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0.5\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"jdO4m5O4Hlo3"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"oKNxFPucHn_R","outputId":"ce564fa2-2bbb-4157-82ed-ccb4dc09351e"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 75.0% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 1313\n","Points in y_train after augmentation: 1313\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.868337631225586\n","Training loss epoch: 0.17903839092118196\n","Training accuracy epoch: 0.9457838055673189\n","Validating model...\n","Validation Loss: 0.08657221714892084\n","Validation Accuracy: 0.9690617563771886\n","Training epoch: 2\n","Training loss per 100 training steps: 0.12304418534040451\n","Training loss epoch: 0.049790286840534353\n","Training accuracy epoch: 0.9841601888712915\n","Validating model...\n","Validation Loss: 0.0767651226903711\n","Validation Accuracy: 0.9745064656651821\n","Training epoch: 3\n","Training loss per 100 training steps: 0.014397555030882359\n","Training loss epoch: 0.024561700674828636\n","Training accuracy epoch: 0.9923839717342329\n","Validating model...\n","Validation Loss: 0.07984142945635886\n","Validation Accuracy: 0.976506330230586\n","Training epoch: 4\n","Training loss per 100 training steps: 0.008969242684543133\n","Training loss epoch: 0.014328436900760574\n","Training accuracy epoch: 0.9956168577492703\n","Validating model...\n","Validation Loss: 0.08440958273907502\n","Validation Accuracy: 0.976489247293617\n","Training epoch: 5\n","Training loss per 100 training steps: 0.011264589615166187\n","Training loss epoch: 0.010294688582218376\n","Training accuracy epoch: 0.9968790417442841\n","Validating model...\n","Validation Loss: 0.09651309003432591\n","Validation Accuracy: 0.9748927123998674\n","Training epoch: 6\n","Training loss per 100 training steps: 0.003365057520568371\n","Training loss epoch: 0.007330218657706752\n","Training accuracy epoch: 0.9977459512892408\n","Validating model...\n","Validation Loss: 0.0945742747022046\n","Validation Accuracy: 0.9765333092348717\n","Training epoch: 7\n","Training loss per 100 training steps: 0.004313221666961908\n","Training loss epoch: 0.004425623259981898\n","Training accuracy epoch: 0.9987417119485419\n","Validating model...\n","Validation Loss: 0.1093714332414998\n","Validation Accuracy: 0.9773915053581224\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 17.97912550000001 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07626659227978616\n","Validation Accuracy: 0.9744571163184327\n","Validation duration: 0.6134511499999765 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.6%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.87      0.93      0.90      4985\n","     Disease       0.78      0.79      0.79      4416\n","\n","   micro avg       0.83      0.86      0.85      9401\n","   macro avg       0.82      0.86      0.84      9401\n","weighted avg       0.83      0.86      0.84      9401\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 1313\n","Points in y_train after augmentation: 1313\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8129444122314453\n","Training loss epoch: 0.1840866085097014\n","Training accuracy epoch: 0.9438098088713035\n","Validating model...\n","Validation Loss: 0.08137946918843285\n","Validation Accuracy: 0.971737415393934\n","Training epoch: 2\n","Training loss per 100 training steps: 0.032012127339839935\n","Training loss epoch: 0.04245070860081588\n","Training accuracy epoch: 0.9866543386260749\n","Validating model...\n","Validation Loss: 0.072240326139662\n","Validation Accuracy: 0.9766122375568633\n","Training epoch: 3\n","Training loss per 100 training steps: 0.023871246725320816\n","Training loss epoch: 0.022089074629482376\n","Training accuracy epoch: 0.9924560999838068\n","Validating model...\n","Validation Loss: 0.08645148516174346\n","Validation Accuracy: 0.9738195381593949\n","Training epoch: 4\n","Training loss per 100 training steps: 0.009441785514354706\n","Training loss epoch: 0.019572204837283814\n","Training accuracy epoch: 0.9941009494967162\n","Validating model...\n","Validation Loss: 0.08173466059896681\n","Validation Accuracy: 0.9773116561204446\n","Training epoch: 5\n","Training loss per 100 training steps: 0.008410538546741009\n","Training loss epoch: 0.00921527456200446\n","Training accuracy epoch: 0.997304638647234\n","Validating model...\n","Validation Loss: 0.09170028691490491\n","Validation Accuracy: 0.9770525656849404\n","Training epoch: 6\n","Training loss per 100 training steps: 0.005488015711307526\n","Training loss epoch: 0.005731249396781807\n","Training accuracy epoch: 0.9984009023115062\n","Validating model...\n","Validation Loss: 0.10072681958240176\n","Validation Accuracy: 0.9772941309867674\n","Training epoch: 7\n","Training loss per 100 training steps: 0.004214192740619183\n","Training loss epoch: 0.00827545086546038\n","Training accuracy epoch: 0.9976919375104767\n","Validating model...\n","Validation Loss: 0.09747213929418534\n","Validation Accuracy: 0.9762321891718165\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 17.97782878333334 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07474481409031247\n","Validation Accuracy: 0.9757136694770936\n","Validation duration: 0.6099984333333244 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.8%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.89      0.93      0.91      4985\n","     Disease       0.79      0.81      0.80      4416\n","\n","   micro avg       0.84      0.87      0.86      9401\n","   macro avg       0.84      0.87      0.85      9401\n","weighted avg       0.84      0.87      0.86      9401\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 1313\n","Points in y_train after augmentation: 1313\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.6609798669815063\n","Training loss epoch: 0.17942862095962087\n","Training accuracy epoch: 0.9449992891560286\n","Validating model...\n","Validation Loss: 0.09917031748900337\n","Validation Accuracy: 0.9628510095550296\n","Training epoch: 2\n","Training loss per 100 training steps: 0.07376571744680405\n","Training loss epoch: 0.04697454224778227\n","Training accuracy epoch: 0.984915907720186\n","Validating model...\n","Validation Loss: 0.07182644023781731\n","Validation Accuracy: 0.9756914196929041\n","Training epoch: 3\n","Training loss per 100 training steps: 0.01995261013507843\n","Training loss epoch: 0.024855395268469332\n","Training accuracy epoch: 0.9928483221218944\n","Validating model...\n","Validation Loss: 0.08132806851986855\n","Validation Accuracy: 0.9762911879641069\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01211970578879118\n","Training loss epoch: 0.01502686086621315\n","Training accuracy epoch: 0.9952546217421674\n","Validating model...\n","Validation Loss: 0.08512454988464477\n","Validation Accuracy: 0.9770751655000426\n","Training epoch: 5\n","Training loss per 100 training steps: 0.02387489750981331\n","Training loss epoch: 0.009480159528446889\n","Training accuracy epoch: 0.9970984823059953\n","Validating model...\n","Validation Loss: 0.09188465333528935\n","Validation Accuracy: 0.9762977376254839\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0022016793955117464\n","Training loss epoch: 0.007335133866353679\n","Training accuracy epoch: 0.9977654225685414\n","Validating model...\n","Validation Loss: 0.1024927119650538\n","Validation Accuracy: 0.9746818118952664\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0032842361833900213\n","Training loss epoch: 0.005334829843213153\n","Training accuracy epoch: 0.9984195378530908\n","Validating model...\n","Validation Loss: 0.10546645486638659\n","Validation Accuracy: 0.9752408244684726\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 18.00073526666662 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07333692328797446\n","Validation Accuracy: 0.9754878795355887\n","Validation duration: 0.6132269499999893 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.1%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.91      0.91      0.91      4985\n","     Disease       0.76      0.81      0.78      4416\n","\n","   micro avg       0.84      0.86      0.85      9401\n","   macro avg       0.84      0.86      0.85      9401\n","weighted avg       0.84      0.86      0.85      9401\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 1313\n","Points in y_train after augmentation: 1313\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.940016508102417\n","Training loss epoch: 0.20027370176401482\n","Training accuracy epoch: 0.9412905480332676\n","Validating model...\n","Validation Loss: 0.08076230998313616\n","Validation Accuracy: 0.972706275579532\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0828423723578453\n","Training loss epoch: 0.056120303739984355\n","Training accuracy epoch: 0.9814138459766392\n","Validating model...\n","Validation Loss: 0.07151348575476617\n","Validation Accuracy: 0.9748920452446445\n","Training epoch: 3\n","Training loss per 100 training steps: 0.045153819024562836\n","Training loss epoch: 0.02851068838892213\n","Training accuracy epoch: 0.9914687738828267\n","Validating model...\n","Validation Loss: 0.07960769167495152\n","Validation Accuracy: 0.9746787514195366\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0054648881778120995\n","Training loss epoch: 0.016127658724582876\n","Training accuracy epoch: 0.9951814642869162\n","Validating model...\n","Validation Loss: 0.08016671142762616\n","Validation Accuracy: 0.9773084492129782\n","Training epoch: 5\n","Training loss per 100 training steps: 0.017952175810933113\n","Training loss epoch: 0.010867286451071143\n","Training accuracy epoch: 0.9973038729956606\n","Validating model...\n","Validation Loss: 0.1361610461322088\n","Validation Accuracy: 0.9651911201157418\n","Training epoch: 6\n","Training loss per 100 training steps: 0.047877293080091476\n","Training loss epoch: 0.01710904231687716\n","Training accuracy epoch: 0.995087762106632\n","Validating model...\n","Validation Loss: 0.09191744212829878\n","Validation Accuracy: 0.9770063854703593\n","Training epoch: 7\n","Training loss per 100 training steps: 0.004015231970697641\n","Training loss epoch: 0.005192417552531977\n","Training accuracy epoch: 0.9986146531649285\n","Validating model...\n","Validation Loss: 0.10201377829625494\n","Validation Accuracy: 0.977343611425318\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 18.015526616666648 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07624864193891721\n","Validation Accuracy: 0.9738305513436738\n","Validation duration: 0.6119432666667005 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.0%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.90      0.92      0.91      4985\n","     Disease       0.75      0.83      0.79      4416\n","\n","   micro avg       0.82      0.88      0.85      9401\n","   macro avg       0.82      0.87      0.85      9401\n","weighted avg       0.83      0.88      0.85      9401\n","\n","!!!!!! Starting model number 5 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 1313\n","Points in y_train after augmentation: 1313\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.6143568754196167\n","Training loss epoch: 0.16503016242241286\n","Training accuracy epoch: 0.9486261912503225\n","Validating model...\n","Validation Loss: 0.08315119058603332\n","Validation Accuracy: 0.9708868773653679\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0732654333114624\n","Training loss epoch: 0.04161248396498611\n","Training accuracy epoch: 0.9867289603503752\n","Validating model...\n","Validation Loss: 0.07472218342480205\n","Validation Accuracy: 0.9760464474629075\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02904253825545311\n","Training loss epoch: 0.02183226067348417\n","Training accuracy epoch: 0.9932136166553703\n","Validating model...\n","Validation Loss: 0.08108595066836902\n","Validation Accuracy: 0.9758148272651895\n","Training epoch: 4\n","Training loss per 100 training steps: 0.016968155279755592\n","Training loss epoch: 0.01695710399850126\n","Training accuracy epoch: 0.9938754519062036\n","Validating model...\n","Validation Loss: 0.08784307775989411\n","Validation Accuracy: 0.9772731788856801\n","Training epoch: 5\n","Training loss per 100 training steps: 0.003022794146090746\n","Training loss epoch: 0.019778125386415834\n","Training accuracy epoch: 0.9942130362103461\n","Validating model...\n","Validation Loss: 0.09001264425497206\n","Validation Accuracy: 0.9772988204130946\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0036378675140440464\n","Training loss epoch: 0.007584801962015679\n","Training accuracy epoch: 0.9978642876309534\n","Validating model...\n","Validation Loss: 0.09593676929436033\n","Validation Accuracy: 0.976463142619338\n","Training epoch: 7\n","Training loss per 100 training steps: 0.002995207440108061\n","Training loss epoch: 0.0035983607676497334\n","Training accuracy epoch: 0.9990245019676693\n","Validating model...\n","Validation Loss: 0.10441362911037036\n","Validation Accuracy: 0.9768203001639237\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 18.01020261666666 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07426219752856664\n","Validation Accuracy: 0.9757007229019038\n","Validation duration: 0.6143773333333229 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.9%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.91      0.92      0.91      4985\n","     Disease       0.75      0.81      0.78      4416\n","\n","   micro avg       0.83      0.87      0.85      9401\n","   macro avg       0.83      0.86      0.85      9401\n","weighted avg       0.83      0.87      0.85      9401\n","\n","!!!!!! Starting model number 6 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 1313\n","Points in y_train after augmentation: 1313\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9729419946670532\n","Training loss epoch: 0.17494890228452453\n","Training accuracy epoch: 0.9442996664141845\n","Validating model...\n","Validation Loss: 0.07870530869279589\n","Validation Accuracy: 0.9733005092368713\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0643020048737526\n","Training loss epoch: 0.049390246553054774\n","Training accuracy epoch: 0.984098674520407\n","Validating model...\n","Validation Loss: 0.0763245906739954\n","Validation Accuracy: 0.9753323230508558\n","Training epoch: 3\n","Training loss per 100 training steps: 0.02317710593342781\n","Training loss epoch: 0.027136121596018952\n","Training accuracy epoch: 0.9917452767286237\n","Validating model...\n","Validation Loss: 0.08536353092344981\n","Validation Accuracy: 0.9743309899067907\n","Training epoch: 4\n","Training loss per 100 training steps: 0.018881333991885185\n","Training loss epoch: 0.021756846418447166\n","Training accuracy epoch: 0.9929273349115385\n","Validating model...\n","Validation Loss: 0.08924391233022251\n","Validation Accuracy: 0.9769579829871904\n","Training epoch: 5\n","Training loss per 100 training steps: 0.00630862545222044\n","Training loss epoch: 0.01694897431263094\n","Training accuracy epoch: 0.9946754151211381\n","Validating model...\n","Validation Loss: 0.09524994556392942\n","Validation Accuracy: 0.9764472870944302\n","Training epoch: 6\n","Training loss per 100 training steps: 0.005776462610810995\n","Training loss epoch: 0.009426002070189914\n","Training accuracy epoch: 0.9971483551254733\n","Validating model...\n","Validation Loss: 0.09907243010543641\n","Validation Accuracy: 0.9769433852389902\n","Training epoch: 7\n","Training loss per 100 training steps: 0.005859261844307184\n","Training loss epoch: 0.006188272042704903\n","Training accuracy epoch: 0.998296373647206\n","Validating model...\n","Validation Loss: 0.10875460280785484\n","Validation Accuracy: 0.9755660758728865\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 17.96899791666668 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07749252080444306\n","Validation Accuracy: 0.9743036901940775\n","Validation duration: 0.6137907000000269 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.1%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.90      0.94      0.92      4985\n","     Disease       0.79      0.75      0.77      4416\n","\n","   micro avg       0.85      0.85      0.85      9401\n","   macro avg       0.84      0.85      0.84      9401\n","weighted avg       0.85      0.85      0.85      9401\n","\n","!!!!!! Starting model number 7 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 1313\n","Points in y_train after augmentation: 1313\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.5966367721557617\n","Training loss epoch: 0.17573278410786605\n","Training accuracy epoch: 0.9452251460324697\n","Validating model...\n","Validation Loss: 0.07879592188530499\n","Validation Accuracy: 0.9734211082674061\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04516372084617615\n","Training loss epoch: 0.04481660821531192\n","Training accuracy epoch: 0.9858547001523483\n","Validating model...\n","Validation Loss: 0.07890686191736705\n","Validation Accuracy: 0.975158383388475\n","Training epoch: 3\n","Training loss per 100 training steps: 0.01600123569369316\n","Training loss epoch: 0.02528547442866018\n","Training accuracy epoch: 0.9920798308056697\n","Validating model...\n","Validation Loss: 0.082535261613509\n","Validation Accuracy: 0.9746893077938468\n","Training epoch: 4\n","Training loss per 100 training steps: 0.008156094700098038\n","Training loss epoch: 0.017686767021126776\n","Training accuracy epoch: 0.9945703609756837\n","Validating model...\n","Validation Loss: 0.10076348678696723\n","Validation Accuracy: 0.9730116814121827\n","Training epoch: 5\n","Training loss per 100 training steps: 0.007627979386597872\n","Training loss epoch: 0.013207993333379412\n","Training accuracy epoch: 0.9959403806721733\n","Validating model...\n","Validation Loss: 0.10436610558203288\n","Validation Accuracy: 0.9759099298839595\n","Training epoch: 6\n","Training loss per 100 training steps: 0.012526923790574074\n","Training loss epoch: 0.00744942081839699\n","Training accuracy epoch: 0.9977979914801343\n","Validating model...\n","Validation Loss: 0.10083335348301464\n","Validation Accuracy: 0.9766592659383297\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 15.36776963333335 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07994356142386558\n","Validation Accuracy: 0.9716877310335477\n","Validation duration: 0.6121634000000389 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.0%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.90      0.89      0.90      4985\n","     Disease       0.70      0.83      0.76      4416\n","\n","   micro avg       0.80      0.86      0.83      9401\n","   macro avg       0.80      0.86      0.83      9401\n","weighted avg       0.81      0.86      0.83      9401\n","\n","!!!!!! Starting model number 8 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 1313\n","Points in y_train after augmentation: 1313\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8705145120620728\n","Training loss epoch: 0.178024129919618\n","Training accuracy epoch: 0.9439600229130813\n","Validating model...\n","Validation Loss: 0.07688469676271317\n","Validation Accuracy: 0.9738086547936913\n","Training epoch: 2\n","Training loss per 100 training steps: 0.06366849690675735\n","Training loss epoch: 0.05684318442840174\n","Training accuracy epoch: 0.9822641119837632\n","Validating model...\n","Validation Loss: 0.07439505734613963\n","Validation Accuracy: 0.9757743219507412\n","Training epoch: 3\n","Training loss per 100 training steps: 0.026502415537834167\n","Training loss epoch: 0.03328006927776767\n","Training accuracy epoch: 0.9876215239688292\n","Validating model...\n","Validation Loss: 0.09578738982478778\n","Validation Accuracy: 0.971533276127436\n","Training epoch: 4\n","Training loss per 100 training steps: 0.049593064934015274\n","Training loss epoch: 0.022882418533091444\n","Training accuracy epoch: 0.992820048641883\n","Validating model...\n","Validation Loss: 0.09203905940410637\n","Validation Accuracy: 0.9759855073657527\n","Training epoch: 5\n","Training loss per 100 training steps: 0.045847296714782715\n","Training loss epoch: 0.01118354196099183\n","Training accuracy epoch: 0.9966042315062686\n","Validating model...\n","Validation Loss: 0.0931137234327339\n","Validation Accuracy: 0.9750084906932454\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0042356522753834724\n","Training loss epoch: 0.007326385316720193\n","Training accuracy epoch: 0.9979206906327095\n","Validating model...\n","Validation Loss: 0.10039265069460111\n","Validation Accuracy: 0.9759892054601784\n","Training epoch: 7\n","Training loss per 100 training steps: 0.00838895607739687\n","Training loss epoch: 0.0043784501732338265\n","Training accuracy epoch: 0.9988452796120603\n","Validating model...\n","Validation Loss: 0.11366221568887196\n","Validation Accuracy: 0.9761528588053696\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 17.961512999999954 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07705085428934248\n","Validation Accuracy: 0.9748599327075993\n","Validation duration: 0.612061183333329 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.5%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.92      0.89      0.91      4985\n","     Disease       0.78      0.77      0.77      4416\n","\n","   micro avg       0.85      0.84      0.85      9401\n","   macro avg       0.85      0.83      0.84      9401\n","weighted avg       0.85      0.84      0.85      9401\n","\n","!!!!!! Starting model number 9 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 1313\n","Points in y_train after augmentation: 1313\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.5251578092575073\n","Training loss epoch: 0.16974327915224685\n","Training accuracy epoch: 0.9490935761349842\n","Validating model...\n","Validation Loss: 0.0786422427802805\n","Validation Accuracy: 0.9725621430465066\n","Training epoch: 2\n","Training loss per 100 training steps: 0.08349226415157318\n","Training loss epoch: 0.04174430052895682\n","Training accuracy epoch: 0.9868241712066126\n","Validating model...\n","Validation Loss: 0.07596659669209094\n","Validation Accuracy: 0.976587335561085\n","Training epoch: 3\n","Training loss per 100 training steps: 0.022629564628005028\n","Training loss epoch: 0.019591007625729025\n","Training accuracy epoch: 0.9940756071942211\n","Validating model...\n","Validation Loss: 0.08130808150957501\n","Validation Accuracy: 0.9760928566255872\n","Training epoch: 4\n","Training loss per 100 training steps: 0.00943229254335165\n","Training loss epoch: 0.013997994744813586\n","Training accuracy epoch: 0.9954392811346752\n","Validating model...\n","Validation Loss: 0.07690897997882631\n","Validation Accuracy: 0.9774775569764469\n","Training epoch: 5\n","Training loss per 100 training steps: 0.004843029659241438\n","Training loss epoch: 0.01431234582805591\n","Training accuracy epoch: 0.9955021293899988\n","Validating model...\n","Validation Loss: 0.09863849522338973\n","Validation Accuracy: 0.9767184721804913\n","Training epoch: 6\n","Training loss per 100 training steps: 0.006042999681085348\n","Training loss epoch: 0.006180316108105008\n","Training accuracy epoch: 0.9981439961051932\n","Validating model...\n","Validation Loss: 0.1016131482781872\n","Validation Accuracy: 0.9775110657903023\n","Training epoch: 7\n","Training loss per 100 training steps: 0.014727567322552204\n","Training loss epoch: 0.005070427151436143\n","Training accuracy epoch: 0.9985268561940084\n","Validating model...\n","Validation Loss: 0.10103157949116495\n","Validation Accuracy: 0.9776441645656708\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 17.94386695000006 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.08232003811096388\n","Validation Accuracy: 0.9740420457314131\n","Validation duration: 0.6098992500000653 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.8%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.87      0.93      0.90      4985\n","     Disease       0.75      0.83      0.79      4416\n","\n","   micro avg       0.81      0.88      0.85      9401\n","   macro avg       0.81      0.88      0.84      9401\n","weighted avg       0.82      0.88      0.85      9401\n","\n","!!!!!! Starting model number 10 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 1313\n","Points in y_train after augmentation: 1313\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.894516944885254\n","Training loss epoch: 0.17591181763234626\n","Training accuracy epoch: 0.9447250545978936\n","Validating model...\n","Validation Loss: 0.08255349401207197\n","Validation Accuracy: 0.9709964124635467\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0630926787853241\n","Training loss epoch: 0.04525258214807654\n","Training accuracy epoch: 0.9859081153543214\n","Validating model...\n","Validation Loss: 0.07525115386242905\n","Validation Accuracy: 0.9758060565831127\n","Training epoch: 3\n","Training loss per 100 training steps: 0.03016209416091442\n","Training loss epoch: 0.022153346227055573\n","Training accuracy epoch: 0.9930663558870031\n","Validating model...\n","Validation Loss: 0.08312261867381278\n","Validation Accuracy: 0.9754267856098126\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01349590253084898\n","Training loss epoch: 0.014195869344353945\n","Training accuracy epoch: 0.9957479898940717\n","Validating model...\n","Validation Loss: 0.08859395226907163\n","Validation Accuracy: 0.9752974115403146\n","Training epoch: 5\n","Training loss per 100 training steps: 0.01343341451138258\n","Training loss epoch: 0.009528290326966546\n","Training accuracy epoch: 0.9970905641907978\n","Validating model...\n","Validation Loss: 0.08998574162759478\n","Validation Accuracy: 0.9762245152924238\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0021732791792601347\n","Training loss epoch: 0.005585793640705791\n","Training accuracy epoch: 0.9984525197292975\n","Validating model...\n","Validation Loss: 0.10073970210930658\n","Validation Accuracy: 0.9754929031434907\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0018619021866470575\n","Training loss epoch: 0.00390440016299071\n","Training accuracy epoch: 0.9989358558372667\n","Validating model...\n","Validation Loss: 0.10510014754439158\n","Validation Accuracy: 0.977549530007372\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 17.961702100000064 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07736734259459707\n","Validation Accuracy: 0.9743796642872165\n","Validation duration: 0.6140825499999968 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.1%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.89      0.92      0.91      4985\n","     Disease       0.73      0.81      0.77      4416\n","\n","   micro avg       0.81      0.87      0.84      9401\n","   macro avg       0.81      0.87      0.84      9401\n","weighted avg       0.82      0.87      0.84      9401\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 0.75\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"oKNxFPucHn_R"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"1tBh5gOBHpN1","outputId":"6bf3d59f-0123-4f0a-b0a5-cb8841af41f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 100% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 1500\n","Points in y_train after augmentation: 1500\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.832338809967041\n","Training loss epoch: 0.16626880409077127\n","Training accuracy epoch: 0.9485937478069272\n","Validating model...\n","Validation Loss: 0.0822743931341739\n","Validation Accuracy: 0.9717779145520387\n","Training epoch: 2\n","Training loss per 100 training steps: 0.056917622685432434\n","Training loss epoch: 0.040244148291171865\n","Training accuracy epoch: 0.9873965640236512\n","Validating model...\n","Validation Loss: 0.0712441321876314\n","Validation Accuracy: 0.9752596138321997\n","Training epoch: 3\n","Training loss per 100 training steps: 0.023599708452820778\n","Training loss epoch: 0.017988096843374535\n","Training accuracy epoch: 0.9943905776726288\n","Validating model...\n","Validation Loss: 0.07869045992219259\n","Validation Accuracy: 0.976493370237805\n","Training epoch: 4\n","Training loss per 100 training steps: 0.009745887480676174\n","Training loss epoch: 0.013084120974142818\n","Training accuracy epoch: 0.995838833054958\n","Validating model...\n","Validation Loss: 0.08967591771885516\n","Validation Accuracy: 0.9747644416212541\n","Training epoch: 5\n","Training loss per 100 training steps: 0.01651132106781006\n","Training loss epoch: 0.008510426463351208\n","Training accuracy epoch: 0.9975471427689626\n","Validating model...\n","Validation Loss: 0.09404872375584784\n","Validation Accuracy: 0.977326418824448\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0012345310533419251\n","Training loss epoch: 0.005151359178621242\n","Training accuracy epoch: 0.998399761855932\n","Validating model...\n","Validation Loss: 0.09767433084429257\n","Validation Accuracy: 0.9768501622041801\n","Training epoch: 7\n","Training loss per 100 training steps: 0.003122958354651928\n","Training loss epoch: 0.004672489441099002\n","Training accuracy epoch: 0.9985797599344227\n","Validating model...\n","Validation Loss: 0.10282291838574031\n","Validation Accuracy: 0.9760981761605454\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 19.923210200000053 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.0769824708501498\n","Validation Accuracy: 0.9728304435997552\n","Validation duration: 0.610380933333363 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.6%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.89      0.93      0.91      4985\n","     Disease       0.73      0.83      0.78      4416\n","\n","   micro avg       0.81      0.88      0.85      9401\n","   macro avg       0.81      0.88      0.84      9401\n","weighted avg       0.82      0.88      0.85      9401\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 1500\n","Points in y_train after augmentation: 1500\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.695281744003296\n","Training loss epoch: 0.1463480491310041\n","Training accuracy epoch: 0.9532799927723609\n","Validating model...\n","Validation Loss: 0.0749393670213601\n","Validation Accuracy: 0.9745838158587691\n","Training epoch: 2\n","Training loss per 100 training steps: 0.09646390378475189\n","Training loss epoch: 0.03575616442856002\n","Training accuracy epoch: 0.988644118178103\n","Validating model...\n","Validation Loss: 0.07334530043105285\n","Validation Accuracy: 0.9764557629143703\n","Training epoch: 3\n","Training loss per 100 training steps: 0.014724635519087315\n","Training loss epoch: 0.018696477371664282\n","Training accuracy epoch: 0.9940670471914314\n","Validating model...\n","Validation Loss: 0.08414812637345186\n","Validation Accuracy: 0.9754724271025592\n","Training epoch: 4\n","Training loss per 100 training steps: 0.007467189338058233\n","Training loss epoch: 0.011948569861062347\n","Training accuracy epoch: 0.9963047022655747\n","Validating model...\n","Validation Loss: 0.09028490130153913\n","Validation Accuracy: 0.976502034556555\n","Training epoch: 5\n","Training loss per 100 training steps: 0.002456177957355976\n","Training loss epoch: 0.007821079878572454\n","Training accuracy epoch: 0.9977172127321674\n","Validating model...\n","Validation Loss: 0.10133633585203261\n","Validation Accuracy: 0.9763554402130254\n","Training epoch: 6\n","Training loss per 100 training steps: 0.004141272511333227\n","Training loss epoch: 0.005119232069502802\n","Training accuracy epoch: 0.9985413504359563\n","Validating model...\n","Validation Loss: 0.1080264477502732\n","Validation Accuracy: 0.9755399398503377\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0011497113155201077\n","Training loss epoch: 0.0039367552065201344\n","Training accuracy epoch: 0.9988310846011531\n","Validating model...\n","Validation Loss: 0.11180578349601655\n","Validation Accuracy: 0.9780491335572666\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 19.9141272333333 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07648208509716722\n","Validation Accuracy: 0.9753223440577572\n","Validation duration: 0.6093502499999885 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.6%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.90      0.93      0.91      4985\n","     Disease       0.76      0.83      0.79      4416\n","\n","   micro avg       0.83      0.88      0.86      9401\n","   macro avg       0.83      0.88      0.85      9401\n","weighted avg       0.84      0.88      0.86      9401\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 1500\n","Points in y_train after augmentation: 1500\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7317423820495605\n","Training loss epoch: 0.15560659774123353\n","Training accuracy epoch: 0.9511135242839205\n","Validating model...\n","Validation Loss: 0.08129124083216228\n","Validation Accuracy: 0.9718289403064287\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04969589784741402\n","Training loss epoch: 0.038286849172746246\n","Training accuracy epoch: 0.9881260400156479\n","Validating model...\n","Validation Loss: 0.07734191195950621\n","Validation Accuracy: 0.9752220064090684\n","Training epoch: 3\n","Training loss per 100 training steps: 0.01977463811635971\n","Training loss epoch: 0.021643164513157086\n","Training accuracy epoch: 0.99323160978298\n","Validating model...\n","Validation Loss: 0.08519851141387508\n","Validation Accuracy: 0.974402627904426\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01570463739335537\n","Training loss epoch: 0.01158751516994287\n","Training accuracy epoch: 0.996649757648847\n","Validating model...\n","Validation Loss: 0.08666591730619234\n","Validation Accuracy: 0.9774043447794253\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0027725149411708117\n","Training loss epoch: 0.006329514115350321\n","Training accuracy epoch: 0.9980518501106815\n","Validating model...\n","Validation Loss: 0.10092402243661502\n","Validation Accuracy: 0.9768369048763103\n","Training epoch: 6\n","Training loss per 100 training steps: 0.006124988663941622\n","Training loss epoch: 0.006919066972802691\n","Training accuracy epoch: 0.9978581638803932\n","Validating model...\n","Validation Loss: 0.09234258662613612\n","Validation Accuracy: 0.976395016758141\n","Training epoch: 7\n","Training loss per 100 training steps: 0.00939514022320509\n","Training loss epoch: 0.005114751004123505\n","Training accuracy epoch: 0.9984423770712447\n","Validating model...\n","Validation Loss: 0.10149153274676156\n","Validation Accuracy: 0.9763819416085296\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 19.894145349999963 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.0808580516586228\n","Validation Accuracy: 0.9742380649172427\n","Validation duration: 0.6116820999999618 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.4%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.88      0.93      0.90      4985\n","     Disease       0.74      0.82      0.78      4416\n","\n","   micro avg       0.81      0.88      0.84      9401\n","   macro avg       0.81      0.87      0.84      9401\n","weighted avg       0.82      0.88      0.85      9401\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 1500\n","Points in y_train after augmentation: 1500\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.875400424003601\n","Training loss epoch: 0.1550792926684656\n","Training accuracy epoch: 0.9508426026078508\n","Validating model...\n","Validation Loss: 0.07873754670459127\n","Validation Accuracy: 0.9730901814482218\n","Training epoch: 2\n","Training loss per 100 training steps: 0.029825186356902122\n","Training loss epoch: 0.03944551334419149\n","Training accuracy epoch: 0.9872296684065297\n","Validating model...\n","Validation Loss: 0.07397170441727789\n","Validation Accuracy: 0.9749094464187322\n","Training epoch: 3\n","Training loss per 100 training steps: 0.036889608949422836\n","Training loss epoch: 0.02002466998082843\n","Training accuracy epoch: 0.9938213019861232\n","Validating model...\n","Validation Loss: 0.08483090843000109\n","Validation Accuracy: 0.974074481773585\n","Training epoch: 4\n","Training loss per 100 training steps: 0.009133970364928246\n","Training loss epoch: 0.012706546888171516\n","Training accuracy epoch: 0.9962335895753966\n","Validating model...\n","Validation Loss: 0.10349742228549624\n","Validation Accuracy: 0.9728077793104254\n","Training epoch: 5\n","Training loss per 100 training steps: 0.010412435978651047\n","Training loss epoch: 0.007873314307715268\n","Training accuracy epoch: 0.9975937963885407\n","Validating model...\n","Validation Loss: 0.10142162170202013\n","Validation Accuracy: 0.9749254887470362\n","Training epoch: 6\n","Training loss per 100 training steps: 0.005254109390079975\n","Training loss epoch: 0.005729759837738536\n","Training accuracy epoch: 0.9984037765823813\n","Validating model...\n","Validation Loss: 0.12020664230462104\n","Validation Accuracy: 0.9720135738916964\n","Training epoch: 7\n","Training loss per 100 training steps: 0.003168881870806217\n","Training loss epoch: 0.0030904531031797464\n","Training accuracy epoch: 0.999237223772211\n","Validating model...\n","Validation Loss: 0.1277768483592404\n","Validation Accuracy: 0.9739125478917471\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 19.930519233333325 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07932202517986298\n","Validation Accuracy: 0.9734408558949352\n","Validation duration: 0.6097879333333064 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.8%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.88      0.94      0.91      4985\n","     Disease       0.73      0.83      0.78      4416\n","\n","   micro avg       0.81      0.89      0.85      9401\n","   macro avg       0.81      0.89      0.85      9401\n","weighted avg       0.81      0.89      0.85      9401\n","\n","!!!!!! Starting model number 5 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 1500\n","Points in y_train after augmentation: 1500\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8801394701004028\n","Training loss epoch: 0.17443611857263333\n","Training accuracy epoch: 0.9462499727136445\n","Validating model...\n","Validation Loss: 0.07502925744841969\n","Validation Accuracy: 0.9741395977199214\n","Training epoch: 2\n","Training loss per 100 training steps: 0.031279101967811584\n","Training loss epoch: 0.041558915333069386\n","Training accuracy epoch: 0.9867889759102306\n","Validating model...\n","Validation Loss: 0.07163641530843008\n","Validation Accuracy: 0.9765627231832615\n","Training epoch: 3\n","Training loss per 100 training steps: 0.011899893172085285\n","Training loss epoch: 0.020946016678824387\n","Training accuracy epoch: 0.993575194266428\n","Validating model...\n","Validation Loss: 0.07995576364180398\n","Validation Accuracy: 0.9766767423805895\n","Training epoch: 4\n","Training loss per 100 training steps: 0.007999842055141926\n","Training loss epoch: 0.012908491566083691\n","Training accuracy epoch: 0.9961245987921475\n","Validating model...\n","Validation Loss: 0.09319115542466679\n","Validation Accuracy: 0.9767045787193482\n","Training epoch: 5\n","Training loss per 100 training steps: 0.006285085342824459\n","Training loss epoch: 0.007595621451903927\n","Training accuracy epoch: 0.9978132973127207\n","Validating model...\n","Validation Loss: 0.10509295749758917\n","Validation Accuracy: 0.9753945989413468\n","Training epoch: 6\n","Training loss per 100 training steps: 0.007992095313966274\n","Training loss epoch: 0.005680868953857769\n","Training accuracy epoch: 0.9982914311472879\n","Validating model...\n","Validation Loss: 0.10865188537845535\n","Validation Accuracy: 0.9769986451906912\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0020180190913379192\n","Training loss epoch: 0.006632952867917955\n","Training accuracy epoch: 0.9979692178769266\n","Validating model...\n","Validation Loss: 0.10442566014234982\n","Validation Accuracy: 0.9733718069511114\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 19.8963546166667 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07562126851980648\n","Validation Accuracy: 0.9755428223939079\n","Validation duration: 0.6108019833332946 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.7%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.90      0.93      0.91      4985\n","     Disease       0.76      0.83      0.79      4416\n","\n","   micro avg       0.83      0.89      0.86      9401\n","   macro avg       0.83      0.88      0.85      9401\n","weighted avg       0.83      0.89      0.86      9401\n","\n","!!!!!! Starting model number 6 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 1500\n","Points in y_train after augmentation: 1500\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7231037616729736\n","Training loss epoch: 0.16284725569347117\n","Training accuracy epoch: 0.9494092046705146\n","Validating model...\n","Validation Loss: 0.07966318566884313\n","Validation Accuracy: 0.9723207768920893\n","Training epoch: 2\n","Training loss per 100 training steps: 0.039281025528907776\n","Training loss epoch: 0.03789995285741826\n","Training accuracy epoch: 0.987490767318565\n","Validating model...\n","Validation Loss: 0.07341097851121237\n","Validation Accuracy: 0.9745597468793888\n","Training epoch: 3\n","Training loss per 100 training steps: 0.013375992886722088\n","Training loss epoch: 0.019482908081857764\n","Training accuracy epoch: 0.9939872489300926\n","Validating model...\n","Validation Loss: 0.08062099588532297\n","Validation Accuracy: 0.9754769157032296\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01406063325703144\n","Training loss epoch: 0.012065192719208116\n","Training accuracy epoch: 0.996285218524602\n","Validating model...\n","Validation Loss: 0.09163398059114577\n","Validation Accuracy: 0.9765386280892\n","Training epoch: 5\n","Training loss per 100 training steps: 0.005544747691601515\n","Training loss epoch: 0.007142854842079922\n","Training accuracy epoch: 0.9978689798244652\n","Validating model...\n","Validation Loss: 0.09264543586011444\n","Validation Accuracy: 0.9760449031033442\n","Training epoch: 6\n","Training loss per 100 training steps: 0.003939182031899691\n","Training loss epoch: 0.005575386393676571\n","Training accuracy epoch: 0.9983430546689844\n","Validating model...\n","Validation Loss: 0.09627856142700665\n","Validation Accuracy: 0.9771068016390988\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0040787868201732635\n","Training loss epoch: 0.0043715250126006916\n","Training accuracy epoch: 0.9988801046578105\n","Validating model...\n","Validation Loss: 0.10857159756715336\n","Validation Accuracy: 0.9760036541775123\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 19.920500399999945 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07494681890285204\n","Validation Accuracy: 0.9741094896348471\n","Validation duration: 0.6095172333333418 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.3%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.91      0.91      0.91      4985\n","     Disease       0.74      0.85      0.79      4416\n","\n","   micro avg       0.82      0.88      0.85      9401\n","   macro avg       0.83      0.88      0.85      9401\n","weighted avg       0.83      0.88      0.85      9401\n","\n","!!!!!! Starting model number 7 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 1500\n","Points in y_train after augmentation: 1500\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.556443214416504\n","Training loss epoch: 0.14887926761219475\n","Training accuracy epoch: 0.953752874408785\n","Validating model...\n","Validation Loss: 0.08007520650114332\n","Validation Accuracy: 0.9732771322259219\n","Training epoch: 2\n","Training loss per 100 training steps: 0.044140953570604324\n","Training loss epoch: 0.03826676568690133\n","Training accuracy epoch: 0.9878949808066128\n","Validating model...\n","Validation Loss: 0.07609520116377444\n","Validation Accuracy: 0.9751103627980183\n","Training epoch: 3\n","Training loss per 100 training steps: 0.01960202492773533\n","Training loss epoch: 0.01732835497092852\n","Training accuracy epoch: 0.9946760320168192\n","Validating model...\n","Validation Loss: 0.07517528217581529\n","Validation Accuracy: 0.9774493142184606\n","Training epoch: 4\n","Training loss per 100 training steps: 0.01397820096462965\n","Training loss epoch: 0.00994922874242741\n","Training accuracy epoch: 0.9971171172886665\n","Validating model...\n","Validation Loss: 0.09941147037205242\n","Validation Accuracy: 0.9762259857823792\n","Training epoch: 5\n","Training loss per 100 training steps: 0.008934197947382927\n","Training loss epoch: 0.008158376959320951\n","Training accuracy epoch: 0.9975369662840802\n","Validating model...\n","Validation Loss: 0.10762974069941611\n","Validation Accuracy: 0.9759515637626279\n","Training epoch: 6\n","Training loss per 100 training steps: 0.003131840145215392\n","Training loss epoch: 0.0044644191248733745\n","Training accuracy epoch: 0.9986774171609477\n","Validating model...\n","Validation Loss: 0.10512508168106988\n","Validation Accuracy: 0.9763568504664473\n","Training epoch: 7\n","Training loss per 100 training steps: 0.002767961472272873\n","Training loss epoch: 0.003041160184712932\n","Training accuracy epoch: 0.9991341658441479\n","Validating model...\n","Validation Loss: 0.11227266685593695\n","Validation Accuracy: 0.9774922756411747\n","Training epoch: 8\n","Training loss per 100 training steps: 0.0005094828084111214\n","Training loss epoch: 0.0024559873119405313\n","Training accuracy epoch: 0.9992719219911861\n","Validating model...\n","Validation Loss: 0.1213187567061848\n","Validation Accuracy: 0.9763834018369737\n","Training epoch: 9\n","Patience limit reached\n","Training duration: 22.79431821666658 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.0787222074965636\n","Validation Accuracy: 0.9768171720348463\n","Validation duration: 0.6115588666666251 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 86.1%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.91      0.92      0.91      4985\n","     Disease       0.77      0.85      0.81      4416\n","\n","   micro avg       0.84      0.88      0.86      9401\n","   macro avg       0.84      0.88      0.86      9401\n","weighted avg       0.84      0.88      0.86      9401\n","\n","!!!!!! Starting model number 8 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 1500\n","Points in y_train after augmentation: 1500\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.059041976928711\n","Training loss epoch: 0.1791505273035232\n","Training accuracy epoch: 0.9450398042507816\n","Validating model...\n","Validation Loss: 0.08592463243338797\n","Validation Accuracy: 0.9701812988731544\n","Training epoch: 2\n","Training loss per 100 training steps: 0.032589785754680634\n","Training loss epoch: 0.04148805226655083\n","Training accuracy epoch: 0.9867118309064631\n","Validating model...\n","Validation Loss: 0.07434162420649378\n","Validation Accuracy: 0.9749797646965387\n","Training epoch: 3\n","Training loss per 100 training steps: 0.023155277594923973\n","Training loss epoch: 0.02121059009508091\n","Training accuracy epoch: 0.9932218957374039\n","Validating model...\n","Validation Loss: 0.08581640181087312\n","Validation Accuracy: 0.975591353217603\n","Training epoch: 4\n","Training loss per 100 training steps: 0.019444642588496208\n","Training loss epoch: 0.011614293082954084\n","Training accuracy epoch: 0.9964850785351261\n","Validating model...\n","Validation Loss: 0.09757393985868447\n","Validation Accuracy: 0.9736536046391382\n","Training epoch: 5\n","Training loss per 100 training steps: 0.004751079715788364\n","Training loss epoch: 0.008228782538393948\n","Training accuracy epoch: 0.9975814415420386\n","Validating model...\n","Validation Loss: 0.08762843055384499\n","Validation Accuracy: 0.9778034534206081\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0052923960611224174\n","Training loss epoch: 0.004888652732219309\n","Training accuracy epoch: 0.9985487744370343\n","Validating model...\n","Validation Loss: 0.10775963418067448\n","Validation Accuracy: 0.9749188393903045\n","Training epoch: 7\n","Training loss per 100 training steps: 0.0050529660657048225\n","Training loss epoch: 0.0035636292004516904\n","Training accuracy epoch: 0.9990129188940411\n","Validating model...\n","Validation Loss: 0.13281709647604398\n","Validation Accuracy: 0.972698625389362\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 19.825714933333316 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07866013741918973\n","Validation Accuracy: 0.9740965260173481\n","Validation duration: 0.6130424500000421 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.8%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.88      0.93      0.91      4985\n","     Disease       0.73      0.85      0.78      4416\n","\n","   micro avg       0.81      0.89      0.85      9401\n","   macro avg       0.81      0.89      0.85      9401\n","weighted avg       0.81      0.89      0.85      9401\n","\n","!!!!!! Starting model number 9 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 1500\n","Points in y_train after augmentation: 1500\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.537195086479187\n","Training loss epoch: 0.1645250890721032\n","Training accuracy epoch: 0.9513568019898332\n","Validating model...\n","Validation Loss: 0.0755069385327044\n","Validation Accuracy: 0.9739311221304945\n","Training epoch: 2\n","Training loss per 100 training steps: 0.020855506882071495\n","Training loss epoch: 0.038278930622370956\n","Training accuracy epoch: 0.9880499228712986\n","Validating model...\n","Validation Loss: 0.07824651814169353\n","Validation Accuracy: 0.9733366377878471\n","Training epoch: 3\n","Training loss per 100 training steps: 0.010415120050311089\n","Training loss epoch: 0.01980373324786729\n","Training accuracy epoch: 0.9938812823380277\n","Validating model...\n","Validation Loss: 0.0842382347891255\n","Validation Accuracy: 0.9750227770243598\n","Training epoch: 4\n","Training loss per 100 training steps: 0.00916668027639389\n","Training loss epoch: 0.009682810876488765\n","Training accuracy epoch: 0.9972987201874217\n","Validating model...\n","Validation Loss: 0.08802221517359453\n","Validation Accuracy: 0.9772688043023612\n","Training epoch: 5\n","Training loss per 100 training steps: 0.014939459972083569\n","Training loss epoch: 0.006896687240557785\n","Training accuracy epoch: 0.9978606367207247\n","Validating model...\n","Validation Loss: 0.09731687197373026\n","Validation Accuracy: 0.9763387157751158\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00484634330496192\n","Training loss epoch: 0.005816293729870441\n","Training accuracy epoch: 0.9982929927978236\n","Validating model...\n","Validation Loss: 0.10116313480668598\n","Validation Accuracy: 0.9771412613628437\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 17.092600999999924 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07645532181338659\n","Validation Accuracy: 0.9737161677305617\n","Validation duration: 0.6119048500000644 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 82.6%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.92      0.88      0.90      4985\n","     Disease       0.70      0.80      0.75      4416\n","\n","   micro avg       0.81      0.84      0.83      9401\n","   macro avg       0.81      0.84      0.82      9401\n","weighted avg       0.82      0.84      0.83      9401\n","\n","!!!!!! Starting model number 10 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 1500\n","Points in y_train after augmentation: 1500\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.4307941198349\n","Training loss epoch: 0.1457411459587673\n","Training accuracy epoch: 0.9544435474296875\n","Validating model...\n","Validation Loss: 0.07805059726039569\n","Validation Accuracy: 0.9732428651780554\n","Training epoch: 2\n","Training loss per 100 training steps: 0.04832431674003601\n","Training loss epoch: 0.03555860440742145\n","Training accuracy epoch: 0.9889445150336743\n","Validating model...\n","Validation Loss: 0.07389142086345052\n","Validation Accuracy: 0.975460812306959\n","Training epoch: 3\n","Training loss per 100 training steps: 0.01915818452835083\n","Training loss epoch: 0.018542515309626594\n","Training accuracy epoch: 0.9944762050456094\n","Validating model...\n","Validation Loss: 0.09000126000434633\n","Validation Accuracy: 0.9743452368056946\n","Training epoch: 4\n","Training loss per 100 training steps: 0.011728765442967415\n","Training loss epoch: 0.012231030640132885\n","Training accuracy epoch: 0.9964209347602294\n","Validating model...\n","Validation Loss: 0.08607029979900709\n","Validation Accuracy: 0.9775173536706181\n","Training epoch: 5\n","Training loss per 100 training steps: 0.06210167333483696\n","Training loss epoch: 0.009031157539364822\n","Training accuracy epoch: 0.9972902439861149\n","Validating model...\n","Validation Loss: 0.09158152702545362\n","Validation Accuracy: 0.9774002612100968\n","Training epoch: 6\n","Training loss per 100 training steps: 0.004559198394417763\n","Training loss epoch: 0.005168284783684748\n","Training accuracy epoch: 0.9985709366406497\n","Validating model...\n","Validation Loss: 0.091237972416575\n","Validation Accuracy: 0.977419918342621\n","Training epoch: 7\n","Training loss per 100 training steps: 0.003278744639828801\n","Training loss epoch: 0.004687400440626005\n","Training accuracy epoch: 0.9987611918079647\n","Validating model...\n","Validation Loss: 0.10926572555705669\n","Validation Accuracy: 0.9762578851656545\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 19.955648783333285 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07991408323129964\n","Validation Accuracy: 0.9741717603439567\n","Validation duration: 0.6167341333333752 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.8%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.93      0.88      0.91      4985\n","     Disease       0.77      0.80      0.78      4416\n","\n","   micro avg       0.85      0.84      0.85      9401\n","   macro avg       0.85      0.84      0.85      9401\n","weighted avg       0.86      0.84      0.85      9401\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 1\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"1tBh5gOBHpN1"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Zjhn7-LqHri0","outputId":"47684851-53ac-4e9d-965c-59cbf7823ac8"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 200% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 2250\n","Points in y_train after augmentation: 2250\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7405290603637695\n","Training loss per 100 training steps: 0.1553428685569232\n","Training loss epoch: 0.1253710087283072\n","Training accuracy epoch: 0.9616022885645659\n","Validating model...\n","Validation Loss: 0.08526618554005547\n","Validation Accuracy: 0.9684810494253057\n","Training epoch: 2\n","Training loss per 100 training steps: 0.020325597375631332\n","Training loss per 100 training steps: 0.027715932448754216\n","Training loss epoch: 0.02658328703267777\n","Training accuracy epoch: 0.9916178114492025\n","Validating model...\n","Validation Loss: 0.08872848474198863\n","Validation Accuracy: 0.9719941801307372\n","Training epoch: 3\n","Training loss per 100 training steps: 0.010445588268339634\n","Training loss per 100 training steps: 0.013385281822007924\n","Training loss epoch: 0.013379546808712978\n","Training accuracy epoch: 0.9959305873585179\n","Validating model...\n","Validation Loss: 0.08925117265492205\n","Validation Accuracy: 0.9758827979709517\n","Training epoch: 4\n","Training loss per 100 training steps: 0.005997915286570787\n","Training loss per 100 training steps: 0.009339815496679137\n","Training loss epoch: 0.009292478702057497\n","Training accuracy epoch: 0.997351431786661\n","Validating model...\n","Validation Loss: 0.09381543661630343\n","Validation Accuracy: 0.9764511140615394\n","Training epoch: 5\n","Training loss per 100 training steps: 0.010585261508822441\n","Training loss per 100 training steps: 0.006961461258037846\n","Training loss epoch: 0.006431568148116588\n","Training accuracy epoch: 0.9981891542719429\n","Validating model...\n","Validation Loss: 0.10340793353934137\n","Validation Accuracy: 0.9765192186413777\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0021148917730897665\n","Training loss per 100 training steps: 0.00503950358205936\n","Training loss epoch: 0.004905991622408627\n","Training accuracy epoch: 0.9986192212825126\n","Validating model...\n","Validation Loss: 0.11403482561073607\n","Validation Accuracy: 0.9751289246846971\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 23.78894503333334 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.08764794433400744\n","Validation Accuracy: 0.9685637664822677\n","Validation duration: 0.6104507333333459 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.8%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.90      0.93      0.92      4985\n","     Disease       0.68      0.85      0.76      4416\n","\n","   micro avg       0.79      0.89      0.84      9401\n","   macro avg       0.79      0.89      0.84      9401\n","weighted avg       0.80      0.89      0.84      9401\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 2250\n","Points in y_train after augmentation: 2250\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.5043381452560425\n","Training loss per 100 training steps: 0.13385655214585881\n","Training loss epoch: 0.10928959896167119\n","Training accuracy epoch: 0.966117123872489\n","Validating model...\n","Validation Loss: 0.07587600741831083\n","Validation Accuracy: 0.9740638736290258\n","Training epoch: 2\n","Training loss per 100 training steps: 0.017382077872753143\n","Training loss per 100 training steps: 0.028033016157327312\n","Training loss epoch: 0.026718959020754548\n","Training accuracy epoch: 0.9913054461635098\n","Validating model...\n","Validation Loss: 0.07548236338392136\n","Validation Accuracy: 0.976725367355104\n","Training epoch: 3\n","Training loss per 100 training steps: 0.014447133988142014\n","Training loss per 100 training steps: 0.012449909928300888\n","Training loss epoch: 0.011821167574904807\n","Training accuracy epoch: 0.996314469196484\n","Validating model...\n","Validation Loss: 0.09222163531988387\n","Validation Accuracy: 0.9753917823552015\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0031260265968739986\n","Training loss per 100 training steps: 0.006751016405927441\n","Training loss epoch: 0.007270169814269171\n","Training accuracy epoch: 0.9978566754862661\n","Validating model...\n","Validation Loss: 0.10164563328264252\n","Validation Accuracy: 0.9761811683224109\n","Training epoch: 5\n","Training loss per 100 training steps: 0.001658670254983008\n","Training loss per 100 training steps: 0.006341741899821428\n","Training loss epoch: 0.005740377855287363\n","Training accuracy epoch: 0.9982440212003721\n","Validating model...\n","Validation Loss: 0.10591365822723933\n","Validation Accuracy: 0.9768703813501793\n","Training epoch: 6\n","Training loss per 100 training steps: 0.009087427519261837\n","Training loss per 100 training steps: 0.0033741875702635116\n","Training loss epoch: 0.003182536037102117\n","Training accuracy epoch: 0.999082712951977\n","Validating model...\n","Validation Loss: 0.12329760909317032\n","Validation Accuracy: 0.9754711904100317\n","Training epoch: 7\n","Training loss per 100 training steps: 0.01194657851010561\n","Training loss per 100 training steps: 0.0031539316351512805\n","Training loss epoch: 0.00331548946346726\n","Training accuracy epoch: 0.9990847008617055\n","Validating model...\n","Validation Loss: 0.11825295933891856\n","Validation Accuracy: 0.9763661549685999\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 27.754269533333353 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07724704614116086\n","Validation Accuracy: 0.9758718944667922\n","Validation duration: 0.6149493333333036 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 86.3%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.90      0.93      0.91      4985\n","     Disease       0.79      0.82      0.80      4416\n","\n","   micro avg       0.85      0.88      0.86      9401\n","   macro avg       0.85      0.87      0.86      9401\n","weighted avg       0.85      0.88      0.86      9401\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 2250\n","Points in y_train after augmentation: 2250\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8876771926879883\n","Training loss per 100 training steps: 0.15211261176310553\n","Training loss epoch: 0.12411433490032846\n","Training accuracy epoch: 0.9608819179214008\n","Validating model...\n","Validation Loss: 0.0719042651000477\n","Validation Accuracy: 0.9754530934768199\n","Training epoch: 2\n","Training loss per 100 training steps: 0.021198123693466187\n","Training loss per 100 training steps: 0.02676860545070307\n","Training loss epoch: 0.026186857461691537\n","Training accuracy epoch: 0.99185324437134\n","Validating model...\n","Validation Loss: 0.07940427196167764\n","Validation Accuracy: 0.9730906633324639\n","Training epoch: 3\n","Training loss per 100 training steps: 0.014144270680844784\n","Training loss per 100 training steps: 0.014894214894456586\n","Training loss epoch: 0.014342975508791546\n","Training accuracy epoch: 0.9956546380026198\n","Validating model...\n","Validation Loss: 0.0857933848682377\n","Validation Accuracy: 0.976503082699182\n","Training epoch: 4\n","Training loss per 100 training steps: 0.007251618895679712\n","Training loss per 100 training steps: 0.009465757259490466\n","Training loss epoch: 0.009088278160238942\n","Training accuracy epoch: 0.9974003561189586\n","Validating model...\n","Validation Loss: 0.09937172264806808\n","Validation Accuracy: 0.9751999396337319\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0063322847709059715\n","Training loss per 100 training steps: 0.005596007711466144\n","Training loss epoch: 0.005833058384352806\n","Training accuracy epoch: 0.9982366411333067\n","Validating model...\n","Validation Loss: 0.10550172012003642\n","Validation Accuracy: 0.9764722856609223\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0003160679480060935\n","Training loss per 100 training steps: 0.0051757289643634555\n","Training loss epoch: 0.004856233625608357\n","Training accuracy epoch: 0.9985930706079097\n","Validating model...\n","Validation Loss: 0.11535738148386517\n","Validation Accuracy: 0.9750173539396376\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 23.75015961666674 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07326282779612238\n","Validation Accuracy: 0.9752072702600166\n","Validation duration: 0.6137553833334095 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.8%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.90      0.92      0.91      4985\n","     Disease       0.74      0.83      0.78      4416\n","\n","   micro avg       0.82      0.88      0.85      9401\n","   macro avg       0.82      0.88      0.85      9401\n","weighted avg       0.82      0.88      0.85      9401\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 2250\n","Points in y_train after augmentation: 2250\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.5858591794967651\n","Training loss per 100 training steps: 0.14732014144411182\n","Training loss epoch: 0.11932937535358236\n","Training accuracy epoch: 0.9623667268775888\n","Validating model...\n","Validation Loss: 0.07204074394844827\n","Validation Accuracy: 0.9758346687221798\n","Training epoch: 2\n","Training loss per 100 training steps: 0.041748106479644775\n","Training loss per 100 training steps: 0.02698877339002372\n","Training loss epoch: 0.02525343264433298\n","Training accuracy epoch: 0.9920324129388296\n","Validating model...\n","Validation Loss: 0.09440678056506883\n","Validation Accuracy: 0.9707857696793114\n","Training epoch: 3\n","Training loss per 100 training steps: 0.021538497880101204\n","Training loss per 100 training steps: 0.013780461725695888\n","Training loss epoch: 0.014379297242770699\n","Training accuracy epoch: 0.9955706815986275\n","Validating model...\n","Validation Loss: 0.10453390253205148\n","Validation Accuracy: 0.9693645996271457\n","Training epoch: 4\n","Training loss per 100 training steps: 0.007434623781591654\n","Training loss per 100 training steps: 0.009012984767749832\n","Training loss epoch: 0.008694039007932846\n","Training accuracy epoch: 0.9974480569427728\n","Validating model...\n","Validation Loss: 0.09099630455649088\n","Validation Accuracy: 0.9767180119719393\n","Training epoch: 5\n","Training loss per 100 training steps: 0.003766911569982767\n","Training loss per 100 training steps: 0.004653126010579048\n","Training loss epoch: 0.004949746115119956\n","Training accuracy epoch: 0.9985466527883019\n","Validating model...\n","Validation Loss: 0.09876072389029321\n","Validation Accuracy: 0.9774508766325729\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0037368913181126118\n","Training loss per 100 training steps: 0.0033070613283751587\n","Training loss epoch: 0.0034907032499925383\n","Training accuracy epoch: 0.9989519428157717\n","Validating model...\n","Validation Loss: 0.1207085730182746\n","Validation Accuracy: 0.9739045473764831\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 23.783879049999936 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07330965966222779\n","Validation Accuracy: 0.9749483315892198\n","Validation duration: 0.6087166333332182 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.6%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.88      0.94      0.91      4985\n","     Disease       0.78      0.82      0.80      4416\n","\n","   micro avg       0.83      0.88      0.86      9401\n","   macro avg       0.83      0.88      0.85      9401\n","weighted avg       0.83      0.88      0.86      9401\n","\n","!!!!!! Starting model number 5 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 2250\n","Points in y_train after augmentation: 2250\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.8943853378295898\n","Training loss per 100 training steps: 0.16541938170200526\n","Training loss epoch: 0.13235803132097348\n","Training accuracy epoch: 0.9594455650509431\n","Validating model...\n","Validation Loss: 0.07167599155079751\n","Validation Accuracy: 0.9757266392943984\n","Training epoch: 2\n","Training loss per 100 training steps: 0.037105951458215714\n","Training loss per 100 training steps: 0.029277213535612762\n","Training loss epoch: 0.028978140909119068\n","Training accuracy epoch: 0.9908104249026402\n","Validating model...\n","Validation Loss: 0.07738985783523983\n","Validation Accuracy: 0.974727684326964\n","Training epoch: 3\n","Training loss per 100 training steps: 0.012555609457194805\n","Training loss per 100 training steps: 0.014294780795416325\n","Training loss epoch: 0.01528166357513702\n","Training accuracy epoch: 0.9951561068972797\n","Validating model...\n","Validation Loss: 0.08548669972353512\n","Validation Accuracy: 0.9724895373862831\n","Training epoch: 4\n","Training loss per 100 training steps: 0.012715419754385948\n","Training loss per 100 training steps: 0.010036534463783891\n","Training loss epoch: 0.009554893469870592\n","Training accuracy epoch: 0.9971159487705549\n","Validating model...\n","Validation Loss: 0.09178361178390564\n","Validation Accuracy: 0.9769020213688427\n","Training epoch: 5\n","Training loss per 100 training steps: 0.001032529049552977\n","Training loss per 100 training steps: 0.004002625307662985\n","Training loss epoch: 0.004615435517741473\n","Training accuracy epoch: 0.9987047952053816\n","Validating model...\n","Validation Loss: 0.0968590233888891\n","Validation Accuracy: 0.9764664208685023\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0070518930442631245\n","Training loss per 100 training steps: 0.00365315012329507\n","Training loss epoch: 0.0038356126390532955\n","Training accuracy epoch: 0.9989060948780492\n","Validating model...\n","Validation Loss: 0.1117473988542481\n","Validation Accuracy: 0.9757126744593043\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 23.753726000000096 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.0722030278236147\n","Validation Accuracy: 0.9755508441606712\n","Validation duration: 0.6095884166665201 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.8%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.90      0.91      0.91      4985\n","     Disease       0.77      0.79      0.78      4416\n","\n","   micro avg       0.84      0.86      0.85      9401\n","   macro avg       0.83      0.85      0.84      9401\n","weighted avg       0.84      0.86      0.85      9401\n","\n","!!!!!! Starting model number 6 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 2250\n","Points in y_train after augmentation: 2250\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.440814733505249\n","Training loss per 100 training steps: 0.13899205628745626\n","Training loss epoch: 0.11179320251318157\n","Training accuracy epoch: 0.9659514157144149\n","Validating model...\n","Validation Loss: 0.07699523529126531\n","Validation Accuracy: 0.9739970444555257\n","Training epoch: 2\n","Training loss per 100 training steps: 0.024383340030908585\n","Training loss per 100 training steps: 0.025563897435912992\n","Training loss epoch: 0.023814062036388944\n","Training accuracy epoch: 0.9925331767416086\n","Validating model...\n","Validation Loss: 0.07914646898233701\n","Validation Accuracy: 0.9754958644513002\n","Training epoch: 3\n","Training loss per 100 training steps: 0.018802611157298088\n","Training loss per 100 training steps: 0.011526465955384002\n","Training loss epoch: 0.011919582515281248\n","Training accuracy epoch: 0.9964185316479937\n","Validating model...\n","Validation Loss: 0.09271118228161146\n","Validation Accuracy: 0.9760622565045308\n","Training epoch: 4\n","Training loss per 100 training steps: 0.016356799751520157\n","Training loss per 100 training steps: 0.008323921627217517\n","Training loss epoch: 0.007936551208782889\n","Training accuracy epoch: 0.9977392923724262\n","Validating model...\n","Validation Loss: 0.09898236943852334\n","Validation Accuracy: 0.9776306782148539\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0016172189498320222\n","Training loss per 100 training steps: 0.0038251499241992535\n","Training loss epoch: 0.0042331335132740145\n","Training accuracy epoch: 0.9988080382507751\n","Validating model...\n","Validation Loss: 0.10277886564532916\n","Validation Accuracy: 0.9777290264134657\n","Training epoch: 6\n","Training loss per 100 training steps: 0.001092773163691163\n","Training loss per 100 training steps: 0.0038836559912969015\n","Training loss epoch: 0.003790327605518103\n","Training accuracy epoch: 0.9989377851508587\n","Validating model...\n","Validation Loss: 0.11343717947602272\n","Validation Accuracy: 0.9759544505711963\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 23.801894499999857 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07962383433348602\n","Validation Accuracy: 0.9735938990410051\n","Validation duration: 0.614900183333278 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.6%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.91      0.91      0.91      4985\n","     Disease       0.75      0.79      0.77      4416\n","\n","   micro avg       0.83      0.86      0.85      9401\n","   macro avg       0.83      0.85      0.84      9401\n","weighted avg       0.84      0.86      0.85      9401\n","\n","!!!!!! Starting model number 7 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 2250\n","Points in y_train after augmentation: 2250\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.649875521659851\n","Training loss per 100 training steps: 0.13952439656425822\n","Training loss epoch: 0.11349187126871965\n","Training accuracy epoch: 0.9638337070642803\n","Validating model...\n","Validation Loss: 0.07138333936768865\n","Validation Accuracy: 0.9751712341719997\n","Training epoch: 2\n","Training loss per 100 training steps: 0.03604959324002266\n","Training loss per 100 training steps: 0.026263381520489064\n","Training loss epoch: 0.02535544646613247\n","Training accuracy epoch: 0.9920280443735642\n","Validating model...\n","Validation Loss: 0.07717748382498348\n","Validation Accuracy: 0.9757164559069837\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0178490299731493\n","Training loss per 100 training steps: 0.012287141630739564\n","Training loss epoch: 0.011684533763439097\n","Training accuracy epoch: 0.9962943516516745\n","Validating model...\n","Validation Loss: 0.09809224351885773\n","Validation Accuracy: 0.9768875693765438\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0030024508014321327\n","Training loss per 100 training steps: 0.007318419020503095\n","Training loss epoch: 0.006804710170270624\n","Training accuracy epoch: 0.9978882448417781\n","Validating model...\n","Validation Loss: 0.10659975327906154\n","Validation Accuracy: 0.9770378392439674\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0012963106855750084\n","Training loss per 100 training steps: 0.0075416217332171034\n","Training loss epoch: 0.006963555920697379\n","Training accuracy epoch: 0.9980040943404415\n","Validating model...\n","Validation Loss: 0.10370600037276745\n","Validation Accuracy: 0.975689535675725\n","Training epoch: 6\n","Training loss per 100 training steps: 0.00812668539583683\n","Training loss per 100 training steps: 0.004764564431014259\n","Training loss epoch: 0.004551642333282858\n","Training accuracy epoch: 0.9987102889146201\n","Validating model...\n","Validation Loss: 0.11810424303015073\n","Validation Accuracy: 0.9747948686495668\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 23.77882905000006 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07657017813078941\n","Validation Accuracy: 0.9730785313037063\n","Validation duration: 0.6127402499999638 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 83.8%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.90      0.93      0.92      4985\n","     Disease       0.69      0.84      0.76      4416\n","\n","   micro avg       0.79      0.89      0.84      9401\n","   macro avg       0.80      0.88      0.84      9401\n","weighted avg       0.80      0.89      0.84      9401\n","\n","!!!!!! Starting model number 8 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 2250\n","Points in y_train after augmentation: 2250\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.4679940938949585\n","Training loss per 100 training steps: 0.13779565848705203\n","Training loss epoch: 0.11213577724993229\n","Training accuracy epoch: 0.9658024519096157\n","Validating model...\n","Validation Loss: 0.07746749075632246\n","Validation Accuracy: 0.9744769403346509\n","Training epoch: 2\n","Training loss per 100 training steps: 0.01917894370853901\n","Training loss per 100 training steps: 0.028142671045469175\n","Training loss epoch: 0.02711739304891609\n","Training accuracy epoch: 0.9912714851008225\n","Validating model...\n","Validation Loss: 0.07639048490968961\n","Validation Accuracy: 0.9767164748105209\n","Training epoch: 3\n","Training loss per 100 training steps: 0.005181846208870411\n","Training loss per 100 training steps: 0.012363419162644313\n","Training loss epoch: 0.012379436274818707\n","Training accuracy epoch: 0.9962806072799569\n","Validating model...\n","Validation Loss: 0.09224001708484832\n","Validation Accuracy: 0.9757067248925623\n","Training epoch: 4\n","Training loss per 100 training steps: 0.013289887458086014\n","Training loss per 100 training steps: 0.006620728728329154\n","Training loss epoch: 0.006723419579649212\n","Training accuracy epoch: 0.997997715629912\n","Validating model...\n","Validation Loss: 0.10549339031179746\n","Validation Accuracy: 0.9748157116508946\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0037457600701600313\n","Training loss per 100 training steps: 0.007087515991545365\n","Training loss epoch: 0.006592038259692887\n","Training accuracy epoch: 0.9980372785820063\n","Validating model...\n","Validation Loss: 0.10964393603896337\n","Validation Accuracy: 0.9742586869269686\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0013064228696748614\n","Training loss per 100 training steps: 0.0041327319709621\n","Training loss epoch: 0.004088395265267885\n","Training accuracy epoch: 0.9988286414858643\n","Validating model...\n","Validation Loss: 0.1066127358566201\n","Validation Accuracy: 0.975936697401003\n","Training epoch: 7\n","Training loss per 100 training steps: 0.001214734511449933\n","Training loss per 100 training steps: 0.0027862392549776465\n","Training loss epoch: 0.0028606312242518213\n","Training accuracy epoch: 0.9991630094119387\n","Validating model...\n","Validation Loss: 0.1072558622866396\n","Validation Accuracy: 0.977122566700845\n","Training epoch: 8\n","Patience limit reached\n","Training duration: 27.72488423333319 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07416399172137654\n","Validation Accuracy: 0.9771877635807195\n","Validation duration: 0.6093428500001513 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 86.0%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.92      0.91      0.92      4985\n","     Disease       0.79      0.80      0.80      4416\n","\n","   micro avg       0.86      0.86      0.86      9401\n","   macro avg       0.86      0.86      0.86      9401\n","weighted avg       0.86      0.86      0.86      9401\n","\n","!!!!!! Starting model number 9 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 2250\n","Points in y_train after augmentation: 2250\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.34819757938385\n","Training loss per 100 training steps: 0.15061231647240053\n","Training loss epoch: 0.12203988590086183\n","Training accuracy epoch: 0.9624570853723393\n","Validating model...\n","Validation Loss: 0.07346778156028853\n","Validation Accuracy: 0.9757115948556683\n","Training epoch: 2\n","Training loss per 100 training steps: 0.017901567742228508\n","Training loss per 100 training steps: 0.026476254908017593\n","Training loss epoch: 0.026143448453740024\n","Training accuracy epoch: 0.9918036810320546\n","Validating model...\n","Validation Loss: 0.07712898314708755\n","Validation Accuracy: 0.9769228508304261\n","Training epoch: 3\n","Training loss per 100 training steps: 0.01792926900088787\n","Training loss per 100 training steps: 0.013747352254945822\n","Training loss epoch: 0.013583735519102014\n","Training accuracy epoch: 0.9959028178157684\n","Validating model...\n","Validation Loss: 0.09559081802292475\n","Validation Accuracy: 0.9758142521678262\n","Training epoch: 4\n","Training loss per 100 training steps: 0.014414306730031967\n","Training loss per 100 training steps: 0.008654551890604935\n","Training loss epoch: 0.00907236906693231\n","Training accuracy epoch: 0.9973234191701131\n","Validating model...\n","Validation Loss: 0.10449520001808803\n","Validation Accuracy: 0.9727171870495069\n","Training epoch: 5\n","Training loss per 100 training steps: 0.008203692734241486\n","Training loss per 100 training steps: 0.005600756865299058\n","Training loss epoch: 0.005412477376979795\n","Training accuracy epoch: 0.9984472978807992\n","Validating model...\n","Validation Loss: 0.11421005510621601\n","Validation Accuracy: 0.97393236969269\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0019800872541964054\n","Training loss per 100 training steps: 0.0047364229812415885\n","Training loss epoch: 0.005019195183801155\n","Training accuracy epoch: 0.9984934595855468\n","Validating model...\n","Validation Loss: 0.11871838120241014\n","Validation Accuracy: 0.9722134798284704\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 23.769038550000065 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07728960093051668\n","Validation Accuracy: 0.9740793312505054\n","Validation duration: 0.6138718333332993 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.2%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.90      0.92      0.91      4985\n","     Disease       0.76      0.83      0.79      4416\n","\n","   micro avg       0.83      0.88      0.85      9401\n","   macro avg       0.83      0.87      0.85      9401\n","weighted avg       0.83      0.88      0.85      9401\n","\n","!!!!!! Starting model number 10 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 2250\n","Points in y_train after augmentation: 2250\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.6859300136566162\n","Training loss per 100 training steps: 0.14378438233444008\n","Training loss epoch: 0.11537515328444065\n","Training accuracy epoch: 0.9642285056011554\n","Validating model...\n","Validation Loss: 0.07202626874167768\n","Validation Accuracy: 0.9755805512041437\n","Training epoch: 2\n","Training loss per 100 training steps: 0.03439994528889656\n","Training loss per 100 training steps: 0.0257502674761385\n","Training loss epoch: 0.02385496507656384\n","Training accuracy epoch: 0.99250377892592\n","Validating model...\n","Validation Loss: 0.08754934760786239\n","Validation Accuracy: 0.9720466656149256\n","Training epoch: 3\n","Training loss per 100 training steps: 0.014269146136939526\n","Training loss per 100 training steps: 0.011238278454575356\n","Training loss epoch: 0.011461213316953352\n","Training accuracy epoch: 0.9965665462611341\n","Validating model...\n","Validation Loss: 0.09036967631370302\n","Validation Accuracy: 0.9762705697268891\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0024904704187065363\n","Training loss per 100 training steps: 0.008996850816708169\n","Training loss epoch: 0.009091987428981943\n","Training accuracy epoch: 0.9973407964302285\n","Validating model...\n","Validation Loss: 0.0904867613599414\n","Validation Accuracy: 0.9772798658459085\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0046964120119810104\n","Training loss per 100 training steps: 0.005457927799659163\n","Training loss epoch: 0.005288684607940851\n","Training accuracy epoch: 0.9984194044244794\n","Validating model...\n","Validation Loss: 0.10348143765614146\n","Validation Accuracy: 0.9771300512829685\n","Training epoch: 6\n","Training loss per 100 training steps: 0.002125605009496212\n","Training loss per 100 training steps: 0.00248321143827876\n","Training loss epoch: 0.002807339978778358\n","Training accuracy epoch: 0.9990947850179122\n","Validating model...\n","Validation Loss: 0.12281479169097212\n","Validation Accuracy: 0.9734227920604519\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 23.768121900000065 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.0745085823157477\n","Validation Accuracy: 0.9753302598388844\n","Validation duration: 0.6097748166665649 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.4%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.90      0.93      0.91      4985\n","     Disease       0.75      0.84      0.79      4416\n","\n","   micro avg       0.82      0.89      0.85      9401\n","   macro avg       0.82      0.88      0.85      9401\n","weighted avg       0.83      0.89      0.86      9401\n","\n"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 2\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"Zjhn7-LqHri0"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"TTDq-xbgHqXQ","outputId":"96890e2f-4e6a-438e-ec59-f22f5e58502c"},"outputs":[{"name":"stdout","output_type":"stream","text":["!!!!!! Augmented Percentage 500% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 4500\n","Points in y_train after augmentation: 4500\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9023598432540894\n","Training loss per 100 training steps: 0.14519231878958716\n","Training loss per 100 training steps: 0.09474032079402488\n","Training loss epoch: 0.07555232009130484\n","Training accuracy epoch: 0.9759067881640587\n","Validating model...\n","Validation Loss: 0.07630694633911526\n","Validation Accuracy: 0.9767534823630636\n","Training epoch: 2\n","Training loss per 100 training steps: 0.021420065313577652\n","Training loss per 100 training steps: 0.015936713123989133\n","Training loss per 100 training steps: 0.015156747106073508\n","Training loss epoch: 0.014181055194625617\n","Training accuracy epoch: 0.995647528366157\n","Validating model...\n","Validation Loss: 0.09009546144968933\n","Validation Accuracy: 0.9746224357147841\n","Training epoch: 3\n","Training loss per 100 training steps: 0.0046989573165774345\n","Training loss per 100 training steps: 0.008980230206974072\n","Training loss per 100 training steps: 0.008798341233797594\n","Training loss epoch: 0.00862937531345656\n","Training accuracy epoch: 0.9975131532089518\n","Validating model...\n","Validation Loss: 0.08966166035286964\n","Validation Accuracy: 0.9775739990134809\n","Training epoch: 4\n","Training loss per 100 training steps: 0.003589341416954994\n","Training loss per 100 training steps: 0.005866500525677687\n","Training loss per 100 training steps: 0.00532582195288043\n","Training loss epoch: 0.005363147338796143\n","Training accuracy epoch: 0.9984306274997125\n","Validating model...\n","Validation Loss: 0.11117484538801133\n","Validation Accuracy: 0.9751046951211065\n","Training epoch: 5\n","Training loss per 100 training steps: 0.006659949664026499\n","Training loss per 100 training steps: 0.0041882312060725685\n","Training loss per 100 training steps: 0.003949107586600776\n","Training loss epoch: 0.0038175980480188\n","Training accuracy epoch: 0.9988880246039425\n","Validating model...\n","Validation Loss: 0.11557442665336624\n","Validation Accuracy: 0.9762138806707195\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0016669717151671648\n","Training loss per 100 training steps: 0.002738034002693822\n","Training loss per 100 training steps: 0.0038813836081272026\n","Training loss epoch: 0.003781889284726031\n","Training accuracy epoch: 0.9988576334415273\n","Validating model...\n","Validation Loss: 0.12441889657860711\n","Validation Accuracy: 0.9754728345163503\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 43.961169616666545 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.07706993629061987\n","Validation Accuracy: 0.9762338615974352\n","Validation duration: 0.6106282666665114 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 86.0%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.90      0.92      0.91      4985\n","     Disease       0.79      0.82      0.81      4416\n","\n","   micro avg       0.85      0.87      0.86      9401\n","   macro avg       0.85      0.87      0.86      9401\n","weighted avg       0.85      0.87      0.86      9401\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 4500\n","Points in y_train after augmentation: 4500\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.746978521347046\n","Training loss per 100 training steps: 0.15230127527277068\n","Training loss per 100 training steps: 0.09702489077025533\n","Training loss epoch: 0.07675639260230017\n","Training accuracy epoch: 0.9762757363282577\n","Validating model...\n","Validation Loss: 0.0816214568912983\n","Validation Accuracy: 0.9723835864207815\n","Training epoch: 2\n","Training loss per 100 training steps: 0.03726527839899063\n","Training loss per 100 training steps: 0.017516560041078245\n","Training loss per 100 training steps: 0.016339336802247004\n","Training loss epoch: 0.01514173047171232\n","Training accuracy epoch: 0.9954191318761471\n","Validating model...\n","Validation Loss: 0.08993177216440912\n","Validation Accuracy: 0.9766555549900108\n","Training epoch: 3\n","Training loss per 100 training steps: 0.010976951569318771\n","Training loss per 100 training steps: 0.006676877271914209\n","Training loss per 100 training steps: 0.0067244684008015\n","Training loss epoch: 0.006970628461113583\n","Training accuracy epoch: 0.997920742702833\n","Validating model...\n","Validation Loss: 0.10278998007850042\n","Validation Accuracy: 0.9746652640063641\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0027883662842214108\n","Training loss per 100 training steps: 0.005427664468562839\n","Training loss per 100 training steps: 0.006175497695062291\n","Training loss epoch: 0.0060316296589498055\n","Training accuracy epoch: 0.9981166649605173\n","Validating model...\n","Validation Loss: 0.10691650194071588\n","Validation Accuracy: 0.9756146022212177\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0052994731813669205\n","Training loss per 100 training steps: 0.003467676199806651\n","Training loss per 100 training steps: 0.003813477330209817\n","Training loss epoch: 0.0038152138070130705\n","Training accuracy epoch: 0.9989364359752736\n","Validating model...\n","Validation Loss: 0.11476149948106872\n","Validation Accuracy: 0.9764300735012833\n","Training epoch: 6\n","Training loss per 100 training steps: 0.001243401668034494\n","Training loss per 100 training steps: 0.0028955652588853924\n","Training loss per 100 training steps: 0.002881275522360458\n","Training loss epoch: 0.0028715000547413346\n","Training accuracy epoch: 0.9990976508314351\n","Validating model...\n","Validation Loss: 0.124756753681198\n","Validation Accuracy: 0.976183114380491\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 43.9471086833335 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.08954904843417424\n","Validation Accuracy: 0.970283628587715\n","Validation duration: 0.6123648333331706 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 84.6%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.91      0.91      0.91      4985\n","     Disease       0.74      0.81      0.78      4416\n","\n","   micro avg       0.83      0.87      0.85      9401\n","   macro avg       0.82      0.86      0.84      9401\n","weighted avg       0.83      0.87      0.85      9401\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Points in X_train after augmentation: 4500\n","Points in y_train after augmentation: 4500\n","Device:  cuda\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.582527995109558\n","Training loss per 100 training steps: 0.13521135740424736\n","Training loss per 100 training steps: 0.0876578001388863\n","Training loss epoch: 0.07018632499719078\n","Training accuracy epoch: 0.9781606665153036\n","Validating model...\n","Validation Loss: 0.0819843305600068\n","Validation Accuracy: 0.9744858767889836\n","Training epoch: 2\n","Training loss per 100 training steps: 0.009989594109356403\n","Training loss per 100 training steps: 0.014949997308396615\n","Training loss per 100 training steps: 0.013852114526239868\n","Training loss epoch: 0.013544366604991996\n","Training accuracy epoch: 0.9958004480470807\n","Validating model...\n","Validation Loss: 0.08338305294986754\n","Validation Accuracy: 0.9755042874987673\n","Training epoch: 3\n","Training loss per 100 training steps: 0.007061033044010401\n","Training loss per 100 training steps: 0.008201810286384961\n","Training loss per 100 training steps: 0.00856789679466909\n","Training loss epoch: 0.008437184946560334\n","Training accuracy epoch: 0.9974352965282\n","Validating model...\n","Validation Loss: 0.10452711694533863\n","Validation Accuracy: 0.9753083075065072\n","Training epoch: 4\n","Training loss per 100 training steps: 0.004262586589902639\n","Training loss per 100 training steps: 0.0042075078068808235\n","Training loss per 100 training steps: 0.005148874512648868\n","Training loss epoch: 0.005236927871216677\n","Training accuracy epoch: 0.9984594110736311\n","Validating model...\n","Validation Loss: 0.11021752223845512\n","Validation Accuracy: 0.975297474212509\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0023718946613371372\n","Training loss per 100 training steps: 0.004427470581053922\n","Training loss per 100 training steps: 0.004334989188088971\n","Training loss epoch: 0.0042582466063219295\n","Training accuracy epoch: 0.9987583197585754\n","Validating model...\n","Validation Loss: 0.10636235838608137\n","Validation Accuracy: 0.9760504084136084\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0006434230599552393\n","Training loss per 100 training steps: 0.002662236942900437\n","Training loss per 100 training steps: 0.0022197393093426683\n","Training loss epoch: 0.0023255756373371903\n","Training accuracy epoch: 0.9992506742313533\n","Validating model...\n","Validation Loss: 0.1320028512014283\n","Validation Accuracy: 0.9755238569464983\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 43.93120969999994 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["Validating model...\n","Validation Loss: 0.08358761100541978\n","Validation Accuracy: 0.9740905214811505\n","Validation duration: 0.6168245499999708 minutes\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"name":"stdout","output_type":"stream","text":["F1-score (test): 85.6%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.87      0.94      0.90      4985\n","     Disease       0.79      0.83      0.81      4416\n","\n","   micro avg       0.83      0.88      0.86      9401\n","   macro avg       0.83      0.88      0.85      9401\n","weighted avg       0.83      0.88      0.86      9401\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"ename":"RuntimeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-5d221e2f919e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_training_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"!!!!!! Starting model number {i+1} !!!!!!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mcreate_train_and_validate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_augmented_percentage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-7-64d8cd75852a>\u001b[0m in \u001b[0;36mcreate_train_and_validate_model\u001b[0;34m(augmented_percentage)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_train_and_validate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmented_percentage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0maugmented_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmented_y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdated_word2idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdated_idx2word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmented_percentage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mmaxlen_X_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maugmented_X_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-71ef841a2454>\u001b[0m in \u001b[0;36mgenerate_sentences\u001b[0;34m(dataset, labels, augmented_set_size_percentage)\u001b[0m\n\u001b[1;32m     55\u001b[0m       \u001b[0mmasked_text_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"[MASK]\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreplace_indices\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncated_sequence_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0mnew_mask_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_text_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m       \u001b[0maugmented_text_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munmasker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mask_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m       \u001b[0maugmented_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtruncated_sequence_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/fill_mask.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;34m-\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mto\u001b[0m \u001b[0mreplace\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmasked\u001b[0m \u001b[0mone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \"\"\"\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1072\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1079\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m    988\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/fill_mask.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mmodel_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1358\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1359\u001b[0m         )\n\u001b[1;32m   1360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1010\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m         )\n\u001b[1;32m   1014\u001b[0m         encoder_outputs = self.encoder(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"absolute\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0membeddings\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mposition_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (513) must match the size of tensor b (512) at non-singleton dimension 1"]}],"source":["number_of_training_models = 10\n","target_augmented_percentage = 5\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"id":"TTDq-xbgHqXQ"},{"cell_type":"code","source":["number_of_training_models = 7\n","target_augmented_percentage = 5\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f21508875a904455b573247e5553cd6b","2b8cd25f7f244fd1b323032991dbca86","5ef957cf49484bbb8f6bf20d8fc79517","ceaf7453ae0947fd94af2659458310c4","b9a43f5ad85f47e79bccd9e869f4dd46","070faa6ac15241158df021e1cca53593","0e3c57d62f0c4b7c9d987882d18a165f","12504dbed6b04ac4b4f1d03fe0f75afc","87747ea4d1554723bd454ad4858a4476","4447dba43f16470182225837b48cdaf0","5fd7ba185d6a47369253fea52fa0069b"]},"id":"UYF3C6akwayl","executionInfo":{"status":"error","timestamp":1666934807442,"user_tz":240,"elapsed":4896012,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"}},"outputId":"222be631-9967-48e7-f6fc-3ba194fae0a5"},"id":"UYF3C6akwayl","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["!!!!!! Augmented Percentage 500% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f21508875a904455b573247e5553cd6b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 4500\n","Points in y_train after augmentation: 4500\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9575245380401611\n","Training loss per 100 training steps: 0.15569759073602682\n","Training loss per 100 training steps: 0.09826033675014528\n","Training loss epoch: 0.07866079029825299\n","Training accuracy epoch: 0.9750293241394914\n","Validating model...\n","Validation Loss: 0.08088682177993986\n","Validation Accuracy: 0.9726193659557103\n","Training epoch: 2\n","Training loss per 100 training steps: 0.027115527540445328\n","Training loss per 100 training steps: 0.018531357468391706\n","Training loss per 100 training steps: 0.016490900756985838\n","Training loss epoch: 0.0154918049006386\n","Training accuracy epoch: 0.9951187812108503\n","Validating model...\n","Validation Loss: 0.09549555025758251\n","Validation Accuracy: 0.9730115698298444\n","Training epoch: 3\n","Training loss per 100 training steps: 0.007643207907676697\n","Training loss per 100 training steps: 0.009432569924179502\n","Training loss per 100 training steps: 0.008605108048479578\n","Training loss epoch: 0.008898775128759973\n","Training accuracy epoch: 0.9974689520158534\n","Validating model...\n","Validation Loss: 0.08991479288254466\n","Validation Accuracy: 0.9765545816411098\n","Training epoch: 4\n","Training loss per 100 training steps: 0.002387109911069274\n","Training loss per 100 training steps: 0.006202972625465234\n","Training loss per 100 training steps: 0.006920801208641806\n","Training loss epoch: 0.006500051121286476\n","Training accuracy epoch: 0.9980389201297121\n","Validating model...\n","Validation Loss: 0.11005338207478561\n","Validation Accuracy: 0.9762088315545145\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0026880160439759493\n","Training loss per 100 training steps: 0.004291198431919928\n","Training loss per 100 training steps: 0.004365251879717469\n","Training loss epoch: 0.00446054403385699\n","Training accuracy epoch: 0.9986576326795469\n","Validating model...\n","Validation Loss: 0.1155567192250774\n","Validation Accuracy: 0.9744122274698712\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0032821795903146267\n","Training loss per 100 training steps: 0.0033349737263916263\n","Training loss per 100 training steps: 0.00319042971567801\n","Training loss epoch: 0.0035869629642315596\n","Training accuracy epoch: 0.998940377187425\n","Validating model...\n","Validation Loss: 0.11943652174834694\n","Validation Accuracy: 0.9764208856710818\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 12.865183850000001 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.08458411291478173\n","Validation Accuracy: 0.9723159094529784\n","Validation duration: 0.2102398666666659 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 84.7%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.89      0.94      0.91      4985\n","     Disease       0.73      0.83      0.78      4416\n","\n","   micro avg       0.81      0.89      0.85      9401\n","   macro avg       0.81      0.89      0.84      9401\n","weighted avg       0.81      0.89      0.85      9401\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 4500\n","Points in y_train after augmentation: 4500\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.6484428644180298\n","Training loss per 100 training steps: 0.13666243921264565\n","Training loss per 100 training steps: 0.08765298926470737\n","Training loss epoch: 0.07114511263946481\n","Training accuracy epoch: 0.9771979673438087\n","Validating model...\n","Validation Loss: 0.08337584404008729\n","Validation Accuracy: 0.9720078661656304\n","Training epoch: 2\n","Training loss per 100 training steps: 0.026608744636178017\n","Training loss per 100 training steps: 0.016501749035819333\n","Training loss per 100 training steps: 0.015021040775020844\n","Training loss epoch: 0.014362227560123363\n","Training accuracy epoch: 0.9955560643562446\n","Validating model...\n","Validation Loss: 0.08812549272699961\n","Validation Accuracy: 0.976269769180964\n","Training epoch: 3\n","Training loss per 100 training steps: 0.018490465357899666\n","Training loss per 100 training steps: 0.008565728485787122\n","Training loss per 100 training steps: 0.007827216643487933\n","Training loss epoch: 0.007913044713691855\n","Training accuracy epoch: 0.9976191563402581\n","Validating model...\n","Validation Loss: 0.1001943964806814\n","Validation Accuracy: 0.9758893201005449\n","Training epoch: 4\n","Training loss per 100 training steps: 0.003128090174868703\n","Training loss per 100 training steps: 0.0056912326461423446\n","Training loss per 100 training steps: 0.005517964403953551\n","Training loss epoch: 0.005812899572427999\n","Training accuracy epoch: 0.9982643481867426\n","Validating model...\n","Validation Loss: 0.10591712369332237\n","Validation Accuracy: 0.9753124539667504\n","Training epoch: 5\n","Training loss per 100 training steps: 0.004884921479970217\n","Training loss per 100 training steps: 0.004665736237248074\n","Training loss per 100 training steps: 0.004334721848193732\n","Training loss epoch: 0.004286959016060288\n","Training accuracy epoch: 0.9987983266510011\n","Validating model...\n","Validation Loss: 0.1121107145907387\n","Validation Accuracy: 0.9767335893136547\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0011723960051313043\n","Training loss per 100 training steps: 0.002415396596447998\n","Training loss per 100 training steps: 0.0034232287130067218\n","Training loss epoch: 0.003313744293762361\n","Training accuracy epoch: 0.9990651505391119\n","Validating model...\n","Validation Loss: 0.1210388256798661\n","Validation Accuracy: 0.9757331507049247\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 12.875044949999998 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.09128477371164731\n","Validation Accuracy: 0.9692339646084064\n","Validation duration: 0.20712871666666313 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 83.7%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.90      0.91      0.91      4985\n","     Disease       0.70      0.84      0.76      4416\n","\n","   micro avg       0.80      0.88      0.84      9401\n","   macro avg       0.80      0.88      0.84      9401\n","weighted avg       0.81      0.88      0.84      9401\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 4500\n","Points in y_train after augmentation: 4500\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.0107758045196533\n","Training loss per 100 training steps: 0.15813953754040275\n","Training loss per 100 training steps: 0.09929688603835023\n","Training loss epoch: 0.07910067740504148\n","Training accuracy epoch: 0.9749815222017065\n","Validating model...\n","Validation Loss: 0.07502757125194111\n","Validation Accuracy: 0.975788258991886\n","Training epoch: 2\n","Training loss per 100 training steps: 0.01876254752278328\n","Training loss per 100 training steps: 0.0163277537506627\n","Training loss per 100 training steps: 0.01496395494079968\n","Training loss epoch: 0.015713950644696384\n","Training accuracy epoch: 0.9951356592345331\n","Validating model...\n","Validation Loss: 0.0813744952163053\n","Validation Accuracy: 0.9758104881172266\n","Training epoch: 3\n","Training loss per 100 training steps: 0.011828157119452953\n","Training loss per 100 training steps: 0.006981577545561192\n","Training loss per 100 training steps: 0.007255001297389709\n","Training loss epoch: 0.008037257803965638\n","Training accuracy epoch: 0.9976559556400335\n","Validating model...\n","Validation Loss: 0.09586756416256466\n","Validation Accuracy: 0.9757136524275998\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0017808701377362013\n","Training loss per 100 training steps: 0.006033611927633312\n","Training loss per 100 training steps: 0.005546264898608814\n","Training loss epoch: 0.0057305104019952586\n","Training accuracy epoch: 0.9983386076705469\n","Validating model...\n","Validation Loss: 0.10322545838379671\n","Validation Accuracy: 0.9760769293955136\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0014432104071602225\n","Training loss per 100 training steps: 0.003211315414962811\n","Training loss per 100 training steps: 0.0032814122837521043\n","Training loss epoch: 0.0037572525177648\n","Training accuracy epoch: 0.9989072681442787\n","Validating model...\n","Validation Loss: 0.10055827018287447\n","Validation Accuracy: 0.9763832422121451\n","Training epoch: 6\n","Training loss per 100 training steps: 0.003045625053346157\n","Training loss per 100 training steps: 0.0028734808108518083\n","Training loss per 100 training steps: 0.0031049799092116286\n","Training loss epoch: 0.0033234571910080177\n","Training accuracy epoch: 0.9990503546123087\n","Validating model...\n","Validation Loss: 0.11850077930897002\n","Validation Accuracy: 0.9762722537377447\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 12.85890738333334 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.07716590021219519\n","Validation Accuracy: 0.9749696493570109\n","Validation duration: 0.2103857500000231 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 84.8%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.88      0.94      0.91      4985\n","     Disease       0.74      0.82      0.78      4416\n","\n","   micro avg       0.81      0.89      0.85      9401\n","   macro avg       0.81      0.88      0.85      9401\n","weighted avg       0.82      0.89      0.85      9401\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-3adcfc116f4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_training_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"!!!!!! Starting model number {i+1} !!!!!!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mcreate_train_and_validate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_augmented_percentage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-7-64d8cd75852a>\u001b[0m in \u001b[0;36mcreate_train_and_validate_model\u001b[0;34m(augmented_percentage)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_train_and_validate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmented_percentage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0maugmented_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmented_y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdated_word2idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdated_idx2word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmented_percentage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mmaxlen_X_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maugmented_X_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-71ef841a2454>\u001b[0m in \u001b[0;36mgenerate_sentences\u001b[0;34m(dataset, labels, augmented_set_size_percentage)\u001b[0m\n\u001b[1;32m     55\u001b[0m       \u001b[0mmasked_text_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"[MASK]\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreplace_indices\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncated_sequence_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0mnew_mask_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_text_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m       \u001b[0maugmented_text_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munmasker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mask_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m       \u001b[0maugmented_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtruncated_sequence_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/fill_mask.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;34m-\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mto\u001b[0m \u001b[0mreplace\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmasked\u001b[0m \u001b[0mone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \"\"\"\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1072\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1079\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m    988\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/fill_mask.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mmodel_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1358\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1359\u001b[0m         )\n\u001b[1;32m   1360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1010\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m         )\n\u001b[1;32m   1014\u001b[0m         encoder_outputs = self.encoder(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"absolute\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0membeddings\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mposition_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (513) must match the size of tensor b (512) at non-singleton dimension 1"]}]},{"cell_type":"code","source":["number_of_training_models = 4\n","target_augmented_percentage = 5\n","\n","print(f\"!!!!!! Augmented Percentage {target_augmented_percentage*100}% !!!!!!\")\n","\n","for i in range(number_of_training_models):\n","  print(f\"!!!!!! Starting model number {i+1} !!!!!!\")\n","  create_train_and_validate_model(target_augmented_percentage)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["832d911852a04f91b1d3dd271897d442","ea0ec1986af1452eaada3f5e8d220c2c","dc62df9fc01c4cb2a8f870d756ed3068","6b63d1c5e4cf4bdf863cf2caad3a717e","10fc444c3a87424781e90fc0f82c0974","116b59de6dd14aa4a73d4c962ac76b74","a0d3e4eda1e24b35af7efe9f1aff6421","c12b9f5e647d4fceb168258b83036e71","63eb3f5ceb914ef1b903aee4079ff038","cf3e925ddb824227bc0097ea488e60a1","5c0f99cfaa7145bbb63d1b468cbbd877"]},"id":"iRSLl8jldGUT","executionInfo":{"status":"ok","timestamp":1666947802336,"user_tz":240,"elapsed":6106433,"user":{"displayName":"Time Altigran Soares","userId":"17972430181076780193"}},"outputId":"0f98caf6-d6d4-444a-fc79-d87e8e9d1ad1"},"id":"iRSLl8jldGUT","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["!!!!!! Augmented Percentage 500% !!!!!!\n","!!!!!! Starting model number 1 !!!!!!\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"832d911852a04f91b1d3dd271897d442"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 4500\n","Points in y_train after augmentation: 4500\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7996671199798584\n","Training loss per 100 training steps: 0.1378577496893335\n","Training loss per 100 training steps: 0.08989202440137145\n","Training loss epoch: 0.07172197002772215\n","Training accuracy epoch: 0.9769146614148707\n","Validating model...\n","Validation Loss: 0.07833569822093797\n","Validation Accuracy: 0.9740999523910411\n","Training epoch: 2\n","Training loss per 100 training steps: 0.00841886643320322\n","Training loss per 100 training steps: 0.013769366289719497\n","Training loss per 100 training steps: 0.01478098815918636\n","Training loss epoch: 0.013657627897238003\n","Training accuracy epoch: 0.9957255833990436\n","Validating model...\n","Validation Loss: 0.09624597415446288\n","Validation Accuracy: 0.9757645974603847\n","Training epoch: 3\n","Training loss per 100 training steps: 0.013267029076814651\n","Training loss per 100 training steps: 0.008828192363760553\n","Training loss per 100 training steps: 0.00802093626820107\n","Training loss epoch: 0.007664774066078351\n","Training accuracy epoch: 0.9977007811011561\n","Validating model...\n","Validation Loss: 0.10743120076164367\n","Validation Accuracy: 0.9723872583283403\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0034650620073080063\n","Training loss per 100 training steps: 0.004982713342524401\n","Training loss per 100 training steps: 0.006227314650296553\n","Training loss epoch: 0.005611957382251416\n","Training accuracy epoch: 0.9983440995000326\n","Validating model...\n","Validation Loss: 0.1062892491500529\n","Validation Accuracy: 0.9768693951922205\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0025058044120669365\n","Training loss per 100 training steps: 0.003025537315383784\n","Training loss per 100 training steps: 0.003537052410332699\n","Training loss epoch: 0.0038149076897249696\n","Training accuracy epoch: 0.9988491065229\n","Validating model...\n","Validation Loss: 0.12332034045978198\n","Validation Accuracy: 0.9763577900002687\n","Training epoch: 6\n","Training loss per 100 training steps: 0.009675784036517143\n","Training loss per 100 training steps: 0.0032352921712883093\n","Training loss per 100 training steps: 0.003470866864680924\n","Training loss epoch: 0.0032603265779032635\n","Training accuracy epoch: 0.9990404339434065\n","Validating model...\n","Validation Loss: 0.12217375618361291\n","Validation Accuracy: 0.9760650414026477\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 12.902908833333337 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.08106884466750282\n","Validation Accuracy: 0.9737131713380628\n","Validation duration: 0.2093607833333408 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 85.1%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.90      0.92      0.91      4985\n","     Disease       0.75      0.83      0.79      4416\n","\n","   micro avg       0.83      0.88      0.85      9401\n","   macro avg       0.83      0.87      0.85      9401\n","weighted avg       0.83      0.88      0.85      9401\n","\n","!!!!!! Starting model number 2 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 4500\n","Points in y_train after augmentation: 4500\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.9287837743759155\n","Training loss per 100 training steps: 0.15692671078561557\n","Training loss per 100 training steps: 0.09980955544340225\n","Training loss epoch: 0.07928938257792001\n","Training accuracy epoch: 0.9752345278421234\n","Validating model...\n","Validation Loss: 0.0757600221014212\n","Validation Accuracy: 0.9769116841111566\n","Training epoch: 2\n","Training loss per 100 training steps: 0.017091860994696617\n","Training loss per 100 training steps: 0.016312919570926097\n","Training loss per 100 training steps: 0.016355598447334706\n","Training loss epoch: 0.015725161698201\n","Training accuracy epoch: 0.9951083344389414\n","Validating model...\n","Validation Loss: 0.09759220052214843\n","Validation Accuracy: 0.9724127245077666\n","Training epoch: 3\n","Training loss per 100 training steps: 0.011806370690464973\n","Training loss per 100 training steps: 0.011395310223480632\n","Training loss per 100 training steps: 0.009591267483867242\n","Training loss epoch: 0.009161429339152899\n","Training accuracy epoch: 0.9972674124362584\n","Validating model...\n","Validation Loss: 0.09677779077300949\n","Validation Accuracy: 0.9769708130570303\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0035169897601008415\n","Training loss per 100 training steps: 0.004649934451104981\n","Training loss per 100 training steps: 0.0043546486308853796\n","Training loss epoch: 0.004760896394971316\n","Training accuracy epoch: 0.9986256330604607\n","Validating model...\n","Validation Loss: 0.10914088090852139\n","Validation Accuracy: 0.9755223577949099\n","Training epoch: 5\n","Training loss per 100 training steps: 0.0026589061599224806\n","Training loss per 100 training steps: 0.0031010306733925503\n","Training loss per 100 training steps: 0.003659149277978461\n","Training loss epoch: 0.004300584326166303\n","Training accuracy epoch: 0.9986384413752959\n","Validating model...\n","Validation Loss: 0.11457534702051253\n","Validation Accuracy: 0.9746816872446941\n","Training epoch: 6\n","Training loss per 100 training steps: 0.002615920500829816\n","Training loss per 100 training steps: 0.003554890981741655\n","Training loss per 100 training steps: 0.0034727222306146495\n","Training loss epoch: 0.003981370796946518\n","Training accuracy epoch: 0.9988605764822691\n","Validating model...\n","Validation Loss: 0.11503753905731534\n","Validation Accuracy: 0.9759102876546615\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 12.858385066666658 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.07458645442412012\n","Validation Accuracy: 0.9770317813447331\n","Validation duration: 0.20589328333333773 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 86.0%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.90      0.93      0.91      4985\n","     Disease       0.78      0.82      0.80      4416\n","\n","   micro avg       0.84      0.88      0.86      9401\n","   macro avg       0.84      0.88      0.86      9401\n","weighted avg       0.84      0.88      0.86      9401\n","\n","!!!!!! Starting model number 3 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 4500\n","Points in y_train after augmentation: 4500\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.6127973794937134\n","Training loss per 100 training steps: 0.14994451982697637\n","Training loss per 100 training steps: 0.0964046273547322\n","Training loss epoch: 0.07825737125207241\n","Training accuracy epoch: 0.9754760436960607\n","Validating model...\n","Validation Loss: 0.07634929904625529\n","Validation Accuracy: 0.973938497513986\n","Training epoch: 2\n","Training loss per 100 training steps: 0.0294486153870821\n","Training loss per 100 training steps: 0.018811172178697468\n","Training loss per 100 training steps: 0.01661439059390246\n","Training loss epoch: 0.015570801994449572\n","Training accuracy epoch: 0.9949306581386217\n","Validating model...\n","Validation Loss: 0.09110603623446964\n","Validation Accuracy: 0.9767047088087301\n","Training epoch: 3\n","Training loss per 100 training steps: 0.007542075123637915\n","Training loss per 100 training steps: 0.008271043755962411\n","Training loss per 100 training steps: 0.008356190589777848\n","Training loss epoch: 0.008068185589641187\n","Training accuracy epoch: 0.9975110830442746\n","Validating model...\n","Validation Loss: 0.09873569363521205\n","Validation Accuracy: 0.9762266530126178\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0017945728031918406\n","Training loss per 100 training steps: 0.0050730811740908\n","Training loss per 100 training steps: 0.005093141986851798\n","Training loss epoch: 0.00552819888990914\n","Training accuracy epoch: 0.9983946336537397\n","Validating model...\n","Validation Loss: 0.11057138176901\n","Validation Accuracy: 0.9768438611423093\n","Training epoch: 5\n","Training loss per 100 training steps: 0.003039771690964699\n","Training loss per 100 training steps: 0.005832486606138472\n","Training loss per 100 training steps: 0.005799665729705226\n","Training loss epoch: 0.0061220200664235\n","Training accuracy epoch: 0.9981684937043563\n","Validating model...\n","Validation Loss: 0.10673742824130589\n","Validation Accuracy: 0.9749389857170792\n","Training epoch: 6\n","Training loss per 100 training steps: 0.004264813847839832\n","Training loss per 100 training steps: 0.004490558458273161\n","Training loss per 100 training steps: 0.0038938301498712092\n","Training loss epoch: 0.0037961685183748655\n","Training accuracy epoch: 0.9988523764348824\n","Validating model...\n","Validation Loss: 0.12565474365911786\n","Validation Accuracy: 0.9729867506300771\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 12.84088121666667 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.08627402658263843\n","Validation Accuracy: 0.9710991651653631\n","Validation duration: 0.20576976666667784 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 84.6%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.89      0.91      0.90      4985\n","     Disease       0.74      0.84      0.78      4416\n","\n","   micro avg       0.82      0.88      0.85      9401\n","   macro avg       0.82      0.88      0.84      9401\n","weighted avg       0.82      0.88      0.85      9401\n","\n","!!!!!! Starting model number 4 !!!!!!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Points in X_train after augmentation: 4500\n","Points in y_train after augmentation: 4500\n","Device:  cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 1.7185451984405518\n","Training loss per 100 training steps: 0.14152162518389155\n","Training loss per 100 training steps: 0.09208828817812068\n","Training loss epoch: 0.07337536271793622\n","Training accuracy epoch: 0.9767886944088072\n","Validating model...\n","Validation Loss: 0.08148194707575299\n","Validation Accuracy: 0.9741641664573881\n","Training epoch: 2\n","Training loss per 100 training steps: 0.014639676548540592\n","Training loss per 100 training steps: 0.017365381960747855\n","Training loss per 100 training steps: 0.015572031532455958\n","Training loss epoch: 0.014772238909986848\n","Training accuracy epoch: 0.9955815156576806\n","Validating model...\n","Validation Loss: 0.10328311130167946\n","Validation Accuracy: 0.9761946259281858\n","Training epoch: 3\n","Training loss per 100 training steps: 0.011377661488950253\n","Training loss per 100 training steps: 0.008946233850876145\n","Training loss per 100 training steps: 0.008567879396370283\n","Training loss epoch: 0.008025420653173066\n","Training accuracy epoch: 0.9976081271179015\n","Validating model...\n","Validation Loss: 0.114353518755663\n","Validation Accuracy: 0.9732076282960643\n","Training epoch: 4\n","Training loss per 100 training steps: 0.0007511763833463192\n","Training loss per 100 training steps: 0.008162065564728536\n","Training loss per 100 training steps: 0.007905880004325095\n","Training loss epoch: 0.007572942263948738\n","Training accuracy epoch: 0.9980612397207974\n","Validating model...\n","Validation Loss: 0.10362567108065363\n","Validation Accuracy: 0.9770316848719527\n","Training epoch: 5\n","Training loss per 100 training steps: 0.002708015963435173\n","Training loss per 100 training steps: 0.0048090097884011295\n","Training loss per 100 training steps: 0.004708704196854346\n","Training loss epoch: 0.004570104464290396\n","Training accuracy epoch: 0.998628666706923\n","Validating model...\n","Validation Loss: 0.12311834179692799\n","Validation Accuracy: 0.9748483660129279\n","Training epoch: 6\n","Training loss per 100 training steps: 0.0008791192667558789\n","Training loss per 100 training steps: 0.002417129380305731\n","Training loss per 100 training steps: 0.0030828869719300373\n","Training loss epoch: 0.0030507644155316205\n","Training accuracy epoch: 0.9991882906479418\n","Validating model...\n","Validation Loss: 0.126120131521944\n","Validation Accuracy: 0.9748003327784139\n","Training epoch: 7\n","Patience limit reached\n","Training duration: 12.813361866666673 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["Validating model...\n","Validation Loss: 0.08296005918629586\n","Validation Accuracy: 0.9736451346413149\n","Validation duration: 0.20864893333333992 minutes\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"]},{"output_type":"stream","name":"stdout","text":["F1-score (test): 85.4%\n","              precision    recall  f1-score   support\n","\n","    Chemical       0.89      0.93      0.91      4985\n","     Disease       0.75      0.84      0.79      4416\n","\n","   micro avg       0.82      0.89      0.85      9401\n","   macro avg       0.82      0.88      0.85      9401\n","weighted avg       0.83      0.89      0.86      9401\n","\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"03174a9e298c421db09bae5ab3c7f612":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1347f3d0e6dd480b9710e8faa9f6de00":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"165186d7f5fb43c4a1570c8e753014c3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2820b745bf554c21ab1cb07a8cb6ef91":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_165186d7f5fb43c4a1570c8e753014c3","placeholder":"​","style":"IPY_MODEL_9bc265cb8db247c7958204cdfd8e2cdf","value":" 442M/442M [00:07&lt;00:00, 60.9MB/s]"}},"30fd7733890e43deb85fef8f6d1f0c26":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_73b8a843f1c24871a5bd2ce347e38488","IPY_MODEL_57eb5e4091b6425391e7d24cb66e9c4b","IPY_MODEL_2820b745bf554c21ab1cb07a8cb6ef91"],"layout":"IPY_MODEL_ecf3d5d4026c4744a69df7f7d7fe5f52"}},"57eb5e4091b6425391e7d24cb66e9c4b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1347f3d0e6dd480b9710e8faa9f6de00","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c01ca9f35f0e4024ab39bce7e42b637c","value":442221694}},"73b8a843f1c24871a5bd2ce347e38488":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03174a9e298c421db09bae5ab3c7f612","placeholder":"​","style":"IPY_MODEL_e06107533ab049508edf9f6d724d857c","value":"Downloading: 100%"}},"9bc265cb8db247c7958204cdfd8e2cdf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c01ca9f35f0e4024ab39bce7e42b637c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e06107533ab049508edf9f6d724d857c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ecf3d5d4026c4744a69df7f7d7fe5f52":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0c735b1553040eba5d4121424132937":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_80d599a4d2f84b28a446b2623ec38b41","IPY_MODEL_ff3ed544fa284ef7a3b2b92383f027cc","IPY_MODEL_6536b532f1384782800c806561663765"],"layout":"IPY_MODEL_d557a5729739409d8b81767bcf9d96d3"}},"80d599a4d2f84b28a446b2623ec38b41":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_94b54acd9e8946eb806fcaa617ac06a2","placeholder":"​","style":"IPY_MODEL_bb54d058950645cd94ae5d5586945918","value":"Downloading: 100%"}},"ff3ed544fa284ef7a3b2b92383f027cc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_96511072903a44abbbc015fc8e9b75a4","max":385,"min":0,"orientation":"horizontal","style":"IPY_MODEL_47cddd2f081f498fa57de353e7909669","value":385}},"6536b532f1384782800c806561663765":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af1851777b8b4dce8d9bc711f2df0e90","placeholder":"​","style":"IPY_MODEL_4f9ebcd5f5be4f2daf51be7fc63f80ef","value":" 385/385 [00:00&lt;00:00, 11.4kB/s]"}},"d557a5729739409d8b81767bcf9d96d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94b54acd9e8946eb806fcaa617ac06a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb54d058950645cd94ae5d5586945918":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96511072903a44abbbc015fc8e9b75a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47cddd2f081f498fa57de353e7909669":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"af1851777b8b4dce8d9bc711f2df0e90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f9ebcd5f5be4f2daf51be7fc63f80ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"477c2dee0fde4d288d6089cb972f328a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ff3f6dd76daa475cbed802c23d176a48","IPY_MODEL_359642753acc48319b4d58797d331359","IPY_MODEL_af6b4c0f9127404ba9c3af4e78b6faf9"],"layout":"IPY_MODEL_dcc981fb03b049ef80b77a5f16b1d673"}},"ff3f6dd76daa475cbed802c23d176a48":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8877048532e4cc59523a20c349ac234","placeholder":"​","style":"IPY_MODEL_d4f71e53bb5146f7b9b4abf578f1020f","value":"Downloading: 100%"}},"359642753acc48319b4d58797d331359":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_91eb8b6a07324de09316daa5049eb28c","max":227845,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f80eed4cf1ec4e6386db032ebc96a20c","value":227845}},"af6b4c0f9127404ba9c3af4e78b6faf9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_767cbd9ba11e45149f4bac28d6a6f564","placeholder":"​","style":"IPY_MODEL_d8a05c16f4f44ced9ae6f32d666afe1c","value":" 228k/228k [00:00&lt;00:00, 1.80MB/s]"}},"dcc981fb03b049ef80b77a5f16b1d673":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8877048532e4cc59523a20c349ac234":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4f71e53bb5146f7b9b4abf578f1020f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"91eb8b6a07324de09316daa5049eb28c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f80eed4cf1ec4e6386db032ebc96a20c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"767cbd9ba11e45149f4bac28d6a6f564":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8a05c16f4f44ced9ae6f32d666afe1c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f21508875a904455b573247e5553cd6b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2b8cd25f7f244fd1b323032991dbca86","IPY_MODEL_5ef957cf49484bbb8f6bf20d8fc79517","IPY_MODEL_ceaf7453ae0947fd94af2659458310c4"],"layout":"IPY_MODEL_b9a43f5ad85f47e79bccd9e869f4dd46"}},"2b8cd25f7f244fd1b323032991dbca86":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_070faa6ac15241158df021e1cca53593","placeholder":"​","style":"IPY_MODEL_0e3c57d62f0c4b7c9d987882d18a165f","value":"Downloading: 100%"}},"5ef957cf49484bbb8f6bf20d8fc79517":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_12504dbed6b04ac4b4f1d03fe0f75afc","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_87747ea4d1554723bd454ad4858a4476","value":442221694}},"ceaf7453ae0947fd94af2659458310c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4447dba43f16470182225837b48cdaf0","placeholder":"​","style":"IPY_MODEL_5fd7ba185d6a47369253fea52fa0069b","value":" 442M/442M [00:07&lt;00:00, 62.6MB/s]"}},"b9a43f5ad85f47e79bccd9e869f4dd46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"070faa6ac15241158df021e1cca53593":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e3c57d62f0c4b7c9d987882d18a165f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"12504dbed6b04ac4b4f1d03fe0f75afc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87747ea4d1554723bd454ad4858a4476":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4447dba43f16470182225837b48cdaf0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fd7ba185d6a47369253fea52fa0069b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"832d911852a04f91b1d3dd271897d442":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ea0ec1986af1452eaada3f5e8d220c2c","IPY_MODEL_dc62df9fc01c4cb2a8f870d756ed3068","IPY_MODEL_6b63d1c5e4cf4bdf863cf2caad3a717e"],"layout":"IPY_MODEL_10fc444c3a87424781e90fc0f82c0974"}},"ea0ec1986af1452eaada3f5e8d220c2c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_116b59de6dd14aa4a73d4c962ac76b74","placeholder":"​","style":"IPY_MODEL_a0d3e4eda1e24b35af7efe9f1aff6421","value":"Downloading: 100%"}},"dc62df9fc01c4cb2a8f870d756ed3068":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c12b9f5e647d4fceb168258b83036e71","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_63eb3f5ceb914ef1b903aee4079ff038","value":442221694}},"6b63d1c5e4cf4bdf863cf2caad3a717e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf3e925ddb824227bc0097ea488e60a1","placeholder":"​","style":"IPY_MODEL_5c0f99cfaa7145bbb63d1b468cbbd877","value":" 442M/442M [00:07&lt;00:00, 55.6MB/s]"}},"10fc444c3a87424781e90fc0f82c0974":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"116b59de6dd14aa4a73d4c962ac76b74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0d3e4eda1e24b35af7efe9f1aff6421":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c12b9f5e647d4fceb168258b83036e71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63eb3f5ceb914ef1b903aee4079ff038":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cf3e925ddb824227bc0097ea488e60a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c0f99cfaa7145bbb63d1b468cbbd877":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"gpuClass":"premium"},"nbformat":4,"nbformat_minor":5}